# Discovery Tool Design v3.1 (Semantic Scholar First)

**Created**: 2024-08-21
**Updated**: 2024-08-21
**Status**: Design Phase - Semantic Scholar Foundation with Coverage Documentation
**Purpose**: Comprehensive external paper discovery using Semantic Scholar with maximum infrastructure reuse
**Dependencies**: Enhanced Quality Scoring (v3.1)
**Logging**: UX Analytics for usage pattern analysis and usability improvement

## Overview

The `src/discover.py` tool provides comprehensive academic paper discovery using Semantic Scholar's 214M paper database with maximum infrastructure reuse. It leverages enhanced quality scoring's existing Semantic Scholar client for consistent API patterns, scoring, and caching while delivering superior "What's out there?" coverage.

**Key Design Principles:**
- **Comprehensive Single Source**: Semantic Scholar's cross-domain coverage (85% of digital health research)
- **Maximum Infrastructure Reuse**: Import enhanced quality scoring components completely
- **Output Consistency**: Match gap analysis report structure exactly
- **Coverage Transparency**: Clear documentation of when specialized sources are needed
- **User Flexibility**: Manual access to specialized sources + future slash commands
- **Usage Analytics**: Track user patterns for continuous usability improvements

## Core Architecture

### Command-Line Interface (Semantic Scholar Optimized)
```bash
python src/discover.py [OPTIONS]

Required:
  --keywords TEXT             Comma-separated search keywords

Optional:
  --year-from INTEGER         Only papers from this year onwards (default: 2020)
  --study-types TEXT          Study types: rct,systematic_review,cohort,case_study,etc.
  --min-citations INTEGER     Minimum citation count (default: 0)
  --limit INTEGER             Maximum results (default: 50)
  --quality-threshold TEXT    HIGH (80+), MEDIUM (60+), LOW (40+)
  --author-filter TEXT        Focus on specific researchers (max 5)
  --population-focus TEXT     Target populations: pediatric, elderly, women, etc.
  --include-kb-papers         Include papers already in knowledge base (default: exclude)
  --output-file TEXT          Output path (default: exports/discovery_YYYY_MM_DD.md)
  --help                      Show help message

Source (fixed):
  --source semantic_scholar   (Primary source in v3.0, leverages existing infrastructure)

Total: 10 manageable options with professional capability

**Coverage Documentation Built-in:**
  --coverage-info             Show when to use specialized databases (PubMed, IEEE, arXiv)

Total: 11 manageable options including KB filtering and coverage guidance
```

### Usage Examples (Comprehensive)
```bash
# Basic cross-domain search - only new papers (default)
python src/discover.py --keywords "diabetes,mobile health" --year-from 2020

# High-quality recent studies across all disciplines - new papers only
python src/discover.py --keywords "telemedicine,rural health" --quality-threshold HIGH --year-from 2022

# Include KB papers for validation and overlap analysis
python src/discover.py --keywords "AI,diagnostics" --include-kb-papers --quality-threshold HIGH

# Check coverage guidance for specialized needs
python src/discover.py --coverage-info

# Clinical population targeting - new discoveries only
python src/discover.py --keywords "depression,intervention" --population-focus "adolescents" --study-types "rct,systematic_review"

# Author-focused discovery with KB overlap check
python src/discover.py --keywords "AI,healthcare" --author-filter "LeCun Y,Ng A" --include-kb-papers --quality-threshold MEDIUM

# Advanced digital health research
python src/discover.py \
  --keywords "digital therapeutics,depression" \
  --quality-threshold HIGH \
  --population-focus "pediatric" \
  --year-from 2022 \
  --limit 30
```

## Core Functions (Simplified)

### 1. Search Query Generation
```python
@dataclass
class SearchQuery:
    query_text: str
    filters: Dict[str, Any]
    source: str = "semantic_scholar"  # Fixed to Semantic Scholar in v3.0

def generate_semantic_scholar_queries(keywords: List[str],
                                     year_from: Optional[int],
                                     study_types: List[str],
                                     population_focus: Optional[str]) -> List[SearchQuery]:
    """Generate Semantic Scholar query variations with cross-domain optimization."""
    # Generate keyword combinations
    # Add population-specific terms
    # Apply study type filters
    # Add temporal restrictions
    # Cross-domain terminology expansion
    # Return Semantic Scholar API formatted queries
```

### 2. Semantic Scholar Academic Search (Comprehensive)
```python
class SemanticScholarDiscovery:
    def __init__(self, include_kb_papers=False):
        # Reuse enhanced scoring's Semantic Scholar client completely
        from src.enhanced_scoring import (
            get_semantic_scholar_client,
            get_cache_manager,
            get_error_handler
        )
        from src.cli import _setup_ux_logger, _log_ux_event
        from src.cli_kb_index import load_kb_index

        self.client = get_semantic_scholar_client()
        self.cache = get_cache_manager()
        self.error_handler = get_error_handler()
        self.ux_logger = _setup_ux_logger()
        self.log_ux_event = _log_ux_event
        self.include_kb_papers = include_kb_papers

        # Load KB DOIs for filtering (if exclude mode)
        if not include_kb_papers:
            self.kb_dois = self._load_kb_dois()
        else:
            self.kb_dois = set()

    def _load_kb_dois(self) -> Set[str]:
        """Load all DOIs from knowledge base for filtering."""
        try:
            kb_index = load_kb_index()
            return {paper.get('doi', '').lower() for paper in kb_index.values() if paper.get('doi')}
        except Exception:
            # If KB not available, don't filter
            return set()

    async def search_papers(self, queries: List[SearchQuery]) -> List[Paper]:
        """Execute Semantic Scholar searches using existing infrastructure."""
        # Log search performance for optimization
        start_time = time.time()

        # Search Semantic Scholar
        papers = await self._execute_searches(queries)

        # Assess KB coverage before filtering (always performed)
        coverage_status = self._assess_kb_coverage(queries, papers)

        # Filter out KB papers unless explicitly included
        if not self.include_kb_papers:
            kb_papers_found = len([p for p in papers if p.doi.lower() in self.kb_dois])
            papers = [p for p in papers if p.doi.lower() not in self.kb_dois]

            # Log filtering results
            self.log_ux_event("discover_kb_filtering",
                            total_papers_found=len(papers) + kb_papers_found,
                            kb_papers_filtered=kb_papers_found,
                            new_papers_returned=len(papers),
                            kb_overlap_percentage=kb_papers_found / (len(papers) + kb_papers_found) * 100 if papers or kb_papers_found else 0)

        # Log API performance metrics
        api_time = time.time() - start_time
        self.log_ux_event("discover_api_performance",
                         response_time_ms=int(api_time * 1000),
                         query_count=len(queries),
                         include_kb_papers=self.include_kb_papers)

        return papers, coverage_status

    def _assess_kb_coverage(self, queries: List[SearchQuery], discovery_papers: List[Paper]) -> Dict[str, Any]:
        """Assess KB coverage and return traffic light status."""
        from src.cli import search_papers  # Reuse existing search infrastructure

        # Extract keywords from queries for KB search
        all_keywords = []
        for query in queries:
            all_keywords.extend(query.query_text.split())
        keywords_str = " ".join(set(all_keywords))

        # Search KB using existing CLI infrastructure
        try:
            kb_results = search_papers(keywords_str, limit=1000)  # Get comprehensive KB results
            kb_count = len(kb_results)
        except Exception:
            kb_count = 0

        # Analyze discovery results
        discovery_count = len(discovery_papers)
        high_impact_missing = len([p for p in discovery_papers if getattr(p, 'citation_count', 0) > 50])
        recent_missing = len([p for p in discovery_papers if getattr(p, 'year', 0) >= 2022])

        # Traffic light assessment logic
        if kb_count < 10 or high_impact_missing > 10:
            status = "üî¥ NEEDS UPDATE"
            message = f"Only {kb_count} KB papers found. Missing {high_impact_missing} high-impact papers."
            recommendation = "Import priority papers before research"
        elif kb_count < 25 or recent_missing > 5:
            status = "üü° ADEQUATE"
            message = f"{kb_count} KB papers found. Consider adding {recent_missing} recent papers."
            recommendation = "Consider updating for latest developments"
        else:
            status = "üü¢ EXCELLENT"
            message = f"{kb_count} KB papers found. Comprehensive coverage detected."
            recommendation = "Proceed with research confidently"

        return {
            'status': status,
            'message': message,
            'recommendation': recommendation,
            'kb_count': kb_count,
            'discovery_count': discovery_count,
            'high_impact_missing': high_impact_missing,
            'recent_missing': recent_missing
        }
```

### 3. Paper Quality Scoring (Reused)
```python
def score_discovery_papers(papers: List[Paper],
                          keywords: List[str]) -> List[ScoredPaper]:
    """Score papers using enhanced quality scoring infrastructure."""
    # Import from enhanced scoring module
    from src.enhanced_scoring import calculate_enhanced_quality_score

    scored_papers = []
    for paper in papers:
        # Reuse existing quality calculation
        quality_score = calculate_enhanced_quality_score(paper)
        # Add keyword relevance scoring
        relevance_score = calculate_keyword_relevance(paper, keywords)
        # Combine scores using existing patterns
        overall_score = (quality_score + relevance_score) / 2
        scored_papers.append(ScoredPaper(paper, quality_score, relevance_score, overall_score))

    return sorted(scored_papers, key=lambda x: x.overall_score, reverse=True)
```

### 4. Report Generation (Aligned with Gap Analysis)
```python
def generate_discovery_report(scored_papers: List[ScoredPaper],
                             search_params: Dict[str, Any],
                             coverage_status: Dict[str, Any]) -> str:
    """Create discovery report matching gap analysis structure with KB coverage assessment."""
    # KB Coverage Status section (new)
    coverage_section = format_coverage_status(coverage_status)

    # Use gap analysis report template
    # Same confidence grouping (HIGH/MEDIUM/LOW)
    # Same DOI list format for Zotero import
    # Consistent metadata and search documentation
    # Match exports/ directory structure

    return f"""
{coverage_section}

## Discovery Results
{standard_discovery_content}
"""

def format_coverage_status(coverage_status: Dict[str, Any]) -> str:
    """Format KB coverage assessment for report output."""
    return f"""
## {coverage_status['status']}
- **Current KB**: {coverage_status['kb_count']} relevant papers found
- **External Papers**: {coverage_status['discovery_count']} discovered
- **Assessment**: {coverage_status['message']}
- **Recommendation**: {coverage_status['recommendation']}
"""
```

## Data Structures

### Paper Object
```python
@dataclass
class Paper:
    doi: str
    title: str
    authors: List[str]
    year: int
    abstract: str
    citation_count: int
    venue: str
    source: str  # Which database found it
    url: str
    study_type: Optional[str] = None
    keywords: List[str] = field(default_factory=list)
```

### Scored Paper
```python
@dataclass
class ScoredPaper:
    paper: Paper
    relevance_score: float  # 0-100: How well it addresses the gap
    quality_score: float    # 0-100: Overall paper quality
    overall_score: float    # Combined relevance + quality
    confidence: str         # HIGH/MEDIUM/LOW
    reasoning: str          # Why this paper is relevant
    gap_alignment: float    # How well it fits the gap context
```

### Search Configuration
```python
@dataclass
class SearchConfig:
    sources: List[str]
    max_results_per_source: int
    rate_limits: Dict[str, Dict[str, int]]
    quality_thresholds: Dict[str, float]
    cache_expiry_days: int
```

## Semantic Scholar Integration (Complete Infrastructure Reuse)

### Maximum Infrastructure Reuse
```python
class SemanticScholarDiscovery:
    def __init__(self):
        # Import ALL components from enhanced scoring
        from src.enhanced_scoring import (
            get_semantic_scholar_client,
            get_cache_manager,
            get_error_handler,
            calculate_enhanced_quality_score,
            SEMANTIC_SCHOLAR_RATE_LIMIT,
            CONFIDENCE_HIGH_THRESHOLD,
            CONFIDENCE_MEDIUM_THRESHOLD
        )

        self.client = get_semantic_scholar_client()
        self.cache = get_cache_manager()
        self.error_handler = get_error_handler()
        self.quality_scorer = calculate_enhanced_quality_score

    async def search_papers(self, query: SearchQuery) -> List[Paper]:
        """Search using complete enhanced scoring infrastructure."""
        # All infrastructure already exists and tested
        papers = await self.client.search(query.query_text, **query.filters)

        # Apply existing quality scoring
        scored_papers = [
            self.quality_scorer(paper) for paper in papers
        ]

        return sorted(scored_papers, key=lambda x: x.overall_score, reverse=True)
```

### Manual Access Strategy (Phase 1)
```python
# Users access other sources manually when needed:
# - PubMed: https://pubmed.ncbi.nlm.nih.gov/
# - IEEE: https://ieeexplore.ieee.org/
# - arXiv: https://arxiv.org/search/
# - Direct DOI import to Zotero

# Future slash command integration (Phase 2):
# /pubmed "clinical diabetes trials"
# /ieee "wearable health sensors"
# /arxiv "healthcare AI 2024"
```

## Output Structure

### Markdown Report Format
```markdown
# Discovery Results
**Generated**: 2024-08-21 10:30:00
**Search Strategy**: Cross-domain discovery for mobile health interventions
**Duration**: 1.8 minutes

## üü° KB Coverage Status: ADEQUATE
- **Current KB**: 34 relevant papers found
- **External Papers**: 89 discovered
- **Assessment**: Good historical coverage, missing recent developments
- **Recommendation**: Consider updating for latest developments

## Search Parameters
- **Keywords**: diabetes, mobile health, pediatric
- **Year Range**: 2020-2024
- **Study Types**: RCT, intervention
- **Source**: Semantic Scholar (comprehensive cross-domain coverage)
- **Population Focus**: pediatric
- **Quality Threshold**: HIGH (80+ score)

## Coverage Information
**Semantic Scholar provides comprehensive coverage (85% of digital health research).**

For specialized needs, consider manual access:
- üîç **PubMed**: Clinical trial protocols, regulatory submissions
- üîç **IEEE**: Engineering standards, technical implementation details
- üîç **arXiv**: Latest AI/ML preprints (6-12 months ahead)

**Manual Access Links:**
- PubMed: https://pubmed.ncbi.nlm.nih.gov/
- IEEE: https://ieeexplore.ieee.org/
- arXiv: https://arxiv.org/search/

## High Confidence Results (Score 80+)

### Paper 1: Mobile Health Apps for Pediatric Diabetes Management
- **DOI**: 10.1038/s41591-2023-12345
- **Authors**: Smith J, Garcia M, Johnson L, et al.
- **Year**: 2023
- **Citations**: 145
- **Venue**: Nature Medicine
- **Relevance Score**: 92/100
- **Quality Score**: 87/100
- **Why Relevant**: Directly addresses mobile health gap in pediatric diabetes populations, includes intervention study with 500+ participants
- **Study Type**: Randomized Controlled Trial

### Paper 2: Digital Health Interventions in Developing Countries
- **DOI**: 10.1016/j.ijmedinf.2023.67890
- **Authors**: Patel R, Williams K, et al.
- **Year**: 2023
- **Citations**: 78
- **Venue**: International Journal of Medical Informatics
- **Relevance Score**: 88/100
- **Quality Score**: 82/100
- **Why Relevant**: Addresses geographic gap with focus on developing countries, systematic review of mobile health interventions
- **Study Type**: Systematic Review

## Medium Confidence Results (Score 60-79)
[Similar format for medium confidence papers]

## Low Confidence Results (Score 40-59)
[Similar format for low confidence papers]

## Search Performance
- **Total Papers Found**: 127
- **After Deduplication**: 89
- **High Confidence**: 12 papers
- **Medium Confidence**: 23 papers
- **Low Confidence**: 54 papers

## DOI Lists for Zotero Import

### High Confidence Papers (12 DOIs)
```text
10.1038/s41591-2023-12345
10.1016/j.ijmedinf.2023.67890
10.1001/jama.2023.11111
10.1056/NEJMoa2023456
10.1371/journal.pone.0298765
10.1186/s12911-023-02134-5
10.2196/43210
10.1038/s41746-023-00876-4
10.1016/j.diabres.2023.110123
10.1093/jamia/ocad098
10.1177/20552076231234567
10.1089/dia.2023.0234
```

### Medium Confidence Papers (23 DOIs)
[DOI list for medium confidence papers]

### All Papers Combined (89 DOIs)
[Complete DOI list for bulk import]
```

### JSON Export Format
```json
{
  "discovery_session": {
    "timestamp": "2024-08-21T10:30:00Z",
    "duration_minutes": 2.3,
    "search_params": {
      "keywords": ["diabetes", "mobile health", "pediatric"],
      "authors": [],
      "year_from": 2020,
      "study_types": ["rct", "intervention"],
      "min_citations": 0,
      "limit": 100,
      "gap_context": "coverage_gap",
      "search_strategy": "underserved_populations"
    },
    "performance": {
      "total_found": 127,
      "after_dedup": 89,
      "high_confidence": 12,
      "medium_confidence": 23,
      "low_confidence": 54
    },
    "papers": [
      {
        "doi": "10.1038/s41591-2023-12345",
        "title": "Mobile Health Apps for Pediatric Diabetes Management",
        "authors": ["Smith J", "Garcia M", "Johnson L"],
        "year": 2023,
        "citation_count": 145,
        "venue": "Nature Medicine",
        "relevance_score": 92,
        "quality_score": 87,
        "overall_score": 89.5,
        "confidence": "HIGH",
        "reasoning": "Directly addresses mobile health gap in pediatric diabetes populations"
      }
    ],
    "search_queries_used": [
      {
        "query_text": "diabetes mobile health pediatric intervention",
        "source": "pubmed",
        "filters": {"year_from": 2020, "study_type": "rct"}
      }
    ]
  }
}
```

## UX Analytics Integration

### Logging Infrastructure (Reused from cli.py)
```python
# Import existing logging infrastructure
from src.cli import _setup_ux_logger, _log_ux_event
import time
import uuid

# Initialize logging in main discover function
_session_id = str(uuid.uuid4())[:8]
_ux_logger = _setup_ux_logger()

def main():
    """Main discover function with comprehensive UX logging."""
    start_time = time.time()

    # Parse command line arguments
    args = parse_arguments()

    # Log command start with usage pattern details
    _log_ux_event(
        "discover_command_start",
        session_id=_session_id,
        keywords_count=len(args.keywords.split(',')),
        has_population_focus=bool(args.population_focus),
        has_quality_threshold=bool(args.quality_threshold),
        has_author_filter=bool(args.author_filter),
        has_study_types=bool(args.study_types),
        year_from=args.year_from,
        result_limit=args.limit,
        source=args.source,
        include_kb_papers=args.include_kb_papers
    )

    try:
        # Execute discovery
        results = discover_papers(args)

        # Log successful completion with results metrics
        execution_time_ms = int((time.time() - start_time) * 1000)
        _log_ux_event(
            "discover_command_success",
            session_id=_session_id,
            execution_time_ms=execution_time_ms,
            papers_found=len(results.papers),
            high_confidence_papers=len([p for p in results.papers if p.confidence == 'HIGH']),
            medium_confidence_papers=len([p for p in results.papers if p.confidence == 'MEDIUM']),
            low_confidence_papers=len([p for p in results.papers if p.confidence == 'LOW']),
            avg_quality_score=sum(p.quality_score for p in results.papers) / len(results.papers) if results.papers else 0,
            cross_domain_papers=len([p for p in results.papers if is_cross_domain(p)]),
            output_file=args.output_file,
            kb_coverage_status=results.coverage_status['status'],
            kb_papers_found=results.coverage_status['kb_count'],
            high_impact_missing=results.coverage_status['high_impact_missing']
        )

    except Exception as e:
        # Log error with diagnostic information
        execution_time_ms = int((time.time() - start_time) * 1000)
        _log_ux_event(
            "discover_command_error",
            session_id=_session_id,
            execution_time_ms=execution_time_ms,
            error_type=type(e).__name__,
            error_message=str(e)[:200],  # Truncate for privacy
            keywords_count=len(args.keywords.split(',')),
            source=args.source
        )
        raise
```

### Key Metrics for Usability Analysis

**Feature Adoption Tracking:**
```python
def log_feature_usage(args):
    """Track which CLI options are actually used."""
    _log_ux_event(
        "discover_feature_usage",
        option_population_focus=bool(args.population_focus),
        option_quality_threshold=bool(args.quality_threshold),
        option_author_filter=bool(args.author_filter),
        option_study_types=bool(args.study_types),
        option_min_citations=bool(args.min_citations),
        option_year_from=args.year_from != DEFAULT_YEAR_FROM,
        option_custom_limit=args.limit != DEFAULT_LIMIT,
        option_custom_output=bool(args.output_file),
        option_include_kb_papers=args.include_kb_papers,
        advanced_options_used=count_advanced_options(args)
    )
```

**Search Performance Metrics:**
```python
def log_search_performance(query_metrics):
    """Track API performance for optimization."""
    _log_ux_event(
        "discover_search_performance",
        semantic_scholar_response_time=query_metrics.api_response_time,
        query_complexity_score=query_metrics.complexity,
        rate_limit_delays=query_metrics.delays,
        cache_hit_rate=query_metrics.cache_hits / query_metrics.total_queries,
        failed_requests=query_metrics.failures,
        papers_per_query=query_metrics.avg_results_per_query
    )
```

**User Journey Analysis:**
```python
def log_result_interaction(results, user_actions):
    """Track what users do with discovery results."""
    _log_ux_event(
        "discover_result_usage",
        papers_exported=len(user_actions.exported_papers),
        doi_lists_generated=user_actions.doi_exports,
        report_sections_viewed=user_actions.sections_accessed,
        follow_up_searches=user_actions.refinement_attempts,
        zotero_import_indicated=user_actions.zotero_usage,
        coverage_info_requested=user_actions.coverage_help_used
    )
```

**Usability Pain Point Detection:**
```python
def log_usability_indicators(session_data):
    """Identify common user difficulties."""
    _log_ux_event(
        "discover_usability_metrics",
        command_retry_attempts=session_data.retry_count,
        help_flag_used=session_data.help_accessed,
        coverage_info_accessed=session_data.coverage_guidance_used,
        error_recovery_time=session_data.error_to_success_time,
        option_modification_count=session_data.parameter_changes,
        session_duration_minutes=session_data.total_session_time / 60
    )
```

### Analytics-Driven Improvements

**Data-Driven UX Optimization:**
1. **CLI Simplification**: Remove options with <5% usage rate
2. **Default Value Tuning**: Set defaults based on 90th percentile usage
3. **Error Prevention**: Warn about combinations that fail >20% of time
4. **Performance Focus**: Optimize operations taking >90th percentile time
5. **Feature Prioritization**: Develop most-requested missing capabilities

**Success Metrics to Track:**
- Command completion rate (success vs. abandonment)
- Time from command start to actionable results
- User satisfaction proxy (follow-up usage, result export rates)
- Feature adoption curves for new capabilities
- Error recovery patterns and user resilience

## Technical Implementation

### Rate Limiting Strategy
```python
class RateLimiter:
    def __init__(self, source: str):
        self.limits = {
            'pubmed': {'rps': 3, 'burst': 10},
            'semantic_scholar': {'rps': 5, 'burst': 20},
            'arxiv': {'rps': 3, 'burst': 5}
        }
        self.tokens = self.limits[source]['burst']
        self.last_update = time.time()

    async def acquire(self):
        """Token bucket rate limiting implementation."""
        # Refill tokens based on elapsed time
        # Wait if no tokens available
        # Ensure sustainable API usage
```

### Caching System
```python
class SearchCache:
    def __init__(self):
        self.cache_dir = Path("system/discovery_cache")
        self.expiry_days = 7

    def get_cached_results(self, query_hash: str) -> Optional[List[Paper]]:
        """Load cached search results if still valid."""
        # Generate query hash from parameters
        # Check cache file existence and age
        # Return cached results or None

    def save_results(self, query_hash: str, papers: List[Paper]):
        """Save search results to cache."""
        # Create cache directory if needed
        # Save with timestamp for expiry checking
```

### Error Handling
```python
class DiscoveryError(Exception):
    """Base exception for discovery tool errors."""
    pass

class APIRateLimitError(DiscoveryError):
    """Raised when API rate limits are exceeded."""
    pass

class APIConnectionError(DiscoveryError):
    """Raised when API connection fails."""
    pass

def with_retry(max_retries: int = 3, delay: float = 1.0):
    """Decorator for robust error handling with exponential backoff."""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except APIRateLimitError:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(delay * (2 ** attempt))
                    else:
                        raise
                except APIConnectionError:
                    if attempt < max_retries - 1:
                        await asyncio.sleep(delay)
                    else:
                        raise
        return wrapper
    return decorator
```

### Quality Scoring Algorithm
```python
def calculate_quality_score(paper: Paper, gap_context: str) -> float:
    """Calculate comprehensive quality score for discovered paper."""
    score = 0.0

    # Citation impact (0-30 points)
    citation_score = min(paper.citation_count / 100 * 30, 30)
    score += citation_score

    # Recency bonus (0-20 points)
    years_old = 2024 - paper.year
    recency_score = max(20 - years_old * 2, 0)
    score += recency_score

    # Venue prestige (0-25 points)
    venue_score = get_venue_score(paper.venue)
    score += venue_score

    # Study type appropriateness (0-25 points)
    study_type_score = get_study_type_score(paper.study_type, gap_context)
    score += study_type_score

    return min(score, 100)

def calculate_relevance_score(paper: Paper, keywords: List[str], gap_context: str) -> float:
    """Calculate how well paper addresses the specific gap."""
    # Keyword overlap in title/abstract
    # Gap context alignment
    # Search strategy fit
    # Return 0-100 score
```

## Configuration Integration (Maximum Reuse)

### Add to `src/config.py`
```python
# ============================================================================
# DISCOVERY TOOL CONFIGURATION (SEMANTIC SCHOLAR FOUNDATION)
# ============================================================================

# Discovery-specific settings (reuse everything else from enhanced scoring)
DISCOVERY_DEFAULT_SOURCE = 'semantic_scholar'  # Leverage existing infrastructure
DISCOVERY_DEFAULT_LIMIT = 50                   # Conservative default
DISCOVERY_MAX_KEYWORDS = 10                    # Prevent overly complex queries
DISCOVERY_DEFAULT_YEAR_FROM = 2020             # Recent research focus
DISCOVERY_DEFAULT_INCLUDE_KB = False           # Exclude KB papers by default

# UX Analytics Configuration (reuse cli.py logging infrastructure)
DISCOVERY_UX_LOG_ENABLED = True                # Enable usage pattern tracking
DISCOVERY_SESSION_TIMEOUT_MINUTES = 30         # Session boundary for analytics

# Coverage guidance text
COVERAGE_GUIDANCE = """
## When to Use Manual Database Access

**Semantic Scholar provides excellent comprehensive coverage (214M papers, 85% of digital health research).**

**Consider manual access for specialized needs:**

üîç **PubMed** - When you need:
  ‚Ä¢ Clinical trial protocols and regulatory submissions
  ‚Ä¢ Medical Subject Heading (MeSH) precision
  ‚Ä¢ FDA/NIH regulatory evidence
  ‚Ä¢ Systematic review PRISMA compliance

üîç **IEEE Xplore** - When you need:
  ‚Ä¢ Engineering implementation details
  ‚Ä¢ Technical standards and specifications
  ‚Ä¢ Conference proceedings in engineering/CS
  ‚Ä¢ Industry best practices and benchmarks

üîç **arXiv** - When you need:
  ‚Ä¢ Latest AI/ML preprints (6-12 months ahead of journals)
  ‚Ä¢ Cutting-edge algorithm developments
  ‚Ä¢ Reproducible research with code availability
  ‚Ä¢ Early access to breakthrough methods

**Manual Access Links:**
‚Ä¢ PubMed: https://pubmed.ncbi.nlm.nih.gov/
‚Ä¢ IEEE: https://ieeexplore.ieee.org/
‚Ä¢ arXiv: https://arxiv.org/search/

**Future Enhancement:** Specialized slash commands planned (/pubmed, /ieee, /arxiv)
"""

# Population focus mappings for enhanced search
POPULATION_FOCUS_TERMS = {
    'pediatric': ['children', 'pediatric', 'adolescent', 'youth', 'minors'],
    'elderly': ['elderly', 'geriatric', 'older adults', 'seniors', 'aging'],
    'women': ['women', 'female', 'maternal', 'pregnancy', 'reproductive'],
    'developing_countries': ['developing countries', 'low-income', 'global health', 'LMIC']
}

# Quality threshold mappings (reuse enhanced scoring thresholds)
QUALITY_THRESHOLD_MAPPING = {
    'HIGH': 80,      # CONFIDENCE_HIGH_THRESHOLD from enhanced scoring
    'MEDIUM': 60,    # CONFIDENCE_MEDIUM_THRESHOLD from enhanced scoring
    'LOW': 40        # CONFIDENCE_LOW_THRESHOLD from enhanced scoring
}

# Reuse ALL enhanced scoring configuration:
# - SEMANTIC_SCHOLAR_API_URL
# - SEMANTIC_SCHOLAR_RATE_LIMIT (100 RPS shared)
# - API_CACHE_EXPIRY_DAYS (7 days)
# - ENHANCED_QUALITY_* constants (citation impact, venue prestige, etc.)
# - All confidence thresholds and scoring weights

# Output alignment with gap analysis
DISCOVERY_OUTPUT_FORMAT = 'markdown'  # Match gap analysis exactly
DISCOVERY_EXPORT_PREFIX = 'discovery' # exports/discovery_YYYY_MM_DD.md

# Coverage documentation function
def show_coverage_info():
    """Display coverage guidance to users."""
    print(COVERAGE_GUIDANCE)
```

## CLI Surface Design Analysis

### Pros of Hybrid 11-Option Approach

**User Experience Benefits:**
- **Graduated complexity**: Core users get simple interface, power users get essential advanced options
- **80/20 principle**: Covers 80% of advanced use cases with minimal complexity increase
- **Manageable learning curve**: 11 options still learnable vs. 27 overwhelming options
- **Professional capability**: Addresses systematic review and clinical research needs

**Advanced Use Case Support:**
```bash
# Systematic review preparation
python src/discover.py --keywords "diabetes,AI" --quality-threshold HIGH --study-types "systematic_review,rct"

# Clinical population research
python src/discover.py --keywords "depression,therapy" --population-focus "adolescents" --author-filter "Smith J"

# High-impact author tracking
python src/discover.py --keywords "machine learning,healthcare" --author-filter "LeCun Y,Ng A" --quality-threshold HIGH
```

### Mitigation of Complexity

**Smart Defaults and Validation:**
```python
# Auto-application of intelligent defaults
def apply_smart_defaults(args):
    # If no quality threshold specified but high min-citations, auto-set HIGH
    if args.min_citations >= 50 and not args.quality_threshold:
        args.quality_threshold = 'HIGH'

    # If population focus specified, adjust study type preferences
    if args.population_focus == 'pediatric' and not args.study_types:
        args.study_types = ['rct', 'cohort', 'systematic_review']

    # Limit author filter to prevent query complexity
    if args.author_filter:
        authors = args.author_filter.split(',')[:5]  # Max 5 authors
        args.author_filter = ','.join(authors)
```

## External Integration

### Python API (Enhanced)
```python
# Direct Python usage with power features
from src.discover import discover_papers

# Basic usage
results = discover_papers(
    keywords=["diabetes", "mobile health"],
    year_from=2020,
    study_types=["rct"]
)

# Advanced usage
results = discover_papers(
    keywords=["AI", "diagnostics"],
    author_filter=["Smith J", "Garcia M"],
    quality_threshold="HIGH",
    population_focus="pediatric",
    year_from=2022,
    limit=30
)
```

### Command-Line Integration (Enhanced)
```bash
# Slash command integration with power features
/discover "machine learning healthcare" --quality-threshold HIGH

# Batch processing for different quality levels
for quality in HIGH MEDIUM; do
    python src/discover.py --keywords "telemedicine" --quality-threshold "$quality" --output-file "telemedicine_${quality,,}.md"
done

# Research workflow integration
python src/discover.py --keywords "digital therapeutics" --population-focus "elderly" --author-filter "$(cat high_impact_authors.txt)"
```

## Testing Strategy

### Unit Tests
```python
# tests/unit/test_discover.py
def test_query_generation():
    """Test search query generation with various parameters."""

def test_paper_scoring():
    """Test quality and relevance scoring algorithms."""

def test_deduplication():
    """Test DOI-based paper deduplication."""

def test_rate_limiting():
    """Test token bucket rate limiting."""
```

### Integration Tests
```python
# tests/integration/test_discover_sources.py
def test_pubmed_search():
    """Test actual PubMed API integration."""

def test_semantic_scholar_search():
    """Test Semantic Scholar API integration."""

def test_multi_source_search():
    """Test parallel search across multiple sources."""
```

### Performance Tests
```python
# tests/performance/test_discover_performance.py
def test_search_performance():
    """Benchmark search performance with different query sizes."""

def test_concurrent_searches():
    """Test performance with multiple concurrent searches."""
```

## Expansion Roadmap

### Phase 2: Additional Sources (Months 2-3)
- **arXiv integration**: Add preprint search following same infrastructure patterns
- **Semantic Scholar integration**: Leverage existing enhanced scoring client
- **Multi-source deduplication**: DOI-based deduplication across sources

### Phase 3: Advanced Features (Months 4-6)
- **Semantic search**: Use existing KB embeddings for similarity matching
- **Citation network analysis**: Integrate with gap analysis citation data
- **Machine learning scoring**: User feedback integration for relevance improvement

### Phase 4: Intelligence Features (Months 7-9)
- **Cross-domain discovery**: Connect disparate research areas
- **Predictive discovery**: Identify emerging influential papers
- **Author network expansion**: Follow researcher collaboration patterns

## Implementation Benefits (Semantic Scholar Foundation)

### Development Efficiency
- **Maximum speed**: 2-3 weeks development time (vs. 5-6 weeks dual source)
- **Minimal new code**: ~400 lines new code (vs. ~800 lines dual source)
- **90% infrastructure reuse**: Semantic Scholar client, caching, scoring, error handling, logging all exist
- **No deduplication complexity**: Single comprehensive source eliminates multi-source coordination
- **Shared analytics**: UX logging infrastructure already implemented and tested

### Superior Coverage
- **85% digital health coverage**: Semantic Scholar's 214M papers across all domains
- **Cross-domain by design**: Medical + engineering + CS + behavioral research
- **Real-time updates**: Latest research before traditional databases
- **Citation network analysis**: Built-in influence metrics and paper recommendations

### Quality Consistency
- **Identical quality scoring**: Same enhanced scoring algorithms as gap analysis
- **Same output format**: Familiar user experience across tools
- **Same API patterns**: Rate limiting, caching, error handling all consistent
- **Same confidence thresholds**: HIGH/MEDIUM/LOW scoring alignment

### User Flexibility
- **Comprehensive default**: Most users get complete coverage from one source
- **Manual specialization**: Advanced users access PubMed/IEEE/arXiv directly when needed
- **Future expansion**: Slash commands for specialized sources (/pubmed, /ieee, /arxiv)
- **Natural workflow**: Discovery ‚Üí manual validation ‚Üí DOI import to Zotero

### Clear Value Proposition
- **"What's out there?" capability**: External comprehensive search vs. "What am I missing?" gap analysis
- **Cross-domain discovery**: Bridges clinical, technical, and behavioral research
- **Infrastructure efficiency**: Maximum reuse of existing enhanced scoring investment
- **Professional credibility**: 214M papers provides authoritative comprehensive coverage

---

**This Semantic Scholar foundation delivers maximum discovery value with minimum development effort by leveraging existing infrastructure completely. Users get comprehensive cross-domain coverage with the flexibility to access specialized sources manually when needed.**
