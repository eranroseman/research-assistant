{
  "paper_id": "VS9HVEI2",
  "title": "How theories, models, and frameworks have been used to implement digital health interventions in services for people with severe mental health problems: a scoping review",
  "abstract": "Background Digital health interventions have the potential to improve the efficacy and accessibility of mental health services for people with severe mental health problems, but their integration into routine practice is a challenge. The real-world implementation of digital health interventions should be considered alongside digital intervention development. However, little is known about the quality of implementation research in this area, including the extent to which implementation science theories, models and frameworks are used. The aim of this review was to synthesise evidence regarding the application of theories, models and frameworks in research investigating the implementation of digital health interventions in services for people with severe mental health problems. Secondary aims were to consider the contexts within which studies had been undertaken and the degree of service user involvement in this research. Methods A scoping review method was employed. Electronic databases were systematically searched for published papers in English and reference lists of included studies were hand searched. Included studies used an implementation science theory, model, or framework to understand, guide or evaluate the implementation of digital health interventions in services for people with severe mental health problems. \n Results Twelve eligible studies were identified. Studies were primarily undertaken in community mental health services with staff participants and there was variation in the types of digital interventions that were investigated. Eight different implementation science theories, models, and frameworks were used and were mainly employed to guide qualitative analysis. Most studies were undertaken in the early exploratory stages of implementation projects and there was little evidence regarding factors affecting the longer-term sustainment of digital health interventions in practice. Only one study reported the inclusion of service users in the design of the implementation study.",
  "year": 2014,
  "date": "2014",
  "journal": "World Psychiatry",
  "publication": "World Psychiatry",
  "authors": [
    {
      "forename": "Sandra",
      "surname": "Bucci",
      "name": "Sandra Bucci",
      "affiliation": "1  Division of Psychology and Mental Health , Faculty of Biology , Medicine and Health , Manchester Academic Health Sciences , School of Health Sciences , The University of Manchester , Manchester , UK \n\t\t\t\t\t\t\t\t Division of Psychology and Mental Health \n\t\t\t\t\t\t\t\t Faculty of Biology \n\t\t\t\t\t\t\t\t Medicine and Health \n\t\t\t\t\t\t\t\t Manchester Academic Health Sciences \n\t\t\t\t\t\t\t\t School of Health Sciences \n\t\t\t\t\t\t\t\t The University of Manchester \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Manchester \n\t\t\t\t\t\t\t\t\t UK",
      "email": "sandra.bucci@manchester.ac.uk"
    },
    {
      "forename": "Hannah",
      "surname": "Ball",
      "name": "Hannah Ball",
      "affiliation": "1  Division of Psychology and Mental Health , Faculty of Biology , Medicine and Health , Manchester Academic Health Sciences , School of Health Sciences , The University of Manchester , Manchester , UK \n\t\t\t\t\t\t\t\t Division of Psychology and Mental Health \n\t\t\t\t\t\t\t\t Faculty of Biology \n\t\t\t\t\t\t\t\t Medicine and Health \n\t\t\t\t\t\t\t\t Manchester Academic Health Sciences \n\t\t\t\t\t\t\t\t School of Health Sciences \n\t\t\t\t\t\t\t\t The University of Manchester \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Manchester \n\t\t\t\t\t\t\t\t\t UK"
    },
    {
      "forename": "Emily",
      "surname": "Eisner",
      "name": "Emily Eisner",
      "affiliation": "1  Division of Psychology and Mental Health , Faculty of Biology , Medicine and Health , Manchester Academic Health Sciences , School of Health Sciences , The University of Manchester , Manchester , UK \n\t\t\t\t\t\t\t\t Division of Psychology and Mental Health \n\t\t\t\t\t\t\t\t Faculty of Biology \n\t\t\t\t\t\t\t\t Medicine and Health \n\t\t\t\t\t\t\t\t Manchester Academic Health Sciences \n\t\t\t\t\t\t\t\t School of Health Sciences \n\t\t\t\t\t\t\t\t The University of Manchester \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Manchester \n\t\t\t\t\t\t\t\t\t UK"
    },
    {
      "forename": "Jennifer",
      "surname": "Nicholas",
      "name": "Jennifer Nicholas",
      "affiliation": "3  Orygen , Melbourne , Australia \n\t\t\t\t\t\t\t\t Orygen \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Melbourne \n\t\t\t\t\t\t\t\t\t Australia"
    },
    {
      "forename": "Paul",
      "surname": "Wilson",
      "name": "Paul Wilson",
      "affiliation": "5  Centre for Primary Care and Health Services Research , Division of Population Health , Health Services Research and Primary Care , School of Health Sciences , The University of Manchester , Manchester , UK \n\t\t\t\t\t\t\t\t Centre for Primary Care and Health Services Research \n\t\t\t\t\t\t\t\t Division of Population Health \n\t\t\t\t\t\t\t\t Health Services Research and Primary Care \n\t\t\t\t\t\t\t\t School of Health Sciences \n\t\t\t\t\t\t\t\t The University of Manchester \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Manchester \n\t\t\t\t\t\t\t\t\t UK"
    }
  ],
  "doi": "",
  "keywords": [
    "Implementation science",
    "Digital health interventions",
    "Severe mental health problems",
    "Scoping review"
  ],
  "sections": [
    {
      "title": "Background",
      "text": "Severe mental health problems (SMI) such as schizophrenia and bipolar disorder present significant health, social and economic challenges, both for individuals and for wider society  [1, 2] . The current treatment offer for people with SMI is insufficient. Mental health services are chronically underfunded and staff vacancies, long waiting lists, time-limited interventions and prioritisation of crisis care hamper services' ability to provide individualised evidence-based interventions for people with SMI  [3] [4] [5] . Indeed, one third of those with SMI in the United States do not receive any treatment, and globally 71% of people with SMI do not receive mental health care  [6] .\n\nDigital health interventions (DHIs) offer the potential to improve access to healthcare for people with SMI. DHIs can be defined as a discrete functionality of digital technology that is applied to achieve health objectives  [7] : they can be delivered directly to the user and/or integrated into service provision. DHIs have been found to be acceptable and usable for people with SMI  [8] [9] [10] [11]  and, although efficacy research is in its infancy, there is preliminary evidence that DHIs can improve mood, cognitive and social outcomes for this client group  [8, [12] [13] [14] . Furthermore, people with SMI report that DHIs can help to facilitate communication about their experiences with clinicians and enable greater choice and control over their healthcare, which may lead to improved access to appropriate interventions and support  [10, 15] . Integrating DHIs into mental healthcare delivery can also reduce clinician workload, increase service user engagement, and enable the widespread dissemination of evidencebased care, particularly in rural areas and developing countries  [16] .\n\nDespite their potential to improve the accessibility and effectiveness of mental health services, there are widespread challenges to the sustained adoption of DHIs in routine clinical practice, with most efforts to implement DHIs failing  [17] . The real-world implementation of evidence-based interventions is notoriously complex, with novel clinical innovations taking an average of 17 years to be implemented  [18] . There are also unique challenges to implementing DHIs: issues related to data security, costs, interoperability with exiting healthcare technology, and clinician resistance to novel technologies have been found to impede their implementation in clinical care  [19] [20] [21] .\n\nFurthermore, people with SMI, and the services that support them, present with personal and contextual factors that affect the implementation of DHIs. People with SMI experience disproportionately high levels of social and economic disadvantage  [22]  and commonly experience motivational and cognitive difficulties which can make engaging with interventions and services challenging  [23, 24] . Indeed, the severity of mental health symptomatology, and the interplay between service users' mental health symptoms and DHIs, have been found to impact on DHI engagement  [25, 26] . Additionally, clinicians' concerns about risks, low staff morale and underfunding of mental health services, have been suggested as unique factors that likely affect the adoption of DHIs in services for people with SMI  [27] . Mental health clinicians are deemed to be more 'hands-on' than most other non-mental health practitioners, often placing great importance on the relational and observational aspects (i.e., observing people's behaviours and emotions) of their work  [28] . This is particularly pertinent in services that support people with SMI, where service users are often assigned name key workers and service user-clinician relationships, collaborative decision making, and active involvement in interventions by service users are intended to be at the cornerstone of care. The unique multi-level complexity of this implementation context highlights the need for comprehensive, systematic research on the implementation of DHIs in this area.\n\nGiven the challenges to implementing DHIs in healthcare for people with SMI, researchers have argued that the implementation and sustainment of DHIs in routine care should be considered from the earliest stages of DHI development, and that co-production with end-users (e.g. administrators, service users, clinicians) throughout DHI development, testing and implementation is important in facilitating greater implementation success  [29] . in a variety of real-world contexts using theoretically or empirically supported implementation strategies  [30] .\n\nGiven that implementation is a multi-faceted, complex process, there is increasing emphasis on the use of theories, models, and frameworks (TMFs) to theoretically underpin implementation research and facilitate understanding of implementation processes and outcomes  [31] . TMFs offer an efficient way of generalising findings across diverse settings by providing explicit explanations of implementation-related phenomena: they provide a common language and facilitate shared understanding across disciplines  [32, 33] . TMFs also help to inform all phases of research by helping to frame study questions, anchor existing literature, clarify constructs to be assessed, describe relationships to be tested, and contextualise findings  [34] . Nilsen  [35]  identified five main types of TMFs applicable to implementation research: process models, which guide the step-by-step planning of implementing an intervention from pre-implementation to sustainability; determinant frameworks, classic theories, implementation theories, which can all be used to identify barriers and facilitators to implementation; and evaluation frameworks, which evaluate implementation effectiveness. Implementation researchers can employ one or multiple TMFs to address their research questions, and it is commonplace for researchers to select particular TMF domains or constructs deemed most applicable to their implementation context.\n\nPrevious reviews have highlighted the use of implementation science TMFs to investigate factors that influence the implementation of DHIs in general health care  [36, 37] , but there is a lack of synthesised evidence for their application in digital mental health research, particularly in SMI populations. This scoping review aims to gain a better understanding of which implementation science TMFs have been used by researchers to investigate the implementation of DHIs in services for people with SMI, how TMFs have been applied, and for what purpose. Synthesising this evidence will improve understanding of the role for implementation science theory when attempting to integrate DHIs in services for people with SMI, facilitate digital mental health researchers' implementation efforts, and highlight future directions for research and application of TMFs in this area."
    },
    {
      "title": "Methods"
    },
    {
      "title": "Objectives",
      "text": "The primary aims of this review are to:\n\n\u2022 explore which implementation science TMFs have been used to understand the implementation of DHIs for people with SMI; and. \u2022 investigate how these TMFs have been applied in research.\n\nSecondary aims are to:\n\n\u2022 examine the settings and contexts in which implementation TMFs have been applied to explore implementation of DHIs for people with SMI; and. \u2022 consider the extent to which people with SMI have been involved in this research.\n\nScoping review methodology was chosen to address these aims because scoping reviews are useful for bringing together bodies of literature that have not been comprehensively reviewed before, and where questions go beyond the effectiveness or experience of an intervention: they provide a broad overview of a topic and enable synthesis of findings across a wide range of study designs  [38] . The review was conducted in accordance with scoping review methods outlined by Arksey & O'Malley  [38]  and Peters and colleagues  [39] . The reporting of the review was guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analysis extension for Scoping Reviews (PRISMA-ScR) guidelines  [40] . The review protocol was registered with the Open Science Framework (registration reference: UXMZ8)."
    },
    {
      "title": "Search strategy",
      "text": "Relevant studies were identified by searching four electronic databases: MEDLINE, Embase, PsycInfo, and PsycArticles. The search was limited to English language publications and search strings captured terms related to implementation, services for people with SMI, and DHIs (the full list of search terms is provided in Additional file 1). Search terms within each string were linked with the Boolean operator \"OR\" and the three sets were linked with the operator \"AND\". The search was executed on 24 April 2024, with all databases searched from their inception until the search date. Reference lists of included studies were also searched to identify any additional eligible studies."
    },
    {
      "title": "Eligibility criteria and selection of sources",
      "text": "Eligible studies were those published in English in peerreviewed journals that utilised at least one implementation TMF to investigate the hypothetical or actual adoption of a digital tool in services for people with severe mental health problems. Studies that did not use a referenced TMF to inform, guide, analyse or evaluate implementation were excluded. Studies where the TMF used was developed to investigate acceptability and/or usability only were excluded because such tools typically focus on stakeholder experience of an intervention at the individual-level, as opposed to systematically investigating implementation processes. Studies were included if the hypothetical or actual implementation setting was a mental health service that provided care to people with SMI aged \u2265 14-years-old: this age was chosen due to it commonly being the youngest age of eligibility for early intervention in psychosis services. SMI was defined as people with diagnoses of bipolar disorder, schizophrenia, or other non-organic psychoses in accordance with the NHS England Quality Outcomes Framework  [41] .\n\nStudies were excluded if the DHI being investigated was solely telehealth, an administrative system, or an electronic medical record without service user input because such technologies are considered to represent standard incremental improvement in service delivery, rather than digital intervention innovation. Non-empirical studies (e.g. opinion pieces, commentary papers, dissertations, conference abstracts) and reviews were also excluded due the requirement for studies to sufficiently describe study procedures and for them to collate, analyse and interpret primary data.\n\nAuthor HB screened titles and abstracts for eligibility. Full-text articles were then obtained and reviewed according to the inclusion criteria. Any uncertainties about study eligibility were discussed with the wider review team until a consensus was reached. A second researcher (EE) screened 10% of retrieved articles; comparison of ratings (include/exclude) with original screening outcomes indicated complete agreement between raters (Kappa = 1.0)."
    },
    {
      "title": "Data extraction and data charting process",
      "text": "Data extraction was completed by author HB using a standardised extraction form and checked by author EE. Information extracted from eligible studies included: study authors and year of publication, country or countries where research was undertaken, setting where research was undertaken (e.g. type of mental health service), sample size and characteristics, name of DHI, mode of digital delivery (e.g. website, app), description of DHI, name of implementation TMF used, description of TMF use, authors' rationale for choice of TMF, authors' evaluation/critique of implementation TMF, and reported implementation outcomes. Implementation outcomes were extracted according to the eight outcomes defined by Proctor and colleagues  [42] : acceptability, adoption, appropriateness, feasibility, fidelity, implementation costs, penetration, and sustainability."
    },
    {
      "title": "Synthesis strategy",
      "text": "Extracted data on study characteristics were descriptively summarised. A narrative synthesis was completed, and findings were reviewed according to use of implementation TMFs, implementation outcomes, and service user involvement in studies. In line with usual procedures for scoping reviews, a formal appraisal of methodological quality of included studies was not completed because the purpose of a scoping review is to provide a broad overview of the evidence base, regardless of quality  [39] ."
    },
    {
      "title": "Results"
    },
    {
      "title": "Search results",
      "text": "The database search yielded 5945 records and hand searches identified a further four articles. A total of 3849 records remained after removing duplicates. Abstract screening identified 120 articles for full-text review. During full-text review, 108 articles were excluded: 98 did not mention an implementation TMF, seven did not investigate a DHI as defined by the review eligibility criteria, and three were undertaken in services that do not provide care to people with SMI. Therefore, 12 articles, reporting on 10 distinct studies, were included for data analysis (see Fig.  1  for study selection process)."
    },
    {
      "title": "Study characteristics"
    },
    {
      "title": "Settings and participants",
      "text": "Key characteristics for included studies are presented in Table  1 . Studies were conducted in the UK (n = 3), USA (n = 3), Sweden (n = 2), Australia (n = 1), Belgium (n = 1), one was conducted in both the UK and Australia  [46]  and another in both the USA and Canada  [47] . Most studies were undertaken in community mental health services or with staff/service users from community mental health teams, two were undertaken in early psychosis services  [28, 48] , and two in both inpatient and outpatient settings  [43, 44] . All 12 studies included participants who were mental health clinicians, six studies also included service users with SMI in the sample  [44] [45] [46] [47] [48] [49] , two included carers/relatives of people with SMI  [27, 45] , and four included other stakeholders such as programme directors  [48, 50] , programmers  [50] , administrative staff  [43]  and managers  [48] [49] [50] [51] [52] ."
    },
    {
      "title": "Study design",
      "text": "Five studies were qualitative studies  [43, 45, 49, 51, 52] , four used a mixed-methods design  [44, 46, 48, 53] , two used case study approaches  [27, 50] , and one conducted a pre-post uncontrolled pilot study  [47] . Three studies  [43, 45, 49]  investigated the hypothetical implementation of a DHI; that is, study participants were asked about their views on the DHI, and its proposed implementation, prior to it being implemented. Eight studies  [27, 44, 46, 47, [50] [51] [52] [53]  investigated the 'actual' implementation of a DHI in practice following piloting or adoption of the DHI. One study investigated clinicians' expectations for DHI implementation prior to using a DHI (hypothetical implementation) as well as staff and service user views of the DHI after using it in a pilot study  [48] . The two studies conducted by Gremyr and colleagues  [50, 53]  explored different implementation phases of the same pilot DHI project. Similarly, the studies by Farr and colleagues  [51]  and Pithara et al.  [52]  explored different factors related to the implementation of the same DHI in the same settings with the same participants."
    },
    {
      "title": "DHIs in included studies",
      "text": "The types of DHIs investigated varied across studies, with some intended to be used primarily by people with SMI or their relatives, and others designed to support collaborative care in services. Three studies investigated smartphone apps for people with SMI, including: an app designed for routine self-monitoring of symptoms and the provision of practical advice, which also involved clinician triage in response to significant changes in mental health detected by the app  [45] ; an app provided on discharge from hospital, aimed at fostering increased treatment adherence, which included cognitive-behavioural strategies for self-coping, and sharing of information from the app with the outpatient team  [43] ; and an app which included psychoeducation, tracking of behavioural health, an auditory hallucination detector tool and a peer newsfeed, with a connected clinician portal  [46] . Blajeski and colleagues  [48]  explored the implementation of virtual reality job interview training (VR-JIT), a computerised job interview simulator aimed at improving job interview skills for people with SMI. One study investigated peer support specialists' expectations regarding the hypothetical implementation of digital peer support for people with SMI  [49] : the authors did not explicitly define digital peer support, but study findings suggested apps and chatbots aimed at facilitating peer support were enquired about.\n\nTwo studies utilised web-based platforms. One study explored implementation of a DHI specifically designed for carers: an online supported self-management toolkit which provided psychoeducation and peer support for relatives of people with psychosis or bipolar  [27] . O'Sullivan and colleagues  [47]  described the implementation of moderated online social therapy, an integrated web-based clinic that blends online support (psychosocial interventions, a social network, clinical moderation, and peer support) with in-person specialised mental health services for young people with SMI.\n\nFive studies described the implementation of computer-based software or tools specifically designed for clinicians to use with people with SMI to support care planning. Two studies by the same research group Study citation Setting Sample type and size Study design Type of DHI DHI target condition or group Description of DHI Purpose of DHI Study purpose citation Setting Sample type and size Study design Type of DHI DHI target condition or group Description of DHI Purpose of DHI Study purpose Gremyr et al. [50]** University hospital outpatient clinics for people with psychosis, in Sweden. Staff stakeholders: line managers, department directors, organisation developers and programmers (n = 11) Qualitative case study. Software on a computer. Schizophrenia A point-of-care digital dashboard which includes a unit-level overview of quality indicators identifying service users at risk, triage and planning tools including support for service user coproduction, a dashboard to be jointly reviewed at the point of care by service users and clinicians to support evaluation and planning, outcomes questionnaires, and care plans. To support service user engagement and at the point of care and coproduction of health and care among service users, their family members and clinicians. To use a pilot version of the NASSS-CAT tool to inform the development and deployment of the point-of-care dashboard. Gremyr et al. [54]** University hospital outpatient clinics for people with psychosis, in Sweden. Case managers with experience of using the DHI (n = 5). Outcome measure data from service users from clinics who piloted the DHI (n = 225) and for service users from clinics who did not use the DHI (n = 228). Cross-sectional mixed-methods pilot study. Software on a computer. Schizophrenia A point-of-care digital dashboard which includes a unit-level overview of quality indicators identifying service users at risk, triage and planning tools including support for service user coproduction, a dashboard to be jointly reviewed at the point of care by service users and clinicians to support evaluation and planning, outcomes questionnaires, and care plans. To support service user engagement and at the point of care and coproduction of health and care among service users, their family members and clinicians. To evaluate whether differences in healthrelated outcome measure data could be attributed to use of the dashboard. To explore how case managers experienced the accessibility, use, and usefulness of the dashboard for coproducing care. Lobban et al. [27] EIP Teams, from six NHS Trusts in the UK. EIP staff took part in interviews (n = 129) Uptake/usage data for EIP staff (n = 281) and relatives of people with psychosis who registered for the DHI (n = 159). Mixed-methods iterative case study. Web-based resource. Relatives of people with psychosis or bipolar A toolkit which provides 12 psychoeducation modules addressing key questions identified by relatives, peer support through a moderated group forum, a confidential direct messaging service, and a resource directory. To support self-management and provide access to evidencebased support. To examine the implementation of an online resource offered to relatives of people with psychosis supported by staff. Moitra et al. [43] Inpatient and outpatient clinics, in the USA. Clinical stakeholders employed at a psychiatric hospital, CMHT, or other outpatient setting including administrative supervisors, support staff and clinicians (n = 18). Cross-sectional qualitative study. Smartphone app. Schizophreniaspectrum disorders App designed to be used for at least once month post hospital discharge and has twice-daily prompted sessions on treatment adherence and self-coping. App strategies are linked to users' assessment responses and are derived from CBT. Data from the app is collated by the research team and shared with outpatient providers. To increase treatment adherence and self-coping, to reduce symptoms and improve functioning. To explore clinical stakeholders' perspectives on what might help or hinder the use of DHIs, particularly when service users transition to outpatient care. Table 1 (continued) Study citation Setting Sample type and size Study design Type of DHI DHI target condition or group Description of DHI Purpose of DHI Study purpose Nicaise et al. [44] Three inpatient units and two outpatient mental health services, in Belgium. Clinicians including psychiatric nurses, psychologists, psychiatrists, and social workers (n = 145). Service users with substanceuser disorder, mood disorder, anxiety or somatoform disorder, psychosis or other disorders (n = 232). Service users who participated in semi-structured interviews (n = 9). Mixed-methods pre-post study. Software on a tablet computer. Severe mental illness A sociogram/social network mapping tool which includes four main components: a computer-assisted data collection interview with service users, a remote data warehouse (server and database), a data-mining module and a customisable web-based feedback report that includes a visualisation of the social support network map and a benchmark against the other networks included in the database. To collect data on service users' social support networks, map their social networks and provide clinicians and users with relevant information for fostering social networks. To describe the intervention and evaluate the appropriateness and acceptability of its implementation in a clinical setting. O'Sullivan et al. [47] Two youth mental health services: one for people with firstepisode psychosis and one for people with BPD, in Australia. Mental health clinicians (n = 18). 15 of these clinicians participated in post-intervention interviews. Young people from the early psychosis clinic (n = 18) and BPD clinic (n = 15). Eight young people participated in post-intervention interviews. Mixed methods pre-post pilot study. Web-based platform. Psychosis and borderline personality disorder An integrated web-based clinic that blends moderated online social therapy with face-to-face support. The platform includes interactive user-directed psychosocial interventions, a social network, clinical moderation, and peer support. To integrate face-toface and web-based support for young people experiencing mental health problems. To evaluate the feasibility, acceptability, and safety of the DHI. To assess changes in clinical and psychosocial outcomes for young people from the point of enrolment in the DHI to after the intervention. To understand clinicians' and young people's experiences of barriers and facilitators to using the DHI in practice. Table 1 (continued) explored the implementation of a mobile digital care pathway tool (CPT), used on a tablet computer, to enable co-production of care plans, crisis plans and progress notes between clinicians and service users, and to introduce specific exercises to encourage new ways of interacting  [51, 52] . The development and adoption of a computer-based digital dashboard aimed at supporting clinician and service user coproduction at the point of care was investigated by Gremyr and colleagues in two separate studies  [50, 53] . Nicaise and colleagues  [44]  explored the implementation of a computer-assisted intervention, used on a tablet computer, aimed at fostering service users' social support networks. The intervention involved clinicians inviting service users to map their social support networks via a computer-assisted data collection interview and included a customisable web-based feedback report of a social network map."
    },
    {
      "title": "Use and application of implementation TMFs",
      "text": "Determinant frameworks were the most commonly applied type of TMF in included papers and were used by five studies, followed by implementation theories which were used by four studies. Three studies used TMFs deemed to be evaluation frameworks  [35] , though one of these  [43]  used the framework in a hypothetical implementation study rather than to evaluate actual implementation efforts. Only one study  [44]  used a process model.\n\nThe most frequently applied TMF was the determinant framework, the Consolidated Framework for Implementation Research (CFIR;  [54] ; three studies  [47, 49, 52]  used the original version, and one study  [48]  cited the updated CFIR  [55] . Three studies  [27, 45, 51]  utilised the implementation theory Normalisation Process Theory (NPT;  [56] , with Allan and colleagues  [45]  also using the Medical Research Council (MRC) process evaluation framework  [57]  to frame their analysis.\n\nAll other TMFs included in the review were used once. The Nonadoption Abandonment and challenges to Scaleup, Spread, and Sustainability (NASSS) framework  [58]  and its associated complexity assessment tool (NASSS-CAT;  [59]  were applied by Gremyr and colleagues  [50]  to complete a complexity assessment of the development and deployment of a point-of-care digital dashboard. In another study  [53] , the same research group used the Clinical Adoption Meta Model (CAMM;  [60] to explore adoption of the dashboard post pilot implementation.\n\nThe Exploration, Preparation, Implementation, Sustainment (EPIS) framework  [61] , an implementation process model, was used by Nicaise and colleagues  [44]  to guide the implementation of a digital social-support mapping programme. A modified version of the Simplified Sociotechnical Model was applied by Sequeira et al.  [46]  to explore implementation of an app and related online portal for clinicians. Finally, Moitra and colleagues  [43]  utilised Proctor and colleagues' implementation outcomes framework  [42] , to evaluate clinicians' expectations regarding the implementation of a smartphone app given to service users post hospital discharge.\n\nAll studies, except for one  [45] , used only one TMF. Studies varied in how TMFs were applied across implementation phases. Three studies reported using TMFs to explore participants' expectations regarding the implementation of the DHI  [43, 45, 49] . All three of these studies used implementation TMFs to inform the development of interview schedules for the collation of qualitative data, as well as to guide and structure their qualitative analysis. In contrast to the studies by Fortuna et al.  [49]  and Moitra et al.  [43] , Allan and colleagues  [45]  used different TMFs at data collection and analysis stages: NPT  [56]  and the MRC process evaluation framework  [60]  respectively.\n\nThe remaining studies used TMFs in the early adoption phase (e.g. post piloting the DHI) of their research. Gremyr and colleagues  [50]  used the NASSS-CAT  [59]  following early piloting that highlighted challenges to the larger-scale development and deployment of their digital dashboard: the NASSS-CAT was used to structure stakeholder workshops, to frame data collection (in the form of observations, field notes, notes from participants and audio recordings of workshop discussions) and to structure findings. The authors were also piloting the NASSS-CAT and tested its utility as part of this study. Five studies, all of which undertook interviews with staff who worked in services where the DHI had been adopted, used TMFs to synthesise qualitative findings regarding the barriers and facilitators to implementation according to TMF constructs  [27, 47, 48, 51, 52] . Three of these studies also reported using the TMF to guide qualitative data collection by informing the development of the interview schedules  [27, 47, 51] . Finally, three studies used the TMF to frame mixed methods analysis and integrated both quantitative and qualitative findings to explore acceptability, use, and usefulness of the DHI in practice  [44, 53]  or to evaluate implementation of the DHI  [46] .\n\nIn summary, TMFs were most frequently used to guide qualitative data analysis. Most, but not all, studies that used a TMF in qualitative analysis also used a TMF to inform qualitative data collection (e.g. by using the TMF in the development of the interview schedule). TMFs were used less frequently for quantitative data analysis: only three of the six studies that collated quantitative data used the TMF to interpret this data. It is of note that most studies included in this review were in the pre-implementation or early adoption phases, meaning that TMFs were primarily used to identify barriers and enablers to more widespread implementation, with only"
    },
    {
      "title": "Study citation Name of TMF(s) Application of TMF(s) TMF(s) domains or constructs used"
    },
    {
      "title": "Modifications to TMF(s) Reported rationale for TMF(s) choice"
    },
    {
      "title": "Evaluation of TMF(s) applied"
    },
    {
      "title": "Studies using the",
      "text": "Consolidated Framework for Implementation Research (CFIR) Blajeski et al. [48] Consolidated Framework for Implementation Research (CFIR)-updated version [56] Framed deductive qualitative analysis. Three domains: Intervention Characteristics, Outer Setting, Individuals. None reported. CFIR provides evidencebased domains that frame the implementation needs of mental health interventions. None reported. Fortuna et al. [49] Consolidated Framework for Implementation Research (CFIR; [55] Informed interview schedule and framed deductive qualitative analysis. For data collection, the authors chose three domains: Intervention Characteristics, Inner Setting, Characteristics of individuals. Four domains were mapped to in analysis: Intervention Characteristics, Inner Setting, Characteristics of Individuals, Outer Setting. None reported. None reported. None reported. O'Sullivan et al. [47] Consolidated Framework for Implementation Research (CFIR; [55]) Informed interview schedule and framed deductive qualitative analysis. Four domains: Intervention Characteristics, Inner Setting, Outer Setting, Characteristics of Individuals. None reported. None reported. None reported. Pithara et al. [52]* Consolidated Framework for Implementation Research (CFIR; [55]) Framed the ordering of codes in qualitative analysis. All domains: Intervention Characteristics, Inner Setting, Outer Setting, Characteristics of Individuals, Implementation Process. None reported. None reported. Authors appraised the CFIR as helpful in capturing factors that impacted on implementation but reported challenges in assigning data items to individuals CFIR domains. Studies using Normalisation Process Theory (NPT) Allan et al. [53] Normalisation Process Theory (NPT; [63]) Medical Research Council (MRC) process evaluation of complex interventions [64] NPT -informed focus group interview schedules. MRC process evaluation of complex interventionsframed deductive qualitative analysis. NPT -all four main constructs: Coherence, Cognitive Participation, Collective Action, Reflexive Monitoring. MRC process evaluation of complex interventionsthe Context theme plus three constructs in the Implementation theme: Fidelity, Adaptations, Reach None reported. NPT -none reported. MRC process evaluation of complex interventions relevant to the needs of a feasibility study, goes beyond barriers and facilitators to implementation and provides a taxonomy of implementation constructs. None reported. Farr et al. [51]* Normalisation Process Theory (NPT; [63]) Informed interview schedule and framed deductive qualitative analysis. All four main constructs: Coherence, Cognitive Participation, Collective Action, Reflexive Monitoring None reported. None reported. None reported. Lobban et al. [27] Normalisation Process Theory (NPT; [63]) Informed interview schedule and framed deductive qualitative analysis. All four main constructs: Coherence, Cognitive Participation, Collective Action, Reflexive Monitoring. None reported. NPT has been extensively applied in digital health settings, allowing comparison of findings with previous research. Authors appraised NPT as a useful framework to understand the work done by clinicians to implement the DHI. Studies using other implementation theories, models, and frameworks Application of TMF(s) TMF(s) domains or constructs used Modifications to TMF(s) Reported rationale for TMF(s) choice Evaluation of TMF(s) applied Gremyr et al. [50]** Non-Adoption, Abandonment, Scale-up, Spread, and Sustainability (NASSS; [59]) and its associated Complexity Assessment Tool (NASSS-CAT; [60]) Structured stakeholder workshops and used to categorise findings. All seven concepts: Condition, Technology, Value Proposition, Adopters, Organisation, Wider System, Embedding and Adapting Over Time. None reported. The usefulness of the NASSS-CAT was being piloted as part of the study. Evaluated usefulness of the NASSS-CAT via stakeholder workshops and found it helped to gain new insights, but stakeholders did not have full understanding of all of the framework's concepts. Authors appraised the framework as helpful in improving understanding of project complexities. Gremyr et al. [54]** Clinical Adoption Meta-Model (CAMM; [61]) Framed quantitative and qualitative data collection and analysis. All four domains: Accessibility, System Use, Behaviour, Clinical Outcomes. None reported. None reported. None reported. Moitra et al. [43] Proctor et al. 's implementation outcomes model [42] Informed interview schedule and framed deductive qualitative analysis. For data collection, the authors chose three domains: Acceptability, Appropriateness, Implementation Cost. Authors do not specify which domains were applied in analysis. None reported. None reported. None reported. Nicaise et al. [44] Exploration, Preparation, Implementation, Sustainment (EPIS; [62]) Framed qualitative and quantitative analysis. Only the Exploration domain. None reported. None reported. None reported. Sequeira et al. [46] Simplified Sociotechnical Model [65] Framed qualitative and quantitative analysis. All three main domains: Culture, Process, Technology. Authors state they used a modified version of the model, but no further details are provided about this. None reported. None reported. *Note. These two studies reported on the factors affecting implementation of a DHI in the same pilot project **Note. These two studies reported on different phases of the same pilot implementation project\n\nTable 2 (continued)\n\ntwo instances of the TMF being used to evaluate implementation efforts  [46, 50] . See Table  2  for a summary of included studies' use of implementation TMFs."
    },
    {
      "title": "TMF domains or constructs applied",
      "text": "Six studies utilised all domains or constructs of the implementation TMF in data collection, analysis, or both  [27, 46, [50] [51] [52] [53] . Allan and colleagues  [45]  utilised all four main constructs of NPT  [56]  to guide data collection but selected specific parts (context, fidelity, adaptations, reach) of the MRC process evaluation framework  [57]  to frame their analysis. Blajeski et al. 's  [48]  findings mapped to three of the five updated CFIR  [55]  domains (intervention characteristics, outer setting, individuals): they did not report findings for the inner setting or implementation process domains, or the characteristics of individuals subdomain. Fortuna and colleagues  [49]  also employed the CFIR and selected three domains (intervention characteristics, inner setting, characteristics of individuals) that they felt would be most relevant to explore in their qualitative study. Their findings mapped to these three domains, plus the outer setting domain. In their study utilising the CFIR, O'Sullivan et al.  [46]  coded qualitative data to all main CFIR domains, apart from the implementation process domain. The implementation process domain refers to the activities and strategies used to implement an intervention  [54, 55] . The relative dearth of evidence pertaining to this domain across papers could be reflective of the fact that most included studies were undertaken in the pre-implementation or early adoption phases.\n\nIndeed, Nicaise and colleagues applied only the 'exploration' stage of EPIS framework  [61]  to investigate the appropriateness and acceptability of the digital socialsupport mapping programme in recognition that the DHI was in the exploratory stage of implementation. A similar strategy was undertaken by Moitra et al.  [49]  in their application of Proctor et al. 's  [42]  implementation model: they selected three out of the eight implementation outcomes (appropriateness, acceptability, and implementation cost) to inform their topic guide: the authors stated this choice was guided by the nascence of the project."
    },
    {
      "title": "Modifications to TMFs",
      "text": "None of the papers described modifications to the implementation TMFs applied. Although, Sequeira and colleagues  [46]  reported that they utilised a modified version of the Simplified Sociotechnical Model  [62] , they did not provide sufficient detail to determine how the model was modified."
    },
    {
      "title": "Study authors' rationale for choice of TMF",
      "text": "Only four papers reported a specific rationale for why a particular TMF was chosen to answer their research questions. Blajeski et al.  [48]  reported the updated CFIR  [55]  was chosen due to its evidence-based domains that frame the needs of mental health interventions. In their study, Lobban and colleagues  [27]  reported that the use of NPT  [56]  enabled them to compare findings with extensive previous research that has utilised the same theory. One of the aims of Gremyr et al. 's  [50]  study was to pilot the NASSS-CAT  [59] , providing a rationale for choosing it as a framework. Finally, although Allan and colleagues  [45]  did not provide a rationale for selecting NPT to inform data collection in their study, they did explain a rationale for moving away from NPT at analysis stage and instead using the MRC process evaluation framework  [57]  to frame their analysis. The authors argued that the MRC framework was more relevant to the needs of their feasibility study because it was too early in DHI development to state whether normalisation of the DHI in routine practice was the ultimate goal. The authors also reported that the MRC framework was chosen because it goes beyond barriers and facilitators to implementation classifications and provides a taxonomy of implementation constructs."
    },
    {
      "title": "Study authors' evaluation of TMF use",
      "text": "Only three studies evaluated the usefulness of applying an implementation TMF to help address their research questions. Lobban and colleagues  [27]  reported that NPT  [56]  provided a useful framework for considering the day-to-day work done by clinicians to implement an online toolkit for relatives of people with SMI. Pithara et al.  [52]  provided a more comprehensive critique of the usefulness of the CFIR  [54]  in understanding the implementation of a digital CPT. They reported that the CFIR was useful in helping to capture and categorise factors impacting on implementation but reported challenges in assigning data items to the individual dimensions of the CFIR due to analytical ambiguity between them and the complexity of the DHI itself. A key aim of the study by Gremyr and colleagues  [50]  was to evaluate the usefulness of the NASSS framework  [58]  in a real-life setting. Via workshops with stakeholders, the authors collected and thematically analysed qualitative data regarding stakeholders' views on the application of the NASSS-CAT tool  [59] . Findings showed that stakeholders thought the tool was useful in helping to gain new insights and in covering areas that may otherwise have not been considered; however, they stated it would have been helpful to have more of an understanding of the tool's concepts before using it. The authors concluded that using the NASSS-CAT can help provide a greater understanding of the complexities in digital projects."
    },
    {
      "title": "Implementation outcomes",
      "text": "Studies varied in their reporting of Proctor et al. 's  [42]  implementation outcomes (see Table  3  for a summary). The most frequently reported outcomes were acceptability and feasibility, followed by adoption and appropriateness. There were no studies which reported data pertaining to costs or penetration, and only one  [51]  that mentioned sustainment. The lack of reporting on these longer-term implementation outcomes is likely to be reflective of the fact that included studies were mostly undertaken in the exploratory pre-implementation or early piloting phases of implementation (see Additional File 2 for further details on reported outcomes)."
    },
    {
      "title": "Service user involvement",
      "text": "Six of 12 studies included in this review investigated people with SMI's views regarding the implementation of the DHI  [44] [45] [46] [47] [48] [49] , with one study also exploring carers' views  [46] . Most studies coded and synthesised the data from service user participants according to implementation TMF constructs and thus data from service user participants, clinician participants, and DHI usage (where applicable) were typically integrated. However, O'Sullivan and colleagues  [47]  analysed the service user data using thematic analysis and presented these findings separately to findings from staff interviews, which were mapped to the CFIR  [54] .\n\nOnly two of the included studies reported that people with SMI had been involved in the design or conduct of the study. Peer support specialists with lived experience of SMI helped to develop the interview schedule in a study investigating peer support specialists' and people with SMI's views on digital peer support  [49] . Peer support workers also led and facilitated implementation of the A4i platform at one site in Sequeira and colleagues' study  [46] ]. Lobban and colleagues  [27]  reported that stakeholder groups, which included relatives of people with SMI, advised on how the DHI would be introduced into services but no further information on this was provided. The authors also stated that relatives were involved in the design of the DHI. Furthermore, although they did not report any service user involvement in the implementation studies in this review, four studies  [47, [50] [51] [52]  reported that service users were involved in the design and development of the DHI being piloted."
    },
    {
      "title": "Discussion",
      "text": "To improve the efficiency with which DHIs are implemented in real-world settings for people with SMI, theory-driven implementation research needs to be systematically conducted. This review aimed to summarise the application of implementation science TMFs in studies investigating the implementation of DHIs for people with SMI. Overall, the number of studies applying TMFs was limited (n = 12). Most studies had taken place in community mental health settings or with community mental health clinicians. All studies explored staff views regarding implementation of DHIs, with only half also investigating service users' perspectives. The DHIs being implemented by studies varied from those designed to be used predominantly by service users (e.g. self-monitoring smartphone apps) to those designed to be used by clinicians in collaboration with people with SMI (e.g. digital care planning programmes). The relatively small number of studies utilising implementation TMFs in this review reflects the infancy of this research area. Indeed, to date, studies in digital mental health have typically focused on DHI development, acceptability, and efficacy, with research into real-world implementation only recently coming into focus."
    },
    {
      "title": "Use and application of TMFs",
      "text": "Studies in this review varied in their application of TMFs, with most using TMFs to inform data collection, analysis, and presentation of findings. TMFs were not typically used to guide the selection and evaluation of implementation strategies, or to guide implementation processes. This is reflective of wider implementation science literature that has traditionally focused on the early stages of implementation and less so on how to sustain innovations in practice  [66] . The most commonly applied TMF in this review was the CFIR  [54, 55] . The CFIR is a metatheoretical determinant framework that measures multiple ecological levels, making it useful for understanding the implementation of complex interventions in complex settings. The framework can offer clarity for researchers by organising, labelling, and describing a complex array of constructs that contribute to implementation, enabling researchers to select constructs most suited to their research  [55] . The CFIR is one of the most highly cited frameworks in implementation science  [67] , perhaps due to its applicability across multiple contexts, its flexibility, the use of clearly operationalised constructs and guidance for its use. Its popularity and usability mean the CFIR is likely to be one of the most familiar frameworks to digital mental health researchers investigating implementation. All four studies that utilised the CFIR used the framework to inform qualitative data collection and/or to guide qualitative analysis. In all cases, the CFIR was used to categorise barriers and facilitators to successful implementation, with limited theorising about relationships between determinants or causal mechanisms through which determinants influence implementation outcomes. This is a common critique of the application of determinant frameworks in implementation science, where complex relationships are in danger of being reduced to prescriptive checklists  [31] ."
    },
    {
      "title": "Feasibility",
      "text": "The extent to which a new treatment, or an innovation, can be successfully used or carried out within a given agency or setting  [66] ."
    },
    {
      "title": "Fidelity",
      "text": "The degree to which an intervention was implemented as it was prescribed in the original protocol or as it was intended by the program developers  [67][68] ."
    },
    {
      "title": "Cost",
      "text": "The cost impact of an implementation effort."
    },
    {
      "title": "Penetration",
      "text": "The integration of a practice within a service setting and its subsystems."
    },
    {
      "title": "Sustainability",
      "text": "The extent to which a newly implemented treatment is maintained or institutionalized within a service setting's ongoing, stable operations."
    },
    {
      "title": "\u2713 1",
      "text": "Three studies in this review used NPT  [56] . NPT is an implementation science theory which explains core mechanisms that shape implementation processes and describes nonlinear relationships between its four overarching constructs (coherence, cognitive participation, collective action, and reflexive monitoring). The theory was developed from attempts to understand the adoption of telemedicine systems in the UK National Health Service  [37]  and is one of the most applied theories in DHI implementation studies  [68] . All studies in this review utilised all four constructs of NPT to inform qualitative data collection and/or analysis, though again, theorising about relationships between constructs and the mechanisms behind implementation processes was limited.\n\nThere was variation in how specific domains or constructs of TMFs were used by studies. Implementation researchers often select TMF domains deemed to be most relevant to their research question or implementation context and it is recommended that rationales for using specific domains or constructs of TMFs are provided  [54] . Three studies in this review  [43, 44, 49]  selected specific TMF domains to use prior to commencing data collection and provided rationales based on pre-existing expectations regarding implementation barriers and facilitators  [49]  or the implementation stage the study was in  [43, 44] . The remaining studies that used a TMF to guide analysis did not select domains or constructs a priori, and most reported findings for all domains of their selected TMF. A notable exception to this was the four studies utilising the CFIR, where only one  [52]  included the implementation process domain. This domain refers to the strategies and activities that are undertaken to implement an innovation  [54, 55] . The omission of this domain in study findings could be reflective of studies being in the early exploratory stages of implementation, where sustained and incremental optimisation of implementation is not yet a main research objective.\n\nDespite the variation in TMFs used, only four studies provided any rationale for choosing a particular TMF and none described a process of TMF selection. This is not unusual in implementation research: researchers commonly fail to provide adequate justification for their selection of a particular implementation TMF  [69] . Indeed, the growth of implementation science research over the past two decades has led to the development of over 150 different TMFs  [69]  and researchers have highlighted difficulties in selecting the most appropriate TMF for a given research project  [70, 71] , meaning TMF choice is often based on convenience or prior familiarity rather than systematic consideration  [32] . This is problematic if the selected TMF is not well suited to the user's objectives and may limit the ability to generalise findings, support progress and promote shared understanding  [32] . To this end, it is recommended that digital health implementation researchers carefully consider, and transparently report, justifications for TMF selection. This transparency will facilitate synthesis of relevant evidence and thus may improve the efficiency with which DHIs are successfully implemented in services for people with SMI.\n\nFurthermore, few studies in this review evaluated their chosen implementation TMF, and where evaluation did occur, this was limited to the utility of the TMF for addressing their research questions or aiding understanding of the implementation context. This 'one-way' engagement with TMFs, where theory shapes data collection and/or analysis but empirical findings are not explained in terms of what they mean for the theory, is common in implementation science  [31] . It is argued that, to advance conceptual knowledge in the field, implementation researchers should engage with their selected TMF(s) in an in-depth manner throughout research design, delivery, and reporting  [72] : this should include scrutiny of the theoretical assumptions of the work in response to empirical findings  [31]  and potential modifications to TMFs where this is grounded in evidence. Most studies in this review did not report any modifications to TMFs, which was understandable given the infancy of the evidence in this area. As the evidence builds, researchers should look to cumulatively refine and build theoretical knowledge by using empirical data actively to evaluate, validate, modify, and develop TMFs."
    },
    {
      "title": "Implementation outcomes",
      "text": "There was variation in the types of implementation outcomes that studies in this review reported on. The lack of evidence pertaining to the implementation outcomes of penetration, sustainment and cost could be reflective of the studies being mostly undertaken in the early exploration and early pilot implementation phases. Indeed, Proctor and colleagues  [42]  note that different implementation outcomes are likely most relevant for decision-making at different points in the implementation life cycle. The most commonly reported implementation outcomes of studies in this review were feasibility, acceptability, adoption, and appropriateness. Thus, the majority of implementation outcome research in this area to date has provided information about the degree to which stakeholders like, or find usable, the DHI and related practices: this can help to refine interventions, support initial uptake, and improve patient centredness  [73] . However, these outcomes do little to inform the reach and sustainment of interventions in practice. These findings are in line with findings from a recent scoping review  [73]  which examined the reporting of Proctor et al. 's  [42]  outcomes in implementation research and found that the least reported outcomes were cost, penetration, and sustainment. The dearth of evidence pertaining to such outcomes is problematic because they are often the most highly prioritised in real-world decision making and thus argued to be some of the main factors that may actually have a public health impact  [72, 73] . Digital mental health implementation researchers should therefore look to advance the evidence for more observable implementation outcomes such as these to support programme leaders and policy makers to make decisions about the equitable deployment, reach and sustainment of DHIs in services for people with SMI."
    },
    {
      "title": "Service user involvement",
      "text": "Despite all studies in this review investigating the implementation of DHIs that require active service user input and use, only half included service user participants. Furthermore, although some studies in the review did report that service users were involved in the development of the DHI, only two  [46]  involved people with SMI in the design or conduct of the study. This is typical of the wider implementation science literature which has traditionally focused on the 'implementers' of innovations, that is, the people integrating an intervention or practice into services (e.g. clinicians, managers)  [55] . Indeed, effective stakeholder involvement, including the involvement of service users, is a recognised challenge in the field  [74] . Given the unique context of mental health services for people with SMI and the active role service users have in DHIs, any efforts to theorise about the implementation of DHIs should undoubtedly involve service users' experiences, knowledge, and perspectives  [29] . Inclusion of service users in the research process is likely to facilitate greater understanding of implementation determinants and help to test, refine, and develop implementation theories. There is a lack of knowledge regarding which methods are most effective for engaging service users in the conduct of implementation research  [75] : further research in this area is necessary to ensure meaningful involvement and prevent tokenism."
    },
    {
      "title": "Limitations",
      "text": "A potential limitation of the review is that it included published research only. Given the relative infancy of implementation science research in the context of DHIs for people with SMI, additional evidence from grey literature could have added to findings. In addition, although efforts were made to use sufficiently broad search terms related to implementation, the lack of consistent shared terminology and somewhat vague descriptions of concepts in the field  [32, 35]  could have meant relevant papers were missed. However, the search approach was deemed acceptable for the purposes of a scoping review.\n\nAll studies in this review were undertaken in Europe, North America, or Australia, limiting applicability of findings to other contexts and healthcare systems. This lack of evidence from low-income and middle-income countries (LMICs) is reflective of the wider DHI literature, where studies that have evaluated DHIs for people with SMI living in LMICs are scarce  [76] . Given that most people with SMI living in LMICs do not have access to mental healthcare  [77] , it is imperative that future research in this area includes systematic consideration of how best to implement DHIs into LMIC healthcare systems and improve access to care."
    },
    {
      "title": "Conclusions",
      "text": "Findings from this review highlight that the use of implementation science TMFs in research investigating the integration of DHIs in services for people with SMI is limited. Most studies utilised TMFs to guide qualitative analysis and structure the presentation of their findings, with few integrating them throughout the research process. Authors often did not provide a rationale for choosing to use a particular TMF and typically applied TMFs in an 'off the shelf ' manner, with limited evaluation or theoretical critique. It is recommended that digital mental health researchers looking to utilise implementation TMFs to understand and facilitate DHI implementation should carefully consider the TMF(s) most applicable to their implementation context and should transparently report this decision making. Furthermore, researchers should evaluate their empirical findings considering the theoretical underpinnings of the TMF, reporting any contributions to theory to advance implementation science research in this area.\n\nFindings showed that most implementation research on the adoption of DHIs in services for people with SMI has been undertaken in the early exploratory stages of implementation, with focus being on the acceptability of DHIs and perceived feasibility of DHI implementation. There is currently little evidence on implementation processes or the sustained implementation of DHIs in practice and few studies report on implementation outcomes related to the longer-term maintenance of interventions. Future research should investigate factors that influence the sustainment of DHIs in services for people with SMI and collate data regarding longer-term implementation outcomes. Finally, for studies in this review there was consistent a lack of service user involvement in study design, procedures, and evaluation. It is essential that future research investigating the integration of DHIs in services for people with SMI effectively involves people with SMI in research design and delivery to facilitate greater understanding of implementation determinants, processes, and outcomes."
    },
    {
      "text": "Fig. 1 PRISMA flow diagram of study selection. *The 12 included articles reported on 10 distinct studies; two of the studies were reported in two articles each"
    },
    {
      "text": "The intention, initial decision, or action to try or employ an innovation or evidence-based practice.The perceived fit, relevance, or compatibility of the innovation or evidence-based practice for a given practice setting, provider, or consumer; and/or perceived fit of the innovation to address a particular issue or problem."
    },
    {
      "text": "Characteristics of included studies"
    },
    {
      "text": "Community Mental Health Service. CMHT, Community Mental Health Team. DSM-5, Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition. DHI, Digital Health Intervention. EIP, Early Intervention in Psychosis. MDD, Major Depressive Disorder. NASSS-CAT, Non-adoption, abandonment, scale-up, spread, and sustainability complexity assessment tool. RCT, Randomised Controlled Trial. SMI, Severe Mental Health Problems. SSD, Schizophrenia Spectrum Disorder. VR-JIT, Virtual Reality Job Interview Training *Note. These two studies reported on the factors affecting implementation of a DHI in the same pilot project **Note. These two studies reported on different phases of the same pilot implementation project"
    },
    {
      "text": "Use of implementation theories, models, and frameworks (TMFs) in included studies, grouped by the TMF used"
    },
    {
      "text": "Summary of implementation outcomes reported by studies"
    }
  ],
  "references": [
    {
      "title": "Risks of all-cause and suicide mortality in mental disorders: a meta-review",
      "authors": [
        "E Chesney",
        "G Goodwin",
        "S Fazel"
      ],
      "year": 2014
    },
    {
      "title": "The societal cost of schizophrenia: an updated systematic review of cost-of-illness studies",
      "authors": [
        "C Lin",
        "X Zhang"
      ],
      "year": 2023,
      "doi": "10.1007/s40273-022-01217-8"
    },
    {
      "title": "Building the mental health workforce capacity needed to treat adults with serious mental illnesses",
      "authors": [
        "M Olfson"
      ],
      "year": 2016
    },
    {
      "title": "Pathways to mental health services for young people: a systematic review",
      "authors": [
        "K Macdonald",
        "N Fainman-Adelman",
        "K Anderson",
        "S Iyer"
      ],
      "year": 2018
    },
    {
      "title": "World mental health report: transforming mental health for all",
      "year": 2022,
      "doi": "10.1002/wps.21018"
    },
    {
      "title": "Classification of digital health. interventions v1.0: a shared language to describe the uses of digital technology for health",
      "year": 2018
    },
    {
      "authors": [
        "W H O -R H R"
      ]
    },
    {
      "title": "Online, social media and mobile technologies for psychosis treatment: a systematic review on novel user-led interventions",
      "authors": [
        "M Alvarez-Jimenez",
        "M Alcazar-Corcoles",
        "C Gonzalez-Blanch",
        "S Bendall",
        "P Mcgorry",
        "J Gleeson"
      ],
      "year": 2014
    },
    {
      "title": "Digital health technology for use in patients with serious mental illness: a systematic review of the literature",
      "authors": [
        "S Batra",
        "R Baker",
        "T Wang",
        "F Forma",
        "F Dibiasi",
        "T Peters-Strickland"
      ],
      "year": 2017
    },
    {
      "title": "Early psychosis service user views on digital technology: qualitative analysis",
      "authors": [
        "S Bucci",
        "R Morris",
        "K Berry",
        "N Berry",
        "G Haddock",
        "C Barrowclough"
      ],
      "year": 2018,
      "doi": "10.2196/10091"
    },
    {
      "title": "Emerging mHealth and eHealth interventions for serious mental illness: a review of the literature",
      "authors": [
        "J Naslund",
        "L Marsch",
        "G Mchugo",
        "S Bartels"
      ],
      "year": 2015
    },
    {
      "title": "Actissist: proof-of-concept trial of a theory-driven digital intervention for psychosis",
      "authors": [
        "S Bucci",
        "C Barrowclough",
        "J Ainsworth",
        "M Machin",
        "R Morris",
        "K Berry",
        "R Emsley",
        "S Lewis",
        "D Edge",
        "I Buchan",
        "G Haddock"
      ],
      "year": 2018
    },
    {
      "title": "Effects of actissist, a digital health intervention for early psychosis: A randomized clinical trial",
      "authors": [
        "S Bucci",
        "N Berry",
        "J Ainsworth",
        "K Berry",
        "D Edge",
        "E Eisner"
      ],
      "year": 2024,
      "doi": "10.1016/j.psychres.2024.116025"
    },
    {
      "title": "A systematic review and meta-analysis of digital health technologies effects on psychotic symptoms in adults with psychosis",
      "authors": [
        "S Clarke",
        "D Hanna",
        "C Mulholland",
        "C Shannon",
        "C Urquhart"
      ],
      "year": 2019
    },
    {
      "title": "Tomorrow's world: current developments in the therapeutic use of technology for psychosis",
      "authors": [
        "P O'hanlon",
        "G Aref-Adib",
        "A Fonseca",
        "B Lloyd-Evans",
        "D Osborn",
        "S Johnson"
      ],
      "year": 2016
    },
    {
      "title": "Systematic review on what works, what does not work and why of implementation of mobile health (mHealth) projects in Africa",
      "authors": [
        "C Aranda-Jan",
        "N Mohutsiwa-Dibe",
        "S Loukanova"
      ],
      "year": 2014,
      "doi": "10.1186/1471-2458-14-188"
    },
    {
      "title": "Digital mental health: challenges and next steps",
      "authors": [
        "K Smith",
        "C Blease",
        "M Faurholt-Jepsen",
        "J Firth",
        "T Van Daele",
        "C Moreno"
      ],
      "year": 2023,
      "doi": "10.1136/bmjment-2023-300670"
    },
    {
      "title": "Narrowing the 17-year research to practice gap",
      "authors": [
        "C Munro",
        "R Savel"
      ],
      "year": 2016
    },
    {
      "title": "A clinical introduction to psychosis: foundations for clinical psychologists and neuropsychologists",
      "authors": [
        "J Badcock",
        "G Paulik"
      ],
      "year": 2019
    },
    {
      "title": "Acceptance and resistance of new digital technologies in medicine: qualitative study",
      "authors": [
        "S Safi",
        "T Thiessen",
        "K Schmailzl"
      ],
      "year": 2018,
      "doi": "10.2196/11072"
    },
    {
      "title": "Applications of digital technology in COVID-19 pandemic planning and response",
      "authors": [
        "S Whitelaw",
        "M Mamas",
        "E Topol",
        "Van Spall"
      ],
      "year": 2020
    },
    {
      "title": "The cost of mental disorders: a systematic review",
      "authors": [
        "M Christensen",
        "C Lim",
        "S Saha",
        "O Plana-Ripoll",
        "D Cannon",
        "F Presley"
      ],
      "year": 2020
    },
    {
      "title": "Firstepisode psychosis and disengagement from treatment: a systematic review",
      "authors": [
        "R Doyle",
        "N Turner",
        "F Fanning",
        "D Brennan",
        "L Renwick",
        "E Lawlor"
      ],
      "year": 2014
    },
    {
      "title": "Disengagement from early intervention services for psychosis: a systematic review",
      "authors": [
        "F Mascayano",
        "E Van Der Ven",
        "G Martinez-Ales",
        "A Henao",
        "J Zambrano",
        "N Jones"
      ],
      "year": 2021
    },
    {
      "title": "Factors affecting implementation of digital health interventions for people with psychosis or bipolar disorder, and their family and friends: a systematic review",
      "authors": [
        "G Aref-Adib",
        "T Mccloud",
        "J Ross",
        "O 'hanlon",
        "P Appleton",
        "V Rowe"
      ],
      "year": 2019
    },
    {
      "title": "Barriers to and facilitators of user engagement with digital mental health interventions: systematic review",
      "authors": [
        "J Borghouts",
        "E Eikey",
        "G Mark",
        "De Leon",
        "C Schueller",
        "S Schneider"
      ],
      "year": 2021,
      "doi": "10.2196/24387"
    },
    {
      "title": "IMPlementation of an online relatives' toolkit for psychosis or bipolar (IMPART study): iterative multiple case study to identify key factors impacting on staff uptake and use",
      "authors": [
        "F Lobban",
        "D Appelbe",
        "V Appleton",
        "J Billsborough",
        "N Fisher",
        "S Foster"
      ],
      "year": 2020,
      "doi": "10.1186/s12913-020-5002-4"
    },
    {
      "title": "Artificial intelligence for mental health and mental illnesses: an overview",
      "authors": [
        "S Graham",
        "C Depp",
        "E Lee",
        "C Nebeker",
        "X Tu",
        "H Kim"
      ],
      "year": 2019
    },
    {
      "title": "Accelerating digital mental health research from early design and creation to successful implementation and sustainment",
      "authors": [
        "D Mohr",
        "A Lyon",
        "E Lattie",
        "M Reddy",
        "S Schueller"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.7725"
    },
    {
      "title": "An overview of research and evaluation designs for dissemination and implementation",
      "authors": [
        "C Brown",
        "G Curran",
        "L Palinkas",
        "G Aarons",
        "K Wells",
        "L Jones"
      ],
      "year": 2017
    },
    {
      "title": "Harnessing the power of theorising in implementation science",
      "authors": [
        "R Kislov",
        "C Pope",
        "G Martin",
        "P Wilson"
      ],
      "year": 2019
    },
    {
      "title": "Criteria for selecting implementation science theories and frameworks: results from an international survey",
      "authors": [
        "S Birken",
        "B Powell",
        "C Shea",
        "E Haines",
        "Alexis Kirk",
        "M Leeman"
      ],
      "year": 2017
    },
    {
      "title": "The role of theory in research to develop and evaluate the implementation of patient safety practices",
      "authors": [
        "R Foy",
        "J Ovretveit",
        "P Shekelle",
        "P Pronovost",
        "S Taylor",
        "S Dy"
      ],
      "year": 2011
    },
    {
      "title": "Writing implementation research grant proposals: ten key ingredients",
      "authors": [
        "E Proctor",
        "B Powell",
        "A Baumann",
        "A Hamilton",
        "R Santens"
      ],
      "year": 2012,
      "doi": "10.1186/1748-5908-7-96"
    },
    {
      "title": "Making sense of implementation theories, models, and frameworks",
      "authors": [
        "P Nilsen"
      ],
      "year": 2020
    },
    {
      "title": "Factors that influence the implementation of e-health: a systematic review of systematic reviews (an update)",
      "authors": [
        "J Ross",
        "F Stevenson",
        "R Lau",
        "E Murray"
      ],
      "year": 2016
    },
    {
      "title": "Using normalization process theory in feasibility studies and process evaluations of complex healthcare interventions: a systematic review",
      "authors": [
        "C May",
        "A Cummings",
        "M Girling",
        "M Bracher",
        "F Mair",
        "C May"
      ],
      "year": 2018
    },
    {
      "title": "Scoping studies: towards a methodological framework",
      "authors": [
        "H Arksey",
        "O' Malley"
      ],
      "year": 2005
    },
    {
      "title": "Guidance for conducting systematic scoping reviews",
      "authors": [
        "M Peters",
        "C Godfrey",
        "H Khalil",
        "P Mcinerney",
        "D Parker",
        "C Soares"
      ],
      "year": 2015
    },
    {
      "title": "PRISMA extension for scoping reviews (PRISMA-ScR): checklist and explanation",
      "authors": [
        "A Tricco",
        "Lillie Zarin",
        "O' Brien",
        "K Colquhoun",
        "H Levac"
      ],
      "year": 2018,
      "doi": "10.7326/m18-0850"
    },
    {
      "title": "NICE Quality and Outcomes Framework indicator",
      "authors": [
        "H Ni For",
        "Ce"
      ],
      "year": 2022
    },
    {
      "title": "Outcomes for implementation research: conceptual distinctions, measurement challenges, and research agenda",
      "authors": [
        "E Proctor",
        "H Silmere",
        "R Raghavan",
        "P Hovmand",
        "G Aarons",
        "A Bunger"
      ],
      "year": 2011,
      "doi": "10.1007/s10488-010-0319-7"
    },
    {
      "title": "Stakeholder perspectives on adjunctive mHealth services during transitions of care for patients with schizophrenia-spectrum disorders",
      "authors": [
        "E Moitra",
        "H Park",
        "K Guthrie",
        "J Johnson",
        "G Peters",
        "E Wittler"
      ],
      "year": 2024
    },
    {
      "title": "Implementation of a computer-assisted face-to-face intervention for mapping the social support networks of patients with severe mental illness in routine clinical practice: analysis of the appropriateness and acceptability of the intervention",
      "authors": [
        "P Nicaise",
        "H Garin",
        "P Smith",
        "D'oreye De Lantremange",
        "S Leleux",
        "L Wyngaerden"
      ],
      "year": 2022
    },
    {
      "title": "Developing a hypothetical implementation framework of expectations for monitoring early signs of psychosis relapse using a mobile app: qualitative study",
      "authors": [
        "S Allan",
        "S Bradstreet",
        "H Mcleod",
        "J Farhall",
        "M Lambrou",
        "J Gleeson"
      ],
      "year": 2019,
      "doi": "10.2196/14366"
    },
    {
      "title": "Exploring contextual factors impacting the implementation of and engagement with a digital platform supporting psychosis recovery: A brief report",
      "authors": [
        "L Sequeira",
        "I Kassam",
        "D ' Arcey",
        "J Zhou",
        "W Junaid",
        "S Luo"
      ],
      "year": 2023
    },
    {
      "title": "A novel blended transdiagnostic intervention (eOrygen) for youth psychosis and borderline personality disorder: uncontrolled Single-Group pilot study",
      "authors": [
        "S O'sullivan",
        "C Mcenery",
        "D Cagliarini",
        "J Hinton",
        "L Valentine",
        "J Nicholas"
      ],
      "year": 2024
    },
    {
      "title": "A Mixed-Methods implementation evaluation of virtual reality job interview training in IPS supported employment",
      "authors": [
        "S Blajeski",
        "M Smith",
        "M Harrington",
        "J Johnson",
        "B Ross",
        "A Weaver"
      ],
      "year": 2024,
      "doi": "10.1176/appi.ps.20230023"
    },
    {
      "title": "As soon as I start trusting human beings, they disappoint me, and now I am going to get on an app that someone could hack. I really do not want to take that chance: barriers and facilitators to digital peer support implementation into community mental health centers",
      "authors": [
        "K Fortuna",
        "S Divatia",
        "S Neupane",
        "P Geiger",
        "A Bohm"
      ],
      "year": 2023,
      "doi": "10.3389/fdgth.2023.1130095"
    },
    {
      "title": "Using complexity assessment to inform the development and deployment of a digital dashboard for schizophrenia care: case study",
      "authors": [
        "A Gremyr",
        "Andersson G\u00e4re",
        "B Greenhalgh",
        "T Malm",
        "U Thor",
        "J Andersson"
      ],
      "year": 2020
    },
    {
      "title": "Pilot implementation of co-designed software for co-production in mental health care planning: a qualitative evaluation of staff perspectives",
      "authors": [
        "M Farr",
        "C Pithara",
        "S Sullivan",
        "H Edwards",
        "W Hall",
        "C Gadd",
        "J Walker",
        "N Hebden",
        "J Horwood"
      ],
      "year": 2019
    },
    {
      "title": "Implementing a digital tool to support shared care planning in community-based mental health services: qualitative evaluation",
      "authors": [
        "C Pithara",
        "M Farr",
        "S Sullivan",
        "H Edwards",
        "W Hall",
        "C Gadd"
      ],
      "year": 2020
    },
    {
      "title": "How a pointof-care dashboard facilitates co-production of health care and health for and with individuals with psychotic disorders: a mixed-methods case study",
      "authors": [
        "A Gremyr",
        "C Holmberg",
        "J Thor",
        "U Malm",
        "B G\u00e4re",
        "A Andersson"
      ],
      "year": 2022
    },
    {
      "title": "Fostering implementation of health services research findings into practice: a consolidated framework for advancing implementation science",
      "authors": [
        "L Damschroder",
        "D Aron",
        "R Keith",
        "S Kirsh",
        "J Alexander",
        "J Lowery"
      ],
      "year": 2009
    },
    {
      "title": "The updated consolidated framework for implementation research based on user feedback",
      "authors": [
        "L Damschroder",
        "C Reardon",
        "Mao Widerquist",
        "J Lowery"
      ],
      "year": 2022,
      "doi": "10.1186/s13012-022-01245-0"
    },
    {
      "title": "Implementing, embedding, and integrating practices: an outline of normalization process theory",
      "authors": [
        "C May",
        "T Finch"
      ],
      "year": 2009,
      "doi": "10.1177/0038038509103208"
    },
    {
      "title": "Process evaluation of complex interventions: medical research Council guidance",
      "authors": [
        "G Moore",
        "S Audrey",
        "M Barker",
        "L Bond",
        "C Bonell",
        "W Hardeman"
      ],
      "year": 2015,
      "doi": "10.1136/bmj.h1258"
    },
    {
      "title": "Beyond adoption: a new framework for theorizing and evaluating nonadoption, abandonment, and challenges to the scale-up, spread, and sustainability of health and care technologies",
      "authors": [
        "T Greenhalgh",
        "J Wherton",
        "C Papoutsi",
        "J Lynch",
        "G Hughes",
        "S Hinder"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.8775"
    },
    {
      "title": "The NASSS-CAT tools for understanding, guiding, monitoring, and researching technology implementation projects in health and social care: protocol for an evaluation study in real-world settings",
      "authors": [
        "T Greenhalgh",
        "H Maylor",
        "S Shaw",
        "J Wherton",
        "C Papoutsi",
        "V Betton"
      ],
      "year": 2020
    },
    {
      "title": "The clinical adoption meta-model: a Temporal meta-model describing the clinical adoption of health information systems",
      "authors": [
        "M Price",
        "F Lau"
      ],
      "year": 2014,
      "doi": "10.1186/1472-6947-14-43"
    },
    {
      "title": "Advancing a conceptual model of evidence-based practice implementation in public service sectors",
      "authors": [
        "G Aarons",
        "M Hurlburt",
        "S Horwitz"
      ],
      "year": 2011
    },
    {
      "title": "patient safety: building safer systems for better care",
      "year": 2012,
      "doi": "10.17226/13269"
    },
    {
      "title": "Beyond usability: designing effective technology implementation systems to promote patient safety",
      "authors": [
        "B Karsh"
      ],
      "year": 2004
    },
    {
      "title": "A review of research on fidelity of implementation: implications for drug abuse prevention in school settings",
      "authors": [
        "L Dusenbury",
        "R Brannigan",
        "M Falco",
        "W Hansen"
      ],
      "year": 2003
    },
    {
      "title": "A glossary for dissemination and implementation research in health",
      "authors": [
        "B Rabin",
        "R Brownson",
        "D Haire-Joshu",
        "M Kreuter",
        "N Weaver"
      ],
      "year": 2008
    },
    {
      "title": "Accelerating the impact of artificial intelligence in mental healthcare through implementation science",
      "authors": [
        "P Nilsen",
        "P Svedberg",
        "J Nygren",
        "M Frideros",
        "J Johansson",
        "S Schueller"
      ],
      "year": 2022,
      "doi": "10.1177/26334895221112033"
    },
    {
      "title": "Assessing citation networks for dissemination and implementation research frameworks",
      "authors": [
        "T Skolarus",
        "T Lehmann",
        "R Tabak",
        "J Harris",
        "J Lecy",
        "A Sales"
      ],
      "year": 2017
    },
    {
      "title": "Theories informing eHealth implementation: systematic review and typology classification",
      "authors": [
        "M Heinsch",
        "J Wyllie",
        "J Carlson",
        "H Wells",
        "C Tickner",
        "F Kay-Lambkin"
      ],
      "year": 2021,
      "doi": "10.2196/18500"
    },
    {
      "title": "Scoping review identifies significant number of knowledge translation theories, models, and frameworks with limited use",
      "authors": [
        "L Strifler",
        "R Cardoso",
        "J Mcgowan",
        "E Cogo",
        "V Nincic",
        "P Khan"
      ],
      "year": 2018,
      "doi": "10.1016/j.jclinepi.2018.04.008"
    },
    {
      "title": "Validation of the theoretical domains framework for use in behaviour change and implementation research",
      "authors": [
        "J Cane",
        "O' Connor",
        "D Michie"
      ],
      "year": 2012,
      "doi": "10.1186/1748-5908-7-37"
    },
    {
      "title": "Instrumentation issues in implementation science",
      "authors": [
        "R Martinez",
        "C Lewis",
        "B Weiner"
      ],
      "year": 2014
    },
    {
      "title": "Implementation science and implementation science communications: a refreshed description of the journals' scope and expectations",
      "authors": [
        "M Wensing",
        "A Sales",
        "P Wilson",
        "R Armstrong",
        "R Kislov",
        "N Rankin"
      ],
      "year": 2021,
      "doi": "10.1186/s13012-021-01175-3"
    },
    {
      "title": "Ten years of implementation outcomes research: a scoping review",
      "authors": [
        "E Proctor",
        "A Bunger",
        "R Lengnick-Hall",
        "D Gerke",
        "J Martin",
        "R Phillips"
      ],
      "year": 2023,
      "doi": "10.1186/s13012-023-01313-z"
    },
    {
      "title": "Knowledge translation in health: how implementation science could contribute more",
      "authors": [
        "M Wensing",
        "R Grol"
      ],
      "year": 2019,
      "doi": "10.1186/s12916-019-1322-9"
    },
    {
      "title": "Integrated knowledge translation (IKT) in health care: a scoping review",
      "authors": [
        "A Gagliardi",
        "Berta Kothari",
        "A Boyko",
        "J Urquhart"
      ],
      "year": 2015
    },
    {
      "title": "Digital technology for management of severe mental disorders in low-income and middle-income countries",
      "authors": [
        "R Merchant",
        "J Torous",
        "E Rodriguez-Villa",
        "J Naslund"
      ],
      "year": 2020
    },
    {
      "title": "World mental health report",
      "year": 2022
    }
  ],
  "num_references": 77,
  "original_doi": "https://doi.org/10.13039/100014653"
}
