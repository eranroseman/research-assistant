{
  "paper_id": "V3ZWIF9V",
  "title": "Design and analysis of stepped wedge cluster randomized trials",
  "abstract": "Cluster randomized trials (CRT) are often used to evaluate therapies or interventions in situations where individual randomization is not possible or not desirable for logistic, financial or ethical reasons. While a significant and rapidly growing body of literature exists on CRTs utilizing a \"parallel\" design (i.e. I clusters randomized to each treatment), only a few examples of CRTs using crossover designs have been described. In this article we discuss the design and analysis of a particular type of crossover CRTthe stepped wedgeand provide an example of its use.",
  "year": 1992,
  "date": "1992",
  "journal": "Control Clin Trials",
  "publication": "Control Clin Trials",
  "authors": [
    {
      "forename": "Michael",
      "surname": "Hussey",
      "name": "Michael Hussey",
      "affiliation": "a  Fred Hutchinson Cancer Research Center , Seattle , WA , United States \n\t\t\t\t\t\t\t\t Fred Hutchinson Cancer Research Center \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Seattle \n\t\t\t\t\t\t\t\t\t WA \n\t\t\t\t\t\t\t\t\t United States"
    },
    {
      "forename": "James",
      "surname": "Hughes",
      "name": "James Hughes",
      "affiliation": "b  Department of Biostatistics 357232 , University of Washington , Seattle , WA 98195 , United States \n\t\t\t\t\t\t\t\t Department of Biostatistics 357232 \n\t\t\t\t\t\t\t\t University of Washington \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 98195 \n\t\t\t\t\t\t\t\t\t Seattle \n\t\t\t\t\t\t\t\t\t WA \n\t\t\t\t\t\t\t\t\t United States",
      "email": "jphughes@u.washington.edu"
    }
  ],
  "doi": "",
  "keywords": [
    "Cluster randomized trial",
    "Stepped wedge design",
    "Prevention trials"
  ],
  "sections": [
    {
      "title": "Introduction",
      "text": "Cluster (or community, or group) randomized trials (CRT) are distinguished by the fact that individuals are randomized in groups rather than individually. CRTs have been used to evaluate antismoking interventions  [1, 2] , methods of preventing human immunodeficiency virus (HIV) and other sexually transmitted diseases (STDs)  [3, 4] , and in a number of other contexts  [5, 6] . Cluster designs may be chosen because the intervention can only be administered on a community-wide scale (e.g. [7] ), or to minimize contamination (  [8] ), or for other logistic, financial or ethical reasons. From a statistical viewpoint, the key characteristic of CRTs is that the individual units within a cluster are correlated and this feature must be incorporated into power calculations and the trial analysis.\n\nCRTs often employ a parallel design: for a two-arm study with 2I independent clusters, I clusters are randomly assigned to each intervention at a single time point. If the cluster sizes are all equal, a two-sample t-test may be used to compare cluster-level mean responses between the intervention groups. If there are more than 2 treatment arms, a oneway analysis of variance may be used. Sometimes the communities are matched and randomization is done within the matched sets. In that case, a paired analysis (e.g. paired t-test) is used. When cluster sizes vary, individual level analyses using generalized estimating equations  [17]  or random effects models  [16]  may be used. Statistical aspects of the design and analysis of parallel CRTs have been widely discussed (e.g. [9, 10] ).\n\nIn contrast, crossover designs are less commonly used in CRTs (three examples are  [6, 11, 12] ). A crossover CRT requires fewer clusters than a parallel design but may take twice as long (or longer) to complete (since each cluster receives both the treatment and control interventions). If the intervention requires a lengthy follow up period, then this fact alone might make a crossover design impractical. In a standard crossover design the order of the interventions is randomized for each cluster and a time period (called the \"washout\" period) is often included between the two interventions so that the first intervention does not affect the second. Analysis of a standard crossover design focuses on within-cluster comparisons using a paired t-test.\n\nA stepped wedge design  [13]  is a type of crossover design in which different clusters cross over (switch treatments) at different time points. In addition, the clusters cross over in one direction only-typically, from control to intervention. The first time point usually corresponds to a baseline measurement where none of the clusters receive the intervention of interest. At subsequent time points, clusters initiate the intervention of interest and the response to the intervention is measured. More than one cluster may start the intervention at a time point, but the time at which a cluster begins the intervention is randomized. Fig.  1  illustrates the differences between the parallel, traditional crossover and stepped wedge designs.\n\nAlthough the stepped wedge design extends the length of a randomized trial due to the presence of multiple time intervals, the nature of the design may be beneficial in certain settings. In a parallel or traditional crossover design, the intervention must be implemented in half of the total clusters simultaneously. However, limited resources or geographical constraints may make this logistically impossible (e.g. [13] ). The stepped wedge design allows the researcher to implement the intervention in a smaller fraction of the clusters at each time point. Another unique feature of the stepped wedge design is that the crossover is unidirectional. All clusters eventually receive the intervention and, in particular, the intervention is never removed once it has been implemented (at least over the course of the trial) which may alleviate ethical and/or community concerns. This makes the stepped wedge design particularly useful for evaluating the population-level impact of an intervention that has been shown to be effective in an individually randomized trial. The unidirectional aspect of the crossover does, however, complicate the analysis since the treatment effect can no longer be estimated exclusively from within-cluster comparisons. More details on the analysis of such trials are provided below.\n\nIn Section 2 we describe a trial being conducted in Washington state that uses a stepped wedge design. This motivating example provides a context for the theoretical and simulation results shown in Section 3 where we describe statistical aspects of the design and analysis of stepped wedge CRTs. In Section 4 we summarize our findings and discuss future areas of research."
    },
    {
      "title": "Examplepartner notification",
      "text": "Partner notification is the process by which sex partners of patients with sexually transmitted infections (STIs) are notified of potential exposure to infection and encouraged to seek treatment. Standard practice for partner notification in most states in the US involves contact of partners by public health authorities. However, the high costs associated with this practice have influenced investigators to seek alternative partner treatment methods. One alternative strategy is patient delivered partner therapy (PDPT) in which infected persons are given drugs or drug vouchers to give to their sex partners. In the case of vouchers, these can be redeemed for appropriate drugs at local pharmacies.\n\nAn individually randomized trial conducted by Golden et al.  [14]  in King County, Washington between 1998 and 2003 evaluated the effectiveness of a PDPT-based partner notification strategy dubbed EPT (expedited partner therapy) versus standard partner notification for the treatment of chlamydia and/or gonnorrhea infection. The primary outcome was the presence of persistent or recurrent infection in the original index patient 3-19 weeks after treatment. Overall, the trial showed a significantly increased proportion of partners treated (per participant report) and a decreased risk of recurrent or persistent infection among participants in the EPT group compared to the control.\n\nBased on the success of this individually randomized trial, the county health commissioners of Washington state have agreed to implement EPT in all the counties in Washington. Support for a CRT to evaluate the population-level effect of the intervention has been received from the National Institutes of Health. Using a stepped wedge design, twenty-four county health districts in Washington state will be randomized to EPT at one of four possible times (six counties at a time). Cross-sectional surveys will be conducted in each county in each time interval (and at baseline) to measure the prevalence of gonorrhea and chlamydia (with different people in each time interval). The randomization times will be separated by 6 months to allow implementation and assessment of the intervention within each time period. The primary outcomes are the prevalence of chlamydial infection among women tested in family planning clinics and the number of reported gonorrhea infections in women in each county. This design will allow the evaluation of the population-level effectiveness of the EPT intervention.\n\nPreliminary data suggest that overall baseline prevalence of chlamydial infection will be 0.05 and the coefficient of variation (CV) for county to county variation  [15]  is 0.30, where CV is defined to be the ratio of the between-county standard deviation over the mean prevalence. Gonorrhea infection is much rarer and incidence rates in the 10-44 year old female population average 79 per 100,000 person years. However, there is substantial variation from county to county and the estimated CV is 0.90."
    },
    {
      "title": "Statistical issues",
      "text": "In this section we examine a number of issues related to the design and analysis of stepped wedge CRTs."
    },
    {
      "title": "Model",
      "text": "Random effects are commonly used to model the correlation between individuals within the same cluster in CRT's. For a design with I clusters, T time points, and N individuals sampled per cluster per time interval, let Y ijk be the response corresponding to individual k at time j from cluster i (i in 1, \u2026, I; j in 1, \u2026, T; k in 1, \u2026, N) and let Y ij be the mean for cluster i at time j. Define\n\nwhere \u03b1 i is a random effect for cluster i such that \u03b1 i \u223c N(0, \u03c4 2 ), \u03b2 j is a fixed effect corresponding to time interval j (j in 1, \u2026, T -1, \u03b2 T = 0 for identifiability), X ij is an indicator of the treatment mode in cluster i at time j (1 = intervention; 0 = control), and \u03b8 is the treatment effect. Individual level responses may be modelled as\n\nwhere e ijk f iid N \u00f00; r 2 e \u00de (individual level covariates may be added to this model by defining \u03bc ijk in an analogous manner). A model for the cluster means is obtained by summing over the individuals in a cluster to obtain:\n\nwhere e ij \u00bc P k e ijk =N f iid N \u00f00; r 2 \u00de and \u03c3 2 = \u03c3 e 2 /N. We also assume that the e ijk (and, hence, e ij ) are independent of \u03b1 i . The variance of an individual-level response is\n\nand the variance of the cluster-level response is\n\n) is referred to as the intraclass correlation and characterizes the correlation between individuals from the same cluster. The increase in the variance of Y ij due to the clustering (relative to independent data) is given by the \"variance inflation factor\" 1 + (N -1)\u03c1. Alternatively, some authors characterize the cluster effect on the variance in terms of the coefficient of variation, \u03c4 / \u03bc  [15] .\n\nIf the individual level responses are binary then the cluster level response Y ij is a proportion and it is reasonable to assume that \u03c3 e 2 = \u03bc\u204e(1 -\u03bc). The model (  3 ) is easily adapted to handle different numbers of individuals sampled per cluster per time interval by substituting N ij for N."
    },
    {
      "title": "Approaches to data analysis",
      "text": "In the following we discuss approaches to analysis of data from a study employing the stepped wedge design. Initially, we focus on equal cluster sizes and the analysis of cluster-level means. We then extend the discussion to the unequal cluster size situation and individual-level analyses."
    },
    {
      "title": "\u03c4 2 and \u03c3 2 known",
      "text": "Model (  3 ) is an example of a linear mixed model (LMM). If the values of the variance components \u03c4 2 and \u03c3 2 are known, then estimates of the fixed effects can be obtained using weighted least squares (WLS). Specifically, let Z be the IT \u00d7 (T + 1) design matrix corresponding to the parameter vector \u03b7 = (\u03bc, \u03b2 1 , \u03b2 2 , \u2026, \u03b2 T-1 , \u03b8) for a stepped wedge design.\n\nThen \u03b7 \u02c6= (Z\u2032V -1 Z) -1 (Z\u2032V -1 Y) (so \u03b8 \u02c6is the T + 1st element of \u03b7 \u02c6) and the covariance matrix of \u03b7 \u02c6is (Z\u2032V -1 Z) -1 , where V is an IT \u00d7 IT block diagonal matrix. Each T \u00d7 T block within V describes the correlation structure between the repeated (in time) cluster means and has the structure\n\n2 6 6 4 3 7 7 5 :\n\nSince \u03c4 2 and \u03c3 2 are seldom known this approach is generally not applicable for data analysis, but provides a useful approach to pre-trial power analyses."
    },
    {
      "title": "\u03c4 2 and \u03c3 2 unknown",
      "text": "When the variance components are unknown, Laird and Ware  [16]  describe an empirical Bayes approach to estimating the fixed effect parameters and variance components of LMM when the response is continuous and normally distributed. In addition, this approach can be used even with non-normal individual-level data (e.g. binary responses) if the cluster sizes are approximately equal, since the analysis can then be done at the cluster mean level. However, if the responses are non-normal and the cluster sizes vary then an efficient analysis at the cluster mean level requires weights that depend on the unknown parameters, \u03c4 2 and \u03c3 2 . In this case an analysis at the individual level using generalized linear mixed models (GLMM) or generalized estimating equations (GEE) is preferred.\n\nGLMM is an extension to the LMM procedure for non-normal data  [24] . The expected value of the outcome, which may be binary, a count or a continuous response, is linked to the linear predictor (1) via a (possibly) nonlinear transformation. The underlying distribution of the outcome can follow any distribution in the exponential family. Use of a GLMM facilitates modeling of individual level binary responses since a logit link can be used to analyze individual-level data. Also, an individual-level GLMM-based analysis automatically provides proper weighting when cluster sizes vary. Software to fit such models has recently been incorporated into many general statistical packages.\n\nAlternatively, generalized estimating equations (GEE)  [17] , which can flexibly handle normal or non-normal endpoints, are sometimes used to analyze CRT data. GEE tends to be more robust to misspecification of the variance structure than LMM or GLMM since \"sandwich\" type variance estimates are used  [18] . As with GLMM, GEE is more natural than LMM for individual-level binary outcomes since a logit link can be used to analyze the individual-level data and the individual-level analysis automatically accounts for variable cluster sizes. However, Sharples and Breslow  [23]  show that the GEE procedure tends to give inflated type I error rates when the number of clusters is small.\n\nThe above methods (LMM, GEE, GLMM) should be used with care if the number of clusters and time points is small since theoretical results for these methods are based on asymptotics. Feng et al.  [19]  contrast GEE and LMM approaches for parallel design CRTs. Section 3.7 uses simulations to compare these three approaches in the context of the stepped wedge design."
    },
    {
      "title": "Within-cluster analysis",
      "text": "The methods discussed above use both within-cluster and between-cluster information to estimate the treatment effect. This approach is necessary to avoid confounding the treatment effect with changes over time. However, if there are no temporal effects on the outcome (i.e. \u03b2 j = 0 for all j in (1)), then a within-cluster analysis can be used to estimate the treatment effect.\n\nConsider a design with I clusters and T time points. Let w i be the number of time points in cluster i that receive the control. Consequently, Tw i is the number of time points in cluster i that receive the intervention. Furthermore, let C i and T i be the sets of time points receiving control and intervention in cluster i, respectively. Then, a within-cluster estimate of \u03b8 is given by\n\nand under model (3) (assuming all \u03b2 j = 0), the variance is given by\n\nNotice that this variance formula does not depend on \u03c4 2 since the cluster effect, \u03b1 i , cancels out in the computation of \u03b8 \u02dc. In this scenario, the paired t-test is an appropriate method for testing the hypothesis of no treatment effect.\n\nThe drawback of a within-cluster analysis is the potential for bias. If the time effects, \u03b2 1 , \u2026, \u03b2 T are not all 0, then the estimated treatment effect (4) will, in general, be biased. The bias is a linear combination of\n\nThus, failure to model time effects will result in a biased estimate of the treatment effect unless \u03b2 1 , \u2026, \u03b2 T = 0. Even a WLS analysis that utilizes both within and between cluster information in estimating \u03b8 will be biased if time effects are not included in (1)  [20] . Note, however, that the bias in \u03b8 \u02dcis independent of the true value of \u03b8. Furthermore, the coefficients of the \u03b2's in (6) can be calculated once the treatment schedule is determined. Thus, understanding of each \u03b2's contribution to the bias can occur during the design phase of the trial."
    },
    {
      "title": "Power calculations",
      "text": "Suppose the goal is to test the hypothesis H o : \u03b8 = 0 versus Ha: \u03b8 = \u03b8 A in model (3) using a stepped wedge design with I sites and T time points. A Wald test may be based on Z \u00bc h= ffiffiffiffiffiffiffiffiffiffiffiffiffi ffi Var\u00f0h\u00de p\n\n, where \u03b8 \u02c6is the estimated treatment effect from a weighted least squares analysis (Section 3.2.1). The approximate power for conducting a two-tailed test of size \u03b1 is given as\n\nwhere \u03a6 is the cumulative standard Normal distribution function and Z 1-\u03b1/2 is the (1 -\u03b1/2)th quantile of the standard Normal distribution function. In general, Var(\u03b8 \u02c6) is the appropriate element of (Z\u2032V -1 Z) -1 from the weighted least squares analysis. However, for models of the form (3) (which includes parallel and crossover as well as stepped wedge designs), and assuming X ij is coded 0 or 1, it is possible to express Var(\u03b8 \u02c6) in closed form. As before, let X ij = 0 if cluster i receives the control at time j and X ij = 1 if cluster i receives the intervention at time j. Assuming equal N per cluster per time interval it can be shown that\n\nwhere\n\nIn the Washington EPT trial, the baseline prevalence of Chlamydia is approximately 0.05 and we plan to test 100 individuals per cluster per time interval. For the power calculations, therefore, we use r 2 \u00f00:05\u00de\u00f00:95\u00de 100 \u00bc 0:000475. The 24 counties will be randomized 6 at a time, so that T = 5. Fig.  2  shows the power of the trial as a function of effect size (expressed as a relative risk) for a coefficient of variation ( s l ) of 0.3 and 0.5. Because the stepped wedge design uses both within-cluster and between-cluster information, power is relatively insensitive to variations in the CV. For a CVof 0.3 the plot shows that the trial has about 80% power to detect a decrease in prevalence of roughly 36% (from 0.05 to 0.032)."
    },
    {
      "title": "Effect of number of steps",
      "text": "An important choice in the stepped wedge design is the number of clusters randomized at each time step. Fig.  3  illustrates the effect of varying the number of clusters randomized at each time step (so that there are fewer time steps and fewer measurement times) for the Washington State EPT trial, assuming a relative risk of 0.7 (other alternatives give similar results).\n\nNot surprisingly, the optimal power is achieved when each cluster is randomized to the intervention at its own randomization step. However, this may be infeasible for logistic reasons, especially if the design calls for the steps to be separated by a period of months. From Fig.  3  we see that randomizing multiple clusters at each time point and thereby reducing the overall number of measurement times significantly reduces power. Separate analyses (not shown) indicate that the loss of power is primarily due to the loss of measurement times rather than the loss of randomization times (in other words, if groups of clusters are randomized to begin the intervention simultaneously but the number of measurement times is not decreased, there is little loss of power; it is not clear why one would design a trial in this manner, however, since the trial would not be shortened). Note that the lines in Fig.  3  stay approximately \"parallel\" across a wide range of the CVs indicating that the loss in power is relatively independent of the coefficient of variation. Fig.  2 . Theoretical power for the Washington EPT trial. The overall prevalence is assumed to be 5%, with 100 individuals sampled per cluster per time point. Power is displayed versus effect size for two coefficients of variation."
    },
    {
      "title": "Efficacy of WLS relative to a within-cluster analysis",
      "text": "The relative efficiency of the WLS estimator, \u03b8 \u02c6(Section 3.2.1), versus the within-cluster estimate, \u03b8 \u02dc(Section 3.2.3), can be determined by taking the (inverse of the) ratio of the respective variances. If there are no time effects, this ratio is\n\n(note that the WLS variance here is different from (8) since this comparison is developed under the assumption that there are no time effects). It can be shown that the WLS estimator always exceeds the within-cluster estimate in efficiency unless \u03c4 2 = 0  [20] . However, if time effects are included in the WLS model (so that the variance (  8 ) is used) then \u03b8 \u02c6is less efficient than \u03b8 \u02dcbut, as described in Section 3.2.3, \u03b8 \u02dcis likely biased."
    },
    {
      "title": "Delayed treatment effect",
      "text": "The results presented in the previous sections assume that the full effect of the intervention is realized in the same time interval that the intervention is introduced. In some situations, however, the full effect of the intervention may not be realized until several time intervals following implementation. This section explores changes in power due to such a delay.\n\nSuppose we expect that the intervention will be 50% effective after one time interval, 80% effective after two time intervals and 100% effective after three time intervals. We may continue to parameterize the treatment effect in terms of a single parameter, \u03b8, which can be interpreted as the maximum or full treatment effect. The delay may be modelled by allowing the X ij in (1) to be fractional. Power may then be calculated as outlined in Section 3.3 although the closed form expression (8) is not valid when the X ij are fractional.\n\nThe overall effect of such a delay is to reduce power. Power can be partly, but not completely, recovered by adding additional measurement periods onto the end of the trial. The greater the delay in the intervention effect, the greater is the effect on power. Fig.  4  shows the effect of a minor delay (80%, 90%, and 100% at 1, 2, and 3 time units postintervention, respectively) and major delay (50%, 80%, and 100% at 1, 2, and 3 time units post-intervention, respectively) on power in the Washington state EPT trial as well as the potential for recovery of power through the addition of extra measurement periods. Although inclusion of additional monitoring periods at the end of the study increases power, it is difficult to recover the full power that was seen with no delay. It is important, therefore, to make the time intervals sufficiently long so that the full intervention effect is realized in a single interval."
    },
    {
      "title": "A simulation comparing analysis methods",
      "text": "We did a small simulation experiment to compare the size and power of the hypothesis test, H o : \u03b8 = 0 vs. H a : \u03b8 \u2260 0, using LMM, GEE, and GLMM methods in the context of the stepped wedge design. Individual level data were simulated using  (2) . LMM analyses were conducted at the cluster mean level, while GEE and GLMM analyses were done at the individual level. Analyses were done in R. LME was implemented using the R function lme()  [22] , GEE was implemented using gee() and GLMM was implemented using glmmPQL(). Algorithms for fitting LMM and GEE models have been fairly standardized; however, algorithms for fitting GLMM models are more variable between software packages so our results may not reflect other implementations. We evaluated two situations: where equal sample sizes are available for each cluster and where variable sample sizes are available for each cluster. These two situations correspond to sampling plans for comparing chlamydial and gonorrheal rates (respectively) in the Washington state EPT trial described in Section 2. A trial with 24 clusters and 4 randomization steps was considered. The baseline prevalence of disease was 0.05 and the between-cluster variance \u03c4 2 was assumed to be 0.000225, which corresponds to a coefficient of variation of 0.3. We used 100 individuals per cluster per time interval for the simulations with equal sample sizes per cluster. For the simulations with different cluster sizes we randomly assigned a total of 2400 individuals to 24 clusters using a multinomial distribution with parameters selected from a flat prior Dirichlet distribution (parameters (1,1,1)). Using this distribution, the interquartile range for the number of individuals per cluster was (32,168). For all methods the power using both the standard variance and a jackknife estimate of variance (in parentheses) is given. The estimated power based on the simulations is given in Table  1 . For both equal and unequal cluster sizes a jackknife estimate of the variance is needed to maintain the size of the test for both GEE and GLMM. For equal cluster sizes LMM has slightly higher power than GEE which, in turn, has greater power than GLMM (assuming jackknife variance estimates are used). The differences are not great, however. When cluster sizes vary, power is much better for GEE and GLMM compared to LMM. This is because the LMM approach analyzes the results at the cluster level and weights must be used to account for the different cluster sizes. However, the correct weights depend on the variance components. Since these are unknown prior to an analysis we tried using weights proportional to the cluster size (results shown in the table) and equal weights (not shown but results similar to those given in the table). Both approaches are inefficient relative to a correctly weighted analysis and this is manifest as low power in the table. In contrast, GEE and GLMM analyze these binary data at the individual level and thereby provide the correct weighting for each cluster. For this reason, we recommend using individual level analyses when cluster sizes vary significantly. A jackknife estimate of the variance is recommended to maintain the size of the test in GEE and GLMM analyses."
    },
    {
      "title": "Discussion",
      "text": "Using theoretical calculations and simulation we have investigated statistical characteristics of the stepped wedge design for cluster randomized trials. In particular, we have outlined a procedure for computing power in such trials and investigated the effect of varying intercluster correlation, number of randomization steps and treatment delay on trial power. The design is relatively insensitive to variations in the intercluster correlation. We also found that, for a fixed number of clusters, power decreases as the number of randomization steps decreases. Most of the power loss is due to a reduction in the number of measurement times rather than the reduction in randomization steps, per se. However, in practice, the optimal situation of having one cluster randomized to the intervention at each time point may be infeasible. A practical strategy is simply to maximize the number of time intervals given constraints on the number of clusters that can logistically be started at one time point and the desired length of the trial.\n\nWe found that a delay in the treatment effect (i.e. where the full treatment effect is not realized until one or more time intervals after the intervention is introduced) significantly reduces power. Delays can be incorporated into the power calculations by using fractional values for the treatment covariate in the design matrix Z. Explicit modeling of the delay in this manner recovers a small portion of the power. Adding additional monitoring periods at the end of the trial results in additional power recovery. However, the loss in power due to a delay in the treatment effect generally cannot be fully recovered. Therefore, it is desirable to make each monitoring period long enough so that the effect of the treatment is fully realized before the next period begins.\n\nAnalyses that rely on within-cluster information only (e.g. paired t-test) provide a valid analysis of the stepped wedge design only if there are no time effects. Otherwise, a within-cluster analysis provides a biased estimate of the treatment effect. A formula for the bias was derived based on the treatment schedule and the true values of time effect parameters \u03b2 1 , \u2026, \u03b2 T-1 . Within-cluster analyses should only be used if no significant temporal trends or fluctuations are expected over the course of the trial. However, if external or a priori information suggests that there are no time effects then an analysis based on model (3) without parameters for time still provides a more efficient analysis than the paired t-test.\n\nAn anonymous reviewer suggested modifying (1) by including time as a random effect. We felt that this approach did not reflect our interest in controlling for temporal trends and fluctuations in disease prevalence over the course of a particular trial (and a relatively complex model for the time effect might be required sincefor infectious disease studiesadjacent time periods are unlikely to be independent). Nonetheless, we found this idea interesting and potentially applicable in some circumstances. Such an approach might be particularly appropriate if temporal variations in the outcome were thought to be due to factors unrelated to changes in the underlying disease prevalence (e.g. changes in personnel doing outcome surveys). Further development of this idea is warranted.\n\nUsing simulations, we compared LMM, GLMM, and GEE with respect to size and power for a trial with 24 clusters and 5 time intervals (to mimic the Washington state EPT trial). The simulation results agreed well with predictions based on asymptotics-LMM maintained the nominal test size and had power close to that predicted by Eq. (  7 ) for the case of equal cluster sizes. GEE and GLMM showed evidence of inflated size that could be resolved using a jackknife variance estimate. This phenomenon may be due to the limited number of clusters  [23] . Although LMM had a slight power advantage when cluster sizes were equal, GEE and GLMM were substantially more efficient than LMM when cluster sizes varied. Model (3) assumes that there are no cluster by time interactions. Including such interactions would result in an overparameterized model, however. If a cluster by time interaction is expected then one possible strategy is to create strata of clusters with similar expected time trends. Then a stratum by time interaction could be included as a factor in the model.\n\nThe stepped wedge design provides an innovative choice for a cluster randomized crossover trial that is subject to constraints that limit the use more conventional designs. The stepped wedge seems particularly suited to investigations of community level public health interventions that have been proven effective in individual level trials and so-called \"phase IV\" effectiveness trials."
    },
    {
      "text": "Fig. 1. Treatment schedules for parallel, crossover, and stepped wedge designs. \"0\" represents control or existing treatment; \"1\" represents an intervention."
    },
    {
      "text": "Fig. 3. Power curves when 24 clusters are randomized and number of randomization steps is varied. The number of measurement times (tp) varies from 8 (3 clusters randomized at each time) to 2 (12 clusters randomized at each time). The baseline event prevalence is 0.05 and the intervention effect corresponds to an risk ratio of 0.7."
    },
    {
      "text": "Fig. 4. Theoretical power vs. CV comparing situations in the Washington EPT trial where a minor treatment effect delay is assumed and when a major delay is assumed. Figures are shown for a risk ratio of 0.7. Plots have lines corresponding to situations with no delay, delay and no additional monitoring, delay and 3 additional measurement times, and delay and 6 additional measurement times."
    },
    {
      "text": "Estimated power to test the hypothesis H o : \u03b8 = 0 for designs with clusters that have the same sample size (N = 100) and clusters with different sample sizes (24 clusters, 5 time points, \u03c4 2 = 0.000225, \u03bc = 0.05, 1000 simulations)"
    }
  ],
  "references": [
    {
      "title": "Aspects of statistical design for the Community Intervention Trial for Smoking Cessation (COMMIT)",
      "authors": [
        "M Gail",
        "D Byar",
        "T Pechacek"
      ],
      "year": 1992,
      "doi": "10.1016/0197-2456(92)90026-v"
    },
    {
      "title": "Hutchinson Smoking Prevention Project: long-term randomized trial in school-based tobacco use prevention-results on smoking",
      "authors": [
        "A Peterson",
        "K Kealey",
        "S Mann"
      ],
      "year": 2000,
      "doi": "10.1093/jnci/92.24.1979"
    },
    {
      "title": "Impact of improved treatment of sexually transmitted diseases on hiv infection in rural tanzania: randomised controlled trial",
      "authors": [
        "H Grosskurth",
        "F Mosha",
        "J Todd"
      ],
      "year": 1995,
      "doi": "10.1016/s0140-6736(95)91380-7"
    },
    {
      "title": "Control of sexually transmitted diseases for AIDS prevention in Uganda: a randomised community trial",
      "authors": [
        "M Wawer",
        "N Sewankambo",
        "D Serwadda"
      ],
      "year": 1999,
      "doi": "10.1016/s0140-6736(98)06439-3"
    },
    {
      "title": "A cluster randomized trial of a sex education programme in Belize, Central America",
      "authors": [
        "A Martiniuk",
        "O' Connor",
        "K King"
      ],
      "year": 2003,
      "doi": "10.1093/ije/dyg014"
    },
    {
      "title": "Effects of a workplace physical exercise intervention on the intensity of headache and neck and shoulder symptoms and upper extremity muscular strength of office workers: a cluster randomized controlled crossover trial",
      "authors": [
        "T Sj\u00f6gren",
        "K Nissinen",
        "K J\u00e4rvenp\u00e4\u00e4"
      ],
      "year": 2005,
      "doi": "10.1016/j.pain.2005.03.031"
    },
    {
      "title": "On design considerations and randomization-based inference for community intervention trials",
      "authors": [
        "M Gail"
      ],
      "year": 1996,
      "doi": "10.1002/(sici)1097-0258(19960615)15:11<1069::aid-sim220>3.3.co;2-h"
    },
    {
      "title": "Contamination in trials: is cluster randomisation the answer?",
      "authors": [
        "D Torgerson"
      ],
      "year": 2001,
      "doi": "10.1136/bmj.322.7282.355"
    },
    {
      "title": "Design and analysis of cluster randomization trials in health research",
      "authors": [
        "A Donner",
        "N Klar"
      ],
      "year": 2000
    },
    {
      "title": "Design and analysis of group-randomized trials",
      "authors": [
        "D Murray"
      ],
      "year": 1998,
      "doi": "10.1093/oso/9780195120363.001.0001"
    },
    {
      "title": "A randomized controlled trial of quality assurance in sixteen ambulatory care practices",
      "authors": [
        "R Palmer",
        "T Louis",
        "L Hsu"
      ],
      "year": 1985,
      "doi": "10.1097/00005650-198506000-00001"
    },
    {
      "title": "The effect of varying levels of outdoor air supply on the symptoms of sick building syndrome",
      "authors": [
        "R Menzies",
        "R Tamblyn",
        "J Farant"
      ],
      "year": 1993,
      "doi": "10.1056/nejm199303253281201"
    },
    {
      "title": "The Gambia Hepatitis Intervention Study",
      "authors": [
        "Gambia Hepatitis",
        "Study Group"
      ],
      "year": 1987
    },
    {
      "title": "Effect of expedited treatment of sex partners on recurrent or persistent gonorrhea or chlamydial infection",
      "authors": [
        "M Golden",
        "W Whittington",
        "H Handsfield"
      ],
      "year": 2005,
      "doi": "10.1056/nejmoa041681"
    },
    {
      "title": "Simple sample size calculation for cluster-randomized trials",
      "authors": [
        "R Hayes",
        "S Bennett"
      ],
      "year": 1999,
      "doi": "10.1093/ije/28.2.319"
    },
    {
      "title": "Random-effects models for longitudinal data",
      "authors": [
        "N Laird",
        "J Ware"
      ],
      "year": 1982,
      "doi": "10.2307/2529876"
    },
    {
      "title": "Longitudinal data analysis using generalized linear models",
      "authors": [
        "K Liang",
        "S Zeger"
      ],
      "year": 1986,
      "doi": "10.1093/biomet/73.1.13"
    },
    {
      "title": "Analysis of longitudinal data",
      "authors": [
        "P Diggle",
        "P Heagerty",
        "K Liang",
        "S Zeger"
      ],
      "year": 2002,
      "doi": "10.1093/oso/9780198524847.001.0001"
    },
    {
      "title": "Selected statistical issues in group randomized trials",
      "authors": [
        "Z Feng",
        "P Diehr",
        "A Peterson"
      ],
      "year": 2001,
      "doi": "10.1146/annurev.publhealth.22.1.167"
    },
    {
      "title": "Cluster randomized crossover trials: aspects of power, variance, and bias in the stepped wedge design",
      "authors": [
        "M Hussey"
      ],
      "year": 2005,
      "doi": "10.1016/j.cct.2006.05.007"
    },
    {
      "title": "054: a cluster randomized crossover trial to evaluate combined access to nevirapine in developing countries",
      "authors": [
        "J Hughes",
        "R Goldenberg",
        "C Wilfert"
      ],
      "year": 2003
    },
    {
      "title": "Mixed-effects models in S and S-PLUS",
      "authors": [
        "J Pinheiro",
        "D Bates"
      ],
      "year": 2000,
      "doi": "10.1007/978-1-4419-0318-1"
    },
    {
      "title": "Regression analysis of correlated binary data: some small sample results for the estimating equation approach",
      "authors": [
        "K Sharples",
        "N Breslow"
      ],
      "year": 1992,
      "doi": "10.1080/00949659208811406"
    },
    {
      "title": "Approximate inference in generalized linear mixed models",
      "authors": [
        "N Breslow",
        "D Clayton"
      ],
      "year": 1993,
      "doi": "10.1080/01621459.1993.10594284"
    }
  ],
  "num_references": 24,
  "original_doi": "https://doi.org/10.13039/100000002"
}
