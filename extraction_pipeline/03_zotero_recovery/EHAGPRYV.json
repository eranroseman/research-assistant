{
  "paper_id": "EHAGPRYV",
  "title": "Automated Detection of Cognitive Distortions in Text Exchanges Between Clinicians and People With Serious Mental Illness",
  "year": 2020,
  "date": "2020-10-15",
  "journal": "JMIR Ment Health",
  "publication": "JMIR Ment Health",
  "authors": [
    {
      "forename": "Justin",
      "surname": "Tauscher",
      "name": "Justin Tauscher"
    },
    {
      "forename": "Kevin",
      "surname": "Lybarger",
      "name": "Kevin Lybarger"
    },
    {
      "forename": "Xiruo",
      "surname": "Ding",
      "name": "Xiruo Ding"
    },
    {
      "forename": "Ayesha",
      "surname": "Chander",
      "name": "Ayesha Chander"
    },
    {
      "forename": "M",
      "surname": "Res",
      "name": "M Res"
    },
    {
      "forename": "William",
      "surname": "Hudenko",
      "name": "William Hudenko"
    },
    {
      "forename": "Trevor",
      "surname": "Cohen",
      "name": "Trevor Cohen"
    }
  ],
  "doi": "",
  "sections": [
    {
      "text": "Objective: The authors tested whether natural language processing (NLP) methods can detect and classify cognitive distortions in text messages between clinicians and people with serious mental illness as effectively as clinically trained human raters.\n\nMethods: Text messages (N57,354) were collected from 39 clients in a randomized controlled trial of a 12-week texting intervention. Clinical annotators labeled messages for common cognitive distortions: mental filtering, jumping to conclusions, catastrophizing, \"should\" statements, and overgeneralizing. Multiple NLP classification methods were applied to the same messages, and performance was compared.\n\nResults: A tuned model that used bidirectional encoder representations from transformers (F150.62) achieved performance comparable to that of clinical raters in classifying texts with any distortion (F150.63) and superior to that of other models.\n\nConclusions: NLP methods can be used to effectively detect and classify cognitive distortions in text exchanges, and they have the potential to inform scalable automated tools for clinical support during message-based care for people with serious mental illness.\n\nPsychiatric Services 2023; 74:407-410; doi: 10.1176/appi.ps.202100692\n\nMobile phone texting is gaining popularity as a promising method for delivering health care outside brick-and-mortar clinics  (1) . Texting may be particularly well suited for psychosocial interventions, in which language is the primary vehicle for administering treatment. Texting interventions have been deployed successfully among clients with a range of mental health conditions, including serious mental illness  (2) . People with serious mental illness in the United States have access to text-capable mobile phones at a level only slightly lower than that of the general population; in addition, surveys suggest that most people with serious mental illness actively use text messaging and are interested in textbased interventions  (3) . Recent research has demonstrated that augmentation of routine services with texting is feasible, acceptable, and clinically useful among people with serious mental illness  (4) .\n\nAlthough technology-mediated services are feasible, a lack of training and clinician expertise presents a barrier to their adoption for treatment of serious mental illness in community settings  (5) . Opportunities for training in technology-based services are limited, and providers adopting these technologies commonly express a need for increased support  (6) . When available, training and supervision in the use of novel interventions are resource intensive and may preclude adoption of texting interventions  (7) . New methods to monitor and support clinicians who offer services via texting are needed to encourage consistent intervention delivery, reduce human resource requirements, and allow more patients to receive care via this modality."
    },
    {
      "title": "HIGHLIGHTS",
      "text": "\u2022 This is the first study to apply natural language processing to text messages between people with serious mental illness and their clinicians, with the goal of identifying cognitive distortions.\n\n\u2022 Findings indicate that a fine-tuned model that used bidirectional encoder representations from transformers achieved performance comparable to that of clinically trained human raters on the task of cognitive distortion identification.\n\n\u2022 Results from this study can inform automated tools for clinical support during message-based care for people with serious mental illness.\n\nPsychiatric Services 74:4, April 2023 ps.psychiatryonline.org 407"
    },
    {
      "title": "BRIEF REPORT",
      "text": "Natural language processing (NLP) is the computational analysis of human language and may augment delivery of text-based care. NLP has shown promise for identifying cognitive distortions expressed by individuals receiving support for mood disorders  (8, 9) . Cognitive distortions are systematic errors in thinking that affect how individuals make sense of the world  (10) . Among people with serious mental illness, distortions exacerbate negative effects of psychiatric symptoms  (11, 12) . To identify and restructure these distortions is an important goal of cognitive-behavioral therapy (CBT). Access to and engagement in high-fidelity CBT interventions that ameliorate distortions are limited for individuals with serious mental illness  (13) . Training clinicians to provide high-quality CBT via text messaging can help alleviate this issue and successfully augment in-clinic services  (2, 4) . Automated methods for proactively flagging distortions in text-based interactions may assist clinicians who provide CBT in reducing distortion-related psychiatric symptoms.\n\nWe are not aware of previous work that has applied NLP methods to text-based interactions between clinicians and clients receiving treatment for serious mental illness. However, prior work that used machine learning methods to identify distortions in data from other populations informed our study. Shickel et al. (  8 ) identified cognitive distortions in journal entries from college students with a self-guided online intervention and in crowdsourced samples from participants who were prompted to provide examples of distortions. Shreevastav and Foltz (9) explored identification of cognitive distortions in publicly available therapist question-and-answer transcripts. Whether NLP can be applied to text-based client-clinician interactions and successfully detect cognitive distortions is an open research question.\n\nThe purpose of this study was to test whether NLP techniques can automatically identify distortions in textmessage exchanges between clients with serious mental illness and their therapists at a similar level to that of trained clinicians. We hypothesized that a fine-tuned NLP classifier would be able to identify distortions with a level of precision and recall, operationalized as an F1 score (range50-1, where higher scores indicate better precision and recall), that is comparable to that of trained clinician annotators."
    },
    {
      "title": "METHODS",
      "text": "Data were collected from 39 clients enrolled in the active intervention arm of a randomized controlled trial between December 2017 and October 2019. Seven clinicians from mental health agencies in the Midwest and Pacific Northwest provided the texting intervention. Clients who contributed data to the current analysis had diagnoses of schizophrenia, schizoaffective disorder, major depressive disorder, or bipolar disorder. Most were male (N522, 56%), with a mean6SD age of 45.4611.1 years, a mean of 12.862.4 years of education, and a mean of 2.863.4 lifetime psychiatric hospitalizations. A full description of the trial, including intervention feasibility, acceptability, engagement, and clinical outcomes, was recently published in Psychiatric Services (4). The study was approved by the University of Washington's Institutional Review Board, and clients provided informed consent. As part of the study, clients participating in standard care engaged with trained clinicians in back-and-forth text-message conversations for 12 weeks. In total, 14,312 messages were sent, with 7,354 coming from clients (mean6SD5188.66226.4 messages per client). Clients had variable levels of engagement, with the average number of client messages ranging from 0.3 to 12.5 messages per day. All data were stored on a secure server, and client and clinician identifiers were removed before annotation and analysis.\n\nWe created a data set of text messages annotated for five common cognitive distortion types: mental filtering, jumping to conclusions, catastrophizing, should statements, and overgeneralizing  (14) . To do this, we selected distortion types noted to play a role in psychosis (e.g., jumping to conclusions) and those used in previous automated classification studies  (8, 9, 11) . Next, we developed an annotation guide that provides definitions and examples of these distortions to facilitate labeling of text messages by two clinically trained annotators  (15) . One annotator holds a psychology master's degree (A.C.), and the other is a doctoral-level licensed clinical mental health counselor (J.S.T.). The annotators labeled client text messages as representing any of the five distortion types or as no distortion (see the online supplement to this report for definitions and examples). Multiple labels were assigned to messages when more than one distortion type was present. Annotators were trained to use the annotation guide and practiced coding transcripts that contained all messages from three randomly selected clients. Interrater discrepancies were discussed, code definitions were refined, and agreement was reached about how to apply codes. Annotators then coded messages from a sample of 23% (N59) of clients (2,318 messages) and reached a moderate level of agreement (Cohen's k50.51), a level comparable with previous work that used human annotation of cognitive distortion  (8) . All remaining transcripts were then equally divided between annotators for coding.\n\nWe created three NLP distortion classification models for comparison with human rater performance. he first model used bidirectional encoder representations from transformers (BERT)  (16) . BERT allows for pretraining on large quantities of unlabeled text and fine-tuning model parameters to specific classification tasks. BERT fine-tuning is an effective transfer learning strategy that has achieved state-of-the-art performance in many classification tasks and domains  (17) . Because BERT has not been previously used for identifying cognitive distortions, we also included the two bestperforming models from prior cognitive distortion work with which to compare our BERT model: logistic regression with term frequency-inverse document frequency features (LR) and support vector machines with input features generated by sentence-BERT without fine-tuning (SVM)  (8, 9) . Using the NLP models, we classified the five cognitive distortions and an \"any distortion\" label, indicating whether one or more of the five cognitive distortions were present, as a multilabel binary classification task.\n\nModels were evaluated with a nested cross-validation procedure  (18) . We randomly split the annotated data set into five folds (1, 2, . . . 5). These folds were used to split data into train (D train ), validation (D val ), and test (D test ) sets. There was no overlap between the messages in the train and test sets; however, a given client could appear in both the training and test sets. We tuned hyperparameters by using D train , and we evaluated D val by using splits of the data. After hyperparameters were tuned, final model performance was assessed by combining D train and D val splits to train a final model to evaluate performance on the previously unused D test split. As a form of repeated holdout testing, we iterated over folds assigned to D train , D val , and D test , retuning the hyperparameters for each iteration. For example, fold assignments for iteration 1 were D train 5{1, 2, 3}, D val 5{4}, D test 5{5}; fold assignments for iteration 2 were D train 5{2, 3, 4}, D val 5{5}, D test 5{1}; and fold assignments for iteration 5 were D train 5{5, 1, 2}, D val 5 {3}, D test 5{4}. We assessed performance of aggregated D test predictions with F1 scores and receiver operating characteristic (ROC) area under the curve (AUC) values. Hyperparameters were optimized to maximize average F1 (macro F1) score across the six binary targets. The F1 score is a standard performance metric in NLP evaluation, and it is calculated by combining precision and recall into a mean score. The selected model configurations are summarized in the online supplement.\n\nWe used the Shapley additive explanations (SHAP) package to identify portions of client messages that most influenced classification decisions and to demonstrate the interpretability of the BERT model  (19) . The online supplement provides examples of SHAP plots for each cognitive distortion type, in which each word is evaluated for its impact on the model output."
    },
    {
      "title": "RESULTS",
      "text": "Frequencies of distortions identified by human annotators and by the NLP models are presented in Table  1 . The mean distortion frequency (any distortion type) per client was 48.56106.1. Table  1  presents clinical rater and NLP model performances for identifying cognitive distortions. BERT outperformed LR and SVM for all distortion labels. The performance of BERT was comparable to that of clinical raters for any distortion, mental filtering, jumping to conclusions, and catastrophizing, indicating that the BERT framework (with pretraining) is a good fit for this task. BERT performed less well, relative to clinical raters, when identifying should statements and overgeneralizing. Our fine-tuned BERT model achieved an AUC of 0.83 (see online supplement for ROC curve) for the any distortion label."
    },
    {
      "title": "DISCUSSION",
      "text": "This study demonstrated that NLP models can identify cognitive distortions in text messages between people with serious mental illness and clinicians at a level comparable to that of clinically trained raters. Our BERT implementation outperformed previously published NLP methods for detecting cognitive distortions in text. BERT's performance in this task is attributable to the transfer learning paradigm, in which a rich representation of language is learned from unlabeled text (pretraining) and then adapted to the target task (fine-tuning). Our work extends previous research on detection of cognitive distortions by confirming that detecting distortions in text messages during text-based care for people with serious mental illness is possible.\n\nA key strength of this study is that data came from realworld communications between clients and clinicians that focused on management of symptoms of serious mental illness. There were no prompts to elicit distortions in these interactions, which allowed our classification model to be trained on the natural language used by clients as they typically communicate. This study is limited by size (number of clients, therapists, and messages). Although the study's BERT model was able to demonstrate strong binary classification of the any distortion label and the most commonly occurring distortions, all NLP models were not as successful in identifying distortion types with fewer instances in the data set. Similar to prior cognitive distortion work, classification performance was limited by the challenge of manually annotating distortions  (8) .\n\nAdditional work with an expanded data set is needed to assess generalizability to a diverse client population,"
    },
    {
      "text": "Frequencies of distortions identified by human annotators and by the NLP models, with interannotator agreement and model prediction performance a NLP performance for LR, SVM, and BERT represents the average F1 score, a weighted average of precision and recall. The F1 score has a range of 0 to 1, where higher scores represent better precision and recall. c BERT was not fine-tuned to the cognitive distortion task. d BERT was fine-tuned to the cognitive distortion task. Psychiatric Services 74:4, April 2023 ps.psychiatryonline.org 409 including clients not represented in the training data and clients engaged in other text-based messaging interventions. Incorporating previously sent messages may also prove beneficial to model performance by ensuring that predictions are grounded in the context of entire conversations. CONCLUSIONS Recent advancements in mobile phone-based mental health interventions, combined with advancements in computational methods of language analysis, have created new possibilities for developing technology-assisted interventions. NLP-based methods from this study show promise for supporting clinicians in future delivery of text-message interventions for people with serious mental illness. By applying NLP classification methodologies to clinical textmessage interactions, it may be possible to proactively prompt clinicians' actions, enhancing their ability to deliver effective, timely interventions."
    }
  ],
  "references": [
    {
      "title": "Mental Health Apps Draw Wave of New Users as Experts Call for More Oversight",
      "authors": [
        "K Herzog"
      ],
      "year": 2020
    },
    {
      "title": "The use of text messaging to improve clinical engagement for individuals with psychosis: systematic review",
      "authors": [
        "J D'arcey",
        "J Collaton",
        "N Kozloff"
      ],
      "year": 2020,
      "doi": "10.2196/16993"
    },
    {
      "title": "Mobile phone and smartphone use by people with serious mental illness",
      "authors": [
        "A Young",
        "A Cohen",
        "N Niv"
      ],
      "year": 2020,
      "doi": "10.1176/appi.ps.201900203"
    },
    {
      "title": "Augmenting evidence-based care with a texting mobile interventionist: a pilot randomized controlled trial",
      "authors": [
        "D Ben-Zeev",
        "B Buck",
        "S Meller"
      ],
      "year": 2020,
      "doi": "10.1176/appi.ps.202000239"
    },
    {
      "title": "Identifying and addressing mental health providers' perceived barriers to clinical video telehealth utilization",
      "authors": [
        "K Perry",
        "S Gold",
        "E Shearer"
      ],
      "year": 2020,
      "doi": "10.1002/jclp.22770"
    },
    {
      "title": "Opportunities for and tensions surrounding the use of technology-enabled mental health services in community mental health care",
      "authors": [
        "E Lattie",
        "J Nicholas",
        "A Knapp"
      ],
      "year": 2020,
      "doi": "10.1007/s10488-019-00979-2"
    },
    {
      "title": "Assessing competence in the use of motivational interviewing",
      "authors": [
        "T Moyers",
        "T Martin",
        "J Manuel"
      ],
      "year": 2005,
      "doi": "10.1016/j.jsat.2004.11.001"
    },
    {
      "title": "Automatic detection and classification of cognitive distortions in mental health text",
      "authors": [
        "B Shickel",
        "S Siegel",
        "M Heesacker"
      ],
      "year": 2020,
      "doi": "10.1109/bibe50027.2020.00052"
    },
    {
      "title": "Detecting cognitive distortions from patient-therapist interactions",
      "authors": [
        "S Shreevastava",
        "P Foltz"
      ],
      "year": 2021,
      "doi": "10.18653/v1/2021.clpsych-1.17"
    },
    {
      "title": "Thinking and depression: idiosyncratic content and cognitive distortions",
      "authors": [
        "A Beck"
      ],
      "year": 1963,
      "doi": "10.1001/archpsyc.1963.01720160014002"
    },
    {
      "title": "Psychosis, delusions and the \"jumping to conclusions\" reasoning bias: a systematic review and meta-analysis",
      "authors": [
        "R Dudley",
        "P Taylor",
        "S Wickham"
      ],
      "year": 2016,
      "doi": "10.1093/schbul/sbv150"
    },
    {
      "title": "Efficacy of psychological interventions targeting cognitive biases in schizophrenia: a systematic review and meta-analysis",
      "authors": [
        "G Sauv\u00e9",
        "K Lavigne",
        "G Pochiet"
      ],
      "year": 2020,
      "doi": "10.1016/j.cpr.2020.101854"
    },
    {
      "title": "Unmet need for mental health care in schizophrenia: an overview of literature and new data from a first-admission study",
      "authors": [
        "R Mojtabai",
        "L Fochtmann",
        "S Chang"
      ],
      "year": 2009,
      "doi": "10.1093/schbul/sbp045"
    },
    {
      "title": "Feeling Good: The New Mood Therapy",
      "authors": [
        "D Burns"
      ],
      "year": 1999
    },
    {
      "title": "Clinical Corpus Annotation: Challenges and Strategies",
      "authors": [
        "F Xia",
        "M Yetisgen-Yildiz"
      ],
      "year": 2012
    },
    {
      "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M Chang",
        "K Lee"
      ],
      "year": 2019,
      "doi": "10.18653/v1/n18-2"
    },
    {
      "title": "Deep Learning Based Text Classification: A Comprehensive Review",
      "authors": [
        "S Minaee",
        "N Kalchbrenner",
        "E Cambria"
      ],
      "year": 2020,
      "doi": "10.1145/3439726"
    },
    {
      "title": "Bias in error estimation when using crossvalidation for model selection",
      "authors": [
        "S Varma",
        "R Simon"
      ],
      "year": 2006,
      "doi": "10.1186/1471-2105-7-91"
    },
    {
      "title": "A unified approach to interpreting model predictions",
      "authors": [
        "S Lundberg",
        "S Lee"
      ],
      "year": 2017
    }
  ],
  "num_references": 19,
  "original_doi": "https://doi.org/10.13039/100015351"
}
