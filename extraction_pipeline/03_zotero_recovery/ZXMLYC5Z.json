{
  "paper_id": "ZXMLYC5Z",
  "title": "Associations Between Ecological Momentary Assessment and Passive Sensor Data in a Large Student Sample",
  "abstract": "Ecological momentary assessment (EMA) increases ecological validity but can be burdensome. To reduce this burden and to better understand psychological constructs in daily life, a growing chorus of voices has called for augmenting or replacing EMA data with data passively collected from wearable devices. It is thus critical to investigate the quality of wearable data and its overlap with typical self-report measures. Here we compared results from passive sensing and EMA data from a project to build a warning system for depression in students (WARN-D) in a large sample of 781 students. For 3 months, participants wore a Garmin VivoSmart 4 watch and answered EMA surveys (up to 352 observations). We investigated whether and to what extent passive sensor metrics were concurrently associated with different self-report measures purportedly measuring the same constructs. We focused on stress, tiredness, and sleep, all of which have transdiagnostic relevance to mental health and can arguably be assessed with self-report and physiological measures. We used longitudinal mixed-effects models to estimate average momentary associations and their interindividual heterogeneity. Self-report and wearable measures of sleep-related variables showed robust associations, while associations were weaker for tiredness, and measures of stress did not overlap for most individuals. These findings suggest that wearable data and their corresponding self-report measures may not necessarily measure similar constructs. We provide several explanations for this result, including semantic differences and measurement issues, and offer insights and ways forward for mental health research combining wearable and self-report data. \n General Scientific Summary We investigated the concurrent overlap between self-report and wearable sensor data measuring stress, tiredness, and sleep. For the majority of individuals in our sample, we found that self-report and physiological measures of stress show very weak to no associations. These results raise several questions about differences between data sources and potential measurement issues.",
  "year": 2017,
  "date": "2017",
  "journal": "Journal of Psychiatric Research",
  "publication": "Journal of Psychiatric Research",
  "authors": [
    {
      "forename": "Bj\u00f6rn",
      "surname": "Siepe",
      "name": "Bj\u00f6rn Siepe",
      "affiliation": "1  Psychological Methods Laboratory , Department of Psychology , University of Marburg \n\t\t\t\t\t\t\t\t Department of Psychology \n\t\t\t\t\t\t\t\t Psychological Methods Laboratory \n\t\t\t\t\t\t\t\t University of Marburg",
      "email": "bjoern.siepe@uni-marburg.de"
    },
    {
      "forename": "Rayyan",
      "surname": "Tutunji",
      "name": "Rayyan Tutunji",
      "affiliation": "2  Department of Clinical Psychology , Leiden University Psychological Methods Laboratory , Department of Psychology , University of Marburg , Gutenbergstra\u00dfe 18 , 35037 Marburg , Germany. \n\t\t\t\t\t\t\t\t Department of Clinical Psychology \n\t\t\t\t\t\t\t\t Department of Psychology \n\t\t\t\t\t\t\t\t Psychological Methods Laboratory \n\t\t\t\t\t\t\t\t Leiden University \n\t\t\t\t\t\t\t\t University of Marburg \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Gutenbergstra\u00dfe 18 \n\t\t\t\t\t\t\t\t\t 35037 \n\t\t\t\t\t\t\t\t\t Marburg \n\t\t\t\t\t\t\t\t\t Germany"
    },
    {
      "forename": "Carlotta",
      "surname": "Rieble",
      "name": "Carlotta Rieble",
      "affiliation": "2  Department of Clinical Psychology , Leiden University Psychological Methods Laboratory , Department of Psychology , University of Marburg , Gutenbergstra\u00dfe 18 , 35037 Marburg , Germany. \n\t\t\t\t\t\t\t\t Department of Clinical Psychology \n\t\t\t\t\t\t\t\t Department of Psychology \n\t\t\t\t\t\t\t\t Psychological Methods Laboratory \n\t\t\t\t\t\t\t\t Leiden University \n\t\t\t\t\t\t\t\t University of Marburg \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Gutenbergstra\u00dfe 18 \n\t\t\t\t\t\t\t\t\t 35037 \n\t\t\t\t\t\t\t\t\t Marburg \n\t\t\t\t\t\t\t\t\t Germany"
    },
    {
      "forename": "Ricarda",
      "surname": "Proppert",
      "name": "Ricarda Proppert",
      "affiliation": "2  Department of Clinical Psychology , Leiden University Psychological Methods Laboratory , Department of Psychology , University of Marburg , Gutenbergstra\u00dfe 18 , 35037 Marburg , Germany. \n\t\t\t\t\t\t\t\t Department of Clinical Psychology \n\t\t\t\t\t\t\t\t Department of Psychology \n\t\t\t\t\t\t\t\t Psychological Methods Laboratory \n\t\t\t\t\t\t\t\t Leiden University \n\t\t\t\t\t\t\t\t University of Marburg \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Gutenbergstra\u00dfe 18 \n\t\t\t\t\t\t\t\t\t 35037 \n\t\t\t\t\t\t\t\t\t Marburg \n\t\t\t\t\t\t\t\t\t Germany"
    },
    {
      "forename": "Eiko",
      "surname": "Fried",
      "name": "Eiko Fried",
      "affiliation": "2  Department of Clinical Psychology , Leiden University Psychological Methods Laboratory , Department of Psychology , University of Marburg , Gutenbergstra\u00dfe 18 , 35037 Marburg , Germany. \n\t\t\t\t\t\t\t\t Department of Clinical Psychology \n\t\t\t\t\t\t\t\t Department of Psychology \n\t\t\t\t\t\t\t\t Psychological Methods Laboratory \n\t\t\t\t\t\t\t\t Leiden University \n\t\t\t\t\t\t\t\t University of Marburg \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Gutenbergstra\u00dfe 18 \n\t\t\t\t\t\t\t\t\t 35037 \n\t\t\t\t\t\t\t\t\t Marburg \n\t\t\t\t\t\t\t\t\t Germany"
    },
    {
      "forename": "Daniel",
      "surname": "Fulford",
      "name": "Daniel Fulford"
    }
  ],
  "doi": "",
  "keywords": [
    "ecological momentary assessment",
    "digital phenotyping",
    "passive sensors",
    "measurement",
    "stress Collecting"
  ],
  "sections": [
    {
      "text": "times per day, can be burdensome for participants. Data collected via passive sensors are increasingly being used to augment or to replace self-report data and to reduce participant burden  (Velozo et al., 2024) .\n\nHere we use a large, multimodal student dataset to answer the question to which degree self-report and sensor data derived from wearable devices assessing similar constructs such as stress are correlated. Such work is important because other fields have recently demonstrated that the assumption that different methods reliably assess the same construct is often not met. For example, self-report and taskbased measures of different constructs such as self-control have shown to be very weakly correlated  (Dang et al., 2020) , and there are considerable discrepancies between self-reported and logged measures of digital media use  (Parry et al., 2021) . In the remainder of the Introductory part, we introduce passive sensor data, outline its relevance for psychopathology research, provide a brief overview of the literature on the validity of passive sensing research, and then conclude with a summary of the present study."
    },
    {
      "title": "Passive Sensing",
      "text": "Digital phenotyping, that is, data collected from passive sensors, is seen as very promising in mental health science  (Adams et al., 2017; Ebner-Priemer & Santangelo, 2020; Huckvale et al., 2019; Insel, 2018) . This broad term includes physiological data collected from wearable devices such as smartwatches and other passive sensing data such as location or communication data collected via smartphones (see  Mohr et al., 2017, for an overview) . In this article, we focus on data from wearable smartwatches while occasionally referring to the broader digital phenotyping literature.\n\nDue to the high temporal resolution of such data, large amounts of data can easily be collected per individual  (Onnela, 2021) , enabling more scalable forms of assessment  (Velozo et al., 2024) . Another hope is that digital measures will provide more \"objective\" assessments of constructs for which self-report measures may be biased or flawed  (Insel, 2018) . The continuous monitoring of individuals may open the door to personalized early interventions and thereby decrease existing barriers to treatments  (Huckvale et al., 2019) . Besides being a useful resource for researchers, people with mental health problems can also use passive sensor data for self-monitoring  (Nadal et al., 2021) . Commercial-grade devices that are practical to wear in everyday life play a crucial role in this regard. It has also been argued that digital phenotyping may be particularly useful for transdiagnostic research  (Ringwald et al., 2025) , as passive markers might relate to various symptoms across disorders. The extent to which digital phenotyping can deliver on these promises depends critically on many factors such as the quality of the data and the extent to which psychological and physiological measures are associated with one another.\n\nIn this article, we will, therefore, investigate three constructs that are highly relevant to mental health. We assess the overlap between self-report and wearable measures of stress, tiredness, and sleep, which can arguably all be measured with both sensors and selfreport. We now describe the transdiagnostic relevance of these variables and summarize their use in the digital phenotyping literature."
    },
    {
      "title": "Stress, Sleep, and Tiredness as Transdiagnostic Markers",
      "text": "There is a long line of research into stressful life events and chronic stress and their relationship with disorders such as major depression (see, e.g.,  Hammen, 2005)  or substance use disorders  (Sinha, 2001) . Daily stressors and their relations to maladaptive traits have also been investigated in research on personality pathology  (Vize et al., 2024) . In the digital phenotyping literature, several studies have focused on predicting stress from passive sensing data in specific populations such as college students (see, e.g.,  Adler et al., 2022) , whose academic stressors may increase their risk to develop mental illness  (Auerbach et al., 2016) .\n\nSleep problems are among the most common symptoms in the Diagnostic and Statistical Manual of Mental Disorders, fifth edition, (DSM-5), and also a robust contributor to psychopathology  (Forbes et al., 2024; Freeman et al., 2020) . Therefore, disturbances of sleep are widely considered a useful transdiagnostic marker for many psychiatric diagnoses  (Baglioni et al., 2016; Harvey et al., 2011) , and it is no surprise that sleep was the most commonly investigated passive variable in a review of the depression literature  (De Angel et al., 2022) . In a transdiagnostic study on digital markers of psychopathology, the sleep-related variable \"later bedtime\" was robustly associated with a summary of psychopathology domains  (Ringwald et al., 2025) .\n\nTiredness or fatigue is conceptually related to sleep problems and can be an indicator thereof  (Coulombe et al., 2010; Shochat et al., 2014) . Fatigue has long been discussed as a common thread in the intertwined nature of psychopathology and medical diagnoses  (Berrios, 1990 ). Due to its potential intraday fluctuations, tiredness is useful for experience sampling studies and has, for example, been used to investigate the interplay of sleep and affect  (Mill et al., 2016; Triantafillou et al., 2019) . Conceptually, low-arousal affect items such as feeling tired have a clear connection to depressive symptoms  (Price et al., 2023) . In digital phenotyping studies, the prediction of tiredness and fatigue with passive sensing has been studied in specific clinical populations  (Rao et al., 2023) .\n\nOverall, we believe that these three constructs present a good starting point to investigate relations between self-report and passive sensing measurement modalities, because they are common in mental health problems, have shown to be transdiagnostically useful, and are relevant to studying various forms of psychopathology in daily life."
    },
    {
      "title": "Challenges in the Digital Phenotyping Literature",
      "text": "To date, much of the literature has focused on using digital phenotyping data for predictive purposes across a wide range of psychological and psychiatric constructs (see  Bufano et al., 2023; Melcher et al., 2020; Mohr et al., 2017 , for some example reviews in mental health). However, the literature is still at too early a stage to obtain a comprehensive overview of measurement issues and draw an overall conclusion about the utility of digital phenotyping for predicting constructs related to psychopathology. While there are some promising and interesting early results (see, e.g.,  Mohr et al., 2017; Smets et al., 2018) , some disappointing results have dampened some of the initial enthusiasm  (Ebner-Priemer & Santangelo, 2020)  and the literature is generally characterized by many small sample studies (see, e.g.,  De Angel et al., 2022, for depression) . We also suspect that, similar to other areas of research, larger samples and preregistered studies will lead to nonreplication of some promising early results (see  Tackett et al., 2017 , for an overview and discussion of this topic for clinical psychology). The emphasis on predictive models, often in the form of complex machine-learning pipelines with limited interpretability, further complicates understanding the relationship between specific passive and self-report measures  (De Angel et al., 2022) . Conversely, the interpretability of predictive models will also benefit from a better understanding of the underlying passive sensing variables. In either case, to make progress in this field, a better understanding of how passive sensor measures relate to traditional self-report measures or clinical ratings-in other words, construct validation in the broadest sense-is crucial  (Davidson, 2022; Langener, Siepe, et al., 2024; Strauss et al., 2022) . This is also our core goal in the present article.\n\nThere are several approaches to providing evidence of construct validity for passive sensors. One approach is to validate measures captured by sensors against existing gold-standard laboratory devices (see  Nelson et al., 2020; Velozo et al., 2024,  for some examples). For example, wearables measuring stress-related arousal have been able to capture similar information to gold-standard laboratory-based psychophysiology measures, with some limitations  (van Lier et al., 2020) . Another approach is to validate measures against self-report data, such as social media use  (Mahalingham et al., 2023) , drug use  (Bertz et al., 2018) , sleep duration  (Lauderdale et al., 2008) , and physical activity  (Prince et al., 2008) . foot_1 These latter studies tend to conclude that selfreport measures of some behavioral or physiological constructs are often imperfect and biased. We believe this is a reasonable conclusion for well-defined and narrow constructs for which valid and reliable laboratory devices exist.\n\nHowever, there are reasons to believe that the discrepancy between more objective and self-report data is not always solely due to measurement issues on the side of self-report  (Das Swain et al., 2022) . For example, the lack of alignment between digital media use and logging data is in part due to poor self-report, but may also arise due to sources of bias on the side of logging  (J\u00fcrgens et al., 2020) . Reviews on digital phenotyping in social media use  (Chancellor & De Choudhury, 2020)  and the social environment  (Langener et al., 2023)  have found a lack of explicit validation and theoretic rationale for the use of passive sensor measures for certain psychological constructs, such as using global positioning system (GPS) and accelerometer data as indicators of social interactions  (Langener et al., 2023) . Conceptually, broad constructs such as stress can subsume various physiological and psychological facets, for which self-report and sensor data might be differentially useful  (Das Swain et al., 2022) . Generally, the more complex the construct to be interrogated, the more difficult validation efforts become, especially when attempting to measure constructs encompassing various psychological and physiological facets, such as many constructs in mental health research  (Tutunji, Kogias, et al., 2023) .\n\nA complicating feature in obtaining validity evidence for digital phenotyping methods is directly related to one of their greatest strengths: they produce large amounts of data, which poses several challenges in data analysis  (Langener, Stulp, et al., 2024; Onnela, 2021) . Researchers must decide on a variety of potential preprocessing and aggregation steps needed to make the temporal resolution of sensor data compatible with self-reported data. In the absence of strong theoretical guidance on the best decisions, this range of possibilities leads to many degrees of freedom for the researcher, which can have a large potential impact on the conclusions of a study. For example,  Niemeijer et al. (2022)  have shown the importance of different preprocessing and modeling choices on the performance of sensor measures for predicting subjective sleep quality. Other work shows that different temporal resolutions for aggregating passive sensor measures collected via smartphones led to different substantive conclusions and predictive model performance  (Langener, Stulp, et al., 2024) . These results suggest that studies investigating the overlap between self-report and passive sensor data should consider plausible alternative pathways in the analysis pipeline."
    },
    {
      "title": "The Present Study",
      "text": "In this study, we investigated whether and to what extent wearable sensor metrics are concurrently associated with self-report measures of the same construct. Specifically, we assessed the overlap between self-report and wearable measures of stress, tiredness, and sleep in a large sample of students over several months. This serves to improve our understanding of the extent to which these transdiagnostically relevant constructs can be assessed using passive sensors. Methodologically, we adopted a multilevel modeling strategy of time-series data to investigate the interindividual heterogeneity of associations between self-report and sensor measures. To account for the wide range of plausible analytic choices, we complement our main analyses with a wide range of additional analyses, which are available-together with code and additional information-in our additional online materials ( https://osf.io/txgnq/ ; Siepe, Tutunji, et al., 2025) ."
    },
    {
      "title": "Method Transparency and Openness",
      "text": "We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study, and we follow the Journal Article Reporting Standards (JARS,  Appelbaum et al., 2018) . This study was not preregistered. Data collection for the project to build a warning system for depression in students (WARN-D) is ongoing and we want to avoid having different small parts of the data shared across many projects. We will therefore make data available (excluding potentially identifiable data) on the WARN-D project hub ( https://osf.io/frqdv/ ) when all data are collected, cleaned, and checked. We share the participant identifiers we used for this article in the additional online materials to make the article reproducible in the future. Data collection was approved by the Leiden University Research Ethics Committee (2021-09-06-E.I.FriedV2-3406). The project is funded by the European Research Council in the Horizon 2020 research and innovation program (Grant 949059).\n\nData were analyzed using the R programming language (Version 4.4.0, R Core Team, 2024). Our main analyses were conducted using nlme (Version 3.1-164,  Pinheiro et al., 2023) . For visualization, we mostly relied on ggplot2  (Wickham, 2016)  and ggdist  (Kay, 2024) . We created a reproducible environment for the project via renv (Version 1.0.7, Ushey & Wickham, 2024) . A list of all other packages used is provided in the additional online materials."
    },
    {
      "title": "Participants and Procedure",
      "text": "Data were collected as part of the WARN-D study which aims to build a personalized warning system for depression in highereducation students. To achieve this goal, 2,000 students were followed over multiple months. To be enrolled in data collection, participants had to be at least 18 years of age and be enrolled as students at a Dutch institution of higher education. All inclusion and exclusion criteria for the study can be found in  Fried et al. (2023) . Notably, participants were excluded when they displayed moderate to high levels of depression, mania, thought disorders, substance-use problems; were undergoing treatment for these mental health issues; experienced moderate to severe suicidal ideation; or indicated that they would find it stressful to see estimates of calories burned as displayed by the smartwatch. Data collection was divided into four cohorts with roughly 500 participants each. We used data from all cohorts but excluded participants who will be used as part of training/validation sets for future prediction projects (see the preregistration by  Tutunji, Proppert, et al., 2023) , leaving us with a final sample size of 1,193 participants. We used the maximum number of participants available to obtain the highest level of precision in our estimates.\n\nThe data collection procedure in WARN-D consists of a baseline, an 85-day daily monitoring/ecological momentary assessment (EMA) phase, and eight follow-up surveys. It is described in more detail by  Fried et al. (2023) . At the time of writing, all regular EMA data collection has finished while follow-up surveys are still ongoing. During EMA data collection, participants received four surveys per day over 85 days as well as a weekly survey on Sundays. Surveys were sent via the Ethica application on their personal smartphones. Additionally, they were provided with a Garmin VivoSmart 4 smartwatch which they were supposed to wear during the full 85-day period. Of the 1,193 participants, 80.64% identified as women, 16.08% identified as male, and 3.28% indicated another gender identity. The average age was 22.5 (SD = 3.94, range = [18, 61]). The majority (51.30%) of participants were of Dutch/Belgian/German nationality, 40.07% were of another European nationality, and the other 8.63% had a non-European nationality. foot_2"
    },
    {
      "title": "Measures",
      "text": "Our interest was to compare self-report and wearable data of stress, sleep, and tiredness."
    },
    {
      "title": "Self-Report Variables",
      "text": "Self-reported momentary stress was assessed four times daily with a single item: \"I feel stressed right now.\" Momentary tiredness was assessed with the question \"I feel tired right now.\" In the morning survey, participants could indicate their sleep quality with the item \"Last night, I slept well.\" All three variables were assessed on a 1-7 Likert scale, ranging from \"not at all\" to \"very much.\""
    },
    {
      "title": "Digital Phenotyping Data",
      "text": "Digital phenotyping data were collected using Garmin VivoSmart 4 smartwatches. The watch automatically tracked parameters such as heart rate, sleep, movement, activity, and stress. In the following, we will use the terms self-report stress, self-report sleep, and selfreport tiredness as well as sensor stress, sensor sleep, and sensor body battery to distinguish between self-report and wearable measures, respectively. The smartwatch provided various sleep indices per night. We chose total sleep duration (in seconds) as the sensor sleep measure, and converted it to sleep in hours. Note that a previous systematic review indicates that the Garmin watch may overestimate total sleep duration compared to polysomnography, often considered a gold standard for sleep assessment  (Schyvens et al., 2024) .\n\nThe smartwatch computed a stress score based on heart rate, heart rate variability, and activity measures. It was quantified continuously from 0 to 100, but Garmin provides four brackets of values for interpretation  (Garmin, 2024b ): 0-25 as resting state, 26-50 as low stress, 51-75 as medium stress, and 76-100 as high stress. The stress score was calculated based on a proprietary algorithm by Firstbeat Technologies  (Garmin, 2024b) . A white paper by the company (Firstbeat Technologies Ltd., 2014) provides some information on the underlying analysis, but the algorithm is not explained in sufficient detail to be reproducible. The smartwatch returned a stress score every 3 min and has been used before, for example, to predict change processes in psychotherapy  (Hehlmann et al., 2021) .\n\nThe smartwatch measure that may best capture the construct of being tired is the so-called \"body battery\" score calculated by the watch. It is supposed to measure the body's energy resources which are influenced by factors such as sleep, exercise, and stress  (Garmin, 2024a) . Similar to the stress score, it was calculated by taking into account heart rate (variability) and activity data and sampled every 3 min. It was also continuously scored from 0 to 100, but there are two main brackets for interpretation  (Garmin, 2024a ): 0-25 as a charging/parasympathetic state, and 26-100 as a tiring/sympathetic state. Underlying these brackets is the assumption that stressful experiences or a sympathetic state drain bodily resources. To the best of our knowledge, this sensor feature has not yet been validated in peer-reviewed research, although it is used as a feature by  Daniels et al. (2024) . We chose to include this feature as a potential passive marker of tiredness."
    },
    {
      "title": "Data Analysis"
    },
    {
      "title": "Preprocessing",
      "text": "As wearable data were assessed at a higher sampling frequency than the EMA data, the sensor data needed to be aggregated before analysis to match it to the concurrent EMA prompts. For this aggregation, we needed to choose (a) the summary measure for aggregation (e.g., the mean or the SD of passive sensor data such as stress), (b) the aggregation window (e.g., the time frame over which we aggregate, such as 15 or 240 min), and (c) the lag size relative to the EMA prompt (i.e., summarizing sensor data before, around, or after the EMA prompt).\n\nIn the absence of strong theoretical expectations, we chose the following procedure. As a summary measure, we selected the mean, although we also estimated models using the SD and the maximum (specifically, the 0.95 quantile of the data to avoid potential outlier effects) as a summary for stress and tiredness scores. As aggregation windows, we chose 15, 30, 60, 120, and 240 min. To align the sensor data with the EMA prompt, we aggregated the data in three distinct time frames (which we call \"lag\"): before the EMA prompt, around the time of the EMA prompt, and after the EMA prompt. For example, a combination of 30-min aggregation and a lag \"around\" the EMA data means that we calculated the mean of the sensor in the 15 min before and the 15 min after the EMA beep. All possible combinations of aggregation window and lag specification resulted in 5 \u00d7 3 = 15 data sets for analysis. We conducted all analyses on each of the individual data sets. We always chose the data set that is aggregated around the EMA beep with a 30-min aggregation window as the main analysis. We estimated the same model on all 15 data sets with different aggregation and lag specifications as sensitivity analyses for different temporal aggregation choices. We additionally provide further secondary analyses that are described in more detail below.\n\nAll negative sensor stress values, representing either the lack of enough data or that a participant was performing a physical activity, were removed and coded as missing data. Further handling of missing data is described below as part of our analysis pipeline."
    },
    {
      "title": "Main Analysis",
      "text": "We decided on a single main analysis for each of the outcomes based on recommendations in the methodological literature (such as  Hamaker & Muth\u00e9n, 2020; Myin-Germeys & Kuppens, 2022; Wang & Maxwell, 2015) , our theoretical expectations, and the properties of the data. For all main analyses, we estimated linear mixed effects models with random intercepts and random slopes with the nlme package in R. We deleted missing data points via listwise deletion during model fitting, within-person centered all nonfactorial predictor variables to separate between-person from within-person effects, and used restricted maximum likelihood estimation.\n\nWe specified relatively simple models without any covariates because we were interested in the overlap of different ways of assessment, and not in any predictive capacities when controlling for covariates. We excluded participants with ,25% of valid data points for all main analyses. While this cutoff is arbitrary, we chose it to retain as many participants as possible while still obtaining reasonably precise estimates of within-person associations. This left us with 730, 709, and 781 included participants for the stress, sleep, and tiredness analyses, respectively. For all variables, most excluded individuals lacked both sufficient EMA and sensor data, followed by insufficient sensor data. Only a few participants were excluded because of missing EMA data only. Additional information is available in the additional online materials.\n\nIn addition, we provide several secondary analyses in the additional online materials. We did not perform a full multiverse analysis in which we would cross each analysis decision in a fully factorial manner (see, e.g.,  Weermeijer et al., 2022) . Rather, we decided on the most appropriate alternative analyses for each target variable to keep computational effort reasonable and the results interpretable. A list of all secondary analyses is provided in Table  1 .\n\nAll multilevel models for the main analyses consisted of the following structure:\n\nwhere y it represents the sensor outcome y of individual i at time t. The value of the EMA predictor variable of individual i at time t is denoted as x it , where x i represents its within-person mean. We additionally grand-mean centered x i for ease of interpretation. d it denotes the value of an additional categorical predictor for the time of day, with the first prompt of the day serving as the reference category.\n\nWe added this predictor because we expected potential (small) intraday trends for stress and tiredness based on the results of a previous study using a subset of the present data  (Siepe, Rieble, et al., 2025) .\n\nThe fixed intercept is denoted as \u03b2 0 . The fixed slope of the withinperson centered response is denoted as \u03b2 1 and can be interpreted as the average within-person association. \u03b2 2 is the fixed slope of the person-specific mean and can be interpreted as the between-person association. \u03b2 3 contains the effects of the dummy-coded categorical predictor and can be interpreted as differences in the predicted outcome variable at different times of the day. All estimates represent conditional effects, that is, effects holding all other predictors constant. For brevity, we do not repeat this point in the Results section. The random effects are represented by u 0i and u 1i , which are the random intercepts and slopes of the within-person effect for individual i, respectively. Both random effects follow a normal distribution.\n\nThe residuals e ij are assumed to follow an autocorrelated structure with lag-1, for which we ignored potentially different time intervals between prompts.\n\nFor the main analysis of stress, we regressed mean sensor stress during the aggregation window on self-reported stress. For the tiredness main analysis, we regressed mean body battery during the aggregation window on self-reported tiredness. After initial problems with estimating the random effects covariance matrix, we divided the sensor outcome variable by 100 for both analyses to avoid large differences in the variance of the outcome and predictors. We report all estimates on the original scale below for ease of interpretation. For the sleep main analysis, we regressed sensor total sleep duration on self-reported sleep quality in the morning after. As we expected no persisting temporal trends across the course of the study, we performed no detrending and did not include a time-of-day variable, as sleep variables were only assessed at the first prompt of the day.\n\nTo better understand the size of an effect, we interpreted the size of the regression coefficient \u03b2 1 with respect to the scale of the outcome variable. As another form of interpretation, we calculated the standardized effects obtained by standardizing outcomes and predictors with the person-specific variance. Additionally, we estimated the marginal R 2 (only considering the variance of fixed effects) and the conditional R 2 (additionally considering the variance of random effects) based on the method by  Nakagawa et al. (2017)  as well as the root-mean-square error (RMSE) as implemented in the performance R package  (L\u00fcdecke et al., 2021)  as estimates of model performance. We used the best linear unbiased predictor estimates for individual random effects in combination with the fixed effects estimates to calculate and visualize personspecific associations between sensor and self-report data. Unless declared otherwise, we used the conventional error level of .05."
    },
    {
      "title": "Secondary Analyses",
      "text": "To save space, we report more detailed results of our secondary analyses and robustness checks for our main analyses in the additional online materials. For all outcomes, we also included interactions of\n\nNote. This table contains an overview of all secondary analyses available in the additional online materials along with a numerical index (e.g., S1) for easy retrieval. S1-S4 = secondary analyses 1-4.\n\nECOLOGICAL MOMENTARY ASSESSMENT SENSOR VALIDATION the main effect of interest (\u03b2 1 ) with age, gender, depression severity at baseline, and study cohort (from one to four). Due to the small sample size of individuals who did not identify as women or men, we did not include them in the estimation of the interaction effect and coded gender as binary.  3 These analyses help to understand whether the withinperson association between self-report and sensor variables differs based on demographic characteristics, depressive symptomatology, or the study cohort. We added the latter to investigate potential seasonal influences and changes in watch quality over time. Depression severity was assessed using an adapted version of the Patient Health Questionnaire-9 (PHQ-9;  Kroenke et al., 2001) , see  Fried et al. (2023)  for more information. We also estimated all models without an autocorrelated residual structure. For stress and sleep, we estimated additional models where we \"binned\" the sensor variables based on the categorization by Garmin provided above. This analysis helps to understand if the categorical understanding of stress and body battery values as put forth by Garmin leads to clearer associations with selfreport variables. For stress and tiredness, we also used the SD and the maximum value during the aggregation window as alternative operationalizations. Using, for example, the maximum of sensor stress values as an outcome could be meaningful if self-reported stress reflects the highest stress level around the EMA beep instead of an average."
    },
    {
      "title": "Results"
    },
    {
      "title": "Descriptives",
      "text": "As explained in the Method section, our data consists of 15 data sets with different lags and aggregation windows of wearable data, whereas the EMA data is identical across these data sets. We calculated person-specific summary statistics for each variable of interest in each data set. To provide a general overview of all data, we aggregated summary statistics across data sets for Table  2 . To summarize: we first calculate person-specific summaries, such as the mean or the standard deviation, for each variable in a data set. We then calculate the mean across individuals for each of these summaries, obtaining the average of person-specific summaries per variable per data set. We can then again average these across data sets.\n\nTo give insight into interindividual variability in summary statistics, Figure  1  contains distributions of person-specific means for the items used in the main analysis. Many individuals had a low mean of self-report stress and a relatively high self-report sleep quality. The person-specific averages of sensor stress and body battery are concentrated rather closely to the scale average of 50. Orienting ourselves at  Siepe, Rieble, et al. (2025) , we present additional descriptive statistics and item properties in the additional online materials."
    },
    {
      "title": "Analysis Results",
      "text": "Table  2  summarizes the main results, that is, regression estimates on the data set that aggregated sensor data in the 30-min window around the EMA prompt. Additionally, the person-specific estimates of the association between EMA and sensor variables are visualized in Figure  2 . These were obtained by adding the estimate of an individual random effect to the fixed effect. In the following, we round results to two decimals, unless values are small enough that the third decimal contains relevant information."
    },
    {
      "title": "Stress",
      "text": "As shown in the leftmost column of Table  3 , the overall withinperson association of self-report and sensor stress was positive, but rather small (\u03b2 1 = .49, 95% CI = [0.35, 0.63]). The standardized estimate for this relationship was 0.026 (95% CI = [0.019, 0.033]), which means that a one SD change in self-report stress corresponds to 0.026 SD change in sensor stress. The random slopes of the within-person effect had a SD of 1.29, implying considerable variability across people. This also means that the association was estimated to be negative for a substantial amount of individuals (see Figure  2 ).\n\nIn the sensitivity analyses of different temporal aggregation choices, we found the same general pattern of results, where \u03b2 1 ranged from .17 to .67 with a mean of .46 (SD = 0.13). See Figure  3  for the results of the sensitivity analyses.\n\nThe between-person component of self-report stress had a small positive association with sensor stress (\u03b2 2 = .56, 95% CI = [-0.02, 1.14]) that was not significant at an \u03b1 level of .05. If the effect were robust, this would mean that individuals with a higher average self-report stress also report higher levels of sensor stress. We additionally found a strong effect of the categorical predictor of time-of-day, showing that sensor stress was lowest for the morning prompt and considerably higher at later prompts of the day.\n\nWhile the conditional and marginal R 2 point estimates of .22 and .13 indicate some amount of explained variance of the overall model, this can largely be attributed to the effects of the time-of-day predictor. When omitting this predictor, conditional and marginal R 2 drop to .085 and .001, respectively. The RMSE was 21.66.\n\nThe same general result holds across our different secondary analyses. In secondary analysis S1, we found no significant associations between age, gender, or depression at baseline with the association between sensor and self-report stress. We found a significant effect of the study cohort, where participants in cohorts two and four showed slightly weaker associations between the sensor and selfreport measure. For the second cohort, the average effect was 0. Changing the autocorrelation structure in S2 had no meaningful impact on results. When binning the outcome into four stress levels as used by  Garmin (no, low, medium, and high stress)  for secondary analysis S3 within an ordinal regression model, we observed a weak relationship (but this is not straightforward to compare to our linear mixed effects models). In S4, using the standard deviation of the sensor stress led to even weaker associations with self-reported stress. Using the maximum sensor stress during the aggregation period as an outcome led to slightly stronger associations (mean within-person relationship across all 15 data sets of 0.59 compared to 0.46 in the main analysis). Full results are available in the additional online materials."
    },
    {
      "title": "Tiredness",
      "text": "We found a negative association between self-reported tiredness and sensor-based body battery in our main analysis (\u03b2 1 = -1.55, 95% CI = [-1.68, -1.42], see the middle column of Table  3 ). The relationship is negative as a higher sensor body battery is Note. Individuals excluded in the main analysis because of the amount of missing data are also excluded here. The boxplot displays the first and third quartile of the distribution as upper and lower hinges, and the median as a horizontal bar. The whiskers extend to 1.5 times the interquartile range. Dots represent individual means. See the online article for the color version of this figure. Note. This figure uses data from the data set aggregated in a 30-min window around the EMA beep. The densities represent the estimated distribution of person-specific estimates for the respective analysis. The person-specific estimates were obtained by adding the empirical Bayes estimate to the fixed effect. The black bars represent the mean (black dot), 66% (thick bar), and 95% (thin bar) of the distribution. These do not represent the intervals of statistical uncertainty, but rather a dispersion of person-specific point estimates. Note that the standard deviation of individual estimates is smaller than the estimated random effect standard deviation due to shrinkage. EMA = ecological momentary assessment. See the online article for the color version of this figure."
    },
    {
      "title": "ECOLOGICAL MOMENTARY ASSESSMENT SENSOR VALIDATION 7",
      "text": "This document is copyrighted by the American Psychological Association or one of its allied publishers.\n\nThis article is intended solely for the personal use of the individual user and is not to be disseminated broadly.\n\nassociated with lower tiredness. As the sensor measure was assessed on the same scale as the sensor stress measure, this indicates a stronger relationship between self-report and sensor measures of tiredness compared to stress. The standardized effect of this relationship was -0.082 (95% CI = [-0.087, -0.076]). Across the 15 different aggregation and lag types in our sensitivity analyses, we estimated a mean point estimate of \u03b2 1 of -1.47 (SD = 0.28). The specific point estimates with their 95% CIs for each aggregation window and lag size are provided in Figure  3 . There seems to be a tendency for associations to be the strongest when the sensor data are aggregated in a relatively long timeframe before the EMA prompt, and the weakest when sensor data are aggregated after the EMA prompt. We found a strong effect of the categorical predictor of time-of-day: body battery values were considerably lower at later times during the day. As indices of model fit, conditional and marginal R 2 values were estimated as .42 and .30 and-similar to the stress analyses-dropped considerably, to .20 and .05, without the inclusion of the time-of-day variable. The RMSE was 20.46. The association remained mostly stable across secondary analyses. In secondary analysis S1, we found a significant interaction effect of the within-person effect with age (point estimate 0.04, 95% CI = [0.007, 0.074]). The interaction with age, albeit significant, is too small to interpret. Participants in cohorts two and four had stronger average within-person associations of the self-report and sensor measure, with average effects being 40% larger compared to the first cohort. The interactions with gender and depression were not significant. Changing the residual correlation structure (S2) resulted in slightly higher within-person associations, but did not change the overall gist of the results. The binning of the outcome into the two categories provided by Garmin (\"parasympathetic\" and \"sympathetic,\" secondary analysis S3) resulted in a similarly modest association as our main analysis. Using alternative summary statistics of body battery during the aggregation window as the outcome (S4) led to considerably weaker (standard deviation as outcome) or roughly similar (maximum as outcome) results compared to the main analysis. Full results are again available in the additional online materials."
    },
    {
      "title": "Sleep",
      "text": "We found a small, positive association between self-reported sleep quality and sensor-based sleep duration in our main analysis (\u03b2 1 = .33, 95% CI = [0.31, 0.35], see the rightmost column of Note. Random intercept SD and random slope SD refer to the standard deviation of the random effects. Values in brackets below a point estimate denote the standard error. We do not report standard errors of variance components here, but their confidence intervals are available in the additional online materials. WP = within-person effect; BP = between-person effect; RMSE = root-mean-square error. ** p , .05. Note. This figure contains the point estimates of the within-person association of self-report with sensor data (in other words, \u03b2 1 ) across different lags and aggregation windows. For example, an aggregation of 120 min \"before\" means that the outcome of the regression was the mean of sensor data within the 2 hr before the EMA prompt. The brackets below the point estimates indicate the 95% CIs. Tiles are color-coded based on the (absolute) strength of the estimated relationship. EMA = ecological momentary assessment; CIs = confidence intervals. See the online article for the color version of this figure. SIEPE, TUTUNJI, RIEBLE, PROPPERT, AND FRIED\n\nTable  3 ). This means that a difference of one point on the self-report response scale corresponds to a difference of around 20 min in sleep duration, meaning that if an individual reports higher sleep quality compared to their average, they also tend to have a longer sensor sleep duration. The standardized effect for this relationship was 0.26 (95% CI = [0.25, 0.28]). The standard deviation of the random slopes for sleep duration 0.21 (95% CI = [0.20, 0.23] indicates a relatively large variability in within-person associations. The point estimate for the between-person association between self-report sleep quality and sensor sleep duration was 0.12 (95% CI = [0.05, 0.19]), indicating that individuals with higher average self-report sleep quality had a higher average sensor sleep duration. As sleep was assessed retrospectively in the morning and there is only one sensor value per night, the aggregation window and lag size do not play a role here. Conditional and marginal R 2 were estimated as .28 and .065, while the RMSE was 1.33.\n\nIn our secondary analysis S1, we found no significant interaction of the within-person association with age, gender, or depression. Participants in cohorts two and four showed higher within-person associations between the sensor and self-report measure compared to the first cohort. Specifically, the average association was 30% stronger in cohort two compared to cohort one. Point estimates of the association were virtually identical to the main analysis when specifying a different autocorrelation structure (S2). Full results are available in the additional online materials."
    },
    {
      "title": "Discussion",
      "text": "We analyzed the concurrent associations between self-report and wearable measures of stress, sleep, and tiredness in a large student sample. Overall, largely independent of preprocessing and modeling choices, we found very small associations for the stress measures, suggesting a lack of overlap between the sensor and self-report measures. For sleep and tiredness, we found stronger relationships (standardized point estimates of 0.26 and -0.082, respectively) with strong interindividual heterogeneity, suggesting that the sensor and self-report versions may tap into a somewhat similar construct.\n\nOur secondary analyses indicate that age, gender, and depression were not meaningful moderators of the association between selfreport and sensor measures. However, average within-person associations for stress were weaker in cohorts two and four whereas they were stronger for tiredness and sleep in the same cohorts. This is a surprising result, and we can only speculate about its causes. One potential factor may be that cohorts one and three were assessed in the winter (December through February), and cohorts two and four in the summer (June through August), implying substantial temperature differences in the Netherlands. While various plausible explanations come to mind-for example, differences in lifestyle or sweat production-we are unaware of any research into the topic. We do not find that sensor data quality systematically goes down with each cohort, implying that the smartwatches likely do not deteriorate meaningfully over the data collection time frame of around 2 years.\n\nWe found no evidence for depression as a moderator of the association between passive sensing and self-report data. Looking at the literature,  Collins et al. (2025)  have found that the discrepancy between both data types was larger for individuals with higher depressive symptoms, which they link to potential recall biases or memory deficits. Price et al. (2025)  used actigraphy-based prediction models for depressive symptoms in both a general population sample and a clinical sample (based on PHQ-9). Their results were mixed: they found slightly higher score accuracy of the prediction models in the clinical population, but not all of these predictions were significantly better than chance. Contrary to these previous studies, we investigated the moment-to-moment associations of passive sensor and self-report data. Our findings suggest no evidence for better or worse validity of passive sensor data in people with higher depressive symptoms. This finding may be partly explained by the weak overlap between passive sensor and self-report data and the large interindividual heterogeneity in associations.\n\nOverall, our findings suggest that some features collected by commercial smartwatches may be useful for obtaining a multimodal insight into transdiagnostic constructs related to mental health. At the same time, the finding regarding stress suggests a lack of conceptual overlap between different data sources. We discuss these results in the following section for sleep, tiredness, and stress, and then highlight the implications of our finding for psychopathology research more broadly."
    },
    {
      "title": "Sleep",
      "text": "We observed a positive relationship between sensor sleep duration and self-report sleep quality in all analyses and for most individuals. This association was estimated to be positive for most individuals. Combined with the fact that the fixed effect estimate implies that a 1-point increase in self-reported sleep quality is associated with around 20 min of more sensor sleep, this indicates the potential utility of the wearable data for unobtrusive sleep tracking. This makes such data relevant for a wide range of mental health research, as sleep problems are part of many different diagnoses in the DSM-5  (Forbes et al., 2024) . Previous studies on the association between self-report sleep quality and sensor sleep duration found no evidence for an overlap between self-reported sleep quality and sensor sleep duration  (Teo et al., 2019)  or limited predictive power of sensor sleep duration for future sleep quality  (Staples et al., 2017) . However, these studies used different ways of assessing self-report and sensor sleep duration and had a considerably lower sample size. While we can expect sensor sleep duration and self-reported sleep quality to be related, they do not measure exactly the same construct, which may partially explain a lack of stronger associations in our sample."
    },
    {
      "title": "Tiredness",
      "text": "The results for the body battery sensor measure, which has not yet been evaluated against self-report data, indicate that it is weakly negatively related to momentary experiences of being tired. This result gives some preliminary validity evidence for researchers using preprocessed Garmin data. At the same time, person-specific estimates showed considerable heterogeneity and a lack of association between self-report and sensor measures for a substantial part of the sample. Also, the RMSE of 20.46 indicates, roughly speaking, that a typical difference between the observed and predicted value in our model is around 20. This corresponds to one-fifth of the full scale range, indicating large differences between the predictions of our model and observed values. For psychopathology research, this means that the body battery may be a somewhat useful proxy for fatigue, which in turn can be used to tap into the effects of sleep problems. Future studies could try to show if body battery is more strongly related to other self-report measures and if it shows predictive validity for future mental health outcomes."
    },
    {
      "title": "Stress",
      "text": "The results for stress show an astonishing lack of overlap between the sensor and self-report measures. The association between selfreport and sensor stress seems to be descriptively slightly lower when aggregating sensor stress before the prompt and in a larger aggregation window, but given the size of confidence intervals, it is unclear how robust this effect is. Overall, the lack of overlap was robust to preprocessing choices and other analysis strategies. There are multiple plausible explanations for this result.\n\nFirst, sensor-based measures of stress rely on physiological signals of arousal. These signals are often valence nonspecific, meaning that excitement or positive arousal may also elicit an increase in heart rate and a decrease in heart rate variability which sensors may interpret as stress signals. Indeed, previous work has shown that such sensor-based measures relate to both negative and positive affect in daily life  (Tutunji, Kogias, et al., 2023; van Halem et al., 2020) .\n\nSecond, there may be a so-called \"semantic gap\"  (Das Swain et al., 2022)  between the physiological and psychological concepts of stress. This means that physiological representations of what one might call stress and individual psychological definitions of stress may diverge, and they may not be able to measure the same underlying construct. This has also been the case for laboratorybased stress research using psychophysiology measures. In such studies, there is at times little overlap between the subjective component of stress following stress induction and the physiological measures acquired  (Campbell & Ehlert, 2012 ). An investigation of postvaccination reactions by  Guan et al. (2022)  provides some preliminary evidence of such a semantic gap with the Garmin VivoSmart 4. In their study, wearable heart rate and stress measures were elevated for some time after vaccination, even in individuals who did not report side effects of the vaccine.\n\nThird, another plausible explanation is measurement issues, potentially both in wearable and self-reported stress. The algorithm used to estimate individual stress scores is proprietary, and little information is available about its specifics. Given that the smartwatch used in this study is a commercial product, the stress score calculation may be optimized not only for high accuracy but also for a good user experience.\n\nAnalyses of the raw stress data indicate that the distribution of stress scores is not continuous, but rather thresholded at 25, which is the highest value in the \"no stress\" category. We illustrate the issue in Figure  4 . Specifically, across all participants, around 56.7% of all stress scores fall into the interval between 0 and 25. We can only speculate that this may serve the purpose of avoiding indicating that individuals are \"stressed\" too often, but it is problematic from the perspective of accurately capturing the underlying phenomenon of stress. We have rarely seen similar figures on the raw distributions of passive sensing data in mental health research. Recent calls for more descriptive work in experience sampling studies  (Siepe, Rieble, et al., 2025) , therefore, also apply to passive sensing research.\n\nAt the same time, self-reported stress may also contain measurement issues, including potential measurement error (we only measured stress with a single item) and recall biases. Furthermore, stress may be conceived of as an umbrella term for multiple distinct constructs (see, e.g.,  Crosswell & Lockwood, 2020; Goodday & Friend, 2019; Vaessen et al., 2021)  whose heterogeneity cannot be fully captured by a single item. Interestingly, there is evidence that this applies to physiological markers of stress as well  (Goodday & Friend, 2019) . Finally, the limited variability and potential floor effects for the self-report stress item could have additionally impeded the possibility of finding associations with sensor data. Irrespective of the reasons for our results, they serve as cautionary reminders not to simply replace self-report with passive measures without proper validation.\n\nThese results do not imply that the sensor stress measure is not useful or in any way incorrect in the data set under consideration. If we follow the idea that there may be a semantic gap between selfreport and wearable measures, wearable measures may still be useful for prediction because they may capture relevant information that is somewhat orthogonal to the self-report measures  (Das Swain et al., 2022) . Combining passive and self-report measures for the same or similar constructs, as many studies already do  (Velozo et al., 2024) , can provide both potential benefits for predictive modeling as well as avenues for research into construct validation. For example, studying associations between both sources of data across a range of aggregation windows and time lags can provide insight into how individuals aggregate their experiences when responding to self-report prompts (see  Leertouwer et al., 2021 , for similar comparisons of different types of self-report data). We believe that such work, in combination with theoretical work on the concepts one intends to measure  (Bringmann et al., 2022) , will advance our ability to understand and predict mental health. If the field of digital phenotyping wants to fulfill its promises, it should, therefore, not neglect to build a strong foundation of construct validation and measurement work. Until we have reached a better understanding of the relationship between passive sensor measures and self-reported variables, researchers should be cautious not to assume that these different data sources necessarily measure similar constructs. Note. This figure contains the absolute counts of specific sensor stress values. We randomly sampled one million stress values from all available sensor stress data across all four cohorts. Bars are colored based on Garmin's classification into no stress (, = 25) and stress (.25). See the online article for the color version of this figure. SIEPE, TUTUNJI, RIEBLE, PROPPERT, AND FRIED"
    },
    {
      "title": "Limitations",
      "text": "For the constructs assessed by wearables, we used data that were internally preprocessed by the Garmin watch, which is sometimes called \"proxy\" data  (Velozo et al., 2024) . Using data processed via openly available algorithms could improve the transparency and validity of results  (Velozo et al., 2024)  and enhance our understanding of the role which specific physiological markers play in mental health science  (Weber et al., 2022) . At the same time, we need to face the reality that commercial-grade sensors in mental health research are likely here to stay. They come with simple data management, are relatively inexpensive, and are easy to use and wear in everyday life. Beyond that, they are already worn by millions of customers in their everyday lives. Therefore, we believe that future research into the statistical properties and validity of these commercial sensors is and will continue to be worthwhile.\n\nWhile the large amount of data is a distinct strength of our study, there was a substantial proportion of individuals with a relatively low compliance. Although we aimed to follow state-of-the-art recommendations in the methodological literature and explored various modeling approaches, we could have modified and extended our modeling strategy in various ways. For example, we assumed heterogeneity in residual variances between individuals (see  Nestler, 2024 , for an alternative), used observed instead of latent person-specific means for centering (see  Hamaker & Muth\u00e9n, 2020 , for an alternative), and did not explore more flexible functional forms of the association between predictors and outcomes, such as polynomials or machine learning approaches. We did not preregister our exploratory analyses but tried to account for plausible alternative analysis pipelines via sensitivity and secondary analyses. Future studies could use preregistration protocols  (Langener, Siepe, et al., 2024)  to test more precise and specific hypotheses about digital phenotyping data."
    },
    {
      "title": "Conclusions",
      "text": "In this study, we investigated the overlap between wearable and self-report measures purportedly measuring the same or similar constructs. We found a robust association between self-reported sleep quality and sensor sleep duration, and a smaller association between self-report tiredness and sensor \"body battery.\" Wearable and selfreport measures of stress showed a lack of overlap for most individuals, likely highlighting both differences in the construct that is supposed to be assessed as well as potential measurement issues. Age, gender, and depressive symptomatology were no meaningful moderators of these associations. We are convinced that further work on measurement in the digital phenotyping literature is crucial for clinical utility and will move the field forward."
    },
    {
      "text": "Figure 1 Raincloud Plots for Person-Specific Means in Main Analysis"
    },
    {
      "text": "Figure 2Individual Estimates for Main Analyses"
    },
    {
      "text": "Figure 3 Fixed Effects of Stress and Tiredness Across Aggregation Windows and Lags"
    },
    {
      "text": "Figure 4 Distribution of all Sensor Stress Values"
    },
    {
      "text": "Overview of Secondary Analyses"
    },
    {
      "text": "Descriptive Statistics"
    },
    {
      "text": "Results for Main Analyses"
    }
  ],
  "references": [
    {
      "title": "Mobile devices for the remote acquisition of physiological and behavioral biomarkers in psychiatric clinical research",
      "authors": [
        "Z Adams",
        "E Mcclure",
        "K Gray",
        "C Danielson",
        "F Treiber",
        "K Ruggiero"
      ],
      "year": 2017,
      "doi": "10.1016/j.jpsychires.2016.10.019"
    },
    {
      "title": "Machine learning for passive mental health symptom prediction: Generalization across different longitudinal mobile sensing studies",
      "authors": [
        "D Adler",
        "F Wang",
        "D Mohr",
        "T Choudhury"
      ],
      "year": 2022,
      "doi": "10.1371/journal.pone.0266516"
    },
    {
      "title": "Journal article reporting standards for quantitative research in psychology: The APA publications and communications board task force report",
      "authors": [
        "M Appelbaum",
        "H Cooper",
        "R Kline",
        "E Mayo-Wilson",
        "A Nezu",
        "S Rao"
      ],
      "year": 2018,
      "doi": "10.1037/amp0000191"
    },
    {
      "title": "Mental disorders among college students in the World Health Organization world mental health surveys",
      "authors": [
        "R Auerbach",
        "J Alonso",
        "W Axinn",
        "P Cuijpers",
        "D Ebert",
        "J Green",
        "I Hwang",
        "R Kessler",
        "H Liu",
        "P Mortier",
        "M Nock",
        "S Pinder-Amaker",
        "N Sampson",
        "S Aguilar-Gaxiola",
        "A Al-Hamzawi",
        "L Andrade",
        "C Benjet",
        "J Caldas-De-Almeida",
        "K Demyttenaere",
        "R Bruffaerts"
      ],
      "year": 2016,
      "doi": "10.1017/s0033291716001665"
    },
    {
      "title": "Sleep and mental disorders: A meta-analysis of polysomnographic research",
      "authors": [
        "C Baglioni",
        "S Nanovska",
        "W Regen",
        "K Spiegelhalder",
        "B Feige",
        "C Nissen",
        "C Reynolds",
        "D Riemann"
      ],
      "year": 2016,
      "doi": "10.1037/bul0000053"
    },
    {
      "title": "Combining ecological momentary assessment with objective, ambulatory measures of behavior and physiology in substance-use research",
      "authors": [
        "G Berrios",
        "J Bertz",
        "D Epstein",
        "K Preston"
      ],
      "year": 1990,
      "doi": "10.1016/j.addbeh.2017.11.027"
    },
    {
      "title": "Back to basics: The importance of conceptual clarification in psychological science",
      "authors": [
        "L Bringmann",
        "T Elmer",
        "M Eronen"
      ],
      "year": 2022,
      "doi": "10.1177/09637214221096485"
    },
    {
      "title": "Digital phenotyping for monitoring mental disorders: Systematic review",
      "authors": [
        "P Bufano",
        "M Laurino",
        "S Said",
        "A Tognetti",
        "D Menicucci"
      ],
      "year": 2023,
      "doi": "10.2196/46778"
    },
    {
      "title": "Acute psychosocial stress: Does the -emotional stress response correspond with physiological responses?",
      "authors": [
        "J Campbell",
        "U Ehlert"
      ],
      "year": 2012,
      "doi": "10.1016/j.psyneuen.2011.12.010"
    },
    {
      "title": "Methods in predictive techniques for mental health status on social media: A critical review",
      "authors": [
        "S Chancellor",
        "M De Choudhury"
      ],
      "year": 2020,
      "doi": "10.1038/s41746-020-0233-7"
    },
    {
      "title": "A comparison of objective and subjective measures of physical activity, sedentary and sleep behaviors between persons with and without depressive symptoms",
      "authors": [
        "A Collins",
        "G Price",
        "V Moreno",
        "D Mackin",
        "J Oh",
        "M Heinz",
        "N Jacobson"
      ],
      "year": 2025,
      "doi": "10.1016/j.jad.2025.01.092"
    },
    {
      "title": "Sleep problems, tiredness, and psychological symptoms among healthy adolescents",
      "authors": [
        "J Coulombe",
        "G Reid",
        "M Boyle",
        "Y Racine"
      ],
      "year": 2010,
      "doi": "10.1093/jpepsy/jsq028"
    },
    {
      "title": "Best practices for stress measurement: How to measure psychological stress in health research",
      "authors": [
        "A Crosswell",
        "K Lockwood"
      ],
      "year": 2020,
      "doi": "10.1177/2055102920933072"
    },
    {
      "title": "Why are self-report and behavioral measures weakly correlated",
      "authors": [
        "J Dang",
        "K King",
        "M Inzlicht"
      ],
      "year": 2020,
      "doi": "10.1016/j.tics.2020.01.007"
    },
    {
      "title": "Unveiling the digital phenotype: A protocol for a prospective study on physical activity behavior in community-dwelling older adults",
      "authors": [
        "K Daniels",
        "S Vonck",
        "J Robijns",
        "A Spooren",
        "D Hansen",
        "B Bonnech\u00e8re"
      ],
      "year": 2024,
      "doi": "10.21203/rs.3.rs-3896647/v1"
    },
    {
      "title": "Semantic gap in predicting mental wellbeing through passive sensing",
      "authors": [
        "V Das Swain",
        "V Chen",
        "S Mishra",
        "S Mattingly",
        "G Abowd",
        "M De Choudhury"
      ],
      "year": 2022,
      "doi": "10.1145/3491102.3502037"
    },
    {
      "authors": [
        "Ecological Momentary Assessment Sensor Validation"
      ]
    },
    {
      "title": "The crossroads of digital phenotyping",
      "authors": [
        "B Davidson"
      ],
      "year": 2022,
      "doi": "10.1016/j.genhosppsych.2020.11.009"
    },
    {
      "title": "Digital health tools for the passive monitoring of depression: A systematic review of methods",
      "authors": [
        "De Angel",
        "V Lewis",
        "S White",
        "K Oetzmann",
        "C Leightley",
        "D Oprea",
        "E Lavelle",
        "G Matcham",
        "F Pace",
        "A Mohr",
        "D Dobson",
        "R Hotopf"
      ],
      "year": 2022,
      "doi": "10.1038/s41746-021-00548-8"
    },
    {
      "title": "Digital phenotyping: Hype or hope?",
      "authors": [
        "U Ebner-Priemer",
        "P Santangelo"
      ],
      "year": 2020,
      "doi": "10.1016/s2215-0366(19)30380-3"
    },
    {
      "title": "Stress and recovery analysis method based on 24-hour heart rate variability",
      "year": 2014,
      "doi": "10.2196/preprints.24704"
    },
    {
      "title": "Elemental psychopathology: Distilling constituent symptoms and patterns of repetition in the diagnostic criteria of the DSM-5",
      "authors": [
        "M Forbes",
        "B Neo",
        "O Nezami",
        "E Fried",
        "K Faure",
        "B Michelsen",
        "M Twose",
        "M Dras"
      ],
      "year": 2024,
      "doi": "10.1017/s0033291723002544"
    },
    {
      "title": "Sleep disturbance and psychiatric disorders",
      "authors": [
        "D Freeman",
        "B Sheaves",
        "F Waite",
        "A Harvey",
        "P Harrison"
      ],
      "year": 2020,
      "doi": "10.1016/S2215-0366(20)30136-X"
    },
    {
      "title": "Building an early warning system for depression: Rationale, objectives, and methods of the WARN-D study",
      "authors": [
        "E Fried",
        "R Proppert",
        "C Rieble"
      ],
      "year": 2023,
      "doi": "10.32872/cpe.10075"
    },
    {
      "title": "Body battery. Garmin Homepage",
      "authors": [
        "Garmin"
      ],
      "year": 2024
    },
    {
      "title": "Unlocking stress and forecasting its consequences with digital technology",
      "authors": [
        "S Goodday",
        "S Friend"
      ],
      "year": 2019,
      "doi": "10.1038/s41746-019-0151-8"
    },
    {
      "title": "Higher sensitivity monitoring of reactions to COVID-19 vaccination using smartwatches",
      "authors": [
        "G Guan",
        "M Mofaz",
        "G Qian",
        "T Patalon",
        "E Shmueli",
        "D Yamin",
        "M Brandeau"
      ],
      "year": 2022,
      "doi": "10.1038/s41746-022-00683-w"
    },
    {
      "title": "The fixed versus random effects debate and how it relates to centering in multilevel modeling",
      "authors": [
        "E Hamaker",
        "B Muth\u00e9n"
      ],
      "year": 2020,
      "doi": "10.1037/met0000239"
    },
    {
      "title": "No time like the present: Discovering the hidden dynamics in intensive longitudinal data",
      "authors": [
        "E Hamaker",
        "M Wichers"
      ],
      "year": 2017,
      "doi": "10.1177/0963721416666518"
    },
    {
      "title": "Stress and depression",
      "authors": [
        "C Hammen"
      ],
      "year": 2005,
      "doi": "10.1146/annurev.clinpsy.1.102803.143938"
    },
    {
      "title": "Sleep disturbance as transdiagnostic: Consideration of neurobiological mechanisms",
      "authors": [
        "A Harvey",
        "G Murray",
        "R Chandler",
        "A Soehner"
      ],
      "year": 2011,
      "doi": "10.1016/j.cpr.2010.04.003"
    },
    {
      "title": "The use of digitally assessed stress levels to model change processes in CBT-A feasibility study on seven case examples",
      "authors": [
        "M Hehlmann",
        "B Schwartz",
        "T Lutz",
        "J G\u00f3mez Penedo",
        "J Rubel",
        "W Lutz"
      ],
      "year": 2021,
      "doi": "10.3389/fpsyt.2021.613085"
    },
    {
      "title": "Toward clinical digital phenotyping: A timely opportunity to consider purpose, quality, and safety",
      "authors": [
        "K Huckvale",
        "S Venkatesh",
        "H Christensen"
      ],
      "year": 2019,
      "doi": "10.1038/s41746-019-0166-1"
    },
    {
      "title": "Digital phenotyping: A global tool for psychiatry",
      "authors": [
        "T Insel"
      ],
      "year": 2018,
      "doi": "10.1002/wps.20550"
    },
    {
      "title": "Two half-truths make a whole? On bias in self-reports and tracking data",
      "authors": [
        "P J\u00fcrgens",
        "B Stark",
        "M Magin"
      ],
      "year": 2020,
      "doi": "10.1177/0894439319831643"
    },
    {
      "title": "ggdist: Visualizations of distributions and uncertainty",
      "authors": [
        "M Kay"
      ],
      "year": 2024,
      "doi": "10.5281/zenodo.3879620"
    },
    {
      "title": "The PHQ-9: Validity of a brief depression severity measure",
      "authors": [
        "K Kroenke",
        "R Spitzer",
        "J Williams"
      ],
      "year": 2001,
      "doi": "10.1046/j.1525-1497.2001.016009606.x"
    },
    {
      "title": "A template and tutorial for preregistering studies using passive smartphone measures",
      "authors": [
        "A Langener",
        "B Siepe",
        "M Elsherif",
        "K Niemeijer",
        "P Andresen",
        "S Akre",
        "L Bringmann",
        "Z Cohen",
        "N Choukas",
        "K Drexl",
        "L Fassi",
        "J Green",
        "T Hoffmann",
        "M Kas",
        "S Kurten",
        "R Schoedel",
        "G Stulp",
        "G Turner",
        "N Jacobson"
      ],
      "year": 2024,
      "doi": "10.31234/osf.io/p4xf8"
    },
    {
      "title": "It's all about timing: Exploring different temporal resolutions for analyzing digital-phenotyping data",
      "authors": [
        "A Langener",
        "G Stulp",
        "N Jacobson",
        "A Costanzo",
        "R Jagesar",
        "M Kas",
        "L Bringmann"
      ],
      "year": 2024,
      "doi": "10.1177/25152459231202677"
    },
    {
      "title": "Capturing the dynamics of the social environment through experience sampling methods, passive sensing, and egocentric networks: Scoping review",
      "authors": [
        "A Langener",
        "G Stulp",
        "M Kas",
        "L Bringmann"
      ],
      "year": 2023,
      "doi": "10.2196/42646"
    },
    {
      "title": "Self-reported and measured sleep duration: How similar are they?",
      "authors": [
        "D Lauderdale",
        "K Knutson",
        "L Yan",
        "K Liu",
        "P Rathouz"
      ],
      "year": 2008,
      "doi": "10.1097/ede.0b013e318187a7b0"
    },
    {
      "title": "A review of explicit and implicit assumptions when providing personalized feedback based on self-report EMA data",
      "authors": [
        "I Leertouwer",
        "A Cramer",
        "J Vermunt",
        "N Schuurman"
      ],
      "year": 2021,
      "doi": "10.3389/fpsyg.2021.764526"
    },
    {
      "title": "Performance: An R package for assessment, comparison and testing of statistical models",
      "authors": [
        "D L\u00fcdecke",
        "M Ben-Shachar",
        "I Patil",
        "P Waggoner",
        "D Makowski"
      ],
      "year": 2021,
      "doi": "10.21105/joss.03139"
    },
    {
      "title": "Assessing the validity of self-report social media use: Evidence of no relationship with objective smartphone use",
      "authors": [
        "T Mahalingham",
        "P Mcevoy",
        "P Clarke"
      ],
      "year": 2023,
      "doi": "10.1016/j.chb.2022.107567"
    },
    {
      "title": "Digital phenotyping for mental health of college students: A clinical review",
      "authors": [
        "J Melcher",
        "R Hays",
        "J Torous"
      ],
      "year": 2020,
      "doi": "10.1136/ebmental-2020-300180"
    },
    {
      "title": "Ambulatory assessment in psychopathology research: Current achievements and future ambitions",
      "authors": [
        "M Mestdagh",
        "E Dejonckheere"
      ],
      "year": 2021,
      "doi": "10.1016/j.copsyc.2021.01.004"
    },
    {
      "title": "Emotional variability predicts tiredness in daily life",
      "authors": [
        "A Mill",
        "A Realo",
        "J Allik"
      ],
      "year": 2016,
      "doi": "10.1027/1614-0001/a000206"
    },
    {
      "title": "Personal sensing: Understanding mental health using ubiquitous sensors and machine learning",
      "authors": [
        "D Mohr",
        "M Zhang",
        "S Schueller"
      ],
      "year": 2017,
      "doi": "10.1146/annurev-clinpsy-032816-044949"
    },
    {
      "title": "The open handbook of experience sampling methodology: A step-by-step guide to designing, conducting, and analyzing ESM studies",
      "year": 2022,
      "doi": "10.11116/9789461666925"
    },
    {
      "title": "Integration of a smartwatch within an internetdelivered intervention for depression: Protocol for a feasibility randomized SIEPE, TUTUNJI, RIEBLE, PROPPERT, AND FRIED controlled trial on acceptance",
      "authors": [
        "C Nadal",
        "C Earley",
        "A Enrique",
        "N Vigano",
        "C Sas",
        "D Richards",
        "G Doherty"
      ],
      "year": 2021,
      "doi": "10.1016/j.cct.2021.106323"
    },
    {
      "title": "The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded",
      "authors": [
        "S Nakagawa",
        "P Johnson",
        "H Schielzeth"
      ],
      "year": 2017,
      "doi": "10.1098/rsif.2017.0213"
    },
    {
      "title": "Guidelines for wrist-worn consumer wearable assessment of heart rate in biobehavioral research",
      "authors": [
        "B Nelson",
        "C Low",
        "N Jacobson",
        "P Are\u00e1n",
        "J Torous",
        "N Allen"
      ],
      "year": 2020,
      "doi": "10.1038/s41746-020-0297-4"
    },
    {
      "title": "A mixed-effects model in which the parameters of the autocorrelated error structure can differ between individuals",
      "authors": [
        "S Nestler"
      ],
      "year": 2024,
      "doi": "10.1080/00273171.2023.2217418"
    },
    {
      "title": "Tracking subjective sleep quality and mood with mobile sensing: Multiverse study",
      "authors": [
        "K Niemeijer",
        "M Mestdagh",
        "P Kuppens"
      ],
      "year": 2022,
      "doi": "10.2196/25643"
    },
    {
      "title": "Opportunities and challenges in the collection and analysis of digital phenotyping data",
      "authors": [
        "J.-P Onnela"
      ],
      "year": 2021,
      "doi": "10.1038/s41386-020-0771-3"
    },
    {
      "title": "A systematic review and meta-analysis of discrepancies between logged and self-reported digital media use",
      "authors": [
        "D Parry",
        "B Davidson",
        "C Sewall",
        "J Fisher",
        "H Mieczkowski",
        "D Quintana"
      ],
      "year": 2021,
      "doi": "10.1038/s41562-021-01117-5"
    },
    {
      "title": "nlme: Linear and nonlinear mixed effects models (R Package Version 3",
      "authors": [
        "J Pinheiro",
        "D Bates",
        "& R Core",
        "Team"
      ],
      "year": 2023,
      "doi": "10.32614/cran.package.nlme"
    },
    {
      "title": "Use of passively collected actigraphy data to detect individual depressive symptoms in a clinical subpopulation and a general population",
      "authors": [
        "G Price",
        "A Collins",
        "D Mackin",
        "M Heinz",
        "N Jacobson"
      ],
      "year": 2025,
      "doi": "10.1037/abn0000933"
    },
    {
      "title": "Using digital phenotyping to capture depression symptom variability: Detecting naturalistic variability in depression symptoms across one year using passively collected wearable movement and sleep data",
      "authors": [
        "G Price",
        "M Heinz",
        "S Song",
        "M Nemesure",
        "N Jacobson"
      ],
      "year": 2023,
      "doi": "10.1038/s41398-023-02669-y"
    },
    {
      "title": "A comparison of direct versus self-report measures for assessing physical activity in adults: A systematic review",
      "authors": [
        "S Prince",
        "K Adamo",
        "M Hamel",
        "J Hardt",
        "S Gorber",
        "M Tremblay"
      ],
      "year": 2008,
      "doi": "10.1186/1479-5868-5-56"
    },
    {
      "title": "R: A language and environment for statistical computing",
      "authors": [
        "Team Core"
      ],
      "year": 2024,
      "doi": "10.32614/r.manuals"
    },
    {
      "title": "Association of digital measures and self-reported fatigue: A remote observational study in healthy participants and participants with chronic inflammatory rheumatic disease",
      "authors": [
        "C Rao",
        "E Di Lascio",
        "D Demanse",
        "N Marshall",
        "M Sopala",
        "V De Luca"
      ],
      "year": 2023,
      "doi": "10.3389/fdgth.2023.1099456"
    },
    {
      "title": "Advancing psychiatry with transdiagnostic targets for digital phenotyping",
      "authors": [
        "W Ringwald",
        "G King",
        "C Vize",
        "A Wright"
      ],
      "year": 2025,
      "doi": "10.31234/osf.io/3tyjp_v2"
    },
    {
      "title": "Accuracy of fitbit charge 4, Garmin VivoSmart 4, and WHOOP versus polysomnography: Systematic review",
      "authors": [
        "A.-M Schyvens",
        "N Oost",
        "J.-M Aerts",
        "F Masci",
        "B Peters",
        "A Neven",
        "H Dirix",
        "G Wets",
        "V Ross",
        "J Verbraecken"
      ],
      "year": 2024,
      "doi": "10.2196/52192"
    },
    {
      "title": "Functional consequences of inadequate sleep in adolescents: A systematic review",
      "authors": [
        "T Shochat",
        "M Cohen-Zion",
        "O Tzischinsky"
      ],
      "year": 2014,
      "doi": "10.1016/j.smrv.2013.03.005"
    },
    {
      "title": "Understanding ecological-momentaryassessment data: A tutorial on exploring item performance in ecologicalmomentary-assessment data",
      "authors": [
        "B Siepe",
        "C Rieble",
        "R Tutunji",
        "A Rimpler",
        "J M\u00e4rz",
        "R Proppert",
        "E Fried"
      ],
      "year": 2025,
      "doi": "10.1177/25152459241286877"
    },
    {
      "title": "Online supplement for: Associations between ecological momentary assessment and passive sensor data in a large student sample",
      "authors": [
        "B Siepe",
        "R Tutunji",
        "C Rieble",
        "R Proppert",
        "E Fried"
      ],
      "year": 2025,
      "doi": "10.31234/osf.io/ybns6"
    },
    {
      "title": "How does stress increase risk of drug abuse and relapse?",
      "authors": [
        "R Sinha"
      ],
      "year": 2001,
      "doi": "10.1007/s002130100917"
    },
    {
      "title": "Large-scale wearable data reveal digital phenotypes for daily-life stress detection",
      "authors": [
        "E Smets",
        "Rios",
        "E Velazquez",
        "G Schiavone",
        "I Chakroun",
        "E D'hondt",
        "W De Raedt",
        "J Cornelis",
        "O Janssens",
        "S Van Hoecke",
        "S Claes",
        "I Van Diest",
        "C Hoof"
      ],
      "year": 2018,
      "doi": "10.1038/s41746-018-0074-9"
    },
    {
      "title": "A comparison of passive and active estimates of sleep in a cohort with schizophrenia",
      "authors": [
        "P Staples",
        "J Torous",
        "I Barnett",
        "K Carlson",
        "L Sandoval",
        "M Keshavan",
        "J.-P Onnela"
      ],
      "year": 2017,
      "doi": "10.1038/s41537-017-0038-0"
    },
    {
      "title": "Validation of accelerometry as a digital phenotyping measure of negative symptoms in schizophrenia",
      "authors": [
        "G Strauss",
        "I Raugh",
        "L Zhang",
        "L Luther",
        "H Chapman",
        "D Allen",
        "B Kirkpatrick",
        "A Cohen"
      ],
      "year": 2022,
      "doi": "10.1038/s41537-022-00241-z"
    },
    {
      "title": "It's time to broaden the replicability conversation: Thoughts for and from clinical psychological science",
      "authors": [
        "J Tackett",
        "S Lilienfeld",
        "C Patrick",
        "S Johnson",
        "R Krueger",
        "J Miller",
        "T Oltmanns",
        "P Shrout"
      ],
      "year": 2017,
      "doi": "10.1177/1745691617690042"
    },
    {
      "title": "Digital phenotyping by consumer wearables identifies sleep-associated markers of cardiovascular disease risk and biological aging",
      "authors": [
        "J Teo",
        "S Davila",
        "C Yang",
        "A Hii",
        "C Pua",
        "J Yap",
        "S Tan",
        "A Sahl\u00e9n",
        "C Chin",
        "-L Teh",
        "B Cook",
        "S Yeo",
        "K Tan",
        "P Lim",
        "W Rozen"
      ],
      "year": 2019,
      "doi": "10.1038/s42003-019-0605-1"
    },
    {
      "title": "Relationship between sleep quality and mood: Ecological momentary assessment study",
      "authors": [
        "S Triantafillou",
        "S Saeb",
        "E Lattie",
        "D Mohr",
        "K Kording"
      ],
      "year": 2019,
      "doi": "10.2196/12613"
    },
    {
      "title": "Detecting prolonged stress in real life using wearable biosensors and ecological momentary assessments: Naturalistic experimental study",
      "authors": [
        "R Tutunji",
        "N Kogias",
        "B Kapteijns",
        "M Krentz",
        "F Krause",
        "E Vassena",
        "E Hermans"
      ],
      "year": 2023,
      "doi": "10.2196/39995"
    },
    {
      "title": "Defining a generic holdout sample for combined exploratory and predictive analyses in the WARN-D dataset",
      "authors": [
        "R Tutunji",
        "R Proppert",
        "C Rieble",
        "E Fried"
      ],
      "year": 2023,
      "doi": "10.17605/OSF.IO/W9NXY"
    },
    {
      "title": "Renv: Project environments (R Package Version 1.0",
      "authors": [
        "K Ushey",
        "H Wickham"
      ],
      "year": 2024,
      "doi": "10.32614/cran.package.renv"
    },
    {
      "title": "The association between selfreported stress and cardiovascular measures in daily life: A systematic review",
      "authors": [
        "T Vaessen",
        "A Rintala",
        "N Otsabryk",
        "W Viechtbauer",
        "M Wampers",
        "S Claes",
        "I Myin-Germeys"
      ],
      "year": 2021,
      "doi": "10.1371/journal.pone.0259557"
    },
    {
      "title": "Moments that matter? On the complexity of using triggers based on skin conductance to sample arousing events within an experience sampling framework",
      "authors": [
        "S Van Halem",
        "E Van Roekel",
        "L Kroencke",
        "N Kuper",
        "J Denissen"
      ],
      "year": 2020,
      "doi": "10.1002/per.2252"
    },
    {
      "title": "A standardized validity assessment protocol for physiological signals from wearable technology: Methodological underpinnings and an application to the E4 biosensor",
      "authors": [
        "Ecological Momentary Assessment Sensor Validation Van Lier",
        "H Pieterse",
        "M Garde",
        "A Postel",
        "M De Haan",
        "H Vollenbroek-Hutten",
        "M Schraagen",
        "J Noordzij"
      ],
      "year": 2020,
      "doi": "10.3758/s13428-019-01263-9"
    },
    {
      "title": "Designing daily-life research combining experience sampling method with parallel data",
      "authors": [
        "J Velozo",
        "J Habets",
        "S George",
        "K Niemeijer",
        "O Minaeva",
        "N Hagemann",
        "C Herff",
        "P Kuppens",
        "A Rintala",
        "T Vaessen",
        "H Riese",
        "P Delespaul"
      ],
      "year": 2024,
      "doi": "10.1017/S0033291722002367"
    },
    {
      "title": "Personality pathology and momentary stress processes",
      "authors": [
        "C Vize",
        "A Kaurin",
        "A Wright"
      ],
      "year": 2024,
      "doi": "10.1177/21677026231192483"
    },
    {
      "title": "On disaggregating betweenperson and within-person effects with longitudinal data using multilevel models",
      "authors": [
        "L Wang",
        "S Maxwell"
      ],
      "year": 2015,
      "doi": "10.1037/met0000030"
    },
    {
      "title": "Physiological reactions to acute stressors and subjective stress during daily life: A systematic review on ecological momentary assessment (EMA) studies",
      "authors": [
        "J Weber",
        "P Angerer",
        "J Apolin\u00e1rio-Hagen"
      ],
      "year": 2022,
      "doi": "10.1371/journal.pone.0271996"
    },
    {
      "title": "Applying multiverse analysis to experience sampling data: Investigating whether preprocessing choices affect robustness of conclusions",
      "authors": [
        "J Weermeijer",
        "G Lafit",
        "G Kiekens",
        "M Wampers",
        "G Eisele",
        "Z Kasanova",
        "T Vaessen",
        "P Kuppens",
        "I Myin-Germeys"
      ],
      "year": 2022,
      "doi": "10.3758/s13428-021-01777-1"
    },
    {
      "title": "ggplot2: Elegant graphics for data analysis",
      "authors": [
        "H Wickham"
      ],
      "year": 2016,
      "doi": "10.1007/978-0-387-98141-3"
    }
  ],
  "num_references": 86,
  "original_doi": "https://doi.org/10.13039/100021533"
}
