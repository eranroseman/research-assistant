{
  "paper_id": "DT9CKWCJ",
  "title": "Bayesian persuasion",
  "abstract": "Calculations From The Introduction Here are the calculations for the expected waiting time under the random beep with probability z. First, consider the probability that there has been an arrival conditional on no beep prior to date t. This is the probability that of at least one silent arrival conditional on the event that there was no noisy arrival. Notice that by the memoryless property of the Poisson process, conditional on any number of noisy arrivals, the distribution of silent arrivals is Poisson with parameter \u03bb(1z). 1 That is, the proba- bility of a silent arrival is independent of the number of noisy arrivals. In particular the probability of at least one silent arrival conditional on no noisy arrival is just the unconditional probability of a silent arrival, i.e.",
  "year": 2016,
  "date": "2016-07-25",
  "authors": [
    {
      "name": "Jeffrey Ely",
      "affiliation": {
        "organization": "Professor of Economics",
        "department": "Professor of Economics",
        "institution": "Northwestern University"
      }
    },
    {
      "name": "Emma Morrison",
      "affiliation": {
        "organization": "Professor of Economics",
        "department": "Professor of Economics",
        "institution": "Northwestern University"
      }
    }
  ],
  "doi": "10.1257/aer.101.6.2590",
  "md5": "67F2735190AF26838B10B5AD1F641934",
  "sections": [
    {
      "text": "Therefore the time it takes for the agent's beliefs to reach p * in the absence of a beep is\n\nand the probability that this time is reached without a beep is\n\nFinally, the expected time before the first beep conditional on that beep occurring prior to the agent's beliefs reaching the threshold is\n\nSince the agent stops working either because his beliefs reach the threshold or because a beep is heard earlier than \u03c9, the total expected waiting time is the weighted average\n\n) and after some algebra this simplifies to\n\n\u03bbz ."
    },
    {
      "title": "2. Formal Derivation Of The HJB Equation",
      "text": "Let us approximate the optimized continuous time discounted payoff for the principal by discretizing the time dimension into intervals of length h and the summation\n\nDividing through by e -rt ,\n\nNow a first-order approximation\n\nI claim that at an optimum q * of the maximization above, E q * V(\u03bd) = V(\u00b5). To see why, for each \u03bd \u2208 \u2206(S), let q * (\u03bd) be a maximizer for the optimization that defines V(\u03bd). Then we have\n\n] since the left-hand side is a feasible value for the right-hand side optimization, taking q to be the degenerate lottery. Therefore\n\nbut also\n\nsince the compound lottery in the middle expression above is feasible for the optimization that defines V(\u00b5). We can thus re-arrange as follows\n\nDividing through by h and then taking h \u2192 0 we obtain by l'Hopital's rule ,\n\n] .\n\n3 Calculations For The Basic Model"
    },
    {
      "title": "3.1. Value Function For Delayed Beep",
      "text": "First, lets calculate the continuation value when the agent's belief is at the threshold p * .\n\nThe principal collects a flow payoff of 1 until a beep arrives. He discounts payoffs at rate r and beeps arrive at rate \u03bb. This yields the following expected discounted value\n\nNext consider any \u00b5 \u2264 p * . Let \u03c4(\u00b5) be the time remaining before the belief reaches p * .\n\nThe principal collects a flow payoff of 1 until the belief for a duration \u03c4(\u00b5) then earns the continuation value V(p * ). The overall payoff is thus"
    },
    {
      "title": "3.2. Solving the HJB Equation",
      "text": "We begin with the function in brackets, i.e.,\n\nFor \u00b5 \u2264 p * , the flow payoff is constant u \u2261 1, the value function is given by Equation  1 and we have\n\nand noting that d\u03c4 d\u00b5 = -( d\u03bd dt ) -1 , this reduces to\n\n1e -r\u03c4(\u00b5) + e -r\u03c4(\u00b5) r r + \u03bb which is simply rV over the range \u00b5 \u2264 p * . For \u00b5 > p * , the flow payoff is constant u \u2261 0, and the value function is linear with negative slope\n\nwhich is negative for \u00b5 < 1 and zero at \u00b5 = 1.\n\nFinally we consider the concavification. We can analyze the two intervals [0,\n\np * ] and [p * , 1] separately. Since the bracketed function equals rV which is already concave on the interval [0, p * ], it is its own concavification on that interval. Turning to the interval [p * , 1], the linear function which connects the points (p * , V(p * )) and (1, 0) is concave and no smaller than the bracketed function over this interval. Therefore the concavifi-cation (which is the pointwise smallest such function) must have these two points in its graph. And any function with smaller values elsewhere would not be concave. Thus the linear function is the concavification on this interval. Finally, rV is just the union of these two functions, and it is concave over the full domain \u00b5 \u2208 [0, 1]. It is therefore the concavification of the function in brackets."
    },
    {
      "title": "4. Proofs For The General Single Agent Model",
      "text": "Proof of Lemma 1. For any current state s and subsequent state s \u2032 let \u03c7(s, s \u2032 ) equal the probability conditional on the process being in state s at time l that the process is in state s \u2032 at time l + h where h is the discrete period length. Let \u03c7 be the matrix of these transition probabilities. Then if the agent begins period t with belief \u00b5 and obtains no information, he will begin period t + 1 with belief\n\nProof of Theorem 1. It remains only to show that the operator\n\nis a contraction mapping on the complete metric space of bounded real-valued functions with the sup metric. The Blackwell sufficient conditions for T to be contraction mapping (with modulus \u03b4) are as follows.\n\nThe first follows from the observation that if g \u2265 g \u2032 , then any concave function which is weakly larger than g is also weakly larger than g \u2032 and therefore cav g \u2265 cav g \u2032 . The second follows from the observation that for any function h and any constant k, a concave function y is weakly larger than h if and only if y + k is weakly larger than h + k.\n\nTherefore cav(h + k) = (cav h) + k."
    },
    {
      "title": "5. Calculations For the Monopoly Example",
      "text": "It was asserted that a convex u implies that full-disclosure is optimal and that a concave u implies that no disclosure is optimal. These claims are immediate consequences of Theorem 1. In particular consider any convex u.\n\nThe operator T applied to any V is hence the concavification of convex function, i.e. linear (and hence convex.) Thus the set of all convex functions V is closed under the operator T when u is convex. Thus its fixed point is in the (sup-norm) closure of of the set of all convex functions. The set of all convex functions is closed in the supnorm topology. The optimal value function is thus the concavification of some convex function and therefore it is linear. A linear value function implies that full-disclosure is optimal. An analogous argument shows that the optimal value function is (strictly) concave when u is (resp. strictly) concave. A (strictly) concave value function implies that no disclosure is (resp. strictly) optimal.\n\nTurning to the mixed demand case, let W(\u03bd) represent the value of the no-disclosure policy beginning with belief \u03bd. It satisfies the recursive equation (recall that we have set \u03bb and r both to 1.)\n\nand it inherits the shape of u: it is first strictly concave and then strictly convex as \u00b5 ranges from 0 to 1. 2 Refer to Figure  1  throughout.\n\nFigure  1 : The mixed-demand monopoly example.\n\nWe will show that the optimal policy is partially informative: at belief \u00b5 = 1 the monopoly continuously sends a partially informative message which sends the belief either to an interior target \u03bd * or keeps it at 1. Once the belief is sent to \u03bd * , no further information is disclosed and the principal earns continuation value W(\u03bd * ).\n\nDefine X(\u03bd * ) by\n\nNote that this formula, rearranged, gives the initial value from a policy which, at rate 1/(1 -\u03bd * ) sends the belief to \u03bd * (and otherwise keeps it fixed at 1.)\n\nThe function W can be computed in closed form:\n\nI claim that there is a unique \u03bd * \u2208 (0, 1) satisfying\n\nTo prove this, first note that for all \u03bd * in the convex range of W, X(\u03bd\n\nLet us prove these inequalities in turn.\n\nConsider a policy which discloses nothing until the belief reaches \u00b5 \u2208 (\u03bd * , 1) whereupon it sends a binary message which sends the belief to 1 or \u03bd * with probabilities p and (1p) respectively. After that it reverts to non-disclosure forever. The value of this policy is\n\nwhere \u03c4(\u00b5) is the time it takes to reach belief \u00b5. If W is convex to the right of \u03bd * and by the law of total probability, this is greater than W(1). By induction therefore the value of a policy which sends the same binary signal every time the belief reaches \u03bd * is greater than W(1). Since this is true for all \u00b5 \u2208 (\u03bd * , 1), it is true by continuity for the policy that generates X(\u03bd * ) (i.e. taking limits as \u00b5 approaches 1), hence X(\u03bd * ) \u2265 W(1).\n\nThe second inequality follows immediately from strict convexity of W on [\u03bd * , 1].\n\nThus, if there exists a solution to the displayed equation it must occur at a value of \u03bd * at which W is (strictly) concave. Moreover by continuity there must exist at least\n\nand thus the derivative vanishes at a value \u03bd * that satisfies the displayed equation.\n\nWhen W is strictly concave, the function W \u2032 (\u00b5)(1 -\u00b5) is strictly decreasing and therefore can intersect at most once where X \u2032 (\u00b5) is zero.\n\nLet L(\u00b5) be the linear function connecting the points (\u03bd * , W(\u03bd * )) and (1, X(\u03bd * )) and consider the candidate value function\n\nThe function V is concave because we have shown that W is concave on [0, \u03bd * ].\n\nWe will show that it solves the HJB equation. Define the function U as the bracketed expression in the HJB equation:\n\nFor \u00b5 < \u03bd * , since V(\u00b5) = W(\u00b5), i.e. the no information value, it satisfies the differential equation in Equation  3 . Therefore U(\u00b5) = V(\u00b5). Also, for \u00b5 = 1, the definition of\n\nis the slope of L and hence equals V \u2032 (1) and d\u00b5 dt (1) = -1. We will now show that for \u00b5 \u2208 (\u03bd * , 1) we have U(\u00b5) \u2264 V(\u00b5). It will then follow that the concave function V is the smallest concave function no smaller than U, i.e. the concavification.\n\nSince\n\nand V is linear on [\u03bd * , 1], as is V \u2032 d\u00b5 dt , it follows that over this range\n\nwhere l is the linear function whose graph is the chord connecting the points (\u03bd * , u(\u03bd * ))\n\nand (1, u(  1 )) on the graph of u. Moreover, by definition\n\nConsider the graph of u. Since u is concave then convex, there exists a point \u03bd \u2208 (0, 1) such that for all \u00b5 \u2265 \u03bd, the chord connecting points (\u00b5, u(\u00b5)) and (1, u(1)) is above the graph of u, and for all \u00b5 < \u03bd, the chord intersects the graph in three points.\n\nIn fact, the point \u03bd is the unique point satisfying foot_0\n\nDirect calculation foot_1  reveals that \u03bd * > \u03bd. Thus, l \u2265 u over [\u03bd * , 1].\n\nWe have shown U \u2264 V. And since the two functions coincide over [0, \u03bd * ] and at 1, there can be no smaller concave function that is pointwise larger than U. Thus V is the concavification of U and thus solves the HJB equation."
    },
    {
      "title": "6. Additional Examples"
    },
    {
      "title": "6.1. Beeps In Discrete Time",
      "text": "In discrete time the email beeps example can be described as follows. The set of states is S = {0, 1} indicating whether or not an email has arrived to the inbox. The discrete time transition probability from state 0 to 1 is the probability within a period of length h that at least one email arrives and is given by M = 1e -\u03bbh yielding the following law of motion for the agent's beliefs when uninformed:\n\nThe principal's indirect utility function is\n\nand he maximizes his expected discounted utility where the discount factor is e -r\u2206\n\ngiven a continuous time discount rate r.\n\nIn Section 3.1 I derive the value function and optimal policy analytically. Here we will follow a sequence of diagrams to visualize the derivation and gain intuition. Recall the Bellman equation:\n\nConsider as an initial guess, a linear V. We can trace through the operations on the right-hand side. The first step is to compose V with the transition mapping f . Since f is linear and f (\u03bd) > \u03bd, this composition has the effect of flattening V by rotating its graph to the left as illustrated in the following figure.\n\nNext, we take the convex combination with the step function u yielding the discontinuous decreasing function below.\n\nLastly, we concavify the resulting function as illustrated in the next figure, and we have the first iteration of the right-hand side operator. Notice that the function obtained differs from the initial candidate value function which is therefore not a fixed point and not the optimal value. In fact, since the beep-on mechanism discussed in the introduction yields a linear value function, we have shown that beep-on is not an optimal mechanism. 5\n\nLet us take stock of this first iteration and its implications for the optimal policy.\n\nRecall that the concavification represents the optimal lottery over interim beliefs, i.e.\n\nthe optimal message distribution. At beliefs along a segment where the concavification differs from the underlying function, the optimal policy is to randomize between the beliefs at the endpoints of the segment. Thus in the interval (p * , 1], the principal wants to send the agent to either \u00b5 = p * or \u00b5 = 1 with the appropriate probabilities. At beliefs along a segment where the concavifcation and the underlying function coincide it is optimal to send no message, as is here between \u00b5 = 0 and \u00b5 = p * .\n\nThe kink at p * is a remnant of the discontinuity in the flow payoff u. It is easy to see that this kink will re-appear at every step of the iteration, as well as the linear segment  5  We did not discuss how to interpret beep-on when the agent begins with a prior greater than zero. A fitting story is the following. The agent arrives to his office in the morning with a belief \u00b5 0 that there is an email already there waiting for him. If indeed there is an email it will beep when his computer boots up, i.e. with probability \u00b5 0 . If it does not, then his belief jumps to 0 and beep-on continues from there. Thus, the value at \u00b5 0 is just (1 -\u00b5 0 )V(0). from p * to 1. What subsequent iterations add are additional kinks, first at the point f -1 (p * ) in the second iteration, then at f -2 (p * ), etc. This occurs when we compose the drift mapping f with the previous iteration, shifting the kinks successively leftward.\n\nAs we continue to iterate these are the qualitative features of the fixed point to which we converge.  6 The optimal value function is represented in Figure  2 . Now consider what happens to the optimal value function when we shorten the period length. In the shorter time interval the belief moves less between periods and f approaches the identity mapping. This has two implications. First, the number of kinks multiplies and in the limit the value function is smooth to the left of p * . Second, the slope of the linear segment just to the left of p * approaches the slope of the linear segment from p * to 1. In the limit therefore, the value function is differentiable at p * and indeed at every belief, see Figure  3 .\n\nIt follows that to the left of p * , it is uniquely optimal to send no message. In the discrete-time approximation, the linear segments between kinks allowed for a multiplicity of optimal policies ranging from randomization across the whole segment to no message at all. In continuous time, the strict concavity implies that any non-degenerate lottery is suboptimal. To the right of p * , it remains optimal to randomize between p * and 1."
    },
    {
      "title": "6.2. Ergodic Process",
      "text": "In the beeps example the state s = 1 is absorbing. When on the other hand the process is ergodic a new issue must be addressed. If the agent's belief reaches \u00b5 = 1, it will begin to drift back to the interior, enabling further information revelation by the principal."
    },
    {
      "title": "How does the principal optimally incorporate this possibility?",
      "text": "To address this, consider now full-support transition probabilities so that the process admits a unique invariant distribution \u00b5 * and let's assume \u00b5 * > p * . foot_3\n\nWith \u00b5 * as the invariant distribution, the law of motion for beliefs is no longer monotonic. Beliefs greater than \u00b5 * move downward and beliefs below \u00b5 * move upward. The mapping f crosses the 45-degree line at \u00b5 * :\n\nTo aid the analysis, it helps to make a general observation about absorbing sets of beliefs. Say that an interval I \u2282 [0, 1] is absorbing under f if f (\u00b5) \u2208 I for all \u00b5 \u2208 I.\n\nAccording to the following lemma, if u is linear over an interval that is absorbing under f , then the value function must also be linear over that interval.\n\nLemma 1. Suppose that I is absorbing under f , and that u is linear over I. Then V is also linear on I.\n\nProof. Consider any candidate value function W which is linear over I. Since f is linear and u is linear over I, the formula\n\nmust be linear over I because it is the convex combination of two functions which are linear over that interval. (That the composition is linear follows from the assumption that I is absorbing and W is linear on I.)\n\nThe concavification of Equation 5 must be linear over I. Thus, iteration starting with W must always stay within the set of functions which are linear over I, i.e. the set of such functions is invariant under the value. Since the value mapping is a contraction, iteration converges globally to a fixed point, the fixed point must belong to any invariant set of functions.\n\nWhen \u00b5 * > p * the interval(p * , 1) is absorbing under f . Therefore the value function is linear there. It follows that the value function has the same shape as in the absorbing beeps problem. The optimal policy is therefore identical. In terms of implementation there is only one novelty: at \u00b5 = 1 beliefs are now trending downward, i.e. the agent knows that eventually there will be a transition from state 1 to state 0. According to the optimal policy, the instant beliefs move into the interior the principal is randomizing between the two endpoints p * and 1. This is achieved by a random message that reveals state changes but with false positives. As soon as a transition occurs the message is sent, but also each instant a transition does not occur the message is still sent but with a probability less than 1 calibrated so that the message induces interim belief p * . Since the message has false positives but not false negatives, the agent remains at \u00b5 = 1 as long as no message is heard.\n\nIn particular, the value V(  1 ) is positive now because the agent will periodically switch back to working when his beliefs jump down to p * ."
    },
    {
      "title": "6.3. Three States",
      "text": "When there are three states, S = {0, 1, 2} and two actions, the threshold is no longer a point but a line segment through the simplex of beliefs \u2206S. On one side of the line the agent takes action 0 and on the other side he takes action 1. The belief dynamics operate in a 2-dimensional simplex and can therefore be significantly more complicated. In this section I analyze a simple extension of the beeps problem to 3 states to illustrate. This example is special because the belief dynamics have a monotonicity property. Once the to zero at the s = 2 vertex, iterations lead to a piecewise linear value function with kinks along these segments.  8 The continuous time limit value function will therefore be linear along these line segments but strictly concave along rays toward the s = 2 vertex in the region below the threshold. It will be linear above the threshold and equal to zero at the s = 2 vertex. Thus, the optimal mechanism is a delayed beep signaling a past arrival of the second email.\n\nThe novelty that arises with three states concerns the evolution of beliefs and continuation values along the threshold. At the threshold the principal's policy is designed to maximize the probability that the agent continues working. As usual this is accomplished by sending the agent either to the threshold or to the most distant point in the shirk region (with the appropriate probability), in this case the vertex (0, 0, 1) where the agent is certain that two emails are waiting. This signal allows the agent to increase his belief that a single email has arrived and thus as long as the agent remains at the threshold, this belief will continue to trend upward, converging toward the right face of the simplex. Note that the right face, where the agent is certain that at least 1 email is waiting, is isomorphic to the original 1-dimensional beeps problem because the agent is simply waiting to find out if one more email arrives.\n\nThe following diagram shows the path of the agent's beliefs. The beliefs will follow this path until they reach the threshold, then remain on the path until a beep sounds.\n\nAs long as there is no beep the beliefs will converge asymptotically to the right face.\n\nIt follows that the length of the optimal delay must change as time passes. To see this, first consider the delay length at the point a where the beliefs first touch the threshold. Let's determine the delay length that keeps the agent on the threshold. Let t a denote the length of time it takes for beliefs to reach a from the vertex (1, 0, 0). If the beep has delay t a then when the agent is at a and hears no beep his updated beliefs continue to attach probability p * to the presence of 2 emails. The absence of a beep tells the agent that a second email did not arrive t a moments ago. The key question is what does this information tell the agent about the conditional distribution over the remaining states s = 0, s = 1. At that point in the past he was at the point (1, 0, 0). In particular he is certain that not even the first email had arrived. Learning that a second email did not arrive at that moment gives him no information about the other states since the simultaneous arrival of two emails has probability zero.\n\nThus, the absence of a beep tells him that his beliefs at the time t a ago were correct, and thus that his current beliefs should be updated from those prior beliefs based only on the information that a time period of length t a has passed during which he learns nothing about arrivals. By construction that updated belief assigns exactly p * to s = 2.\n\nBy contrast, consider a point like b, further to the right. At this point he attaches higher probability to the presence of a single email. Suppose the principal continued to use a beep with delay t a . What does the agent believe conditional on hearing no beep?\n\nHe learns that as of t a ago, the second email had not arrived. At that point in the past he assigned positive probability to the arrival of the first email. Of course the absence of the second email is information: it makes it less likely that the first email arrived.\n\nBut nevertheless he will continue to assign positive probability to the event that a first email had arrived t a ago. To obtain his current beliefs he will update that posterior based on knowing that t a time has passed. His updated belief that a second has arrived during that time will be larger when starting from a positive probability of a first email than when starting with probability zero. The latter starting point would lead him to p * , so using the delay length t a would put him above p * .\n\nTherefore, in order to keep the agent on the threshold, the delay length must be shorter the more time has passed. In particular if the second email arrives at time t \u2032 then the delay before beeping must be shorter than if the second email arrived at time t < t \u2032 . What happens to this delay length asymptotically as time increases? Since the beliefs are approaching probability 1 that exactly 1 email is waiting, the length of time it takes for the probability of a second email to equal p * converges to the length of time it would take if the agent were certain at the outset that the first email had already arrived. This is just the length of time for the arrival of a single email and that is the length t * from the 1-dimensional problem.\n\nWe can understand in these terms why the continuation value must decline as we move toward the right face. Because the delay is shortening but the arrival rate of email is constant, it follows that beeps are arriving more quickly and thus the agent is jumping sooner on average to the upper vertex."
    },
    {
      "title": "6.4. Three Actions",
      "text": "The solutions for each of the examples considered thus far are special in at least two senses. First, as was shown by Renault, Solan and Vieille (2014) the optimal mechanism is greedy; in particular it is nearly identical to the optimal mechanism in a static version of the problem. Second, the optimal policy is monotonic in that there is an initial phase of silence leading eventually to a phase of random messages. These features are typical of problems with two states and two actions. In this subsection I present the simplest 3 action problem in which the optimal mechanism is very different than the static problem and in particular consists of an early phase of messages followed by a duration of silence and then ultimately a final message phase. foot_5\n\nConsider the following indirect utility function with 3 steps:\n\nHere is a story that goes with it. When the agent is certain there is no email waiting he can work with full concentration. When there is a small chance of an email he is tempted to check but he resists the temptation. The effort spent on willpower makes him somewhat less productive. Finally when his beliefs cross the threshold (here p * = 1/2) he succumbs to temptation and stops working.\n\nThe interval (1/2, 1] is absorbing and u is linear there and so by Lemma 1 the value function has the familiar linear segment and the optimal mechanism randomizes between 1/2 and 1 when the beliefs are anywhere in between. To analyze the interval [0, 1/2) note that one feasible mechanism for the principal is to use the optimal mechanism from the basic beep example. That would yield a value function which is differentiable at the threshold 1/2. Even though this is not optimal for the present problem, it places a lower bound on the optimal value function. In particular, the optimal value function cannot have a kink at 1/2. The value function is in fact smooth and strictly concave over some interval (p * * , 1/2] so that no message is optimal there. However, unlike the original beeps problem, p * * \u0338 = 0 and on the interval [0, p * * ] the value function is again linear. Intuitively, randomizing between 0 and p * * allows the principal to stay at the point 0, earning the high flow payoff of 5/4 for some duration, whereas following the original beeps solution the beliefs would spend only an instant there.\n\nWith these observations in hand we can now show formally how the optimal mechanism changes in the three action version. Indeed, if we take the original beeps value function V as a candidate continuous-time value function for the three-action problem, the HJB equation tells us to compute its time-derivative and add it to the three-step u in Equation  6 . We obtain exactly the same graph except that the height at \u00b5 = 0 jumps up by 1/4. When we concavify:\n\nWe see that we do not recover V but instead there is now a linear segment over an initial interval. This gives us a hint that the optimal value function will have a similar shape. We can solve the model by picking the p * * that equates these and thus produces a fixed point.\n\nV(p * * ) + p * * V \u2032 (p * * ) = 5/4 + V \u2032 (p * * )\u03bb.\n\nA distinguishing feature of this example is that the optimal policy uses both false negatives and false positives. In the initial phase, the signals that move from 0 to p * * are false positives: conditional on the agent receiving this signal he changes his behavior but there is a probability 1p * * that this signal was received even if no email arrived.\n\nOn the other hand, once the agent reaches \u00b5 = 1/2 the optimal policy reverts to the false negatives from the original email problem.\n\nfunctions of the state change date, \u03d5. In particular,\n\nThe graphs of these functions are depicted in Figure  4 . Highlighted in blue is the graph of max ri , the date at which a bank run occurs. First, notice that a bank run cannot occur prior to the date t * * . It is the unique intersection of the two curves above, t * * = r1 (\u03d5 * * ) = r2 (\u03d5 * * ). Since this occurs prior to t * it"
    },
    {
      "text": "Figure 2: The optimal value function for the Beeps problem."
    },
    {
      "text": "Figure 3: The continuous time value function."
    },
    {
      "text": "And indeed we can reduce the functional fixed-point problem in the HJB equation to a parametric equation with a single unknown p * * . For suppose we pick a threshold p * * where the mechanism switches from randomizing to silence. Knowing that the value function will be smooth at that point tells us what the slope of the initial linear segment must be. It must be the slope of the email value function at p * * , namely V \u2032 (p * * ). This therefore tells us a candidate value for V(0):V(p * * ) + p * * V \u2032 (p * * )Now when we take the resulting candidate value function and feed it into the righthand side of the HJB equation we obtain a new value for V(0):u(0) + V \u2032 (p * * )\u03bb"
    },
    {
      "text": "Figure 4: Beep times ri as a function of the state change time \u03d5 for the optimal multiagent mechanism."
    },
    {
      "text": "beliefs leave the region where the agent takes a given action they never return (absent information from the principal). With two states the belief dynamics always have this property. With three states the beliefs may cycle and move up and down the steps of the principal's payoff function u on their path toward the invariant distribution. Such problems are considerably more complex to solve. In independent work Renault, Solan   and Vieille (2014) analyze the many-state problem in more detail.\n\nConsider a variation of the email problem in which the agent wishes to check as soon as the probability is sufficiently large, at least p * , that there are at least two emails to read. Let s \u2208 S = {0, 1, 2} denote the number of unread emails currently in the inbox, where s = 0 and s = 1 indicate the exact number and s = 2 indicates 2 or more.\n\nMaintain the assumption that email arrives at rate \u03bb. The following diagram illustrates the situation. The simplex is the set of possible beliefs for the agent and the line depicts the threshold above which the agent checks. The arrows show the flow of the agent's beliefs when the principal withholds information. The constant arrival of email implies that the beliefs move up and to the right. This analysis of this problem follows similar lines as the two-state email beep problem.\n\nIn the diagram below the lines represent points which lead by iterations of f to the threshold line. If we begin with a candidate value function which is linear and equal 7 Appendix For The Multi-Agent Section"
    },
    {
      "title": "7.1. Construction Of The Mechanism",
      "text": "The two-agent mechanism is constructed by the following logic. Let's consider mechanisms in which agent 1 has a beep with a delay t * , and agent 2 withdraws immediately if the state change happens after t * . Within mechanisms with these properties, if the state changes after date t * , i.e. \u03d5 > t * then agent 1 will be the last to withdraw and the date of the bank run is \u03d5 + t * . It remains only to specify the date at which 2 withdraws if the state change happens before t * . Let us define the function \u03c8(\u03d5) to give the date at which agent 2 withdraws as a function of the state change date \u03d5. The only requirement of the random variable \u03c8 is that its distribution be exponential with parameter \u03bb, to satisfy incentive compatibility for agent 2.\n\nThen, conditional on \u03d5 \u2264 t * agent 2 switches to run at r2 = \u03c8(\u03d5), agent 1 switches to run at r1 = \u03d5 + t * and a bank run occurs at the following time max {r 1 , r2 } = max {\u03d5 + t * , \u03c8(\u03d5)} with conditional expected value (conditional on the state change occurring prior to t * )\n\nwhere\n\nis the conditional CDF of max {r 1 , r2 }.\n\nFrom the theory of copulae in probability theory, and in particular Sklar's Theorem and the Fr\u00e9chet-Hoeffding Theorem (see Nelsen (1999)) we can minimize G pointwise, and therefore maximize the expected delay length in Equation 7 by adopting as the the joint distribution for \u03d5 and \u03c8 (whose marginal distributions we are given) the Fr\u00e9chet-Hoeffding lower bound. In this case the lower bound is achieved by setting\n\nfor all \u03d5 \u2264 t * where F is the (marginal) CDF of \u03d5, (i.e. the CDF of the exponential distribution with parameter \u03bb.) To verify, conditional on \u03d5 \u2264 t * the distribution of"
    }
  ],
  "references": [
    {
      "title": "Bayesian persuasion",
      "authors": [
        "Emir Kamenica",
        "Matthew Gentzkow"
      ],
      "year": 2011,
      "doi": "10.1257/aer.101.6.2590",
      "journal": "American Economic Review",
      "volume": "101",
      "issue": "6",
      "raw": "Bayesian persuasion \n\t\t \n\t\t\t Emir Kamenica \n\t\t \n\t\t \n\t\t\t Matthew Gentzkow \n\t\t \n\t\t 10.1257/aer.101.6.2590 \n\t \n\t \n\t\t American Economic Review \n\t\t \n\t\t\t 101 \n\t\t\t 6 \n\t\t\t 2011 \n\t\t \n\t \n\t Kamenica, Emir, and Matthew Gentzkow. 2011. \"Bayesian persuasion.\" American Eco- nomic Review, 101(6)."
    },
    {
      "title": "An introduction to copulas",
      "authors": [
        "Roger Nelsen"
      ],
      "year": 1999,
      "doi": "10.1007/978-1-4757-3076-0_4",
      "raw": "An introduction to copulas \n\t\t \n\t\t\t Roger B Nelsen \n\t\t \n\t\t 10.1007/978-1-4757-3076-0_4 \n\t\t \n\t\t\t 1999 \n\t\t\t Springer \n\t\t \n\t \n\t Nelsen, Roger B. 1999. An introduction to copulas. Springer."
    },
    {
      "title": "Optimal Dynamic Information Provision",
      "authors": [
        "J\u00e9r Renault",
        "Eilon \u00d4me",
        "Nicolas Solan"
      ],
      "year": 2014,
      "doi": "10.1016/j.geb.2017.04.010",
      "raw": "J\u00e9r Renault \n\t\t \n\t\t \n\t\t\t Eilon \u00d4me \n\t\t \n\t\t \n\t\t\t Nicolas Solan \n\t\t \n\t\t \n\t\t\t Vieille \n\t\t \n\t\t 10.1016/j.geb.2017.04.010 \n\t\t arXiv:1407.5649 \n\t\t Optimal Dynamic Information Provision \n\t\t \n\t\t\t 2014 \n\t\t \n\t \n\t arXiv preprint \n\t Renault, J\u00e9r \u00f4me, Eilon Solan, and Nicolas Vieille. 2014. \"Optimal Dynamic Informa- tion Provision.\" arXiv preprint arXiv:1407.5649."
    }
  ],
  "num_references": 3,
  "figures": [
    {
      "caption": "Figure 2 :",
      "description": "Figure 2: The optimal value function for the Beeps problem."
    },
    {
      "caption": "Figure 3 :",
      "description": "Figure 3: The continuous time value function."
    },
    {
      "description": "And indeed we can reduce the functional fixed-point problem in the HJB equation to a parametric equation with a single unknown p * * . For suppose we pick a threshold p * * where the mechanism switches from randomizing to silence. Knowing that the value function will be smooth at that point tells us what the slope of the initial linear segment must be. It must be the slope of the email value function at p * * , namely V \u2032 (p * * ). This therefore tells us a candidate value for V(0):V(p * * ) + p * * V \u2032 (p * * )Now when we take the resulting candidate value function and feed it into the righthand side of the HJB equation we obtain a new value for V(0):u(0) + V \u2032 (p * * )\u03bb"
    },
    {
      "caption": "Figure 4 :",
      "description": "Figure 4: Beep times ri as a function of the state change time \u03d5 for the optimal multiagent mechanism."
    }
  ],
  "num_figures": 4,
  "formulas": [
    {
      "text": "\u03c9 = - log(1 -p * ) \u03bb(1 -z)"
    },
    {
      "text": "e -\u03bbz\u03c9 ."
    },
    {
      "text": "1 \u03bbz - \u03c9 e \u03bbz\u03c9 -1"
    },
    {
      "text": "\u03c9e -\u03bbz\u03c9 + ( 1 \u03bbz - \u03c9 e \u03bbz\u03c9 -1 ) ( 1 -e -\u03bbz\u03c9"
    },
    {
      "text": "1 -(1 -p * ) -z z-1"
    },
    {
      "text": "J(t, \u00b5 t ) = E \u221e \u2211 s=0 e -r(t+sh) u(\u00b5 t+sh ) \u2022 h + O(h 2 ). E q [ e -rt u(\u03bd)h + e -r(t+h) V( f (\u03bd)) ] + O(h 2 )."
    },
    {
      "text": "V(\u00b5) = max q\u2208\u2206(\u2206S) Eq=\u00b5 E q [ u(\u03bd)h + e -rh V( f (\u03bd)) ] + O(h 2 )."
    },
    {
      "text": "e -rh V( f (\u03bd)) = e -rh [ V(\u03bd) + V \u2032 (\u03bd) d\u03bd dt h ] + O(h 2 ), so V(\u00b5) = max q\u2208\u2206(\u2206S) Eq=\u00b5 E q { u(\u03bd)h + e -rh [ V(\u03bd) + V \u2032 (\u03bd) d\u03bd dt h ]} + O(h 2 )."
    },
    {
      "text": "u(\u03bd)h + e -rh V( f (\u03bd)) \u2264 E q * (\u03bd) [ u(\u03bd \u2032 )h + e -rh V( f (\u03bd \u2032 )) ] = max q\u2208\u2206(\u2206S) Eq=\u03bd E q [ u(\u03bd \u2032 )h + e -rh V( f (\u03bd \u2032 ))"
    },
    {
      "text": "V(\u00b5) = E q * [ u(\u03bd)h + e -rh V( f (\u03bd)) ] \u2264 E q * E q * (\u03bd) [ u(\u03bd \u2032 )h + e -rh V( f (\u03bd \u2032 )) ] = E q * V(\u03bd)"
    },
    {
      "text": "V(\u00b5) \u2265 E q * V(\u03bd)"
    },
    {
      "text": "( 1 -e -rh ) V(\u00b5) = max q\u2208\u2206(\u2206S) Eq=\u00b5 E q [ u(\u03bd)h + e -rh V \u2032 (\u03bd) d\u03bd dt h ] + O(h 2 )."
    },
    {
      "text": "rV(\u00b5 t ) = max q\u2208\u2206(\u2206S) Eq=\u00b5 E q [ u(\u03bd) + V \u2032 (\u03bd) d\u03bd dt ] or rV = cav [ u + V \u2032 \u2022 d\u03bd dt"
    },
    {
      "text": "V(p * ). \u222b \u221e 0 \u222b t 0 e -rs \u03bbe -\u03bbt dsdt = \u222b \u221e 0 [ r -1 e -rs | s=t s=0 ] \u03bbe -\u03bbt dt = \u222b \u221e 0 1 -e -rt r \u03bbe -\u03bbt dt = r -1 [ 1 - \u222b \u221e 0 e -rt \u03bbe -\u03bbt dt ] = r -1 [ 1 -\u03bb \u222b \u221e 0 e -(r+\u03bb)t dt ] = r -1 [ 1 + ( \u03bb r + \u03bb e -(r+\u03bb)t | t=\u221e t=0 )] = r -1 [ 1 - \u03bb r + \u03bb ] = 1 r + \u03bb"
    },
    {
      "text": "V(\u00b5) = \u222b \u03c4(\u00b5) 0 e -rt dt + e -r\u03c4(\u00b5) 1 r + \u03bb = 1 r [ 1 -e -r\u03c4(\u00b5) + e -r\u03c4(\u00b5) r r + \u03bb ] (1)"
    },
    {
      "text": "u + V \u2032 \u2022 d\u03bd dt (2)"
    },
    {
      "text": "1 + 1 r [ re -r\u03c4(\u00b5) \u2022 d\u03c4 d\u00b5 -re -r\u03c4(\u00b5) r r + \u03bb \u2022 d\u03c4 d\u00b5 ] d\u03bd dt = 1 + [ e -r\u03c4(\u00b5) -e -r\u03c4(\u00b5) r r + \u03bb ] d\u03c4 d\u00b5 \u2022 d\u03bd dt"
    },
    {
      "text": "-V(p * ) 1 -p * . Thus u + V \u2032 \u2022 d\u03bd dt = -V(p * ) 1 -p * \u03bb (1 -\u00b5)"
    },
    {
      "text": "f (\u00b5) = \u00b5 \u2022 \u03c7."
    },
    {
      "text": "TV = cav [(1 -\u03b4)u + \u03b4 (V \u2022 f )] ."
    },
    {
      "text": "1. If V \u2265 V \u2032 then TV \u2265 TV \u2032 , 2. If c is a constant then T(V + c) \u2264 TV + \u03b4c."
    },
    {
      "text": "If V is convex then so is (1 -\u03b4)u + \u03b4 \u2022 f ."
    },
    {
      "text": "W(\u00b5) = u(\u00b5) -W \u2032 (\u00b5) \u2022 d\u00b5 dt (3)"
    },
    {
      "text": "X(\u03bd * ) = u(1) - X(\u03bd * ) -W(\u03bd * ) (1 -\u03bd * ) . ( 4"
    },
    {
      "text": ")"
    },
    {
      "text": "X(\u03bd * ) = u(1) 1 + 1 (1-\u03bd * ) + 1 (1-\u03bd * ) W(\u03bd * ) 1 + 1 (1-\u03bd * ) = (1 -\u03bd * )u(1) + W(\u03bd * ) 2 -\u03bd * 2"
    },
    {
      "text": "W(\u00b5) = 6\u00b5 1/2 + 8\u00b5 5/4 + 3\u00b5 2 72 ."
    },
    {
      "text": "W \u2032 (\u03bd * ) = X(\u03bd * ) -W(\u03bd * ) 1 -\u03bd * ."
    },
    {
      "text": "* ) \u2265 W(1) > W(\u03bd * ) + W \u2032 (\u03bd * )(1 -\u03bd * )."
    },
    {
      "text": "W(1) + e -\u03c4(\u00b5) [pW(1) + (1 -p)W(\u03bd * ) -W(\u00b5)]"
    },
    {
      "text": "one solution because W \u2032 (0) is infinite (because u \u2032 (0) is infinite) and X(0) is finite. Re- arrange the equation to obtain (2 -\u03bd * )W \u2032 (\u03bd * ) + W(\u03bd * ) -u(1) = 0. X \u2032 (\u03bd * ) = (2 -\u03bd * )W \u2032 (\u03bd * ) + W(\u03bd * ) -u(1) (2 -\u03bd * ) 2"
    },
    {
      "text": "V(\u00b5) = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 W(\u00b5) if \u00b5 \u2264 \u03bd * L(\u00b5) if \u00b5 > \u03bd * ."
    },
    {
      "text": "U(\u00b5) = u(\u00b5) -V \u2032 (\u00b5) \u2022 d\u00b5 dt ."
    },
    {
      "text": "X(\u03bd * ) (Equation 4) ensures that U(1) = V(1) because X(\u03bd * )-W(\u03bd * ) (1-\u03bd * )"
    },
    {
      "text": "V(\u03bd * ) = u(\u03bd * ) + V \u2032 (\u03bd * ) d\u00b5 dt (\u03bd * ) and V(1) = u(1) + V \u2032 (1) d\u00b5 dt (1)"
    },
    {
      "text": "V = l + V \u2032 \u2022 d\u00b5 dt"
    },
    {
      "text": "U(\u00b5) = u(\u00b5) + V \u2032 (\u00b5) d\u00b5 dt (\u00b5). So if we can show that l \u2265 u over the range [\u03bd * , 1] then it follows that U \u2264 V."
    },
    {
      "text": "u \u2032 ( \u03bd) = u(1) -u( \u03bd) 1 - \u03bd ."
    },
    {
      "text": "f (\u03bd t ) = \u03bd t + (1 -\u03bd t )M"
    },
    {
      "text": "u(\u03bd) = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 1 if \u03bd \u2264 p * 0 otherwise"
    },
    {
      "text": "V = cav [(1 -\u03b4)u + \u03b4 (V \u2022 f )] ."
    },
    {
      "text": "(1 -\u03b4)u + \u03b4 (W \u2022 f ) (5)"
    },
    {
      "text": "u(\u03bd) = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 5/4 if \u03bd = 0 1 if \u03bd \u2208 (0, 1/2] 0 otherwise (6)"
    },
    {
      "text": "r1 (\u03d5) = \u03d5 + t * r2 (\u03d5) = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 \u03d5 if \u03d5 \u2265 t * -1 \u03bb log ( F(\u03d5) p * ) + t * if \u03d5 < t *"
    }
  ],
  "num_formulas": 44,
  "num_citations": 3,
  "notes": [
    "[raw_affiliation] Professor of Economics , Northwestern University.",
    "[raw_affiliation] Professor of Economics , Northwestern University.",
    "In fact if we were to consider a static version of this problem, we would apply the methods of Kamenica and Gentzkow (2011) and consider the concavification of u. The concavification would coincide with u to the left of \u03bd, and would be linear to the right. Thus, \u03bd would be the target belief of a partially informative policy in the static problem.",
    "Specifically, \u03bd \u2248 0.031 while \u03bd * \u2248 0.058.",
    "The number of kinks will be the maximum index k such that f k (0) \u2264 p * .",
    "If \u00b5 * \u2264 p * the problem is simpler and less interesting. Eventually the beliefs will reach p * . Once there the principal can cease sending messages and the agent will remain at p * and work forever. The only problem to solve is how to get the agent to start working as quickly as possible when he begins away from p * . It can be shown that this is accomplished by following exactly the strategy from the original beeps example.",
    "These are not the level sets. As we will show below, the value declines as we move to the right along the p * line. This pattern will thus be preserved at all of its inverse images under f .",
    "Renault, Solan and Vieille (2014) also present an example in which the optimal mechanism is nongreedy involving two actions but three states. Two-state problems are generally easier to analyze so the example below is simpler.",
    "[raw_reference] Kamenica, Emir, and Matthew Gentzkow. 2011. \"Bayesian persuasion.\" American Eco- nomic Review, 101(6).",
    "[raw_reference] Nelsen, Roger B. 1999. An introduction to copulas. Springer.",
    "[report_type] arXiv preprint",
    "[raw_reference] Renault, J\u00e9r \u00f4me, Eilon Solan, and Nicolas Vieille. 2014. \"Optimal Dynamic Informa- tion Provision.\" arXiv preprint arXiv:1407.5649."
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  },
  "journal": "American Economic Review",
  "volume": "101",
  "issue": "6",
  "pages": "2590-2615",
  "zotero_recovery": {
    "fields_recovered": [
      "journal"
    ],
    "timestamp": "2025-09-01T11:08:22.658327",
    "zotero_item_type": "journalArticle"
  }
}
