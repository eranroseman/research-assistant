{
  "paper_id": "VLJ5GQT6",
  "title": "Measuring Engagement in eHealth and mHealth Behavior Change Interventions: Viewpoint of Methodologies",
  "abstract": "Engagement in electronic health (eHealth) and mobile health (mHealth) behavior change interventions is thought to be important for intervention effectiveness, though what constitutes engagement and how it enhances efficacy has been somewhat unclear in the literature. Recently published detailed definitions and conceptual models of engagement have helped to build consensus around a definition of engagement and improve our understanding of how engagement may influence effectiveness. This work has helped to establish a clearer research agenda. However, to test the hypotheses generated by the conceptual modules, we need to know how to measure engagement in a valid and reliable way. The aim of this viewpoint is to provide an overview of engagement measurement options that can be employed in eHealth and mHealth behavior change intervention evaluations, discuss methodological considerations, and provide direction for future research. To identify measures, we used snowball sampling, starting from systematic reviews of engagement research as well as those utilized in studies known to the authors. A wide range of methods to measure engagement were identified, including qualitative measures, self-report questionnaires, ecological momentary assessments, system usage data, sensor data, social media data, and psychophysiological measures. Each measurement method is appraised and examples are provided to illustrate possible use in eHealth and mHealth behavior change research. Recommendations for future research are provided, based on the limitations of current methods and the heavy reliance on system usage data as the sole assessment of engagement. The validation and adoption of a wider range of engagement measurements and their thoughtful application to the study of engagement are encouraged.",
  "year": 2016,
  "date": "2016-03",
  "journal": "J Nutr Educ Behav",
  "publication": "J Nutr Educ Behav",
  "authors": [
    {
      "forename": "Camille",
      "surname": "Short",
      "name": "Camille Short",
      "affiliation": "1  Freemasons Foundation Centre for Men's Health , School of Medicine , University of Adelaide , Adelaide , Australia \n\t\t\t\t\t\t\t\t Freemasons Foundation Centre for Men's Health \n\t\t\t\t\t\t\t\t School of Medicine \n\t\t\t\t\t\t\t\t University of Adelaide \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Adelaide \n\t\t\t\t\t\t\t\t\t Australia",
      "email": "camille.short@adelaide.edu.au"
    },
    {
      "forename": "Ann",
      "surname": "Desmet",
      "name": "Ann Desmet",
      "affiliation": "2  Department of Movement and Sports Sciences , Ghent University , Brussels , Belgium \n\t\t\t\t\t\t\t\t Department of Movement and Sports Sciences \n\t\t\t\t\t\t\t\t Ghent University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Brussels \n\t\t\t\t\t\t\t\t\t Belgium"
    },
    {
      "forename": "Catherine",
      "surname": "Woods",
      "name": "Catherine Woods",
      "affiliation": "3  Health Research Institute , Centre for Physical Activity and Health , Department of Physical Education and Sport Sciences , University of Limerick , Limerick , Ireland \n\t\t\t\t\t\t\t\t Health Research Institute \n\t\t\t\t\t\t\t\t Centre for Physical Activity and Health \n\t\t\t\t\t\t\t\t Department of Physical Education and Sport Sciences \n\t\t\t\t\t\t\t\t University of Limerick \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Limerick \n\t\t\t\t\t\t\t\t\t Ireland"
    },
    {
      "forename": "Susan",
      "surname": "Williams",
      "name": "Susan Williams",
      "affiliation": "4  Physical Activity Research Group , Appleton Institute , School of Health , Medical and Applied Sciences , Central Queensland University , Rockhampton , Australia \n\t\t\t\t\t\t\t\t School of Health \n\t\t\t\t\t\t\t\t Medical and Applied Sciences \n\t\t\t\t\t\t\t\t Physical Activity Research Group \n\t\t\t\t\t\t\t\t Appleton Institute \n\t\t\t\t\t\t\t\t Central Queensland University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Rockhampton \n\t\t\t\t\t\t\t\t\t Australia"
    },
    {
      "forename": "Carol",
      "surname": "Maher",
      "name": "Carol Maher",
      "affiliation": "5  Alliance for Research in Exercise, Nutrition and Activity , Sansom Institute , School of Health Sciences , University of South Australia , Adelaide , Australia \n\t\t\t\t\t\t\t\t Alliance for Research in Exercise, Nutrition and Activity \n\t\t\t\t\t\t\t\t School of Health Sciences \n\t\t\t\t\t\t\t\t Sansom Institute \n\t\t\t\t\t\t\t\t University of South Australia \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Adelaide \n\t\t\t\t\t\t\t\t\t Australia"
    },
    {
      "forename": "Anouk",
      "surname": "Middelweerd",
      "name": "Anouk Middelweerd",
      "affiliation": "6  Department of Rheumatology , Erasmus Medical Center , Rotterdam , Netherlands \n\t\t\t\t\t\t\t\t Department of Rheumatology \n\t\t\t\t\t\t\t\t Erasmus Medical Center \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Rotterdam \n\t\t\t\t\t\t\t\t\t Netherlands"
    },
    {
      "forename": ";",
      "surname": "Andre",
      "name": "; Andre"
    },
    {
      "forename": "Matthias",
      "surname": "M\u00fcller",
      "name": "Matthias M\u00fcller",
      "affiliation": "7  Saw Swee Hock School of Public Health , National University of Singapore , Singapore , Singapore \n\t\t\t\t\t\t\t\t Saw Swee Hock School of Public Health \n\t\t\t\t\t\t\t\t National University of Singapore \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Singapore \n\t\t\t\t\t\t\t\t\t Singapore"
    },
    {
      "forename": "Petra",
      "surname": "Wark",
      "name": "Petra Wark",
      "affiliation": "9  Centre for Innovative Research Across the Life Course , Faculty of Health and Life Sciences , Coventry University , Coventry , United Kingdom \n\t\t\t\t\t\t\t\t Centre for Innovative Research Across the Life Course \n\t\t\t\t\t\t\t\t Faculty of Health and Life Sciences \n\t\t\t\t\t\t\t\t Coventry University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Coventry \n\t\t\t\t\t\t\t\t\t United Kingdom"
    },
    {
      "surname": "Vandelanotte",
      "name": "Vandelanotte",
      "affiliation": "4  Physical Activity Research Group , Appleton Institute , School of Health , Medical and Applied Sciences , Central Queensland University , Rockhampton , Australia \n\t\t\t\t\t\t\t\t School of Health \n\t\t\t\t\t\t\t\t Medical and Applied Sciences \n\t\t\t\t\t\t\t\t Physical Activity Research Group \n\t\t\t\t\t\t\t\t Appleton Institute \n\t\t\t\t\t\t\t\t Central Queensland University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Rockhampton \n\t\t\t\t\t\t\t\t\t Australia"
    },
    {
      "forename": "Louise",
      "surname": "Poppe",
      "name": "Louise Poppe",
      "affiliation": "2  Department of Movement and Sports Sciences , Ghent University , Brussels , Belgium \n\t\t\t\t\t\t\t\t Department of Movement and Sports Sciences \n\t\t\t\t\t\t\t\t Ghent University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Brussels \n\t\t\t\t\t\t\t\t\t Belgium"
    },
    {
      "forename": "Melanie",
      "surname": "Hingle",
      "name": "Melanie Hingle",
      "affiliation": "10  Department of Nutritional Sciences , College of Agriculture & Life Sciences , University of Arizona , Tucson , AZ , United States \n\t\t\t\t\t\t\t\t Department of Nutritional Sciences \n\t\t\t\t\t\t\t\t College of Agriculture & Life Sciences \n\t\t\t\t\t\t\t\t University of Arizona \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Tucson \n\t\t\t\t\t\t\t\t\t AZ \n\t\t\t\t\t\t\t\t\t United States"
    },
    {
      "forename": "Rik",
      "surname": "Crutzen",
      "name": "Rik Crutzen",
      "affiliation": "11  Department of Health Promotion , Care and Public Health Research Institute , Maastricht University , Maastricht , Netherlands \n\t\t\t\t\t\t\t\t Department of Health Promotion \n\t\t\t\t\t\t\t\t Care and Public Health Research Institute \n\t\t\t\t\t\t\t\t Maastricht University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Maastricht \n\t\t\t\t\t\t\t\t\t Netherlands"
    },
    {
      "forename": "E",
      "surname": "Short",
      "name": "E Short"
    },
    {
      "forename": "Andre",
      "surname": "M\u00fcller",
      "name": "Andre M\u00fcller"
    },
    {
      "forename": "Corneel",
      "surname": "Vandelanotte",
      "name": "Corneel Vandelanotte"
    },
    {
      "surname": "Originally",
      "name": "Originally"
    }
  ],
  "doi": "",
  "sections": [
    {
      "title": "Introduction",
      "text": "Electronic health (eHealth) and mobile health (mHealth) behavioral interventions offer wide-reaching support at a low cost, while retaining the capacity to provide comprehensive, ongoing, tailored, and interactive support necessary for improving public health  [1, 2] . Although there is evidence that eHealth and mHealth behavior change interventions can be effective, low levels of adherence and high levels of attrition have been commonly reported  [1] [2] [3] . In response, there have been calls to design and implement more engaging interventions to address these concerns  [4] [5] [6] .\n\nIt is generally agreed that a certain level of engagement is necessary for intervention effectiveness. However, there is a lack of clarity on how to conceptualize engagement. Some researchers have defined engagement solely as a psychological process relating to user perceptions and experience, whereas others consider engagement a purely behavioral construct, synonymous with intervention usage  [4, 7] . Consequently, it is often confused with adherence, which refers to whether the intervention is used as intended by the developers  [3, 8, 9] . There have also been interdisciplinary differences. Behavioral scientists tend to characterize good engagement as high acceptability, satisfaction, or intervention adherence, whereas computer scientists tend to consider high engagement as a mental state associated with increased attention and enjoyment  [4] . To consolidate these viewpoints and provide a less fragmented foundation for future research, 2 new conceptual models of engagement have been proposed  [4, 5] .\n\nUsing a process of expert consensus, Yardley et al  [5]  proposed distinguishing between micro-and macrolevel engagement when examining the relationships between the user experience, usage, and behavior change. Microlevel engagement refers to the moment-to-moment engagement with the intervention, including the extent of use of the intervention (eg, number of activities completed) and the user experience (eg, level of user interest and attention when completing activities). Macrolevel engagement is defined as the depth of involvement with the behavior change process (eg, extent of motivation for changing behavior) and is linked to the behavioral goals of the intervention. The timing and relationship between micro and macro forms of engagement depend on the intervention, the user, and the broader context. Yardley's model suggests that after a period of effective engagement at the microlevel, the user may disengage from the platform but still be immersed in the behavior change process. Perski et al  [4]  offer a similar but more extensive framework based on a systematic review. Similar to Yardley et al, they define engagement as both the extent of usage and a subjective experience but refine this further by characterizing the subjective experience as being related specifically to attention, interest, and affect. These constructs are said to capture the cognitive and emotional aspects of engagement as they are described in computer science disciplines (eg, flow, immersion, and presence), all of which relate to a level of absorption and preoccupation (see Table  1  for definitions of these constructs). According to Perksi et al  [4] , high engagement influences behavior change through its influence on the determinants of behavior (similar to macroengagement, as described by Yardley et al). Engagement itself is hypothesized to be influenced by intervention features such as content, mode of delivery, and contextual features such as the physical environment (eg, internet access) and individual characteristics (eg, internet self-efficacy).\n\nBoth Perski et al and Yardley et al extend previous models  [6, [9] [10] [11]  by considering the interaction between usage and psychological processes. By doing so, both models suggest that intervention usage may be a useful indicator of overall engagement with the intervention but is not a valid indicator of engagement in the behavior change process per se. Perski et al also highlight potential moderators and mediators of the engagement process and outline possible pathways in which engagement can influence overall intervention efficacy. These models serve as useful tools to refine and test hypotheses about how to influence engagement and how engagement impacts efficacy, which is necessary if we are to advance eHealth and mHealth behavioral science. However, an understanding of how to measure engagement is needed to test these models.\n\nBasic overviews of the types of measures to assess engagement in eHealth and mHealth interventions have been provided by Yardley et al  [5]  as well as Perski et al  [4] . Yardley et al briefly described the potential usefulness of different measurement types, including qualitative measures, self-report questionnaires, ecological momentary assessment, system usage data, sensor data, and psychophysiological measures. Perski et al identified over 100 studies related to engagement and noted the data collection methods used (eg, survey, website logs, and face-to-face interviews) in each study. Our aim is to extend their work by providing a comprehensive overview of the measurement options currently available. Our overall goal is to summarize and appraise measures of engagement used in eHealth and mHealth research and to highlight future areas of research when evaluating engagement in eHealth and mHealth behavior change interventions. We anticipate this will serve as a useful primer for those interested in the study of engagement and help to advance the field of eHealth and mHealth and behavior change by facilitating the use and validation of a wider range of engagement measurements and their thoughtful application to the study of engagement. identified by Perski et al  [4]  as well as other systematic reviews and published articles known to us through our former work in the field  [12] [13] [14] . A data extraction table (see Multimedia Appendix 1) focusing on measurement type, engagement domain, and validity information was used to extract, sort, and explore measurement information to aid synthesis. During the writing and revision process, we searched for additional articles using Google Scholar and reran Perski's  [4]  original search strategy on MEDLINE and PsycINFO to identify more recent relevant literature. Readers should, therefore, consider this as a comprehensive, but not exhaustive, overview of the literature.\n\nIn line with Yardley et al's suggestions  [5] , our overview focuses on a wide range of methods to measure engagement. These include qualitative measures, self-report questionnaires, ecological momentary assessment, psychophysiological measures, as well as the analysis of system usage data, sensor data, and social media data. Methods that capture microlevel constructs were included in our synthesis if they were related to emotional, cognitive, or behavioral aspects of the user experience that could be characterized as interest, attention, affect, or intervention usage. This includes the constructs of flow, cognitive absorption, presence, and immersion, which have been commonly used in other disciplines. An overview of definitions for each of these constructs is provided in Table  1 . Macrolevel measures were included if they related specifically to engagement in the behavior change process because of the digital intervention or its features. A single author initially drafted each section below, with all other authors providing a critical review.\n\nTable  1 . Definitions for constructs used to describe the emotional, cognitive, or behavioral aspects of engagement in previous literature."
    },
    {
      "title": "Description Construct",
      "text": "Individual interest is an enduring preference for certain topics and activities. It is impacted by pre-existing knowledge, personal experiences, and emotions. Situational interest is an emotional state brought about by situational stimuli (eg, the unexpectedness of information). It is evoked spontaneously and is presumed to be transitory. Both types of interest are related to liking and willful engagement in a cognitive activity that affects the use of specific learning strategies and how we allocate attention  [15, 16] ."
    },
    {
      "title": "Interest",
      "text": "A state of focused awareness of specific perceptual information  [17] . Focalization and concentration of consciousness are the essence of attention. Paying attention implies withdrawal from some perceptual information to deal effectively with others  [18] ."
    },
    {
      "title": "Attention",
      "text": "Affect is an intrinsic part of the sensory experience. It represents how an object or situation impacts how a person feels. It can be described by 2 psychological properties: hedonic valence (pleasure/displeasure) and arousal (activation/sleepy). It can be a central or background feature of consciousness, depending on where and how attention is applied  [19, 20] ."
    },
    {
      "title": "Affect",
      "text": "Flow refers to an optimal state that arises when an individual is deeply absorbed in a task. It is characterized by enjoyment, focused attention, absorption, and distorted time perception and is considered intrinsically rewarding. It assumes the complete absence of negative affect  [21] ."
    },
    {
      "title": "Flow",
      "text": "Cognitive absorption is a state of deep involvement, similar to flow, though it does not assume intrinsic motivation or the complete absence of negative affect. Cognitive absorption may still occur when a user is frustrated (and, therefore, the experience is not optimal) or extrinsically motivated (eg, by winning a competition with friends;  [22] )."
    },
    {
      "title": "Cognitive absorption",
      "text": "Immersion is also similar to cognitive absorption and flow, though it is often used to describe a less extreme experience of engagement, one where one may still have some awareness of one's surroundings  [22, 23] ."
    },
    {
      "title": "Immersion",
      "text": "The term presence has been popular since the development of virtual reality technologies. Definitional consensus for presence is still emerging, though it is often described as the psychological sense of being there  [24] ."
    },
    {
      "title": "Presence",
      "text": "The extent to which the intervention has been observed or interacted with by the user. It is made up of several components, including frequency of use, time spent on the intervention, and the type of interaction participated in. This is distinct from intended usage, which is the way in which users should utilize the intervention to derive the minimum benefit, as defined by the intervention developers  [3] ."
    },
    {
      "title": "Intervention usage"
    },
    {
      "title": "Overview of Engagement Measures"
    },
    {
      "title": "Qualitative Methods"
    },
    {
      "title": "Focus Areas",
      "text": "Qualitative measures enable evaluation of micro-and macrolevel engagement and include methods such as focus groups, observations, interviews, and think-aloud activities (Table  2 ). At the microlevel, they allow for an in-depth account of the users' experience of the intervention. At the macrolevel, they can be used to explore the users' perceptions of how the intervention has helped them to engage in the behavior change process."
    },
    {
      "title": "Current Use and Future Directions",
      "text": "Qualitative methodologies are commonly employed in the digital health setting to inform the development of interventions (ie, usability testing) and as an evaluation measure (eg,  [25] [26] [27] [28] [29] ). In most cases, the focus of the evaluation has been on perceptions of usability and acceptability, rather than engagement. However, there are some notable exceptions. For example, some studies have used think-aloud measures to understand cognitive processes and emotional reactions when navigating the intervention and viewing intervention content in real time  [30] [31] [32] [33] . Others have explored users' flow experiences, adherence and lived experience of technology using qualitative interviews  [34] [35] [36] , focus groups  [37] , or a combination of think-aloud and interview methods  [32] .\n\nAlong with exploring the direct user experience, qualitative measures are also often used to probe the perceived usefulness of the intervention experience. Although this can relate to macroengagement (eg, by providing insights into how the intervention may have helped the user to achieve behavioral goals), efforts to explore the users' experience of the behavior change process in more depth are recommended. For example, researchers could explore how certain intervention features impact intentions and self-efficacy and how the relationship between intervention features and changes in psychosocial factors relate to use or disuse. This could be achieved using simple methods such as open-ended items in a questionnaire or more elaborate methods such as postintervention focus groups, which may help users to reflect on how the intervention has or has not engaged them in the behavior change process in more detail. Assessing these constructs at different time points may be particularly fruitful, especially given the cyclical nature of behavior change  [38] . Exploring users' real-time engagement in the behavior change process was achieved in 1 recent study by thematically analyzing participant responses to intervention text messages  [39] . By doing so, the authors were able to demonstrate that the study participants frequently gained positive cognitive and behavioral benefits from the text messages."
    },
    {
      "title": "Considerations",
      "text": "A limitation of qualitative measures is that the results can be difficult to compare between studies. Results are also often not generalizable, mostly due to sampling bias. Qualitative measures are often used to collect rich data rather than representative data. For this reason, qualitative methods may be particularly suited to help generate hypotheses about engagement including how engagement relates to efficacy and effectiveness. They may also be useful for exploring hypotheses, especially when the focus is on understanding engagement on an individual level such as in n-of-1 studies  [40] . In instances where representative data can be collected, such as in the text messaging study described above  [39] , hypothesis testing at the group level may be possible. However, the time and expertise needed to analyze data, which would ideally involve more than 1 person, is a barrier. This may be overcome in the future using machine learning tools to automate the coding of qualitative data  [41] .\n\nTable  2 . Overview of qualitative approaches to assessing engagement with considerations and example questions."
    },
    {
      "title": "Considerations (pros/cons) Example items Description Qualitative approach",
      "text": "Pros: inform modifications to increase acceptability, interactivity and tailor to enduser needs; identify a range of issues associated with use (both short and long term); augment interpretation of quantitative evaluation; generally small sample sizes.\n\nCons: subject to bias (eg, recall and social desirability), especially if leading questions are asked; time consuming to collect and transcribe; time consuming to analyze and often requires more than 1 person to decide on and confirm themes.\n\nMicrolevel: Tell us what you think about the content; How did completing that module make you feel?; Please explain your pattern of use?; Why did you log on when you did?; Macrolevel: Did you notice any change to your thinking as a result of using the \u2026(\"app\")?; What impact did using the ... (\"website\") have on how you are going about changing your behavior? Provide an opportunity for sharing of lived experiences and feelings to uncover concealed perceptions related to digital health intervention or the technology; includes informal conversational interviews (spontaneous-suited to ethnographic research), semistructured interviews (interview guide used to steer otherwise spontaneous conversation), or standardized open-ended interviews (worded questions used for all participants)."
    },
    {
      "title": "Semistructured interviews",
      "text": "Pros: can be used at various stages of development and implementation to understand how intervention features impact on engagement; occurs in real time, so less subject to recall bias.\n\nCons: subject to observer bias; can be cognitively difficult for participants and requires practice; may require additional resources such as video or sound recording equipment to obtain a comprehensive picture. Acquired data can be time consuming and complex to analyze; may be most useful for exploring microlevel engagement."
    },
    {
      "title": "Microlevel",
      "text": ": Tell me what you are thinking; What are you looking at?; What's on your mind?; How are you feeling?; Why did you click on this?; Why did you frown/smile/sigh?; Macrolevel: Are you learning anything new?\n\nAim to capture the experience of using the technology in real time. The user is provided with a specific task to complete and is observed while they perform the task. The user is prompted to think aloud throughout the process."
    },
    {
      "title": "Think aloud",
      "text": "Pros: allow for spontaneous discussion of topics and subsequent voicing of ideas and perceptions that may go unnoticed in semistructured or structured interviews; Can obtain rich data from multiple people at the same time.\n\nCons: subject to group or social desirability bias; some participants may not express themselves as fully in a group situation; requires practice to manage group discussion; can take a long time to transcribe due to interruptions/butting in; time consuming to analyze and often requires more than 1 person to decide on and confirm themes.\n\nMicrolevel: What did you think of the intervention?; Which components caught your attention the most?; What about them caught your attention?; Were there any components that caused frustration?; Did any aspects make you feel guilty?\n\nMacrolevel: How often did you think of the intervention during the week?; Was the intervention in the back of your mind?; How did the intervention help or hinder you reach your goals? Used to identify the social and contextual factors in specific population subgroups that influence engagement with digital health intervention and needs for technological characteristics and operations that promote user alignment and functional utility."
    },
    {
      "title": "Focus groups",
      "text": "To facilitate the use of qualitative measures in the future, a brief overview of example questions by qualitative method type, as well as key considerations are provided in Table  2 ."
    },
    {
      "title": "Self-Report Questionnaires"
    },
    {
      "title": "Focus Areas",
      "text": "Questionnaires can be used to assess both experiential and behavioral aspects of microlevel engagement as well as aspects of macrolevel engagement."
    },
    {
      "title": "Current Use and Future Directions",
      "text": "Self-report questionnaires have most often been used to gain insight into users' subjective experience of digital platforms. Although questionnaire items have often been purpose-built and not subjected to psychometric testing (see Multimedia Appendix 1), there are a number of more rigorously developed scales. An overview of scales identified by our search  [4, [12] [13] [14]  is presented in Multimedia Appendix 2. In brief, most scales have been developed to assess subjective experiential engagement with e-commerce websites or video games. Only 2 scales developed specifically for the eHealth and mHealth setting were identified (ie, the eHealth Engagement Scale  [42]  and the Digital Behavior Change Intervention Engagement Scale  [43] ), and only 1 of these has been validated  [42] , whereas validation of the other is currently underway  [43] . Of note, some of the available scales assess attributes posited to predict engagement (eg, aesthetic appeal and usability experience  [44] [45] [46] ) as well as attributes considered to be a part of engagement (interest, attention, and affect). This is particularly the case for scales developed in the e-commerce setting and raises some validity concerns. Several of the scales are also quite long, which may place an undue burden on participants. The development and evaluation of high-quality short questionnaires relevant to eHealth and mHealth are therefore encouraged.\n\nQuestionnaires have also been used to assess behavioral aspects of engagement (ie, intervention usage). Although objective behavioral data are often available (see usage data below), questionnaires have been used when this is not the case. For example, a study comparing the relative efficacy of 2 off-the-shelf apps used questionnaires to assess the frequency and time of app use  [47] . Although there are several scales with reasonable psychometric properties available for assessing the users' subjective experience (Multimedia Appendix 2), scales for assessing behavioral aspects of engagement in eHealth and mHealth interventions are lacking. Perski et al's self-report measure  [43] , which includes 2 items on behavioral engagement, is an exception. However, the validity of the measure is still being investigated. Perski's items and the purpose-built item used by other researchers usually have reasonable face-validity (eg, \"how many times per week did you use the app?\") but might lead to over-or underreporting depending on how items are phrased  [48, 49] . The validity of the chosen scale should be considered when interpreting the findings of self-reported behavioral data, and we recommend efforts to test the psychometric properties of developed items before use, if not yet available. This could be achieved by comparing the self-reported data with objectively collected data in a controlled setting (eg,  [43] ). The development of self-reported usage questionnaires that complement and provide useful context for objective usage measures should be considered. For example, if time on site or using an app is of interest, questionnaire data may identify cases where the user has left the program running in the background but has not been actively engaged. Likewise, information on behavioral cues at the point of engagement (eg, \"what were you doing before you logged your steps using the app?\") may complement usage data and provide a more comprehensive measure of usage patterns. Lessons may be gleaned from the scales developed to assess social networking intensity  [50] .\n\nThe third use of questionnaires relevant to the study of engagement at the macrolevel is the repeated assessment of psychological mechanisms hypothesized to account for behavioral changes (eg, self-efficacy). The assessment of change in these mechanisms and the conduction of a formal mediation analysis have been increasingly encouraged in the behavioral sciences  [51, 52]  to investigate whether interventions are working as intended (ie, that the selected eHealth and mHealth strategies are indeed influencing determinants and changes in determinants are influencing behavior, eg,  [53] ). This methodology can be adopted to study engagement. Arguably, a user who demonstrates favorable changes in 1 or more of these determinants can be considered engaged in the behavior change process (eg, self-efficacy significantly increases over time). Furthermore, someone demonstrating changes at a prespecified cut point or where changes are associated with behavioral outcomes could be said to be engaged effectively. There are a number of pre-existing scales that can be used to assess changes in psychological determinants of behavior (eg,  [54] [55] [56] ) as well as guides for constructing purpose-built questions if existing scales are not suitable (eg,  [57, 58] ). Decisions regarding what psychological constructs to assess changes in should be based on the theoretical underpinning of the intervention and the key intervention objectives and strategies used to achieve them."
    },
    {
      "title": "Considerations",
      "text": "Overall, questionnaires can be a useful tool for measuring various aspects of engagement in a systematic, standardized, and convenient way. This can allow for easy comparison across studies and between experimental arms  [5] . Limitations include questionnaire length (and, therefore, duration of completion); a lack of experiential measures designed and tested within a health context; a lack of focus on the behavioral aspects of engagement; and in some cases, the inclusion of items that measure predictors of engagement within engagement scales.\n\nTo select an appropriate scale, an understanding of the different constructs used to describe engagement across disciplines will be necessary (see Table  1 ). Reviewing the wording of the items and assessing how they will fit within the context of one's project may further help with scale selection. To this end, example items for each scale summarized above are provided in Multimedia Appendix 3. Most items will need to be adapted for a health setting, and not all scales will be applicable across study types or useful for assessing all aspects of engagement (ie, interest, attention, affect, intervention usage, and involvement in behavior change process). In some cases, it may be necessary to generate completely new items or a completely new scale. In such cases, researchers are encouraged to report a measure of internal consistency (preferably McDonald omega) and present factor-analytic evidence confirming the dimensionality of the scale  [59] . Attention to the length of the scale should also be given. This will likely be necessary to minimize missing data. The perceptions of those who drop out of the study are currently often not captured in evaluations of eHealth and mHealth interventions, which is problematic as those who drop out are usually those who have used the intervention the least. Ecological momentary assessments (EMAs; described in more detail below) may be useful to assess relevant engagement parameters regularly during the intervention and give a better impression of engagement throughout use  [60] . Alternatively, selecting a representative subsample to administer surveys to and reimbursing them for their time might be a viable solution."
    },
    {
      "title": "Ecological Momentary Assessments"
    },
    {
      "title": "Focus Area",
      "text": "EMAs can be used to assess both experiential and behavioral aspects of microlevel engagement as well as aspects of macrolevel engagement. The main objective of EMAs is to assess behaviors, perceptions, or experiences in real time and as they occur in their natural setting  [61] . By prompting users to self-report data at varying times per day, EMAs allow these phenomena to be studied in different contexts and times."
    },
    {
      "title": "Current Use and Future Directions",
      "text": "In EMAs, short surveys can either be accessed by the user on demand (eg, when logging a recent behavior), sent at specific or random intervals (eg, every 2 hours per day: time-based sampling), or they can be triggered by a certain event (eg, only when an activity tracker indicates the user is performing moderate to vigorous physical activity: event-based sampling). The latter is especially useful to capture rare behaviors, perceptions, or experiences. EMAs are often conducted on smartphone screens, but wearable devices can also be used (eg, CamNtech ProDiary, Philips Actiwatch Spectrum Plus, or Samsung Gear Life)  [62] .\n\nEMAs have mostly been applied in eHealth and mHealth studies to measure health behavior and determinants (eg,  [63, 64] ). We identified 1 study from previous reviews that used EMA to measure user engagement. This study  [65]  used event-based sampling to assess the breaks in levels of presence with a shooter game (not intended to improve health). The events that were sampled consisted of several parts of game play. No validity or reliability information for the slider was explicitly provided.\n\nDespite the limited application of EMAs to measure engagement so far, EMAs may be well suited to study moment-to-moment or microlevel engagement with an intervention  [5] . EMAs could provide data-driven insights into reasons for low adherence or dropout. EMAs are usually conducted over a short period with regular measurements over the day or week. However, it is also possible to adjust the timing and measurement intervals to collect longer-term insights into engagement. Contextual data and determinant data provided in EMA may enrich intervention usage data obtained from other sources to provide further insights into reasons for dropout."
    },
    {
      "title": "Considerations",
      "text": "EMA surveys are intended to be very brief, because the purpose is to capture experiences in the moment and often to collect many data points over time, which can pose a burden to users  [61] . Ensuring measures are brief is, therefore, important for both validity and for promoting adherence to the EMA protocol. Recent reviews of adherence to EMA protocols in health settings  [66, 67]  suggest that compliance rates (proportion of EMAs completed) are reasonable (>70%), especially when sampling protocols are easy to follow. This speaks to the feasibility of utilizing this measurement approach; however, data analysis can be challenging for those unfamiliar with intensive longitudinal datasets (for a discussion regarding the challenges of EMA and example analysis approaches, see  [68] [69] [70] [71] [72] ). Advantages of EMAs include less recall bias than retrospective self-reports and potential for high ecological validity, as it studies behavior or effects in real-world contexts  [60, 61] ."
    },
    {
      "title": "System Usage Data"
    },
    {
      "title": "Focus Area",
      "text": "System usage data quantitatively capture how the intervention is physically used by each participant. This relates to the behavioral component of microlevel engagement. When paired with other data sources, system usage data can provide insights into how usage patterns, intervention dose, and different adherence rates relate to other aspects of engagement (eg, interest, attention, affect, and changes in determinants) and efficacy and effectiveness outcomes (eg,  [73] [74] [75] [76] )."
    },
    {
      "title": "Current Use and Future Directions",
      "text": "System usage data are the most commonly collected and reported measures of engagement in eHealth and mHealth interventions  [4] . Although the focus has predominantly been on nonusage attrition and overall adherence to the intervention  [3, 8] , more recent studies have begun to explore the multidimensional nature of usage data  [77] [78] [79] , focusing on the depth and type of engagement as well as frequency measures. As the field progresses, it would be helpful to have shared ways of conceptualizing these data, as recent reviews have tended to categorize types of usage data differently using an inductive approach  [4, 78] . The FITT acronym  [80] , which stands for frequency, intensity, time, and type, and is commonly used in physical activity research, might be a useful tool in this sense, especially for considering usage data as an engagement measure a priori. Specific examples of how usage data could be categorized using this principle are given in Table  3 . Frequency provides information on how often a participant visits the intervention site or uses the app. Intensity measures the strength or depth of engagement with the intervention, for example, the proportion of the intervention site or app features used out of the total available features  [4] . Type refers to the type of engagement, for example, this could be categorized as reflective (eg, self-reporting behavior change), altruistic (eg, helping others), or gamified (eg, participating in a challenge) in nature. Type can also be divided into \"active\" (eg, active input such as when responding to a quiz, self-monitoring, or writing an action plan) or \"passive\" (eg, an individual can view the intervention without having to interact with it) categories. Time is a measure of the duration of engagement during any single visit or a measure to assess level of exposure as an aggregate over the intervention period.\n\nExamining usage data by aggregating data across the FITT categories can provide greater insights into engagement than focusing on any one domain  [77, 79, 88] . For example, although the total time on site for users may appear similar (time data), their intensity data could be meaningfully different, which could lead to differences in engagement profiles (eg, attention, elaboration, and experience  [79, 88] ). Separating users with similar data for time on site but markedly different patterns of use in terms of the type of activities may be helpful for identifying what aspects of the intervention are more engaging than others  [92] ; what aspects may be more influential for achieving behavior change, and in addition, whether this is moderated by user profiles (eg,  [88] ). The insight obtained from careful examination of system usage data in this way can assist intervention developers with data-driven solutions to encourage engagement  [93] ."
    },
    {
      "title": "Frequency of engagement with the intervention",
      "text": "Log-in (number of log-ins recorded per participant, average log-ins per unit of time or total for intervention duration) Visits to the site (number of visits/hits per participant, average per unit of time or total)"
    },
    {
      "title": "Considerations",
      "text": "User behavior in digital health interventions can be tracked by embedding programming code as part of the development process or by using third-party services. For both methods, it is important during software design (or selection) to consider the type of data desired or needed to track behavioral engagement and ensure the data are adequately captured and can be extracted easily. The most commonly used third-party service is Google Analytics, a service that can be implemented by connecting to the Google Analytics application programming interface. Google Analytics can be used to collect information on the users' environment (location, browser, and connection speed), and the users' behavior (eg, number of page visits, time on site, where users came from, and which page they visited last before exiting  [94] ). Capturing usage data more specific to the intervention platform, such as participation in a quiz or percentages of answers correct, require, as in Google Analytics, intentional programming and capture at the level of the software. Before programming, considerable thought should be given to how the usage data will be analyzed, as good tracking generates a large amount of data (ie, every navigational move that every participant has ever made and even the moves they did not make) that can be hard to make sense of; therefore, an a priori analysis plan is recommended. Visualization tools  [82]  and engagement indices such as those discussed by Baltierra et al  [79]  and Couper et al  [88] , or consideration of new data analyses techniques may be useful to get insights into data  [95, 96] . Although system usage data are often considered objective and reliable, some caution interpreting data is recommended. The increasing use of dynamic internet protocol (IP) addresses and virtual private networks (which change or hide your IP address), the use of IP addresses shared by multiple users (eg, via the family computer and internet cafes), and typical browsing behavior (eg, leaving multiple tabs open) may obscure usage data, especially for applications that do not require a unique log-in. This may be less of an issue for mobile apps compared with websites. Intervention developers should, wherever possible, collect and analyze system usage data. Compared with the usage of other behavioral interventions (eg, a printed booklet), these data can be easily collected with early planning and good data capture techniques. Although usage data does not provide direct information on the psychological form of user engagement  [4, 5] , it can provide some information to help us to understand what is engaging about an intervention, and what is not, in an unobtrusive way. There is also some evidence of predictive validity, with technology usage generally correlating with positive behavior change or health outcomes  [81, 91, 97, 98] . However, more research to establish the predictive validity of system usage data is needed, especially given that most analyses to date have lacked a suitable control group.\n\nAs with analyzing intensive longitudinal EMA data, the analysis of system usage data can be challenging. This is due to the intensive longitudinal and multidimensional nature of the data as well as the pattern of missingness (which tends to be nonrandom and nonignorable). Recognizing this, a comprehensive analysis plan should be developed before the commencement of the study. Exploration of the data visualization tools, composite engagement metrics, and analysis approaches referenced above might assist with the development of this plan.\n\nIt is also recommended that developers consider and outline the intended usage of the intervention. Intended usage is the way in which individuals should experience the intervention to derive maximum benefit, based on the conceptual framework informing intervention design (ie, developers' views on how the intervention should work best for who). Notably, intended usage may not be the same for all individuals (eg, in adaptive interventions  [99, 100] ). By specifying intended usage a priori and comparing this with observed usage, we can establish whether individuals have adhered to the intervention and, in turn, the impact of adherence on efficacy  [3] ."
    },
    {
      "title": "Sensor Data"
    },
    {
      "title": "Focus Area",
      "text": "Sensors such as global positioning systems (GPS), cameras (eg, facilitating eye tracking analyses), microphones, and accelerometers can unobtrusively monitor users' behavior and the physical context in which this behavior takes place. They can be provided by the investigator, but many of them are embedded in smartphones or trackers. This relates to the behavioral component of microlevel (eg, information on intervention fidelity) and macrolevel (eg, tracking behavior in real-life settings) engagement."
    },
    {
      "title": "Current Use and Future Directions",
      "text": "Analyzing sensor data presents an unobtrusive way of measuring engagement that requires no additional time effort from users other than the time spent engaging with the program. Their value lies in being able to track behavior of many users [101] and to enrich usage information in real-life situations or combining them with other user engagement measures such as EMA. There are calls for a different evaluation of eHealth and mHealth behavior change interventions than traditional interventions, to more nimbly respond to rapidly changing technologies and user preferences for functionalities  [102] [103] [104] [105] . Adaptations to eHealth and mHealth interventions are likely to be needed soon after first design and again after first implementation. Information from sensors that automatically track usage in real-life situations can help in measuring engagement with these interventions and distinguishing between successful mastery of intervention goals or need for continued engagement  [5] . For example, in physical activity interventions, accelerometer information could continuously monitor the current activity level and indicate whether lower adherence to the intervention should be considered as a successful completion or disengagement. Sensor data paired with usage information may thus provide insights in macrolevel engagement as a mediator of positive intervention outcomes. In a similar vein, GPS information can enrich macrolevel engagement measures. GPS gives information on where people use the intervention and where it is less often used. For example, an app designed to facilitate healthy food choices may be used at home or at grocery stores but shows lower usage in restaurants. The GPS data give further insight into offline engagement with the intervention goals.\n\nSensors can also provide an indication of intervention fidelity. For example, distance traveled as measured by GPS and phone cameras taking pictures of meals can indicate whether the intervention is used in the appropriate manner and context  [106] . The combination of usage and commonly included sensors can provide more detailed measures of real-life user engagement than usage information by itself. Sensor data can, moreover, trigger the event-based form of EMA. For example, users may be prompted to indicate their engagement with the intervention when the accelerometer shows the person is physically inactive or assess user engagement when GPS data show the person is in a certain physical context (eg, at a bar where there is a personal risk of smoking or alcohol consumption)."
    },
    {
      "title": "Considerations",
      "text": "A challenge of using GPS data for this purpose is the time-intensive nature of GPS data preparation and analysis. This will likely get easier in the future as new analysis packages become available to facilitate automation. Sensors, moreover, have the advantage of presenting a low level of respondent burden. However, especially with context-aware sensing using GPS, users are concerned about privacy issues [107,108]. In addition, sensors integrated in smartphones tend to negatively impact the battery life of the mobile device, and users may, therefore, be less compliant with running these sensors on their phones. This may especially be the case when users are skeptical toward the accuracy and relevance of context-aware smartphone sensing  [25] . Therefore, communicating research findings about the validity of such measures  [109, 110] ) and conducting pilot tests and validity studies of new measures may be necessary to increase their use in future interventions and optimize uptake among participants."
    },
    {
      "title": "Social Media"
    },
    {
      "title": "Focus Area",
      "text": "Another unobtrusive, low-burden approach to capturing engagement with the intervention is to analyze users' social media patterns. In social media, users create online communities (eg, social networking sites) via which they share information, opinions, personal messages, or visual material. Despite the interest of behavior change professionals in using social media to increase intervention effectiveness (see eg,  [111] ), to our knowledge, little research is available on the use of social media to measure engagement with eHealth and mHealth. The available resources mostly come from marketing and media audience research  [112, 113] . Social media message threads may provide useful information on user experience (microlevel engagement with the intervention) but might also provide insights in macrolevel engagement (eg, wall posts on behavioral achievements)."
    },
    {
      "title": "Current Use and Future Directions",
      "text": "One study examined the number of wall posts made over time as an indication of engagement with a social networking physical activity intervention  [114] . An approach to reduce the burden in analysis is to use markers that are previously nonexisting words launched exclusively within the intervention  [115] . These markers are used to trace any conversation that takes place on social media in relation to the intervention and are a way to measure social proliferation associated with the intervention content. An example comes from a video intervention on cognitive problems that may result from being a victim of violence  [115] . To clearly identify all conversations and mentions on social media that would result from this topic, they launched the word falterhead to describe how the main character experienced the negative effects on his brain functioning after being violently attacked. This marker allowed a quick identification of all social media content related to the program, as this nonexisting word is unlikely to occur for content unrelated to the intervention. Several social media sources are then searched with text-and data-mining tools (eg, HowardsHome Finchline) for the occurrence and content of messages that contain these markers. The messages are next analyzed in terms of quantity (eg, Is the intervention being talked about?; What are patterns of social proliferation over time?) and quality (eg, How is the topic mentioned or discussed?; Is this how we wished viewers would think and talk about the intervention?). Social media messages relating to the eHealth and mHealth intervention might also be analyzed for their occurrence of certain profiles in social media engagement. On a continuum from passive and uninterested to more active and engaged, profiles of lurkers, casuals, actives, committed, and loyalists can be distinguished. Although to our knowledge, this has not yet been applied to analyze engagement with eHealth and mHealth behavior change interventions, interventions showing more actives, committed, and loyalists on social media might indicate higher user engagement than those receiving more lurkers and casuals  [116] . This might especially be useful to assess comments on engagement in behavior change programs in real-life settings."
    },
    {
      "title": "Considerations",
      "text": "The vast amount of social media content may make it difficult to extract what is relevant to the intervention. Markers mentioned earlier and audit tools are useful to facilitate such social media analyses. Examples of free audit tools to analyze social media are Sprout Social Simply Measured, Instagram Insights, and Union Metrics. The free statistical software program R also has many packages to analyze social media data. The analysis of these social media patterns requires a combination of qualitative techniques to assess discussion or post sentiment and topic, and quantitative methods, for example, to assess reach by combining number of followers for each mention on social media  [117] . Text analytic tools available in many statistical packages such as R and SAS may also be useful here."
    },
    {
      "title": "Psychophysiological Measures"
    },
    {
      "title": "Focus Area",
      "text": "Psychophysiological methods of measurement are used to examine the relationship between physiology and overt behavior or cognitive processes and variables. Psychophysiological measures are operationalization of cognitive processes or variables, just as self-reported questionnaires are used to measure processes or variables derived from theory  [118] . They have been shown to be valuable approaches for measuring the experiential aspects of microengagement  [119] ."
    },
    {
      "title": "Current Use and Future Directions",
      "text": "There are several types of psychophysiological measures used to study cognitive and affective processes (for a comprehensive overview of measures used in human-computer interaction and user experience research, see  [119] [120] [121] ). We describe the 2 most common methods with a strong temporal resolution (ie, electroencephalography [EEG] and eye-tracking). A strong temporal solution (ie, precision of measurement with respect to time) is warranted to investigate engagement over time. It needs to be stressed, however, that other methods show promising results as well [122-127]. For example, predicting engagement using a novel visual analysis approach to recognize affect performed significantly better or on par with using self-reports  [125] . The methods presented here are noninvasive but obtrusive in comparison with, for example, most measurements of system usage data. These methods are mostly used in laboratory settings and during intervention development (eg, pretesting of a website), but the opportunities to use them in field settings are increasing (eg,  [128] ). Moreover, it is also possible to use these methods in parallel with a trial or afterward to gain more insight into user engagement and, thereby, shed more light on trial findings.\n\nEEG records electrical activity in the brain using small, flat metal discs (electrodes) attached to a person's scalp. Using this method requires adequate expertise, both in terms of measurement [129] and analysis [130] of data. Event-related potentials (ERPs) are the average changes in the EEG signal in response to a stimulus, and characteristic ERP responses are referred to as components  [131] . For example,  Leiker et al [132] , in a study on motion-controlled video games, focused on the amplitude of a specific component (labeled eP3a), which is a reliable index of attentional reserve  [133, 134] . This study revealed that participants who reported higher levels of engagement (as measured by the Intrinsic Motivation Inventory) showed a smaller eP3a, which is indicative of paying more attention to the primary task (eg, playing the game). Another study revealed that late negative slow wave components of the ERP were indicative of attention, which was partly confirmed by findings from self-reports (ie, the Immersive Experience Questionnaire)  [123] .\n\nEye-tracking is based on the strong association between eye movements and attention  [135] . It is a suitable method to assess the course of attention over time  [136] . For example, fixation data of an experimental study revealed that participants' eye movements in the immersive condition decreased over time, which is indicative of increased attention  [137] . Another example is a study comparing a video with a text condition of a physical activity intervention. This study revealed that participants in the video condition displayed greater attention to the physical activity feedback in terms of gaze duration, total fixation duration, and focusing on feedback  [138] . Another study using eye-tracking found that participants focused more on certain experimentally manipulated aspects of a health-related website (ie, in terms of frequency and duration), but this did not affect usage data (ie, the number of pages visited or the time on the website)  [139] . It might be that these aspects attract attention, but there is a trade-off in the sense that participants then focus less on other aspects of the website. However, it could also be that attention only partly predicts engagement."
    },
    {
      "title": "Considerations",
      "text": "With regard to both EEG and eye-tracking, it is important to note that attention is only the first appraisal in the process of engagement  [139] . There are other psychophysiological methods besides EEG and eye-tracking that are mostly focused on measuring arousal. A previous study, for example, recorded electrodermal activity (EDA) and facial muscle activity (electromyography [EMG]) in addition to a Game Experience Questionnaire  [140] . The association between these measures, however, was not straightforward. For example, EMG orbicularis oculi (periocular) is usually used to indicate positive emotions and high arousal but was negatively correlated to competence (which is a positive dimension of the Game Experience Questionnaire). Another study measured engagement in 5 different ways: self-reports using 4 dimensions of the Temple Presence Inventory, content analyses of user videos, EDA, mouse movements, and click logs (the latter 2 are measurements of usage data) [124]. These 5 measures correlated in limited ways. The authors concluded that \"engagements as a construct is more complex than is captured in any of these measures individually and that using multiple methods to assess engagement can illuminate aspects of engagement not detectable by a single method of measurement\" [124]. This is indicative of the complexity of engagement as a construct and reflects recent calls from the human-computer interaction field for future studies to identify valid combinations of psychophysiological measures that more fully capture the multidimensional nature of engagement  [119] ."
    },
    {
      "title": "Discussion",
      "text": "It is generally agreed that some form of engagement is necessary for eHealth and mHealth behavior change interventions to be effective. However, cohesive and in-depth knowledge about how to develop engaging interventions and the pathways between engagement and efficacy are lacking. Several models of engagement have been proposed in the literature to address this deficit, but little testing of the models has been conducted. To support research in this area and progress the science of user engagement, we aimed to provide a comprehensive overview of the measurement options available to assess engagement in an eHealth and mHealth behavioral intervention setting. The overview should not be treated as exhaustive; however, it should serve as a useful point of reference when considering engagement measures for behavioral eHealth and mHealth research.\n\nThe best measurement approach will likely depend on the stage of research and the specific research context, although there are benefits from using multiple methods and pairing the data (eg, self-report data relating to interest, attention and affect combined with system usage data). It is also important to make an inventory-before data collection-to check whether the available expertise for using different methods (eg, EEG) is available. Given the complexity of engagement as a construct, using multiple methods may be necessary to illuminate it fully  [119, 124] . At present, most studies in the eHealth and mHealth behavioral intervention space rely on system usage data only. Although system usage data is undoubtedly a valuable engagement marker, it is not considered a valid measure of micro-or macroengagement on its own  [4, 5] . Greater efforts are needed to also assess the psychological aspects of engagement to better understand the interplay between perceptions, usage, and efficacy.\n\nQuestionnaires are perhaps the most accessible way to assess microlevel engagement in terms of cost. However, there is currently a lack of validated self-report questionnaires specific to the eHealth and mHealth behavior change intervention context. This is reflected in the large number of purpose-built questionnaires (ie, questionnaires designed for a specific study) that have been used to date  [4] . As the main benefit of questionnaires is that they allow for the collection of subjective data in a standardized way, greater efforts are needed to develop and implement standard items.\n\nAlthough not yet validated, the questionnaire developed by Perski et al  [44]  is promising in this regard, as it includes constructs related to both psychological and behavioral aspects of engagement and only focuses on engagement constructs. The other questionnaires identified focus only on the psychological aspects of engagement, and some include constructs more aligned with standard acceptability items (eg, perceived credibility), rather than the constructs of interest, attention, and affect. It may be best to avoid these questionnaires when testing models that hypothesize that acceptability markers influence engagement parameters.\n\nThere are several other measures of engagement that may also be used to test engagement models (eg, sensors, social media data, EMA, and psychophysiological measures). Despite their potential advantages, little research has been conducted exploring their use (and validity) in the digital behavior change setting. This is likely due to higher cost, time, and data analysis requirements relative to other measures. To mitigate this, behavioral researchers are increasingly drawing on expertise across other relevant disciplines (eg, informatics, human-computer interaction, experimental, and cognitive psychology). It is hoped that this paper will help to facilitate this research, especially research establishing the criterion, as well as divergent and predictive validity of these measures.\n\nOverall, establishing the validity of engagement measures across multiple settings and learning how to triangulate measures in a complementary way are necessary next steps to advance the field. This will allow us to thoroughly test contemporary models of user engagement and hence, deepen our understanding of the interplay between intervention perceptions, usage, and efficacy across different settings."
    },
    {
      "text": "Intensity of engagementPages viewed (number) Lessons or modules viewed (total number, % of prescribed) Posts viewed (eg, lurking) Number of emails sent Number of posts written Accessed \"Expert forum\" (Ask the Expert) to pose a question/seek advice (number) Action plan created Number of quizzes attempted [88,89] Time or duration of engagement with the program Amount of time spent at each visit per participant (average and total minutes) Number of days between first and last log-in (duration or intervention stickiness) [90,91] Type of engagement Reflective (eg, participant recording of behavior or health status) Gamified (eg, accepting challenges and sending gifts) Altruistic (eg, helping others) or malevolent (eg, trolling others) Didactic (eg, reading posts and taking quizzes) Active (eg, recording behavior) versus Passive (eg, reading posts)."
    },
    {
      "text": "Examples of system usage data and type of information recorded."
    }
  ],
  "references": [
    {
      "title": "Past, present, and future of eHealth and mHealth research to improve physical activity and dietary behaviors",
      "authors": [
        "C Vandelanotte",
        "A M\u00fcller",
        "C Short",
        "M Hingle",
        "N Nathan",
        "S Williams"
      ],
      "year": 2016,
      "doi": "10.1016/j.jneb.2015.12.006"
    },
    {
      "title": "Developing and evaluating digital interventions to promote behavior change in health and health care: recommendations resulting from an international workshop",
      "authors": [
        "S Michie",
        "Yardley West",
        "R Patrick",
        "K Greaves"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.7126"
    },
    {
      "title": "Persuasive system design does matter: a systematic review of adherence to web-based interventions",
      "authors": [
        "M Kelders",
        "R Kok",
        "H Ossebaard",
        "J Van Gemert-Pijnen"
      ],
      "year": 2012,
      "doi": "10.2196/jmir.2104"
    },
    {
      "title": "Conceptualising engagement with digital behaviour change interventions: a systematic review using principles from critical interpretive synthesis",
      "authors": [
        "O Perski",
        "A Blandford",
        "R West",
        "S Michie"
      ],
      "year": 2017,
      "doi": "10.1007/s13142-016-0453-1"
    },
    {
      "title": "Understanding and promoting effective engagement with digital behavior change interventions",
      "authors": [
        "L Yardley",
        "B Spring",
        "H Riper",
        "L Morrison",
        "D Crane",
        "K Curtis"
      ],
      "year": 2016,
      "doi": "10.1016/j.amepre.2016.06.015"
    },
    {
      "title": "Designing engaging online behaviour change interventions: a proposed model of user engagement",
      "authors": [
        "C Short",
        "A Rebar",
        "R Plotnikoff",
        "C Vandelanotte"
      ],
      "year": 2015,
      "doi": "10.1007/s00520-017-3786-5"
    },
    {
      "title": "Measures of fidelity of delivery of, and engagement with, complex, face-to-face health behaviour change interventions: a systematic review of measure quality",
      "authors": [
        "H Walton",
        "A Spector",
        "I Tombor",
        "S Michie"
      ],
      "year": 2017,
      "doi": "10.1111/bjhp.12260"
    },
    {
      "title": "Clarifying the concept of adherence to eHealth technology: systematic review on when usage becomes adherence",
      "authors": [
        "F Sieverink",
        "S Kelders",
        "J Van Gemert-Pijnen"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.8578"
    },
    {
      "title": "Theoretical perspectives of adherence to web-based interventions: a scoping review",
      "authors": [
        "C Ryan",
        "M Bergin",
        "J Wells"
      ],
      "year": 2018,
      "doi": "10.1007/s12529-017-9678-8"
    },
    {
      "title": "What is user engagement? A conceptual framework for defining user engagement with technology",
      "authors": [
        "H O'brien",
        "E Toms"
      ],
      "year": 2008,
      "doi": "10.1002/asi.20801"
    },
    {
      "title": "Interest in behavior change interventions: a conceptual model",
      "authors": [
        "R Crutzen",
        "R Ruiter"
      ],
      "year": 2015
    },
    {
      "title": "Beyond Usability Performance: A Review of User Experience-focused Evaluations in Visualization",
      "authors": [
        "B Saket",
        "Stasko"
      ],
      "year": 2016
    },
    {
      "title": "A-142",
      "authors": [
        "M Baltimore",
        "Usa"
      ],
      "doi": "10.18240/ijo.2021.05.08"
    },
    {
      "title": "The Convergence of Player Experience Questionnaires",
      "authors": [
        "A Denisova",
        "A Nordin",
        "P Cairns"
      ],
      "year": 2016,
      "doi": "10.1145/2967934.2968095"
    },
    {
      "title": "Engagement in digital entertainment games: a systematic review",
      "authors": [
        "E Boyle",
        "T Connolly",
        "T Hainey",
        "J Boyle"
      ],
      "year": 2012,
      "doi": "10.1016/j.chb.2011.11.020"
    },
    {
      "title": "Interest, learning, and motivation",
      "authors": [
        "U Schiefele"
      ],
      "year": 1991,
      "doi": "10.1080/00461520.1991.9653136"
    },
    {
      "title": "Situational interest:a review of the literature and directions for future research",
      "authors": [
        "G Schraw",
        "S Lehman"
      ],
      "year": 2001,
      "doi": "10.1023/A:1009004801455"
    },
    {
      "title": "Psychology and Life",
      "authors": [
        "R Gerrig",
        "P Zimbardo"
      ],
      "year": 2012
    },
    {
      "title": "The Principles of Psychology",
      "authors": [
        "W James"
      ],
      "year": 1950
    },
    {
      "title": "Affect is a form of cognition: a neurobiological analysis",
      "authors": [
        "S Duncan",
        "L Barrett"
      ],
      "year": 2007,
      "doi": "10.1080/02699930701437931"
    },
    {
      "title": "The structure of current affect: controversies and emerging consensus",
      "authors": [
        "L Barrett",
        "J Russell"
      ],
      "year": 2016,
      "doi": "10.1111/1467-8721.00003"
    },
    {
      "title": "Flow: The Psychology of Optimal Experience",
      "authors": [
        "M Csikszentmihalyi"
      ],
      "year": 1990
    },
    {
      "title": "The development of the Game Engagement Questionnaire: a measure of engagement in video game-playing",
      "authors": [
        "J Brockmyer",
        "C Fox",
        "K Curtiss",
        "E Mcbroom",
        "K Burkhart",
        "J Pidruzny"
      ],
      "year": 2009,
      "doi": "10.1016/j.jesp.2009.02.016"
    },
    {
      "title": "Immersion and emotion: their impact on the sense of presence",
      "authors": [
        "R Ba\u00f1os",
        "C Botella",
        "M Alca\u00f1iz",
        "V Lia\u00f1o",
        "B Guerrero",
        "B Rey"
      ],
      "year": 2004,
      "doi": "10.1089/cpb.2004.7.734"
    },
    {
      "title": "At the heart of it all: the concept of presence",
      "authors": [
        "M Lombard",
        "T Ditton"
      ],
      "year": 1997,
      "doi": "10.1111/j.1083-6101.1997.tb00072.x"
    },
    {
      "title": "Opportunities and challenges for smartphone applications in supporting health behavior change: qualitative study",
      "authors": [
        "L Dennison",
        "L Morrison",
        "G Conway"
      ],
      "year": 2013,
      "doi": "10.2196/jmir.2583"
    },
    {
      "title": "User preferences for content, features, and style for an app to reduce harmful drinking in young adults: analysis of user feedback in app stores and focus group interviews",
      "authors": [
        "J Milward",
        "Z Khadjesari",
        "S Fincham-Campbell",
        "P Deluca",
        "R Watson",
        "C Drummond"
      ],
      "year": 2016,
      "doi": "10.2196/mhealth.5242"
    },
    {
      "title": "Usability testing and piloting of the Mums Step It Up program--a team-based social networking physical activity intervention for women with young children",
      "authors": [
        "J Kernot",
        "T Olds",
        "L Lewis",
        "C Maher"
      ],
      "year": 2014,
      "doi": "10.1371/journal.pone.0108842"
    },
    {
      "title": "Designing more engaging computer-tailored physical activity behaviour change interventions for breast cancer survivors: lessons from the iMove More for Life study",
      "authors": [
        "C Short",
        "E James",
        "A Rebar",
        "M Duncan",
        "K Courneya",
        "R Plotnikoff"
      ],
      "year": 2017,
      "doi": "10.1007/s00520-017-3786-5"
    },
    {
      "title": "Design, development, and formative evaluation of a smartphone application for recording and monitoring physical activity levels: the 10,000 Steps \"iStepLog",
      "authors": [
        "M Kirwan",
        "M Duncan",
        "C Vandelanotte",
        "W Mummery"
      ],
      "year": 2013,
      "doi": "10.1177/1090198112449460"
    },
    {
      "title": "Smokers' and drinkers' choice of smartphone applications and expectations of engagement: a think aloud and interview study",
      "authors": [
        "O Perski",
        "A Blandford",
        "H Ubhi",
        "R West",
        "S Michie"
      ],
      "year": 2017,
      "doi": "10.1186/s12911-017-0422-8"
    },
    {
      "title": "Using the person-based approach to optimise a digital intervention for the management of hypertension",
      "authors": [
        "K Bradbury",
        "K Morton",
        "R Band",
        "A Van Woezik",
        "R Grist",
        "R Mcmanus"
      ],
      "year": 2018,
      "doi": "10.1371/journal.pone.0196868"
    },
    {
      "title": "Factors influencing usability of a smartphone app to reduce excessive alcohol consumption: Think Aloud and Interview Studies",
      "authors": [
        "D Crane",
        "C Garnett",
        "J Brown",
        "R West",
        "S Michie"
      ],
      "year": 2017,
      "doi": "10.3389/fpubh.2017.00039"
    },
    {
      "title": "Promoting engagement with a dimgital health intervention (HeLP-Diabetes) using email and text message prompts: mixed-methods study",
      "authors": [
        "G Alkhaldi",
        "K Modrow",
        "F Hamilton",
        "K Pal",
        "J Ross",
        "E Murray"
      ],
      "year": 2017,
      "doi": "10.2196/ijmr.6952"
    },
    {
      "title": "Game On? Smoking cessation through the gamification of mHealth: a longitudinal qualitative study",
      "authors": [
        "A El-Hilly",
        "S Iqbal",
        "M Ahmed",
        "Y Sherwani",
        "M Muntasir",
        "S Siddiqui"
      ],
      "year": 2016,
      "doi": "10.2196/games.5678"
    },
    {
      "title": "Elders' usability, dependability, and flow experiences on embodied interactive video games",
      "authors": [
        "M Hwang",
        "J Hong",
        "Y Hao",
        "J Jong"
      ],
      "year": 2011,
      "doi": "10.1080/03601271003723636"
    },
    {
      "title": "Optimizing engagement with Internet-based health behaviour change interventions: comparison of self-assessment with and without tailored feedback using a mixed methods approach",
      "authors": [
        "L Morrison",
        "R Moss-Morris",
        "S Michie"
      ],
      "year": 2014,
      "doi": "10.1111/bjhp.12083"
    },
    {
      "title": "Adherence to technology-mediated insomnia treatment: a meta-analysis, interviews, and focus groups",
      "authors": [
        "C Horsch",
        "J Lancee",
        "R Beun",
        "M Neerincx",
        "W Brinkman"
      ],
      "year": 2015,
      "doi": "10.2196/jmir.4115"
    },
    {
      "title": "A behavior change model for internet interventions",
      "authors": [
        "L Ritterband",
        "F Thorndike",
        "D Cox",
        "B Kovatchev",
        "L Gonder-Frederick"
      ],
      "year": 2009,
      "doi": "10.1007/s12160-009-9133-4"
    },
    {
      "title": "Real time monitoring of engagement with a text message intervention to reduce binge drinking among men living in socially disadvantaged areas of Scotland",
      "authors": [
        "L Irvine",
        "A Melson",
        "B Williams",
        "F Sniehotta",
        "A Mckenzie",
        "C Jones"
      ],
      "year": 2017,
      "doi": "10.1007/s12529-017-9666-z"
    },
    {
      "title": "The state of the art and future opportunities for using longitudinal n-of-1 methods in health behaviour research: a systematic literature overview",
      "authors": [
        "S Mcdonald",
        "F Quinn",
        "R Vieira",
        "O 'brien",
        "N White",
        "M Johnston"
      ],
      "year": 2017,
      "doi": "10.1080/17437199.2017.1316672"
    },
    {
      "title": "Machine learning and rule-based automated coding of qualitative data",
      "authors": [
        "C Kevin",
        "L Xiaozhong"
      ],
      "year": 2010,
      "doi": "10.1002/bult.2010.1720360403"
    },
    {
      "title": "The assessment of user engagement with eHealth content: the eHealth engagement scale",
      "authors": [
        "C Lefebvre",
        "Y Tada",
        "S Hilfiker",
        "C Baur"
      ],
      "year": 2010,
      "doi": "10.1111/j.1083-6101.2009.01514.x"
    },
    {
      "title": "Study protocol: Development and psychometric evaluation of a self-report instrument to measure engagement with digital behaviour change interventions",
      "authors": [
        "O Perski",
        "Osf"
      ],
      "year": 2017
    },
    {
      "title": "The development and evaluation of a survey to measure user engagement",
      "authors": [
        "H O'brien",
        "E Toms"
      ],
      "year": 2009,
      "doi": "10.1002/asi.21229"
    },
    {
      "title": "Construction and Evaluation of a User Experience Questionnaire",
      "authors": [
        "B Laugwitz",
        "T Held",
        "M Schrepp"
      ],
      "year": 2008,
      "doi": "10.1007/978-3-540-89350-9_6"
    },
    {
      "title": "Development and validation of a scale to measure optimal experience: the flow state scale",
      "authors": [
        "S Jackson",
        "H Marsh"
      ],
      "year": 1996,
      "doi": "10.1123/jsep.18.1.17"
    },
    {
      "title": "Apps for IMproving FITness and increasing physical activity among young people: the AIMFIT pragmatic randomized controlled trial",
      "authors": [
        "A Direito",
        "Y Jiang",
        "R Whittaker",
        "R Maddison"
      ],
      "year": 2015,
      "doi": "10.2196/jmir.4568"
    },
    {
      "title": "Measuring mobile phone use: self-report versus log data",
      "authors": [
        "J Boase",
        "R Ling"
      ],
      "year": 2013,
      "doi": "10.1111/jcc4.12021"
    },
    {
      "title": "The accuracy of self-reported internet use-a validation study using client log data",
      "authors": [
        "M Scharkow"
      ],
      "year": 2016,
      "doi": "10.1080/19312458.2015.1118446"
    },
    {
      "title": "Scales for measuring user engagement with social network sites: A systematic review of psychometric properties",
      "authors": [
        "L Sigerson",
        "C Cheng"
      ],
      "year": 2018,
      "doi": "10.1016/j.chb.2018.01.023"
    },
    {
      "title": "Mediation analysis",
      "authors": [
        "D Mackinnon",
        "A Fairchild",
        "M Fritz"
      ],
      "year": 2007,
      "doi": "10.1146/annurev.psych.58.110405.085542"
    },
    {
      "title": "Mediators of behavior change maintenance in physical activity interventions for young and middle-aged adults: a systematic review",
      "authors": [
        "J Murray",
        "S Brennan",
        "D French",
        "C Patterson",
        "F Kee",
        "R Hunter"
      ],
      "year": 2018,
      "doi": "10.1093/abm/kay012"
    },
    {
      "title": "Mediators of physical activity behaviour change among adult non-clinical populations: a review update",
      "authors": [
        "R Rhodes",
        "L Pfaeffli"
      ],
      "year": 2010,
      "doi": "10.1186/1479-5868-7-37"
    },
    {
      "title": "Development and evaluation of social cognitive measures related to adolescent physical activity",
      "authors": [
        "D Dewar",
        "D Lubans",
        "P Morgan",
        "R Plotnikoff"
      ],
      "year": 2013,
      "doi": "10.1186/1479-5868-9-36"
    },
    {
      "title": "Evaluation of social cognitive scaling response options in the physical activity domain",
      "authors": [
        "R Rhodes",
        "Hunt Matheson",
        "D Mark"
      ],
      "year": 2010,
      "doi": "10.1080/1091367X.2010.495539"
    },
    {
      "title": "Development and validation of a social cognitive theory-based survey for elementary nutrition education program",
      "authors": [
        "E Hall",
        "W Chai",
        "W Koszewski",
        "J Albrecht"
      ],
      "year": 2015,
      "doi": "10.1186/s12966-015-0206-4"
    },
    {
      "title": "Constructing questionnaires based on the theory of planned behaviour: a manual for Health Services Researchers",
      "authors": [
        "J Francis",
        "M Johnston",
        "M Eccles",
        "A Walker",
        "J Grimshaw",
        "R Foy"
      ],
      "year": 2004
    },
    {
      "title": "Guide for constructing self-efficacy scales",
      "authors": [
        "A Bandura"
      ],
      "year": 2006,
      "doi": "10.12691/jpar-2-1-2"
    },
    {
      "title": "Scale quality: alpha is an inadequate estimate and factor-analytic evidence is needed first of all",
      "authors": [
        "R Crutzen",
        "G Peters"
      ],
      "year": 2017,
      "doi": "10.1080/17437199.2015.1124240"
    },
    {
      "title": "The construal of experience in HCI: uUnderstanding self-reports",
      "authors": [
        "K Doherty",
        "G Doherty"
      ],
      "year": 2018,
      "doi": "10.1016/j.ijhcs.2017.10.006"
    },
    {
      "title": "Why Researchers Should Think \"Real World\": A Conceptual Rationale",
      "authors": [
        "H Reis"
      ],
      "year": 2013
    },
    {
      "title": "Wearable ESM: differences in the experience sampling method across wearable devices",
      "authors": [
        "J Hernandez",
        "D Mcduff",
        "C Infante",
        "P Maes",
        "K Quigley",
        "R Picard"
      ],
      "year": 2016
    },
    {
      "title": "Investigating children's physical activity and sedentary behavior using ecological momentary assessment with mobile phones",
      "authors": [
        "G Dunton",
        "Y Liao",
        "S Intille",
        "D Spruijt-Metz",
        "M Pentz"
      ],
      "year": 2011,
      "doi": "10.1038/oby.2010.302"
    },
    {
      "title": "Physical activity, mind wandering, affect, and sleep: an ecological momentary assessment",
      "authors": [
        "J Fanning",
        "M Mackenzie",
        "S Roberts",
        "I Crato",
        "D Ehlers",
        "E Mcauley"
      ],
      "year": 2016,
      "doi": "10.2196/mhealth.5855"
    },
    {
      "title": "Temporal presence variation in immersive computer games",
      "authors": [
        "J Chung",
        "H Gardner"
      ],
      "year": 2012,
      "doi": "10.1080/10447318.2011.627298"
    },
    {
      "title": "Compliance with mobile ecological momentary assessment protocols in children and adolescents: a systematic review and meta-analysis",
      "authors": [
        "C Wen",
        "S Schneider",
        "A Stone",
        "D Spruijt-Metz"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.6641"
    },
    {
      "title": "Ecological momentary assessment in aging research: a critical review",
      "authors": [
        "A Cain",
        "C Depp",
        "D Jeste"
      ],
      "year": 2009,
      "doi": "10.1016/j.jpsychires.2009.01.014"
    },
    {
      "title": "Are we making the most of ecological momentary assessment data? A comment on Richardson",
      "authors": [
        "K Modecki",
        "Gl ; Mazza",
        "O' Fuller-Tyszkiewicz",
        "Ling Donnell",
        "Staiger"
      ],
      "year": 2017,
      "doi": "10.1080/17437199.2017.1347513"
    },
    {
      "title": "Regression tree analysis of ecological momentary assessment data",
      "authors": [
        "B Richardson",
        "M Fuller-Tyszkiewicz",
        "O' Donnell",
        "R Ling",
        "M Staiger"
      ],
      "year": 2017,
      "doi": "10.1080/17437199.2017.1343677"
    },
    {
      "title": "The promise of intensive longitudinal data capture for behavioral health research",
      "authors": [
        "E Ginexi",
        "W Riley",
        "A Atienza",
        "P Mabry"
      ],
      "year": 2014,
      "doi": "10.1093/ntr/ntt273"
    },
    {
      "title": "No Time Like the Present",
      "authors": [
        "E Hamaker",
        "M Wichers"
      ],
      "year": 2017,
      "doi": "10.1177/0963721416666518"
    },
    {
      "title": "Ecological momentary assessment in behavioral research: addressing technological and human participant challenges",
      "authors": [
        "L Burke",
        "S Shiffman",
        "E Music",
        "M Styn",
        "A Kriska",
        "A Smailagic"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.7138"
    },
    {
      "title": "Effectiveness of a Web-based intervention aimed at healthy dietary and physical activity behavior: a randomized controlled trial about users and usage",
      "authors": [
        "S Kelders",
        "J Van Gemert-Pijnen",
        "A Werkman",
        "N Nijland",
        "E Seydel"
      ],
      "year": 2011,
      "doi": "10.2196/jmir.1624"
    },
    {
      "title": "Defining participant exposure measures in Web-based health behavior change programs",
      "authors": [
        "B Danaher",
        "S Boles",
        "L Akers",
        "J Gordon",
        "H Severson"
      ],
      "year": 2006,
      "doi": "10.2196/jmir.8.3.e15"
    },
    {
      "title": "Does usage of an eHealth intervention reduce the risk of excessive gestational weight gain? Secondary analysis from a randomized controlled trial",
      "authors": [
        "M Graham",
        "M Strawderman",
        "M Demment",
        "C Olson"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.6644"
    },
    {
      "title": "Usage and dose response of a mobile acceptance and commitment therapy app: secondary analysis of the intervention arm of a randomized controlled trial",
      "authors": [
        "E Mattila",
        "R Lappalainen",
        "P V\u00e4lkkynen",
        "E Sairanen",
        "P Lappalainen",
        "L Karhunen"
      ],
      "year": 2016,
      "doi": "10.2196/mhealth.5241"
    },
    {
      "title": "Assessing user engagement of an mHealth intervention: development and implementation of the growing healthy app engagement index",
      "authors": [
        "S Taki",
        "S Lymer",
        "C Russell",
        "K Campbell",
        "R Laws",
        "K Ong"
      ],
      "year": 2017,
      "doi": "10.2196/mhealth.7236"
    },
    {
      "title": "Evaluating the impact of physical activity apps and wearables: interdisciplinary review",
      "authors": [
        "C Mccallum",
        "J Rooksby",
        "C Gray"
      ],
      "year": 2018,
      "doi": "10.2196/mhealth.9054"
    },
    {
      "title": "More than just tracking time: Complex measures of user engagement with an internet-based health promotion intervention",
      "authors": [
        "N Baltierra",
        "K Muessig",
        "E Pike",
        "S Legrand",
        "S Bull",
        "L Hightow-Weidman"
      ],
      "year": 2016,
      "doi": "10.1016/j.jbi.2015.12.015"
    },
    {
      "title": "Importance of frequency, intensity, time and type (FITT) in physical activity assessment for epidemiological research",
      "authors": [
        "A Barisic",
        "S Leatherdale",
        "N Kreiger"
      ],
      "year": 2011
    },
    {
      "title": "Associations of internet website use with weight change in a long-term weight loss maintenance program",
      "authors": [
        "K Funk",
        "V Stevens",
        "L Appel",
        "A Bauck",
        "P Brantley",
        "C Champagne"
      ],
      "year": 2010,
      "doi": "10.2196/jmir.1504"
    },
    {
      "title": "A visualization tool to analyse usage of web-based interventions: the example of positive online weight reduction (POWeR)",
      "authors": [
        "Arden-Close Ej",
        "E Smith",
        "K Bradbury",
        "L Morrison",
        "L Dennison",
        "D Michaelides"
      ],
      "year": 2015,
      "doi": "10.2196/humanfactors.4310"
    },
    {
      "title": "Do adherence variables predict outcome in an online program for the prevention of eating disorders?",
      "authors": [
        "J Manwaring",
        "S Bryson",
        "A Goldschmidt",
        "A Winzelberg",
        "K Luce",
        "D Cunning"
      ],
      "year": 2008,
      "doi": "10.1037/0022-006X.76.2.341"
    },
    {
      "title": "The 1% rule in four digital health social networks: an observational study",
      "authors": [
        "T Van Mierlo"
      ],
      "year": 2014,
      "doi": "10.2196/jmir.2966"
    },
    {
      "title": "Feasibility and preliminary efficacy of an online intervention to increase physical activity in Nova Scotian cancer survivors: a randomized controlled trial",
      "authors": [
        "C Forbes",
        "C Blanchard",
        "W Mummery",
        "K Courneya"
      ],
      "year": 2015,
      "doi": "10.2196/cancer.4586"
    },
    {
      "title": "How do different delivery schedules of tailored web-based physical activity advice for breast cancer survivors influence intervention use and efficacy?",
      "authors": [
        "C Short",
        "A Rebar",
        "James Duncan",
        "M Courneya",
        "K Plotnikoff"
      ],
      "year": 2017,
      "doi": "10.1007/s11764-016-0565-0"
    },
    {
      "title": "Varying social media post types differentially impacts engagement in a behavioral weight loss intervention",
      "authors": [
        "S Hales",
        "C Davidson",
        "G Turner-Mcgrievy"
      ],
      "year": 2014,
      "doi": "10.1007/s13142-014-0274-z"
    },
    {
      "title": "Engagement and retention: measuring breadth and depth of participant use of an online intervention",
      "authors": [
        "M Couper",
        "G Alexander",
        "N Zhang",
        "R Little",
        "N Maddy",
        "M Nowak"
      ],
      "year": 2010,
      "doi": "10.2196/jmir.1430"
    },
    {
      "title": "A randomized controlled trial evaluating a manualized TeleCoaching protocol for improving adherence to a web-based intervention for the treatment of depression",
      "authors": [
        "D Mohr",
        "J Duffecy",
        "J Ho",
        "M Kwasny",
        "X Cai",
        "M Burns"
      ],
      "year": 2013,
      "doi": "10.1371/journal.pone.0070086"
    },
    {
      "title": "Maintenance of weight loss in overweight middle-aged women through the Internet",
      "authors": [
        "E Cussler",
        "P Teixeira",
        "S Going",
        "L Houtkooper",
        "L Metcalfe",
        "R Blew"
      ],
      "year": 2008,
      "doi": "10.1038/oby.2008.19"
    },
    {
      "title": "Engagement in a diabetes self-management website: usage patterns and generalizability of program use",
      "authors": [
        "R Glasgow",
        "S Christiansen",
        "D Kurz",
        "D King",
        "T Woolley",
        "A Faber"
      ],
      "year": 2011,
      "doi": "10.2196/jmir.1391"
    },
    {
      "title": "Prospective associations between intervention components and website engagement in a publicly available physical activity website: the case of 10,000 Steps Australia",
      "authors": [
        "C Davies",
        "Corry Van Itallie",
        "A Vandelanotte",
        "C Caperchione",
        "C Mummery"
      ],
      "year": 2012,
      "doi": "10.2196/jmir.1792"
    },
    {
      "title": "Self-Monitoring Utilization Patterns Among Individuals in an Incentivized Program for Healthy Behaviors",
      "authors": [
        "J Kim",
        "N Wineinger",
        "M Taitel",
        "J Radin",
        "O Akinbosoye",
        "J Jiang"
      ],
      "year": 2016,
      "doi": "10.2196/jmir.6371"
    },
    {
      "title": "Using Google Analytics as a process evaluation method for Internet-delivered interventions: an example on sexual health",
      "authors": [
        "R Crutzen",
        "J Roosjen",
        "J Poelman"
      ],
      "year": 2013,
      "doi": "10.1093/heapro/das008"
    },
    {
      "title": "Analyzing mHealth Engagement: joint models for intensively collected user engagement data",
      "authors": [
        "E Scherer",
        "D Ben-Zeev",
        "Z Li",
        "J Kane"
      ],
      "year": 2017,
      "doi": "10.2196/mhealth.6474"
    },
    {
      "title": "Mining big data",
      "authors": [
        "W Fan",
        "A Bifet"
      ],
      "year": 2013,
      "doi": "10.1145/2481244.2481246"
    },
    {
      "title": "Online interventions for social marketing health behavior change campaigns: a meta-analysis of psychological architectures and adherence factors",
      "authors": [
        "B Cugelman",
        "M Thelwall",
        "P Dawes"
      ],
      "year": 2011,
      "doi": "10.2196/jmir.1367"
    },
    {
      "title": "A systematic review of the impact of adherence on the effectiveness of e-therapies",
      "authors": [
        "L Donkin",
        "H Christensen",
        "S Naismith",
        "B Neal",
        "I Hickie",
        "N Glozier"
      ],
      "year": 2011,
      "doi": "10.2196/jmir.1772"
    },
    {
      "title": "Adaptive interventions and SMART designs: application to child behavior research in a community setting",
      "authors": [
        "K Kidwell",
        "L Hyde"
      ],
      "year": 2016,
      "doi": "10.1177/1098214015617013"
    },
    {
      "title": "A conceptual framework for adaptive preventive interventions",
      "authors": [
        "L Collins",
        "S Murphy",
        "K Bierman"
      ],
      "year": 2004,
      "doi": "10.1023/B:PREV.0000037641.26017.00"
    },
    {
      "title": "Large-scale physical activity data reveal worldwide activity inequality",
      "authors": [
        "T Althoff",
        "R Sosi\u010d",
        "J Hicks",
        "A King",
        "Delp Leskovec"
      ],
      "year": 2017,
      "doi": "10.1038/nature23018"
    },
    {
      "title": "Trials of intervention principles: evaluation methods for evolving behavioral intervention technologies",
      "authors": [
        "D Mohr",
        "S Schueller",
        "W Riley",
        "C Brown",
        "P Cuijpers",
        "N Duan"
      ],
      "year": 2015,
      "doi": "10.2196/jmir.4391"
    },
    {
      "title": "Iterative development and evaluation methods of mHealth behavior change interventions",
      "authors": [
        "M Jacobs",
        "A Graham"
      ],
      "year": 2016,
      "doi": "10.1016/j.copsyc.2015.09.001"
    },
    {
      "title": "More real-world trials are needed to establish if web-based physical activity interventions are effective",
      "authors": [
        "C Vandelanotte",
        "M Duncan",
        "G Kolt",
        "C Caperchione",
        "T Savage",
        "A Van Itallie"
      ],
      "year": 2018,
      "doi": "10.1136/bjsports-2018-099437"
    },
    {
      "title": "The multiphase optimization strategy (MOST) and the sequential multiple assignment randomized trial (SMART): new methods for more potent eHealth interventions",
      "authors": [
        "L Collins",
        "S Murphy",
        "V Strecher"
      ],
      "year": 2007,
      "doi": "10.1016/j.amepre.2007.01.022"
    },
    {
      "title": "mHealth interventions for weight loss: a guide for achieving treatment fidelity",
      "authors": [
        "R Shaw",
        "D Steinberg",
        "L Zullig",
        "H Bosworth",
        "C Johnson",
        "L Davis"
      ],
      "year": 2014,
      "doi": "10.1136/amiajnl-2013-002610"
    },
    {
      "title": "Systematic review of smartphone-based passive sensing for health and wellbeing",
      "authors": [
        "V Cornet",
        "R Holden"
      ],
      "year": 2018,
      "doi": "10.1016/j.jbi.2017.12.008"
    },
    {
      "title": "Accuracy of smartphone applications and wearable devices for tracking physical activity data",
      "authors": [
        "L Barkhuus",
        "A ; Dey",
        "Ma",
        "H Burwick",
        "K Volpp",
        "M Patel"
      ],
      "year": 2003,
      "doi": "10.1001/jama.2014.17841"
    },
    {
      "title": "Physical activity intensity can be accurately monitored by smartphone global positioning system 'app",
      "authors": [
        "B Gordon",
        "L Bruce",
        "A Benson"
      ],
      "year": 2016,
      "doi": "10.1080/17461391.2015.1105299"
    },
    {
      "title": "Are health behavior change interventions that use online social networks effective? A systematic review",
      "authors": [
        "C Maher",
        "L Lewis",
        "K Ferrar",
        "S Marshall",
        "De Bourdeaudhuij",
        "I Vandelanotte"
      ],
      "year": 2014,
      "doi": "10.2196/jmir.2952"
    },
    {
      "title": "Representation of health conditions on Facebook: content analysis and evaluation of user engagement",
      "authors": [
        "T Hale",
        "A Pathipati",
        "S Zan",
        "K Jethwani"
      ],
      "year": 2014,
      "doi": "10.2196/jmir.3275"
    },
    {
      "title": "What social media data mean for audience studies: a multidimensional investigation of Twitter use during a current affairs TV programme",
      "authors": [
        "E D'heer",
        "P Verdegem"
      ],
      "year": 2014,
      "doi": "10.1080/1369118X.2014.952318"
    },
    {
      "title": "Engagement, compliance and retention with a gamified online social networking physical activity intervention",
      "authors": [
        "J Ryan",
        "S Edney",
        "C Maher"
      ],
      "year": 2017,
      "doi": "10.1007/s13142-017-0499-8"
    },
    {
      "title": "Mark My Words: the design of an innovative methodology to detect and analyze interpersonal health conversations in web and social media",
      "authors": [
        "M Bouman",
        "C Drossaert",
        "M Pieterse"
      ],
      "year": 2012,
      "doi": "10.1080/15228835.2012.743394"
    },
    {
      "title": "Measure What Matters: Online Tools for Understanding Customers, Social Media, Engagement, and Key Relationships",
      "authors": [
        "Delahaye Paine"
      ],
      "year": 2018
    },
    {
      "title": "Social Media Measurement",
      "authors": [
        "C Murdough"
      ],
      "year": 2009,
      "doi": "10.1080/15252019.2009.10722165"
    },
    {
      "title": "Pragmatic nihilism: how a Theory of Nothing can help health psychology progress",
      "authors": [
        "G Peters",
        "R Crutzen"
      ],
      "year": 2017,
      "doi": "10.1080/17437199.2017.1284015"
    },
    {
      "title": "Psychophysiological measures of human cognitive states applied in human computer interaction",
      "authors": [
        "A Dirican",
        "M G\u00f6kt\u00fcrk"
      ],
      "year": 2011,
      "doi": "10.1016/j.procs.2011.01.016"
    },
    {
      "title": "The Psychophysiology Primer: a guide to methods and a broad review with a focus on human-computer interaction",
      "authors": [
        "B Cowley",
        "M Filetti",
        "K Lukander",
        "J Torniainen",
        "A Henelius",
        "L Ahonen"
      ],
      "year": 2015,
      "doi": "10.1561/9781680831993"
    },
    {
      "title": "Applying psychophysiological methods for measuring user experience: possibilities, challenges and feasibility",
      "authors": [
        "E Ganglbauer",
        "J Schrammel",
        "S Deutsch",
        "M Tscheligi"
      ],
      "year": 2009
    },
    {
      "title": "Physiological correlates of the flow experience during computer game playing",
      "authors": [
        "L Harmat",
        "\u00d6 De Manzano",
        "T Theorell",
        "L H\u00f6gman",
        "H Fischer",
        "F Ull\u00e9n"
      ],
      "year": 2015,
      "doi": "10.1016/j.ijpsycho.2015.05.001"
    },
    {
      "title": "Use of auditory event-related potentials to measure immersion during a computer game",
      "authors": [
        "C Burns",
        "S Fairclough"
      ],
      "year": 2015,
      "doi": "10.1016/j.ijhcs.2014.09.002"
    },
    {
      "title": "Measuring Game Engagement",
      "authors": [
        "R Martey",
        "K Kenski",
        "J Folkestad",
        "L Feldman",
        "E Gordis",
        "A Shaw"
      ],
      "year": 2014,
      "doi": "10.1177/1046878114553575"
    },
    {
      "title": "Automated mood-aware engagement prediction",
      "authors": [
        "S Dhamija",
        "T Boult"
      ],
      "year": 2017
    },
    {
      "title": "EngageMon",
      "authors": [
        "S Huynh",
        "S Kim",
        "J Ko",
        "R Balan",
        "Y Lee"
      ],
      "year": 2018,
      "doi": "10.1145/3191745"
    },
    {
      "title": "Changes in heart rate and facial actions during a gaming session with provoked boredom and stress",
      "authors": [
        "F Bevilacqua",
        "H Engstr\u00f6m",
        "P Backlund"
      ],
      "year": 2018,
      "doi": "10.1016/j.entcom.2017.10.004"
    },
    {
      "title": "From lab to field conditions: a pilot study on EEG methodology in applied sports sciences",
      "authors": [
        "K Reinecke",
        "M Cordes",
        "C Lerch",
        "F Koutsandr\u00e9ou",
        "M Schubert",
        "M Weiss"
      ],
      "year": 2011,
      "doi": "10.1007/s10484-011-9166-x"
    },
    {
      "title": "Issues and considerations for using the scalp surface Laplacian in EEG/ERP research: A tutorial review",
      "authors": [
        "J Kayser",
        "C Tenke"
      ],
      "year": 2015,
      "doi": "10.1016/j.ijpsycho.2015.04.012"
    },
    {
      "title": "EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis",
      "authors": [
        "A Delorme",
        "S Makeig"
      ],
      "year": 2004,
      "doi": "10.1016/j.jneumeth.2003.10.009"
    },
    {
      "title": "An Introduction to the Event-Related Potential Technique",
      "authors": [
        "S Luck"
      ],
      "year": 2005
    },
    {
      "title": "The relationship between engagement and neurophysiological measures of attention in motion-controlled video games: a randomized controlled trial",
      "authors": [
        "A Leiker",
        "M Miller",
        "L Brewer",
        "M Nelson",
        "M Siow",
        "K Lohse"
      ],
      "year": 2016,
      "doi": "10.2196/games.5460"
    },
    {
      "title": "The efficacy of auditory probes in indexing cognitive workload is dependent on stimulus complexity",
      "authors": [
        "F Dyke",
        "A Leiker",
        "K Grand",
        "M Godwin",
        "A Thompson",
        "J Rietschel"
      ],
      "year": 2015,
      "doi": "10.1016/j.ijpsycho.2014.12.008"
    },
    {
      "title": "Electrophysiological measurement of interest during walking in a simulated environment",
      "authors": [
        "Y Takeda",
        "T Okuma",
        "M Kimura",
        "T Kurata",
        "T Takenaka",
        "S Iwaki"
      ],
      "year": 2014,
      "doi": "10.1016/j.ijpsycho.2014.05.012"
    },
    {
      "title": "Eye movements in reading and information processing: 20 years of research",
      "authors": [
        "K Rayner"
      ],
      "year": 1998,
      "doi": "10.1037//0033-2909.124.3.372"
    },
    {
      "title": "Eye movement registration as a continuous index of attention deployment: data from a group of spider anxious students",
      "authors": [
        "D Hermans",
        "D Vansteenwegen",
        "P Eelen"
      ],
      "year": 1999,
      "doi": "10.1080/026999399379249"
    },
    {
      "title": "Measuring and defining the experience of immersion in games",
      "authors": [
        "C Jennett",
        "A Cox",
        "P Cairns",
        "S Dhoparee",
        "A Epps",
        "T Tijs"
      ],
      "year": 2008,
      "doi": "10.1016/j.ijhcs.2008.04.004"
    },
    {
      "title": "Do personally tailored videos in a web-based physical activity intervention lead to higher attention and recall? -An eye-tracking study",
      "authors": [
        "S Alley",
        "C Jennings",
        "N Persaud",
        "R Plotnikoff",
        "M Horsley",
        "C Vandelanotte"
      ],
      "year": 2014,
      "doi": "10.3389/fpubh.2014.00013"
    },
    {
      "title": "Social presence and use of internet-delivered interventions: a multi-method approach",
      "authors": [
        "R Crutzen",
        "D Cyr",
        "H Larios",
        "R Ruiter",
        "N De Vries"
      ],
      "year": 2013,
      "doi": "10.1371/journal.pone.0057067"
    },
    {
      "title": "More than a feeling: measurement of sonic user experience and psychophysiology in a first-person shooter game",
      "authors": [
        "L Nacke",
        "M Grimshaw",
        "C Lindley",
        "A Desmet",
        "C Woods",
        "S Williams",
        "C Maher",
        "A Middelweerd",
        "A M\u00fcller",
        "P Wark",
        "C Vandelanotte",
        "L Poppe",
        "M Hingle",
        "R Crutzen"
      ],
      "year": 2010,
      "doi": "10.2196/jmir.9397"
    }
  ],
  "num_references": 140,
  "original_doi": "https://doi.org/10.13039/501100001030"
}
