{
  "paper_id": "UHBB5IRG",
  "title": "Current applications and challenges in large language models for patient care: a systematic review Check for updates",
  "abstract": "Background The introduction of large language models (LLMs) into clinical practice promises to improve patient education and empowerment, thereby personalizing medical care and broadening access to medical knowledge. Despite the popularity of LLMs, there is a significant gap in systematized information on their use in patient care. Therefore, this systematic review aims to synthesize current applications and limitations of LLMs in patient care. Methods We systematically searched 5 databases for qualitative, quantitative, and mixed methods articles on LLMs in patient care published between 2022 and 2023. From 4349 initial records, 89 studies across 29 medical specialties were included. Quality assessment was performed using the Mixed Methods Appraisal Tool 2018. A data-driven convergent synthesis approach was applied for thematic syntheses of LLM applications and limitations using free line-by-line coding in Dedoose. Results We show that most studies investigate Generative Pre-trained Transformers (GPT)-3.5 (53.2%, n = 66 of 124 different LLMs examined) and GPT-4 (26.6%, n = 33/124) in answering medical questions, followed by patient information generation, including medical text summarization or translation, and clinical documentation. Our analysis delineates two primary domains of LLM limitations: design and output. Design limitations include 6 secondorder and 12 third-order codes, such as lack of medical domain optimization, data transparency, and accessibility issues, while output limitations include 9 second-order and 32 third-order codes, for example, non-reproducibility, non-comprehensiveness, incorrectness, unsafety, and bias. Conclusions This review systematically maps LLM applications and limitations in patient care, providing a foundational framework and taxonomy for their implementation and evaluation in healthcare settings.",
  "year": 2023,
  "date": "2023-02-02",
  "authors": [
    {
      "name": "Felix Busch",
      "email": "felix.busch@tum.de",
      "orcid": "0000-0001-9770-8555",
      "affiliation": {
        "organization": "School of Medicine and Health",
        "department": "School of Medicine and Health",
        "institution": "Isar",
        "address": "Munich, Germany"
      }
    },
    {
      "name": "Lena Hoffmann",
      "affiliation": {
        "organization": "Department of Neuroradiology",
        "department": "Department of Neuroradiology",
        "institution": "Charit\u00e9 -Universit\u00e4tsmedizin Berlin",
        "address": "Berlin, Germany"
      }
    },
    {
      "name": "Christopher Rueger",
      "affiliation": {
        "organization": "Department of Neuroradiology",
        "department": "Department of Neuroradiology",
        "institution": "Charit\u00e9 -Universit\u00e4tsmedizin Berlin",
        "address": "Berlin, Germany"
      }
    },
    {
      "name": "Elon Van Dijk",
      "affiliation": {
        "organization": "Department of Ophthalmology",
        "department": "Department of Ophthalmology",
        "institution": "Leiden University Medical Center",
        "address": "Leiden, The Netherlands"
      }
    },
    {
      "name": "Rawen Kader",
      "orcid": "0000-0001-9133-0838",
      "affiliation": {
        "organization": "Division of Surgery and Interventional Sciences",
        "department": "Division of Surgery and Interventional Sciences",
        "institution": "University College London",
        "address": "London, United Kingdom"
      }
    },
    {
      "name": "Esteban Ortiz-Prado",
      "affiliation": {
        "organization": "One Health Research Group",
        "department": "One Health Research Group"
      }
    },
    {
      "name": "Marcus Makowski",
      "orcid": "0000-0001-8778-647X",
      "affiliation": {
        "organization": "School of Medicine and Health",
        "department": "School of Medicine and Health",
        "institution": "Isar",
        "address": "Munich, Germany"
      }
    },
    {
      "name": "Luca Saba"
    },
    {
      "name": "Martin Hadamitzky"
    },
    {
      "name": "Jakob Nikolas Kather",
      "orcid": "0000-0002-3730-5348"
    },
    {
      "name": "Daniel Truhn",
      "orcid": "0000-0002-9605-0728"
    },
    {
      "name": "Renato Cuocolo"
    },
    {
      "name": "Lisa Adams",
      "affiliation": {
        "organization": "School of Medicine and Health",
        "department": "School of Medicine and Health",
        "institution": "Isar",
        "address": "Munich, Germany"
      }
    },
    {
      "name": "Keno Bressem",
      "affiliation": {
        "organization": "School of Medicine and Health",
        "department": "School of Medicine and Health",
        "institution": "Isar",
        "address": "Munich, Germany"
      }
    }
  ],
  "doi": "10.1038/s43856-024-00717-2",
  "orcid": "0000-0002-9605-0728",
  "md5": "6EE8978CC09E700B90979366BF3924E9",
  "publication": {
    "journal": "medRxiv",
    "journal_inferred": true
  },
  "funding": [
    "",
    "",
    "Acknowledgements This research is funded by the  European Union  ( 101079894 ). Views and opinions expressed are however those of the authors only and do not necessarily reflect those of the  European Union  or European Commission. Neither the European Union nor the granting authority can be held responsible for them. The funding had no role in the study design, data collection and analysis, manuscript preparation, or decision to publish."
  ],
  "sections": [
    {
      "text": "Public and academic interest in large language models (LLMs) and their potential applications has increased substantially, especially since the release of OpenAI's ChatGPT (Chat Generative Pre-trained Transformers) in November 2022  [1] [2] [3]  . One of the main reasons for their popularity is the remarkable ability to mimic human writing, a result of extensive training on massive amounts of text and reinforcement learning from human feedback  4  .\n\nSince most LLMs are designed as general-purpose chatbots, recent research has focused on developing specialized models for the medical domain, such as Meditron or BioMistral, by enriching the training data of LLMs with medical knowledge  5, 6  . However, this approach to fine-tuning LLMs requires significant computational resources that are not available to everyone and is also not applicable to closed-source LLMs, which are often the most powerful. Therefore, another approach to improve LLMs for database in the Supplementary Methods). After importing the bibliographic data into Rayyan and removing duplicates, LH and CR conducted an independent blind review of each article's title and abstract  16  . Any article flagged as potentially eligible by either reviewer proceeded to the full-text evaluation stage. For this stage, LH and CR used a custom data extraction form created in Google Forms (available online)  17  to collect all relevant data independently from the studies that met the inclusion criteria. Quality assessment was also performed independently for each article within this data extraction form, using the Mixed Methods Appraisal Tool (MMAT) 2018  18  . Disagreements at any stage of the review were resolved through discussion with the author FB. In cases of studies with incomplete data, we have tried to contact the corresponding authors for clarification or additional information."
    },
    {
      "title": "Data analysis",
      "text": "Due to the diversity of investigated outcomes and study designs we sought to include, a meta-analysis was not practical. Instead, a data-driven convergent synthesis approach was selected for thematic syntheses of LLM applications and limitations in patient care  19  . Following Thomas and Harden, FB coded each study's numerical and textual data in Dedoose using free line-by-line coding  20, 21  . Initial codes were then systematically categorized into descriptive and subsequently into analytic themes, incorporating new codes for emerging concepts within a hierarchical tree structure. Upon completion of the codebook, FB and LH reviewed each study to ensure consistent application of codes. Discrepancies were resolved through discussion with the author KKB, and the final codebook and analytical themes were discussed and refined in consultation with all contributing authors."
    },
    {
      "title": "Results"
    },
    {
      "title": "Screening results",
      "text": "Of the 4349 reports identified, 2991 underwent initial screening, and 126 were deemed suitable for potential inclusion and underwent full-text screening. Two articles could not be retrieved because the authors or the corresponding title and abstract could not be identified online. Following full-text screening, 35 articles were excluded, and 89 articles were included in the final review. Most studies were excluded because they targeted the wrong discipline (n = 10/35, 28.6%) or population (n = 7/35, 20%) or were not original research (n = 8/35, 22.9%) (see Supplementary Dataset file 2). For example, we evaluated a study that focused on classifying physician notes to identify patients without active bleeding who were appropriate candidates for thromboembolism prophylaxis  22  . Although the classification tasks may lead to patient treatment, the primary outcome was informing clinicians rather than directly forwarding this information to patients. We also reviewed a study assessing the accuracy and completeness of several LLMs when answering Methotrexate-related questions  23  . This study was excluded because it focused solely on the pharmacological treatment of rheumatic disease. For a detailed breakdown of the inclusion and exclusion process at each stage, please refer to the PRISMA flowchart in Fig.  1 ."
    },
    {
      "title": "Characteristics of included studies",
      "text": "Supplementary Dataset file 3 summarizes the characteristics of the analyzed studies, including their setting, results, and conclusions. One study (n = 1/ 89, 1.1%) was published in 2022  24  , 84 (n = 84/89, 94.4%) in 2023  13,  , and 4 (n = 4/89, 4.5%) in 2024  [108] [109] [110] [111]  (all of which were peer-reviewed publications of preprints published in 2023). Most s udies were quantitative nonrandomized (n = 84/89, 94.4%)  13, [25] [26] [27] 103, 104, 106, 107, [109] [110] [111]  , 4 (n = 4/89, 4.5%)  28, 102, 105, 108  had a qualitative study design, and one (n = 1/89, 1.1%)  24  was quantitative randomized according to the MMAT 2018 criteria. However, the LLM outputs were often first analyzed quantitatively but followed by a qualitative analysis of certain responses. Therefore, if the primary outcome was quantitative, we considered the study design to be quantitative rather than mixed methods, resulting in the inclusion of zero mixed methods studies. The quality of the included studies was mixed (see Supplementary Dataset file 4). The authors were primarily affiliated with institutions in the United States (n = 47 of 122 different countries identified per publication, 38.5%), followed by Germany (n = 11/122, 9%), Turkey (n = 7/122, 5.7%), the United Kingdom (n = 6/122, 4.9%), China/Australia/Italy (n = 5/122, 4.1%, respectively), and 24 (n = 36/122, 29.5%) other countries. Most studies examined one or more applications based on the GPT-3.5 architecture (n = 66 of 124 different LLMs examined per study, 53.2%)  13,26-29,31-34, 36-40,42-49,52-54,56-61,63,65-67,71,72,74,75,77,78,81-89,91,92,94,95,97-100,102-104,106-109,111  , followed by GPT-4 (n = 33/124, 26.6%)  13, 25, 27, 29, 30, [34] [35] [36] 41, 43, 50, 51, 54, 55, 58, 61, 64, [68] [69] [70] 74, 76, [79] [80] [81] 83, 87, 89, 90, 93, 96, 98, 99, 101, 105  , Bard (n = 10/124, 8.1%; now known as Gemini)  33, 48, 49, 55, 73, 74, 80, 87, 94, 99  , Bing Chat (n = 7/124, 5.7%; now Microsoft Copilot)  49, 51, 55, 73, 94, 99, 110  , and other applications based on Bidirectional Encoder Representations from Transformers (BERT; n = 4/124, 3.2%)  13, 83, 84  , Large Language Model Meta-AI (LLaMA; n = 3/124, 2.4%)  55  , or Claude by Anthropic (n = 1/124, 0.8%)  55  . The maj rity of applications were primarily targeted at patients (n = 64 of 89 included studies, 73%)  24, 25, 29, 32, [34] [35] [36] [37] [38] [39] [41] [42] [43] [45] [46] [47] [48] [52] [53] [54] [56] [57] [58] [59] [60] 62, 63, 65, 66, [68] [69] [70] [71] [73] [74] [75] [77] [78] [79] [80] [85] [86] [87] [88] [89] [90] [91] [92] [93] [94] [95] 97, 99, 100, [102] [103] [104] [105] [106] [107] [108] [109] [110] [111]  or both patients and caregivers (n = 25/89, 27%)  13, [26] [27] [28] 30, 31, 33, 40, 44, [49] [50] [51] 55, 61, 64, 67, 72, 76, [81] [82] [83] [84] 96, 98, 101  . Information about conflicts of interest and funding was not explicitly stated in 23 (n = 23/89, 25.8%) studies, while 48 (n = 48/89, 53.9%) reported that there were no conflicts of interest or funding. A total of 18 (n = 18/89, 20.2%) studies reported the presence of conflicts of interest and funding  13, 24, 38, 40, 54, 58, 59, 67, [69] [70] [71] 74, 80, 84, 96, 103, 105, 111  . Most studies did not report information about the institutional review board (IRB) approval (n = 55/89, 61.8%) or deemed IRB approval unnecessary (n = 28/89, 31.5%). Six studies obtained IRB approval (n = 6/89, 6.7%)  52, 82, [84] [85] [86] 92  ."
    },
    {
      "title": "Applications of large language models",
      "text": "An overview of the presence of codes for each study is provided in the Supplementary Dataset file 3. The majority of articles investigated the use and feasibility of LLMs as medical chatbots (n = 84/89, 94.4%) 13,24-62,64-66,68,69,71-96,98-111 , while fewer reports additionally or exclusively focused on the generation of patient information (n = 18/89, 20.2%)  24, 31, 43, 48, 49, 57, 59, 62, 67, 79, [88] [89] [90] [91] 97, 102, 106, 107  , including clinical documentation such as informed consent forms (n = 5/89, 5.6%)  43, 67, 91, 97, 102  and discharge instructions (n = 1/89, 1.1%)  31  , or translation/summarization tasks of medical texts (n = 5/89, 5.6%)  24, 49, 57, 79, 89  , creation of patient education materials (n = 5/89, 5.6%)  48, 62, 90, 106, 107  , and simplification of radiology reports (n = 2/89, 2.3%)  59, 88  . Most reports evaluated LLMs in English (n = 88/89, 98.9%)  13, [105] [106] [107] [108] [109] [110] [111]  , followed by Arabic (n = 2/84, 2.3%)  32, 104  , Mandarin (n = 2/84, 2.3%)  36, 75  , and Korean or Spanish (n = 1/89, 1.1%, respectively)  75  . The top-five specialties studied were ophthalmology (n = 10/89, 11.2%)  37, 40, 48, 51, 65, 74, 97, 98, 100, 101  , gastroenterology (n = 9/89, 10.1%)  25, 32, 34, 36, 39, 61, 62, 72, 96  , head and neck surgery/otolaryngology (n = 8/89, 9%)  35, 42, 56, 64, 66, 76, 78, 79  , and radiology  59, 70, [88] [89] [90] 110  or plastic surgery  45, 47, 49, 102, 107, 108  (n = 6/89, 6.7%, respectively). A schematic ill stration of the identified concepts of LLM applications in patient care is shown in Fig.  2 ."
    },
    {
      "title": "Limitations of large language models",
      "text": "The thematic synthesis of limitations resulted in two main concepts: one related to design limitations and one related to output. Figure  3  illustrates the hierarchical tree structure and quantity of the codes derived from the thematic synthesis of limitations. Supplementary Dataset file 5 provides an overview of the taxonomy of all identified limitation concepts, including their description and examples.\n\nDesign limitations. In terms of design limitations, many authors noted the limitation that LLMs are not optimized for medical use (n = 46/89, 51.7%)  13, 26, 28, 34, 35, [37] [38] [39] 46, 49, 50, [54] [55] [56] [57] [58] [59] 61, 62, 65, 66, 68, 70, 71, [79] [80] [81] [83] [84] [85] 88, 91, [93] [94] [95] [96] [97] [98] [100] [101] [102] [103] [104] [105] [106] [107] 109  , including implicit knowledge/lack of clinical context (n = 13/89, 14.6%)  28, 39, 46, 66, 71, 79, 81, [83] [84] [85] 98, 103  , limitations in clinical reasoning (n = 7/89, Fig.  1  | Preferred reporting items for systematic reviews and meta-analyzes (PRISMA) flow diagram. A total of 4349 reports were identified from Web of Science, PubMed, Embase/Embase Classic, ACM Digital Library, and IEEE Xplore. After excluding 1358 duplicates, 2991 underwent initial screening and 126 were deemed suitable for potential inclusion and underwent full-text screening. Two articles could not be retrieved because the authors or the corresponding title and abstract could not be identified online. After full text screening, 35 articles were excluded and 89 articles were included in the final review.\n\n7.9%)  55, 84, 95, [102] [103] [104] [105]  , limitations in medical image processing/production (n = 5/89, 5.6%)  37, 55, 91, 106, 107  , and misunderstanding of medical information and terms by the model (n = 7/89, 7.9%)  28, 38, 39, 59, 62, 65, 97  . In addition, data-related limitations were identified, including limited access to data on the internet (n = 22/89, 24.7%)  38, 39, 41, 43, [54] [55] [56] [57] 59, 60, 64, 76, 79, [82] [83] [84] 88, 91, 94, 96, 104, 109  , the undisclosed origin of training data (n = 36/89, 40.5%)  25, 26, 29, 30, 32, 34, 36, 37, 40, 46, 47, 50, 51, [53] [54] [55] [56] [57] [58] [59] [60] 64, 65, 70, 71, 76, 82, 83, 91, [94] [95] [96] 101, 105, 109  , limitations in providing, evaluating, and validating references (n = 20/89, 22.5%)  45, 49, [54] [55] [56] [57] 65, 71, 73, 76, 80, 83, 85, 91, 94, 96, 98, 101, 103, 105  , and storage/processing of sensitive health information (n = 8/89, 9%)  13, 34, 46, 55, 62, 76, 83, 109  . Further second-order concepts include  black-box algorithms, i.e., nonexplainable AI (n = 12/89, 13.5%)  27, 36, 55, 57, 65, 73, 76, 83, 91, 94, 103, 105  , limited engagement and dialog capabilities (n = 10/89, 11.2%)  13, 27, 28, 37, 38, 51, 56, 66, 95, 103  , and the inability of self-validation and correction (n = 4/89, 4.5%)  61, 73, 74, 107  .\n\nOutput limitations. The evaluation of limitations in output data yielded 7 second-order codes concerning the non-reproducibility (n = 38/89, 42.7%)  28, 29, 34, 38, 39, 41, 43, 45, 46, 49, [54] [55] [56] [57] [58] [59] [60] [61] 64, 65, [71] [72] [73] 76, 80, 82, 83, 85, 90, 91, 94, 96, 98, 99, 101, [103] [104] [105]  , noncomprehensiveness (n = 78/89, 87.6%) 13,25,26,28-30,32-44,46,48-62,64,65,67-79, 81-98,100,102-107,109-111 , incorrectness (n = 78/89, 87.6%) 13,25-44,46,49-52, 54-62,64-66,69-79,81-85,87-107,109-111\n\n, (un-)safeness (n = 39/89, 43.8%)  28, 30, 35, 37, 39, 40, [42] [43] [44] 46, 50, 51, [57] [58] [59] [60] 62, 64, 65, 69, 70, 73, 74, 76, [78] [79] [80] 82, 84, 85, 91, 94, 95, [98] [99] [100] 105, 106, 109  , bias (n = 6/89, 6.7%)  26, 32, 34, 36, 66, 103  , and the dependence of the quality of output on the prompt-/input provided (n = 27/89, 30.3%)  [26] [27] [28] 34, 38, 41, 44, 46, 51, 52, 56, [68] [69] [70] [71] [72] 74, 76, 78, 79, [81] [82] [83] 90, 94, 95, 100, 101  or the environment (n = 16/89, 18%)  13, 34, 46, [49] [50] [51] 54, 58, 60, 72, 73, 88, 90, 93, 97, 109  . Non-reproducibility. For non-reproducibility, key concepts included the non For non-reproducibility, key concepts included the non-deterministic nature of the output, e.g., due to inconsistent results across multiple iterations (n = 34/89, 38.2%)  28, 29, 34, 38, 39, 41, 43, 46, [58] [59] [60] [61] 72, 76, 82, 90, 94, 98, 99, 101, 103, 104  and the inability to provide reliable references (n = 20/89, 22.5%)  45, 49, [54] [55] [56] [57] 65, 71, 73, 76, 80, 83, 85, 91, 94, 96, 98, 101, 103, 105  . 38.2%)  13, 28, 30, 34, 37, 38, 41, 43, 49, 51, 56, 57, 59, 61, 65, 70, 77, 79, 81, [84] [85] [86] 90, 94, 95, 100, [102] [103] [104] [105] [106] [107] 110  , incompleteness of output (n = 68/89, 76.4%)  13, 25, 26, [28] [29] [30] 32, [34] [35] [36] [37] [38] [39] [41] [42] [43] [44] 46 ,49-52,55-62,64,65,67-69,72-77, 79,81-86,89-98,100,102-107,109-111"
    },
    {
      "title": "Non",
      "text": ", provision of information that is not standard of care (n = 24/89, 27%)  28, 40, 43, 46, 49, 50, 54, 57, 58, 65, 69, 72, 73, 77, 78, 81, 85, 91, 94, 98, 100, 103, 107, 111  and/or outdated (n = 12/89, 13.5%)  13, 25, 32, 34, 38, 41, 43, 44, 49, 54, 83, 84  , and production of oversimplified (n = 10/89, 11.2%)  38, 46, 49, 54, 59, 79, 84, 85, 103  , superfluous (n = 16/89, 18%)  13, 28, 34, 38, 46, 62, 72, 79, 86, 90, 94, 97, 100, 106, 107  , o v e r c a u t i o u s ( n = 7/89, 7.9%)  13, 28, 37, 51, 70, 103, 110  , overempathic (n = 1/89, 1.1%)  13  , or output with inappropriate complexity/reading level for patients (n = 22/89, 24.7%)  13, 34, 42, 48, 50, 51, 53, 55, 56, 67, 71, 78, 79, 85, 87, 88, 90, 93, 106, 107, 109, 110  .\n\nIncorrectness. For incorrectness, we identified 6 key concepts. Some of the incorrect information could be attributed to what is commonly known as hallucination (n = 38/89, 42.7%)  25, 28, 32, 33, [35] [36] [37] [38] [40] [41] [42] [43] [44] [49] [50] [51] [57] [58] [59] [60] 65, 73, 74, 76, 77, 81, 83, 85, 91, 94, [96] [97] [98] 100, 103, 106, 107, 109  , i.e., the creation of entirely fictitious or false information that has no basis in the input provided or in reality (e.g., \"You may be asked to avoid eating or drinking for a few hours before the scan\" for a bone scan). Other instances of misinformation were more appropriately classified unde  alternative concepts of the original psychiatric analogy, as described in detail by Currie et al.  43, 112, 113  . These include illusion (n = 12/89, 13.5%) 28,36,38,43,57,59,77,78,85,88,94,105 , which is characterized by the generation of deceptive perceptions or the distortion of information by conflating similar but separate concepts (e.g., suggesting that MRI-type sounds might be experienced during standard nuclear medicine imaging), delirium (n = 34/89, 38.2%)  13, 26, 28, 30, 37, 43, 50, 58, 59, 61, 65, 70, [72] [73] [74] [75] 77, 79, [81] [82] [83] [84] [85] [90] [91] [92] 94, 95, 98, 102, 103, 107, 109, 110  , which indicates significant gaps in vital information, resulting in a fragmented or confused understanding of a subject (e.g., omission of crucial information about caffeine cessation for stress myocardial perfusion scans), extrapolation (n = 11/89, 12.4%)  43, 59, 65, 78, 81, 91, 94, 106, 107, 110  , which involves applying general knowledge or patterns to specific situations where they are inapplicable (e.g., advice about injection-site discomfort that is more typical of CT contrast administration), delusion (n = 14/89, 15.7%)  28, 30, 43, 50, 59, 65, 69, 73, 74, 78, 81, 94, 103, 111  , a fixed, false belief despite contradictory evidence (e.g., inaccurate waiting times for the thyroid scan), and confabulation (n = 18/89, 20.2%)  25, 28, [36] [37] [38] 40, 46, 59, 62, 65, 71, [77] [78] [79] 94, 103, 107  , i.e., filling in memory or knowledge gaps with plausible but invented information (e.g., \"You should drink plenty of fluids to help flush the radioactive material from your body\" for a biliary system-excreted radiopharmaceutical). Safety and bias. Many studies rated the generated output as unsafe, including misleading (n = 34/89, 38.2%) 28,30,35,43,44,46,50,51,57-60,62,64,65,69,73,74,76, LLM limitations (n = 89) Fig.  3  | Illustration of the hierarchical tree structure for the thematic synthesis of large language model (LLM) limitations in patient care, including the presence of codes for each concept. The font size of each concept is shown in proportion to its frequency in the studies analyzed. Our analysis delineates two primary domains of LLM limitations: design and output. Design limitations included 6 second-order and 12 thirdorder codes, while output limitations included 9 second-order and 32 third-order codes. 78-80,82,84,85,94,95,98-100,105,106,109   or even harmful content (n = 26/89, 29.2%)  28, 30, 37, 39, 40, 42, 43, 50, 51, [58] [59] [60] 70, 73, 74, 76, 79, 84, 85, 91, 94, 95, [98] [99] [100] 109  .\n\nA minority of reports identified biases in the output, which were related to language (n = 2/89, 2.3%)  32, 36  , insurance status 103 , underserved racial groups  26  , or underrepresented procedures  34  (n = 1/89, 1.1%, each).\n\nDependence on input and environment. Many authors suggested that performance was related to the prompting/input provided or the environment, i.e., depending on the evidence (n = 7/89, 7.9%)  52, 68, 69, 71, 81, 82, 95  , complexity (n = 11/89, 12.4%)  28, 34, 44, 46, 70, 74, 76, 79, 94, 102  , specificity (n = 13/89, 14.6%)  27, 38, 41, 56, 70, 72, 74, 76, 78, 81, 95, 100, 101  , quantity (n = 3/89, 3.4%)  26, 52, 74  of the input, type of conversation (n = 3/89, 3.4%)  27, 51, 90  , or the appropriateness of the output related to the target group (n = 9/89, 10.1%)  46, 49, 51, 54, 72, 90, 93, 97, 109  , provider/organization (n = 4/89, 4.5%)  13, 50, 60, 88  , and local/national medical resources (n = 5/89, 5.6%)  34, 50, 58, 60, 73  ."
    },
    {
      "title": "Discussion",
      "text": "In this systematic review, we synthesized the current applications and limitations of LLMs in patient care, incorporating a broad analysis across 29 medical specialties and highlighting key limitations in LLM design and output, providing a comprehensive framework and taxonomy for describing and categorizing limitations that may arise when using LLMs in healthcare settings.\n\nMost articles examined the use of LLMs based on the GPT-3.5 or GPT-4 architecture for answering medical questions, followed by the generation of patient information, including medical text summarization or translation and clinical documentation. The conceptual synthesis of LLM limitations revealed two key concepts: the first related to design, including 6 secondorder and 12 third-order codes, and the second related to output, including 9 second-order and 32 third-order codes. By systematically categorizing the limitations of LLMs in clinical settings, our taxonomy aims to provide healthcare professionals and developers with a framework for assessing potential risks associated with the use of LLMs in patient care. In addition, our work highlights key areas for improvement in the development of LLMs and aims to enable clinicians to make more informed decisions by understanding the limitations inherent in the design and output, thereby supporting the establishment of best practices for LLM use in clinical settings.\n\nAlthough many LLMs have been developed specifically for the biomedical domain in recent years, we found that ChatGPT has been a disruptor in the medical literature on LLMs, with GPT-3.5 and GPT-4 accounting for almost 80% of the LLMs examined in this systematic review. While it was not possible to conduct a meta-analysis of the performance on medical tasks, many authors provided a positive outlook towards the integration of LLMs into clinical practice. However, we have conceptualized several key limitations in the design and output of LLMs, some of the most prevalent in our systematic review are briefly discussed in the following paragraphs.\n\nThe majority of studies (n = 55/89) reported limitations that were conceptualized as related to the underlying data of the LLMs studied. Especially the use of proprietary models such as ChatGPT in the biomedical field was a concern in many of the studies analyzed, mainly because of the lack of training data transparency (third-order code: undisclosed origin of training data). In practice, it is widely recognized that limited access to the underlying algorithms, training data, and data processing and storage mechanisms of LLMs is a significant barrier to their application in healthcare  114  . This opacity makes it difficult for healthcare professionals to fully understand how these models function, assess their reliability, or ensure compliance with local medical standards and regulations. Consequently, the use of such models in healthcare settings can be problematic, and the need to recognize and correct potential limitations in the outputs of such models is paramount.\n\nMoreover, integrating proprietary models into clinical practice introduces a vulnerability to performance changes that occur with model updates  115  . As these models are updated by their developers, functionalities that healthcare providers rely on may be altered or broken, potentially leading to harmful outcomes for patients, which was also conceptualized in our study under output limitations (second-order code: unsafe; third-order codes: misleading/harmful). This unpredictability is a serious concern in the biomedical field, where consistency and reliability are crucial. Notably, the unpredictability of LLMs was another concept of output limitations in our systematic review (second-order code: non-reproducible; third-order codes: non-deterministic/non-referenceable).\n\nAs a result, open-source models such as BioMistral may offer a viable solution  6  . Such open source models not only offer more transparency, as their algorithms and training data are accessible but can also be adapted locally. However, given the limited number of articles on open-source LLMs in our review, we strongly encourage future studies investigating the applicability of open-source LLMs in patient care.\n\nAbout half of the studies analyzed reported limitations related to LLMs not being optimized for the medical domain. One possible solution to this limitation may be to provide medical knowledge during inference using RAG  116  . However, even when trained for general purposes, ChatGPT has previously been shown to pass the United States Medical Licensing Examination (USMLE), the German State Examination in Medicine, or even a radiology board-style examination without images  [117] [118] [119] [120]  . Although outperformed on specific tasks by specialized medical LLMs, such as Google's MedPaLM-2, this suggests that general-purpose LLMs can comprehend complex medical literature and case scenarios to a degree that meets professional standards 121 . Furthermore, given the large amounts of data on which proprietary models such as ChatGPT are trained, it is not unlikely that they have been exposed to more medical data overall than smaller specialized models despite being generalist models. Notably, a recent study even suggested that fine-tuning LLMs on biomedical data does not improve performance compared to their general-purpose counterparts  122  .\n\nIt should also be noted that passing these exams does not equate to the practical competence required of a healthcare provider, which was also a limitation identified in our review (third-order codes: implicit knowledge/ lack of clinical context; limited clinical reasoning; misunderstanding of medical information/terms; limited in processing/producing medical images)  123  . In addition, reliance on exam-based assessments carries a significant risk of bias. For example, if the exam questions or similar variants are publicly available and, thus, may be present in the training data, the LLM does not demonstrate any knowledge outside of training data memorization  124  . In fact, these types of tests can be misleading in estimating the model's true abilities in terms of comprehension or analytical skills.\n\nThe non-reproducibility of LLM output, as conceptualized in 38 studies, highlights key challenges in ensuring consistency and determinism in LLMgenerated results. One major issue is the inherent stochasticity in the models' architecture, particularly in transformer-based models, which utilize probabilistic techniques during inference (e.g., beam search or temperature sampling)  125  . This non-determinism can lead to different outputs for the same input, making it difficult to replicate results exactly across different instances or even across models with identical training data. Further external factors contributing to non-reproducibility, such as variations in hardware, software versions, or context windows, complicate the assurance of reproducibility 126 . As the reproducibility of results is a central principle in medical practice, our concepts highlight the need for more standardized protocols, improved documentation of model configurations, the examination of nondeterminism for evaluation purposes, and further research on how robust results can be achieved before implementing LLMs in real-world clinical practice. Interestingly, Ouyang et al. reported that only a minority of studies take non-determinism into account in their experimental evaluation when using ChatGPT for code generation, suggesting that this limitation is also prevalent and overlooked in other domains of LLM use  125  .\n\nThe concept of non-comprehensiveness was prevalent in almost 90% of the studies analyzed (n = 78/89). For this concept, the majority of thirdorder codes were related to LLM outputs that were incomplete. This issue is particularly significant when considering the application of LLMs in medical tasks such as clinical decision support or diagnosis, where incomplete or partial results can have serious consequences. In clinical practice, missing key information could lead to suboptimal patient outcomes, incorrect diagnoses, or improper treatment recommendations. For instance, an incomplete therapy suggestion could render the entire treatment plan insufficient, potentially resulting in harm to the patient. Given the potential of using LLMs in medical decision-making, these limitations underscore the necessity for expert supervision and validation of LLM outputs depending on their application. While LLMs used as chatbots for general patient inquiries may not require consistent human oversight, using LLMs for treatment advice would require consistent validation to ensure that incomplete information does not lead to adverse outcomes. Depending on their application, the same problem arises when the LLM generates generic or non-personalized information, which was another third-order code identified. The generation of content with high complexity and an inappropriate reading level, which was above the American Medical Association (AMA) recommended 6th-grade reading level in almost all of the 22 studies that analyzed the complexity level of the output, may further limit its usefulness for patient information 127 . Again, the best solution to the lack of comprehensiveness in clinical practice so far seems to be human oversight.\n\nIncorrectness, alongside non-comprehensiveness (as above), was the most common second-order code, identified in about 90% of studies (n = 78/89). In our conceptual synthesis of incorrect results, we followed the taxonomy of Currie et al. to classify incorrect outputs more precisely into illusions, delusions, delirium, confabulation, and extrapolation, thus proposing a framework for a more precise and structured error classification to improve the characterization of incorrect outputs and enabling more detailed performance comparisons with other research  43, 112, 113  .\n\nMany studies currently refer to all non-factual LLM results as \"hallucinations.\" However, this generalization fails to capture the complexity of errors when considering the original psychiatric analogy. Simply classifying errors as hallucinations restricts their description to invented information, overlooking errors that, for example, omit critical information and leading to fragmented or confused understanding (third-order code: delirium). Notably, the third-order code \"delirium\" was observed in nearly as many studies as the third-order code \"hallucination.\" However, a non-detailed classification of incorrect results can affect not only the comparability of research findings but also has implications for clinical practice. While hallucinations (for example, fabricating instructions like \"You may need to fast before a bone scan.\") may not always have serious consequences, errors classified as delirium-such as omitting crucial details like caffeine cessation before a stress myocardial perfusion scan-would always result in undesired outcomes (in the here presented example, most likely in repeating postponing the examination). As a result, our review advocates for a more detailed classification of incorrect results in order to increase the qualitative comparability of incorrect LLM outputs and, ultimately, the relevance and implications of these results for clinical practice.\n\nThe conceptualization of unsafeness in 39 of 89 studies presents a significant concern when considering the integration of LLMs into medical practice. In the field of medicine, any tool or intervention that could lead to misleading or harmful outcomes must be critically assessed, as the potential for patient harm is high  128, 129  . Such tools are generally only accepted when the benefits clearly outweigh the risks, and even then, informed consent from the affected individual is essential 130 . While informed consent might ensure that patients understand the risks involved and are able to make an educated decision about their care, which could be obtained, for example, in the form of a disclaimer before using the LLM, studies suggest that even when obtaining informed consent the patient understanding increases not significantly  131  . In the case of disclaimers, there might also be the risk that these are accepted without proper reading or understanding  132  . The practicality of informed consent once LLMs are deeply integrated into clinical workflows also remains an issue, as it is when patients no longer have the ability to opt out, such as in the case of serious illness. In any case, the finding that nearly half of the studies reported limitations related to LLM unsafeness suggests that LLMs are not yet reliable enough for autonomous medical use, and there is a critical need for safety measures and regulatory and human oversight to prevent adverse consequences in medical contexts  133  .\n\nFurther second-order concepts suggested that the output is influenced by the input or environment in which it is expressed. In fact, LLMs can be highly dependent on the quality and specificity of input, making their output prone to errors when faced with vague or incomplete information  [134] [135] [136]  . Again, this poses significant risks in patient care, where incorrect outputs can lead to adverse outcomes, such as inappropriate triage or treatment. For example, in our review, eleven studies reported a decrease in performance with increasing complexity of the input, which can have implications in clinical practice, such as failing to consider multifactorial medical issues like comorbidities, thus compromising the quality of care for those patients.\n\nWe found that the environment also influences the appropriateness of LLM outputs in medical settings. Models may recommend treatments that are inappropriate for certain patient populations, such as offering adult care protocols for pediatric patients or suggesting therapies that are not available in certain regions. This also raises ethical concerns, particularly in resourceconstrained settings, where making inappropriate or inaccessible recommendations may reinforce existing inequalities and lead to uncomfortable situations for both the healthcare provider and the patient  137  . One solution may be to provide adequate training to LLM users, or in our scenario, to patients, on how to present input to the model to achieve the best results. Another solution is to train or fine-tune the model to the environment in which it will be used. For example, if the LLM is trained on the standard operating procedure for handling patients with major adverse cardiovascular events in a particular hospital, it is more likely to recommend the adequate procedure in this setting than when it is trained on worldwide data from an unknown time frame, where there is a chance that it will suggest non-standard care that may only be relevant in other countries where most of the training data is coming from, or even provides outdated information (which is another third-order code that was conceptualized under noncomprehensiveness) if it is trained on data that is not current.\n\nUltimately, only six studies have identified biases in their results, for example, reflecting the unequal representation of certain content or the biases inherent in human-generated text in the training data  138  . Here, we conceptualized the results of studies that identified bias in their analysis and not only mentioned bias as a theoretical limitation. Thus, these results may indicate that the implemented safeguards are effective. On the other hand, identifying bias was not the primary outcome of most studies, and not much is known about the technology and developer policies of proprietary LLMs. Moreover, previous work has shown that automated jailbreak generation is possible across various commercial LLM chatbots 139 . In the end, LLMs are trained on large datasets that inevitably contain biases-such as gender, racial, or cultural biases-embedded in the text 140 . These biases can be amplified or reflected by the models, leading to unfair or harmful outputs. Despite the use of various mitigation techniques, such as debiasing algorithms, curating balanced datasets, or incorporating fairness-focused training objectives, eliminating bias entirely is a persistent challenge  [141] [142] [143]  . This is because LLMs learn patterns from their training data, and human biases are inherently present in much of the data they consume. Moreover, the biases introduced or reinforced by LLM are not always obvious, making them more difficult to detect and correct, which may have contributed to the comparatively low number of studies that reported any bias in their results. Notably, subtle biases, such as those related to linguistic connotations, regional dialects, or implicit associations, can be especially insidious and difficult to eliminate through technical safeguards  144  . Therefore, the results of our review may encourage future studies to more explicitly examine the biases inherent in LLMs when used for medical tasks and how such biases could be mitigated.\n\nOur findings raise a key question when applying LLMs to the medical domain: how can we entrust our patients to LLMs if they are neither reliable nor transparent? Given that models like ChatGPT are already publicly accessible and widely used, patients may already refer to them for medical questions in much the same way they use Google Search, making concerns about their early adoption somewhat academic  145  .\n\nIn addition to the advances in the development of LLMs and the focus on open source, adopting appropriate security measures to prevent the identified LLM limitations in clinical practice out-of-the-box will become increasingly important. For example, strategies to ensure LLM security and privacy can include continuous monitoring for new vulnerabilities, implementing input validation, conducting regular audits of training data, and using secure data pipelines 146 . Additionally, data anonymization, encryption, access controls, and regular security updates are essential to prevent data leakage, model theft, and privacy breaches.\n\nMoreover, expert oversight of the final LLM output could mitigate any remaining risks in the last instance, ensuring that erroneous or inappropriate suggestions are identified and corrected before they can impact patient care. Recently, efforts have been made in this direction by adopting the widely recognized Physician Documentation Quality Instrument (PDQI-9) for the assessment of AI transcripts and clinical summaries 147 . However, whether ongoing human oversight and validation of LLM-generated content is feasible and can reduce the likelihood of adverse outcomes remains the subject of further research at this early stage of LLM deployment in healthcare.\n\nAnother important factor for the successful clinical implementation of LLMs in patient care could be patient acceptance, which was not assessed in any of the studies analyzed. The growing use of LLMs in healthcare might be perceived as a reduction in the interpersonal relationship between healthcare professionals and patients, potentially leading to a sense of dehumanization in medicine 148 . Therefore, to promote a positive reception of AI tools among patients, incorporating their perspectives already during the AI development and implementation process could be key 149 . Eventually, patient perspectives are already considered in AI regulatory frameworks, such as in the European Union AI Act, which came into force in August 2024  150  . The associated challenges faced by generative AI and LLM, for example, in terms of training data transparency and validation of nondeterministic output, will show which approaches the companies will take to bring these models into compliance with the law 151 . How the notified bodies interpret and enforce the law in practice will likely be decisive for the further development of LLMs in the biomedical sector.\n\nOur study has limitations. First, our review focused on LLM applications and limitations in patient care, thus excluding research directed at clinicians only. Future studies may extend our synthesis approach to LLM applications that explicitly focus on healthcare professionals. Second, while it was not possible to conduct a meta-analysis of LLM performance to the different study designs and evaluation methods used, this will be an important area for future work as the field of LLM research in clinical settings continues to evolve. Third, there is a risk that potentially eligible studies were not included in our analysis if they were not present in the 5 databases reviewed or were not available in English. However, we screened nearly 3,000 articles in total and systematically analyzed 89 articles, providing a comprehensive overview of the current state of LLMs in patient care, even if some articles could have been missed. With our chosen cut-off date of January 2022, there is also a risk of missing relevant publications on predecessor LLM models, such as GPT-3, which was introduced in 2020. However, as our review focused on current LLM applications and limitations, it seemed most beneficial to include only recent publications from the last two years on the most advanced models, especially when considering that ChatGPT was first made available in November 2022. Finally, the rapid development and advancement of LLMs make it difficult to keep this systematic review up to date. For example, Gemini 1.5 Pro was published in February 2024, and corresponding articles are not included in this review, which synthesized articles from 2022 to 2023. This also has implications for our introduced taxonomy of LLM limitations, as new limitations may emerge as models evolve, and previous limitations may become less relevant or even obsolete. For example, our taxonomy identifies \"limited access to internet data\" as a limitation; however, with the introduction of web browsing capabilities for GPT-4 in May 2023, this particular limitation no longer applies to that model. Given these ongoing developments, we strongly encourage future studies to test, update, and extend our taxonomy to ensure that it remains a relevant tool for categorizing LLM limitations in clinical and other high-stakes applications."
    },
    {
      "text": "Fig. 2 | Schematic illustration of the identified disciplines, languages, and clinical concepts of large language models (LLMs) applications in patient care. A Column plot showing the distribution of medical specialties in which LLMs have been tested for patient care. B Pie chart illustrating the distribution of languages in which LLMs have been tested. C Schematic representation of the concepts identified for the application of LLMs in patient care."
    },
    {
      "text": "Underrepresented procedures (n = 1) Underserved racial groups (n = 1) Insurance status (n = 1) Language (n = 2) Local/national medical resources (n = 5) Provider/organization (n = 4) Target-group (n = 9) Conversation type (n = 3) Quantity (n = 3) Specificity (n = 13) Complexity (n = 11) Evidence (n = 7) Harmful (n = 26) Misleading (n = 34) Confabulation (n = 18) Illusion (n = 12) Hallucination (n = 38) Delusion (n = 14) Delirium (n = 34) Extrapolation (n = 10) High complexity/reading level (n = 22) Overempathic (n = 1) Overcautious (n = 7) Superfluous (n = 16) Oversimplification (n = 10) Outdated (n = 12) Non-standard of care (n = 24) Incomplete (n = 68) Generic/non-personalized (n = 34) Non-referenceable (n = 20) Non-deterministic (n = 24) Not open source (n = 10) Not freely accessible (n = 9) Limited number of prompts (n = 3) Stores/processes sensitive health information (n = 8) Limited in reference provision/evaluation/validation (n = 20) Undisclosed origin of training data (n = 36) Restricted access to internet data (n = 22) Misunderstanding of medical information/terms (n = 7) Limited in processing/producing medical images (n = 5) Limited clinical reasoning (n = 7) Implicit knowledge/lack of clinical context (n = 13) Bias (n = 6) Environment-dependent (n = 16) Prompt-/input dependent (n = 27) Unsafe (n = 39) Incorrect (n = 78) Non-comprehensive (n = 78) Non-reproducible (n = 38) Incapable of self-validation/correction (n = 4) Limited engagement/dialogue capabilities (n = 10) Black box (n = 12) Accessibility (n = 18) Data (n = 55) Not optimized for the medical domain (n = 46) Output (n = 86) Design (n = 67)"
    },
    {
      "title": "Acknowledgements",
      "text": "This research is funded by the  European Union  ( 101079894 ). Views and opinions expressed are however those of the authors only and do not necessarily reflect those of the  European Union  or European Commission. Neither the European Union nor the granting authority can be held responsible for them. The funding had no role in the study design, data collection and analysis, manuscript preparation, or decision to publish."
    },
    {
      "title": "Funding",
      "text": "Open Access funding enabled and organized by  Projekt DEAL ."
    },
    {
      "title": "Data availability"
    },
    {
      "title": "Author contributions"
    },
    {
      "title": "Additional information",
      "text": "Supplementary information The online version contains supplementary material available at  https://doi.org/10.1038/s43856-024-00717-2 .\n\nCorrespondence and requests for materials should be addressed to Felix Busch."
    },
    {
      "title": "Peer review information Communications Medicine thanks Dmitry",
      "text": "Scherbakov and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.\n\nReprints and permissions information is available at  http://www.nature.com/reprints Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit  http://creativecommons.org/licenses/by/4.0/ ."
    }
  ],
  "references": [
    {
      "title": "ChatGPT reaches 100 million users two months after launch",
      "authors": [
        "D Milmo"
      ],
      "year": 2023,
      "raw": "D Milmo \n\t\t \n\t\t \n\t\t ChatGPT reaches 100 million users two months after launch \n\t\t \n\t\t\t February 2, 2023 \n\t\t \n\t \n\t Milmo, D. ChatGPT reaches 100 million users two months after launch, https://www.theguardian.com/technology/2023/feb/02/chatgpt-100- million-users-open-ai-fastest-growing-app (February 2, 2023)."
    },
    {
      "year": 2023,
      "raw": "Openai \n\t\t \n\t\t arXiv:2303.08774 \n\t\t \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t GPT-4 Technical Report \n\t OpenAI. GPT-4 Technical Report. arXiv:2303.08774. https://ui. adsabs.harvard.edu/abs/2023arXiv230308774O (2023)."
    },
    {
      "title": "A survey of large language models",
      "authors": [
        "W Zhao"
      ],
      "year": 2023,
      "raw": "W X Zhao \n\t\t \n\t\t arXiv:2303.18223 \n\t\t A survey of large language models \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t arXiv preprint \n\t Zhao, W. X. et al. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023)."
    },
    {
      "title": "The future landscape of large language models in medicine",
      "authors": [
        "J Clusmann"
      ],
      "year": 2023,
      "journal": "Communications Medicine",
      "volume": "3",
      "pages": "141",
      "raw": "The future landscape of large language models in medicine \n\t\t \n\t\t\t J Clusmann \n\t\t \n\t \n\t \n\t\t Communications Medicine \n\t\t \n\t\t\t 3 \n\t\t\t 141 \n\t\t\t 2023 \n\t\t \n\t \n\t Clusmann, J. et al. The future landscape of large language models in medicine. Communications Medicine 3, 141 (2023)."
    },
    {
      "title": "Meditron-70b: Scaling medical pretraining for large language models",
      "authors": [
        "Z Chen"
      ],
      "year": 2023,
      "raw": "Z Chen \n\t\t \n\t\t arXiv:2311.16079 \n\t\t Meditron-70b: Scaling medical pretraining for large language models \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t arXiv preprint \n\t Chen, Z. et al. Meditron-70b: Scaling medical pretraining for large language models. arXiv preprint arXiv:2311.16079 (2023)."
    },
    {
      "title": "BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains",
      "authors": [
        "Y Labrak"
      ],
      "year": 2024,
      "doi": "10.18653/v1/2024.findings-acl.348",
      "raw": "BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains \n\t\t \n\t\t\t Y Labrak \n\t\t \n\t\t 10.18653/v1/2024.findings-acl.348 \n\t\t arXiv:2402.10373 \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t arXiv preprint \n\t Labrak, Y. et al. BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains. arXiv preprint arXiv:2402.10373 (2024)."
    },
    {
      "title": "Benchmarking Retrieval-Augmented Generation for Medicine",
      "authors": [
        "G Xiong",
        "Q Jin",
        "Z Lu",
        "A Zhang"
      ],
      "year": 2024,
      "doi": "10.18653/v1/2024.findings-acl.372",
      "raw": "Benchmarking Retrieval-Augmented Generation for Medicine \n\t\t \n\t\t\t G Xiong \n\t\t \n\t\t \n\t\t\t Q Jin \n\t\t \n\t\t \n\t\t\t Z Lu \n\t\t \n\t\t \n\t\t\t A Zhang \n\t\t \n\t\t 10.18653/v1/2024.findings-acl.372 \n\t\t arXiv:2402.13178 \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t arXiv preprint \n\t Xiong, G., Jin, Q., Lu, Z. & Zhang, A. Benchmarking Retrieval- Augmented Generation for Medicine. arXiv preprint arXiv:2402.13178 (2024)."
    },
    {
      "title": "A large language model for electronic health records",
      "authors": [
        "X Yang"
      ],
      "year": 2022,
      "journal": "npj Digital Medicine",
      "volume": "5",
      "pages": "194",
      "raw": "A large language model for electronic health records \n\t\t \n\t\t\t X Yang \n\t\t \n\t \n\t \n\t\t npj Digital Medicine \n\t\t \n\t\t\t 5 \n\t\t\t 194 \n\t\t\t 2022 \n\t\t \n\t \n\t Yang, X. et al. A large language model for electronic health records. npj Digital Medicine 5, 194 (2022)."
    },
    {
      "title": "Opportunities and challenges for ChatGPT and large language models in biomedicine and health",
      "authors": [
        "S Tian"
      ],
      "doi": "10.1093/bib/bbad493",
      "journal": "Briefings in Bioinformatics",
      "volume": "25",
      "raw": "Opportunities and challenges for ChatGPT and large language models in biomedicine and health \n\t\t \n\t\t\t S Tian \n\t\t \n\t\t 10.1093/bib/bbad493 \n\t\t \n\t \n\t \n\t\t Briefings in Bioinformatics \n\t\t \n\t\t\t 25 \n\t\t \n\t \n\t Tian, S. et al. Opportunities and challenges for ChatGPT and large language models in biomedicine and health. Briefings in Bioinformatics 25. https://doi.org/10.1093/bib/bbad493 (2024)"
    },
    {
      "title": "Leveraging GPT-4 for post hoc transformation of free-text radiology reports into structured reporting: a multilingual feasibility study",
      "authors": [
        "L Adams"
      ],
      "year": 2023,
      "doi": "10.1148/radiol.230725",
      "journal": "Radiology",
      "volume": "307",
      "pages": "230725",
      "raw": "Leveraging GPT-4 for post hoc transformation of free-text radiology reports into structured reporting: a multilingual feasibility study \n\t\t \n\t\t\t L C Adams \n\t\t \n\t\t 10.1148/radiol.230725 \n\t \n\t \n\t\t Radiology \n\t\t \n\t\t\t 307 \n\t\t\t 230725 \n\t\t\t 2023 \n\t\t \n\t \n\t Adams, L. C. et al. Leveraging GPT-4 for post hoc transformation of free-text radiology reports into structured reporting: a multilingual feasibility study. Radiology 307, e230725 (2023)."
    },
    {
      "title": "Towards accurate differential diagnosis with large language models",
      "authors": [
        "D Mcduff"
      ],
      "year": 2023,
      "raw": "Towards accurate differential diagnosis with large language models \n\t\t \n\t\t\t D Mcduff \n\t\t \n\t\t arXiv:2312.00164 \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t arXiv preprint \n\t McDuff, D. et al. Towards accurate differential diagnosis with large language models. arXiv preprint arXiv:2312.00164 (2023)."
    },
    {
      "title": "Health system-scale language models are allpurpose prediction engines",
      "authors": [
        "L Jiang"
      ],
      "year": 2023,
      "doi": "10.1038/s41586-023-06160-y",
      "journal": "Nature",
      "volume": "619",
      "raw": "Health system-scale language models are allpurpose prediction engines \n\t\t \n\t\t\t L Y Jiang \n\t\t \n\t\t 10.1038/s41586-023-06160-y \n\t \n\t \n\t\t Nature \n\t\t \n\t\t\t 619 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Jiang, L. Y. et al. Health system-scale language models are all- purpose prediction engines. Nature 619, 357-362 (2023)."
    },
    {
      "title": "Leveraging Large Language Models for Generating Responses to Patient Messages",
      "authors": [
        "S Liu"
      ],
      "year": 2023,
      "doi": "10.1101/2023.07.14.23292669",
      "journal": "medRxiv",
      "raw": "Leveraging Large Language Models for Generating Responses to Patient Messages \n\t\t \n\t\t\t S Liu \n\t\t \n\t\t 10.1101/2023.07.14.23292669 \n\t\t 2023.2007.2014.23292669 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Liu, S. et al. Leveraging Large Language Models for Generating Responses to Patient Messages. medRxiv, 2023.2007.2014.23292669. https://doi.org/10.1101/2023.07.14. 23292669 (2023)"
    },
    {
      "title": "A systematic review of current large language model applications and biases in patient care",
      "authors": [
        "F Busch",
        "L Hoffmann",
        "L Adams",
        "K Bressem"
      ],
      "year": 2024,
      "doi": "10.1101/2024.03.04.24303733",
      "raw": "A systematic review of current large language model applications and biases in patient care \n\t\t \n\t\t\t F Busch \n\t\t \n\t\t \n\t\t\t L Hoffmann \n\t\t \n\t\t \n\t\t\t L C Adams \n\t\t \n\t\t \n\t\t\t K K Bressem \n\t\t \n\t\t 10.1101/2024.03.04.24303733 \n\t\t \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Busch, F., Hoffmann, L., Adams, L. C. & Bressem, K. K. A systematic review of current large language model applications and biases in patient care, https://www.crd.york.ac.uk/prospero/display_record. php?ID=CRD42024504542 (2024)."
    },
    {
      "title": "The PRISMA 2020 statement: an updated guideline for reporting systematic reviews",
      "authors": [
        "M Page"
      ],
      "year": 2021,
      "journal": "Bmj",
      "volume": "372",
      "pages": "71",
      "raw": "The PRISMA 2020 statement: an updated guideline for reporting systematic reviews \n\t\t \n\t\t\t M J Page \n\t\t \n\t \n\t \n\t\t Bmj \n\t\t \n\t\t\t 372 \n\t\t\t 71 \n\t\t\t 2021 \n\t\t \n\t \n\t Page, M. J. et al. The PRISMA 2020 statement: an updated guideline for reporting systematic reviews. Bmj 372, n71 (2021)."
    },
    {
      "title": "Rayyan -a web and mobile app for systematic reviews",
      "authors": [
        "M Ouzzani",
        "H Hammady",
        "Z Fedorowicz",
        "A Elmagarmid"
      ],
      "year": 2016,
      "doi": "10.1186/s13643-016-0384-4",
      "journal": "Systematic Reviews",
      "volume": "5",
      "pages": "210",
      "raw": "Rayyan -a web and mobile app for systematic reviews \n\t\t \n\t\t\t M Ouzzani \n\t\t \n\t\t \n\t\t\t H Hammady \n\t\t \n\t\t \n\t\t\t Z Fedorowicz \n\t\t \n\t\t \n\t\t\t A Elmagarmid \n\t\t \n\t\t 10.1186/s13643-016-0384-4 \n\t \n\t \n\t\t Systematic Reviews \n\t\t \n\t\t\t 5 \n\t\t\t 210 \n\t\t\t 2016 \n\t\t \n\t \n\t Ouzzani, M., Hammady, H., Fedorowicz, Z. & Elmagarmid, A. Rayyan -a web and mobile app for systematic reviews. Systematic Reviews 5, 210 (2016)."
    },
    {
      "title": "Data extraction form",
      "year": 2024,
      "doi": "10.18173/2354-1075.2024-0020",
      "raw": "10.18173/2354-1075.2024-0020 \n\t\t \n\t\t Data extraction form \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Data extraction form, https://docs.google.com/forms/d/e/ 1FAIpQLScFwE5KaOugxX_ xXtt9Y6fbBhV4s77S9cWRdVuiHh34vmArkQ/viewform (2024)."
    },
    {
      "title": "The Mixed Methods Appraisal Tool (MMAT) version 2018 for information professionals and researchers",
      "authors": [
        "Q Hong"
      ],
      "year": 2018,
      "doi": "10.3233/efi-180221",
      "journal": "Education for Information",
      "volume": "34",
      "raw": "The Mixed Methods Appraisal Tool (MMAT) version 2018 for information professionals and researchers \n\t\t \n\t\t\t Q N Hong \n\t\t \n\t\t 10.3233/efi-180221 \n\t \n\t \n\t\t Education for Information \n\t\t \n\t\t\t 34 \n\t\t\t \n\t\t\t 2018 \n\t\t \n\t \n\t Hong, Q. N. et al. The Mixed Methods Appraisal Tool (MMAT) version 2018 for information professionals and researchers. Education for Information 34, 285-291 (2018)."
    },
    {
      "title": "Convergent and sequential synthesis designs: implications for conducting and reporting systematic reviews of qualitative and quantitative evidence",
      "authors": [
        "Q Hong",
        "P Pluye",
        "M Bujold",
        "M Wassef"
      ],
      "year": 2017,
      "journal": "Syst Rev",
      "volume": "6",
      "pages": "61",
      "raw": "Convergent and sequential synthesis designs: implications for conducting and reporting systematic reviews of qualitative and quantitative evidence \n\t\t \n\t\t\t Q N Hong \n\t\t \n\t\t \n\t\t\t P Pluye \n\t\t \n\t\t \n\t\t\t M Bujold \n\t\t \n\t\t \n\t\t\t M Wassef \n\t\t \n\t \n\t \n\t\t Syst Rev \n\t\t \n\t\t\t 6 \n\t\t\t 61 \n\t\t\t 2017 \n\t\t \n\t \n\t Hong, Q. N., Pluye, P., Bujold, M. & Wassef, M. Convergent and sequential synthesis designs: implications for conducting and reporting systematic reviews of qualitative and quantitative evidence. Syst Rev 6, 61 (2017)."
    },
    {
      "title": "Methods for the thematic synthesis of qualitative research in systematic reviews",
      "authors": [
        "J Thomas",
        "A Harden"
      ],
      "year": 2008,
      "doi": "10.1186/1471-2288-8-45",
      "journal": "BMC Medical Research Methodology",
      "volume": "8",
      "pages": "45",
      "raw": "Methods for the thematic synthesis of qualitative research in systematic reviews \n\t\t \n\t\t\t J Thomas \n\t\t \n\t\t \n\t\t\t A Harden \n\t\t \n\t\t 10.1186/1471-2288-8-45 \n\t \n\t \n\t\t BMC Medical Research Methodology \n\t\t \n\t\t\t 8 \n\t\t\t 45 \n\t\t\t 2008 \n\t\t \n\t \n\t Thomas, J. & Harden, A. Methods for the thematic synthesis of qualitative research in systematic reviews. BMC Medical Research Methodology 8, 45 (2008)."
    },
    {
      "title": "Dedoose Version 9.2.4, cloud application for managing, analyzing, and presenting qualitative and mixed method research data",
      "year": 2024,
      "doi": "10.1038/s43856-024-00717-2",
      "raw": "10.1038/s43856-024-00717-2 \n\t\t \n\t\t Dedoose Version 9.2.4, cloud application for managing, analyzing, and presenting qualitative and mixed method research data \n\t\t Los Angeles, CA \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Dedoose Version 9.2.4, cloud application for managing, analyzing, and presenting qualitative and mixed method research data (Los Angeles, CA, 2024). https://doi.org/10.1038/s43856-024-00717-2"
    },
    {
      "title": "A Large Language Model Screening Tool to Target Patients for Best Practice Alerts: Development and Validation",
      "authors": [
        "T Savage",
        "J Wang",
        "L Shieh"
      ],
      "year": 2023,
      "journal": "JMIR Med Inform",
      "volume": "11",
      "pages": "49886",
      "raw": "A Large Language Model Screening Tool to Target Patients for Best Practice Alerts: Development and Validation \n\t\t \n\t\t\t T Savage \n\t\t \n\t\t \n\t\t\t J Wang \n\t\t \n\t\t \n\t\t\t L Shieh \n\t\t \n\t \n\t \n\t\t JMIR Med Inform \n\t\t \n\t\t\t 11 \n\t\t\t 49886 \n\t\t\t 2023 \n\t\t \n\t \n\t Savage, T., Wang, J. & Shieh, L. A Large Language Model Screening Tool to Target Patients for Best Practice Alerts: Development and Validation. JMIR Med Inform 11, e49886 (2023)."
    },
    {
      "title": "Assessing the accuracy and completeness of artificial intelligence language models in providing information on methotrexate use",
      "authors": [
        "B Coskun",
        "B Yagiz",
        "G Ocakoglu",
        "E Dalkilic",
        "Y Pehlivan"
      ],
      "year": 2023,
      "doi": "10.1007/s00296-023-05473-5",
      "journal": "Rheumatol Int",
      "raw": "Assessing the accuracy and completeness of artificial intelligence language models in providing information on methotrexate use \n\t\t \n\t\t\t B N Coskun \n\t\t \n\t\t \n\t\t\t B Yagiz \n\t\t \n\t\t \n\t\t\t G Ocakoglu \n\t\t \n\t\t \n\t\t\t E Dalkilic \n\t\t \n\t\t \n\t\t\t Y Pehlivan \n\t\t \n\t\t 10.1007/s00296-023-05473-5 \n\t\t \n\t \n\t \n\t\t Rheumatol Int \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Coskun, B. N., Yagiz, B., Ocakoglu, G., Dalkilic, E. & Pehlivan, Y. Assessing the accuracy and completeness of artificial intelligence language models in providing information on methotrexate use. Rheumatol Int. https://doi.org/10.1007/s00296-023-05473-5 (2023)"
    },
    {
      "title": "Increasing Women's Knowledge about HPV Using BERT Text Summarization: An Online Randomized Study",
      "authors": [
        "H Bitar",
        "A Babour",
        "F Nafa",
        "O Alzamzami",
        "S Alismail"
      ],
      "year": 2022,
      "doi": "10.3390/ijerph19138100",
      "journal": "Int J Environ Res Public Health",
      "volume": "19",
      "raw": "Increasing Women's Knowledge about HPV Using BERT Text Summarization: An Online Randomized Study \n\t\t \n\t\t\t H Bitar \n\t\t \n\t\t \n\t\t\t A Babour \n\t\t \n\t\t \n\t\t\t F Nafa \n\t\t \n\t\t \n\t\t\t O Alzamzami \n\t\t \n\t\t \n\t\t\t S Alismail \n\t\t \n\t\t 10.3390/ijerph19138100 \n\t\t \n\t \n\t \n\t\t Int J Environ Res Public Health \n\t\t \n\t\t\t 19 \n\t\t\t 2022 \n\t\t \n\t \n\t Bitar, H., Babour, A., Nafa, F., Alzamzami, O. & Alismail, S. Increasing Women's Knowledge about HPV Using BERT Text Summarization: An Online Randomized Study. Int J Environ Res Public Health 19. https://doi.org/10.3390/ijerph19138100 (2022)"
    },
    {
      "title": "Artificial Intelligence and Patient Education: Examining the Accuracy and Reproducibility of Responses to Nutrition Questions Related to Inflammatory Bowel Disease by GPT-4",
      "authors": [
        "J Samaan"
      ],
      "year": 2023,
      "doi": "10.1101/2023.10.28.23297723",
      "journal": "medRxiv",
      "raw": "Artificial Intelligence and Patient Education: Examining the Accuracy and Reproducibility of Responses to Nutrition Questions Related to Inflammatory Bowel Disease by GPT-4 \n\t\t \n\t\t\t J S Samaan \n\t\t \n\t\t 10.1101/2023.10.28.23297723 \n\t\t .2010.2028.23297723 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023. 2023 \n\t\t \n\t \n\t Samaan, J. S. et al. Artificial Intelligence and Patient Education: Examining the Accuracy and Reproducibility of Responses to Nutrition Questions Related to Inflammatory Bowel Disease by GPT- 4. medRxiv, 2023.2010.2028.23297723. https://doi.org/10.1101/ 2023.10.28.23297723 (2023)"
    },
    {
      "title": "Racial Disparities in Knowledge of Cardiovascular Disease by a Chat-Based Artificial Intelligence Model",
      "authors": [
        "O Eromosele",
        "T Sobodu",
        "O Olayinka",
        "D Ouyang"
      ],
      "year": 2023,
      "doi": "10.1101/2023.09.20.23295874",
      "journal": "medRxiv",
      "raw": "Racial Disparities in Knowledge of Cardiovascular Disease by a Chat-Based Artificial Intelligence Model \n\t\t \n\t\t\t O B Eromosele \n\t\t \n\t\t \n\t\t\t T Sobodu \n\t\t \n\t\t \n\t\t\t O Olayinka \n\t\t \n\t\t \n\t\t\t D Ouyang \n\t\t \n\t\t 10.1101/2023.09.20.23295874 \n\t\t 2023.2009.2020.23295874 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Eromosele, O. B., Sobodu, T., Olayinka, O. & Ouyang, D. Racial Disparities in Knowledge of Cardiovascular Disease by a Chat- Based Artificial Intelligence Model. medRxiv, 2023.2009.2020.23295874. https://doi.org/10.1101/2023.09.20. 23295874 (2023)"
    },
    {
      "title": "Guidelines For Rigorous Evaluation of Clinical LLMs For Conversational Reasoning",
      "authors": [
        "S Johri"
      ],
      "year": 2024,
      "doi": "10.1101/2023.09.12.23295399",
      "journal": "medRxiv",
      "raw": "Guidelines For Rigorous Evaluation of Clinical LLMs For Conversational Reasoning \n\t\t \n\t\t\t S Johri \n\t\t \n\t\t 10.1101/2023.09.12.23295399 \n\t\t 2023.2009.2012.23295399 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Johri, S. et al. Guidelines For Rigorous Evaluation of Clinical LLMs For Conversational Reasoning. medRxiv, 2023.2009.2012.23295399. https://doi.org/10.1101/2023.09.12. 23295399 (2024)"
    },
    {
      "title": "Use of ChatGPT in Pediatric Urology and its Relevance in Clinical Practice: Is it useful? medRxiv",
      "authors": [
        "A Braga"
      ],
      "year": 2023,
      "doi": "10.1101/2023.09.11.23295266",
      "raw": "Use of ChatGPT in Pediatric Urology and its Relevance in Clinical Practice: Is it useful? medRxiv \n\t\t \n\t\t\t A V N M Braga \n\t\t \n\t\t 10.1101/2023.09.11.23295266 \n\t\t 2023.2009.2011.23295266 \n\t\t \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Braga, A. V. N. M. et al. Use of ChatGPT in Pediatric Urology and its Relevance in Clinical Practice: Is it useful? medRxiv, 2023.2009.2011.23295266. https://doi.org/10.1101/2023.09.11. 23295266 (2023)"
    },
    {
      "title": "Appropriateness of ChatGPT in answering heart failure related questions",
      "authors": [
        "R King"
      ],
      "year": 2023,
      "doi": "10.1101/2023.07.07.23292385",
      "journal": "medRxiv",
      "raw": "Appropriateness of ChatGPT in answering heart failure related questions \n\t\t \n\t\t\t R C King \n\t\t \n\t\t 10.1101/2023.07.07.23292385 \n\t\t 2023.2007.2007.23292385 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t King, R. C. et al. Appropriateness of ChatGPT in answering heart failure related questions. medRxiv, 2023.2007.2007.23292385. https://doi.org/10.1101/2023.07.07.23292385 (2023)"
    },
    {
      "title": "Fact Check: Assessing the Response of ChatGPT to Alzheimer's Disease Statements with Varying Degrees of Misinformation",
      "authors": [
        "S Huang"
      ],
      "year": 2023,
      "doi": "10.1101/2023.09.04.23294917",
      "journal": "medRxiv",
      "raw": "Fact Check: Assessing the Response of ChatGPT to Alzheimer's Disease Statements with Varying Degrees of Misinformation \n\t\t \n\t\t\t S S Huang \n\t\t \n\t\t 10.1101/2023.09.04.23294917 \n\t\t 2023.2009.2004.23294917 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Huang, S. S. et al. Fact Check: Assessing the Response of ChatGPT to Alzheimer's Disease Statements with Varying Degrees of Misinformation. medRxiv, 2023.2009.2004.23294917. https://doi. org/10.1101/2023.09.04.23294917 (2023)"
    },
    {
      "title": "Assessing Racial and Ethnic Bias in Text Generation for Healthcare-Related Tasks by ChatGPT1",
      "authors": [
        "J Hanna",
        "A Wakene",
        "C Lehmann",
        "R Medford"
      ],
      "year": 2023,
      "doi": "10.1101/2023.08.28.23294730",
      "journal": "medRxiv",
      "raw": "Assessing Racial and Ethnic Bias in Text Generation for Healthcare-Related Tasks by ChatGPT1 \n\t\t \n\t\t\t J J Hanna \n\t\t \n\t\t \n\t\t\t A D Wakene \n\t\t \n\t\t \n\t\t\t C U Lehmann \n\t\t \n\t\t \n\t\t\t R J Medford \n\t\t \n\t\t 10.1101/2023.08.28.23294730 \n\t\t 2023.2008.2028.23294730 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Hanna, J. J., Wakene, A. D., Lehmann, C. U. & Medford, R. J. Assessing Racial and Ethnic Bias in Text Generation for Healthcare- Related Tasks by ChatGPT1. medRxiv, 2023.2008.2028.23294730. https://doi.org/10.1101/2023.08.28.23294730 (2023)"
    },
    {
      "title": "ChatGPT's ability to comprehend and answer cirrhosis related questions in Arabic",
      "authors": [
        "J Samaan"
      ],
      "year": 2023,
      "journal": "Arab J Gastroenterol",
      "volume": "24",
      "raw": "ChatGPT's ability to comprehend and answer cirrhosis related questions in Arabic \n\t\t \n\t\t\t J S Samaan \n\t\t \n\t \n\t \n\t\t Arab J Gastroenterol \n\t\t \n\t\t\t 24 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Samaan, J. S. et al. ChatGPT's ability to comprehend and answer cirrhosis related questions in Arabic. Arab J Gastroenterol 24, 145-148 (2023)."
    },
    {
      "title": "Quantitative evaluation of ChatGPT versus Bard responses to anaesthesia-related queries",
      "authors": [
        "S Patnaik",
        "U Hoffmann"
      ],
      "year": 2024,
      "journal": "Br J Anaesth",
      "volume": "132",
      "raw": "Quantitative evaluation of ChatGPT versus Bard responses to anaesthesia-related queries \n\t\t \n\t\t\t S S Patnaik \n\t\t \n\t\t \n\t\t\t U Hoffmann \n\t\t \n\t \n\t \n\t\t Br J Anaesth \n\t\t \n\t\t\t 132 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Patnaik, S. S. & Hoffmann, U. Quantitative evaluation of ChatGPT versus Bard responses to anaesthesia-related queries. Br J Anaesth 132, 169-171 (2024)."
    },
    {
      "title": "Evaluating the performance of ChatGPT in responding to questions about endoscopic procedures for patients",
      "authors": [
        "H Ali"
      ],
      "year": 2023,
      "journal": "iGIE",
      "volume": "2",
      "raw": "Evaluating the performance of ChatGPT in responding to questions about endoscopic procedures for patients \n\t\t \n\t\t\t H Ali \n\t\t \n\t \n\t \n\t\t iGIE \n\t\t \n\t\t\t 2 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Ali, H. et al. Evaluating the performance of ChatGPT in responding to questions about endoscopic procedures for patients. iGIE 2, 553-559 (2023)."
    },
    {
      "title": "Utility of GPT-4 as an Informational Patient Resource in Otolaryngology",
      "authors": [
        "K Suresh"
      ],
      "year": 2023,
      "doi": "10.1101/2023.05.14.23289944",
      "journal": "medRxiv",
      "raw": "Utility of GPT-4 as an Informational Patient Resource in Otolaryngology \n\t\t \n\t\t\t K Suresh \n\t\t \n\t\t 10.1101/2023.05.14.23289944 \n\t\t 2023.2005.2014.23289944 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Suresh, K. et al. Utility of GPT-4 as an Informational Patient Resource in Otolaryngology. medRxiv, 2023.2005.2014.23289944. https:// doi.org/10.1101/2023.05.14.23289944 (2023)"
    },
    {
      "title": "GPT-4 outperforms ChatGPT in answering non-English questions related to cirrhosis",
      "authors": [
        "Y Yeo"
      ],
      "year": 2023,
      "doi": "10.1101/2023.05.04.23289482",
      "journal": "medRxiv",
      "raw": "GPT-4 outperforms ChatGPT in answering non-English questions related to cirrhosis \n\t\t \n\t\t\t Y H Yeo \n\t\t \n\t\t 10.1101/2023.05.04.23289482 \n\t\t 2023.2005.2004.23289482 \n\t\t \n\t \n\t \n\t\t medRxiv \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Yeo, Y. H. et al. GPT-4 outperforms ChatGPT in answering non- English questions related to cirrhosis. medRxiv, 2023.2005.2004.23289482. https://doi.org/10.1101/2023.05.04. 23289482 (2023)"
    },
    {
      "title": "Assessment of ChatGPT in the Prehospital Management of Ophthalmological Emergencies -An Analysis of 10 Fictional Case Vignettes",
      "authors": [
        "D Knebel"
      ],
      "year": 2023,
      "doi": "10.1055/a-2149-0447",
      "journal": "Klin Monbl Augenheilkd",
      "raw": "Assessment of ChatGPT in the Prehospital Management of Ophthalmological Emergencies -An Analysis of 10 Fictional Case Vignettes \n\t\t \n\t\t\t D Knebel \n\t\t \n\t\t 10.1055/a-2149-0447 \n\t\t \n\t \n\t \n\t\t Klin Monbl Augenheilkd \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Knebel, D. et al. Assessment of ChatGPT in the Prehospital Management of Ophthalmological Emergencies -An Analysis of 10 Fictional Case Vignettes. Klin Monbl Augenheilkd. https://doi.org/ 10.1055/a-2149-0447 (2023)"
    },
    {
      "title": "Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge",
      "authors": [
        "L Zhu",
        "W Mou",
        "R Chen"
      ],
      "year": 2023,
      "doi": "10.1186/s12967-023-04123-5",
      "journal": "Journal of Translational Medicine",
      "volume": "21",
      "pages": "269",
      "raw": "Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge \n\t\t \n\t\t\t L Zhu \n\t\t \n\t\t \n\t\t\t W Mou \n\t\t \n\t\t \n\t\t\t R Chen \n\t\t \n\t\t 10.1186/s12967-023-04123-5 \n\t \n\t \n\t\t Journal of Translational Medicine \n\t\t \n\t\t\t 21 \n\t\t\t 269 \n\t\t\t 2023 \n\t\t \n\t \n\t Zhu, L., Mou, W. & Chen, R. Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge? Journal of Translational Medicine 21, 269 (2023)."
    },
    {
      "title": "Evaluating the Utility of a Large Language Model in Answering Common Patients' Gastrointestinal Health-Related Questions: Are We There Yet?",
      "authors": [
        "A Lahat",
        "E Shachar",
        "B Avidan",
        "B Glicksberg",
        "E Klang"
      ],
      "year": 2023,
      "doi": "10.3390/diagnostics13111950",
      "journal": "Diagnostics",
      "volume": "13",
      "raw": "Evaluating the Utility of a Large Language Model in Answering Common Patients' Gastrointestinal Health-Related Questions: Are We There Yet? \n\t\t \n\t\t\t A Lahat \n\t\t \n\t\t \n\t\t\t E Shachar \n\t\t \n\t\t \n\t\t\t B Avidan \n\t\t \n\t\t \n\t\t\t B Glicksberg \n\t\t \n\t\t \n\t\t\t E Klang \n\t\t \n\t\t 10.3390/diagnostics13111950 \n\t\t \n\t \n\t \n\t\t Diagnostics \n\t\t \n\t\t\t 13 \n\t\t\t 2023 \n\t\t\t Basel \n\t\t \n\t \n\t Lahat, A., Shachar, E., Avidan, B., Glicksberg, B. & Klang, E. Evaluating the Utility of a Large Language Model in Answering Common Patients' Gastrointestinal Health-Related Questions: Are We There Yet? Diagnostics (Basel) 13 (2023). https://doi.org/10. 3390/diagnostics13111950"
    },
    {
      "title": "Comparison of ophthalmologist and large language model chatbot responses to online patient eye care questions",
      "authors": [
        "I Bernstein"
      ],
      "year": 2023,
      "journal": "JAMA Network Open",
      "volume": "6",
      "raw": "Comparison of ophthalmologist and large language model chatbot responses to online patient eye care questions \n\t\t \n\t\t\t I A Bernstein \n\t\t \n\t \n\t \n\t\t JAMA Network Open \n\t\t \n\t\t\t 6 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Bernstein, I. A. et al. Comparison of ophthalmologist and large language model chatbot responses to online patient eye care questions. JAMA Network Open 6, e2330320-e2330320 (2023)."
    },
    {
      "title": "Can You Prepare My Patients for [18F]FDG PET/CT and Explain My Reports",
      "authors": [
        "J Rogasch"
      ],
      "year": 2023,
      "doi": "10.2967/jnumed.123.266114",
      "journal": "Journal of Nuclear Medicine",
      "pages": "266114",
      "raw": "Can You Prepare My Patients for [18F]FDG PET/CT and Explain My Reports \n\t\t \n\t\t\t J M M Rogasch \n\t\t \n\t\t 10.2967/jnumed.123.266114 \n\t\t \n\t \n\t \n\t\t Journal of Nuclear Medicine \n\t\t \n\t\t\t 266114 \n\t\t\t 2023 \n\t\t \n\t \n\t Rogasch, J. M. M. et al. ChatGPT: Can You Prepare My Patients for [18F]FDG PET/CT and Explain My Reports? Journal of Nuclear Medicine, jnumed.123.266114. https://doi.org/10.2967/jnumed. 123.266114 (2023)"
    },
    {
      "title": "Evaluating ChatGPT Responses on Thyroid Nodules for Patient Education",
      "authors": [
        "D Campbell"
      ],
      "year": 2023,
      "doi": "10.1089/thy.2023.0491",
      "journal": "Thyroid\u00ae",
      "raw": "Evaluating ChatGPT Responses on Thyroid Nodules for Patient Education \n\t\t \n\t\t\t D J Campbell \n\t\t \n\t\t 10.1089/thy.2023.0491 \n\t\t \n\t \n\t \n\t\t Thyroid\u00ae \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Campbell, D. J. et al. Evaluating ChatGPT Responses on Thyroid Nodules for Patient Education. Thyroid\u00ae. https://doi.org/10.1089/ thy.2023.0491 (2023)"
    },
    {
      "title": "ChatGPT and patient information in nuclear medicine: GPT-3.5 versus GPT-4",
      "authors": [
        "G Currie",
        "S Robbie",
        "P Tually"
      ],
      "year": 2023,
      "doi": "10.2967/jnmt.123.266151",
      "journal": "J Nucl Med Technol",
      "volume": "51",
      "raw": "ChatGPT and patient information in nuclear medicine: GPT-3.5 versus GPT-4 \n\t\t \n\t\t\t G Currie \n\t\t \n\t\t \n\t\t\t S Robbie \n\t\t \n\t\t \n\t\t\t P Tually \n\t\t \n\t\t 10.2967/jnmt.123.266151 \n\t \n\t \n\t\t J Nucl Med Technol \n\t\t \n\t\t\t 51 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Currie, G., Robbie, S. & Tually, P. ChatGPT and patient information in nuclear medicine: GPT-3.5 versus GPT-4. J Nucl Med Technol 51, 307-313 (2023)."
    },
    {
      "title": "Are ChatGPT's Free-Text Responses on Periprosthetic Joint Infections of the Hip and Knee Reliable and Useful?",
      "authors": [
        "A Draschl"
      ],
      "year": 2023,
      "doi": "10.3390/jcm12206655",
      "journal": "J Clin Med",
      "volume": "12",
      "raw": "Are ChatGPT's Free-Text Responses on Periprosthetic Joint Infections of the Hip and Knee Reliable and Useful? \n\t\t \n\t\t\t A Draschl \n\t\t \n\t\t 10.3390/jcm12206655 \n\t\t \n\t \n\t \n\t\t J Clin Med \n\t\t \n\t\t\t 12 \n\t\t\t 2023 \n\t\t \n\t \n\t Draschl, A. et al. Are ChatGPT's Free-Text Responses on Periprosthetic Joint Infections of the Hip and Knee Reliable and Useful? J Clin Med 12. https://doi.org/10.3390/jcm12206655 (2023)"
    },
    {
      "title": "Online patient education in body contouring: a comparison between Google and ChatGPT",
      "authors": [
        "M Alessandri-Bonetti",
        "H Liu",
        "M Palmesano",
        "V Nguyen",
        "F Egro"
      ],
      "year": 2023,
      "doi": "10.1016/j.bjps.2023.10.091",
      "journal": "Journal of Plastic, Reconstructive & Aesthetic Surgery",
      "volume": "87",
      "raw": "Online patient education in body contouring: a comparison between Google and ChatGPT \n\t\t \n\t\t\t M Alessandri-Bonetti \n\t\t \n\t\t \n\t\t\t H Y Liu \n\t\t \n\t\t \n\t\t\t M Palmesano \n\t\t \n\t\t \n\t\t\t V T Nguyen \n\t\t \n\t\t \n\t\t\t F M Egro \n\t\t \n\t\t 10.1016/j.bjps.2023.10.091 \n\t \n\t \n\t\t Journal of Plastic, Reconstructive & Aesthetic Surgery \n\t\t \n\t\t\t 87 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Alessandri-Bonetti, M., Liu, H. Y., Palmesano, M., Nguyen, V. T. & Egro, F. M. Online patient education in body contouring: a comparison between Google and ChatGPT. Journal of Plastic, Reconstructive & Aesthetic Surgery 87, 390-402 (2023)."
    },
    {
      "title": "Can ChatGPT, an artificial intelligence language model, provide accurate and highquality patient information on prostate cancer?",
      "authors": [
        "B Coskun",
        "G Ocakoglu",
        "M Yetemen",
        "O Kaygisiz"
      ],
      "year": 2023,
      "doi": "10.1016/j.urology.2023.05.040",
      "journal": "Urology",
      "volume": "180",
      "raw": "Can ChatGPT, an artificial intelligence language model, provide accurate and highquality patient information on prostate cancer? \n\t\t \n\t\t\t B Coskun \n\t\t \n\t\t \n\t\t\t G Ocakoglu \n\t\t \n\t\t \n\t\t\t M Yetemen \n\t\t \n\t\t \n\t\t\t O Kaygisiz \n\t\t \n\t\t 10.1016/j.urology.2023.05.040 \n\t \n\t \n\t\t Urology \n\t\t \n\t\t\t 180 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Coskun, B., Ocakoglu, G., Yetemen, M. & Kaygisiz, O. Can ChatGPT, an artificial intelligence language model, provide accurate and high- quality patient information on prostate cancer? Urology 180, 35-58 (2023)."
    },
    {
      "title": "Artificial Intelligence Versus Expert Plastic Surgeon: Comparative Study Shows ChatGPT \"Wins\" Rhinoplasty Consultations: Should We Be Worried? Facial Plastic Surgery & Aesthetic Medicine",
      "authors": [
        "K Durairaj"
      ],
      "year": 2023,
      "doi": "10.1089/fpsam.2023.0224",
      "raw": "Artificial Intelligence Versus Expert Plastic Surgeon: Comparative Study Shows ChatGPT \"Wins\" Rhinoplasty Consultations: Should We Be Worried? Facial Plastic Surgery & Aesthetic Medicine \n\t\t \n\t\t\t K K Durairaj \n\t\t \n\t\t 10.1089/fpsam.2023.0224 \n\t\t \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Durairaj, K. K. et al. Artificial Intelligence Versus Expert Plastic Surgeon: Comparative Study Shows ChatGPT \"Wins\" Rhinoplasty Consultations: Should We Be Worried? Facial Plastic Surgery & Aesthetic Medicine. https://doi.org/10.1089/fpsam.2023.0224 (2023)"
    },
    {
      "title": "The Use of Large Language Models to Generate Education Materials about Uveitis",
      "authors": [
        "R Kianian",
        "D Sun",
        "E Crowell",
        "E Tsui"
      ],
      "year": 2023,
      "doi": "10.1016/j.oret.2023.09.008",
      "journal": "Ophthalmol Retina",
      "raw": "The Use of Large Language Models to Generate Education Materials about Uveitis \n\t\t \n\t\t\t R Kianian \n\t\t \n\t\t \n\t\t\t D Sun \n\t\t \n\t\t \n\t\t\t E L Crowell \n\t\t \n\t\t \n\t\t\t E Tsui \n\t\t \n\t\t 10.1016/j.oret.2023.09.008 \n\t\t \n\t \n\t \n\t\t Ophthalmol Retina \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Kianian, R., Sun, D., Crowell, E. L. & Tsui, E. The Use of Large Language Models to Generate Education Materials about Uveitis. Ophthalmol Retina https://doi.org/10.1016/j.oret.2023.09.008 (2023)."
    },
    {
      "title": "Exploring the Role of a Large Language Model on Carpal Tunnel Syndrome Management: An Observation Study of ChatGPT",
      "authors": [
        "I Seth"
      ],
      "year": 2023,
      "journal": "J Hand Surg Am",
      "volume": "48",
      "raw": "Exploring the Role of a Large Language Model on Carpal Tunnel Syndrome Management: An Observation Study of ChatGPT \n\t\t \n\t\t\t I Seth \n\t\t \n\t \n\t \n\t\t J Hand Surg Am \n\t\t \n\t\t\t 48 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Seth, I. et al. Exploring the Role of a Large Language Model on Carpal Tunnel Syndrome Management: An Observation Study of ChatGPT. J Hand Surg Am 48, 1025-1033 (2023)."
    },
    {
      "title": "Can ChatGPT explain it? Use of artificial intelligence in multiple sclerosis communication",
      "authors": [
        "H Inojosa"
      ],
      "year": 2023,
      "doi": "10.1186/s42466-023-00270-8",
      "journal": "Neurological Research and Practice",
      "volume": "5",
      "pages": "48",
      "raw": "Can ChatGPT explain it? Use of artificial intelligence in multiple sclerosis communication \n\t\t \n\t\t\t H Inojosa \n\t\t \n\t\t 10.1186/s42466-023-00270-8 \n\t \n\t \n\t\t Neurological Research and Practice \n\t\t \n\t\t\t 5 \n\t\t\t 48 \n\t\t\t 2023 \n\t\t \n\t \n\t Inojosa, H. et al. Can ChatGPT explain it? Use of artificial intelligence in multiple sclerosis communication. Neurological Research and Practice 5, 48 (2023)."
    },
    {
      "title": "Artificial intelligence chatbot performance in triage of ophthalmic conditions",
      "authors": [
        "R Lyons",
        "S Arepalli",
        "O Fromal",
        "J Choi",
        "N Jain"
      ],
      "year": 2023,
      "doi": "10.1016/j.jcjo.2023.07.016",
      "journal": "Can J Ophthalmol",
      "raw": "Artificial intelligence chatbot performance in triage of ophthalmic conditions \n\t\t \n\t\t\t R J Lyons \n\t\t \n\t\t \n\t\t\t S R Arepalli \n\t\t \n\t\t \n\t\t\t O Fromal \n\t\t \n\t\t \n\t\t\t J D Choi \n\t\t \n\t\t \n\t\t\t N Jain \n\t\t \n\t\t 10.1016/j.jcjo.2023.07.016 \n\t\t \n\t \n\t \n\t\t Can J Ophthalmol \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Lyons, R. J., Arepalli, S. R., Fromal, O., Choi, J. D. & Jain, N. Artificial intelligence chatbot performance in triage of ophthalmic conditions. Can J Ophthalmol. https://doi.org/10.1016/j.jcjo.2023.07.016 (2023)"
    },
    {
      "title": "Potential use of ChatGPT for patient information in periodontology: a descriptive pilot study",
      "authors": [
        "O Babayi\u011fit",
        "Z Tastan Eroglu",
        "D Ozkan Sen",
        "F Ucan Yarkac"
      ],
      "year": 2023,
      "doi": "10.7759/cureus.48518",
      "journal": "Cureus",
      "volume": "15",
      "pages": "48518",
      "raw": "Potential use of ChatGPT for patient information in periodontology: a descriptive pilot study \n\t\t \n\t\t\t O Babayi\u011fit \n\t\t \n\t\t \n\t\t\t Z Tastan Eroglu \n\t\t \n\t\t \n\t\t\t D Ozkan Sen \n\t\t \n\t\t \n\t\t\t F Ucan Yarkac \n\t\t \n\t\t 10.7759/cureus.48518 \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 15 \n\t\t\t 48518 \n\t\t\t 2023 \n\t\t \n\t \n\t Babayi\u011fit, O., Tastan Eroglu, Z., Ozkan Sen, D. & Ucan Yarkac, F. Potential use of ChatGPT for patient information in periodontology: a descriptive pilot study. Cureus 15, e48518 (2023)."
    },
    {
      "title": "ChatGPT in answering queries related to lifestyle-related diseases and disorders",
      "authors": [
        "H Mondal",
        "I Dash",
        "S Mondal",
        "J Behera"
      ],
      "year": 2023,
      "journal": "Cureus",
      "volume": "15",
      "pages": "48296",
      "raw": "ChatGPT in answering queries related to lifestyle-related diseases and disorders \n\t\t \n\t\t\t H Mondal \n\t\t \n\t\t \n\t\t\t I Dash \n\t\t \n\t\t \n\t\t\t S Mondal \n\t\t \n\t\t \n\t\t\t J K Behera \n\t\t \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 15 \n\t\t\t 48296 \n\t\t\t 2023 \n\t\t \n\t \n\t Mondal, H., Dash, I., Mondal, S. & Behera, J. K. ChatGPT in answering queries related to lifestyle-related diseases and disorders. Cureus 15, e48296 (2023)."
    },
    {
      "title": "Assessing the performance of ChatGPT's responses to questions related to epilepsy: a cross-sectional study on natural language processing and medical information retrieval",
      "authors": [
        "H Kim",
        "D Shin",
        "J Kim",
        "G Lee",
        "J Cho"
      ],
      "year": 2023,
      "doi": "10.1016/j.seizure.2023.11.013",
      "journal": "Seizure",
      "volume": "114",
      "raw": "Assessing the performance of ChatGPT's responses to questions related to epilepsy: a cross-sectional study on natural language processing and medical information retrieval \n\t\t \n\t\t\t H W Kim \n\t\t \n\t\t \n\t\t\t D H Shin \n\t\t \n\t\t \n\t\t\t J Kim \n\t\t \n\t\t \n\t\t\t G H Lee \n\t\t \n\t\t \n\t\t\t J W Cho \n\t\t \n\t\t 10.1016/j.seizure.2023.11.013 \n\t \n\t \n\t\t Seizure \n\t\t \n\t\t\t 114 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Kim, H. W., Shin, D. H., Kim, J., Lee, G. H. & Cho, J. W. Assessing the performance of ChatGPT's responses to questions related to epilepsy: a cross-sectional study on natural language processing and medical information retrieval. Seizure 114, 1-8 (2023)."
    },
    {
      "title": "Evaluating the performance of different large language models on health consultation and patient education in urolithiasis",
      "authors": [
        "H Song"
      ],
      "year": 2023,
      "doi": "10.1007/s10916-023-02021-3",
      "journal": "J Med Syst",
      "volume": "47",
      "pages": "125",
      "raw": "Evaluating the performance of different large language models on health consultation and patient education in urolithiasis \n\t\t \n\t\t\t H Song \n\t\t \n\t\t 10.1007/s10916-023-02021-3 \n\t \n\t \n\t\t J Med Syst \n\t\t \n\t\t\t 47 \n\t\t\t 125 \n\t\t\t 2023 \n\t\t \n\t \n\t Song, H. et al. Evaluating the performance of different large language models on health consultation and patient education in urolithiasis. J Med Syst 47, 125 (2023)."
    },
    {
      "title": "Can ChatGPT help patients answer their otolaryngology questions?",
      "authors": [
        "H Zalzal",
        "A Abraham",
        "J Cheng",
        "R Shah"
      ],
      "year": 2023,
      "doi": "10.1002/lio2.1193",
      "journal": "Laryngoscope Investigative Otolaryngology",
      "raw": "Can ChatGPT help patients answer their otolaryngology questions? \n\t\t \n\t\t\t H G Zalzal \n\t\t \n\t\t \n\t\t\t A Abraham \n\t\t \n\t\t \n\t\t\t J H Cheng \n\t\t \n\t\t \n\t\t\t R K Shah \n\t\t \n\t\t 10.1002/lio2.1193 \n\t\t \n\t \n\t \n\t\t Laryngoscope Investigative Otolaryngology \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Zalzal, H. G., Abraham, A., Cheng, J. H. & Shah, R. K. Can ChatGPT help patients answer their otolaryngology questions? Laryngoscope Investigative Otolaryngology. https://doi.org/10.1002/lio2.1193 (2023)"
    },
    {
      "title": "ChatGPT performs strongly as a fertility counseling tool with limitations",
      "authors": [
        "J Chervenak",
        "H Lieman",
        "M Blanco-Breindel",
        "S Jindal"
      ],
      "year": 2023,
      "doi": "10.1038/s43856-024-00717-2information",
      "volume": "120",
      "raw": "ChatGPT performs strongly as a fertility counseling tool with limitations \n\t\t \n\t\t\t J Chervenak \n\t\t \n\t\t \n\t\t\t H Lieman \n\t\t \n\t\t \n\t\t\t M Blanco-Breindel \n\t\t \n\t\t \n\t\t\t S Jindal \n\t\t \n\t\t 10.1038/s43856-024-00717-2information \n\t\t \n\t \n\t \n\t\t The promise and peril of using a large language model to obtain clinical \n\t\t \n\t\t\t 2023 \n\t\t\t 120 \n\t\t\t \n\t\t \n\t \n\t Chervenak, J., Lieman, H., Blanco-Breindel, M. & Jindal, S. The promise and peril of using a large language model to obtain clinical https://doi.org/10.1038/s43856-024-00717-2 information: ChatGPT performs strongly as a fertility counseling tool with limitations. Fertility and Sterility 120, 575-583 (2023)."
    },
    {
      "title": "ChatGPT, can you help me save my child's life?\"diagnostic accuracy and supportive capabilities to lay rescuers by ChatGPT in prehospital basic life support and paediatric advanced life support cases -an in-silico analysis",
      "authors": [
        "S Bushuven"
      ],
      "year": 2023,
      "doi": "10.1007/s10916-023-02019-x",
      "journal": "J Med Syst",
      "volume": "47",
      "pages": "123",
      "raw": "ChatGPT, can you help me save my child's life?\"diagnostic accuracy and supportive capabilities to lay rescuers by ChatGPT in prehospital basic life support and paediatric advanced life support cases -an in-silico analysis \n\t\t \n\t\t\t S Bushuven \n\t\t \n\t\t 10.1007/s10916-023-02019-x \n\t \n\t \n\t\t J Med Syst \n\t\t \n\t\t\t 47 \n\t\t\t 123 \n\t\t\t 2023 \n\t\t \n\t \n\t Bushuven, S. et al. ChatGPT, can you help me save my child's life?\" - diagnostic accuracy and supportive capabilities to lay rescuers by ChatGPT in prehospital basic life support and paediatric advanced life support cases -an in-silico analysis. J Med Syst 47, 123 (2023)."
    },
    {
      "title": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports",
      "authors": [
        "K Jeblick"
      ],
      "year": 2023,
      "doi": "10.1007/s00330-023-10213-1",
      "journal": "European Radiology",
      "raw": "ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports \n\t\t \n\t\t\t K Jeblick \n\t\t \n\t\t 10.1007/s00330-023-10213-1 \n\t\t \n\t \n\t \n\t\t European Radiology \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Jeblick, K. et al. ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports. European Radiology. https://doi.org/10.1007/s00330-023-10213-1 (2023)"
    },
    {
      "title": "Assessing the accuracy of responses by the language model ChatGPT to questions regarding bariatric surgery",
      "authors": [
        "J Samaan"
      ],
      "year": 2023,
      "doi": "10.1007/s11695-023-06603-5",
      "journal": "Obes Surg",
      "volume": "33",
      "raw": "Assessing the accuracy of responses by the language model ChatGPT to questions regarding bariatric surgery \n\t\t \n\t\t\t J S Samaan \n\t\t \n\t\t 10.1007/s11695-023-06603-5 \n\t \n\t \n\t\t Obes Surg \n\t\t \n\t\t\t 33 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Samaan, J. S. et al. Assessing the accuracy of responses by the language model ChatGPT to questions regarding bariatric surgery. Obes Surg 33, 1790-1796 (2023)."
    },
    {
      "title": "Exploring ChatGPT's potential for consultation, recommendations and report diagnosis: gastric cancer and gastroscopy reports' case",
      "authors": [
        "J Zhou",
        "T Li",
        "S Fong",
        "N Dey",
        "R Crespo"
      ],
      "year": 2023,
      "journal": "International Journal of Interactive Multimedia and Artificial Intelligence",
      "volume": "8",
      "raw": "Exploring ChatGPT's potential for consultation, recommendations and report diagnosis: gastric cancer and gastroscopy reports' case \n\t\t \n\t\t\t J M Zhou \n\t\t \n\t\t \n\t\t\t T Y Li \n\t\t \n\t\t \n\t\t\t S J Fong \n\t\t \n\t\t \n\t\t\t N Dey \n\t\t \n\t\t \n\t\t\t R G Crespo \n\t\t \n\t \n\t \n\t\t International Journal of Interactive Multimedia and Artificial Intelligence \n\t\t \n\t\t\t 8 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Zhou, J. M., Li, T. Y., Fong, S. J., Dey, N. & Crespo, R. G. Exploring ChatGPT's potential for consultation, recommendations and report diagnosis: gastric cancer and gastroscopy reports' case. International Journal of Interactive Multimedia and Artificial Intelligence 8, 7-13 (2023)."
    },
    {
      "title": "Toward improving health literacy in patient education materials with neural machine translation models",
      "authors": [
        "D Oniani"
      ],
      "year": 2023,
      "journal": "AMIA Jt Summits Transl Sci Proc",
      "raw": "Toward improving health literacy in patient education materials with neural machine translation models \n\t\t \n\t\t\t D Oniani \n\t\t \n\t \n\t \n\t\t AMIA Jt Summits Transl Sci Proc \n\t\t \n\t\t\t \n\t\t\t 2023. 2023 \n\t\t \n\t \n\t Oniani, D. et al. Toward improving health literacy in patient education materials with neural machine translation models. AMIA Jt Summits Transl Sci Proc 2023, 418-426 (2023)."
    },
    {
      "title": "The future of patient education: ai-driven guide for type 2 diabetes",
      "authors": [
        "C Hernandez"
      ],
      "year": 2023,
      "journal": "Cureus",
      "volume": "15",
      "pages": "48919",
      "raw": "The future of patient education: ai-driven guide for type 2 diabetes \n\t\t \n\t\t\t C A Hernandez \n\t\t \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 15 \n\t\t\t 48919 \n\t\t\t 2023 \n\t\t \n\t \n\t Hernandez, C. A. et al. The future of patient education: ai-driven guide for type 2 diabetes. Cureus 15, e48919 (2023)."
    },
    {
      "title": "Is ChatGPT accurate and reliable in answering questions regarding head and neck cancer?",
      "authors": [
        "O Ku\u015fcu",
        "A Pamuk",
        "N S\u00fctay S\u00fcsl\u00fc",
        "S Hosal"
      ],
      "year": 2023,
      "doi": "10.3389/fonc.2023.1256459",
      "journal": "Front Oncol",
      "volume": "13",
      "pages": "1256459",
      "raw": "Is ChatGPT accurate and reliable in answering questions regarding head and neck cancer? \n\t\t \n\t\t\t O Ku\u015fcu \n\t\t \n\t\t \n\t\t\t A E Pamuk \n\t\t \n\t\t \n\t\t\t N S\u00fctay S\u00fcsl\u00fc \n\t\t \n\t\t \n\t\t\t S Hosal \n\t\t \n\t\t 10.3389/fonc.2023.1256459 \n\t \n\t \n\t\t Front Oncol \n\t\t \n\t\t\t 13 \n\t\t\t 1256459 \n\t\t\t 2023 \n\t\t \n\t \n\t Ku\u015fcu, O., Pamuk, A. E., S\u00fctay S\u00fcsl\u00fc, N. & Hosal, S. Is ChatGPT accurate and reliable in answering questions regarding head and neck cancer? Front Oncol 13, 1256459 (2023)."
    },
    {
      "title": "Assessing the utility of ChatGPT as an artificial intelligencebased large language model for information to answer questions on myopia",
      "authors": [
        "S Biswas",
        "N Logan",
        "L Davies",
        "A Sheppard",
        "J Wolffsohn"
      ],
      "year": 2023,
      "journal": "Ophthalmic Physiol Opt",
      "volume": "43",
      "raw": "Assessing the utility of ChatGPT as an artificial intelligencebased large language model for information to answer questions on myopia \n\t\t \n\t\t\t S Biswas \n\t\t \n\t\t \n\t\t\t N S Logan \n\t\t \n\t\t \n\t\t\t L N Davies \n\t\t \n\t\t \n\t\t\t A L Sheppard \n\t\t \n\t\t \n\t\t\t J S Wolffsohn \n\t\t \n\t \n\t \n\t\t Ophthalmic Physiol Opt \n\t\t \n\t\t\t 43 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Biswas, S., Logan, N. S., Davies, L. N., Sheppard, A. L. & Wolffsohn, J. S. Assessing the utility of ChatGPT as an artificial intelligence- based large language model for information to answer questions on myopia. Ophthalmic Physiol Opt 43, 1562-1570 (2023)."
    },
    {
      "title": "Exploring the potential of Chat-GPT as a supportive tool for sialendoscopy clinical decision making and patient information support",
      "authors": [
        "C Chiesa-Estomba"
      ],
      "year": 2023,
      "doi": "10.1007/s00405-023-08104-8",
      "journal": "Eur Arch Otorhinolaryngol",
      "raw": "Exploring the potential of Chat-GPT as a supportive tool for sialendoscopy clinical decision making and patient information support \n\t\t \n\t\t\t C M Chiesa-Estomba \n\t\t \n\t\t 10.1007/s00405-023-08104-8 \n\t\t \n\t \n\t \n\t\t Eur Arch Otorhinolaryngol \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Chiesa-Estomba, C. M. et al. Exploring the potential of Chat-GPT as a supportive tool for sialendoscopy clinical decision making and patient information support. Eur Arch Otorhinolaryngol. https://doi. org/10.1007/s00405-023-08104-8 (2023)"
    },
    {
      "title": "Large language model-based chatbot vs surgeongenerated informed consent documentation for common procedures",
      "authors": [
        "H Decker"
      ],
      "year": 2023,
      "journal": "JAMA Netw Open",
      "volume": "6",
      "pages": "2336997",
      "raw": "Large language model-based chatbot vs surgeongenerated informed consent documentation for common procedures \n\t\t \n\t\t\t H Decker \n\t\t \n\t \n\t \n\t\t JAMA Netw Open \n\t\t \n\t\t\t 6 \n\t\t\t 2336997 \n\t\t\t 2023 \n\t\t \n\t \n\t Decker, H. et al. Large language model-based chatbot vs surgeon- generated informed consent documentation for common procedures. JAMA Netw Open 6, e2336997 (2023)."
    },
    {
      "title": "Exploring the potential of ChatGPT as a supplementary tool for providing orthopaedic information",
      "authors": [
        "J Kaarre"
      ],
      "year": 2023,
      "journal": "Knee Surg Sports Traumatol Arthrosc",
      "volume": "31",
      "raw": "Exploring the potential of ChatGPT as a supplementary tool for providing orthopaedic information \n\t\t \n\t\t\t J Kaarre \n\t\t \n\t \n\t \n\t\t Knee Surg Sports Traumatol Arthrosc \n\t\t \n\t\t\t 31 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Kaarre, J. et al. Exploring the potential of ChatGPT as a supplementary tool for providing orthopaedic information. Knee Surg Sports Traumatol Arthrosc 31, 5190-5198 (2023)."
    },
    {
      "title": "Evaluation of ChatGPT dermatology responses to common patient queries",
      "authors": [
        "A Ferreira",
        "B Chu",
        "J Grant-Kels",
        "T Ogunleye",
        "J Lipoff"
      ],
      "year": 2023,
      "journal": "JMIR Dermatol",
      "volume": "6",
      "pages": "49280",
      "raw": "Evaluation of ChatGPT dermatology responses to common patient queries \n\t\t \n\t\t\t A L Ferreira \n\t\t \n\t\t \n\t\t\t B Chu \n\t\t \n\t\t \n\t\t\t J M Grant-Kels \n\t\t \n\t\t \n\t\t\t T Ogunleye \n\t\t \n\t\t \n\t\t\t J B Lipoff \n\t\t \n\t \n\t \n\t\t JMIR Dermatol \n\t\t \n\t\t\t 6 \n\t\t\t 49280 \n\t\t\t 2023 \n\t\t \n\t \n\t Ferreira, A. L., Chu, B., Grant-Kels, J. M., Ogunleye, T. & Lipoff, J. B. Evaluation of ChatGPT dermatology responses to common patient queries. JMIR Dermatol 6, e49280 (2023)."
    },
    {
      "title": "A pilot study on the efficacy of GPT-4 in providing orthopedic treatment recommendations from MRI reports",
      "authors": [
        "D Truhn"
      ],
      "year": 2023,
      "journal": "Sci Rep",
      "volume": "13",
      "pages": "20159",
      "raw": "A pilot study on the efficacy of GPT-4 in providing orthopedic treatment recommendations from MRI reports \n\t\t \n\t\t\t D Truhn \n\t\t \n\t \n\t \n\t\t Sci Rep \n\t\t \n\t\t\t 13 \n\t\t\t 20159 \n\t\t\t 2023 \n\t\t \n\t \n\t Truhn, D. et al. A pilot study on the efficacy of GPT-4 in providing orthopedic treatment recommendations from MRI reports. Sci Rep 13, 20159 (2023)."
    },
    {
      "title": "Evaluation High-Quality of Information from ChatGPT (Artificial Intelligence-Large Language Model) Artificial Intelligence on Shoulder Stabilization Surgery",
      "authors": [
        "E Hurley"
      ],
      "year": 2023,
      "doi": "10.1016/j.arthro.2023.07.048",
      "journal": "Arthroscopy",
      "raw": "Evaluation High-Quality of Information from ChatGPT (Artificial Intelligence-Large Language Model) Artificial Intelligence on Shoulder Stabilization Surgery \n\t\t \n\t\t\t E T Hurley \n\t\t \n\t\t 10.1016/j.arthro.2023.07.048 \n\t\t \n\t \n\t \n\t\t Arthroscopy \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Hurley, E. T. et al. Evaluation High-Quality of Information from ChatGPT (Artificial Intelligence-Large Language Model) Artificial Intelligence on Shoulder Stabilization Surgery. Arthroscopy. https:// doi.org/10.1016/j.arthro.2023.07.048 (2023)"
    },
    {
      "title": "Reliability and usefulness of ChatGPT for inflammatory bowel diseases: an analysis for patients and healthcare professionals",
      "authors": [
        "R Cankurtaran",
        "Y Polat",
        "N Aydemir",
        "E Umay",
        "O Yurekli"
      ],
      "year": 2023,
      "journal": "Cureus",
      "volume": "15",
      "pages": "46736",
      "raw": "Reliability and usefulness of ChatGPT for inflammatory bowel diseases: an analysis for patients and healthcare professionals \n\t\t \n\t\t\t R E Cankurtaran \n\t\t \n\t\t \n\t\t\t Y H Polat \n\t\t \n\t\t \n\t\t\t N G Aydemir \n\t\t \n\t\t \n\t\t\t E Umay \n\t\t \n\t\t \n\t\t\t O T Yurekli \n\t\t \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 15 \n\t\t\t 46736 \n\t\t\t 2023 \n\t\t \n\t \n\t Cankurtaran, R. E., Polat, Y. H., Aydemir, N. G., Umay, E. & Yurekli, O. T. Reliability and usefulness of ChatGPT for inflammatory bowel diseases: an analysis for patients and healthcare professionals. Cureus 15, e46736 (2023)."
    },
    {
      "title": "Large language model (LLM)-powered chatbots fail to generate guideline-consistent content on resuscitation and may provide potentially harmful advice",
      "authors": [
        "A Birkun",
        "A Gautam"
      ],
      "year": 2023,
      "journal": "Prehosp Disaster Med",
      "volume": "38",
      "raw": "Large language model (LLM)-powered chatbots fail to generate guideline-consistent content on resuscitation and may provide potentially harmful advice \n\t\t \n\t\t\t A A Birkun \n\t\t \n\t\t \n\t\t\t A Gautam \n\t\t \n\t \n\t \n\t\t Prehosp Disaster Med \n\t\t \n\t\t\t 38 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Birkun, A. A. & Gautam, A. Large language model (LLM)-powered chatbots fail to generate guideline-consistent content on resuscitation and may provide potentially harmful advice. Prehosp Disaster Med 38, 757-763 (2023)."
    },
    {
      "title": "Popular large language model chatbots' accuracy, comprehensiveness, and self-awareness in answering ocular symptom queries",
      "authors": [
        "K Pushpanathan"
      ],
      "year": 2023,
      "doi": "10.1016/j.isci.2023.108163",
      "journal": "iScience",
      "volume": "26",
      "pages": "108163",
      "raw": "Popular large language model chatbots' accuracy, comprehensiveness, and self-awareness in answering ocular symptom queries \n\t\t \n\t\t\t K Pushpanathan \n\t\t \n\t\t 10.1016/j.isci.2023.108163 \n\t \n\t \n\t\t iScience \n\t\t \n\t\t\t 26 \n\t\t\t 108163 \n\t\t\t 2023 \n\t\t \n\t \n\t Pushpanathan, K. et al. Popular large language model chatbots' accuracy, comprehensiveness, and self-awareness in answering ocular symptom queries. iScience 26, 108163 (2023)."
    },
    {
      "title": "Appropriateness and comprehensiveness of using ChatGPT for perioperative patient education in thoracic surgery in different language contexts: survey study",
      "authors": [
        "C Shao"
      ],
      "year": 2023,
      "journal": "Interact J Med Res",
      "volume": "12",
      "pages": "46900",
      "raw": "Appropriateness and comprehensiveness of using ChatGPT for perioperative patient education in thoracic surgery in different language contexts: survey study \n\t\t \n\t\t\t C Y Shao \n\t\t \n\t \n\t \n\t\t Interact J Med Res \n\t\t \n\t\t\t 12 \n\t\t\t 46900 \n\t\t\t 2023 \n\t\t \n\t \n\t Shao, C. Y. et al. Appropriateness and comprehensiveness of using ChatGPT for perioperative patient education in thoracic surgery in different language contexts: survey study. Interact J Med Res 12, e46900 (2023)."
    },
    {
      "title": "Accuracy of ChatGPT-Generated Information on Head and Neck and Oromaxillofacial Surgery: A Multicenter Collaborative Analysis",
      "authors": [
        "L Vaira"
      ],
      "year": 2023,
      "doi": "10.1002/ohn.489",
      "journal": "Otolaryngol Head Neck Surg",
      "raw": "Accuracy of ChatGPT-Generated Information on Head and Neck and Oromaxillofacial Surgery: A Multicenter Collaborative Analysis \n\t\t \n\t\t\t L A Vaira \n\t\t \n\t\t 10.1002/ohn.489 \n\t\t \n\t \n\t \n\t\t Otolaryngol Head Neck Surg \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Vaira, L. A. et al. Accuracy of ChatGPT-Generated Information on Head and Neck and Oromaxillofacial Surgery: A Multicenter Collaborative Analysis. Otolaryngol Head Neck Surg. https://doi.org/ 10.1002/ohn.489 (2023)"
    },
    {
      "title": "Use of artificial intelligence Chatbots for cancer treatment information",
      "authors": [
        "S Chen"
      ],
      "year": 2023,
      "journal": "JAMA Oncol",
      "volume": "9",
      "raw": "Use of artificial intelligence Chatbots for cancer treatment information \n\t\t \n\t\t\t S Chen \n\t\t \n\t \n\t \n\t\t JAMA Oncol \n\t\t \n\t\t\t 9 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Chen, S. et al. Use of artificial intelligence Chatbots for cancer treatment information. JAMA Oncol 9, 1459-1462 (2023)."
    },
    {
      "title": "BPPV Information on Google Versus AI (ChatGPT)",
      "authors": [
        "J Bellinger"
      ],
      "year": 2023,
      "doi": "10.1002/ohn.506",
      "journal": "Otolaryngol Head Neck Surg",
      "raw": "BPPV Information on Google Versus AI (ChatGPT) \n\t\t \n\t\t\t J R Bellinger \n\t\t \n\t\t 10.1002/ohn.506 \n\t\t \n\t \n\t \n\t\t Otolaryngol Head Neck Surg \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Bellinger, J. R. et al. BPPV Information on Google Versus AI (ChatGPT). Otolaryngol Head Neck Surg. https://doi.org/10.1002/ ohn.506 (2023)"
    },
    {
      "title": "Validity of the large language model ChatGPT (GPT4) as a patient information source in otolaryngology by a variety of doctors in a tertiary otorhinolaryngology department",
      "authors": [
        "J Nielsen",
        "C Von Buchwald",
        "C Gr\u00f8nh\u00f8j"
      ],
      "year": 2023,
      "journal": "Acta Otolaryngol",
      "volume": "143",
      "raw": "Validity of the large language model ChatGPT (GPT4) as a patient information source in otolaryngology by a variety of doctors in a tertiary otorhinolaryngology department \n\t\t \n\t\t\t J P S Nielsen \n\t\t \n\t\t \n\t\t\t C Von Buchwald \n\t\t \n\t\t \n\t\t\t C Gr\u00f8nh\u00f8j \n\t\t \n\t \n\t \n\t\t Acta Otolaryngol \n\t\t \n\t\t\t 143 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Nielsen, J. P. S., von Buchwald, C. & Gr\u00f8nh\u00f8j, C. Validity of the large language model ChatGPT (GPT4) as a patient information source in otolaryngology by a variety of doctors in a tertiary otorhinolaryngology department. Acta Otolaryngol 143, 779-782 (2023)."
    },
    {
      "title": "Clinical accuracy of large language models and google search responses to postpartum depression questions: cross-sectional study",
      "authors": [
        "E Sezgin",
        "F Chekeni",
        "J Lee",
        "S Keim"
      ],
      "year": 2023,
      "journal": "J Med Internet Res",
      "volume": "25",
      "pages": "49240",
      "raw": "Clinical accuracy of large language models and google search responses to postpartum depression questions: cross-sectional study \n\t\t \n\t\t\t E Sezgin \n\t\t \n\t\t \n\t\t\t F Chekeni \n\t\t \n\t\t \n\t\t\t J Lee \n\t\t \n\t\t \n\t\t\t S Keim \n\t\t \n\t \n\t \n\t\t J Med Internet Res \n\t\t \n\t\t\t 25 \n\t\t\t 49240 \n\t\t\t 2023 \n\t\t \n\t \n\t Sezgin, E., Chekeni, F., Lee, J. & Keim, S. Clinical accuracy of large language models and google search responses to postpartum depression questions: cross-sectional study. J Med Internet Res 25, e49240 (2023)."
    },
    {
      "title": "Current Strengths and Weaknesses of ChatGPT as a Resource for Radiation Oncology Patients and Providers",
      "authors": [
        "W Floyd"
      ],
      "year": 2023,
      "doi": "10.1016/j.ijrobp.2023.10.020",
      "journal": "International Journal of Radiation Oncology, Biology, Physics",
      "raw": "Current Strengths and Weaknesses of ChatGPT as a Resource for Radiation Oncology Patients and Providers \n\t\t \n\t\t\t W Floyd \n\t\t \n\t\t 10.1016/j.ijrobp.2023.10.020 \n\t\t \n\t \n\t \n\t\t International Journal of Radiation Oncology, Biology, Physics \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Floyd, W. et al. Current Strengths and Weaknesses of ChatGPT as a Resource for Radiation Oncology Patients and Providers. International Journal of Radiation Oncology, Biology, Physics. https://doi.org/10.1016/j.ijrobp.2023.10.020 (2023)"
    },
    {
      "title": "Dr ChatGPT\": is it a reliable and useful source for common rheumatic diseases?",
      "authors": [
        "C Uz",
        "E Umay"
      ],
      "year": 2023,
      "journal": "Int J Rheum Dis",
      "volume": "26",
      "raw": "Dr ChatGPT\": is it a reliable and useful source for common rheumatic diseases? \n\t\t \n\t\t\t C Uz \n\t\t \n\t\t \n\t\t\t E Umay \n\t\t \n\t \n\t \n\t\t Int J Rheum Dis \n\t\t \n\t\t\t 26 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Uz, C. & Umay, E. \"Dr ChatGPT\": is it a reliable and useful source for common rheumatic diseases? Int J Rheum Dis 26, 1343-1349 (2023)."
    },
    {
      "title": "The potential of chatbots in chronic venous disease patient management",
      "authors": [
        "A Athavale",
        "J Baier",
        "E Ross",
        "E Fukaya"
      ],
      "year": 2023,
      "doi": "10.1016/j.jvsvi.2023.100019",
      "journal": "JVS Vasc Insights",
      "volume": "1",
      "raw": "The potential of chatbots in chronic venous disease patient management \n\t\t \n\t\t\t A Athavale \n\t\t \n\t\t \n\t\t\t J Baier \n\t\t \n\t\t \n\t\t\t E Ross \n\t\t \n\t\t \n\t\t\t E Fukaya \n\t\t \n\t\t 10.1016/j.jvsvi.2023.100019 \n\t\t \n\t \n\t \n\t\t JVS Vasc Insights \n\t\t \n\t\t\t 1 \n\t\t\t 2023 \n\t\t \n\t \n\t Athavale, A., Baier, J., Ross, E. & Fukaya, E. The potential of chatbots in chronic venous disease patient management. JVS Vasc Insights 1. https://doi.org/10.1016/j.jvsvi.2023.100019 (2023)"
    },
    {
      "title": "ChatDoctor: a medical chat model fine-tuned on a large language model meta-AI (LLaMA) using medical domain knowledge",
      "authors": [
        "Y Li"
      ],
      "year": 2023,
      "journal": "Cureus",
      "volume": "15",
      "pages": "40895",
      "raw": "ChatDoctor: a medical chat model fine-tuned on a large language model meta-AI (LLaMA) using medical domain knowledge \n\t\t \n\t\t\t Y Li \n\t\t \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 15 \n\t\t\t 40895 \n\t\t\t 2023 \n\t\t \n\t \n\t Li, Y. et al. ChatDoctor: a medical chat model fine-tuned on a large language model meta-AI (LLaMA) using medical domain knowledge. Cureus 15, e40895 (2023)."
    },
    {
      "title": "Comparing the efficacy of large language models ChatGPT, BARD, and Bing AI in providing information on rhinoplasty: an observational study",
      "authors": [
        "I Seth"
      ],
      "year": 2023,
      "journal": "Aesthet Surg J Open Forum",
      "volume": "5",
      "pages": "84",
      "raw": "Comparing the efficacy of large language models ChatGPT, BARD, and Bing AI in providing information on rhinoplasty: an observational study \n\t\t \n\t\t\t I Seth \n\t\t \n\t \n\t \n\t\t Aesthet Surg J Open Forum \n\t\t \n\t\t\t 5 \n\t\t\t 84 \n\t\t\t 2023 \n\t\t \n\t \n\t Seth, I. et al. Comparing the efficacy of large language models ChatGPT, BARD, and Bing AI in providing information on rhinoplasty: an observational study. Aesthet Surg J Open Forum 5, ojad084 (2023)."
    },
    {
      "title": "Evaluation of a chat GPT generated patient information leaflet about laparoscopic cholecystectomy",
      "authors": [
        "E Lockie",
        "J Choi"
      ],
      "year": 2023,
      "doi": "10.1111/ans.18834",
      "journal": "ANZ J Surg",
      "raw": "Evaluation of a chat GPT generated patient information leaflet about laparoscopic cholecystectomy \n\t\t \n\t\t\t E Lockie \n\t\t \n\t\t \n\t\t\t J Choi \n\t\t \n\t\t 10.1111/ans.18834 \n\t\t \n\t \n\t \n\t\t ANZ J Surg \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Lockie, E. & Choi, J. Evaluation of a chat GPT generated patient information leaflet about laparoscopic cholecystectomy. ANZ J Surg. https://doi.org/10.1111/ans.18834 (2023)"
    },
    {
      "title": "Use of ChatGPT, GPT-4, and Bard to improve readability of ChatGPT's answers to common questions about lung cancer and lung cancer screening",
      "authors": [
        "H Haver",
        "C Lin",
        "A Sirajuddin",
        "P Yi",
        "J Jeudy"
      ],
      "year": 2023,
      "journal": "AJR Am J Roentgenol",
      "volume": "221",
      "raw": "Use of ChatGPT, GPT-4, and Bard to improve readability of ChatGPT's answers to common questions about lung cancer and lung cancer screening \n\t\t \n\t\t\t H L Haver \n\t\t \n\t\t \n\t\t\t C T Lin \n\t\t \n\t\t \n\t\t\t A Sirajuddin \n\t\t \n\t\t \n\t\t\t P H Yi \n\t\t \n\t\t \n\t\t\t J Jeudy \n\t\t \n\t \n\t \n\t\t AJR Am J Roentgenol \n\t\t \n\t\t\t 221 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Haver, H. L., Lin, C. T., Sirajuddin, A., Yi, P. H. & Jeudy, J. Use of ChatGPT, GPT-4, and Bard to improve readability of ChatGPT's answers to common questions about lung cancer and lung cancer screening. AJR Am J Roentgenol 221, 701-704 (2023)."
    },
    {
      "title": "Decoding radiology reports: potential application of OpenAI ChatGPT to enhance patient understanding of diagnostic reports",
      "authors": [
        "H Li"
      ],
      "year": 2023,
      "journal": "Clin Imaging",
      "volume": "101",
      "raw": "Decoding radiology reports: potential application of OpenAI ChatGPT to enhance patient understanding of diagnostic reports \n\t\t \n\t\t\t H Li \n\t\t \n\t \n\t \n\t\t Clin Imaging \n\t\t \n\t\t\t 101 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Li, H. et al. Decoding radiology reports: potential application of OpenAI ChatGPT to enhance patient understanding of diagnostic reports. Clin Imaging 101, 137-141 (2023)."
    },
    {
      "title": "Feasibility of GPT-3 and GPT-4 for in-depth patient education prior to interventional radiological procedures: a comparative analysis",
      "authors": [
        "M Scheschenja"
      ],
      "year": 2024,
      "journal": "CardioVascular and Interventional Radiology",
      "volume": "47",
      "raw": "Feasibility of GPT-3 and GPT-4 for in-depth patient education prior to interventional radiological procedures: a comparative analysis \n\t\t \n\t\t\t M Scheschenja \n\t\t \n\t \n\t \n\t\t CardioVascular and Interventional Radiology \n\t\t \n\t\t\t 47 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Scheschenja, M. et al. Feasibility of GPT-3 and GPT-4 for in-depth patient education prior to interventional radiological procedures: a comparative analysis. CardioVascular and Interventional Radiology 47, 245-250 (2024)."
    },
    {
      "title": "Enhancing patient communication With Chat-GPT in radiology: evaluating the efficacy and readability of answers to common imaging-related questions",
      "authors": [
        "E Gordon"
      ],
      "year": 2024,
      "journal": "J Am Coll Radiol",
      "volume": "21",
      "raw": "Enhancing patient communication With Chat-GPT in radiology: evaluating the efficacy and readability of answers to common imaging-related questions \n\t\t \n\t\t\t E B Gordon \n\t\t \n\t \n\t \n\t\t J Am Coll Radiol \n\t\t \n\t\t\t 21 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Gordon, E. B. et al. Enhancing patient communication With Chat- GPT in radiology: evaluating the efficacy and readability of answers to common imaging-related questions. J Am Coll Radiol 21, 353-359 (2024)."
    },
    {
      "title": "Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery?",
      "authors": [
        "A Stroop"
      ],
      "year": 2023,
      "doi": "10.1007/s00586-023-07975-z",
      "journal": "Eur Spine J",
      "raw": "Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery? \n\t\t \n\t\t\t A Stroop \n\t\t \n\t\t 10.1007/s00586-023-07975-z \n\t\t \n\t \n\t \n\t\t Eur Spine J \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Stroop, A. et al. Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery? Eur Spine J. https://doi.org/10.1007/s00586-023-07975-z (2023)"
    },
    {
      "title": "ChatGPT in the development of medical questionnaires. The example of the low back pain",
      "authors": [
        "D Coraci"
      ],
      "year": 2023,
      "doi": "10.4081/ejtm.2023.12114",
      "journal": "Eur J Transl Myol",
      "volume": "33",
      "raw": "ChatGPT in the development of medical questionnaires. The example of the low back pain \n\t\t \n\t\t\t D Coraci \n\t\t \n\t\t 10.4081/ejtm.2023.12114 \n\t\t \n\t \n\t \n\t\t Eur J Transl Myol \n\t\t \n\t\t\t 33 \n\t\t\t 2023 \n\t\t \n\t \n\t Coraci, D. et al. ChatGPT in the development of medical questionnaires. The example of the low back pain. Eur J Transl Myol 33. https://doi.org/10.4081/ejtm.2023.12114 (2023)"
    },
    {
      "title": "Doctor Versus Artificial Intelligence: Patient and Physician Evaluation of Large Language Model Responses to Rheumatology Patient Questions in a Cross-Sectional Study",
      "authors": [
        "C Ye",
        "E Zweck",
        "Z Ma",
        "J Smith",
        "S Katz"
      ],
      "doi": "10.1002/art.42737",
      "journal": "Arthritis & Rheumatology",
      "raw": "Doctor Versus Artificial Intelligence: Patient and Physician Evaluation of Large Language Model Responses to Rheumatology Patient Questions in a Cross-Sectional Study \n\t\t \n\t\t\t C Ye \n\t\t \n\t\t \n\t\t\t E Zweck \n\t\t \n\t\t \n\t\t\t Z Ma \n\t\t \n\t\t \n\t\t\t J Smith \n\t\t \n\t\t \n\t\t\t S Katz \n\t\t \n\t\t 10.1002/art.42737 \n\t\t \n\t \n\t \n\t\t Arthritis & Rheumatology \n\t\t \n\t \n\t Ye, C., Zweck, E., Ma, Z., Smith, J. & Katz, S. Doctor Versus Artificial Intelligence: Patient and Physician Evaluation of Large Language Model Responses to Rheumatology Patient Questions in a Cross-Sectional Study. Arthritis & Rheumatology n/a https://doi.org/10.1002/art.42737"
    },
    {
      "title": "Validity and reliability of artificial intelligence chatbots as public sources of information on endodontics",
      "authors": [
        "H Mohammad-Rahimi"
      ],
      "year": 2024,
      "doi": "10.1038/s43856-024-00717-2",
      "journal": "Int Endod J",
      "volume": "57",
      "raw": "Validity and reliability of artificial intelligence chatbots as public sources of information on endodontics \n\t\t \n\t\t\t H Mohammad-Rahimi \n\t\t \n\t\t 10.1038/s43856-024-00717-2 \n\t\t \n\t \n\t \n\t\t Int Endod J \n\t\t \n\t\t\t 57 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Mohammad-Rahimi, H. et al. Validity and reliability of artificial intelligence chatbots as public sources of information on endodontics. Int Endod J 57, 305-314 (2024). https://doi.org/10.1038/s43856-024-00717-2"
    },
    {
      "title": "Let's chat about cervical cancer: Assessing the accuracy of ChatGPT responses to cervical cancer questions",
      "authors": [
        "C Hermann"
      ],
      "year": 2023,
      "journal": "Gynecologic Oncology",
      "volume": "179",
      "raw": "Let's chat about cervical cancer: Assessing the accuracy of ChatGPT responses to cervical cancer questions \n\t\t \n\t\t\t C E Hermann \n\t\t \n\t \n\t \n\t\t Gynecologic Oncology \n\t\t \n\t\t\t 179 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Hermann, C. E. et al. Let's chat about cervical cancer: Assessing the accuracy of ChatGPT responses to cervical cancer questions. Gynecologic Oncology 179, 164-168 (2023)."
    },
    {
      "title": "Accuracy of ChatGPT in Common Gastrointestinal Diseases: Impact for Patients and Providers",
      "authors": [
        "A Kerbage"
      ],
      "year": 2023,
      "doi": "10.1016/j.cgh.2023.11.008",
      "journal": "Clin Gastroenterol Hepatol",
      "raw": "Accuracy of ChatGPT in Common Gastrointestinal Diseases: Impact for Patients and Providers \n\t\t \n\t\t\t A Kerbage \n\t\t \n\t\t 10.1016/j.cgh.2023.11.008 \n\t\t \n\t \n\t \n\t\t Clin Gastroenterol Hepatol \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Kerbage, A. et al. Accuracy of ChatGPT in Common Gastrointestinal Diseases: Impact for Patients and Providers. Clin Gastroenterol Hepatol. https://doi.org/10.1016/j.cgh.2023.11.008 (2023)"
    },
    {
      "title": "Generating Informed Consent Documents Related to Blepharoplasty Using ChatGPT",
      "authors": [
        "M Shiraishi"
      ],
      "year": 2023,
      "doi": "10.1097/iop.0000000000002574",
      "journal": "Ophthalmic Plast Reconstr Surg",
      "raw": "Generating Informed Consent Documents Related to Blepharoplasty Using ChatGPT \n\t\t \n\t\t\t M Shiraishi \n\t\t \n\t\t 10.1097/iop.0000000000002574 \n\t\t \n\t \n\t \n\t\t Ophthalmic Plast Reconstr Surg \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Shiraishi, M. et al. Generating Informed Consent Documents Related to Blepharoplasty Using ChatGPT. Ophthalmic Plast Reconstr Surg. https://doi.org/10.1097/iop.0000000000002574 (2023)"
    },
    {
      "title": "Quality and Agreement With Scientific Consensus of ChatGPT Information Regarding Corneal Transplantation and Fuchs Dystrophy",
      "authors": [
        "K Barclay"
      ],
      "year": 2023,
      "doi": "10.1097/ico.0000000000003439",
      "journal": "Cornea",
      "raw": "Quality and Agreement With Scientific Consensus of ChatGPT Information Regarding Corneal Transplantation and Fuchs Dystrophy \n\t\t \n\t\t\t K S Barclay \n\t\t \n\t\t 10.1097/ico.0000000000003439 \n\t\t \n\t \n\t \n\t\t Cornea \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Barclay, K. S. et al. Quality and Agreement With Scientific Consensus of ChatGPT Information Regarding Corneal Transplantation and Fuchs Dystrophy. Cornea. https://doi.org/10. 1097/ico.0000000000003439 (2023)"
    },
    {
      "title": "Can Large Language Models Safely Address Patient Questions Following Cataract Surgery?",
      "authors": [
        "A Qarajeh"
      ],
      "year": 2023,
      "journal": "Clin Pract",
      "volume": "13",
      "pages": "101",
      "raw": "Can Large Language Models Safely Address Patient Questions Following Cataract Surgery? \n\t\t \n\t\t\t A Qarajeh \n\t\t \n\t \n\t \n\t\t Clin Pract \n\t\t \n\t\t\t 13 \n\t\t\t 101 \n\t\t\t 2023. 2023 \n\t\t \n\t \n\t AI-powered renal diet support: performance of ChatGPT, Bard AI, and Bing Chat \n\t Qarajeh, A. et al. AI-powered renal diet support: performance of ChatGPT, Bard AI, and Bing Chat. Clin Pract 13, 1160-1172 (2023). 100. Chowdhury, M. et al. Can Large Language Models Safely Address Patient Questions Following Cataract Surgery?, (2023). 101."
    },
    {
      "title": "Development and evaluation of aeyeconsult: a novel ophthalmology chatbot leveraging verified textbook knowledge and GPT-4",
      "authors": [
        "M Singer",
        "J Fu",
        "J Chow",
        "C Teng"
      ],
      "year": 2024,
      "journal": "J Surg Educ",
      "volume": "81",
      "pages": "102",
      "raw": "Development and evaluation of aeyeconsult: a novel ophthalmology chatbot leveraging verified textbook knowledge and GPT-4 \n\t\t \n\t\t\t M B Singer \n\t\t \n\t\t \n\t\t\t J J Fu \n\t\t \n\t\t \n\t\t\t J Chow \n\t\t \n\t\t \n\t\t\t C C Teng \n\t\t \n\t \n\t \n\t\t J Surg Educ \n\t\t \n\t\t\t 81 \n\t\t\t 102 \n\t\t\t 2024 \n\t\t \n\t \n\t Singer, M. B., Fu, J. J., Chow, J. & Teng, C. C. Development and evaluation of aeyeconsult: a novel ophthalmology chatbot leveraging verified textbook knowledge and GPT-4. J Surg Educ 81, 438-443 (2024). 102"
    },
    {
      "title": "Aesthetic surgery advice and counseling from artificial intelligence: a rhinoplasty consultation with ChatGPT",
      "authors": [
        "Y Xie"
      ],
      "year": 2023,
      "doi": "10.1007/s00266-023-03338-7",
      "journal": "Aesthetic Plast Surg",
      "volume": "47",
      "pages": "103",
      "raw": "Aesthetic surgery advice and counseling from artificial intelligence: a rhinoplasty consultation with ChatGPT \n\t\t \n\t\t\t Y Xie \n\t\t \n\t\t 10.1007/s00266-023-03338-7 \n\t \n\t \n\t\t Aesthetic Plast Surg \n\t\t \n\t\t\t 47 \n\t\t\t 103 \n\t\t\t 2023 \n\t\t \n\t \n\t Xie, Y. et al. Aesthetic surgery advice and counseling from artificial intelligence: a rhinoplasty consultation with ChatGPT. Aesthetic Plast Surg 47, 1985-1993 (2023). 103"
    },
    {
      "title": "A vignette-based evaluation of ChatGPT's ability to provide appropriate and equitable medical advice across care contexts",
      "authors": [
        "A Nastasi",
        "K Courtright",
        "S Halpern",
        "G Weissman"
      ],
      "year": 2023,
      "journal": "Sci Rep",
      "volume": "13",
      "pages": "104",
      "raw": "A vignette-based evaluation of ChatGPT's ability to provide appropriate and equitable medical advice across care contexts \n\t\t \n\t\t\t A J Nastasi \n\t\t \n\t\t \n\t\t\t K R Courtright \n\t\t \n\t\t \n\t\t\t S D Halpern \n\t\t \n\t\t \n\t\t\t G E Weissman \n\t\t \n\t \n\t \n\t\t Sci Rep \n\t\t \n\t\t\t 13 \n\t\t\t 104 \n\t\t\t 2023 \n\t\t \n\t \n\t Nastasi, A. J., Courtright, K. R., Halpern, S. D. & Weissman, G. E. A vignette-based evaluation of ChatGPT's ability to provide appropriate and equitable medical advice across care contexts. Sci Rep 13, 17885 (2023). 104"
    },
    {
      "title": "Can ChatGPT be Your Personal Medical Assistant?",
      "authors": [
        "M Biswas",
        "A Islam",
        "Z Shah",
        "W Zaghouani",
        "S Brahim Belhaouari"
      ],
      "year": 2023,
      "pages": "105",
      "raw": "Can ChatGPT be Your Personal Medical Assistant? \n\t\t \n\t\t\t M Biswas \n\t\t \n\t\t \n\t\t\t A Islam \n\t\t \n\t\t \n\t\t\t Z Shah \n\t\t \n\t\t \n\t\t\t W Zaghouani \n\t\t \n\t\t \n\t\t\t S Brahim Belhaouari \n\t\t \n\t\t \n\t\t\t 2023 \n\t\t\t 105 \n\t\t \n\t \n\t Biswas, M., Islam, A., Shah, Z., Zaghouani, W. & Brahim Belhaouari, S. Can ChatGPT be Your Personal Medical Assistant?, (2023). 105."
    },
    {
      "title": "Evaluating the Potential of LLMs and ChatGPT on Medical Diagnosis and Treatment",
      "authors": [
        "D Panagoulias",
        "F Palamidas",
        "M Virvou",
        "G Tsihrintzis"
      ],
      "year": 2023,
      "pages": "106",
      "raw": "Evaluating the Potential of LLMs and ChatGPT on Medical Diagnosis and Treatment \n\t\t \n\t\t\t D Panagoulias \n\t\t \n\t\t \n\t\t\t F Palamidas \n\t\t \n\t\t \n\t\t\t M Virvou \n\t\t \n\t\t \n\t\t\t G Tsihrintzis \n\t\t \n\t\t \n\t\t\t 2023 \n\t\t\t 106 \n\t\t \n\t \n\t Panagoulias, D., Palamidas, F., Virvou, M. & Tsihrintzis, G. Evaluating the Potential of LLMs and ChatGPT on Medical Diagnosis and Treatment. (2023). 106."
    },
    {
      "title": "Utility of allergen-specific patient-directed handouts generated by chat generative pretrained transformer",
      "authors": [
        "A Chandra",
        "M Davis",
        "D Hamann",
        "C Hamann"
      ],
      "year": 2023,
      "journal": "Dermatitis",
      "volume": "34",
      "pages": "107",
      "raw": "Utility of allergen-specific patient-directed handouts generated by chat generative pretrained transformer \n\t\t \n\t\t\t A Chandra \n\t\t \n\t\t \n\t\t\t M J Davis \n\t\t \n\t\t \n\t\t\t D Hamann \n\t\t \n\t\t \n\t\t\t C R Hamann \n\t\t \n\t \n\t \n\t\t Dermatitis \n\t\t \n\t\t\t 34 \n\t\t\t 107 \n\t\t\t 2023 \n\t\t \n\t \n\t Chandra, A., Davis, M. J., Hamann, D. & Hamann, C. R. Utility of allergen-specific patient-directed handouts generated by chat generative pretrained transformer. Dermatitis 34, 448 (2023). 107"
    },
    {
      "title": "Comparison of patient education materials generated by chat generative pretrained transformer versus experts: an innovative way to increase readability of patient education materials",
      "authors": [
        "Y.-C Hung",
        "S Chaker",
        "M Sigel",
        "M Saad",
        "E Slater"
      ],
      "year": 2023,
      "doi": "10.1055/a-2219-4901",
      "journal": "Annals of Plastic Surgery",
      "volume": "91",
      "raw": "Comparison of patient education materials generated by chat generative pretrained transformer versus experts: an innovative way to increase readability of patient education materials \n\t\t \n\t\t\t Y.-C Hung \n\t\t \n\t\t \n\t\t\t S Chaker \n\t\t \n\t\t \n\t\t\t M Sigel \n\t\t \n\t\t \n\t\t\t M Saad \n\t\t \n\t\t \n\t\t\t E Slater \n\t\t \n\t\t 10.1055/a-2219-4901 \n\t\t \n\t \n\t \n\t\t Annals of Plastic Surgery \n\t\t \n\t\t\t 91 \n\t\t\t \n\t\t\t 2023. 2024 \n\t\t \n\t \n\t ChatGPT and Rhinoplasty Recovery: An Exploration of AI's Role in Postoperative Guidance Facial Plast Surg \n\t Hung, Y.-C., Chaker, S., Sigel, M., Saad, M. & Slater, E. Comparison of patient education materials generated by chat generative pre- trained transformer versus experts: an innovative way to increase readability of patient education materials. Annals of Plastic Surgery 91, 409-412 (2023). 108. Capelleras, M., Soto-Galindo, G. A., Cruellas, M. & Apaydin, F. ChatGPT and Rhinoplasty Recovery: An Exploration of AI's Role in Postoperative Guidance. Facial Plast Surg (2024). https://doi.org/ 10.1055/a-2219-4901 109."
    },
    {
      "title": "Testing ChatGPT ability to answer laypeople questions about cardiac arrest and cardiopulmonary resuscitation",
      "authors": [
        "T Scquizzato"
      ],
      "year": 2024,
      "doi": "10.1016/j.resuscitation.2023.110077",
      "journal": "Resuscitation",
      "volume": "194",
      "pages": "111",
      "raw": "Testing ChatGPT ability to answer laypeople questions about cardiac arrest and cardiopulmonary resuscitation \n\t\t \n\t\t\t T Scquizzato \n\t\t \n\t\t 10.1016/j.resuscitation.2023.110077 \n\t \n\t \n\t\t Resuscitation \n\t\t \n\t\t\t 194 \n\t\t\t 111 \n\t\t\t 2024. 2024 \n\t\t \n\t \n\t Assessing AI-powered patient education: a case study in radiology Acad Radiol \n\t Scquizzato, T. et al. Testing ChatGPT ability to answer laypeople questions about cardiac arrest and cardiopulmonary resuscitation. Resuscitation 194, 110077 (2024). 110. Kuckelman, I. J. et al. Assessing AI-powered patient education: a case study in radiology. Acad Radiol 31, 338-342 (2024). 111"
    },
    {
      "title": "A large language model artificial intelligence for patient queries in atopic dermatitis",
      "authors": [
        "P Sulejmani"
      ],
      "doi": "10.1111/jdv.19737",
      "journal": "J Eur Acad Dermatol Venereol",
      "raw": "A large language model artificial intelligence for patient queries in atopic dermatitis \n\t\t \n\t\t\t P Sulejmani \n\t\t \n\t\t 10.1111/jdv.19737 \n\t\t \n\t \n\t \n\t\t J Eur Acad Dermatol Venereol \n\t\t \n\t \n\t Sulejmani, P. et al. A large language model artificial intelligence for patient queries in atopic dermatitis. J Eur Acad Dermatol Venereol. https://doi.org/10.1111/jdv.19737 (2024) 112."
    },
    {
      "title": "ChatGPT in nuclear medicine education",
      "authors": [
        "G Currie",
        "K Barry"
      ],
      "year": 2023,
      "journal": "Journal of Nuclear Medicine Technology",
      "volume": "51",
      "pages": "113",
      "raw": "ChatGPT in nuclear medicine education \n\t\t \n\t\t\t G Currie \n\t\t \n\t\t \n\t\t\t K Barry \n\t\t \n\t \n\t \n\t\t Journal of Nuclear Medicine Technology \n\t\t \n\t\t\t 51 \n\t\t\t 113 \n\t\t\t 2023 \n\t\t \n\t \n\t Currie, G. & Barry, K. ChatGPT in nuclear medicine education. Journal of Nuclear Medicine Technology 51, 247-254 (2023). 113"
    },
    {
      "title": "Academic integrity and artificial intelligence: is ChatGPT hype, hero or heresy?",
      "authors": [
        "G Currie"
      ],
      "year": 2023,
      "journal": "Seminars in Nuclear Medicine",
      "volume": "53",
      "pages": "114",
      "raw": "Academic integrity and artificial intelligence: is ChatGPT hype, hero or heresy? \n\t\t \n\t\t\t G M Currie \n\t\t \n\t \n\t \n\t\t Seminars in Nuclear Medicine \n\t\t \n\t\t\t 53 \n\t\t\t 114 \n\t\t\t 2023 \n\t\t \n\t \n\t Currie, G. M. Academic integrity and artificial intelligence: is ChatGPT hype, hero or heresy? Seminars in Nuclear Medicine 53, 719-730 (2023). 114"
    },
    {
      "title": "ChatGPT in healthcare: a taxonomy and systematic review",
      "authors": [
        "J Li",
        "A Dada",
        "B Puladi",
        "J Kleesiek",
        "J Egger"
      ],
      "year": 2024,
      "journal": "Computer Methods and Programs in Biomedicine",
      "volume": "245",
      "pages": "115",
      "raw": "ChatGPT in healthcare: a taxonomy and systematic review \n\t\t \n\t\t\t J Li \n\t\t \n\t\t \n\t\t\t A Dada \n\t\t \n\t\t \n\t\t\t B Puladi \n\t\t \n\t\t \n\t\t\t J Kleesiek \n\t\t \n\t\t \n\t\t\t J Egger \n\t\t \n\t \n\t \n\t\t Computer Methods and Programs in Biomedicine \n\t\t \n\t\t\t 245 \n\t\t\t 115 \n\t\t\t 2024 \n\t\t \n\t \n\t Li, J., Dada, A., Puladi, B., Kleesiek, J. & Egger, J. ChatGPT in healthcare: a taxonomy and systematic review. Computer Methods and Programs in Biomedicine 245, 108013 (2024). 115"
    },
    {
      "title": "Exploring Vulnerabilities and Protections in Large Language Models: A Survey",
      "authors": [
        "F Liu",
        "C Hu"
      ],
      "year": 2024,
      "pages": "117",
      "raw": "Exploring Vulnerabilities and Protections in Large Language Models: A Survey \n\t\t \n\t\t\t F W Liu \n\t\t \n\t\t \n\t\t\t C Hu \n\t\t \n\t\t \n\t\t\t M \n\t\t \n\t\t arXiv:2406.00240 \n\t\t arXiv:2402.00746 \n\t \n\t \n\t\t Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model \n\t\t \n\t\t\t 2024. 2024 \n\t\t\t 117 \n\t\t \n\t \n\t arXiv preprint \n\t Liu, F. W. & Hu, C. Exploring Vulnerabilities and Protections in Large Language Models: A Survey. arXiv preprint arXiv:2406.00240 (2024). 116. Jin, M. et al. Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model. arXiv preprint arXiv:2402.00746 (2024). 117"
    },
    {
      "title": "Capabilities of gpt-4 on medical challenge problems",
      "authors": [
        "H Nori",
        "N King",
        "S Mckinney",
        "D Carignan",
        "E Horvitz"
      ],
      "year": 2023,
      "pages": "118",
      "raw": "H Nori \n\t\t \n\t\t \n\t\t\t N King \n\t\t \n\t\t \n\t\t\t S M Mckinney \n\t\t \n\t\t \n\t\t\t D Carignan \n\t\t \n\t\t \n\t\t\t E Horvitz \n\t\t \n\t\t arXiv:2303.13375 \n\t\t Capabilities of gpt-4 on medical challenge problems \n\t\t \n\t\t\t 2023 \n\t\t\t 118 \n\t\t \n\t \n\t arXiv preprint \n\t Nori, H., King, N., McKinney, S. M., Carignan, D. & Horvitz, E. Capabilities of gpt-4 on medical challenge problems. arXiv preprint arXiv:2303.13375 (2023). 118"
    },
    {
      "title": "Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments",
      "authors": [
        "D Brin"
      ],
      "year": 2023,
      "doi": "10.1038/s41598-023-43436-9",
      "journal": "Scientific Reports",
      "volume": "13",
      "pages": "119",
      "raw": "Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments \n\t\t \n\t\t\t D Brin \n\t\t \n\t\t 10.1038/s41598-023-43436-9 \n\t \n\t \n\t\t Scientific Reports \n\t\t \n\t\t\t 13 \n\t\t\t 119 \n\t\t\t 2023 \n\t\t \n\t \n\t Brin, D. et al. Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments. Scientific Reports 13, 16492 (2023). 119"
    },
    {
      "title": "ChatGPT passes German State examination in medicine with picture questions omitted",
      "authors": [
        "L Jung"
      ],
      "year": 2023,
      "doi": "10.3238/arztebl.m2023.0113",
      "journal": "Dtsch Arztebl Int",
      "volume": "120",
      "pages": "120",
      "raw": "ChatGPT passes German State examination in medicine with picture questions omitted \n\t\t \n\t\t\t L B Jung \n\t\t \n\t\t 10.3238/arztebl.m2023.0113 \n\t \n\t \n\t\t Dtsch Arztebl Int \n\t\t \n\t\t\t 120 \n\t\t\t 120 \n\t\t\t 2023 \n\t\t \n\t \n\t Jung, L. B. et al. ChatGPT passes German State examination in medicine with picture questions omitted. Dtsch Arztebl Int 120, 373-374 (2023). 120"
    },
    {
      "title": "Performance of ChatGPT on a radiology board-style examination: insights into current strengths and limitations",
      "authors": [
        "R Bhayana",
        "S Krishna",
        "R Bleakney"
      ],
      "year": 2023,
      "doi": "10.1148/radiol.230582",
      "journal": "Radiology",
      "volume": "307",
      "pages": "121",
      "raw": "Performance of ChatGPT on a radiology board-style examination: insights into current strengths and limitations \n\t\t \n\t\t\t R Bhayana \n\t\t \n\t\t \n\t\t\t S Krishna \n\t\t \n\t\t \n\t\t\t R R Bleakney \n\t\t \n\t\t 10.1148/radiol.230582 \n\t \n\t \n\t\t Radiology \n\t\t \n\t\t\t 307 \n\t\t\t 121 \n\t\t\t 2023 \n\t\t \n\t \n\t Bhayana, R., Krishna, S. & Bleakney, R. R. Performance of ChatGPT on a radiology board-style examination: insights into current strengths and limitations. Radiology 307, e230582 (2023). 121"
    },
    {
      "title": "Towards expert-level medical question answering with large language models",
      "authors": [
        "K Singhal"
      ],
      "year": 2023,
      "pages": "122",
      "raw": "Towards expert-level medical question answering with large language models \n\t\t \n\t\t\t K Singhal \n\t\t \n\t\t arXiv:2305.09617 \n\t\t \n\t\t\t 2023 \n\t\t\t 122 \n\t\t \n\t \n\t arXiv preprint \n\t Singhal, K. et al. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617 (2023). 122"
    },
    {
      "title": "Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data",
      "authors": [
        "F Dorfner"
      ],
      "year": 2024,
      "pages": "123",
      "raw": "Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data \n\t\t \n\t\t\t F J Dorfner \n\t\t \n\t\t arXiv:2408.13833 \n\t\t \n\t\t\t 2024 \n\t\t\t 123 \n\t\t \n\t \n\t arXiv preprint \n\t Dorfner, F. J. et al. Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data. arXiv preprint arXiv:2408.13833 (2024). 123"
    },
    {
      "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models",
      "authors": [
        "T Kung"
      ],
      "year": 2023,
      "journal": "PLOS Digital Health",
      "volume": "2",
      "pages": "124",
      "raw": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models \n\t\t \n\t\t\t T H Kung \n\t\t \n\t \n\t \n\t\t PLOS Digital Health \n\t\t \n\t\t\t 2 \n\t\t\t 124 \n\t\t\t 2023 \n\t\t \n\t \n\t Kung, T. H. et al. Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models. PLOS Digital Health 2, e0000198 (2023). 124."
    },
    {
      "title": "Promises and pitfalls of artificial intelligence for legal applications",
      "authors": [
        "S Kapoor",
        "P Henderson",
        "A Narayanan"
      ],
      "year": 2024,
      "doi": "10.2139/ssrn.4695412",
      "pages": "125",
      "raw": "Promises and pitfalls of artificial intelligence for legal applications \n\t\t \n\t\t\t S Kapoor \n\t\t \n\t\t \n\t\t\t P Henderson \n\t\t \n\t\t \n\t\t\t A Narayanan \n\t\t \n\t\t 10.2139/ssrn.4695412 \n\t\t arXiv:2402.01656 \n\t\t \n\t\t\t 2024 \n\t\t\t 125 \n\t\t \n\t \n\t arXiv preprint \n\t Kapoor, S., Henderson, P. & Narayanan, A. Promises and pitfalls of artificial intelligence for legal applications. arXiv preprint arXiv:2402.01656 (2024). 125"
    },
    {
      "title": "LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation",
      "authors": [
        "S Ouyang",
        "J Zhang",
        "M Harman",
        "M Wang"
      ],
      "year": 2023,
      "pages": "126",
      "raw": "LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation \n\t\t \n\t\t\t S Ouyang \n\t\t \n\t\t \n\t\t\t J M Zhang \n\t\t \n\t\t \n\t\t\t M Harman \n\t\t \n\t\t \n\t\t\t M Wang \n\t\t \n\t\t arXiv:2308.02828 \n\t\t \n\t\t\t 2023 \n\t\t\t 126 \n\t\t \n\t \n\t arXiv preprint \n\t Ouyang, S., Zhang, J. M., Harman, M. & Wang, M. LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation. arXiv preprint arXiv:2308.02828 (2023). 126"
    },
    {
      "title": "LLM Stability: A detailed analysis with some surprises",
      "authors": [
        "B Atil"
      ],
      "year": 2024,
      "pages": "127",
      "raw": "LLM Stability: A detailed analysis with some surprises \n\t\t \n\t\t\t B Atil \n\t\t \n\t\t arXiv:2408.04667 \n\t\t \n\t\t\t 2024 \n\t\t\t 127 \n\t\t \n\t \n\t arXiv preprint \n\t Atil, B. et al. LLM Stability: A detailed analysis with some surprises. arXiv preprint arXiv:2408.04667 (2024). 127"
    },
    {
      "title": "Health Literacy: A Manual for Clinicians",
      "authors": [
        "B Weis"
      ],
      "year": 2003,
      "pages": "128",
      "raw": "B Weis \n\t\t \n\t\t Health Literacy: A Manual for Clinicians \n\t\t Chicago, IL \n\t\t \n\t\t\t National Library of Medicine Website \n\t\t\t 2003 \n\t\t\t 128 \n\t\t \n\t \n\t How to Write Easy to Read Health Materials \n\t Weis, B. Health Literacy: A Manual for Clinicians. Chicago, IL: American Medical Association, American Medical Foundation; 2003. National Institutes of Health. How to Write Easy to Read Health Materials: National Library of Medicine Website. How to Write Easy to Read Health Materials: National Library of Medicine Website 128."
    },
    {
      "title": "Explainability for artificial intelligence in healthcare: a multidisciplinary perspective",
      "authors": [
        "J Amann"
      ],
      "year": 2020,
      "journal": "BMC Medical Informatics and Decision Making",
      "volume": "20",
      "pages": "129",
      "raw": "Explainability for artificial intelligence in healthcare: a multidisciplinary perspective \n\t\t \n\t\t\t J Amann \n\t\t \n\t \n\t \n\t\t BMC Medical Informatics and Decision Making \n\t\t \n\t\t\t 20 \n\t\t\t 129 \n\t\t\t 2020 \n\t\t \n\t \n\t Amann, J. et al. Explainability for artificial intelligence in healthcare: a multidisciplinary perspective. BMC Medical Informatics and Decision Making 20, 310 (2020). 129"
    },
    {
      "title": "Ethical and legal challenges of artificial intelligence-driven healthcare",
      "authors": [
        "S Gerke",
        "T Minssen",
        "G Cohen"
      ],
      "doi": "10.1016/b978-0-12-818438-7.00012-5",
      "journal": "Artificial Intelligence in Healthcare",
      "raw": "Ethical and legal challenges of artificial intelligence-driven healthcare \n\t\t \n\t\t\t S Gerke \n\t\t \n\t\t \n\t\t\t T Minssen \n\t\t \n\t\t \n\t\t\t G Cohen \n\t\t \n\t\t 10.1016/b978-0-12-818438-7.00012-5 \n\t\t \n\t \n\t \n\t\t Artificial Intelligence in Healthcare \n\t\t \n\t\t\t \n\t\t \n\t \n\t Gerke, S., Minssen, T. & Cohen, G. Ethical and legal challenges of artificial intelligence-driven healthcare. Artificial Intelligence in Healthcare, 295-336. https://doi.org/10.1016/b978-0-12-818438- 7.00012-5 (2020) 130."
    },
    {
      "title": "Fully informed consent can be needlessly cruel",
      "authors": [
        "J Tobias",
        "R Souhami"
      ],
      "year": 1993,
      "journal": "Bmj",
      "volume": "307",
      "pages": "131",
      "raw": "Fully informed consent can be needlessly cruel \n\t\t \n\t\t\t J S Tobias \n\t\t \n\t\t \n\t\t\t R L Souhami \n\t\t \n\t \n\t \n\t\t Bmj \n\t\t \n\t\t\t 307 \n\t\t\t 131 \n\t\t\t 1993 \n\t\t \n\t \n\t Tobias, J. S. & Souhami, R. L. Fully informed consent can be needlessly cruel. Bmj 307, 1199-1201 (1993). 131"
    },
    {
      "title": "The reality of informed consent: empirical studies on patient comprehension-systematic review",
      "authors": [
        "T Pietrzykowski",
        "K Smilowska"
      ],
      "year": 2021,
      "journal": "Trials",
      "volume": "22",
      "pages": "132",
      "raw": "The reality of informed consent: empirical studies on patient comprehension-systematic review \n\t\t \n\t\t\t T Pietrzykowski \n\t\t \n\t\t \n\t\t\t K Smilowska \n\t\t \n\t \n\t \n\t\t Trials \n\t\t \n\t\t\t 22 \n\t\t\t 132 \n\t\t\t 2021 \n\t\t \n\t \n\t Pietrzykowski, T. & Smilowska, K. The reality of informed consent: empirical studies on patient comprehension-systematic review. Trials 22, 57 (2021). 132"
    },
    {
      "title": "Mandatory disclaimers on dietary supplements do not reliably communicate the intended issues",
      "authors": [
        "A Kesselheim",
        "J Connolly",
        "J Rogers",
        "J Avorn"
      ],
      "year": 2015,
      "journal": "Health Affairs",
      "volume": "34",
      "pages": "133",
      "raw": "Mandatory disclaimers on dietary supplements do not reliably communicate the intended issues \n\t\t \n\t\t\t A S Kesselheim \n\t\t \n\t\t \n\t\t\t J Connolly \n\t\t \n\t\t \n\t\t\t J Rogers \n\t\t \n\t\t \n\t\t\t J Avorn \n\t\t \n\t \n\t \n\t\t Health Affairs \n\t\t \n\t\t\t 34 \n\t\t\t 133 \n\t\t\t 2015 \n\t\t \n\t \n\t Kesselheim, A. S., Connolly, J., Rogers, J. & Avorn, J. Mandatory disclaimers on dietary supplements do not reliably communicate the intended issues. Health Affairs 34, 438-446 (2015). 133"
    },
    {
      "title": "High-performance medicine: the convergence of human and artificial intelligence",
      "authors": [
        "E Topol"
      ],
      "year": 2019,
      "journal": "Nature Medicine",
      "volume": "25",
      "pages": "134",
      "raw": "High-performance medicine: the convergence of human and artificial intelligence \n\t\t \n\t\t\t E J Topol \n\t\t \n\t \n\t \n\t\t Nature Medicine \n\t\t \n\t\t\t 25 \n\t\t\t 134 \n\t\t\t 2019 \n\t\t \n\t \n\t Topol, E. J. High-performance medicine: the convergence of human and artificial intelligence. Nature Medicine 25, 44-56 (2019). 134"
    },
    {
      "title": "Semantic consistency for assuring reliability of large language models",
      "authors": [
        "H Raj",
        "V Gupta",
        "D Rosati",
        "S Majumdar"
      ],
      "year": 2023,
      "pages": "135",
      "raw": "Semantic consistency for assuring reliability of large language models \n\t\t \n\t\t\t H Raj \n\t\t \n\t\t \n\t\t\t V Gupta \n\t\t \n\t\t \n\t\t\t D Rosati \n\t\t \n\t\t \n\t\t\t S Majumdar \n\t\t \n\t\t arXiv:2308.09138 \n\t\t \n\t\t\t 2023 \n\t\t\t 135 \n\t\t \n\t \n\t arXiv preprint \n\t Raj, H., Gupta, V., Rosati, D. & Majumdar, S. Semantic consistency for assuring reliability of large language models. arXiv preprint arXiv:2308.09138 (2023). 135"
    },
    {
      "title": "Large Language Models Are Human-Level Prompt Engineers",
      "authors": [
        "Y Zhou"
      ],
      "year": 2022,
      "pages": "136",
      "raw": "Large Language Models Are Human-Level Prompt Engineers \n\t\t \n\t\t\t Y Zhou \n\t\t \n\t\t ArXiv abs/2211.01910 \n\t\t \n\t\t\t 2022 \n\t\t\t 136 \n\t\t \n\t \n\t Zhou, Y. et al. Large Language Models Are Human-Level Prompt Engineers. ArXiv abs/2211.01910 (2022). 136"
    },
    {
      "title": "Certified Robustness for Large Language Models with Self-Denoising",
      "authors": [
        "Z Zhang"
      ],
      "year": 2023,
      "pages": "137",
      "raw": "Certified Robustness for Large Language Models with Self-Denoising \n\t\t \n\t\t\t Z Zhang \n\t\t \n\t\t ArXiv abs/2307.07171 \n\t\t \n\t\t\t 2023 \n\t\t\t 137 \n\t\t \n\t \n\t Zhang, Z. et al. Certified Robustness for Large Language Models with Self-Denoising. ArXiv abs/2307.07171 (2023). 137"
    },
    {
      "title": "Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology -a recent scoping review",
      "authors": [
        "E Ullah",
        "A Parwani",
        "M Baig",
        "R Singh"
      ],
      "year": 2024,
      "doi": "10.1038/s43856-024-00717-2138",
      "journal": "Diagn Pathol",
      "volume": "19",
      "pages": "43",
      "raw": "Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology -a recent scoping review \n\t\t \n\t\t\t E Ullah \n\t\t \n\t\t \n\t\t\t A Parwani \n\t\t \n\t\t \n\t\t\t M M Baig \n\t\t \n\t\t \n\t\t\t R Singh \n\t\t \n\t\t 10.1038/s43856-024-00717-2138 \n\t\t \n\t \n\t \n\t\t Diagn Pathol \n\t\t \n\t\t\t 19 \n\t\t\t 43 \n\t\t\t 2024 \n\t\t \n\t \n\t Ullah, E., Parwani, A., Baig, M. M. & Singh, R. Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology -a recent scoping review. Diagn Pathol 19, 43 (2024). https://doi.org/10.1038/s43856-024-00717-2 138."
    },
    {
      "title": "Biases in large language models: origins, inventory, and discussion",
      "authors": [
        "R Navigli",
        "S Conia",
        "B Ross"
      ],
      "year": 2023,
      "journal": "ACM Journal of Data and Information Quality",
      "volume": "15",
      "pages": "139",
      "raw": "Biases in large language models: origins, inventory, and discussion \n\t\t \n\t\t\t R Navigli \n\t\t \n\t\t \n\t\t\t S Conia \n\t\t \n\t\t \n\t\t\t B Ross \n\t\t \n\t \n\t \n\t\t ACM Journal of Data and Information Quality \n\t\t \n\t\t\t 15 \n\t\t\t 139 \n\t\t\t 2023 \n\t\t \n\t \n\t Navigli, R., Conia, S. & Ross, B. Biases in large language models: origins, inventory, and discussion. ACM Journal of Data and Information Quality 15, 1-21 (2023). 139"
    },
    {
      "title": "Jailbreaker: Automated jailbreak across multiple large language model chatbots",
      "authors": [
        "G Deng"
      ],
      "year": 2023,
      "pages": "140",
      "raw": "Jailbreaker: Automated jailbreak across multiple large language model chatbots \n\t\t \n\t\t\t G Deng \n\t\t \n\t\t arXiv:2307.08715 \n\t\t \n\t\t\t 2023 \n\t\t\t 140 \n\t\t \n\t \n\t arXiv preprint \n\t Deng, G. et al. Jailbreaker: Automated jailbreak across multiple large language model chatbots. arXiv preprint arXiv:2307.08715 (2023). 140"
    },
    {
      "title": "Large language models show humanlike content biases in transmission chain experiments",
      "authors": [
        "A Acerbi",
        "J Stubbersfield"
      ],
      "year": 2023,
      "journal": "Proceedings of the National Academy of Sciences",
      "volume": "120",
      "pages": "141",
      "raw": "Large language models show humanlike content biases in transmission chain experiments \n\t\t \n\t\t\t A Acerbi \n\t\t \n\t\t \n\t\t\t J M Stubbersfield \n\t\t \n\t \n\t \n\t\t Proceedings of the National Academy of Sciences \n\t\t \n\t\t\t 120 \n\t\t\t 141 \n\t\t\t 2023 \n\t\t \n\t \n\t Acerbi, A. & Stubbersfield, J. M. Large language models show human- like content biases in transmission chain experiments. Proceedings of the National Academy of Sciences 120, e2313790120 (2023). 141"
    },
    {
      "title": "Adaptive data debiasing through bounded exploration",
      "authors": [
        "Y Yang",
        "Y Liu",
        "P Naghizadeh"
      ],
      "year": 2022,
      "journal": "Advances in Neural Information Processing Systems",
      "volume": "35",
      "pages": "142",
      "raw": "Adaptive data debiasing through bounded exploration \n\t\t \n\t\t\t Y Yang \n\t\t \n\t\t \n\t\t\t Y Liu \n\t\t \n\t\t \n\t\t\t P Naghizadeh \n\t\t \n\t \n\t \n\t\t Advances in Neural Information Processing Systems \n\t\t \n\t\t\t 35 \n\t\t\t 142 \n\t\t\t 2022 \n\t\t \n\t \n\t Yang, Y., Liu, Y. & Naghizadeh, P. Adaptive data debiasing through bounded exploration. Advances in Neural Information Processing Systems 35, 1516-1528 (2022). 142"
    },
    {
      "title": "Bias and Fairness in Large Language Models: A Survey",
      "authors": [
        "I Gallegos"
      ],
      "doi": "10.1162/coli_a_00524",
      "journal": "Computational Linguistics",
      "raw": "Bias and Fairness in Large Language Models: A Survey \n\t\t \n\t\t\t I O Gallegos \n\t\t \n\t\t 10.1162/coli_a_00524 \n\t\t \n\t \n\t \n\t\t Computational Linguistics \n\t\t \n\t\t\t \n\t\t \n\t \n\t Gallegos, I. O. et al. Bias and Fairness in Large Language Models: A Survey. Computational Linguistics, 1-83. https://doi.org/10.1162/ coli_a_00524 (2024) 143."
    },
    {
      "title": "On the Fairness ROAD: Robust Optimization for Adversarial Debiasing",
      "authors": [
        "V Grari",
        "T Laugel",
        "T Hashimoto",
        "S Lamprier",
        "M Detyniecki"
      ],
      "year": 2023,
      "doi": "10.1007/s10994-022-06206-8",
      "pages": "144",
      "raw": "On the Fairness ROAD: Robust Optimization for Adversarial Debiasing \n\t\t \n\t\t\t V Grari \n\t\t \n\t\t \n\t\t\t T Laugel \n\t\t \n\t\t \n\t\t\t T Hashimoto \n\t\t \n\t\t \n\t\t\t S Lamprier \n\t\t \n\t\t \n\t\t\t M Detyniecki \n\t\t \n\t\t 10.1007/s10994-022-06206-8 \n\t\t arXiv:2310.18413 \n\t\t \n\t\t\t 2023 \n\t\t\t 144 \n\t\t \n\t \n\t arXiv preprint \n\t Grari, V., Laugel, T., Hashimoto, T., Lamprier, S. & Detyniecki, M. On the Fairness ROAD: Robust Optimization for Adversarial Debiasing. arXiv preprint arXiv:2310.18413 (2023). 144"
    },
    {
      "title": "AI generates covertly racist decisions about people based on their dialect",
      "authors": [
        "V Hofmann",
        "P Kalluri",
        "D Jurafsky",
        "S King"
      ],
      "year": 2024,
      "journal": "Nature",
      "volume": "633",
      "pages": "145",
      "raw": "AI generates covertly racist decisions about people based on their dialect \n\t\t \n\t\t\t V Hofmann \n\t\t \n\t\t \n\t\t\t P R Kalluri \n\t\t \n\t\t \n\t\t\t D Jurafsky \n\t\t \n\t\t \n\t\t\t S King \n\t\t \n\t \n\t \n\t\t Nature \n\t\t \n\t\t\t 633 \n\t\t\t 145 \n\t\t\t 2024 \n\t\t \n\t \n\t Hofmann, V., Kalluri, P. R., Jurafsky, D. & King, S. AI generates covertly racist decisions about people based on their dialect. Nature 633, 147-154 (2024). 145"
    },
    {
      "title": "Head-to-Head Comparison of ChatGPT Versus Google Search for Medical Knowledge Acquisition",
      "authors": [
        "N Ayoub",
        "Y Lee",
        "D Grimm",
        "V Divi"
      ],
      "doi": "10.1002/ohn.465",
      "journal": "Otolaryngol Head Neck Surg",
      "raw": "Head-to-Head Comparison of ChatGPT Versus Google Search for Medical Knowledge Acquisition \n\t\t \n\t\t\t N F Ayoub \n\t\t \n\t\t \n\t\t\t Y J Lee \n\t\t \n\t\t \n\t\t\t D Grimm \n\t\t \n\t\t \n\t\t\t V Divi \n\t\t \n\t\t 10.1002/ohn.465 \n\t\t \n\t \n\t \n\t\t Otolaryngol Head Neck Surg \n\t\t \n\t \n\t Ayoub, N. F., Lee, Y. J., Grimm, D. & Divi, V. Head-to-Head Comparison of ChatGPT Versus Google Search for Medical Knowledge Acquisition. Otolaryngol Head Neck Surg. https://doi. org/10.1002/ohn.465 (2023) 146."
    },
    {
      "title": "A survey on large language model (LLM) security and privacy: the good, the bad, and the ugly",
      "authors": [
        "Y Yao"
      ],
      "year": 2024,
      "journal": "High-Confidence Computing",
      "volume": "4",
      "pages": "147",
      "raw": "A survey on large language model (LLM) security and privacy: the good, the bad, and the ugly \n\t\t \n\t\t\t Y Yao \n\t\t \n\t \n\t \n\t\t High-Confidence Computing \n\t\t \n\t\t\t 4 \n\t\t\t 147 \n\t\t\t 2024 \n\t\t \n\t \n\t Yao, Y. et al. A survey on large language model (LLM) security and privacy: the good, the bad, and the ugly. High-Confidence Computing 4, 100211 (2024). 147"
    },
    {
      "title": "Medical AI and human dignity: contrasting perceptions of human and artificially intelligent (AI) decision making in diagnostic and medical resource allocation contexts",
      "authors": [
        "A Tierney"
      ],
      "year": 2022,
      "journal": "Computers in Human Behavior",
      "volume": "5",
      "pages": "149",
      "raw": "Medical AI and human dignity: contrasting perceptions of human and artificially intelligent (AI) decision making in diagnostic and medical resource allocation contexts \n\t\t \n\t\t\t A A Tierney \n\t\t \n\t\t CAT.23.0404 \n\t \n\t \n\t\t Computers in Human Behavior \n\t\t \n\t\t\t 5 \n\t\t\t 149 \n\t\t\t 2024. 2022 \n\t\t \n\t \n\t Ambient artificial intelligence scribes to alleviate the burden of clinical documentation NEJM Catalyst \n\t Tierney, A. A. et al. Ambient artificial intelligence scribes to alleviate the burden of clinical documentation. NEJM Catalyst 5, CAT.23.0404 (2024). 148. Formosa, P., Rogers, W., Griep, Y., Bankins, S. & Richards, D. Medical AI and human dignity: contrasting perceptions of human and artificially intelligent (AI) decision making in diagnostic and medical resource allocation contexts. Computers in Human Behavior 133, 107296 (2022). 149"
    },
    {
      "title": "Patient perspectives on the use of artificial intelligence in health care: a scoping review",
      "authors": [
        "S Moy"
      ],
      "year": 2024,
      "journal": "J Patient Cent Res Rev",
      "volume": "11",
      "pages": "150",
      "raw": "Patient perspectives on the use of artificial intelligence in health care: a scoping review \n\t\t \n\t\t\t S Moy \n\t\t \n\t \n\t \n\t\t J Patient Cent Res Rev \n\t\t \n\t\t\t 11 \n\t\t\t 150 \n\t\t\t 2024 \n\t\t\t Union, C. O. T. E \n\t\t \n\t \n\t . Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts -Analysis of the final compromise text with a view to agreement, (2024). 151 \n\t Moy, S. et al. Patient perspectives on the use of artificial intelligence in health care: a scoping review. J Patient Cent Res Rev 11, 51-62 (2024). 150. Union, C. O. T. E. Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts -Analysis of the final compromise text with a view to agreement, (2024). 151."
    },
    {
      "title": "Navigating the european union artificial intelligence act for healthcare",
      "authors": [
        "F Busch"
      ],
      "year": 2024,
      "journal": "npj Digital Medicine",
      "volume": "7",
      "pages": "210",
      "raw": "Navigating the european union artificial intelligence act for healthcare \n\t\t \n\t\t\t F Busch \n\t\t \n\t \n\t \n\t\t npj Digital Medicine \n\t\t \n\t\t\t 7 \n\t\t\t 210 \n\t\t\t 2024 \n\t\t \n\t \n\t Busch, F. et al. Navigating the european union artificial intelligence act for healthcare. npj Digital Medicine 7, 210 (2024)."
    },
    {
      "authors": [
        "Else Kroener"
      ],
      "volume": "11",
      "raw": "Else Kroener \n\t\t \n\t\t \n\t\t\t Fresenius \n\t\t \n\t\t \n\t\t\t 11 \n\t\t\t Dresden, Germany; Aachen, Germany; Baronissi, Italy \n\t\t \n\t\t \n\t\t\t Center for Digital Health, Medical Faculty Carl Gustav Carus ; Technical University Dresden ; Department of Diagnostic and Interventional Radiology, University Hospital Aachen ; Department of Medicine, Surgery and Dentistry, University of Salerno \n\t\t \n\t \n\t Else Kroener Fresenius Center for Digital Health, Medical Faculty Carl Gustav Carus, Technical University Dresden, Dresden, Germany. 11 Department of Diagnostic and Interventional Radiology, University Hospital Aachen, Aachen, Germany. 12 Department of Medicine, Surgery and Dentistry, University of Salerno, Baronissi, Italy."
    },
    {
      "title": "busch@tum",
      "authors": [
        "Lisa Adams",
        "Keno Bressem"
      ],
      "raw": "busch@tum \n\t\t \n\t\t\t Lisa C Adams \n\t\t \n\t\t \n\t\t\t Keno K Bressem \n\t\t \n\t\t \n\t \n\t These authors contributed equally: Lisa C. Adams, Keno K. Bressem. e-mail: felix.busch@tum."
    }
  ],
  "num_references": 147,
  "figures": [
    {
      "caption": "Fig. 2 |",
      "description": "Fig. 2 | Schematic illustration of the identified disciplines, languages, and clinical concepts of large language models (LLMs) applications in patient care. A Column plot showing the distribution of medical specialties in which LLMs have been tested for patient care. B Pie chart illustrating the distribution of languages in which LLMs have been tested. C Schematic representation of the concepts identified for the application of LLMs in patient care."
    },
    {
      "description": "Underrepresented procedures (n = 1) Underserved racial groups (n = 1) Insurance status (n = 1) Language (n = 2) Local/national medical resources (n = 5) Provider/organization (n = 4) Target-group (n = 9) Conversation type (n = 3) Quantity (n = 3) Specificity (n = 13) Complexity (n = 11) Evidence (n = 7) Harmful (n = 26) Misleading (n = 34) Confabulation (n = 18) Illusion (n = 12) Hallucination (n = 38) Delusion (n = 14) Delirium (n = 34) Extrapolation (n = 10) High complexity/reading level (n = 22) Overempathic (n = 1) Overcautious (n = 7) Superfluous (n = 16) Oversimplification (n = 10) Outdated (n = 12) Non-standard of care (n = 24) Incomplete (n = 68) Generic/non-personalized (n = 34) Non-referenceable (n = 20) Non-deterministic (n = 24) Not open source (n = 10) Not freely accessible (n = 9) Limited number of prompts (n = 3) Stores/processes sensitive health information (n = 8) Limited in reference provision/evaluation/validation (n = 20) Undisclosed origin of training data (n = 36) Restricted access to internet data (n = 22) Misunderstanding of medical information/terms (n = 7) Limited in processing/producing medical images (n = 5) Limited clinical reasoning (n = 7) Implicit knowledge/lack of clinical context (n = 13) Bias (n = 6) Environment-dependent (n = 16) Prompt-/input dependent (n = 27) Unsafe (n = 39) Incorrect (n = 78) Non-comprehensive (n = 78) Non-reproducible (n = 38) Incapable of self-validation/correction (n = 4) Limited engagement/dialogue capabilities (n = 10) Black box (n = 12) Accessibility (n = 18) Data (n = 55) Not optimized for the medical domain (n = 46) Output (n = 86) Design (n = 67)"
    }
  ],
  "num_figures": 2,
  "num_citations": 1026,
  "cited_references": [
    "b43",
    "b39",
    "b20",
    "b41",
    "b51",
    "b76",
    "b83",
    "b27",
    "b33",
    "b66",
    "b49",
    "b16",
    "b57",
    "b94",
    "b30",
    "b71",
    "b45",
    "b17",
    "b53",
    "b84",
    "b95",
    "b26",
    "b86",
    "b79",
    "b78",
    "b93",
    "b62",
    "b73",
    "b46",
    "b23",
    "b52",
    "b35",
    "b68",
    "b31",
    "b58",
    "b88",
    "b64",
    "b75",
    "b56",
    "b36",
    "b96",
    "b25",
    "b54",
    "b59",
    "b32",
    "b92",
    "b67",
    "b77",
    "b55",
    "b28",
    "b97",
    "b61",
    "b80",
    "b70",
    "b91",
    "b29",
    "b18",
    "b3",
    "b5",
    "b15",
    "b37",
    "b98",
    "b22",
    "b2",
    "b72",
    "b82",
    "b89",
    "b48",
    "b38",
    "b4",
    "b24",
    "b40",
    "b19",
    "b63",
    "b42",
    "b69",
    "b1",
    "b90",
    "b87",
    "b34",
    "b47",
    "b60",
    "b85",
    "b81",
    "b65",
    "b0",
    "b21",
    "b50",
    "b44",
    "b74"
  ],
  "notes": [
    "[raw_affiliation] 1  School of Medicine and Health , Department of Diagnostic and Interventional Radiology , Klinikum rechts der Isar , TUM University Hospital , Technical University of Munich , Munich , Germany.",
    "[raw_affiliation] 2  Department of Neuroradiology , Charit\u00e9 -Universit\u00e4tsmedizin Berlin , Corporate Member of Freie Universit\u00e4t Berlin and Humboldt Universit\u00e4t zu Berlin , Berlin , Germany.",
    "[raw_affiliation] 2  Department of Neuroradiology , Charit\u00e9 -Universit\u00e4tsmedizin Berlin , Corporate Member of Freie Universit\u00e4t Berlin and Humboldt Universit\u00e4t zu Berlin , Berlin , Germany.",
    "[raw_affiliation] 3  Department of Ophthalmology , Leiden University Medical Center , Leiden , The Netherlands.",
    "[raw_affiliation] 4  Department of Ophthalmology , Sir Charles Gairdner Hospital , Perth , Australia.",
    "[raw_affiliation] 5  Division of Surgery and Interventional Sciences , University College London , London , United Kingdom.",
    "[raw_affiliation] 6  One Health Research Group ,",
    "[raw_affiliation] 1  School of Medicine and Health , Department of Diagnostic and Interventional Radiology , Klinikum rechts der Isar , TUM University Hospital , Technical University of Munich , Munich , Germany.",
    "[raw_affiliation] 1  School of Medicine and Health , Department of Diagnostic and Interventional Radiology , Klinikum rechts der Isar , TUM University Hospital , Technical University of Munich , Munich , Germany.",
    "[raw_affiliation] 1  School of Medicine and Health , Department of Diagnostic and Interventional Radiology , Klinikum rechts der Isar , TUM University Hospital , Technical University of Munich , Munich , Germany.",
    "[submission] Received: 11 March 2024; Accepted: 17 December 2024;",
    "Communications Medicine | (2025) 5:26",
    "[raw_reference] Milmo, D. ChatGPT reaches 100 million users two months after launch, https://www.theguardian.com/technology/2023/feb/02/chatgpt-100- million-users-open-ai-fastest-growing-app (February 2, 2023).",
    "[report_type] GPT-4 Technical Report",
    "[raw_reference] OpenAI. GPT-4 Technical Report. arXiv:2303.08774. https://ui. adsabs.harvard.edu/abs/2023arXiv230308774O (2023).",
    "[report_type] arXiv preprint",
    "[raw_reference] Zhao, W. X. et al. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023).",
    "[raw_reference] Clusmann, J. et al. The future landscape of large language models in medicine. Communications Medicine 3, 141 (2023).",
    "[report_type] arXiv preprint",
    "[raw_reference] Chen, Z. et al. Meditron-70b: Scaling medical pretraining for large language models. arXiv preprint arXiv:2311.16079 (2023).",
    "[report_type] arXiv preprint",
    "[raw_reference] Labrak, Y. et al. BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains. arXiv preprint arXiv:2402.10373 (2024).",
    "[report_type] arXiv preprint",
    "[raw_reference] Xiong, G., Jin, Q., Lu, Z. & Zhang, A. Benchmarking Retrieval- Augmented Generation for Medicine. arXiv preprint arXiv:2402.13178 (2024).",
    "[raw_reference] Yang, X. et al. A large language model for electronic health records. npj Digital Medicine 5, 194 (2022).",
    "[raw_reference] Tian, S. et al. Opportunities and challenges for ChatGPT and large language models in biomedicine and health. Briefings in Bioinformatics 25. https://doi.org/10.1093/bib/bbad493 (2024)",
    "[raw_reference] Adams, L. C. et al. Leveraging GPT-4 for post hoc transformation of free-text radiology reports into structured reporting: a multilingual feasibility study. Radiology 307, e230725 (2023).",
    "[report_type] arXiv preprint",
    "[raw_reference] McDuff, D. et al. Towards accurate differential diagnosis with large language models. arXiv preprint arXiv:2312.00164 (2023).",
    "[raw_reference] Jiang, L. Y. et al. Health system-scale language models are all- purpose prediction engines. Nature 619, 357-362 (2023).",
    "[raw_reference] Liu, S. et al. Leveraging Large Language Models for Generating Responses to Patient Messages. medRxiv, 2023.2007.2014.23292669. https://doi.org/10.1101/2023.07.14. 23292669 (2023)",
    "[raw_reference] Busch, F., Hoffmann, L., Adams, L. C. & Bressem, K. K. A systematic review of current large language model applications and biases in patient care, https://www.crd.york.ac.uk/prospero/display_record. php?ID=CRD42024504542 (2024).",
    "[raw_reference] Page, M. J. et al. The PRISMA 2020 statement: an updated guideline for reporting systematic reviews. Bmj 372, n71 (2021).",
    "[raw_reference] Ouzzani, M., Hammady, H., Fedorowicz, Z. & Elmagarmid, A. Rayyan -a web and mobile app for systematic reviews. Systematic Reviews 5, 210 (2016).",
    "[raw_reference] Data extraction form, https://docs.google.com/forms/d/e/ 1FAIpQLScFwE5KaOugxX_ xXtt9Y6fbBhV4s77S9cWRdVuiHh34vmArkQ/viewform (2024).",
    "[raw_reference] Hong, Q. N. et al. The Mixed Methods Appraisal Tool (MMAT) version 2018 for information professionals and researchers. Education for Information 34, 285-291 (2018).",
    "[raw_reference] Hong, Q. N., Pluye, P., Bujold, M. & Wassef, M. Convergent and sequential synthesis designs: implications for conducting and reporting systematic reviews of qualitative and quantitative evidence. Syst Rev 6, 61 (2017).",
    "[raw_reference] Thomas, J. & Harden, A. Methods for the thematic synthesis of qualitative research in systematic reviews. BMC Medical Research Methodology 8, 45 (2008).",
    "[raw_reference] Dedoose Version 9.2.4, cloud application for managing, analyzing, and presenting qualitative and mixed method research data (Los Angeles, CA, 2024). https://doi.org/10.1038/s43856-024-00717-2",
    "[raw_reference] Savage, T., Wang, J. & Shieh, L. A Large Language Model Screening Tool to Target Patients for Best Practice Alerts: Development and Validation. JMIR Med Inform 11, e49886 (2023).",
    "[raw_reference] Coskun, B. N., Yagiz, B., Ocakoglu, G., Dalkilic, E. & Pehlivan, Y. Assessing the accuracy and completeness of artificial intelligence language models in providing information on methotrexate use. Rheumatol Int. https://doi.org/10.1007/s00296-023-05473-5 (2023)",
    "[raw_reference] Bitar, H., Babour, A., Nafa, F., Alzamzami, O. & Alismail, S. Increasing Women's Knowledge about HPV Using BERT Text Summarization: An Online Randomized Study. Int J Environ Res Public Health 19. https://doi.org/10.3390/ijerph19138100 (2022)",
    "[raw_reference] Samaan, J. S. et al. Artificial Intelligence and Patient Education: Examining the Accuracy and Reproducibility of Responses to Nutrition Questions Related to Inflammatory Bowel Disease by GPT- 4. medRxiv, 2023.2010.2028.23297723. https://doi.org/10.1101/ 2023.10.28.23297723 (2023)",
    "[raw_reference] Eromosele, O. B., Sobodu, T., Olayinka, O. & Ouyang, D. Racial Disparities in Knowledge of Cardiovascular Disease by a Chat- Based Artificial Intelligence Model. medRxiv, 2023.2009.2020.23295874. https://doi.org/10.1101/2023.09.20. 23295874 (2023)",
    "[raw_reference] Johri, S. et al. Guidelines For Rigorous Evaluation of Clinical LLMs For Conversational Reasoning. medRxiv, 2023.2009.2012.23295399. https://doi.org/10.1101/2023.09.12. 23295399 (2024)",
    "[raw_reference] Braga, A. V. N. M. et al. Use of ChatGPT in Pediatric Urology and its Relevance in Clinical Practice: Is it useful? medRxiv, 2023.2009.2011.23295266. https://doi.org/10.1101/2023.09.11. 23295266 (2023)",
    "[raw_reference] King, R. C. et al. Appropriateness of ChatGPT in answering heart failure related questions. medRxiv, 2023.2007.2007.23292385. https://doi.org/10.1101/2023.07.07.23292385 (2023)",
    "[raw_reference] Huang, S. S. et al. Fact Check: Assessing the Response of ChatGPT to Alzheimer's Disease Statements with Varying Degrees of Misinformation. medRxiv, 2023.2009.2004.23294917. https://doi. org/10.1101/2023.09.04.23294917 (2023)",
    "[raw_reference] Hanna, J. J., Wakene, A. D., Lehmann, C. U. & Medford, R. J. Assessing Racial and Ethnic Bias in Text Generation for Healthcare- Related Tasks by ChatGPT1. medRxiv, 2023.2008.2028.23294730. https://doi.org/10.1101/2023.08.28.23294730 (2023)",
    "[raw_reference] Samaan, J. S. et al. ChatGPT's ability to comprehend and answer cirrhosis related questions in Arabic. Arab J Gastroenterol 24, 145-148 (2023).",
    "[raw_reference] Patnaik, S. S. & Hoffmann, U. Quantitative evaluation of ChatGPT versus Bard responses to anaesthesia-related queries. Br J Anaesth 132, 169-171 (2024).",
    "[raw_reference] Ali, H. et al. Evaluating the performance of ChatGPT in responding to questions about endoscopic procedures for patients. iGIE 2, 553-559 (2023).",
    "[raw_reference] Suresh, K. et al. Utility of GPT-4 as an Informational Patient Resource in Otolaryngology. medRxiv, 2023.2005.2014.23289944. https:// doi.org/10.1101/2023.05.14.23289944 (2023)",
    "[raw_reference] Yeo, Y. H. et al. GPT-4 outperforms ChatGPT in answering non- English questions related to cirrhosis. medRxiv, 2023.2005.2004.23289482. https://doi.org/10.1101/2023.05.04. 23289482 (2023)",
    "[raw_reference] Knebel, D. et al. Assessment of ChatGPT in the Prehospital Management of Ophthalmological Emergencies -An Analysis of 10 Fictional Case Vignettes. Klin Monbl Augenheilkd. https://doi.org/ 10.1055/a-2149-0447 (2023)",
    "[raw_reference] Zhu, L., Mou, W. & Chen, R. Can the ChatGPT and other large language models with internet-connected database solve the questions and concerns of patient with prostate cancer and help democratize medical knowledge? Journal of Translational Medicine 21, 269 (2023).",
    "[raw_reference] Lahat, A., Shachar, E., Avidan, B., Glicksberg, B. & Klang, E. Evaluating the Utility of a Large Language Model in Answering Common Patients' Gastrointestinal Health-Related Questions: Are We There Yet? Diagnostics (Basel) 13 (2023). https://doi.org/10. 3390/diagnostics13111950",
    "[raw_reference] Bernstein, I. A. et al. Comparison of ophthalmologist and large language model chatbot responses to online patient eye care questions. JAMA Network Open 6, e2330320-e2330320 (2023).",
    "[raw_reference] Rogasch, J. M. M. et al. ChatGPT: Can You Prepare My Patients for [18F]FDG PET/CT and Explain My Reports? Journal of Nuclear Medicine, jnumed.123.266114. https://doi.org/10.2967/jnumed. 123.266114 (2023)",
    "[raw_reference] Campbell, D. J. et al. Evaluating ChatGPT Responses on Thyroid Nodules for Patient Education. Thyroid\u00ae. https://doi.org/10.1089/ thy.2023.0491 (2023)",
    "[raw_reference] Currie, G., Robbie, S. & Tually, P. ChatGPT and patient information in nuclear medicine: GPT-3.5 versus GPT-4. J Nucl Med Technol 51, 307-313 (2023).",
    "[raw_reference] Draschl, A. et al. Are ChatGPT's Free-Text Responses on Periprosthetic Joint Infections of the Hip and Knee Reliable and Useful? J Clin Med 12. https://doi.org/10.3390/jcm12206655 (2023)",
    "[raw_reference] Alessandri-Bonetti, M., Liu, H. Y., Palmesano, M., Nguyen, V. T. & Egro, F. M. Online patient education in body contouring: a comparison between Google and ChatGPT. Journal of Plastic, Reconstructive & Aesthetic Surgery 87, 390-402 (2023).",
    "[raw_reference] Coskun, B., Ocakoglu, G., Yetemen, M. & Kaygisiz, O. Can ChatGPT, an artificial intelligence language model, provide accurate and high- quality patient information on prostate cancer? Urology 180, 35-58 (2023).",
    "[raw_reference] Durairaj, K. K. et al. Artificial Intelligence Versus Expert Plastic Surgeon: Comparative Study Shows ChatGPT \"Wins\" Rhinoplasty Consultations: Should We Be Worried? Facial Plastic Surgery & Aesthetic Medicine. https://doi.org/10.1089/fpsam.2023.0224 (2023)",
    "[raw_reference] Kianian, R., Sun, D., Crowell, E. L. & Tsui, E. The Use of Large Language Models to Generate Education Materials about Uveitis. Ophthalmol Retina https://doi.org/10.1016/j.oret.2023.09.008 (2023).",
    "[raw_reference] Seth, I. et al. Exploring the Role of a Large Language Model on Carpal Tunnel Syndrome Management: An Observation Study of ChatGPT. J Hand Surg Am 48, 1025-1033 (2023).",
    "[raw_reference] Inojosa, H. et al. Can ChatGPT explain it? Use of artificial intelligence in multiple sclerosis communication. Neurological Research and Practice 5, 48 (2023).",
    "[raw_reference] Lyons, R. J., Arepalli, S. R., Fromal, O., Choi, J. D. & Jain, N. Artificial intelligence chatbot performance in triage of ophthalmic conditions. Can J Ophthalmol. https://doi.org/10.1016/j.jcjo.2023.07.016 (2023)",
    "[raw_reference] Babayi\u011fit, O., Tastan Eroglu, Z., Ozkan Sen, D. & Ucan Yarkac, F. Potential use of ChatGPT for patient information in periodontology: a descriptive pilot study. Cureus 15, e48518 (2023).",
    "[raw_reference] Mondal, H., Dash, I., Mondal, S. & Behera, J. K. ChatGPT in answering queries related to lifestyle-related diseases and disorders. Cureus 15, e48296 (2023).",
    "[raw_reference] Kim, H. W., Shin, D. H., Kim, J., Lee, G. H. & Cho, J. W. Assessing the performance of ChatGPT's responses to questions related to epilepsy: a cross-sectional study on natural language processing and medical information retrieval. Seizure 114, 1-8 (2023).",
    "[raw_reference] Song, H. et al. Evaluating the performance of different large language models on health consultation and patient education in urolithiasis. J Med Syst 47, 125 (2023).",
    "[raw_reference] Zalzal, H. G., Abraham, A., Cheng, J. H. & Shah, R. K. Can ChatGPT help patients answer their otolaryngology questions? Laryngoscope Investigative Otolaryngology. https://doi.org/10.1002/lio2.1193 (2023)",
    "[raw_reference] Chervenak, J., Lieman, H., Blanco-Breindel, M. & Jindal, S. The promise and peril of using a large language model to obtain clinical https://doi.org/10.1038/s43856-024-00717-2 information: ChatGPT performs strongly as a fertility counseling tool with limitations. Fertility and Sterility 120, 575-583 (2023).",
    "[raw_reference] Bushuven, S. et al. ChatGPT, can you help me save my child's life?\" - diagnostic accuracy and supportive capabilities to lay rescuers by ChatGPT in prehospital basic life support and paediatric advanced life support cases -an in-silico analysis. J Med Syst 47, 123 (2023).",
    "[raw_reference] Jeblick, K. et al. ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports. European Radiology. https://doi.org/10.1007/s00330-023-10213-1 (2023)",
    "[raw_reference] Samaan, J. S. et al. Assessing the accuracy of responses by the language model ChatGPT to questions regarding bariatric surgery. Obes Surg 33, 1790-1796 (2023).",
    "[raw_reference] Zhou, J. M., Li, T. Y., Fong, S. J., Dey, N. & Crespo, R. G. Exploring ChatGPT's potential for consultation, recommendations and report diagnosis: gastric cancer and gastroscopy reports' case. International Journal of Interactive Multimedia and Artificial Intelligence 8, 7-13 (2023).",
    "[raw_reference] Oniani, D. et al. Toward improving health literacy in patient education materials with neural machine translation models. AMIA Jt Summits Transl Sci Proc 2023, 418-426 (2023).",
    "[raw_reference] Hernandez, C. A. et al. The future of patient education: ai-driven guide for type 2 diabetes. Cureus 15, e48919 (2023).",
    "[raw_reference] Ku\u015fcu, O., Pamuk, A. E., S\u00fctay S\u00fcsl\u00fc, N. & Hosal, S. Is ChatGPT accurate and reliable in answering questions regarding head and neck cancer? Front Oncol 13, 1256459 (2023).",
    "[raw_reference] Biswas, S., Logan, N. S., Davies, L. N., Sheppard, A. L. & Wolffsohn, J. S. Assessing the utility of ChatGPT as an artificial intelligence- based large language model for information to answer questions on myopia. Ophthalmic Physiol Opt 43, 1562-1570 (2023).",
    "[raw_reference] Chiesa-Estomba, C. M. et al. Exploring the potential of Chat-GPT as a supportive tool for sialendoscopy clinical decision making and patient information support. Eur Arch Otorhinolaryngol. https://doi. org/10.1007/s00405-023-08104-8 (2023)",
    "[raw_reference] Decker, H. et al. Large language model-based chatbot vs surgeon- generated informed consent documentation for common procedures. JAMA Netw Open 6, e2336997 (2023).",
    "[raw_reference] Kaarre, J. et al. Exploring the potential of ChatGPT as a supplementary tool for providing orthopaedic information. Knee Surg Sports Traumatol Arthrosc 31, 5190-5198 (2023).",
    "[raw_reference] Ferreira, A. L., Chu, B., Grant-Kels, J. M., Ogunleye, T. & Lipoff, J. B. Evaluation of ChatGPT dermatology responses to common patient queries. JMIR Dermatol 6, e49280 (2023).",
    "[raw_reference] Truhn, D. et al. A pilot study on the efficacy of GPT-4 in providing orthopedic treatment recommendations from MRI reports. Sci Rep 13, 20159 (2023).",
    "[raw_reference] Hurley, E. T. et al. Evaluation High-Quality of Information from ChatGPT (Artificial Intelligence-Large Language Model) Artificial Intelligence on Shoulder Stabilization Surgery. Arthroscopy. https:// doi.org/10.1016/j.arthro.2023.07.048 (2023)",
    "[raw_reference] Cankurtaran, R. E., Polat, Y. H., Aydemir, N. G., Umay, E. & Yurekli, O. T. Reliability and usefulness of ChatGPT for inflammatory bowel diseases: an analysis for patients and healthcare professionals. Cureus 15, e46736 (2023).",
    "[raw_reference] Birkun, A. A. & Gautam, A. Large language model (LLM)-powered chatbots fail to generate guideline-consistent content on resuscitation and may provide potentially harmful advice. Prehosp Disaster Med 38, 757-763 (2023).",
    "[raw_reference] Pushpanathan, K. et al. Popular large language model chatbots' accuracy, comprehensiveness, and self-awareness in answering ocular symptom queries. iScience 26, 108163 (2023).",
    "[raw_reference] Shao, C. Y. et al. Appropriateness and comprehensiveness of using ChatGPT for perioperative patient education in thoracic surgery in different language contexts: survey study. Interact J Med Res 12, e46900 (2023).",
    "[raw_reference] Vaira, L. A. et al. Accuracy of ChatGPT-Generated Information on Head and Neck and Oromaxillofacial Surgery: A Multicenter Collaborative Analysis. Otolaryngol Head Neck Surg. https://doi.org/ 10.1002/ohn.489 (2023)",
    "[raw_reference] Chen, S. et al. Use of artificial intelligence Chatbots for cancer treatment information. JAMA Oncol 9, 1459-1462 (2023).",
    "[raw_reference] Bellinger, J. R. et al. BPPV Information on Google Versus AI (ChatGPT). Otolaryngol Head Neck Surg. https://doi.org/10.1002/ ohn.506 (2023)",
    "[raw_reference] Nielsen, J. P. S., von Buchwald, C. & Gr\u00f8nh\u00f8j, C. Validity of the large language model ChatGPT (GPT4) as a patient information source in otolaryngology by a variety of doctors in a tertiary otorhinolaryngology department. Acta Otolaryngol 143, 779-782 (2023).",
    "[raw_reference] Sezgin, E., Chekeni, F., Lee, J. & Keim, S. Clinical accuracy of large language models and google search responses to postpartum depression questions: cross-sectional study. J Med Internet Res 25, e49240 (2023).",
    "[raw_reference] Floyd, W. et al. Current Strengths and Weaknesses of ChatGPT as a Resource for Radiation Oncology Patients and Providers. International Journal of Radiation Oncology, Biology, Physics. https://doi.org/10.1016/j.ijrobp.2023.10.020 (2023)",
    "[raw_reference] Uz, C. & Umay, E. \"Dr ChatGPT\": is it a reliable and useful source for common rheumatic diseases? Int J Rheum Dis 26, 1343-1349 (2023).",
    "[raw_reference] Athavale, A., Baier, J., Ross, E. & Fukaya, E. The potential of chatbots in chronic venous disease patient management. JVS Vasc Insights 1. https://doi.org/10.1016/j.jvsvi.2023.100019 (2023)",
    "[raw_reference] Li, Y. et al. ChatDoctor: a medical chat model fine-tuned on a large language model meta-AI (LLaMA) using medical domain knowledge. Cureus 15, e40895 (2023).",
    "[raw_reference] Seth, I. et al. Comparing the efficacy of large language models ChatGPT, BARD, and Bing AI in providing information on rhinoplasty: an observational study. Aesthet Surg J Open Forum 5, ojad084 (2023).",
    "[raw_reference] Lockie, E. & Choi, J. Evaluation of a chat GPT generated patient information leaflet about laparoscopic cholecystectomy. ANZ J Surg. https://doi.org/10.1111/ans.18834 (2023)",
    "[raw_reference] Haver, H. L., Lin, C. T., Sirajuddin, A., Yi, P. H. & Jeudy, J. Use of ChatGPT, GPT-4, and Bard to improve readability of ChatGPT's answers to common questions about lung cancer and lung cancer screening. AJR Am J Roentgenol 221, 701-704 (2023).",
    "[raw_reference] Li, H. et al. Decoding radiology reports: potential application of OpenAI ChatGPT to enhance patient understanding of diagnostic reports. Clin Imaging 101, 137-141 (2023).",
    "[raw_reference] Scheschenja, M. et al. Feasibility of GPT-3 and GPT-4 for in-depth patient education prior to interventional radiological procedures: a comparative analysis. CardioVascular and Interventional Radiology 47, 245-250 (2024).",
    "[raw_reference] Gordon, E. B. et al. Enhancing patient communication With Chat- GPT in radiology: evaluating the efficacy and readability of answers to common imaging-related questions. J Am Coll Radiol 21, 353-359 (2024).",
    "[raw_reference] Stroop, A. et al. Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery? Eur Spine J. https://doi.org/10.1007/s00586-023-07975-z (2023)",
    "[raw_reference] Coraci, D. et al. ChatGPT in the development of medical questionnaires. The example of the low back pain. Eur J Transl Myol 33. https://doi.org/10.4081/ejtm.2023.12114 (2023)",
    "[raw_reference] Ye, C., Zweck, E., Ma, Z., Smith, J. & Katz, S. Doctor Versus Artificial Intelligence: Patient and Physician Evaluation of Large Language Model Responses to Rheumatology Patient Questions in a Cross-Sectional Study. Arthritis & Rheumatology n/a https://doi.org/10.1002/art.42737",
    "[raw_reference] Mohammad-Rahimi, H. et al. Validity and reliability of artificial intelligence chatbots as public sources of information on endodontics. Int Endod J 57, 305-314 (2024). https://doi.org/10.1038/s43856-024-00717-2",
    "[raw_reference] Hermann, C. E. et al. Let's chat about cervical cancer: Assessing the accuracy of ChatGPT responses to cervical cancer questions. Gynecologic Oncology 179, 164-168 (2023).",
    "[raw_reference] Kerbage, A. et al. Accuracy of ChatGPT in Common Gastrointestinal Diseases: Impact for Patients and Providers. Clin Gastroenterol Hepatol. https://doi.org/10.1016/j.cgh.2023.11.008 (2023)",
    "[raw_reference] Shiraishi, M. et al. Generating Informed Consent Documents Related to Blepharoplasty Using ChatGPT. Ophthalmic Plast Reconstr Surg. https://doi.org/10.1097/iop.0000000000002574 (2023)",
    "[raw_reference] Barclay, K. S. et al. Quality and Agreement With Scientific Consensus of ChatGPT Information Regarding Corneal Transplantation and Fuchs Dystrophy. Cornea. https://doi.org/10. 1097/ico.0000000000003439 (2023)",
    "AI-powered renal diet support: performance of ChatGPT, Bard AI, and Bing Chat",
    "[raw_reference] Qarajeh, A. et al. AI-powered renal diet support: performance of ChatGPT, Bard AI, and Bing Chat. Clin Pract 13, 1160-1172 (2023). 100. Chowdhury, M. et al. Can Large Language Models Safely Address Patient Questions Following Cataract Surgery?, (2023). 101.",
    "[raw_reference] Singer, M. B., Fu, J. J., Chow, J. & Teng, C. C. Development and evaluation of aeyeconsult: a novel ophthalmology chatbot leveraging verified textbook knowledge and GPT-4. J Surg Educ 81, 438-443 (2024). 102",
    "[raw_reference] Xie, Y. et al. Aesthetic surgery advice and counseling from artificial intelligence: a rhinoplasty consultation with ChatGPT. Aesthetic Plast Surg 47, 1985-1993 (2023). 103",
    "[raw_reference] Nastasi, A. J., Courtright, K. R., Halpern, S. D. & Weissman, G. E. A vignette-based evaluation of ChatGPT's ability to provide appropriate and equitable medical advice across care contexts. Sci Rep 13, 17885 (2023). 104",
    "[raw_reference] Biswas, M., Islam, A., Shah, Z., Zaghouani, W. & Brahim Belhaouari, S. Can ChatGPT be Your Personal Medical Assistant?, (2023). 105.",
    "[raw_reference] Panagoulias, D., Palamidas, F., Virvou, M. & Tsihrintzis, G. Evaluating the Potential of LLMs and ChatGPT on Medical Diagnosis and Treatment. (2023). 106.",
    "[raw_reference] Chandra, A., Davis, M. J., Hamann, D. & Hamann, C. R. Utility of allergen-specific patient-directed handouts generated by chat generative pretrained transformer. Dermatitis 34, 448 (2023). 107",
    "ChatGPT and Rhinoplasty Recovery: An Exploration of AI's Role in Postoperative Guidance Facial Plast Surg",
    "Assessing AI-powered patient education: a case study in radiology Acad Radiol",
    "[raw_reference] Scquizzato, T. et al. Testing ChatGPT ability to answer laypeople questions about cardiac arrest and cardiopulmonary resuscitation. Resuscitation 194, 110077 (2024). 110. Kuckelman, I. J. et al. Assessing AI-powered patient education: a case study in radiology. Acad Radiol 31, 338-342 (2024). 111",
    "[raw_reference] Sulejmani, P. et al. A large language model artificial intelligence for patient queries in atopic dermatitis. J Eur Acad Dermatol Venereol. https://doi.org/10.1111/jdv.19737 (2024) 112.",
    "[raw_reference] Currie, G. & Barry, K. ChatGPT in nuclear medicine education. Journal of Nuclear Medicine Technology 51, 247-254 (2023). 113",
    "[raw_reference] Currie, G. M. Academic integrity and artificial intelligence: is ChatGPT hype, hero or heresy? Seminars in Nuclear Medicine 53, 719-730 (2023). 114",
    "[raw_reference] Li, J., Dada, A., Puladi, B., Kleesiek, J. & Egger, J. ChatGPT in healthcare: a taxonomy and systematic review. Computer Methods and Programs in Biomedicine 245, 108013 (2024). 115",
    "[report_type] arXiv preprint",
    "[raw_reference] Liu, F. W. & Hu, C. Exploring Vulnerabilities and Protections in Large Language Models: A Survey. arXiv preprint arXiv:2406.00240 (2024). 116. Jin, M. et al. Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model. arXiv preprint arXiv:2402.00746 (2024). 117",
    "[report_type] arXiv preprint",
    "[raw_reference] Nori, H., King, N., McKinney, S. M., Carignan, D. & Horvitz, E. Capabilities of gpt-4 on medical challenge problems. arXiv preprint arXiv:2303.13375 (2023). 118",
    "[raw_reference] Brin, D. et al. Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments. Scientific Reports 13, 16492 (2023). 119",
    "[raw_reference] Jung, L. B. et al. ChatGPT passes German State examination in medicine with picture questions omitted. Dtsch Arztebl Int 120, 373-374 (2023). 120",
    "[raw_reference] Bhayana, R., Krishna, S. & Bleakney, R. R. Performance of ChatGPT on a radiology board-style examination: insights into current strengths and limitations. Radiology 307, e230582 (2023). 121",
    "[report_type] arXiv preprint",
    "[raw_reference] Singhal, K. et al. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617 (2023). 122",
    "[report_type] arXiv preprint",
    "[raw_reference] Dorfner, F. J. et al. Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data. arXiv preprint arXiv:2408.13833 (2024). 123",
    "[raw_reference] Kung, T. H. et al. Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models. PLOS Digital Health 2, e0000198 (2023). 124.",
    "[report_type] arXiv preprint",
    "[raw_reference] Kapoor, S., Henderson, P. & Narayanan, A. Promises and pitfalls of artificial intelligence for legal applications. arXiv preprint arXiv:2402.01656 (2024). 125",
    "[report_type] arXiv preprint",
    "[raw_reference] Ouyang, S., Zhang, J. M., Harman, M. & Wang, M. LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation. arXiv preprint arXiv:2308.02828 (2023). 126",
    "[report_type] arXiv preprint",
    "[raw_reference] Atil, B. et al. LLM Stability: A detailed analysis with some surprises. arXiv preprint arXiv:2408.04667 (2024). 127",
    "How to Write Easy to Read Health Materials",
    "[raw_reference] Weis, B. Health Literacy: A Manual for Clinicians. Chicago, IL: American Medical Association, American Medical Foundation; 2003. National Institutes of Health. How to Write Easy to Read Health Materials: National Library of Medicine Website. How to Write Easy to Read Health Materials: National Library of Medicine Website 128.",
    "[raw_reference] Amann, J. et al. Explainability for artificial intelligence in healthcare: a multidisciplinary perspective. BMC Medical Informatics and Decision Making 20, 310 (2020). 129",
    "[raw_reference] Gerke, S., Minssen, T. & Cohen, G. Ethical and legal challenges of artificial intelligence-driven healthcare. Artificial Intelligence in Healthcare, 295-336. https://doi.org/10.1016/b978-0-12-818438- 7.00012-5 (2020) 130.",
    "[raw_reference] Tobias, J. S. & Souhami, R. L. Fully informed consent can be needlessly cruel. Bmj 307, 1199-1201 (1993). 131",
    "[raw_reference] Pietrzykowski, T. & Smilowska, K. The reality of informed consent: empirical studies on patient comprehension-systematic review. Trials 22, 57 (2021). 132",
    "[raw_reference] Kesselheim, A. S., Connolly, J., Rogers, J. & Avorn, J. Mandatory disclaimers on dietary supplements do not reliably communicate the intended issues. Health Affairs 34, 438-446 (2015). 133",
    "[raw_reference] Topol, E. J. High-performance medicine: the convergence of human and artificial intelligence. Nature Medicine 25, 44-56 (2019). 134",
    "[report_type] arXiv preprint",
    "[raw_reference] Raj, H., Gupta, V., Rosati, D. & Majumdar, S. Semantic consistency for assuring reliability of large language models. arXiv preprint arXiv:2308.09138 (2023). 135",
    "[raw_reference] Zhou, Y. et al. Large Language Models Are Human-Level Prompt Engineers. ArXiv abs/2211.01910 (2022). 136",
    "[raw_reference] Zhang, Z. et al. Certified Robustness for Large Language Models with Self-Denoising. ArXiv abs/2307.07171 (2023). 137",
    "[raw_reference] Ullah, E., Parwani, A., Baig, M. M. & Singh, R. Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology -a recent scoping review. Diagn Pathol 19, 43 (2024). https://doi.org/10.1038/s43856-024-00717-2 138.",
    "[raw_reference] Navigli, R., Conia, S. & Ross, B. Biases in large language models: origins, inventory, and discussion. ACM Journal of Data and Information Quality 15, 1-21 (2023). 139",
    "[report_type] arXiv preprint",
    "[raw_reference] Deng, G. et al. Jailbreaker: Automated jailbreak across multiple large language model chatbots. arXiv preprint arXiv:2307.08715 (2023). 140",
    "[raw_reference] Acerbi, A. & Stubbersfield, J. M. Large language models show human- like content biases in transmission chain experiments. Proceedings of the National Academy of Sciences 120, e2313790120 (2023). 141",
    "[raw_reference] Yang, Y., Liu, Y. & Naghizadeh, P. Adaptive data debiasing through bounded exploration. Advances in Neural Information Processing Systems 35, 1516-1528 (2022). 142",
    "[raw_reference] Gallegos, I. O. et al. Bias and Fairness in Large Language Models: A Survey. Computational Linguistics, 1-83. https://doi.org/10.1162/ coli_a_00524 (2024) 143.",
    "[report_type] arXiv preprint",
    "[raw_reference] Grari, V., Laugel, T., Hashimoto, T., Lamprier, S. & Detyniecki, M. On the Fairness ROAD: Robust Optimization for Adversarial Debiasing. arXiv preprint arXiv:2310.18413 (2023). 144",
    "[raw_reference] Hofmann, V., Kalluri, P. R., Jurafsky, D. & King, S. AI generates covertly racist decisions about people based on their dialect. Nature 633, 147-154 (2024). 145",
    "[raw_reference] Ayoub, N. F., Lee, Y. J., Grimm, D. & Divi, V. Head-to-Head Comparison of ChatGPT Versus Google Search for Medical Knowledge Acquisition. Otolaryngol Head Neck Surg. https://doi. org/10.1002/ohn.465 (2023) 146.",
    "[raw_reference] Yao, Y. et al. A survey on large language model (LLM) security and privacy: the good, the bad, and the ugly. High-Confidence Computing 4, 100211 (2024). 147",
    "Ambient artificial intelligence scribes to alleviate the burden of clinical documentation NEJM Catalyst",
    "[raw_reference] Tierney, A. A. et al. Ambient artificial intelligence scribes to alleviate the burden of clinical documentation. NEJM Catalyst 5, CAT.23.0404 (2024). 148. Formosa, P., Rogers, W., Griep, Y., Bankins, S. & Richards, D. Medical AI and human dignity: contrasting perceptions of human and artificially intelligent (AI) decision making in diagnostic and medical resource allocation contexts. Computers in Human Behavior 133, 107296 (2022). 149",
    ". Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts -Analysis of the final compromise text with a view to agreement, (2024). 151",
    "[raw_reference] Moy, S. et al. Patient perspectives on the use of artificial intelligence in health care: a scoping review. J Patient Cent Res Rev 11, 51-62 (2024). 150. Union, C. O. T. E. Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts -Analysis of the final compromise text with a view to agreement, (2024). 151.",
    "[raw_reference] Busch, F. et al. Navigating the european union artificial intelligence act for healthcare. npj Digital Medicine 7, 210 (2024).",
    "[raw_reference] Else Kroener Fresenius Center for Digital Health, Medical Faculty Carl Gustav Carus, Technical University Dresden, Dresden, Germany. 11 Department of Diagnostic and Interventional Radiology, University Hospital Aachen, Aachen, Germany. 12 Department of Medicine, Surgery and Dentistry, University of Salerno, Baronissi, Italy.",
    "[raw_reference] These authors contributed equally: Lisa C. Adams, Keno K. Bressem. e-mail: felix.busch@tum."
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  },
  "journal": "Communications Medicine",
  "volume": "5",
  "issue": "1",
  "pages": "26",
  "zotero_recovery": {
    "fields_recovered": [
      "journal"
    ],
    "timestamp": "2025-09-01T11:08:21.394116",
    "zotero_item_type": "journalArticle"
  }
}
