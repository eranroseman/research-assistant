{
  "paper_id": "2D9BK2HL",
  "title": "Recommendation system for human physical activities using smartphones",
  "abstract": "Important information can be obtained from smartphone users data such as profile modeling, behavior recognition, geolocalization, etc. Human activity recognition (HAR) from sensor smartphone data is a field which has garnered a lot of attention due to its high application in various domains such as the user health. In this paper, we will consider data from accelerometer to recognize the kind of user movements that we will classify to six kinds using machine and deep learning algorithms. Then, based on these results, we will make a recommendation system to inform the users of smartphone about their healthy behavior related to their physical activities.",
  "year": 2016,
  "date": "2016",
  "authors": [
    {
      "name": "Nesrine Kadri",
      "email": "kadrinesrine2@gmail.com",
      "affiliation": {
        "organization": "ISIT'COM",
        "department": "ISIT'COM",
        "institution": "ENIS"
      }
    },
    {
      "name": "Ameni Ellouze",
      "email": "ameni_ellouze@yahoo.fr",
      "affiliation": {
        "organization": "ISIT'COM",
        "department": "ISIT'COM",
        "institution": "ENIS"
      }
    },
    {
      "name": "Mohamed Ksantini",
      "email": "mohamedksantini@yahoo.fr",
      "affiliation": {
        "organization": "ISIT'COM",
        "department": "ISIT'COM",
        "institution": "ENIS"
      }
    }
  ],
  "doi": "10.3390/s16040426",
  "md5": "133CF3C0B450FD3454F9A9BE20E5585C",
  "publication": {
    "journal": "Sensors",
    "journal_inferred": true
  },
  "keywords": [
    "physical movements recognition",
    "machine learning",
    "deep learning",
    "healthy recommendation system",
    "smartphone sensors"
  ],
  "sections": [
    {
      "title": "I. INTRODUCTION",
      "text": "Beyond their use in calls, messages, mailing and connectivity, smartphones can give us many data that we can extract knowledge used in many aspects of our life.\n\nMobile devices especially smartphones contain big data such as the geolocalization, movement, etc. This work deals with the recognition of physical activities which is obtained from the classification of person's movements. Considered movements are often physical activities such as jogging, walking, upstairs, downstairs, standing and sitting. We will collect movement data from the accelerometer smartphone sensor. This data will be trained in first time and features will be extracted from it in the second time. These transformed data were segmented and a recognition model was created to identify the user's activities. Many methods have been developed that can identify these activities such as machine learning algorithms or deep learning algorithms. In the case of machine learning, we can talk about the most used methods with this kind of data, like Support Vector Machine (SVM)  [1] , Decision Tree algorithm  [2]  and K-Nearest Neighbors (KNN)  [3] . In the case of deep learning, we can talk about convolutional neural networks  [4]  and recurrent neural networks  [5] .\n\nIn this work, we will use decision tree algorithm and bidirectional long short-term memory (BiLSTM) algorithm to train and classify the physical activities.\n\nWe will compare results from machine learning and deep learning algorithms. We will compute the total time of physical activities consuming calories (jogging, walking, upstairs and downstairs) to decide about the healthy behavior of a person taking on his gender and age, based on their daily physical activities.\n\nThis system can be implemented as an application on smartphone to inform users that don't move enough on a day. This paper will be structured as follows: Section 2 will present machine learning and deep learning applied to mobile sensors data. Section 3 describes our method used to predict physical activities. Section 4 presents experimental results and discussion. In conclusion, we will propose some perspectives to extend this work."
    },
    {
      "title": "II. MACHINE AND DEEP LEARNING",
      "text": "Machine and Deep learning are two disciplines of Artificial Intelligence used to classify and predict phenomena in large scale of fields. The performance of algorithms used in machine and deep learning depends on the nature and the origin of data.\n\nIn our case, we will use data from accelerometer sensors that gives signals divided into three variables X, Y and Z positions taken of different periods of time.\n\nThe machine and deep learning algorithms will be applied to determine the best accuracy based on our date."
    },
    {
      "title": "A. Machine learning",
      "text": "Many methods can be used in machine learning like SVM and KNN. Hence, A. Jain et al. proposed in  [6]  these two classifiers for human activity classification using accelerometer and gyroscope sensor signals of Smartphone. Moreover, by using Radial Basis Function kernel (RBF) with SVM, W. Wang et al. proposed in  [7]  a classifier that uses confusion matrix to give information about the actual and predicted classifications of nine activities. This algorithm gave different recognition accuracies. For example, biking and gym-bike activities give higher accuracy (82% and 80% respectively), but Walking presents the lowest accuracy (51%). For better performance methods of activity recognition than previous ones, R. Yang and B. Wang proposed in  [1]  a new position-independent method called PACP (Parameters Adjustment Corresponding to smartphone Position). In this method, many performances were extracted from sensors data to recognize the position of the smartphone and the activities by the trained SVM model. Another model proposed by A. Harasimowic et al. in  [3]  named the KNN algorithm which used for to classify eight user activities such as running, walking, going upstairs, going downstairs, standing, lying, turning and sitting.\n\nDecision tree algorithms could be also used to recognize human physical activities. In this case, Shoaib et al. proposed in  [2]  the use of multiple motion smartphone sensors to recognize complex human activity."
    },
    {
      "title": "B. Deep learning",
      "text": "Convolutional Neural Network (CNN) and Recurrent Neural Network models are used for time series classification. In fact, they perform well on human activity recognition using sensor Smartphone data. An important work using CNNs was proposed by Zeng et al. in  [4]  where the authors develop a simple CNN model for accelerometer data which is fed to convolutional layers, pooling layers and fully connected layers. Cho et al.  [8]  have proposed another interesting example, where a CNN model has been developed to distinguish between dynamic activities such as \"walking\" and static activities as such \"sitting\". The human activity recognition was then done by using two 3-class classifiers instead of using a single 6-class classifier. Another interesting approach was proposed by W. Jiang et al. in  [9] , where they combined the signal data from different sensors, together, and used CNN algorithm with two dimensions instead of one.\n\nLSTMs can also be applied to the problem of human activity recognition. Murad and Pyun in  [10]  explored the use of LSTMs and Bidirectional LSTMs for predicting the activities for each input time step of a subsequence of sensor data. LSTM can be used with CNN on human activity recognition as in  [5]  where the authors proposed a deep network with four convolutional layers followed by two LSTM layers."
    },
    {
      "title": "III. OUR APPROCH",
      "text": "Our approach is based on a three-step method (Fig.  1 ): the data processing, the prediction of physical activities using machine and deep learning algorithms and the computation of the calories of dynamic activities to decide about the physical behavior."
    },
    {
      "title": "Fig.1. Steps of our approach"
    },
    {
      "title": "A. Data processing",
      "text": "The data used for our approach is provided from the Wireless Sensor Data Mining (WISDM)  [11]  by collecting the sensor data from smart phones. The user's movements are measured by the smartphone tri-axial accelerometer, which it consists of 1,098,207 examples of various physical activities (sampled at 20Hz, 1 sample every 50 ms) obtained from 36 users with six attributes: user, activity, timestamp, xacceleration y-acceleration, z-acceleration and the activities included walking, jogging, downstairs, upstairs, sitting and standing.\n\nWe have added two attributes: age and gender for every physical activity with random distribution.\n\nFor the data processing, we have splitted the dataset based on the user identifiers (Ids). We kept users with Id from 1 to 28 for training the model and users with Id greater than 28 for the test set."
    },
    {
      "title": "B. Machine and Deep learning algorithms",
      "text": "For the machine learning algorithm, we have used the decision tree classifier and we have used the BiLSTM with 10 epochs and 400 samples as a deep learning model with a bidirectional layer followed by a dropout layer to read, extract its own features before a final mapping to an activity was made. The efficient Adam version of stochastic gradient descent will be used to optimize the deep neural network. The categorical cross entropy loss function will be also used."
    },
    {
      "title": "C. Decision of healthy behavior",
      "text": "For the decision of predicted physical activities of person per day, we have classified users by age and gender into four categories: Men with age is between 20 and 40 years, Men with age is between 41 and 60 years, Women with age is between 20 and 40 years and Women with age between is 41-60 years.\n\nAccording to the World Health Organization (WHO), we had classified also the activities into 3 categories: intense, moderate and inactive. For that, we have considered jogging and upstairs as intense, walking and downstairs as moderate and others activities as inactive (sitting and standing).\n\nWe compared the number of calories for each activity per day with references from the WHO. Therefore the concerned person will be informed by message on its healthiness behavior."
    },
    {
      "title": "IV. EXPERIMENTS RESULTS AND DISCUSSION",
      "text": "In our experiments, we have used Python (version 3. \uf0b7 False Negatives (FN): The number of positive instances that were classified as negative.\n\nThe metrics of the confusion matrix were:\n\nPrecision, often referred to as positive predictive value, is the ratio of correctly classified positive instances to the total number of instances classified as positive:\n\n(1) Recall, also called sensitivity or true positive rate, is the ratio of correctly classified positive instances to the total number of positive instances:\n\n(2) F1 combines precision and recall as single value:\n\n(3) At the beginning, let's know where the decision tree and the BiLSTM algorithms wrongly predicted the labels using a confusion matrix. In fact, as shown in (Fig.  2  and Fig.  3 ), the precision of these two algorithms is good for predicting jogging, sitting, standing, and walking but some problems have been appeared for clearly identifying upstairs and downstairs activities. As shown in Table  1 , the decision tree algorithm can predict jogging with 80%, standing with 83% and walking with 67%. The results are better than the Bidirectional LSTM which had 74% for jogging, 52% for standing and 57% for walking. As our deep learning model can't predict upstairs and has 0% for this activity, we have decided to continue our work with the machine learning algorithm: Decision Tree."
    },
    {
      "title": "Fig.2. Confusion matrix by Decision Tree",
      "text": "We have used these predicted labels to verify the distribution of daily physical activities (Table  2 ) and construct a recommandation system for being informed on healthy daily physical activities of persons classified by age and gender (Table  3 ).\n\nTable 2. Distribution of daily physical activities per gender and age\n\nAs shown in (Table  2 ) and in the case of dynamic activities, walking dominate all the other activities. Indeed, it presents the percentage of 39.82% for young men that their age is between 20 and 40 years and the percentage of 33.50% for women for the same age. Although, these young men have the lower distribution in jogging and adult women that their age is between 41 and 60 years have the lower distribution in walking. In the case of the downstairs and upstairs, adult women which their age is between 41 and 60 years have the lowest distribution with 5.65% and 10.20%. This distribution helps us to compute the number of calories for each physical activity per day and understand the healthy daily activities of persons (Table  3 )."
    },
    {
      "title": "Table3. Recommendation system per gender and age",
      "text": "As shown in (Table3.), all the participants are not healthy persons and they should practice sports more times. This result is justified by the energy produced by these persons was not enough in comparison with WHO references' values per day."
    },
    {
      "title": "V. CONCLUSION AND PERSPECTIVES",
      "text": "In this work, we have used smartphone accelerometer data to make a healthy recommendation system. This system gives the state of the daily physical activities for users of mobiles where are healthy or not based on references from WHO.\n\nWe have classified data into six categories including four active physical activities consuming calories and 2 passives. The machine learning classification had given us better results than deep learning algorithms. This is can be justified by the problem of the unbalanced classes during the step of the training.\n\nAs perspectives, we can apply the recommendation system per week. Also, we can use another sensor smartphone data which is Global Positioning System (GPS) to know the kilometers number of dynamic activities as walking and jogging to improve the results."
    },
    {
      "text": "6.5) with Anaconda distribution on Ubuntu 16.04.6 LTS (Xenial Xerus), Keras (version 2.1.6) and Tensorflow (version 1.7.0) as backend of keras. The following values can be obtained from the confusion matrix in a classification problem: \uf0b7 True Positives (TP): The number of positive instances that were classified as positive. \uf0b7 True Negatives (TN): The number of negative instances that were classified as negative. \uf0b7 False Positives (FP): The number of negative instances that were classified as positive."
    },
    {
      "text": "Fig.3. Confusion matrix by Bidirectional LSTM However, the two models presents different values of the predicted precision activities (Table.1)"
    },
    {
      "text": "1) Precision of activities between machine and deep learning algorithms"
    }
  ],
  "references": [
    {
      "title": "PACP: A Position-Independent Activity Recognition Method Using Smartphone Sensors",
      "authors": [
        "R Yang",
        "B Wang"
      ],
      "year": 2016,
      "raw": "PACP: A Position-Independent Activity Recognition Method Using Smartphone Sensors \n\t\t \n\t\t\t R Yang \n\t\t \n\t\t \n\t\t\t B Wang \n\t\t \n\t\t \n\t\t\t 210044. 2016 \n\t\t\t Nanjing; Jiangsu, China \n\t\t \n\t\t \n\t\t\t School of Computer and Software, Nanjing University of Information Science & Technology \n\t\t \n\t \n\t R. Yang and B. Wang, \"PACP: A Position-Independent Activity Recognition Method Using Smartphone Sensors\", School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing 210044, Jiangsu, China, 2016."
    },
    {
      "title": "Complex Human Activity Recognition Using Smartphone and Wrist-Worn Motion Sensors",
      "authors": [
        "M Shoaib",
        "S Bosch",
        "O Incel",
        "H Scholten",
        "P Havinga"
      ],
      "year": 2016,
      "doi": "10.3390/s16040426",
      "journal": "Sensors",
      "volume": "16",
      "issue": "4",
      "pages": "426",
      "raw": "Complex Human Activity Recognition Using Smartphone and Wrist-Worn Motion Sensors \n\t\t \n\t\t\t M Shoaib \n\t\t \n\t\t \n\t\t\t S Bosch \n\t\t \n\t\t \n\t\t\t O Incel \n\t\t \n\t\t \n\t\t\t H Scholten \n\t\t \n\t\t \n\t\t\t P Havinga \n\t\t \n\t\t 10.3390/s16040426 \n\t \n\t \n\t\t Sensors \n\t\t \n\t\t\t 16 \n\t\t\t 4 \n\t\t\t 426 \n\t\t\t 2016 \n\t\t \n\t \n\t M. Shoaib, S. Bosch, O. Incel, H. Scholten and P. Havinga \"Complex Human Activity Recognition Using Smartphone and Wrist-Worn Motion Sensors\", Sensors, 16(4), 426. doi:10.3390/s16040426, 2016."
    },
    {
      "title": "Accelerometer-based Human Activity Recognition and the Impact of the Sample Size",
      "authors": [
        "A Harasimowic",
        "T Dziubich",
        "A Brzeski"
      ],
      "year": 2014,
      "raw": "Accelerometer-based Human Activity Recognition and the Impact of the Sample Size \n\t\t \n\t\t\t A Harasimowic \n\t\t \n\t\t \n\t\t\t T Dziubich \n\t\t \n\t\t \n\t\t\t A Brzeski \n\t\t \n\t \n\t \n\t\t Proceedings of the 13th International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases \n\t\t the 13th International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases Gdansk, Poland \n\t\t \n\t\t\t 2014 \n\t\t \n\t \n\t A. Harasimowic, T. Dziubich and A. Brzeski, \"Accelerometer-based Human Activity Recognition and the Impact of the Sample Size\", in Proceedings of the 13th International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases, Gdansk, Poland, 2014."
    },
    {
      "title": "Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors",
      "authors": [
        "M Zeng",
        "L Nguyen",
        "B Yu",
        "O Mengshoel",
        "J Zhu",
        "P Wu",
        "J Zhang"
      ],
      "year": 2014,
      "doi": "10.4108/icst.mobicase.2014.257786",
      "raw": "Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors \n\t\t \n\t\t\t M Zeng \n\t\t \n\t\t \n\t\t\t L T Nguyen \n\t\t \n\t\t \n\t\t\t B Yu \n\t\t \n\t\t \n\t\t\t O J Mengshoel \n\t\t \n\t\t \n\t\t\t J Zhu \n\t\t \n\t\t \n\t\t\t P Wu \n\t\t \n\t\t \n\t\t\t J Zhang \n\t\t \n\t\t 10.4108/icst.mobicase.2014.257786 \n\t \n\t \n\t\t Proceedings of the 6th International Conference on Mobile Computing, Applications and Services \n\t\t the 6th International Conference on Mobile Computing, Applications and Services \n\t\t \n\t\t\t 2014 \n\t\t \n\t \n\t M. Zeng, L. T. Nguyen, B. Yu, O. J. Mengshoel, J. Zhu, P. Wu and J. Zhang, \"Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors\", Proceedings of the 6th International Conference on Mobile Computing, Applications and Services. doi: 10.4108/icst. mobicase. 2014. 257786, 2014."
    },
    {
      "title": "Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition",
      "authors": [
        "F Ordonez",
        "D Roggen"
      ],
      "year": 2016,
      "doi": "10.3390/s16010115",
      "journal": "Sensors",
      "volume": "16",
      "issue": "1",
      "pages": "115",
      "raw": "Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition \n\t\t \n\t\t\t F J Ordonez \n\t\t \n\t\t \n\t\t\t D Roggen \n\t\t \n\t\t 10.3390/s16010115 \n\t \n\t \n\t\t Sensors \n\t\t \n\t\t\t 16 \n\t\t\t 1 \n\t\t\t 115 \n\t\t\t 2016 \n\t\t \n\t \n\t F. J. Ordonez and D. Roggen, \"Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition\", Sensors, 16 (1), 115. doi: 10. 3390/ s16010115, 2016."
    },
    {
      "title": "Human Activity Classification in Smartphones Using Accelerometer and Gyroscope Sensors",
      "authors": [
        "A Jain",
        "V Kanhangad"
      ],
      "year": 2018,
      "doi": "10.1109/jsen.2017.2782492",
      "journal": "IEEE Sensors Journal",
      "raw": "Human Activity Classification in Smartphones Using Accelerometer and Gyroscope Sensors \n\t\t \n\t\t\t A Jain \n\t\t \n\t\t \n\t\t\t V Kanhangad \n\t\t \n\t\t 10.1109/jsen.2017.2782492 \n\t \n\t \n\t\t IEEE Sensors Journal \n\t\t \n\t\t\t 2018 \n\t\t \n\t \n\t A. Jain and V. Kanhangad, \"Human Activity Classification in Smartphones Using Accelerometer and Gyroscope Sensors\", IEEE Sensors Journal, 2018."
    },
    {
      "title": "Human Activity Recognition using Smart Phone Embedded Sensors: A Linear Dynamical Systems Method",
      "authors": [
        "W Wang",
        "H Liu",
        "L Yu",
        "F Sun"
      ],
      "year": 2014,
      "doi": "10.1109/ijcnn.2014.6889585",
      "raw": "Human Activity Recognition using Smart Phone Embedded Sensors: A Linear Dynamical Systems Method \n\t\t \n\t\t\t W Wang \n\t\t \n\t\t \n\t\t\t H Liu \n\t\t \n\t\t \n\t\t\t L Yu \n\t\t \n\t\t \n\t\t\t F Sun \n\t\t \n\t\t 10.1109/ijcnn.2014.6889585 \n\t \n\t \n\t\t International Joint Conference on Neural Networks (IJCNN) \n\t\t China \n\t\t \n\t\t\t 2014 \n\t\t \n\t \n\t W. Wang, H. Liu, L. Yu, F. Sun, \"Human Activity Recognition using Smart Phone Embedded Sensors: A Linear Dynamical Systems Method\", International Joint Conference on Neural Networks (IJCNN), China, 2014."
    },
    {
      "title": "Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening",
      "authors": [
        "H Cho",
        "S Yoon"
      ],
      "year": 2018,
      "doi": "10.3390/s18041055",
      "journal": "Sensors",
      "volume": "18",
      "issue": "4",
      "pages": "1055",
      "raw": "Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening \n\t\t \n\t\t\t H Cho \n\t\t \n\t\t \n\t\t\t S M Yoon \n\t\t \n\t\t 10.3390/s18041055 \n\t \n\t \n\t\t Sensors \n\t\t \n\t\t\t 18 \n\t\t\t 4 \n\t\t\t 1055 \n\t\t\t 2018 \n\t\t \n\t \n\t H. Cho and S. M. Yoon, \"Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening\", Sensors, 18(4), 1055. doi:10.3390/s18041055, 2018."
    },
    {
      "title": "Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks",
      "authors": [
        "W Jiang",
        "Z Yin"
      ],
      "year": 2015,
      "doi": "10.1145/2733373.2806333",
      "raw": "Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks \n\t\t \n\t\t\t W Jiang \n\t\t \n\t\t \n\t\t\t Z Yin \n\t\t \n\t\t 10.1145/2733373.2806333 \n\t \n\t \n\t\t Proceedings of the 23rd ACM International Conference on Multimedia-MM'15 \n\t\t the 23rd ACM International Conference on Multimedia-MM'15 \n\t\t \n\t\t\t 2015 \n\t\t \n\t \n\t W. Jiang and Z. Yin, \"Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks\", Proceedings of the 23rd ACM International Conference on Multimedia- MM'15. doi:10.1145/2733373.2806333, 2015."
    },
    {
      "title": "Deep Recurrent Neural Networks for Human Activity Recognition",
      "authors": [
        "A Murad",
        "J-Y Pyun"
      ],
      "year": 2017,
      "doi": "10.3390/s17112556",
      "journal": "Sensors",
      "volume": "17",
      "issue": "11",
      "pages": "2556",
      "raw": "Deep Recurrent Neural Networks for Human Activity Recognition \n\t\t \n\t\t\t A Murad \n\t\t \n\t\t \n\t\t\t J-Y Pyun \n\t\t \n\t\t 10.3390/s17112556 \n\t \n\t \n\t\t Sensors \n\t\t \n\t\t\t 17 \n\t\t\t 11 \n\t\t\t 2556 \n\t\t\t 2017 \n\t\t \n\t \n\t A. Murad and J-Y. Pyun, \"Deep Recurrent Neural Networks for Human Activity Recognition\", Sensors, 17 (11), 2556. doi: 10.3390/ s17112556, 2017."
    },
    {
      "title": "Activity Recognition using Cell Phone Accelerometers",
      "authors": [
        "J Kwapisz",
        "G Weiss",
        "S Moore"
      ],
      "year": 2010,
      "doi": "10.1145/1964897.1964918",
      "raw": "Activity Recognition using Cell Phone Accelerometers \n\t\t \n\t\t\t J R Kwapisz \n\t\t \n\t\t \n\t\t\t G M Weiss \n\t\t \n\t\t \n\t\t\t S A Moore \n\t\t \n\t\t 10.1145/1964897.1964918 \n\t \n\t \n\t\t Proceedings of the Fourth International Workshop on Knowledge Discovery from Sensor Data \n\t\t the Fourth International Workshop on Knowledge Discovery from Sensor Data Washington DC \n\t\t \n\t\t\t 2010 \n\t\t \n\t \n\t J. R. Kwapisz, G. M. Weiss and S. A. Moore, \"Activity Recognition using Cell Phone Accelerometers\", Proceedings of the Fourth International Workshop on Knowledge Discovery from Sensor Data, Washington DC, 2010."
    }
  ],
  "num_references": 11,
  "figures": [
    {
      "description": "6.5) with Anaconda distribution on Ubuntu 16.04.6 LTS (Xenial Xerus), Keras (version 2.1.6) and Tensorflow (version 1.7.0) as backend of keras. The following values can be obtained from the confusion matrix in a classification problem: \uf0b7 True Positives (TP): The number of positive instances that were classified as positive. \uf0b7 True Negatives (TN): The number of negative instances that were classified as negative. \uf0b7 False Positives (FP): The number of negative instances that were classified as positive."
    },
    {
      "caption": "Fig. 3 .",
      "description": "Fig.3. Confusion matrix by Bidirectional LSTM However, the two models presents different values of the predicted precision activities (Table.1)"
    },
    {
      "type": "table",
      "caption": "Table 1 .",
      "description": "1) Precision of activities between machine and deep learning algorithms"
    }
  ],
  "num_figures": 3,
  "tables": [
    {
      "content": "Decision Tree Bidirectional LSTM Downstairs 23% 37% Jogging 80% 74% Sitting 89% 99% Standing 83% 52% Upstairs 19% 00% Walking 67% 57%"
    }
  ],
  "num_tables": 1,
  "num_citations": 16,
  "cited_references": [
    "b8",
    "b6",
    "b4",
    "b1",
    "b9",
    "b0",
    "b3",
    "b5",
    "b2",
    "b10",
    "b7"
  ],
  "notes": [
    "[raw_affiliation] CEM Lab , ENIS , University of Sfax , ISIT'COM , University of Sousse CEM Lab , Departement of Electrical Engineering , ENIS , University of Sfax CEM Lab , Departement of Electrical Engineering , ENIS , University of Sfax",
    "[raw_affiliation] CEM Lab , ENIS , University of Sfax , ISIT'COM , University of Sousse CEM Lab , Departement of Electrical Engineering , ENIS , University of Sfax CEM Lab , Departement of Electrical Engineering , ENIS , University of Sfax",
    "[raw_affiliation] CEM Lab , ENIS , University of Sfax , ISIT'COM , University of Sousse CEM Lab , Departement of Electrical Engineering , ENIS , University of Sfax CEM Lab , Departement of Electrical Engineering , ENIS , University of Sfax",
    "Authorized licensed use limited to: The University of Iowa. Downloaded on August 05,2025 at 04:21:00 UTC from IEEE Xplore. Restrictions apply.",
    "[raw_reference] R. Yang and B. Wang, \"PACP: A Position-Independent Activity Recognition Method Using Smartphone Sensors\", School of Computer and Software, Nanjing University of Information Science & Technology, Nanjing 210044, Jiangsu, China, 2016.",
    "[raw_reference] M. Shoaib, S. Bosch, O. Incel, H. Scholten and P. Havinga \"Complex Human Activity Recognition Using Smartphone and Wrist-Worn Motion Sensors\", Sensors, 16(4), 426. doi:10.3390/s16040426, 2016.",
    "[raw_reference] A. Harasimowic, T. Dziubich and A. Brzeski, \"Accelerometer-based Human Activity Recognition and the Impact of the Sample Size\", in Proceedings of the 13th International Conference on Artificial Intelligence, Knowledge Engineering and Data Bases, Gdansk, Poland, 2014.",
    "[raw_reference] M. Zeng, L. T. Nguyen, B. Yu, O. J. Mengshoel, J. Zhu, P. Wu and J. Zhang, \"Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors\", Proceedings of the 6th International Conference on Mobile Computing, Applications and Services. doi: 10.4108/icst. mobicase. 2014. 257786, 2014.",
    "[raw_reference] F. J. Ordonez and D. Roggen, \"Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition\", Sensors, 16 (1), 115. doi: 10. 3390/ s16010115, 2016.",
    "[raw_reference] A. Jain and V. Kanhangad, \"Human Activity Classification in Smartphones Using Accelerometer and Gyroscope Sensors\", IEEE Sensors Journal, 2018.",
    "[raw_reference] W. Wang, H. Liu, L. Yu, F. Sun, \"Human Activity Recognition using Smart Phone Embedded Sensors: A Linear Dynamical Systems Method\", International Joint Conference on Neural Networks (IJCNN), China, 2014.",
    "[raw_reference] H. Cho and S. M. Yoon, \"Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening\", Sensors, 18(4), 1055. doi:10.3390/s18041055, 2018.",
    "[raw_reference] W. Jiang and Z. Yin, \"Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks\", Proceedings of the 23rd ACM International Conference on Multimedia- MM'15. doi:10.1145/2733373.2806333, 2015.",
    "[raw_reference] A. Murad and J-Y. Pyun, \"Deep Recurrent Neural Networks for Human Activity Recognition\", Sensors, 17 (11), 2556. doi: 10.3390/ s17112556, 2017.",
    "[raw_reference] J. R. Kwapisz, G. M. Weiss and S. A. Moore, \"Activity Recognition using Cell Phone Accelerometers\", Proceedings of the Fourth International Workshop on Knowledge Discovery from Sensor Data, Washington DC, 2010."
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  },
  "pages": "1-4"
}
