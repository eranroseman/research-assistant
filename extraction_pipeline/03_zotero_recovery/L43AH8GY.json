{
  "paper_id": "L43AH8GY",
  "title": "Key challenges for delivering clinical impact with artificial intelligence",
  "abstract": "Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful postmarket surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. \n Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.",
  "year": 2019,
  "date": "2019",
  "journal": "Nat Med",
  "publication": "Nat Med",
  "authors": [
    {
      "forename": "Christopher",
      "surname": "Kelly",
      "name": "Christopher Kelly",
      "affiliation": "1  Google Health , London , UK \n\t\t\t\t\t\t\t\t Google Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t London \n\t\t\t\t\t\t\t\t\t UK",
      "email": "cjkelly@google.com"
    },
    {
      "forename": "Alan",
      "surname": "Karthikesalingam",
      "name": "Alan Karthikesalingam",
      "affiliation": "1  Google Health , London , UK \n\t\t\t\t\t\t\t\t Google Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t London \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0002-1246-844X"
    },
    {
      "forename": "Mustafa",
      "surname": "Suleyman",
      "name": "Mustafa Suleyman",
      "affiliation": "2  DeepMind , London , UK. \n\t\t\t\t\t\t\t\t DeepMind \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t London \n\t\t\t\t\t\t\t\t\t UK"
    },
    {
      "forename": "Greg",
      "surname": "Corrado",
      "name": "Greg Corrado",
      "affiliation": "3  Google Health , California , USA. \n\t\t\t\t\t\t\t\t Google Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t California \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Dominic",
      "surname": "King",
      "name": "Dominic King",
      "affiliation": "1  Google Health , London , UK \n\t\t\t\t\t\t\t\t Google Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t London \n\t\t\t\t\t\t\t\t\t UK"
    }
  ],
  "doi": "10.1186/s12916-019-1426-2",
  "keywords": [
    "Artificial intelligence",
    "Machine learning",
    "Algorithms",
    "Translation",
    "Evaluation",
    "Regulation"
  ],
  "sections": [
    {
      "title": "Background",
      "text": "The exciting promise of artificial intelligence (AI) in healthcare has been widely reported, with potential applications across many different domains of medicine  [1, 2] . This promise has been welcomed as healthcare systems globally struggle to deliver the 'quadruple aim', namely improving experience of care, improving the health of populations, reducing per capita costs of healthcare  [3] , and improving the work life of healthcare providers  [4] .\n\nNevertheless, the potential of AI in healthcare has not been realised to date, with limited existing reports of the clinical and cost benefits that have arisen from realworld use of AI algorithms in clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice."
    },
    {
      "title": "The potential of artificial intelligence in healthcare",
      "text": "A rapidly accelerating number of academic research studies have demonstrated the various applications of AI in healthcare, including algorithms for interpreting chest radiographs  [5] [6] [7] [8] [9] , detecting cancer in mammograms  [10, 11] , analysing computer tomography scans  [12] [13] [14] [15] , identifying brain tumours on magnetic resonance images  [16] , and predicting development of Alzheimer's disease from positron emission tomography  [17] . Applications have also been shown in pathology  [18] , identifying cancerous skin lesions  [19] [20] [21] [22] , interpreting retinal imaging  [23, 24] , detecting arrhythmias  [25, 26] , and even identifying hyperkalaemia from electrocardiograms  [27] . Furthermore, AI has aided in polyp detection from colonoscopy  [28] , improving genomics interpretation  [29] , identifying genetic conditions from facial appearance  [30] , and assessing embryo quality to maximise the success of in vitro fertilisation  [31] .\n\nAnalysis of the immense volume of data collected from electronic health records (EHRs) offers promise in extracting clinically relevant information and making diagnostic evaluations  [32]  as well as in providing real-time risk scores for transfer to intensive care  [33] , predicting inhospital mortality, readmission risk, prolonged length of stay and discharge diagnoses  [34] , predicting future deterioration, including acute kidney injury  [35] , improving decision-making strategies, including weaning of mechanical ventilation  [36]  and management of sepsis  [37] , and learning treatment policies from observational data  [38] . Proof-of-concept studies have aimed to improve the clinical workflow, including automatic extraction of semantic information from transcripts  [39] , recognising speech in doctor-patient conversations  [40] , predicting risk of failure to attend hospital appointments  [41] , and even summarising doctor-patient consultations  [42] .\n\nGiven this impressive array of studies, it is perhaps surprising that real world deployments of machine learning algorithms in clinical practice are rare. Despite this, we believe that AI will have a positive impact on many aspects of medicine. AI systems have the potential to reduce unwarranted variation in clinical practice, improve efficiency and prevent avoidable medical errors that will affect almost every patient during their lifetime  [43] . By providing novel tools to support patients and augment healthcare staff, AI could enable better care delivered closer to the patient in the community. AI tools could assist patients in playing a greater role in managing their own health, primary care physicians by allowing them to confidently manage a greater range of complex disease, and specialists by offering superhuman diagnostic performance and disease management. Finally, through the detection of novel signals of disease that clinicians are unable to perceive, AI can extract novel insights from existing data. Examples include the identification of novel predictive features for breast cancer prognosis using stromal cells (rather than the cancer cells themselves)  [44] , predicting cardiovascular risk factors and sex from a fundus photograph  [45] , inferring blood flow in coronary arteries from cardiac computed tomography  [46] , detecting individuals with atrial fibrillation from ECG acquired during normal sinus rhythm  [26] , and using retinal imaging to assist an earlier diagnosis of dementia  [47] ."
    },
    {
      "title": "The challenge of translation to clinical practice"
    },
    {
      "title": "Retrospective versus prospective studies",
      "text": "While existing studies have encompassed very large numbers of patients with extensive benchmarking against expert performance, the vast majority of studies have been retrospective, meaning that they use historically labelled data to train and test algorithms. Only through prospective studies will we begin to understand the true utility of AI systems, as performance is likely to be worse when encountering real-world data that differ from that encountered in algorithm training. The limited number of prospective studies to date include diabetic retinopathy grading  [48] [49] [50] , detection of breast cancer metastases in sentinel lymph node biopsies  [51, 52] , wrist fracture detection  [53] , colonic polyp detection  [28, 54] , and detection of congenital cataracts  [55] . Consumer technology is enabling enormous prospective studies, in relation to historical standards, through the use of wearables; for example, there is an ongoing study to detect atrial fibrillation in 419,093 consenting Apple watch owners  [56] ."
    },
    {
      "title": "Peer-reviewed randomised controlled trials as an evidence gold standard",
      "text": "As is common in the machine learning community, many studies have been published on preprint servers only and are not submitted to peer-reviewed journals. Peer-reviewed evidence will be important for the trust and adoption of AI within the wider medical community. There are very few randomised controlled trials (RCTs) of AI systems to date; these include an algorithm to detect childhood cataracts with promising performance in a small prospective study  [55]  but less accurate performance compared to senior clinicians in a diagnostic RCT  [57] ; a single-blind RCT that showed a significantly reduced blind-spot rate in esophagogastroduodenoscopy  [58] ; an open, non-blinded randomised trial of an automatic polyp detection algorithm for diagnostic colonoscopy demonstrating a significant increase in detection of diminutive adenomas and hyperplastic polyps  [59] ; a simulated prospective, double-blind RCT of an algorithm to detect acute neurologic events  [60] ; and an unmasked RCT of a system to provide automated interpretation of cardiotocographs in labour that found no improvement in clinical outcomes for mothers or babies  [61] . The final study is a cautionary example of how higher accuracy enabled by AI systems does not necessarily result in better patient outcomes  [61] . Future studies should aim to use clinical outcomes as trial endpoints to demonstrate longer-term benefit, while recognising that algorithms are likely to result in changes of the sociocultural context or care pathways; this may necessitate more sophisticated approaches to evaluation  [62] .\n\nHigh quality reporting of machine learning studies is critical. Only with full and clear reporting of information on all aspects of a diagnosis or prognosis model can risk of bias and potential usefulness of prediction models be adequately assessed. Machine learning studies should aim to follow best practice recommendations, such as the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD), designed to assist the reporting of studies that develop, validate or update a prediction model for either diagnostic or prognostic purposes  [63] . In addition, a new version of the TRIPOD statement that is specific to machine learning prediction algorithms (TRIPOD-ML) is in development and will focus on the introduction of machine learning prediction algorithms, establishing methodological and reporting standards for machine learning studies in healthcare  [64] ."
    },
    {
      "title": "Metrics often do not reflect clinical applicability",
      "text": "The term 'AI chasm' has been coined to reflect the fact that accuracy does not necessarily represent clinical efficacy  [65] . Despite its universal use in machine learning studies, area under the curve of a receiver operating characteristic curve is not necessarily the best metric to represent clinical applicability  [66]  and is not easily understandable by many clinicians. As well as reporting sensitivity and specificity at a selected model operating point (required to turn the continuous model output into discrete decision categories), papers should include information about positive and negative predictive values. As no single measure captures all the desirable properties of a model, several measures are typically reported to summarise its performance. However, none of these measures ultimately reflect what is most important to patients, namely whether the use of the model results in a beneficial change in patient care  [67] .\n\nClinicians need to be able to understand how the proposed algorithms could improve patient care within a relatable workflow, yet most papers do not attempt to present such information; potential approaches to this have been suggested, including decision curve analysis, which aims to quantify the net benefit of using a model to guide subsequent actions  [68] . To improve understanding, medical students and practising clinicians should be provided with an easily accessible AI curriculum to enable them to critically appraise, adopt and use AI tools safely in their practice."
    },
    {
      "title": "Difficulty comparing different algorithms",
      "text": "The comparison of algorithms across studies in an objective manner is challenging due to each study's performance being reported using variable methodologies on different populations with different sample distributions and characteristics. To make fair comparisons, algorithms need to be subjected to comparison on the same independent test set that is representative of the target population, using the same performance metrics. Without this, clinicians will have difficulty in determining which algorithm is likely to perform best for their patients.\n\nThe curation of independent local test sets by each healthcare provider could be used to fairly compare the performance of the various available algorithms in a representative sample of their population. Such independent test sets should be constructed using an unenriched representative sample along with data that are explicitly not available to train algorithms. A supplementary local training dataset could be provided to allow fine tuning of algorithms prior to formal testing.\n\nFor researchers, comparison will become easier with the increasing availability of large, open datasets, allowing studies to benchmark their performance in a consistent manner.\n\nChallenges related to machine learning science AI algorithms have the potential to suffer from a host of shortcomings, including inapplicability outside of the training domain, bias and brittleness (tendency to be easily fooled)  [69] . Important factors for consideration include dataset shift, accidentally fitting confounders rather than true signal, propagating unintentional biases in clinical practice, providing algorithms with interpretability, developing reliable measures of model confidence, and the challenge of generalisation to different populations."
    },
    {
      "title": "Dataset shift",
      "text": "Particularly important for EHR algorithms, it is easy to ignore the fact that all input data are generated within a non-stationary environment with shifting patient populations, where clinical and operational practices evolve over time  [70] . The introduction of a new predictive algorithm may cause changes in practice, resulting in a new distribution compared to that used to train the algorithm. Therefore, methods to identify drift and update models in response to deteriorating performance are critical. Mitigations to manage this effect include careful quantification of performance over time to proactively identify problems, alongside the likely requirement for periodical retraining. Data-driven testing procedures have been suggested to recommend the most appropriate updating method, from simple recalibration to full model retraining, in order to maintain performance over time  [71] ."
    },
    {
      "title": "Accidentally fitting confounders versus true signal",
      "text": "Machine learning algorithms will use whatever signals are available to achieve the best possible performance in the dataset used. This may include the exploitation of unknown confounders that may not be reliable, impairing the algorithm's ability to generalise to new datasets. For instance, in one classic example, a machine learning model did not learn the intrinsic difference between dogs and wolves, but instead learned that wolves are usually pictured standing on snow, while dogs usually appear on grass  [72] . There are similar concerns in healthcare. In one study, an algorithm was more likely to classify a skin lesion as malignant if an image had a ruler in it because the presence of a ruler correlated with an increased likelihood of a cancerous lesion  [19] . The presence of surgical skin markings have also been shown to falsely increase a deep learning model's melanoma probability scores and hence false positive rate  [73] . In another study, hip fracture detection was found to be aided by confounders, including the scanner model and scans marked 'urgent'  [74] . Another algorithm for detection of pneumonia on chest x-rays was able to accurately identify hospital equipment and department, learning an association between a portable x-ray machine and pneumonia  [75] . Ongoing work is required to understand the specific features being learned by neural networks and will be critical for generalisation across multiple healthcare settings."
    },
    {
      "title": "Challenges in generalisation to new populations and settings",
      "text": "The majority of AI systems are far from achieving reliable generalisability, let alone clinical applicability, for most types of medical data. A brittle model may have blind spots that can produce particularly bad decisions. Generalisation can be hard due to technical differences between sites (including differences in equipment, coding definitions, EHR systems, and laboratory equipment and assays) as well as variations in local clinical and administrative practices.\n\nTo overcome these issues, it is likely that a degree of site-specific training will be required to adapt an existing system for a new population, particularly for complex tasks like EHR predictions. Methods to detect out-ofdistribution inputs and provide a reliable measure of model confidence will be important to prevent clinical decisions being made on inaccurate model outputs. For simpler tasks, including medical image classification, this problem may be less crucial and overcome by the curation of large, heterogenous, multi-centre datasets  [14] . Generalisation of model operating points may also prove challenging across new populations, as illustrated in a recent study to detect abnormal chest radiographs, where specificity at a fixed operating point varied widely, from 0.566 to 1.000, across five independent datasets  [5] .\n\nProper assessment of real-world clinical performance and generalisation requires appropriately designed external validation involving testing of an AI system using adequately sized datasets collected from institutions other than those that provided the data for model training. This will ensure that all relevant variations in patient demographics and disease states of target patients in real-world clinical settings are adequately represented in the system where it will be applied  [76] . This practice is currently rare in the literature and is of critical concern. A recent systematic review of studies that evaluated AI algorithms for the diagnostic analysis of medical imaging found that only 6% of 516 eligible published studies performed external validation  [77] ."
    },
    {
      "title": "Algorithmic bias",
      "text": "Intertwined with the issue of generalisability is that of discriminatory bias. Blind spots in machine learning can reflect the worst societal biases, with a risk of unintended or unknown accuracies in minority subgroups, and there is fear over the potential for amplifying biases present in the historical data  [78] . Studies indicate that, in some current contexts, the downsides of AI systems disproportionately affect groups that are already disadvantaged by factors such as race, gender and socioeconomic background  [79] . In medicine, examples include hospital mortality prediction algorithms with varying accuracy by ethnicity  [80]  and algorithms that can classify images of benign and malignant moles with accuracy similar to that of board-certified dermatologists  [19, 81] , but with underperformance on images of lesions in skin of colour due to training on open datasets of predominantly fair skinned patients. The latter is particularly concerning as patients with skin of colour already present with more advanced dermatological diseases and have lower survival rates than those with fair skin  [82] .\n\nAlgorithmic unfairness can be distilled into three components, namely (1) model bias (i.e. models selected to best represent the majority and not necessarily underrepresented groups), (2) model variance (due to inadequate data from minorities), and (3) outcome noise (the effect of a set of unobserved variables that potentially interacts with model predictions, avoidable by identifying subpopulations to measure additional variables)  [80] . A greater awareness of these issues and empowering clinicians to participate critically in system design and development will help guide researchers to ensure that the correct steps are taken to quantify bias before deploying models. Algorithms should be designed with the global community in mind, and clinical validation should be performed using a representative population of the intended deployment population. Careful performance analysis by population subgroups should be performed, including age, ethnicity, sex, sociodemographic stratum and location. Analysis to understand the impact of a new algorithm is particularly important, i.e. if the spectrum of disease detected using the AI system differs from current clinical practice, then the benefits and harms of detecting this different spectrum of disease must be evaluated. In mammography, this might be the detection of less severe ductal carcinoma in situ, potentially resulting in increased treatment with little benefit in outcomes. Prospective pilots within healthcare systems should be undertaken to understand the product characteristics and identify potential pitfalls in practical deployment."
    },
    {
      "title": "Susceptibility to adversarial attack or manipulation",
      "text": "Algorithms have been shown to be susceptible to risk of adversarial attack. Although somewhat theoretical at present, an adversarial attack describes an otherwiseeffective model that is susceptible to manipulation by inputs explicitly designed to fool them. For example, in one study, images of benign moles were misdiagnosed as malignant by adding adversarial noise or even just rotation  [83] ."
    },
    {
      "title": "Logistical difficulties in implementing AI systems",
      "text": "Many of the current challenges in translating AI algorithms to clinical practice are related to the fact that most healthcare data are not readily available for machine learning. Data are often siloed in a multitude of medical imaging archival systems, pathology systems, EHRs, electronic prescribing tools and insurance databases, which are very difficult to bring together. Adoption of unified data formats, such as Fast Healthcare Interoperability Resources  [84] , offer the potential for better aggregation of data, although improved interoperability does not necessarily fix the problem of inconsistent semantic coding in EHR data  [85] ."
    },
    {
      "title": "Achieving robust regulation and rigorous quality control",
      "text": "A fundamental component to achieving safe and effective deployment of AI algorithms is the development of the necessary regulatory frameworks. This poses a unique challenge given the current pace of innovation, significant risks involved and the potentially fluid nature of machine learning models. Proactive regulation will give confidence to clinicians and healthcare systems. Recent U.S. Food and Drug Administration guidance has begun developing a modern regulatory framework to make sure that safe and effective artificial intelligence devices can efficiently progress to patients  [86] .\n\nIt is also important to consider the regulatory impact of improvements and upgrades that providers of AI products are likely to develop throughout the life of the product. Some AI systems will be designed to improve over time, representing a challenge to traditional evaluation processes. Where AI learning is continuous, periodic system-wide updates following a full evaluation of clinical significance would be preferred, compared to continuous updates which may result in drift. The development of ongoing performance monitoring guidelines to continually calibrate models using human feedback will support the identification of performance deficits over time."
    },
    {
      "title": "Human barriers to AI adoption in healthcare",
      "text": "Even with a highly effective algorithm that overcomes all of the above challenges, human barriers to adoption are substantial. In order to ensure that this technology can reach and benefit patients, it will be important to maintain a focus on clinical applicability and patient outcomes, advance methods for algorithmic interpretability, and achieve a better understanding of human-computer interactions."
    },
    {
      "title": "Algorithmic interpretability is at an early stage but rapidly advancing",
      "text": "While AI approaches in medicine have yielded some impressive practical successes to date, their effectiveness is limited by their inability to 'explain' their decision-making in an understandable way  [87] . Even if we understand the underlying mathematical principles of such models, it is difficult and often impossible to interrogate the inner workings of models to understand how and why it made a certain decision. This is potentially problematic for medical applications, where there is particular demand for approaches that are not only well-performing, but also trustworthy, transparent, interpretable and explainable  [88] .\n\nHealthcare offers one of the strongest arguments in favour of explainability  [88, 89] . Given the combination of the devastating consequences of unacceptable results, the high risk of unquantified bias that is difficult to identify a priori, and the recognised potential for models to use inappropriate confounding variables, explainability enables system verification. This improves experts' ability to recognise system errors, detect results based upon inappropriate reasoning, and identify the work required to remove bias. In addition, AI systems are trained using large numbers of examples and may detect patterns in data that are not accessible to humans. Interpretable systems may allow humans to extract this distilled knowledge in order to acquire new scientific insights. Finally, recent European Union General Data Protection Regulation legislation mandates a 'right to explanation' for algorithmically generated user-level predictions that have the potential to 'significantly affect' users; this suggests that there must be a possibility to make results re-traceable on demand  [88] .\n\nAt present, a trade-off exists between performance and explainability. The best performing models (e.g. deep learning) are often the least explainable, whereas models with poorer performance (e.g. linear regression, decision trees) are the most explainable. A key current limitation of deep learning models is that they have no explicit declarative knowledge representation, leading to considerable difficulty in generating the required explanation structures  [90] . Machine learning methods that build upon a long history of research in traditional symbolic AI techniques to allow for encoding of semantics of data and the use of ontologies to guide the learning process may permit human experts to understand and retrace decision processes more effectively  [91, 92] . One recent approach replaced end-to-end classification with a twostage architecture comprising segmentation and classification, allowing the clinician to interrogate the segmentation map to understand the basis of the subsequent classification  [24] .\n\nIf 'black box' algorithms are to be used in healthcare, they need to be used with knowledge, judgement and responsibility. In the meantime, research into explainable AI and evaluation of interpretability is occurring at a rapid pace  [93] . Explainable AI approaches are likely to facilitate faster adoption of AI systems into the clinical healthcare setting, and will help foster vital transparency and trust with their users."
    },
    {
      "title": "Developing a better understanding of interaction between human and algorithm",
      "text": "We have a limited but growing understanding of how humans are affected by algorithms in clinical practice. Following the U. S. Food and Drug Administration approval of computer-aided diagnosis for mammography in the late 1990s, computer-aided diagnosis was found to significantly increase recall rate without improving outcomes  [94] . Excessive warnings and alerts are known to result in alert fatigue  [94, 95] . It has also been shown that humans assisted by AI performed better than either alone in a study of diabetic retinopathy screening  [96, 97] . Techniques to more meaningfully represent medical knowledge, provide explanation and facilitate improved interaction with clinicians will only improve this performance further. We need to continue gaining a better understanding of the complex and evolving relationship between clinicians and human-centred AI tools in the live clinical environment  [98] ."
    },
    {
      "title": "Conclusion",
      "text": "Recent advances in artificial intelligence present an exciting opportunity to improve healthcare. However, the translation of research techniques to effective clinical deployment presents a new frontier for clinical and machine learning research. Robust, prospective clinical evaluation will be essential to ensure that AI systems are safe and effective, using clinically applicable performance metrics that go beyond measures of technical accuracy to include how AI affects the quality of care, the variability of healthcare professionals, the efficiency and productivity of clinical practice and, most importantly, patient outcomes. Independent datasets that are representative of future target populations should be curated to enable the comparison of different algorithms, while carefully evaluating for signs of potential bias and fitting to unintended confounders. Developers of AI tools must be cognisant of the potential unintended consequences of their algorithms and ensure that algorithms are designed with the global community in mind. Further work to improve the interpretability of algorithms and to understand human-algorithm interactions will be essential to their future adoption and safety supported by the development of thoughtful regulatory frameworks."
    }
  ],
  "references": [
    {
      "title": "High-performance medicine: the convergence of human and artificial intelligence",
      "authors": [
        "E Topol"
      ],
      "year": 2019,
      "doi": "10.1038/s41591-018-0300-7"
    },
    {
      "title": "A guide to deep learning in healthcare",
      "authors": [
        "A Esteva",
        "A Robicquet",
        "B Ramsundar",
        "V Kuleshov",
        "M Depristo",
        "K Chou"
      ],
      "year": 2019,
      "doi": "10.1038/s41591-018-0316-z"
    },
    {
      "title": "The triple aim: care, health, and cost",
      "authors": [
        "D Berwick",
        "T Nolan",
        "J Whittington"
      ],
      "year": 2008,
      "doi": "10.1377/hlthaff.27.3.759"
    },
    {
      "title": "From triple to quadruple aim: care of the patient requires care of the provider",
      "authors": [
        "T Bodenheimer",
        "C Sinsky"
      ],
      "year": 2014,
      "doi": "10.1370/afm.1713"
    },
    {
      "title": "Development and validation of a deep learning-based automated detection algorithm for major thoracic diseases on chest radiographs",
      "authors": [
        "E Hwang",
        "S Park",
        "K-N Kim",
        "J Choi",
        "S Lee"
      ],
      "year": 2019
    },
    {
      "title": "ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases",
      "authors": [
        "X Wang",
        "Y Peng",
        "L Lu",
        "Z Lu",
        "M Bagheri",
        "R Summers"
      ],
      "year": 2017,
      "doi": "10.1109/cvpr.2017.369"
    },
    {
      "title": "Thoracic Disease Identification and Localization with Limited Supervision",
      "authors": [
        "Z Li",
        "C Wang",
        "M Han",
        "Y Xue",
        "W Wei",
        "L-J Li"
      ],
      "year": 2018,
      "doi": "10.1109/cvpr.2018.00865"
    },
    {
      "title": "Deep learning in chest radiography: detection of findings and presence of change",
      "authors": [
        "R Singh",
        "M Kalra",
        "C Nitiwarangkul",
        "J Patti",
        "F Homayounieh",
        "A Padole"
      ],
      "year": 2018,
      "doi": "10.1371/journal.pone.0204155"
    },
    {
      "title": "Development and validation of deep learning-based automatic detection algorithm for malignant pulmonary nodules on chest radiographs",
      "authors": [
        "J Nam",
        "S Park",
        "E Hwang",
        "J Lee",
        "K-N Lim"
      ],
      "year": 2019,
      "doi": "10.1148/radiol.2018180237"
    },
    {
      "title": "High-resolution breast cancer screening with multi-view deep convolutional neural networks",
      "authors": [
        "K Geras",
        "S Wolfson",
        "Y Shen",
        "N Wu",
        "Gene Kim",
        "S Kim"
      ],
      "year": 2019
    },
    {
      "title": "Deep neural networks improve radiologists' performance in breast cancer screening",
      "authors": [
        "N Wu",
        "J Phang",
        "J Park",
        "Y Shen",
        "Z Huang",
        "M Zorin"
      ],
      "year": 2019,
      "doi": "10.1109/tmi.2019.2945514"
    },
    {
      "title": "Computer-aided classification of lung nodules on computed tomography images via deep learning technique",
      "authors": [
        "K-L Hua",
        "C-H Hsu",
        "S Hidayati",
        "W-H Cheng",
        "Y-J Chen"
      ],
      "year": 2015
    },
    {
      "title": "Deep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced CT: a preliminary study",
      "authors": [
        "K Yasaka",
        "H Akai",
        "O Abe",
        "S Kiryu"
      ],
      "year": 2018,
      "doi": "10.1148/radiol.2017170706"
    },
    {
      "title": "Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study",
      "authors": [
        "S Chilamkurthy",
        "R Ghosh",
        "S Tanamala",
        "M Biviji",
        "N Campeau",
        "V Venugopal"
      ],
      "year": 2018
    },
    {
      "title": "Fully-convolutional deeplearning based system for coronary calcium score prediction from noncontrast chest CT",
      "authors": [
        "R Shadmi",
        "V Mazo",
        "O Bregman-Amitai",
        "E Elnekave"
      ],
      "year": 2018,
      "doi": "10.1109/isbi.2018.8363515"
    },
    {
      "title": "DeepMedic for brain tumor segmentation",
      "authors": [
        "K Kamnitsas",
        "E Ferrante",
        "S Parisot",
        "C Ledig",
        "A Nori",
        "A Criminisi"
      ],
      "year": 2016,
      "doi": "10.1007/978-3-319-55524-9_14"
    },
    {
      "title": "A deep learning model to predict a diagnosis of Alzheimer disease by using F-FDG PET of the brain",
      "authors": [
        "Y Ding",
        "J Sohn",
        "M Kawczynski",
        "H Trivedi",
        "R Harnish",
        "N Jenkins"
      ],
      "year": 2019,
      "doi": "10.1148/radiol.2018180958"
    },
    {
      "title": "Artificial intelligence in pathology",
      "authors": [
        "H Chang",
        "C Jung",
        "J Woo",
        "S Lee",
        "J Cho",
        "S Kim"
      ],
      "year": 2019,
      "doi": "10.4132/jptm.2018.12.16"
    },
    {
      "title": "Dermatologist-level classification of skin cancer with deep neural networks",
      "authors": [
        "A Esteva",
        "B Kuprel",
        "R Novoa",
        "J Ko",
        "S Swetter",
        "H Blau"
      ],
      "year": 2017,
      "doi": "10.1038/nature21056"
    },
    {
      "title": "Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists",
      "authors": [
        "H Haenssle",
        "C Fink",
        "R Schneiderbauer",
        "F Toberer",
        "T Buhl",
        "A Blum"
      ],
      "year": 2018
    },
    {
      "title": "Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm",
      "authors": [
        "S Han",
        "M Kim",
        "W Lim",
        "G Park",
        "I Park",
        "S Chang"
      ],
      "year": 2018
    },
    {
      "title": "Deep learning outperformed 136 of 157 dermatologists in a head-tohead dermoscopic melanoma image classification task",
      "authors": [
        "T Brinker",
        "A Hekler",
        "A Enk",
        "J Klode",
        "A Hauschild",
        "C Berking"
      ],
      "year": 2019,
      "doi": "10.1016/j.ejca.2019.05.023"
    },
    {
      "title": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs",
      "authors": [
        "V Gulshan",
        "L Peng",
        "M Coram",
        "M Stumpe",
        "D Wu",
        "A Narayanaswamy"
      ],
      "year": 2016,
      "doi": "10.1001/jama.2016.17216"
    },
    {
      "title": "Clinically applicable deep learning for diagnosis and referral in retinal disease",
      "authors": [
        "J De Fauw",
        "J Ledsam",
        "B Romera-Paredes",
        "S Nikolov",
        "N Tomasev",
        "S Blackwell"
      ],
      "year": 2018,
      "doi": "10.1038/s41591-018-0107-6"
    },
    {
      "title": "Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network",
      "authors": [
        "A Hannun",
        "P Rajpurkar",
        "M Haghpanahi",
        "G Tison",
        "C Bourn",
        "M Turakhia"
      ],
      "year": 2019,
      "doi": "10.1038/s41591-018-0268-3"
    },
    {
      "title": "An artificial intelligence-enabled ECG algorithm for the identification of patients with atrial fibrillation during sinus rhythm: a retrospective analysis of outcome prediction",
      "authors": [
        "Z Attia",
        "P Noseworthy",
        "F Lopez-Jimenez",
        "S Asirvatham",
        "A Deshmukh",
        "B Gersh"
      ],
      "year": 2019,
      "doi": "10.1016/S0140-6736(19)31721-0"
    },
    {
      "title": "Development and validation of a deep-learning model to screen for hyperkalemia from the electrocardiogram",
      "authors": [
        "C Galloway",
        "A Valys",
        "J Shreibati",
        "D Treiman",
        "F Petterson",
        "V Gundotra"
      ],
      "year": 2019,
      "doi": "10.1001/jamacardio.2019.0640"
    },
    {
      "title": "Development and validation of a deep-learning algorithm for the detection of polyps during colonoscopy",
      "authors": [
        "P Wang",
        "X Xiao",
        "Glissen Brown",
        "J Berzin",
        "T Tu",
        "M Xiong"
      ],
      "year": 2018,
      "doi": "10.1038/s41551-018-0301-3"
    },
    {
      "title": "Translating cancer genomics into precision medicine with artificial intelligence: applications, challenges and future perspectives",
      "authors": [
        "J Xu",
        "P Yang",
        "S Xue",
        "B Sharma",
        "M Sanchez-Martin",
        "F Wang"
      ],
      "year": 2019
    },
    {
      "title": "Identifying facial phenotypes of genetic disorders using deep learning",
      "authors": [
        "Y Gurovich",
        "Y Hanani",
        "O Bar",
        "G Nadav",
        "N Fleischer",
        "D Gelbman"
      ],
      "year": 2019,
      "doi": "10.1038/s41591-018-0279-0"
    },
    {
      "title": "Deep learning enables robust assessment and selection of human blastocysts after in vitro fertilization",
      "authors": [
        "P Khosravi",
        "E Kazemi",
        "Q Zhan",
        "J Malmsten",
        "M Toschi",
        "P Zisimopoulos"
      ],
      "year": 2019,
      "doi": "10.1038/s41746-019-0096-y"
    },
    {
      "title": "Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence",
      "authors": [
        "H Liang",
        "B Tsui",
        "H Ni",
        "Ccs Valentim",
        "S Baxter",
        "G Liu"
      ],
      "year": 2019,
      "doi": "10.1038/s41591-018-0335-9"
    },
    {
      "title": "Piloting electronic medical record-based early detection of inpatient deterioration in community hospitals",
      "authors": [
        "G Escobar",
        "B Turk",
        "A Ragins",
        "J Ha",
        "B Hoberman",
        "S Levine"
      ],
      "year": 2016
    },
    {
      "title": "Scalable and accurate deep learning with electronic health records",
      "authors": [
        "A Rajkomar",
        "Oren Chen",
        "K Dai",
        "A Hajaj",
        "N Hardt"
      ],
      "year": 2018,
      "doi": "10.1038/s41746-018-0029-1"
    },
    {
      "title": "A clinically applicable approach to continuous prediction of future acute kidney injury",
      "authors": [
        "N Toma\u0161ev",
        "X Glorot",
        "J Rae",
        "M Zielinski",
        "H Askham",
        "A Saraiva"
      ],
      "year": 2019,
      "doi": "10.1038/s41586-019-1390-1"
    },
    {
      "title": "A reinforcement learning approach to weaning of mechanical ventilation in intensive care units",
      "authors": [
        "N Prasad",
        "L-F Cheng",
        "C Chivers",
        "M Draugelis",
        "B Engelhardt"
      ],
      "year": 2019
    },
    {
      "title": "Deep reinforcement learning for sepsis treatment",
      "authors": [
        "A Raghu",
        "M Komorowski",
        "I Ahmed",
        "L Celi",
        "P Szolovits",
        "M Ghassemi"
      ],
      "year": 2019
    },
    {
      "title": "Evaluating reinforcement learning algorithms in observational health settings",
      "authors": [
        "O Gottesman",
        "F Johansson",
        "J Meier",
        "J Dent",
        "D Lee",
        "S Srinivasan"
      ],
      "year": 2019,
      "doi": "10.7717/peerjcs.633/table-4"
    },
    {
      "title": "Semi-supervised learning for information extraction from dialogue",
      "authors": [
        "A Kannan",
        "K Chen",
        "D Jaunzeikare",
        "A Rajkomar"
      ],
      "year": 2018,
      "doi": "10.21437/interspeech.2018-1318"
    },
    {
      "title": "Speech recognition for medical conversations",
      "authors": [
        "C-C Chiu",
        "A Tripathi",
        "K Chou",
        "C Co",
        "N Jaitly",
        "D Jaunzeikare"
      ],
      "year": 2019
    },
    {
      "title": "Predicting scheduled hospital attendance with artificial intelligence",
      "authors": [
        "A Nelson",
        "D Herron",
        "G Rees",
        "P Nachev"
      ],
      "year": 2019,
      "doi": "10.1038/s41746-019-0103-3"
    },
    {
      "title": "Automatically charting symptoms from patient-physician conversations using machine learning",
      "authors": [
        "A Rajkomar",
        "A Kannan",
        "K Chen",
        "L Vardoulakis",
        "K Chou",
        "C Cui"
      ],
      "year": 2019,
      "doi": "10.1001/jamainternmed.2018.8558"
    },
    {
      "title": "Measurement is essential for improving diagnosis and reducing diagnostic error: a report from the institute of medicine",
      "authors": [
        "E Mcglynn",
        "K Mcdonald",
        "C Cassel"
      ],
      "year": 2015,
      "doi": "10.1001/jama.2015.13453"
    },
    {
      "title": "Systematic analysis of breast cancer morphology uncovers stromal features associated with survival",
      "authors": [
        "A Beck",
        "A Sangoi",
        "S Leung",
        "R Marinelli",
        "T Nielsen",
        "M Van De Vijver"
      ],
      "year": 2011,
      "doi": "10.1126/scitranslmed.3002564"
    },
    {
      "title": "Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning",
      "authors": [
        "R Poplin",
        "A Varadarajan",
        "K Blumer",
        "Y Liu",
        "M Mcconnell",
        "G Corrado"
      ],
      "year": 2018,
      "doi": "10.1038/s41551-018-0195-0"
    },
    {
      "title": "Computed fractional flow reserve (FFTCT) derived from coronary CT angiography",
      "authors": [
        "C Zarins",
        "C Taylor",
        "J Min"
      ],
      "year": 2013,
      "doi": "10.1007/s12265-013-9498-4"
    },
    {
      "title": "Association of retinal neurodegeneration on optical coherence tomography with dementia: a population-based study",
      "authors": [
        "U Mutlu",
        "J Colijn",
        "M Ikram",
        "Pwm Bonnemaijer",
        "S Licher",
        "F Wolters"
      ],
      "year": 2018,
      "doi": "10.1001/jamaneurol.2018.1563"
    },
    {
      "title": "Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices",
      "authors": [
        "M Abr\u00e0moff",
        "P Lavin",
        "M Birch",
        "N Shah",
        "J Folk"
      ],
      "year": 2018,
      "doi": "10.1038/s41746-018-0040-6"
    },
    {
      "title": "Evaluation of artificial intelligence-based grading of diabetic retinopathy in primary care",
      "authors": [
        "Y Kanagasingam",
        "D Xiao",
        "J Vignarajan",
        "A Preetham",
        "M-L Tay-Kearney",
        "A Mehrotra"
      ],
      "year": 2018,
      "doi": "10.1001/jamanetworkopen.2018.2665"
    },
    {
      "title": "Artificial intelligence using deep learning to screen for referable and visionthreatening diabetic retinopathy in Africa: a clinical validation study",
      "authors": [
        "V Bellemo",
        "Z Lim",
        "G Lim",
        "Q Nguyen",
        "Y Xie",
        "Myt Yip"
      ],
      "year": 2019
    },
    {
      "title": "Artificial intelligence-based breast cancer nodal metastasis detection: insights into the black box for pathologists",
      "authors": [
        "Y Liu",
        "T Kohlberger",
        "M Norouzi",
        "G Dahl",
        "J Smith",
        "A Mohtashamian"
      ],
      "year": 2018,
      "doi": "10.5858/arpa.2018-0147-oa"
    },
    {
      "title": "Impact of deep learning assistance on the histopathologic review of lymph nodes for metastatic breast cancer",
      "authors": [
        "D Steiner",
        "R Macdonald",
        "Y Liu",
        "P Truszkowski",
        "J Hipp",
        "C Gammage"
      ],
      "year": 2018
    },
    {
      "title": "Deep neural network improves fracture detection by clinicians",
      "authors": [
        "R Lindsey",
        "A Daluiski",
        "S Chopra",
        "A Lachapelle",
        "M Mozer",
        "S Sicular"
      ],
      "year": 2018,
      "doi": "10.1073/pnas.1806905115"
    },
    {
      "title": "Real-time use of artificial intelligence in identification of diminutive polyps during colonoscopy",
      "authors": [
        "Y Mori",
        "S-E Kudo",
        "M Misawa",
        "Y Saito",
        "H Ikematsu",
        "K Hotta"
      ],
      "year": 2018,
      "doi": "10.7326/m18-0249"
    },
    {
      "title": "An artificial intelligence platform for the multihospital collaborative management of congenital cataracts",
      "authors": [
        "E Long",
        "H Lin",
        "Z Liu",
        "X Wu",
        "L Wang",
        "J Jiang"
      ],
      "year": 2017,
      "doi": "10.1038/s41551-016-0024"
    },
    {
      "title": "Rationale and design of a large-scale, app-based study to identify cardiac arrhythmias using a smartwatch: The Apple Heart Study",
      "authors": [
        "M Turakhia",
        "M Desai",
        "H Hedlin",
        "A Rajmane",
        "N Talati",
        "T Ferris"
      ],
      "year": 2019
    },
    {
      "title": "Diagnostic efficacy and therapeutic decision-making capacity of an artificial intelligence platform for childhood cataracts in eye clinics: a multicentre randomized controlled trial",
      "authors": [
        "H Lin",
        "R Li",
        "Z Liu",
        "J Chen",
        "Y Yang",
        "H Chen"
      ],
      "year": 2019,
      "doi": "10.1016/j.eclinm.2019.03.001"
    },
    {
      "title": "Randomised controlled trial of WISENSE, a real-time quality improving system for monitoring blind spots during esophagogastroduodenoscopy",
      "authors": [
        "L Wu",
        "J Zhang",
        "W Zhou",
        "P An",
        "L Shen",
        "J Liu"
      ],
      "year": 2019,
      "doi": "10.1136/gutjnl-2018-317366"
    },
    {
      "title": "Real-time automatic detection system increases colonoscopic polyp and adenoma detection rates: a prospective randomised controlled study",
      "authors": [
        "P Wang",
        "T Berzin",
        "Jrg Brown",
        "S Bharadwaj",
        "A Becq",
        "X Xiao"
      ],
      "year": 2019,
      "doi": "10.1136/gutjnl-2018-317500"
    },
    {
      "title": "Automated deep-neural-network surveillance of cranial images for acute neurologic events",
      "authors": [
        "J Titano",
        "M Badgeley",
        "J Schefflein",
        "M Pain",
        "A Su",
        "M Cai"
      ],
      "year": 2018
    },
    {
      "title": "Computerised interpretation of fetal heart rate during labour (INFANT): a randomised controlled trial",
      "authors": [
        "P Brocklehurst",
        "D Field",
        "K Greene",
        "E Juszczak",
        "R Keith",
        "S Kenyon"
      ],
      "year": 2017,
      "doi": "10.1016/s0140-6736(17)30568-8"
    },
    {
      "title": "Developing and evaluating complex interventions: an introduction to the new Medical Research Council guidance",
      "authors": [
        "P Craig",
        "P Dieppe",
        "S Macintyre",
        "S Michie",
        "I Nazareth",
        "M Petticrew"
      ],
      "year": 2009,
      "doi": "10.1093/acprof:oso/9780199563623.003.012"
    },
    {
      "title": "Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD)",
      "authors": [
        "G Collins",
        "J Reitsma",
        "D Altman",
        "Kgm Moons"
      ],
      "year": 2015,
      "doi": "10.1161/circulationaha.114.014508"
    },
    {
      "title": "Reporting of artificial intelligence prediction models",
      "authors": [
        "G Collins",
        "Kgm Moons"
      ],
      "year": 2019
    },
    {
      "title": "With an eye to AI and autonomous diagnosis",
      "authors": [
        "P Keane",
        "E Topol"
      ],
      "year": 2018,
      "doi": "10.1038/s41746-018-0048-y"
    },
    {
      "title": "The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets",
      "authors": [
        "T Saito",
        "M Rehmsmeier"
      ],
      "year": 2015,
      "doi": "10.1371/journal.pone.0118432"
    },
    {
      "title": "Making machine learning models clinically useful",
      "authors": [
        "N Shah",
        "A Milstein",
        "Bagley Phd"
      ],
      "year": 2019,
      "doi": "10.1001/jama.2019.10306"
    },
    {
      "title": "Extensions to decision curve analysis, a novel method for evaluating diagnostic tests, prediction models and molecular markers",
      "authors": [
        "A Vickers",
        "A Cronin",
        "E Elkin",
        "M Gonen"
      ],
      "year": 2008
    },
    {
      "title": "Deep learning: a critical appraisal",
      "authors": [
        "G Marcus"
      ],
      "year": 2019
    },
    {
      "title": "Rethinking clinical prediction: why machine learning must consider year of care and feature aggregation",
      "authors": [
        "B Nestor",
        "Mba Mcdermott",
        "G Chauhan",
        "T Naumann",
        "M Hughes",
        "A Goldenberg"
      ],
      "year": 2018
    },
    {
      "title": "A nonparametric updating method to correct clinical prediction model drift",
      "authors": [
        "S Davis",
        "R Greevy",
        "C Fonnesbeck",
        "T Lasko",
        "C Walsh",
        "M Matheny"
      ],
      "year": 2019,
      "doi": "10.1093/jamia/ocz127"
    },
    {
      "title": "Explaining the Predictions of Any Classifier",
      "authors": [
        "M Ribeiro",
        "S Singh",
        "C Guestrin"
      ],
      "year": 2016,
      "doi": "10.18653/v1/n16-3020"
    },
    {
      "title": "Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition",
      "authors": [
        "J Winkler",
        "C Fink",
        "F Toberer",
        "A Enk",
        "T Deinlein",
        "R Hofmann-Wellenhof"
      ],
      "year": 2019,
      "doi": "10.1001/jamadermatol.2019.1735"
    },
    {
      "title": "Deep learning predicts hip fracture using confounding patient and healthcare variables",
      "authors": [
        "M Badgeley",
        "J Zech",
        "L Oakden-Rayner",
        "B Glicksberg",
        "M Liu",
        "W Gale"
      ],
      "year": 2019
    },
    {
      "title": "Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study",
      "authors": [
        "J Zech",
        "M Badgeley",
        "M Liu",
        "A Costa",
        "J Titano",
        "E Oermann"
      ],
      "year": 2018
    },
    {
      "title": "A new framework to enhance the interpretation of external validation studies of clinical prediction models",
      "authors": [
        "Tpa Debray",
        "Y Vergouwe",
        "H Koffijberg",
        "D Nieboer",
        "E Steyerberg",
        "Kgm Moons"
      ],
      "year": 2015
    },
    {
      "title": "Design characteristics of studies reporting the performance of artificial intelligence algorithms for diagnostic analysis of medical images: results from recently published papers",
      "authors": [
        "D Kim",
        "H Jang",
        "K Kim",
        "Y Shin",
        "S Park"
      ],
      "year": 2019
    },
    {
      "title": "There is a blind spot in AI research",
      "authors": [
        "K Crawford",
        "R Calo"
      ],
      "year": 2016
    },
    {
      "title": "Big Data's Disparate Impact",
      "authors": [
        "S Barocas",
        "A Selbst"
      ],
      "year": 2016,
      "doi": "10.2139/ssrn.2477899"
    },
    {
      "title": "Why Is My Classifier Discriminatory?",
      "authors": [
        "I Chen",
        "F Johansson",
        "D Sontag"
      ],
      "year": 2018
    },
    {
      "title": "Reply to \"Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists",
      "authors": [
        "H Haenssle",
        "C Fink",
        "A Rosenberger",
        "L Uhlmann"
      ],
      "year": 2019,
      "doi": "10.1093/annonc/mdz015"
    },
    {
      "title": "Association between race/ethnicity and survival of melanoma patients in the United States over 3 decades",
      "authors": [
        "M Ward-Peterson",
        "J Acu\u00f1a",
        "M Alkhalifah",
        "A Nasiri",
        "E Al-Akeel",
        "T Alkhaldi"
      ],
      "year": 2016,
      "doi": "10.1097/md.0000000000003315"
    },
    {
      "title": "Adversarial attacks on medical machine learning",
      "authors": [
        "S Finlayson",
        "J Bowers",
        "J Ito",
        "J Zittrain",
        "A Beam",
        "I Kohane"
      ],
      "year": 2019
    },
    {
      "title": "SMART on FHIR: a standards-based, interoperable apps platform for electronic health records",
      "authors": [
        "J Mandel",
        "D Kreda",
        "K Mandl",
        "I Kohane",
        "R Ramoni"
      ],
      "year": 2016
    },
    {
      "title": "Caveats for the use of operational electronic health record data in comparative effectiveness research",
      "authors": [
        "W Hersh",
        "M Weiner",
        "P Embi",
        "J Logan",
        "Pro Payne",
        "E Bernstam"
      ],
      "year": 2013
    },
    {
      "title": "Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD): FDA",
      "year": 2019
    },
    {
      "title": "Building Explainable Artificial Intelligence Systems",
      "authors": [
        "M Core",
        "H Lane",
        "M Van Lent",
        "D Gomboc",
        "S Solomon",
        "M Rosenberg"
      ],
      "year": 2006,
      "doi": "10.21236/ada459166"
    },
    {
      "title": "What do we need to build explainable AI systems for the medical domain?",
      "authors": [
        "A Holzinger",
        "C Biemann",
        "C Pattichis"
      ],
      "year": 2019
    },
    {
      "title": "Explainable artificial intelligence: understanding, visualizing and interpreting deep learning models",
      "authors": [
        "W Samek",
        "T Wiegand",
        "K-R M\u00fcller"
      ],
      "year": 2019,
      "doi": "10.1007/978-3-030-28954-6_1"
    },
    {
      "title": "Characterization of symbolic rules embedded in deep DIMLP networks: a challenge to transparency of deep learning",
      "authors": [
        "G Bologna",
        "Y Hayashi"
      ],
      "year": 2017,
      "doi": "10.1515/jaiscr-2017-0019"
    },
    {
      "title": "A short account of Knowledge Engineering",
      "authors": [
        "J Fox"
      ],
      "year": 1984,
      "doi": "10.1017/s0269888900000424"
    },
    {
      "title": "A review of explanation methods for Bayesian networks",
      "authors": [
        "C Lacave",
        "F D\u00edez"
      ],
      "year": 2002,
      "doi": "10.1017/s026988890200019x"
    },
    {
      "title": "Towards a rigorous science of interpretable machine learning",
      "authors": [
        "F Doshi-Velez",
        "B Kim"
      ],
      "year": 2019,
      "doi": "10.1007/978-3-319-98131-4_1"
    },
    {
      "title": "Diagnostic accuracy of digital screening mammography with and without computer-aided detection",
      "authors": [
        "C Lehman",
        "R Wellman",
        "Dsm Buist",
        "K Kerlikowske",
        "Ana Tosteson",
        "D Miglioretti"
      ],
      "year": 2015,
      "doi": "10.1001/jamainternmed.2015.5231"
    },
    {
      "title": "Drug-drug interactions that should be non-interruptive in order to reduce alert fatigue in electronic health records",
      "authors": [
        "S Phansalkar",
        "H Van Der Sijs",
        "A Tucker",
        "A Desai",
        "D Bell",
        "J Teich"
      ],
      "year": 2013
    },
    {
      "title": "Using a deep learning algorithm and integrated gradients explanation to assist grading for diabetic retinopathy",
      "authors": [
        "R Sayres",
        "A Taly",
        "E Rahimy",
        "K Blumer",
        "D Coz",
        "N Hammel"
      ],
      "year": 2019
    },
    {
      "title": "Deep Learning for Identifying Metastatic Breast Cancer",
      "authors": [
        "D Wang",
        "A Khosla",
        "R Gargeya",
        "H Irshad",
        "A Beck"
      ],
      "year": 2016
    },
    {
      "title": "People and AI Guidebook",
      "authors": [
        "Google"
      ],
      "year": 2019
    }
  ],
  "num_references": 98
}
