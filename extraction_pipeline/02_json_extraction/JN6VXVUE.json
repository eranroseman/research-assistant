{
  "paper_id": "JN6VXVUE",
  "title": "A new method for computing the projection median, its influence curve and techniques for the production of projected quantile plots",
  "abstract": "This article introduces a new formulation of, and method of computation for, the projection median. Additionally, we explore its behaviour on a specific bivariate set up, providing the first theoretical result on form of the influence curve for the projection median, accompanied by numerical simulations. Via new simulations we comprehensively compare our performance with an established method for computing the projection median, as well as other existing multivariate medians. We focus on answering questions about accuracy and computational speed, whilst taking into account the underlying dimensionality. Such considerations are vitally important in situations where the data set is large, or where the operations have to be repeated many times and some well-known techniques are extremely computationally expensive. We briefly describe our associated R package that includes our new methods and novel functionality to produce animated multidimensional projection quantile plots, and also exhibit its use on some high-dimensional data examples.",
  "year": 2020,
  "date": "2020-05-07",
  "journal": "Journal of the American Statistical Association",
  "publication": "Journal of the American Statistical Association",
  "authors": [
    {
      "forename": "Fan",
      "surname": "Chen",
      "name": "Fan Chen",
      "affiliation": "1  School of Mathematics , University of Bristol , Fry Building , Woodland Road , Bristol , England , United Kingdom , \n\t\t\t\t\t\t\t\t School of Mathematics \n\t\t\t\t\t\t\t\t University of Bristol \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Fry Building Woodland Road \n\t\t\t\t\t\t\t\t\t Bristol \n\t\t\t\t\t\t\t\t\t England United Kingdom"
    },
    {
      "forename": "Guy",
      "surname": "Nason",
      "name": "Guy Nason",
      "affiliation": "2  Dept. Mathematics , Imperial College , London , England , United Kingdom \n\t\t\t\t\t\t\t\t Dept. Mathematics \n\t\t\t\t\t\t\t\t Imperial College \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t London \n\t\t\t\t\t\t\t\t\t England United Kingdom",
      "email": "g.nason@imperial.ac.uk",
      "orcid": "0000-0002-4664-3154"
    },
    {
      "affiliation": "Huazhong University of Science and Technology , CHINA \n\t\t\t\t\t\t\t\t Huazhong University of Science and Technology \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t CHINA"
    }
  ],
  "doi": "https://doi.org/10.13039/501100000266",
  "sections": [
    {
      "title": "Introduction: Overview of multivariate medians",
      "text": "The median is an estimator of location that is robust, i.e. not heavily influenced by outlying values, which are, loosely speaking, points that are far from the main body of the data. Let x = (x 1 , . . ., x k ) T be a mutually independent and identically distributed (i.i.d.) sample of length k 2 N from a univariate distribution with distribution function F. The univariate population median functional M(F) is\n\nThere are several equivalent definitions of the univariate median that all yield same unique value of true median \u03bc for a distribution F with a bounded and continuous density f(\u03bc) at \u03bc.\n\nFor multivariate data there is no natural ordering of the data to enable the choice of the middle observation in the same way as for one-dimensional data. However, several different multivariate median concepts have been developed that retain some characteristics of the univariate median. For example, an early extension of the multivariate median was suggested by Hayford  [1] , which is simply the component-wise median, also known as the vector of marginal medians. The spatial median, also known as the L 1 median  [2, 3] , and Tukey's median  [4]  are two other popular variants. Oja's median  [5]  provides an alternative to the spatial median, but it is known to be more computationally expensive than other choices. These, and others, are reviewed in  [6] [7] [8] . We briefly review some of them here next, not least as we use them later in our simulation study."
    },
    {
      "title": "Component-wise median",
      "text": "Let X = (x 1 , . . ., x k ) T be an n-dimensional i.i.d. sample with distribution function F : R n ! R. We assume that the n marginal distributions have bounded densities f 1 (\u03bc 1 ), . . ., f n (\u03bc n ) at the uniquely defined marginal medians \u03bc = (\u03bc 1 , . . ., \u03bc n ). The component-wise median, also known as the marginal sample median, M C \u00f0X\u00de 2 R n minimises\n\nthe sum of component-wise distances over m 2 R n , where m = (m 1 , . . ., m n ). The corresponding population functional, M C (F), for the vector of population medians minimises"
    },
    {
      "title": "Spatial median",
      "text": "The spatial median M S (X), also known as the L 1 median, minimises\n\nover m 2 R n , where jjmjj 2 \u00bc P n i\u00bc1 m 2 i is the (squared) Euclidean norm. The corresponding functional spatial median, M S (F), minimises E F fjjx \u00c0 mjj \u00c0 jjxjjg: \u00f05\u00de"
    },
    {
      "title": "Oja's median",
      "text": "Let X = (x 1 , . . ., x k ) T be an i.i.d. sample in R n with distribution function F : R n ! R. The volume of the n-variate simplex determined by the n + 1 vertices (m 1 , . . ., m n+1 ) is\n\nThe Oja median, M O (X), minimises\n\nn V\u00f0x i 1 ; . . . ; x i n ; m\u00de; \u00f07\u00de over m 2 R n . The corresponding functional M O (F) minimises E F fV\u00f0x i 1 ; . . . ; x i n ; m\u00deg:"
    },
    {
      "title": "Tukey's median",
      "text": "Let X = (x 1 , . . ., x k ) T be an i.i.d. sample of size k in R n with distribution function F : R n ! R.\n\nLet H be the class of all closed half spaces in R n . For each H 2 H, define the empirical distribution\n\nwhere I is the usual indicator function. Then, define the depth, D(\u03bc), of a point \u03bc 2 R n within the dataset, to be the infinum of F\u00f0H\u00de, that is taken over all closed half spaces H for which \u03bc 2 H. Tukey's median is defined as the set of points \u03bc of maximal depth."
    },
    {
      "title": "The projection median",
      "text": "This section introduces our new method for computing the projection median, yamm. We prove that yamm is equivalent to the projection median, as defined by Durocher and Kirkpatrick  [9]  in R 2 and then generalised to higher dimensions by Basu et al.  [10] . We also explore, theoretically and numerically, the statistical behaviour of yamm using a mixture of two bivariate normal distributions."
    },
    {
      "title": "Review of the projection median",
      "text": "2.1.1 Projection median in R 2 . Let X be a multiset of points in R 2 and \u03b8 2 [0, 2\u03c0) be an angle. Let X \u03b8 denote the multiset defined by the projection of X onto the unit vector u \u03b8 = (cos \u03b8, sin \u03b8), so\n\nwhere h\ufffdi denotes the usual inner product.\n\nThe projection median of a non-empty finite set X with points in R 2 is\n\nwhere med\u00f0X y \u00de 2 R 2 is the median of the projection of X onto the line through the origin, parallel to u \u03b8 ."
    },
    {
      "title": "Generalisation of the projection median.",
      "text": "Given a fixed positive integer, n \ufffd 2, and a finite set of points X in R n , the n-dimensional projection median of X is\n\nwhere X n\u00c0 1 \u00bc fx 2 R n : jjxjj \u00bc 1g is the unit n-dimensional hypersphere, med(X a) is the median of the projection of X onto the line through the origin parallel to a, and f is the normalised uniform measure over X n-1 . Hence, for a point x = (x 1 , x 2 , . . ., x n )2X n-1 , the n-dimensional spherical coordinates are given by\n\nwhere each angle \u03b8 1 , \u03b8 2 , . . ., \u03b8 n-2 has a range of \u03c0 and \u03b8 n-1 has range of 2\u03c0. Also, the normalised uniform measure f over X n-1 is given by\n\nwhere d X n\u00c0 1 V \u00bc sin n\u00c0 2 y 1 sin n\u00c0 3 y 2 . . . sin y n\u00c0 2 dy 1 dy 2 . . . dy n\u00c0 1 is the volume element of the (n -1)-sphere. Basu et al.  [10]  proved that the projection median has a breakdown point of 1/2 for all n \ufffd 2."
    },
    {
      "title": "Yet another multivariate median (Yamm)",
      "text": "Let a be a n \u00d7 1 projection vector of unit length, 1 k be the k \u00d7 1 vector of ones and \u03bc a shift vector of length n. Let y be the projection of X onto a after X has been shifted by \u03bc:\n\nwhere y 2 R k . The univariate median m of the projected points y is m X \u00f0\u03bc; a\u00de \u00bc m\u00f0y\u00de: \u00f016\u00de\n\nNow define the integral\n\nThe yamm estimator of location for X is\n\nEqs (  17 ) and (  18 ) illustrate the rationale behind yamm. Intuitively, if the shift vector \u03bc is far away from the true 'middle' of the dataset, then the magnitude of m X (\u03bc, a), as well as the integral M X, m (\u03bc), will be large. By contrast, a smaller m X (\u03bc, a) can be obtained when the \u03bc is moving closer to the true 'middle' of the data set.\n\nInstead of computing the squared value of m X (\u03bc, a) for the integral, we also considered the absolute value as an alternative. However, this leads to similar numerical results.\n\nExample. We now generate two polar plots of the absolute value of m X (\u03bc, a), when \u03bc is both close to, and far away, from the true median, respectively. A random two-dimensional dataset with k = 100 points was generated, whose Tukey's median computed as  (2.78, 8.16 ). Here, the Tukey median is to be interpreted as a 'sensible' middle of the data set. The shift vector \u03bc is set to be (2.2, 8) and (2, 7.5) respectively, and for each plot, two thousand random projections were used to calculate the univariate median m X (\u03bc, a), using methods to be explained in Section 2.4. Fig  1  shows that when \u03bc is near the Tukey's median, the magnitude of each m X (\u03bc, a) is less than 0.65, while a larger value, ranging from 0 to 1.2, is shown in the figure when \u03bc is far away from the median. Overall, when integrated the quantity involving the \u03bc is closer to the Tukey median it gives a smaller result.\n\nThe projection median and yamm definitions seem similar, as both project the multiset onto the line passing through the origin, and then take the median. However, the projection median integrates med(X a ) directly over the unit hypersphere in R n , whereas yamm minimises the objective function M X;m \u00f0\u03bc\u00de 2 R over the shift vector \u03bc. Despite these differences, the following theorem shows that the projection median and yamm are identical. Theorem. For any finite multiset X \ufffd R n with n \ufffd 2, yamm is equivalent to the projection median.\n\nFor the proof of the theorem, see S1 Appendix."
    },
    {
      "title": "Yamm behaviour on a bivariate normal mixture",
      "text": "To gain insight about the theoretical behaviour of yamm we study the case of yamm applied to a mixture of two bivariate normals, where one is thought of as the bulk and the other as the outlier of the distribution. Such a setup enables us to evaluate the robustness of yamm. We numerically and theoretically assess the influence curve when moving the outlier far from the bulk."
    },
    {
      "title": "Bivariate mixture setup.",
      "text": "Let X 1 \ufffd N 2 \u00f0n 1 ; S 1 \u00de and X 2 \ufffd N 2 \u00f0n 2 ; S 2 \u00de be independent bivariate normal random variables, where X 1 = (X 11 , X 12 ) T , X 2 = (X 21 , X 22 ) T with mean vector \u03bd 1 = (\u03bd 11 , \u03bd 12 ) T and \u03bd 2 = (\u03bd 21 , \u03bd 22 ) T . Let R(\u03b8) be a rotation matrix with angle \u03b8 given by\n\nWe are interested in the first row of this matrix, which describes the projection onto direction \u03b8.\n\nT is a shift vector mentioned in  (15) . Basic multivariate theory shows that\n\nThe mixture distribution that we study is\n\nwhere f X i is the density of X i , and \ufffd 2 [0, 1], is typically small. Here, f X 1 is considered to be the bulk of the distribution and f X 2 the outlier."
    },
    {
      "title": "Projected distribution.",
      "text": "Based on the bivariate setup above, the projected distribution is\n\nwhere s 1 ; s 2 ; s 2 1 ; s 2 2 are as above and \u03d5 is the standard normal density. The distribution function of the projected Y(\u03b8) is\n\nwhere F is the standard normal distribution function. We require the median of the projected distribution, i.e. find y m \u00f0\ufffd; y; s 1 ; s\n\nFinding an analytic exact solution for y m is difficult. Hence, we will simplify the problem and assume that S 1 = S 2 = I 2 , the identity matrix. Since R(\u03b8) is an orthogonal matrix, this means that s 2 1 \u00bc s 2 2 \u00bc 1 and Eq  (25)  becomes\n\nFor small \ufffd, we know that the median should be close to the median of the bulk, so the median of F Y should be close to s 1 , the median of the first component of the mixture in Eq  (27) .\n\n2.3.3 Theoretical approximation of yamm on the mixture. We derive a theoretically based approximation to the empirical influence function. We proceed by using a Taylor series expansion of F Y (y) around s 1 , the quantity we know is close to our median:\n\nwhere Erfc \u00f0y\u00de \u00bc 2p \u00c0 1=2 R 1 y e \u00c0 t 2 dt: When y is close to s 1 , Eq (  28 ) is approximately equal to 1/2 when \ufffd is small, which is the behaviour we expect.\n\nTo find an approximation to the median we solve F Y {y m (\u03b8)} = 1/2. Ignoring remainders, subtracting 1/2 off both sides of Eq  (28)  gives\n\nand then\n\nNow using\n\nFor small \ufffd the denominator is close to 1. From Eqs (  21 ) and (  22 ), we can write:\n\nwhere \u03b4 1 = \u03bd 21 -\u03bd 11 and \u03b4 2 = \u03bd 22 -\u03bd 12 . Thus\n\nAccording to Eq  (17) , our job is to find the optimal \u03bc\n\nThe integrand involves the standard normal distribution function, which is tricky to handle analytically. Hence, we use the approximation, \u03d5(z)\ufffd(1 + cos z)/2\u03c0, for -\u03c0 < z < \u03c0, for the standard normal density  [11] , which enables the following proposition.\n\nProposition. Let X 1 = (X 11 , X 12 ) T and X 2 = (X 21 , X 22 ) T . Suppose that X 1 \ufffd N 2 \u00f0\u03bd 1 ; S 1 \u00de and X 2 \ufffd N 2 \u00f0\u03bd 2 ; S 2 \u00de independently, where \u03bd 1 = (\u03bd 11 , \u03bd 12 ) T and \u03bd 2 = (\u03bd 21 , \u03bd 22 ) T , respectively. Let the mixture, W, of X 1 and X 2 be\n\nAn approximation of the yamm estimator,\n\n. The approximation we use is valid whenever jR cos \u00f0y \u00fe a\u00dej < ffi ffi ffi 2 p p, where \u03b8 is the projection direction when computing yamm. This inequality is true for all \u03b8 whenever R < ffi ffi ffi 2 p p. Intuitively, the approximation in the Proposition works whenever the two cluster means are close enough together, i.e. when R 2\n\nIn particular, when \u03bd 11 = \u03bd 21 or \u03bd 12 = \u03bd 22 (i.e. when one of the \u03b4 i = 0, i = 1, 2), we can form a more accurate approximation. This is because the approximation for the standard normal distribution function, \u03d5(z)\ufffd(1 + cos z)/2\u03c0, is no longer required to find the optimal \u03bc\n\nT minimising Eq  (35) . Without loss of generality, let \u03bd 1 = (\u03bd 11 , \u03bd 12 ) T = (0, 0) T and \u03bd 2 = (\u03bd 21 , \u03bd 22 ) T = (0, d) T , we obtain the yamm estimator as follows\n\nwhere BesselI[n, z] is the modified Bessel function of the first kind, sometimes denoted I n (z).\n\nFor the proof of the proposition, see S2 Appendix."
    },
    {
      "title": "2.3.4",
      "text": "The yamm influence curve on the mixture. This section numerically computes and plots yamm for the case where \ufffd = 0.05, T for d 2 R. We explore how yamm varies as d increases from 0 to 10 in steps of 0.2. If yamm is robust, then it should increase with d, but plateau beyond a certain point.\n\nFor each value d we estimate yamm as the mean over five hundred bivariate mixture realizations, with two thousand projections involved for each yamm computation, using methods described below in Section 2. The solid red line in Fig  2  shows our theoretical approximation of the yamm influence curve with the more specific setup, where \u03bc \ufffd follows Eq (37). Under this approximation, the influence curve closely follows the numerically computed crosses. On the other hand, the solid blue line is the approximation of the yamm under the more general setting of Eq (36), which exhibits poor approximation after d > 4.5, although it performs reasonably well when the inter-cluster mean distance 0 < d < 4.5, and does not plateau. This is because, in the setup, \u03b4 1 = d, \u03b4 2 = 0, and\n\n. However, the specific setup approximation of yamm obviously does not work for arbitrary values of \u03bd 1 and \u03bd 2 , whereas the general approximation gives a good theoretical idea of the yamm influence curve when the two means of the clusters are close enough together. [12]  can be used to compute an approximation of the projection median by"
    },
    {
      "title": "Projection median and yamm computation 2.4.1 Projection median computation. A simple Monte Carlo integration",
      "text": "where J represents the number of projections used, and fa j g J j\u00bc1 is a set of random, independently-drawn, unit length n-vectors over X n-1 .\n\nCalculating approximation of Eq (38) is relatively straightforward, but a large value of J is required to ensure accuracy. Another approach computes the projection median directly from the definition in Eq  (12) , using the spherical coordinates illustrated in Eq  (13) , where the integral can be obtained by the trapezoidal rule. For example, in the two-dimensional case, we apply the trapezoidal rule once on Eq  (11) . In the three-dimensional case, we have to apply the trapezoidal rule twice for the double integral, and so on. This direct approach is easy to implement when our dataset has a low dimension, but excessive work is required in not that many higher dimensions, even with, e.g. n = 10."
    },
    {
      "title": "Computing yamm.",
      "text": "To compute an approximation to yamm, we can also use Monte Carlo integration together with an optimiser. Let J 2 N be the number of projections, fa j g J j\u00bc1 be a set of independent random unit length n-vectors, an estimator for M X, m (\u03bc) is given by\n\nWe then numerically minimise MX;m \u00f0\u03bc\u00de over \u03bc to obtain our estimated location measure, using the BFGS optimization method  [13] [14] [15] [16] . BFGS is a quasi-Newton algorithm searching for a stationary point of a function via local quadratic approximation. Parallel versions such as optimParallel exist as easy to use packages in R.\n\nWith reasonable starting values, such as the mean or other multivariate medians, yamm typically provides accurate results with a considerably smaller number of projections than used by the Monte Carlo projection median method mentioned above.\n\nIn conclusion, projection median computation via the trapezoidal rule is fast and accurate in low dimensions, but increasingly onerous in higher dimensions, as progressively more multidimensional integration is required. For higher dimensions, we prefer the Monte Carlo method and prefer yamm over the projection median as it does not require such a large number of projections, particularly if the optimiser is given a good starting solution.\n\nOverall, approximating the projection median by the trapezoidal rule is a good choice in R 2 and R 3 , and either of the other two methods can be used in higher dimensions."
    },
    {
      "title": "Empirical performance for different medians",
      "text": "This section reviews the theoretical computational complexity for a variety of medians and computes some running times for real implementations of several medians computed in R. We then present some results for accuracy of estimation for these medians."
    },
    {
      "title": "Computational complexity and empirical speed",
      "text": "For a dataset in R n with k observations, the computational complexity for the Spatial median is O(nk)  [17] , which is the same for the exact computation of the component-wise median. The projection median can be obtained in O(k 4/3 log 1+\ufffd k) time in R 2  [9] , and O(k\n\nn /(n+1)}+\ufffd] time is required to compute the projection median, where \u03b4 n = (4n -3) -n and \ufffd is a fixed small constant. Several algorithms for other multivariate medians have been developed or the bivariate case. The current best algorithms for Oja's and Liu's medians require O(k log 3 k) and O(k 4 ) time, respectively  [18] , whereas that for the fastest bivariate Tukey median is O(k log 3 k)  [19] . The calculation of these three multivariate medians in higher dimensions is more complicated and approximate computation is often preferred/required.\n\nTo provide empirical assessment of the real computation speed, we apply several R software medians to simulated data. There are several R functions using different algorithms to compute one median. For example, spatial.median from the library ICSNP estimates the median with the algorithm developed by Vardi and Zhang  [20] , while Gmedian developed by Cardot et al.  [21]  is faster but, perhaps, less accurate. In addition, l1median  [22]  from library pcaPP and med from depth also provide opportunities to compute the spatial median.\n\nHence, after some experiments, we choose the best function (evaluated in terms of speed and accuracy) for each multivariate median in R 2 and R 3 shown in Table  1 . Much of the software for multivariate medians in R only works in low numbers of dimensions.\n\nThe med function can only calculate the bivariate Liu's median, which is considerably more challenging in higher dimensions. The calculation of Tukey's median is exact in one and two dimensions, and approximate in higher dimensions. We use the approximate Tukey's median computation in the med function, due to numerical errors that sometimes surface when using the exact algorithm. For Oja's median, the approximate method (evolutionary algorithm) is used instead of the exact one, as it is faster and can deal with high dimensions.\n\nTable  2  displays mean computation times and their standard deviations across 1000 simulated datasets from the two-dimensional Laplace distribution with different numbers of observations (k) for each set. The results are produced by running R on a single core of an Intel i7-8750h processor with 2.20 GHz base clock using 16Gb RAM. For small k, Liu's median is fastest, but its speed is not as fast as others for higher k. In this experiment, Oja's median is the slowest for small k values, but its speed does not appear to be particularly sensitive to k. Hence, its speed is faster than Tukey's median when k = 200. The projection median is one of the quickest when k is below 100, while for large k values, the component-wise median and the Spatial median are faster.\n\nThe results in Table  2  are produced by only one possible R function for one median. However, other functions can be used. For example, the med function from the depth package can also be used to calculate the spatial median and provides accurate answers. It is extremely\n\nTable 1. R functions used for analysing different multivariate medians. Median Function Package Source Spatial l1median pcaPP [22] CWmed med depth -Liu's med depth [23] Tukey's med depth [24] [25] Oja's ojaMedianEvo OjaNP [26] Projection PmedTrapz Yamm Ours  https://doi.org/10.1371/journal.pone.0229845.t001 Table 2. Mean and standard deviation (s.d.) of the operation time (\u00d710 -5 ) in seconds for data in R 2 . Median k = 10 k = 25 k = 50 k = 100 k = 200 Spatial mean 27 28 30 29 28 s.d. 44 45 57 45 45 Component-wise mean 24 21 25 25 24 s.d. 42 41 43 43 43 Liu's mean 3 6 14 49 190 s.d. 18 24 35 66 250 Tukey's mean 67 210 510 970 1890 s.d. 47 28 40 56 100 Oja's mean 1430 1400 1460 1410 1410 s.d. 410 190 270 190 160 Projection mean 7 12 18 31 60 s.d. 26 32 39 46 49  https://doi.org/10.1371/journal.pone.0229845.t002\n\nfast for small k and lower dimensions, but it becomes slower than l1median for larger k.\n\nHence, we use l1median to compute the spatial median, whose performance for small k is also good."
    },
    {
      "title": "Mean squared error for some medians",
      "text": "We assess the accuracy of some of the medians via empirical mean squared error. If X is an estimator in R n with respect to the unknown parameter \u03bc 2 R n , then the mean squared error is\n\nwhere n \u00c0 1 jj X \u00c0 \u03bcjj 2 2 represents the squared Euclidean distance between X and \u03bc, normalized by the vector length. Smaller MSE \u00f0 X\u00de values are better.\n\nTable  3  shows MSE results based on the same simulations as used for Table  2 . Not surprisingly, for this long-tailed data, all medians perform better than the sample mean. The spatial median and the projection median have smaller mean squared error, the latter performing better for small k values. On the other hand, Liu's median always produces a very high mean squared error.\n\nConclusion. Based on these simulations, for the R functions listed in Table  1 , the spatial and projection medians always have the lowest mean squared error, but also fast running speeds. Although Liu's median has the shortest computation time, for small k, it is the most inaccurate, and its computation time becomes long for large datasets. Similarly, the component-wise median is fast, even when k increases, but it has a large mean squared error. Hence, the spatial and projection medians are good choices when computing two-dimensional robust measures of location in this case, and the latter is preferred for small datasets. The computational results for high-dimensional simulations (n = 3, 5, 10) can be found in S1 Table."
    },
    {
      "title": "2D projection median computation functions",
      "text": "The R package DurocherProjectionMedian can be downloaded from Github at  https://github.com/12ramsake/DurocherProjectionMedian .\n\nThe DurocherProjectionMedian package provides functions to compute the projection median via the Monte Carlo integration method using projectionMedianMC)  [27]  and an exact method for two dimensions proposed by Ramsay  [28]  using projection-Median2D. Tables  4  and  5  show the performance of the different functions computing the two-dimensional projection median of 1000 simulated datasets from the Laplace distribution with different k.\n\nTable 3. Mean squared error (\u00d710 -2 ) for data as in Table 2. Location Estimator k = 10 k = 25 k = 50 k = 100 k = 200 Spatial 67 21 9.7 4.6 2.3 Component-wise 74 26 12.0 5.7 2.9 Liu's 110 31 14.0 6.3 3.2 Tukey's 73 21 10.0 4.8 2.3 Oja's 75 22 11.0 5.6 3.2 Projection 66 21 9.8 4.7 2.3 Mean 110 39 20.0 9.9 5.0  https://doi.org/10.1371/journal.pone.0229845.t003\n\nFor the Monte Carlo Integration method, when k is small (e.g. under 150 in R 2 ), the computation time of projectionMedianMC is longer than our PmedMCInt under the same number of projections in both R 2 and high dimensions, whereas both implementations have almost the same MSE.\n\nAlthough the projectionMedian2D provides a slightly smaller MSE, its running time is slow. Our PmedTrapz is faster and its MSE performance is comparable to projection-Median2D, and, hence, the former might be recommended as the best choice for R 2 ."
    },
    {
      "title": "The yamm R package",
      "text": "Our Yamm R package provides users with functions to compute the projection median according to the different methods mentioned in section 2.4. PmedMCInt computes the projection median using the Monte Carlo approximation; PmedTrapz uses the trapezoidal rule and currently, it is only valid in two and three dimensions; yamm computes the projection median using the Monte Carlo approximation to find the shift vector \u03bc minimising our objective function yamm.obj. The package also includes functions Plot2dMedian and Plot2dMedian to plot different multivariate medians for data in both R 2 and R 3 . Most functions in our package are implemented internally using C code. This section provides some brief illustrations of the use of Yamm."
    },
    {
      "title": "Yamm projection medians",
      "text": "The function PmedMCInt computes the projection median for any multivariate data, x, by invoking PmedMCInt(x, nprojs = 20000) Since this function uses Monte Carlo integration, we need to choose the number of projections J, which has a default value of 20000. Typically, a large J is required to obtain a stable\n\nTable 4. Mean and standard deviation (s.d.) of the operation time (\u00d710 -5 ) in seconds for different R functions to produce the projection median. k R Function 10 25 50 100 200 PmedTrapz mean 7 12 18 31 60 s.d. 26 32 39 46 49 projectionMedian2D mean 320 1020 3930 11640 44830 s.d. 50 99 420 970 2690 PmedMCInt mean 250 320 490 870 1670 s.d. 40 39 33 50 58 projectionMedianMC mean 930 970 1010 1130 1280 s.d. 49 57 65 60 55  https://doi.org/10.1371/journal.pone.0229845.t004 Table 5. Mean squared error (\u00d710 -3 ) for 1000 sets of data in R 2 generated from Laplace distribution. k R Function 10 25 50 100 200 PmedTrapz 656 207 98.2 47.1 23.2 projectionMedian2D 656 206 97.4 46.9 22.9 PmedMCInt 659 205 97.8 47.0 23.0 projectionMedianMC 659 205 97.6 47.0 23.0  https://doi.org/10.1371/journal.pone.0229845.t005\n\nanswer, which means the result will not change much if recomputed under the same conditions. This function returns the projection median estimate vector. The function PmedTrapz computes the projection median in R 2 and R 3 and is invoked by PmedTrapz(x, no.subinterval) PmedTrapz applies the trapezoidal rule once in R 2 and twice in R 3 on each entry of the vector med\u00f0X a \u00de, mentioned in section 2.1.2, and returns a vector of the projection median estimate.\n\nThe argument no.subinterval determines the number of subintervals for the trapezoidal rule. For the bivariate case the no.subinterval argument is a single number that controls the number of subdivisions for the one-dimensional integration; for the trivariate case the argument is a vector of length two that controls the number of subdivisions for the two integrals. In general, it is better to use at least 36 subintervals, which typically produces accurate results without excessive running time.\n\nMore subintervals may be appropriate for more complex datasets. For some unusual data sets it would be ideal to have a high resolution of the interval of integration in one particular region, and a relatively low resolution elsewhere, but this is beyond the scope of the current research. A small number of partitions, e.g. below 15, is not recommended for reasons of accuracy.\n\nThe yamm function is valid for data of any dimension. It uses an optimiser to provide another method to compute the projection median. The arguments are yamm(x, nprojs = 2000, reltol = 1e-06, xstart = l1median(x), opt.method = \"BFGS\", doabs = 0, full.results = FALSE).\n\nThe yamm function is a wrapper to minimise the the objective function yamm.obj, which uses the Monte Carlo method to approximate the squared or absolute value of the univariate median of the projection of the shifted data matrix. The nprojs argument controls the number of projections in the Monte Carlo approximation and doabs is an indicator, where 1 uses the absolute value of the univariate median and 0 forces the use of the squared value. The arguments reltol, xstart, opt.method are supplied directly to the R optimisation function optim: reltol is the tolerance for the optimiser, with default value of 10 -6 . Usually, we set a larger value (e.g. 10 -3 ) to this argument, which will reduce the running time, whilst maintaining accuracy. The argument opt.method controls the selection of optimisation methods, which can be chosen from any of the four options, \"BFGS\", \"Nelder-Mead\"  [29] , \"CG\"  [30] , \"L-BFGS-B\"  [31] , and \"SANN\"  [32] . The default choice \"BFGS\" is relatively fast and stable in our case. See the help page of the function optim in R for further details about the different optimisation methods. The xstart argument provides the initial value for the parameters to optimise over, which plays an important role in the function yamm. A good starting point will reduce the running time and provide a more accurate result, so we use the spatial median as the default value. Other multivariate medians could be used, but they need to be fast. If full. results = TRUE, the output of this function involves a list with components obtained from the optim function, otherwise, it returns a vector containing the multivariate median estimate."
    },
    {
      "title": "Some real examples",
      "text": "We now exhibit results for the projection medians applied to some real datasets. Our plots show different multivariate medians and the sample mean value for two simulated datasets in R 2 and R 3 , respectively, allowing the methods to be compared."
    },
    {
      "title": "Beetle data.",
      "text": "The famous beetle data  [33]  takes six measurements on 74 flea-beetles, with each belonging to one of three different species. We apply yamm and obtain the following output: yamm(beetle, nprojs = 1000, reltol = 1e-3, doabs = 0, full.results = TRUE)  [1]  180.19194 123.73920 49.97819 135.87913 13.62603 95.49062 $value [1] 5.585139 $counts function gradient 90 4 $convergence [1] 0 $message NULL The yamm results show that the optimiser executed 90 calls to the objective function yamm.obj and constructed 4 gradients. The par component contains the estimate of the yamm for the beetle data. These results are not that different from the output generated by PmedMCInt, which is PmedMCInt(beetle, nprojs = 100000) [1] 179.54428 124.72128 50.56934 137.47363 13.23372 94.80188\n\nFor the beetle data, we chose the number of projections in yamm to be 1000, while many more projections were required (e.g. 100000) in PmedMCInt to obtain a similar and consistent result; although yamm requires optimisation. Fewer projections for the function PmedM-CInt may lead inaccurate results for some components of the multivariate median. PmedTrapz is not valid in this six-dimensional case, but we will show that it has a similar output when computing projection median in two-and three-dimensions.\n\n4.2.2 Simulated Data in R 2 with three clusters. We now use the function Plot2dMedian in the package Yamm to generate and display different multivariate medians for the simulated data set clusters2d. This set contains three clusters, which are generated randomly from different independent normal distributions, and two outliers.\n\nHere, we display the three different estimates of the projection median. When computing other multivariate medians, we use functions from R packages listed in section 3."
    },
    {
      "title": "The muqie plot and some examples",
      "text": "As well as obtaining a robust location measure, we can use projections to provide information on the spread and configuration of the data. Obtaining true multivariate quantiles can be computationally challenging, and what we produce are not true multivariate quantiles, but they do enable us to gain useful understanding about multivariate data. The muqie (MUltivariate QuantIlE) plots are constructed as follows.\n\nFirst choose a unit-length direction vector, u. Then project our yamm-centred multivariate data onto u to obtain a univariate set. The muqie point, Q(\u03b1, u), is merely the vector u rescaled to have length equal to the \u03b1-quantile of the univariate set. A muqie plot is the collection of all muqie points, Q(\u03b1, u) over all unit-length direction vectors u. In practice, we construct our plot by choosing a number of directions and joining the points. The basic concept, and plots, are not new, Section 2 of Fraiman and Pateiro-Lopez  [34]  introduces the concept based on mean-centred data and is related to ideas in  [35] . Our main addition to this body of work is to (i) centre using yamm, or other robust median and (ii) presenting the muqie plots as dynamic videos of increasing \u03b1. Fig 5. Muqie plot for the three cluster two-dimensional data set without outliers. The figures are produced for different values of pseudo-quantile \u03b1. The centre point (in blue) in each plot is the yamm median. Left: \u03b1 = 0.4, Right: \u03b1 = 0.8. These plots were produced by the muqie() function in the Yamm package. For the animated plot, the package includes the makeplot() function, which calls muqie() for multiple values of \u03b1. Then we use the CRAN package animation to produce an animated GIF using saveGIF(makeplot(clusters2d[,-c(102,103)], nprojs = 4000), diff.col = 3, interval = 0.1, width = 500, height = 500).\n\nThe movie beetle shows a three-dimensional Muqie plot using three variables from the beetle data. The R commands used were: saveGIF(makeplot3D(beetle, dm = c(1,3,6)), diff.col = 3, interval = 0.2, width = 500, height = 500)"
    },
    {
      "title": "Conclusions and discussions",
      "text": "We have introduced a new method, yamm, to compute the projection median, for data in R n with n \ufffd 2. We have proved the theoretical equivalence of yamm and the projection median. Through theoretical and numerical investigations we demonstrate the robustness of yamm on a simple, but illuminating, bivariate setup. Then, we illustrated three computation methods for the projection median, which can be best deployed in different situations. Approximating the projection median by the Monte Carlo method is valid in any dimensions but requires a large number of projections to ensure accuracy, while using the trapezoidal rule is computationally fast and accurate in two and three dimensions, but requires more integration on the projection vector in the higher dimensions, which becomes rapidly more complex. The yamm approximation can also compute the median in any dimensions. Its computational speed is not as quick as the other two, under the same conditions (e.g. the number of projections). However, thanks to the optimiser, a small number of the projections can be chosen to obtain an accurate median with a reasonable starting point (e.g. other multivartiate medians or mean value), which can be a distinct advantage.\n\nOur research also documents the simulated empirical performance for different medians in terms of the computation time and the mean squared error. Using different R functions to calculate different multivariate medians, we find that the spatial median and the projection median are always accurate with relatively fast speed using the existing R functions. The performance of other multivariate medians either exhibits slow speed or large mean squared error.\n\nFinally, we introduce our R package, Yamm, that contains our three methods to compute the projection median. We show that our methods coincide with each other in R 2 and R 3 , and all multivariate medians are not affected by the outliers in the dataset, but the location of the mean value varies a lot. Currently, the function PmedTrapz in the R package is only valid in R 2 and R 3 , further investment can be conducted on extending this function to higher dimensions.\n\nThe Yamm package also introduces our Muqie plots, which are capable of producing animated plots of two-and three-dimensional sets' projected quantiles. The animated 'growth' of these \"quantile\" plots give a vivid picture of the extent, spread and configuration of data in the sets.\n\nThe Yamm package is available on the CRAN archive."
    },
    {
      "text": "Fig 1. Polar plot (in radians) of the magnitude of m X (\u03bc, a). Grey line: \u03bc = (2.2, 8) and Blue line: \u03bc = (2, 7.5). https://doi.org/10.1371/journal.pone.0229845.g001"
    },
    {
      "text": "The numerically computed crosses inFig 2 show that, for this setup, yamm plateaus somewhere between d = 2 and d = 4."
    },
    {
      "text": "Fig 2. Yamm computed on simulated setup, increasing the distance between two bivariate normals. Crosses: numerically computed values; Solid blue line: approximation computed for general \u03bd 1 and \u03bd 2 ; Solid red line: approximation computed when \u03bd 1 = (0, 0) T and \u03bd 2 = (0, d) T . https://doi.org/10.1371/journal.pone.0229845.g002"
    },
    {
      "text": "1. The actual data points is plotted with grey dots. The first plot in Fig 3 is producing excluding the two outliers, whilst the second one includes them. The projection medians produced with different estimators are very close to each other, and not far from the other median estimators also. Fig 3 also shows that the multivariate medians are not particularly affect by the outliers, whilst the mean value is. Simulated data in R 3 with four clusters. The function Plot3dMedian in Yamm plots the three-dimensional medians. The dataset clusters3d has four clusters, each generated from different independent normal distributions, as well as five outliers. Fig 4 is produced with the dataset clusters3d, whose outliers have been removed. It shows that apart from the Oja's median, the other medians are located close to each other. Again, the three approximations of the projection median almost coincide in every component."
    },
    {
      "text": "Fig 3. Bivariate medians and mean for three cluster two-dimensional set. Top: without outliers; Bottom: with outliers (out of plot area). https://doi.org/10.1371/journal.pone.0229845.g003"
    },
    {
      "text": "shows two muqie plots for \u03b1 = 0.4 and \u03b1 = 0.8. The latter indicates the three cluster nature. Surprisingly, this also shows up clearly in the \u03b1 = 0.4 plot with the 0.4 quantile for, e.g."
    },
    {
      "text": "Fig 4. Trivariate medians & mean for four cluster three-dimensional set. https://doi.org/10.1371/journal.pone.0229845.g004"
    }
  ],
  "references": [
    {
      "title": "What is the center of an area or the center of a population",
      "authors": [
        "J Hayford"
      ],
      "year": 1902,
      "doi": "10.2307/2276137"
    },
    {
      "title": "U \u00a8ber den Standort der Industrien",
      "authors": [
        "A Weber"
      ],
      "year": 1909
    },
    {
      "title": "Theory of the Location of Industries",
      "authors": [
        "A Weber"
      ],
      "year": 1929
    },
    {
      "title": "Mathematics and the picturing of data",
      "authors": [
        "J Tukey"
      ],
      "year": 1975,
      "doi": "10.1090/amsip/042.2/08"
    },
    {
      "title": "Descriptive statistics for multivariate distributions",
      "authors": [
        "H Oja"
      ],
      "year": 1983,
      "doi": "10.1016/0167-7152(83)90054-8"
    },
    {
      "title": "A survey of multidimensional medians",
      "authors": [
        "C Small"
      ],
      "year": 1990,
      "doi": "10.2307/1403809"
    },
    {
      "title": "Sign tests in multidimension: Inference based on the geometry of data cloud",
      "authors": [
        "P Chaudhuri",
        "D Sengupta"
      ],
      "year": 1993,
      "doi": "10.1080/01621459.1993.10476419"
    },
    {
      "title": "Multivariate median",
      "authors": [
        "H Oja"
      ],
      "year": 2013,
      "doi": "10.1007/978-3-642-35494-6"
    },
    {
      "title": "The projection median of a set of points in R 2",
      "authors": [
        "S Durocher",
        "D Kirkpatrick"
      ],
      "year": 2005,
      "doi": "10.1016/j.comgeo.2008.06.006"
    },
    {
      "title": "The projection median of a set of points in R d",
      "authors": [
        "R Basu",
        "B Bhattacharya",
        "T Talukdar"
      ],
      "year": 2012,
      "doi": "10.1007/s00454-011-9380-6"
    },
    {
      "title": "Continuous univariate distributions",
      "authors": [
        "N Johnson",
        "S Kotz",
        "N Balakrishnan"
      ],
      "year": 1995
    },
    {
      "title": "Monte Carlo Statistical Methods",
      "authors": [
        "C Robert",
        "G Casella"
      ],
      "year": 2005
    },
    {
      "title": "The convergence of a class of double-rank minimization algorithms",
      "authors": [
        "C Broyden"
      ],
      "year": 1970,
      "doi": "10.1093/imamat/6.1.76"
    },
    {
      "title": "A new approach to variable metric algorithms",
      "authors": [
        "R Fletcher"
      ],
      "year": 1970,
      "doi": "10.1093/comjnl/13.3.317"
    },
    {
      "title": "A family of variable metric updates derived by variational means",
      "authors": [
        "D Goldfarb"
      ],
      "year": 1970,
      "doi": "10.2307/2004873"
    },
    {
      "title": "Conditioning of quasi-newton methods for function minimization",
      "authors": [
        "D Shanno"
      ],
      "year": 1970,
      "doi": "10.1090/s0025-5718-1970-0274029-x"
    },
    {
      "title": "Fast approximations for sums of distances, clustering and the Fermat-Weber problem",
      "authors": [
        "P Bose",
        "A Maheshwari",
        "P Morin"
      ],
      "year": 2003,
      "doi": "10.1016/s0925-7721(02)00102-5"
    },
    {
      "title": "Algorithms for bivariate medians and a Fermat-Torricelli problem for lines",
      "authors": [
        "G Aloupis",
        "S Langerman",
        "M Soss",
        "G Toussaint"
      ],
      "year": 2003,
      "doi": "10.1016/s0925-7721(02)00173-6"
    },
    {
      "title": "Optimization in Arrangements",
      "authors": [
        "S Langerman",
        "W Steiger"
      ],
      "year": 2003,
      "doi": "10.1007/3-540-36494-3_6"
    },
    {
      "title": "The multivariate l1-median and associated data depth",
      "authors": [
        "Y Vardi",
        "C Zhang"
      ],
      "year": 2000,
      "doi": "10.1073/pnas.97.4.1423"
    },
    {
      "title": "Efficient and fast estimation of the geometric median in Hilbert spaces with an averaged stochastic gradient algorithm",
      "authors": [
        "H Cardot",
        "P Ce",
        "P Zitt"
      ],
      "year": 2013,
      "doi": "10.3150/11-bej390"
    },
    {
      "title": "Algorithms for projection-pursuit robust principal component analysis",
      "authors": [
        "C Croux",
        "P Filzmoser",
        "M Oliveira"
      ],
      "year": 2006,
      "doi": "10.2139/ssrn.968376"
    },
    {
      "title": "Algorithm AS 307: Bivariate location depth",
      "authors": [
        "P Rousseeuw",
        "I Ruts"
      ],
      "year": 1996,
      "doi": "10.2307/2986073"
    },
    {
      "title": "The bagplot: A bivariate boxplot",
      "authors": [
        "P Rousseeuw",
        "I Ruts",
        "J Tukey"
      ],
      "year": 1999,
      "doi": "10.2307/2686061"
    },
    {
      "title": "High-dimensional computation of the deepest location",
      "authors": [
        "A Struyf",
        "P Rousseeuw"
      ],
      "year": 2000,
      "doi": "10.1016/s0167-9473(99)00112-7"
    },
    {
      "title": "Computing the Oja median in R: The package OjaNP",
      "authors": [
        "D Fischer",
        "K Mosler",
        "J Mo \u00a8tto \u00a8nen",
        "K Nordhausen",
        "O Pokotylo",
        "D Vogel"
      ],
      "year": 2016,
      "doi": "10.18637/jss.v092.i08"
    },
    {
      "title": "The projection median as a weighted average",
      "authors": [
        "S Durocher",
        "A Leblanc",
        "M Skala"
      ],
      "year": 2017,
      "doi": "10.1016/j.comgeo.2008.06.006"
    },
    {
      "title": "Computable, robust multivariate location using integrated univariate ranks",
      "authors": [
        "K Ramsay"
      ],
      "year": 2017
    },
    {
      "title": "A simplex algorithm for function minimization",
      "authors": [
        "J Nelder",
        "R Mead"
      ],
      "year": 1965,
      "doi": "10.1093/comjnl/7.4.308"
    },
    {
      "title": "Function minimization by conjugate gradients",
      "authors": [
        "R Fletcher",
        "C Reeves"
      ],
      "year": 1964,
      "doi": "10.1093/comjnl/7.2.149"
    },
    {
      "title": "Numerical Optimization",
      "authors": [
        "J Nocedal",
        "S Wright"
      ],
      "year": 1999,
      "doi": "10.1007/b98874"
    },
    {
      "title": "A limited memory algorithm for bound constrained optimization",
      "authors": [
        "R Byrd",
        "P Lu",
        "J Nocedal",
        "C Zhu"
      ],
      "year": 1995,
      "doi": "10.1137/0916069"
    },
    {
      "title": "On the use of discriminant functions in taxonomy",
      "authors": [
        "A Lubischew"
      ],
      "year": 1962,
      "doi": "10.2307/2527894"
    },
    {
      "title": "Quantiles for finite and infinite dimensional data",
      "authors": [
        "R Fraiman",
        "B Pateiro-Lopez"
      ],
      "year": 2012,
      "doi": "10.1016/j.jmva.2012.01.016"
    },
    {
      "title": "Quantile tomography: using quantiles with multivariate data",
      "authors": [
        "L Kong",
        "I Mizera"
      ],
      "year": 2012,
      "doi": "10.5705/ss.2010.224"
    }
  ],
  "num_references": 35
}
