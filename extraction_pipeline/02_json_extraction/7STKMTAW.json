{
  "paper_id": "7STKMTAW",
  "title": "Clinical medidne m\"\"\"t~modern epidemiology-and both profit",
  "abstract": "Since the Second Edition was written in 1988, the pace of change in medicine has accelerated. Changes have brought greater recognition of the persp('(tivcs and methods of clinical epidemiology. COlmtries throughout the world have, in their efforts to provide highquality health care, experienced growing difficulties controlling the cost of care. The tension between demands for care and resources to provide it have increased the need for better information about clinical effectiveness in setting priorities. It has become dearer that not all clinical care is effective and that the outcomes of care are the best way of judging effectiveness. Variations in care among clinicians and regions, not explained by patients' needs and not accompanied by similar differences in outcomes, hilve wised questions ilbout which practices are best. All these forces in modern society have increased the villue of good clinical research and of those who can perfonn and interpret this research properly. Phenomenill advances in understanding the biology of disease, especially at the molecular level, have also occurred. Discoveries in the laboratory increase the need for good patient~basedresearch. They must be tested in patients before they can be accepted as clinically useful. Thus the twolaboratory science and clinicill epidemiology-complement each other and are not alternatives or competitors. Other aspects of medicine are timeless. Piltients and physicians still face the same kinds of questions about diagnosis, prognosis, and treiltment ilod still value the same outcomes: to relieve suffering, restore function, and prevent untimely death. We rely on the same basic strategies (cohort and case-control studies, randomized trials, and the like) to answer the questions. The inherent uncertainty of all clinical information, even that based on the best studies, persists. In preparing the third edition of this text, we have tried to take into account the sweeping changes in medicine as well as what has not changed. We have left the basic structure of the book intact. We updated examples throughout in recognition that some diseases, such as AIDS, are new and others, such as peptic ulcer disease, arc better understood. We have tried to remember that the book's niche is as an introduction v vi PREFACE to clinical epidemiology and to avoid pitching the presentation to our colleagues who already have a firm grasp of the basics. The presentation is meant to be as simple as the topic allows. However, the field is covered in somewhat greater depth on the belief that readers expect more of the book now than they did when the field was new. This edition is still primarily for clinicians who wish to develop a systematic understanding of how the evidence base for patient care is developed and assessed. Researchers begin with many of the same basic needs. The text should be useful at any level of clinical training: from medical student to practicing clinician. viii ACKNOWLEDGMENTS were together on the faculties of Medicine and Epidemiology at the University of North Carolina at Chapel Hill. Now, 13 years later and in different places, we appreciate more than ever the importance of the many colleagues who have helped us improve our understanding of clinical epidemiology and to express it more clearly.",
  "year": 1992,
  "date": "1992",
  "journal": "Ann Epidemini",
  "publication": "Ann Epidemini",
  "doi": "10.1056/nejm199310213291715",
  "sections": [
    {
      "text": "We have been privileged to work with wonderful colleagues, many of them clinical epidemiologists. This edition of the text distills what we have learned from them and from our own efforts to use clinical epidemiology. Our teachers were the pioneers of this field: Archic Cochrane, John Cassell, Alvan Feinstein, David Sackett, Kerr White, and others. More recently we have ledITled from the many young physicians throughout the world who have believed in this way of thinking about health and medical care and have put their beliefs into practice. Many are members of distinct programs-such as the International Clinical Epidemiology Network  (INC LEN)  and the Robert Wood Johnson Clinical Scholars Program-but the number of groups has become too numerous to list each one here.\n\nThe Flete/lers are especially grateful to the editorial staff of Annals of Internal Medicine, our colleagues during the four ye<lfs we were Editorsin-Chief. Articles in peer-reviewed clinical journals are the written record of clinical epidemiology, and we learned a great deal from our efforts to select and improve manuscripts. We were able to begin work on the third edition of this text~a daunting task in the midst of a move from the American College of Physicians in Philadelphia to Boston-thanks to the hospitality of Drs. Steven Jones and Wendy Levinson of the Legacy Portland Hospitals, our hosts while we were on sabbatical in Oregon. Tom Inui invited us to our new academic home-the Department of Ambulatory Care and Prevention at Harvard Medical School and Harvard Community Health Plan-and provided all the fellowship and resources we needed to finish the writing.\n\nEd Wagner is grateful for having been given the privilege to explore the uses of clinical epidemiology in studying, planning, and improving care for the 0.5 million enrollees of Group Health Cooperative of Puget Sound. My contribution to this edition owes much to the stimulation and support of my colleagues at the Center for Health Studies, the Group Health delivery system, at the University of Washington.\n\nThis edition reflects all of our experiences from the time the three of us vii 1"
    },
    {
      "title": "INTRODUCTION",
      "text": "A 51-year-old man asks to sec you because of chest pain. He was well until 2 weeks ago, when he noticed tightness in the center of his chest while walking uphill. The tightness stopped after 2 to 3 min of rest. A similar discomfort occurred several times since then, sometimes during exercise and sometimes at rest. He smokes one pack of cigarettes per day and has been told that his blood pressure is \"a little high.\" He is otherwise well and takes no medications. However, he is worried about his health, particularly about heart disease. A complete physical examination and resting electrocardiogram are normal except for a blood pressure of 150/96. This patient is likely to have many questions. Am 1 sick? How sure are you? If Tam sick, what is causing my illness? How will it affect me? What can be done about it? How much will it cost?\n\nAs the clinician caring for this patient, you must respond to these questions and use them to guide your course of action. Ts the probability of serious, treatable disease high enough to proceed immediately beyond simple explanation and reassurance to diagnostic tests? How well do various tests distinguish among the possible causes of chest pain: ilngina pectoris, esophageal spilsm, muscle strain, anxiety, and the like. For example, how helpful will an exercise electrocardiogram be in either confirming or ruling out coronary artery disease? Tf coronary disease is found, how long can the patient expect to have the pain? Will the condition shorten his life? How likely is it that other complications-congestive heart failure, myocardial infarction, or atherosclerotic disease of other organs-will occur? Will reduction of his risk factors for coronary disease-cigareUt> smoking and hypertension-reduce his risk? If medications control the pain, should the patient have coronary ilftery bypass surgery anyway?\n\nClinicians use various sources of information to answer these questions: their own experiences, the advice of their colleagues, and the medical literature. In general, they depend on past observations on other similar patients to predict what will hilppen to the patient at hand. The manner \u2022 Probability for an individual patient is best estimated by rderring to past experience with groups of similar patients \u2022 Because clinical observations are made on people who are free to do as they please and by clinicians with variable skills and biases, the observations may be affected by systematic errors that can cause misleading conclusions \u2022 All observations, including clinical ones, are also influenced by the play of chance \u2022 To avoid being mislead, clinicians should rely on observations that are based on sound scientific principles, including ways to reduce bias and estimate the role of chance."
    },
    {
      "title": "THE SOCIAL CONTEXT OF CLINICAL EPIDEMIOLOGY",
      "text": "Important forces in modern society have accelerated the recognition of dinical epidemiologic methods and perspectives. The costs of medical care are rising beyond the point where even the most affluent societies are able to pay for all the care people want. Studies have shown wide variation in clinical practices without corresponding variation in outcomes of care, suggesting that not all common and expensive practices are usdul. More rigorous methods of evaluating clinical evidence are being developed and are valued by decision makers. These observations have led to the consensus that clinical care should be based on the strongest possible research and should be judged by the outcomes it achieves at a cost society can afford. Also, individual patients are increasingly seen in relation to the larger group of which they are members, both to make accurate predictions about them and to assist in deciding which uses of limited medical resources do the most good for the most people."
    },
    {
      "title": "Basic Principles",
      "text": "The basic purpose of clinical epidemiology is to foster methods of clinical observation and interpretation that lead to valid conclusions. The most credible answers to clinical questions are based on the fo]]owing principles."
    },
    {
      "title": "CLINICAL QUESTIONS",
      "text": "Types of questions addressed by clinical epidemiology are listed in Table  1 .1. These are the same questions confronting the doctor and patient in the example presented at the beginning of this chapter. They are at issue in most doctor-patient encOlmters."
    },
    {
      "title": "HEALTH OUTCOMES",
      "text": "The clinical events of primary interest in clinical epidemiology are the health outcomes of particular concern to patients and those caring for them (Table  1 .2). They are the events doctors try to understand, predict, interpret, and change when caring for patients. An important distinction between\n\nTable 1.1 Clinical Questions Question Abnormality Diagnosis Frequcncy Risk Prognosis Treatment Prevention Cause Cost Is the patient sick or well\"! How accurate are tests uscd to diagnose disease? How oftcn docs a disease occur') What factors are associated with an increased risk ot disease? What are the consequences of having a disease? How does treatment change the course of disease? Docs an interJcntion on wcll peoplc keep disease from arising? DOGS early detection and treatment improve the course of disease? What conditions lead to disease? What me the pathogenetic mcchanisms ot disease') How much will care for an illness cost? A barj outcome it untimely A set of symptoms, physical signs, and laboratory abnormalities Symptoms such as pain, nausea, dyspnea, itching, and tinnitis Impaired ability to go about usual actFvities at home, work, or recreation I::motionat reaction to disease and its care, such as sadness or anger Perhaps a sixth 0, destitution, belongs on this list because the financial cost of illness (for individ\",,1 patients or society) is an importanf oonsequElnOO of diseaso, \"Or illness, the patient's experience of disease clinical epidemiology and other medical sciences is that the events of interest in clinical epidemiology can be studied directly only in intact humans and not in animals or parts of humans, such as humeral transmitters, tissue cultures, cell membranes, and genetic sequences, Biologic outcomes carmot properly be substituted for clinical ones without direct evidence that the two are related. Table  1 .3 summarizes some biologic and clinical outcomes for the modern treatment of a patient with human immwlOdeficiency virus (HIV) infection. It is plausible, from what is known about the biology of HIV infection, that clinical outcomes such as opportunistic infections, Kaposi's sarcoma, and death would be better if an intervention reduced the decline in CD4+ cell counts and p34 antigen. However, there is evidence that these are incomplete markers of disease progression and response to treatment. It is too much to assume that patient outcomes would improve as a result of the intervention just because biologic markers do, because many other factors might determine the end result. Clinical decisions should, therefore, be based on direct evidence that clinical outcomes themselves arc improved.\n\nTable 1.3 Biologic and Clinical Outcomes; Treatment of Human Immunodeficiency Virus Infection Outcomes HIV infection Interventions Zidovudine 001 DOC 8iolooic CD4+ counts p24 antigenemia Viremia Clinical Opporiunistic infections Quality of life Death"
    },
    {
      "title": "NUMBERS AND PROBABILITY",
      "text": "Association kflowrl or ,lssumod?\n\nClinical science is at its strongest when measurements are quantitative, in part because numerical information allows better confirmation, more precise communication among clinicians and between clinicians and patients, and estimation of error. Clinical outcomes such as death, symptoms, or disability, can be counted and expres~ed as numbers. Although qualitative observation is also important in clinical medicine, it is not part of clinical epidemiology.\n\nIndividual patients will either experience a clinical outcome or not, but predicting whether or not an individual will do so is seldom exact. Rather, clinicians use the results of resemch to assign probabilities that the outcome will occur. The clinical epidemiologic approach accepts that clinical predictions are uncertain, but can be quantitated, by expressing predictions as probabi1itie~-forexample, that symptomatic coronary disease occurs in 1 in 100 middle-aged men per year, that cigarette smoking doubles one's ri~k of dying at all ages, and that exogenous estrogens reduce the risk of fractures from osteoporo~is by half."
    },
    {
      "title": "POPULATIONS AND SAMPLES",
      "text": "In general, populatiolls are large groups of people in a defined setting (such as North Carolina) or with a certain characteristic (such as age >65 years). These include relatively unselected people in the community, the usual population for epidemiologic ~tudies of cause, as well as groups of people selected because of their attendance in a clinic or hospital or because of a characteristic such as the presence or severity of disease, as is more often the ca~l' in clinical studies. Thus Olle speaks of the general population, a hospitalized population, or a population of patients with a specific disease.\n\nA sample is a subset of a population and is selected from the population. Clinical research i~ordinarily carried out on samples. One is interested in the characteristics of the defined population but must, for practica1reasons, estimate them by describing a sample."
    },
    {
      "title": "BIAS",
      "text": "Bias is \"il process at any stage of inference tending to produce results that depart systemiltically from the true values\" (3). Suppose, for example, thilt treatment A is found La work better than treatment B. What kinds of biases might have brought 'lbout this (lbservation if it were not true? Perhaps A is given to healthier piltients than is B; then the results could be due to the systemiltic difference in health between the groups of patients whether or not they were treated rather than to differences in the effective-neSS of treatment. Or A might taste better than B so that p\"tients take the drug more regularly. Or A might be \" new, very popular drug 'lnd B ,Ill old one, so that researchers and patients are more inclined to think th<lt the new drug works better whether or not it really does. All of these 'lre examples of potential biases.\n\nObservations on patients (whether for p\"tlent care or research) <lre particularly susceptible to bias. The process tends to be just plain untidy. As participants in a study, human beings h\"ve the disconcerting habit of doing as they please and not necessarily v\"hat would be required for producing scientifically rigorous answers. When researchers attempt to conduct 'ln experiment with them, as one might in a laboratory, things tend to go wrong. Some people refuse to participate, \\vhi1c others drop out or choose ilnother treatment. Wh'lt is more, some of the most important things about humans-feelings, comfort, performance-are generally more difficult to measure than physical characteristics, such as blood pressure or serum sodium. Then, too, clinicians arc inclined to believe that their therapies are successful. (Most patients would not want a physician who felt otherwise.) This attitude, so impurtant in the practice of medicine, makes clinical observations particularly vu]ncr<lble to bias.\n\nAlthough dozens of biases have been defined  (4) , most fall into one of three broild categories (Table  1   .4) .\n\nScll'ctiOil IJins occurs when comparisons are made behveen groups of p\"bents that differ in \\vays, other than the main f\"dors tmder study, that <lffecl Table  1.4"
    },
    {
      "title": "Bias in Clinical Observation",
      "text": "\u2022 Selection bidS occurs wherl c:ornp8risons are Iliade hetween groups of patients th<lt differ in (jeterrnillant~; of outcoille other than the one under study, \u2022 Measurement bl~gs occurs when the metllods of measurement me dissimilJr among groups of patients, \u2022 Confounding bias occurs when two fuctors [lrc <lssoci8tcd {\"'trilvet togdll,~r\"i dnd H18 effect of one is confused with or distorted by tile dfect of the on1er the outcome of the shldy. Croups of patients often differ in many waysage, sex, severity of disease, the presence of other diseases, and the care they receive. If we compare the experience of two groups that differ on a spedfic characteristic of interest (for example, a treatment or a suspected cause of disease) but are dissimilar in these other ways and the differences are themselves related to outcome, the comparison is biased imd little can be concluded about the independent effects of the characteristic of interest. In the example used earlier, selection bias would have occurred if patients given treahnent A were healthier than those givL>tl treahnent B.\n\nMeasurement bins occurs when the methods of measurement are consistently dissimilar in different groups of patients. An example of a potential measurement bias would be the use of information taken from medical records to determine if women on birth control pills were at greater risk for thromboembolism than those not on the Pill. Suppose a study were made comparing the frequency of oral contraceptive use among women admitted to a hospital because of thrombophlebitis and a group of women admitted for other reasons. It is entirely possible that women with thrombophlebitis, if aware of the reported association between estrogens and thrombotic events, might report use of oral contraceptives more completely than women without thrombophlebitis, because they had already heard of the association. For the same reasons, clinicians might obtain and record infonnation about oral contraceptive use more completely for women with phlebitis than for those without it. If so, an association between oral contraceptives and thrombophlebitis might be observed because of the way in which the history of exposure was reported and not because there really is an association.\n\nCorifoundillg bias occurs when two factors <lfe associated with each other, or \"travel together,\" and the effect of one is confused with or distorted by the effect of the other. This could occur because of selection bias, by chance, or because the two really are associated in nature.\n\nLxample Is herpesvirus infection a cau~e of cervical cancer) It has becn con~i~tently observed that the prevalence of herpesvirus infection is higher in women with cervical cancer than in those without. However, both herpesvirus ilnd a number of other infectious agents, themselve~possible causes of cervica I cancer, arc transmitted by sexual contact. In particular, there i~strong evidence that human papillomavirus infection Icads to cervical cancer. Perhaps the higher prevalence of herpesviru~infection in women with cervical cancer i~only a consequence of greater sexual activity and so is indirectly related to a true cause, which is also transmitted sexually (Fig.  1.1) . To show that herpesvirus infection is ,lssociated with cervical cancer independently of other agents, it would be necessary to observe the effecls of herpesvirus frcc of the other factors related to increased sexual activity  (5) .\n\nSelection bias and confounding bias are not mutually exclusive. They arc described separately, however, because they present problems at different Confounding bias: Is herpesvirus 2 (HSV-2) a possible cause of cervical cancer? Only if its association with cervical cancer is independent of human papillomavirus (HPV) infection, known to be a cause of cervical cancer. Both viruses are related to increased sexual activity.\n\npoints in a clinical observation or study. Selection bias is at issue primarily when patients arc chosen for observation, and so it is important in the design of a study. Confounding bias must be dealt with during analysis of the data, once the observations have beell made.\n\nOften in the Silme study more thiln one bias operiltes, i1S in the following hypothetical example.\n\nExample A study was done to de\\('rmine whether reglJl;u exercise lowers the risk of coronary heart disease (CHD). An exercise program was offered to employees of a plant, and the rate of subsequent coronary events was compared between employees who volunteer('d for the program and those who did not volunteer. Coronilry events were determined by means of regular voluntary checkups, including a careful history, an electrocardiogram, and a review of routine health records. The group that exercised had lower rates of CHD. However, they also smoked cigarettes less.\n\nIn this example, selection bias could be present if volunteers for the exercise program were i1t lower risk for coronary disease even before the program began-for example, because they had lower serum lipids or less family history of coronary disease. Measurement bias might have occurred because the exercise group stood a better chance of having a coronary event detected, because more of them were examined routinely. Finally, the conclusion that exercise lowered the risk of coronary disease might be the result of a confoW1ding bias if the i1ssociation between exercise and coronary events in this particular study resulted from the fact that smoking cigarettes is a risk factor for coronary disease and the exercise group smoked less.\n\nA potential for bias does not mean that bias is actually present in a particular study. For a researcher or reader to deal effectively with bias, it is first necessary to know where and how to look for it and what can be done about it. But one should not stop there. It is also necessary to determine whether bias is actually present and how large it is likely to be to decide whether it is important enough to change the conclusions of the study in a clinically meaningful way."
    },
    {
      "title": "CHANCE",
      "text": "Observations about disease are ordinarily made on a sample of patients rather than all those with the disease in question. Observations on a sample of patients, even if unbiased, may misrepresent the situation in the population as a whole because of chance. However, if the observations were repeated on many such patient samples, results for the samples would vary about the true value. The divergence of an observation on a sample from the tme population value, due to chance alone, is called random mrilltiol1.\n\nWe are all familiar with chance as an explanation for why il coin does not come up heads exactly 50'~<, of the time when it is flipped, say, 100 times. The same effect, random variation, applies when assessing the effects of treatments A and 13, discussed earlier. Suppose all biases were removed from a study of the relative effects of the two treatments. Suppose, further, that the two treatments are, in reality, equally effective, each improving about 50'10 of the patients treated. Even so, because of chance alone a single study including small numbers of patients in each treatment group might easily find A improving a larger proportion of patients than 13 or vice versa.\n\nChance can affect all of the steps involved in clinical observations. In the assessment of treahnents A and B, random variation occurs in the sampling of patients for the study, the selection of treahnent groups, and the measurements made on the groups.\n\nUnlike bias, which deflects values in one direction or another, random variation is as likely to result in observations above the true value as below it. As a consequence, the mean of many unbiased observations on samples tends to correspond to the true value in the population, even though the results of individual small samples may not.\n\nStatistics can be used to estimate the probability of chance (random variation) accounting for clinical results. A knowledge of statistics can also help reduce that probability by allowing one to formulate a better design and analyses. However, random variation can never be totally eliminated, so chance should always be considered when assessing the results of clinical observations.\n\nThe relationship betwl'en bias and chance is i11ustrated in Figure  1 .2. The measurement of diastolic blood pressure on a single patient is taken as an example. True blood pressure can be obtained by an intraarterial carulUla, which is SO mm Hg for this patient. But this method is not possible for routine measurements; blood pressure is ordinarily measured indi-----B i a s ----Blood pressure measurement  (sphygmomanometer)  .,\n\nr::: o 1l o '0 1: E :> z True blood pressure (intraarterial cannula)\n\nl.. I.\n\nDiastolic Blood Pressure (mm Hg) reetly, using a sphygmomanometer. The simpler instrument is prone to error, or deviations from the true value. In the figure, the error is represented by all of the sphygmomanometer readings falling to the right of the true value. The deviation of sphygmomanometer readings to the right (bias) may have several explanations-for example, a poorly calibrated sphygmomanometer, the wrong cuff size, or a deaf clinician. Bias could also result if different sounds were chosen to represent diastolic blood pressure. The usual end points-phase IV and phase V Korotkoff sounds-tend to be above and below the true diastolic pressure, respectively, and even that is unpredictable in obese people. Individual blood pressure readings are also subject to error because of random variation in measurement, as illustrated by the spread of the sphygmomanometer readings around the mean value (90 mm Hg).\n\nThe two sources of error-bias and chance-are not mUhlally exclusive. In most sirnations, both are present. The main reason for distinguishing between the two is that they are handled differently.\n\nBias can in theory be prevented by conducting clinical investigations properly or corrected through proper data analysis. Tf not eliminated, bias often can be detected by the discerning reader. Most of this book is about how to recognize, avoid, or minimize bias. Chance, on the other hand, cannot be eliminated, but its influence can. be reduced by proper design of research, and the remaining: error can be estima~{'d by statistics. Statistics can also help remove the effects of known biases. However, no amount of statistical treatment can correct for unknown biases in data. Some statisticians would go so far as to suggest thilt statistics not be applied to data vulnerable to bias because of poor research design, for fear of giving false respectability to misleading work."
    },
    {
      "title": "INTERNAL AND EXTERNAL VALIDITY",
      "text": "When making: inferences about a population from observations on a sample, two fundamental questions arise (Fig.  1 .3): First, are the conclusions of the research correct for the people in the sample? Second, if so, does the sample represent fairly the population of interest?\n\nInternal validity is the degrec to which the results of a study are correct for the sample of patients being studied. It is \"internal\" because it applies to the conditions of the particular group of patients being observed and not necessarily to others. The internal validity of clinical research is determined by how we]] the design, data collection, and analyses are carried out and is threatened by all of the biases and random variation discussed above. For a clinical observation to be usefuL internal validity is a necessary but not sufficient condition.\n\nExternal validity  (genl'ralizability)  is the degree to which the results of an observation hold true in other settings. for an individual physician, it is an answer to the question, \"Assuming that the res:dts of a srudy are true, do they apply to my patient as well?\" Gcneralizability expresses the validity of assuming that patients in a study arc comparable with other patients. An wtimpeachable study, with high internal validity, may be totally misleading if its results are genera lizcd to the wrong patients.\n\nExample What is the risk that an abdominal aortic aneurysm will rupture? Clinicians seeing patients with ant:'urysms must have this information to make wise decisions about the need for elective surgical repair. The answer dl.'pends on which kinds of patients arc described. Among patients with aneurysms <5 cm in diameter, above which surgt:'ry is commonly advised, those seen in referral centers have about a 10 times greater rate of rupture during 5 yt:'ars of follow-up than those in the general population (Fig 1 .4) (6) . This may be because patients in cenlers are referred for symptoms or sib'lls of impending rupture. If clinicians in office practice were to use the results of research from referra 1centers to predict rupture, they would greatly overestimate the risk and perhaps make the wrong decision about the need for elective surgical repair.\n\nThe gcncralizability of clinical observations, even those with high internal validity, is a matter of opinion about which reasonable people might disagrce.\n\nExample The Physician's Health Study showed th(lt low-dost:' aspirin (325 mg every other day) prevented myocardial infarction in male physicians  30  \u2022 \"\n\n\u2022 \u2022 ,.. Sampling bias: Range of risk of rupture (shaded area) in the next 5 years of abdominal aortic aneurysm \u00ab5.0 cm in diameter) according to whether the patient is from the general population or a referral center  (6) .\n\nwithout known coronary heart disease  (7) . The 11, 037  physicians randomly assigned to take aspirin had a 44~;) lower rate (,f myocardial infarction than the 11,034 assigned to take placebo. The study was C\"arcfully conducted and used a strong research design; its findings have stood up well to criticisms. However, only healthy male physicians wefe in the study. When the results of the study Ivere first released, clinicians had to decide whether it was justified to i;ive aspirin to women, peopl,> with many risk fadors, and patients who arc already known to have coronary dis<'ase. Subsequently, rlOviews of evidence from all available studies have suggested that <lspirin is also effec-tiVIO in these other groups of people  (8) .\n\nCener<lliz<lbility can rarely be dealt with satisfactorily in anyone study. Even a defined, geographically based population is a biased s<lmple of larger populations; for eX<lmple, hospital patients ilre biased samples of county residents; counties, of stiltes; states, of regions, and so on. Doing <I study in many centers m<lY improve generaliz<lbility, but does not settle the issue.\n\nUsually, the best a researcher can do about generalizilbility is to ensure intemal validity, have the study population fit the reseilrch question, and avoid studying groups so lll1USllill that experience with them generalizes to few other patients. It then remains for other studies, in other settings, to extend generalizability.\n\nSampling bias has occurred when the sample of patients in a Shldy is systematically different from those appropriilte for the research question or the clinical usc of the information. Because most clinical studies take pl<lcl' in medicill centers and beciluse patients in such centers llsually overrepresent the serious cod of the disease spectrum, sampling bias in clinical research tends to result in an exaggerated view of the seriolls nahue of disease."
    },
    {
      "title": "Uses of Clinical Epidemiology",
      "text": "Learning and applying clinical epidemiology adds time to an already busy clinician's schedule. What can he or she expect in return?\n\nUnderstanding the strengths and weaknesses of dinical evidence, such as reports of research, gives intellectual satisfaction and confidence where there might otherwise be bewilderment and frustration. It can increase efficiency in acquiring sound information by allowing one to decide quickly, from basic principles, which articles or sources of clinical information ilre credible. During interi:lction with colleagues, it provides a sounder alternative to other ways of deciding where to invest belief in an asser-tion~lhe conviction, rhetoric, seniority, or specialty of the proponent. By rdying on clinical epidemiology, clinicians of <111 backgrounds are on a more equal footing, all depending mainly on the interpretation of the s<lme set of strong studies. Finally, clinical epidemiology gives clinicians a perspective on the extent to which their efforts, relative to other factors, such as the biology of disease and the physical and social environment, determine health outcomes, so that they can know whdt they can and cannot change.\n\nFor these reasons, we believe the time invested in learning clinical epidemiology is more than repaid."
    },
    {
      "title": "Information and Decisions",
      "text": "The primary concerns of this book are the quality of clinical information i:md its correct interpretation. Making decisions is another matter. True, good decisions depend on good information; but they involve a great deal more as well, including value judgments and the weighing of competing risks and benefits.\n\nIn recent years, medical decision making has become a valued discipline in its own right. The field includes qualitative studies of how clinicians make decisions and how the process might be biased and can be improved. It also includes quantitative methods-decision analysis, cost-benefit analysis, and cost-effectiveness analysis-that present the decision-making process in an explicit way so its components and the consequences of assigning various probabilities and values to them can be examined.\n\nSome aspects of decision analysis, such as evaluation of diagnostic tests, are included in this book. However, we have elected not to go deeply into medical decision making itself. Our justification is that decisions are only as good as the information used to make them, and we have found enough to say about the essentials of collecting and interpreting clinical information to fill a book. Readers who wish to delve more deeply into medical decision making can begin with some of the suggested readings listed at the end of this chapter."
    },
    {
      "title": "Organization of the Book",
      "text": "TIlis book is written for clinicians who wish to understand for themselves the validity of clinical observations to be able to judge the credibility of their own clinical observations, those of their colleagues, and research findings in the medical literature. We have not written primarily for those who do clinical research, but for all the rest who depend on it. However, we believe that the basic needs of those who do and those who use clinical research findings are similar.\n\nTn most textbooks of clinical medicine, information about disease is presented as answers to traditional clinical questions: diagnosis, clinical course, treatment, and the like. On the other hand, most books about clinical investigation are organized around research strategies such as clinical trials, surveys, and case-control studies. This way of organizing a book may serve those who perform clinical research, but it is mvkward for clinicians.\n\nWe have organized the book primarily according to the clinical questions encountered when doctors care for patients. Figure  1 .5 illustrates how these questions correspond to the book chapters, taking lung cancer as an example. The questions relate to the entire natural history of disease, from the time people without lung cancer arc first exposed to risk, through when some acquire the disease and emerge as patients, until the end results of diseasc are manifest.\n\nIn each chapter, we describe research strategies used to answer that chapter's clinical questions. Some strategies, such as cohort studies, are useful for answering several different kinds of clinical questions. For the purposes of presentation, wc have discussed each strategy primarily in one chapter and simply referred to the discussion when the method is relevant to other questions in other chapters."
    },
    {
      "title": "ABNORMALITY",
      "text": "Clinicians spend a great deal of time distinguishing \"normal\" from \"abnormal.\" When confronted with something grossly different from the usual, there is Ii ttle difficulty telling the two apart. We all are fami liar with pictures in textbooks of physical diagnosis showing massive hepatosplenomegaly, huge goiters, or severe changes of rheumatoid arthritis in the hand. We can take no particular pride in recognizing this degree of abnormality. More often, however, clinicians must make subtler distinctions between normal and abnormal. Is fleeting chest pain angina or inconsequential? Is a soft systolic heart sound a sign of valvular heart disease or an innocent murmur? Is a slightly elevated serum alkaline phosphatase evidence for liver disease, asymptomatic Paget's disease, or nothing important?\n\nDecisions about what is abnormal are most difficult among relatively unselected patients, usually found outside of hospitals. When patients have already been selected for special attention, as is the case in most referral centers, it is usually clear that something is wrong. The tasks are then to refine the diagnosis and to treat the problem. Tn primary carl.' settings, however, patients with subtle manifestations of disease are mixed with those with the everyday complaints of healthy people. It is not possible to pursue all of these complaints aggressively. Which of many patients with abdominal pain have self-limited gastroenteritis and which have early appendicitis? Which patients with sore throat and hoarseness have a garden variety pharyngitis and which the rare but potentially lethal Haemophillls epiglottitis? These are examples of how difficult, and important, distinguishing various kinds of abnormalities can bc.\n\nThe point of distinguishing normal from abnormal is to separate out those clinical observations that should be considered for action from those that mn be simply noted. Observations that are thought to be normal arC' usually described as \"within norma] limits,\" \"unremarkable,\" or \"noncontributory\" and remain buried in the body of a medical record. The abnormal findings are set out in a problem list or under the heading \"impressions\" or \"diagnoses\" and c.re the basis for action.\n\nSimply calling clinical findings normal or abnormill is undoubtedly crude and results in some misclassification. The justification for taking this approach is that it is often impractical or unnecessary to consider the raw data in all their detail. As Bertrand Russell put it, \"To be perfectly intelligible one must be inaccurate, and to be perfectly accurate, one must be unintelligible.\" Physicians usually choose to err on the side of being intelligible-to themselves and others-even at the expense of some accuracy. Another reason for simplifying data is that each aspect of a clinician's work ends in a decision-to pursue evaluation or to wait, to select a treatment or reassure. Under these circumstances some sort of present/ absent classification is necessary.\n\nTable  2 .1 is an example of how relatively simple expressions of abnormality are derived from more complex clinical data. On the left is a typical problem list, a statement of the patient's important medical problems. On the right are some of the data on which the decisions to call them problems are based. Conclusions from the data, represented by the problem list, are by no means noncontroversial. For example, the mean of the four diastolic blood pressure measurements is 94 mm Hg. Some might argue that this level of blood pressure does not justify the label \"hypertension,\" because it is not particularly high and there are some disadvantages to telling patients they are sick and giving them pills. Others might consider the label fair, considering that this level of blood pressure is associated with an increased risk of cardiovascular disease and that the risk may be reduced by treatment. Although crude, the problem list serves as a basis for decisions-about diagnosis, prognosis, and trcahnent-and clinical decisions must be made, whether actively (by additional diagno~tic tests and treatment) or passively (by no intervention). This chapter describes some of the ways clinicians di~tinguish normal from abnormal. To do ~o, first it will be necessary to consider how biologic phenomena are measured, vary, and are summarized. Then it will be possible to consider how these data are used as a ba~i~for value judgments about what is worth calling abnormal."
    },
    {
      "title": "Clinical Measurement",
      "text": "Measurement~of clinical phenomena yield three kinds of data: nominal, ordinal, ilnd interval.\n\nNominal data occur in categories without any inherent order. Examples of nominal data are characteristics that are determined by a small set of genes (e.g., tissue antigens, sex, inborn errors of metabolism) or are dramatic, discrete events (e.g., death, dialysis, or surgery). These data can be placed in categories without much concern about misdassification. Nominal data that can be divided into two categories (e.g., present/absent, yes/ no, alive/dead) are called dichotomous.\n\nOrdinal data posse~s some inherent ordering or rank, such as small to large or good to bad, but the size of the intervals between categories cannot be specified. Some clinical examples include 1+ to 4+ leg edema, grade\u0128 to VI murmurs (heard only with special effort to audible with the stethoscope off the chest), and grades 1 to 5 muscle strength (no movement to normal strength) For intemal data, there is inherent order and the intelVal between successive value~is equal, no matter wheT(' one is on the scale. There are two types of interval data. Continuous data can take on any value in a continuum. Examples include most serum chemistries, weight, blood pressure, and partial pressure of oxygen in arterial blood. The meaSUTem('J1t and descriptions of continuous variables may in practice be confined to a limited number of points on the continuum, often integers, because the precision of the measurement, or its usc, does not warrant greater detail. For example, a particular blood glucose reading may in fact be 1':)3.2846573 ... mg/lOO mL but simply reported as 193 mg/100 mT.. Discrete data, can take on only specific values and arc expresslx.! as counts. Examples of discrete data arc the number of a woman's pregnancies and live births and the number of seizures a patient has per month.\n\nIt is for ordinal and numerical data that the follmving question arises: Where docs normal leave off and abnormal begin? When, for example, does a large normal prostate become too large to be considered normal? Clinicians are free to choose any cutoff point. Some of the reasons for the choices will be considered later in this chapter."
    },
    {
      "title": "Performance of Measurements",
      "text": "Whatever the type of measurement, its performance can be described in several ways, discussed below."
    },
    {
      "title": "VALIDITY",
      "text": "As pointed out in Chapter 1, validity is the degree to which the data measure what they were intended to measun'~that is, the results of a measurement correspond to the true state of the pl~enomenon being measured. Another word for validity is IIcCliracy.\n\nfoor clinical observations that can be measured by physical means, it is relatively easy to establish validity. The observed measurement is compared with some accepted standard. For example, serum sodium can be measured on an instrument recently calibrated against solutions made up with known concentrations of sodium. Clinical laboratory measurements are commonly subjected to extensive ilnd repeated validity checks. For example, it is a national standard in the United States that blood glucose measurements be monitored for accuracy by comparing readings against high and low standards at the beginning of each day, before each technician begins a day, and after any changes in the techniques such as a new bottle of reagents or a new battery for the instrument. Similarly, the validity of a physical finding Ciln be established by the results of surgery or an autopsy.\n\nOther clinical measurements such as pain, nausea, dyspnea, depression, and fear cannot be verified physically. In clinical medicine, information about these phenomena is obtained by \"taking a history.\" More formal and standardized approaches, used in clinical research, are structured interviews and questionnaires. Groups of individual questions (items) are designed to measure specific phenomena (such as symptoms, feelings, attitudes, knowledge, beliefs) called \"constructs.\" Responses to questions concerning a construct are converted to numbers and grouped together to form \"scales.\"\n\nThere are three general strategies for establishing the validity of measurements that cannot be directly verified by the physical senses.\n\nContCliI validily is the extent to which a particular method of measurement includes all of the dimensions of the construct one intends to measure and nothing more. For example, a scale for measuring pain would have content v<llidity if it included questions about aching, throbbing, burning, and stinging but not about pressure, itching, nausea, tingling, and the like.\n\nConstruct validity is present to the extent that the measurement is consistent with other measurements of the same phellomenon. For example, the researcher might show that responses to a sC<lle lllCilsuring pain are related to other manifestations of the severity of pain such as sweating, moaning, writhing, and asking for pain mediCiltions.\n\nCriterion villidity is present to the extent that the measurements predict a directly observable phenomenon. for example, one might see if responses on a scale measuring pain bear il predictable relationship to pain of known severity: mild pain from minor abrasion, moderate pain from ordinary headache and peptic ulcer, and severe pain from renal colic.\n\nValidity is not, as is often asserted, either present or absent; Rather, with these strategies one can build a case for or against the validity of a scale, under the conditions in which it is used, so as to convince others that the scale is more or less valid.\n\nBecause of their selection and training, physicians tend to prefer the kind of precise measurements the physicill and biologic sciences afford, and they avoid or discount others, especially for research. Yet relief of symptoms and promoting satisfaction and a feeling of well-being are among the most important outcomes of care, central concerns of patients and doctors alike. To guide clinical decisions, research must include them, Jest the \"picrure\" of medicine painted by the research be distorted.\n\nAs  Feinstein (1)  put it:\n\nThe term \"hard\" is usually applied to data that are reliable and preferably dimensional k.g., laboratory data, demogrJphic data, and financial costs). Hut clinical performance, convenience, anticipation, ,1nd familial data are \"soft.\" They depend on subjl.'ctive statements, usually expressed in words rather than numbers, by the people who are the observers and til(' observed.\n\nTo avoid sllch soft data, the results of treatml.'nt arc commonly restricted to laborJtory information that Cilll be objective, dinwnsional, and reliablebut it is also dehumilnized. If we are told lhat the serum cholesterol is 230 mg per 100 ml, that the chest X-rily shuws CilrdiJc enlargement, and that the electrocardiogram has Q Wilves, we would not know whether the treated object was a dog or a person. If we were told that capacity at work was restored, that the Illedicine tasted good ,1nd W,lS easy to take, and that the family was happy about the results, we would recognize a human set of responses."
    },
    {
      "title": "RELIABILITY",
      "text": "Reliability is the extent to which repeated measurements of a stable phenomenon-by different people and instruments, at different times and pbces-get similar results. Reproducibility and precision are other words for this property.\n\nThe reliability of laboratory measurements is established by repeated measures-for example, of the same serum or tissue specimen-sometimes by different people and with different instruments. TIle reliability of symptoms can be established by Shll',ving that they are similarly described to different observers under different conditions.\n\nThe relationships between reliability and validity are shown in Figure  2. 1. An instrument (laboratory apparatus or a qucstionnain') used to collect\n\nVALIDITY High low High >u c RELIABILITY co \" u. low A , B , , , a large set of measurements can be valid (accurate) on the average but not be reliable, because the measures obtained are widely scattered about the true value. On the other hand, an instrument can be very reliable but be systematically off the mark (inaccurate). A single measurement with poor reliability has low validity because it is likely to be off the mark simply because of chance alone."
    },
    {
      "title": "RANGE",
      "text": "An instrument may not register very low or high values of the thing being measured, limiting the information it conveys. Thus the \"firstgeneration\" method of measuring serum thyroid-stimulating hormone (1'Sl I) was not useful for diagnosing hyperthyroidism or for precise titration of thyroxine administration because the method could not detect low levels of TSH. Similarly, the Activities of Daily Living scale (which measures people's ability at feeding, continence, transferring, going to the toilet, dressing, and bathing) docs not measure inability to read, write, or play the piano-activities that might be very important to individual patients."
    },
    {
      "title": "RESPONSIVENESS",
      "text": "An instrument is responsive to the extent that its rl.:sults change as conditions change. For example, the New York Heart Association scale-classes 1 to IV (no symptoms, symptoms with slight and moderate exertion, and symptoms at rest)-is not sensitive to subtle changes in congestive heart failure, ones patients would value, whereas laboratory measurements of ejection fraction can detect changes too subtle for patients to notice."
    },
    {
      "title": "INTERPRETABILITY",
      "text": "A disadvantage of scales based on questionnaires that is not generally shared by physical measurl'ments is that the results may not have meaning to clinicians and patients. for example, just how bad is it to have a Zung depression scale value of 72? To overcome this disadvantage, researchers can \"anchor\" scale values to familiar phenomena-for example, by indicating that people with scores below 50 are considered normal and those with scores of 70 or over are severely or extremely dl'pressl'd, requiring immediate care."
    },
    {
      "title": "Variation",
      "text": "Clinical measurements of the same phenomenon can take on a range of values, depending on the circumstances in which they are made. To avoid erroneous conclusions from data, clinicians should be aware of the reasons for variation in a given siLuation and know which are likely to play a large part, a small part, or no part aL all in what has becn observed.\n\nOverall variation is the sum of variation related to the act of measurement, biologic differences within individuals from time to time, and biologic differences from person to person (Table  2 .2)."
    },
    {
      "title": "MEASUREMENT VARIATION",
      "text": "All observations are subject to variation because of the performance of the instruments and observers involved in making the measurement. The conditions of measurement can lead to a biased result (lack of validity) or\n\nTable 2.2"
    },
    {
      "title": "Sources of Variation"
    },
    {
      "title": "Source"
    },
    {
      "title": "Measurement"
    },
    {
      "title": "InstrumE~llt"
    },
    {
      "title": "Observer"
    },
    {
      "title": "Biologic",
      "text": "Within individuals Among individlJills"
    },
    {
      "title": "Dc'ipition",
      "text": "The rne<m~; of rnClking the rneasuremelll The person making the measurernent Changes in people with tirnc and situation Biologic differences frorn person to person simply random error (lack of reliability). It is possible to reduce this source of variation by making measurements with great care and by following standard protocols. However, when measurements involve human judgment, rather than machines, variation can be particularly large and difficult to control.\n\nExample Fetal heart rate is oftt;'n monitored by auscultation, which is subject to observer error. Electronic monitoring gives the true ratc.Fetal heart rates that are unusually high or low arc markers of fetal distress, suggt..sting a need for early delivery.\n\nDay et al. (  2 ) compared fdal heart rates obtained by auscultation by hospital st\",ff with rates obtaint;'d by electronic monitoring (Fig.  2 .2). When the true fetal heart rate was in the normal range, rates by auscultation wert;' evenly distributed about the true valu!.', i.e., there was only random error. But when the true fetal ht;'art rak was unusually high or low, rates by auscultation werc bias!.'d toward normal. Low rates tended to be reported as higher than the trut;' ratt;'s, and high rates as lower than the true rates.\n\nThis study illustrates both random and systematic errors in clinical observations. In this case, the bias toward normal rates might have arisen because the hospital staff hoped the ferus was \\vell and were reluctant to undertake a major intervention based on their observation of an abnormally high or low heart rate.\n\nVariations in measurements also arise because measurements are mtlde on only a sample of the phenomenon being described, which mtly misrepresent the whole. Often the samplingfraction (the fraction of the whole that is included in the sample) is very small. For example, a liver biopsy represents only about l/JOO,OOO of the liver. Because such a small part of the whole is examined, there is room for considerable variation from one sample to another.\n\nIf measurements are made by several different methods (e.g., different laboratories, technicitlns, or instruments) some of the determinations may be unreliable and/or manifest systematic differences from the correct value, contributing to the spread of values obtained."
    },
    {
      "title": "BIOLOGIC VARIATION",
      "text": "Variation also arises because of biologic chtlnges within individuals over time. Most biologic phenomena change from moment to moment. A measurement at a point in time is a sample of measurements during a period of time ilnd mtly not represent the usual value of these measurements.\n\nExample Clinicians estimiltl' the frequency of ventricular premature depolarization (V!'!)) to help determine the need for and effectiveness of treilt-men\\. For practical rt;'asons, they may do so by making relatively brief observations-perhaps feeling a pulse for 1 min or reviewing an electrocardiogram (a record of about 10 sec). llowever, the frequency of VI'Os in a given patient varies over time. To obtain ,1 lilrger sample of VPO rate, a portable (Holter) monitor is sometimes used. f}ut monitoring eveil for extended periods of time can be misll'ilding. figure  23   Figure 2.2. Observer variability. Error in reporting fetal heart rate according to whether the true rate, determined by electronic monitor, is within the normal range, low, or high. (Redrawn from Day E, Maddern L, Wood C. Auscultation of foetal heart rate: an assessment of its error and significance. Br Med J 1968;4:422-424.) VPDs, similar to other patients studied (3). VPDs per hour varied from less than 20 to 380 during a 3-day period, according to day and time of day. The authors concluded: \"To distinguish a reduction in VPD frequency attributable to therapeutic intervention rather than biologic or spontaneous variation alone required a greater than 83% reduction in VPD frequency if only two 24-hour monitoring periods were compared.\"\n\nVilriation also arises because of differences among people. Biologic differences among people predominate in many situations. For example, several studies have shown that high blood pressure on single, casual mea- surements, although subject to all other forms of variation, is related to subsequent cardiovascular disease."
    },
    {
      "title": "TOTAL VARIATION",
      "text": "The several sources or variation are cumulative. Figure  2 .4 i11ustrates this for the measurement of blood pressure. Variation from measurement contributes relatively little, although it covers as much as a 12 mm Hg range among various observers. On the other hand, each patient's blood pressure varies a great deal from moment to moment throughout the day, so th<lt any single blood pressure reading might not represent the usual for that patient. Much of this variation is not random: blood pressure is generally higher when people are awake, excited, visiting physicians, or taking over-the-counter cold medications, Of course, we are most interested in knowing how an individual's blood pressure compares with that of his or her peers, especially if the blood pressure level is related to complications of hypertension and the effectiveness of treatment."
    },
    {
      "title": "EFFECTS OF VARIATION",
      "text": "Another way of thinking about variation is in tenns of its net effect on the validity <lnd reliability of a measurement and what com be done about it. Random variation-for example, by unstable instruments or many ob-servers with various biases that tend to balance each other out-results on average in no net misrepresentation of the true state of a phenomenon if a set of measurements are made; individual measurements, however, may be misleading. Inaccuracy resulting from random variation can be reduced by taking a larger sample of what is being measured, for example, by counting more cells on a blood smear, examining a larger area of a urine sediment, or studying more patients. Also, the extent of random variation can be estimated by statistical methods (see  Chapter 9) . On the other hand, biased results are systematically different from the true"
    },
    {
      "title": "Conditions of Measurement",
      "text": "One patient, one observer, repeated observations at one point in time\n\nOne patient, many observers, at one time"
    },
    {
      "title": "Distribution of Measurements"
    },
    {
      "title": "J\\",
      "text": "Source(s) of Variation"
    },
    {
      "title": "Measurement",
      "text": "One patient, one observer, almanYI;meSOf~, value, no matter how mallY times they are repeated. For example, when investigating a patient suspected of having ,In infiltrative hver disease (perhttps following up an elevated senun alkaline phosphatase) a single liver biopsy may be misleading, depending on how the lesions are distributed in the liver. If the lesion is a metastasis in the left lobe of the jiver, a biopsy in the usual place (the right lobe) would miss it. On the other halld, a biopsy for miliary tul:x'Tculosis, which is represented by miJliOl'LS of small grallulomata throughout the liver, would be inaccurate only through random variation. Similarly, all of the high values for VPDs shown in Figure  2 .3 were recorded on the first day, and most of the low valm.'S on the third."
    },
    {
      "title": "Many patients"
    },
    {
      "title": "Biologic and Measurement",
      "text": "The days were bia. . <;Lu estimates of each other, because of variation in VPD rate from day to day."
    },
    {
      "title": "Distributions",
      "text": "Data that are measured on interval scales are often presented as a figure, called a frequency distributiol1, showing the number (or proportion) of a defined group of people possessing the different values of the measurement (Fig.  2 .5). Presenting interval d<lta as a frequency distribution conveys the information in relatively fine detail.\n\n20 Mode \u2022 15 c: \" CJ 1 0 \" l1. 5 2 3 4 5 6 7 PSA (ng/mL) 8 9 10 Figure 2.5. Measures of central tendency and dispersion, The distribution of prostate-specific antigen (PSA) levels in presumably normal men, (Data from Kane RA, Littrup PJ, Babaian R, Drago JR, Lee F, Chesley A, Murphy GP, Mettlin C. Prostatespecific antigen levels in 1695 men without evidence of prostate cancer. Cancer 1992;69:1201-1201,)\n\nTable 2.3 Expressions of Central Tendency and Dispersion Expression Definition Advantages Disadvantages Mean Sum of values for observations Number of observations Central Tendency Well suited tor mathematical manipulation Affected by extreme values Median Mode The point where the rlumber ot observations above equals the number below Most frequently occurring value Not easily influenced by extreme values Simplicity of meaning Not well suited for mathematical manipulation Sometimes there are no, or many, most frequent values Dispersion Range Standard deviation\" Percentile, decile, quartile, etc. From lowest to highest value in a (Jistribution The absolute value of the average difference 01 individual values tram the mean The proportion of all observations falling between specified values Indudes all values Well suited tor mathematical manipulation Describes the \"unusualness\" of a value without assumptions about the shape of a distribution Greatly affected by extreme values For non-Gaussian distributions, does not describe a known proportion of the observations Not well suited for statistical manipulation where X ~each obse\"\"Rtion; X = rT\"\"' ' ' of ali observations; and N ~number of observations"
    },
    {
      "title": "DESCRIBING DISTRIBUTIONS",
      "text": "It is convenient to smnmari/..l' distributions. IndeeJ, summari7...ation is imperative if a large number of distribution',; art:' to be presentLx:! and compared.\n\nTwo basic properties of distributions aTe used to summarize them: central tendency, the middle of the distribution, and dispersion, how spread out the values are. Several ways of expressing centriJI tendency and dispersion, along with their advantages and disadvantiJges, iJre summarized in Table  2 .3 iJnd illustrated in Figure  2 .5."
    },
    {
      "title": "ACTUAL DISTRIBUTIONS",
      "text": "The frequency distributions of four common blood tests (potassium, alkaline phosphatiJse, glucose, and hemoglobin) are shown in Figure  2 .6. In geneT<\\l, most of the values appear near the middle, and except fOT the  30 20  Serum Alkaline potassium 20\n\nphosphatase 10 10 3.0 4.0 50 20 40 60 80 100120140 c: mEq/L units Gl 0 Gl \"-30 40 Plasma 30 20 glucose Hemoglobin 20 10 10 100 150 200 B 9 10 11 12 13 14 15 16\n\nmg/1 00 mL g/1 00 mL central part of the curves, there are no \"humps\" or irregularities. The high and low ends of the distributions stretch out into tails, with the tail at one end often being more elongated than the tail at the other (i.e., the curves are \"skewed\" toward the long end). Whereas some of the distributions are skewed toward higher values, others are skewed toward lower values. Tn other words, all these distributions are unimodal, are roughly bellshaped, and are not necessary symmetric; otherwise they do not resemble each other.\n\nThe distribution of values for many laboratory tests changes with characteristics of the patients such as agc, sex, racl', and nutrition. figure  2 .7 shows how the distribution of one such test, blood urea nitrogen (BUN), changes with age. A BUN of 25 mg/lOO mL would be unusually high for a young person, but not particularly remarkable for an older person."
    },
    {
      "title": "THE NORMAL DISTRIBUTION",
      "text": "I\\nother kind of distribution, called the \"nonna)\" or Caussian distribution, is sometimes asswned to approximate naturally oCCllTring distributions, though it is based in statistical theory and has no nC\"Cl'ssary relationship to natural distributions. The normal curve describes the frequency distribution of repeated measurements of the same physical object by the same instrument. Dispersion of values represents random variation alone. A normal curve is shown in Figure  2  >-\" l:\n\n. .\n\n2.14 13.59 34.13 34.13 13.59 2.14"
    },
    {
      "title": "Percent of area under the curve",
      "text": "--68.26-:\n\n---95.44 --------99.72 -----. mathematical property that about two-thirds of the observations fall within ] standard deviation of the mean, and about 95'\\\"0 within 2 standard deviations.\n\nAlthough clinical distributions often resemble a normal distribution the resemblance is superficial. As nne statistician (4) put it:\n\nThe experimental fact is that for most physiologic variables the distribution is smooth, unimodal, and skewed, and that mean ::'::2 standard deviations does not cut off the desired ':15%. We have no mathematical, stillistical, or other theorems that enable us to predict the shape of the distribution.,; of phySiologic measurements.\n\nVVhereas the normal distribution is derived from mathematical theory and reflects only random variation, many other sources of variation contribute to distributions of clinical measurements, especially biologic differences among people. Therefore, if distributions of clinical measurements resemble normal curves, it is largely by accident. Even so, it is often assumed, as a matter of convenience (because means and standard deviations are relatively easy to calculate and manipulate mathematically), that clinical measurements are \"normally\" distributed."
    },
    {
      "title": "Criteria for Abnormality",
      "text": "It would be convenient if the frequency distributions of clinical measurements for normal and abnormal people were so different that these distributions could be used to distinguish two or more distinct populations.\n\nThii::i is the case for specific DNA and RNA sequences and antigens (Fig.  2 .9A), which are either present or absent, although their clinical manifestations may not be so dear-cut.\n\nHowever, most distributions of clinical variables are not easily divided into \"normal\" and \"abnormal,\" because they are not inherently dichotomous and they do not display sharp breaks or two peaks that\n\nA Normal Mutant B o A lIeles for Phenylalanine Hydroxylase 2 4 6 8\n\nBlood Phenylalanine (mg IdL)\n\n10 Figure 2.9. Screening for phenylketonuria (PKUj in infants: dichotomous and overlapping distributions of normal and abnormal. A, Alleles coding for phenylalanine hydroxylase are either normal or mutant. B, The distributions of blood phenylalanine levels in newborns with and without PKU overlap and are of greatly different magnitude. (The prevalence of PKU, actually about 1/10,000, is exaggerated so that its distribution can be seen in the figure.) ch<lr<lcterize normal <lnd abnormal results. There are sever<ll reasons why this is so.\n\nFor m<lny laboratory tests there are not even theoretical w<lsons for believing that distinct popul<ltions-weJl <lnd diseased---exist. Disease is acquired by degrees, and so there is a smooth transition from low to high v<llues with increasing degrees of dysfunction. Laboratory tests reflecting organ f<lilure, such <IS serum creatinine for renal failure, behave in this \\\\'<lY.\n\nIn other situations, well and diseased persons do in fact belong to separate populations, but when the two populatio11s are mixed together they C<ltlHot be recognized as separate bec<luse values for the abnormals v<lry, they overlap thosc for normals, and there are few <lbnormals in the popul<ltion.\n\nExample Phenylketonuriil (I'KU) is <1 disease characterized by progressive mental retilfliiltiotl in childhood. 1\\ variety of mutant ilileles coding for phenylalanine hydroxylase results in dysfunction of the enzyme and, with iI normal diet, accumulation of phenylalanine. The diah'llosis, which becomes appilrent in the first year of life, is confirmed by persistently high phenylalanine len'ls (several times the usual range) and low tyrosine levels in the blood.\n\n11 is common prilclice to screen newborns for PKC with a blood test for phenylalanine a few dilys after birth, in time to treat before there is irreversible damilgl'. However, the test misclassifies some infants, because ilt th,lt age there is an overlap in the distributions of serum phenylalanine concentriltions in infants with ilnd without PKU and bl.'cause infants with I'KU make up only a small proportion of those screened, about IIlO,OOO (Fig.  2 .9Ll). Some newborns with PKU are in Lhe normill range either beciluse they have not yet ingested enough protein or because they ha~e a combiniltion of alleles associated with mild disease. Some childrell who are not destined to develop PKU hilvc relatively high levels \u2022\u2022-for eXMnple, bec,ltlsc their mothers have abnormill phenylalanine mdilbolism. The test is set Lo be positive at the lower end of tlw overlap between normal and abnonnill levels, to detect most infants with thl.' disease, even though only about lout of 5 infants with an ilhn(lrmal screening test turns out to hilve I'KL'.\n\nIn unse!cctcd populations, the diseased patients often do not stand out because there are very few of them relative to normal pc'ople and bL'Cause laboratory valucs for the diseased popubtion overlap thosc for normals. The curve for diseased people is \"swallowed up\" by the larger curve for normal people. If, on the other hand, normal and diseased populations are mixed in more equal proportions-perhaps by selecting out for testing people with an unusually high likelihood of disease-thc11 the resulting distribution could be truly bimodal. Eve11 so, it would not be possible to choose a test value th<lt dearly separates diseased and nnndiscased persons (see  Chapter 3) .\n\nIf there is no sharp dividing line between normal and abnormaL and the clinician can choose where the Hne is placed, what ground rules should be used to decide? Three criteria have proven useful: being unusual, being sick, and being treatable. For a given measuremer,t, the results of these approaches bear no necessary relation to each other, so that what might be considered abnormal using one criterion might be normal by another."
    },
    {
      "title": "ABNORMAL ~UNUSUAL",
      "text": "Normal often refers to the most frequently occurring or usual condition. Whatever occurs often is considered normal, and whatever occurs infrequently is abnormal. This is a statistical definition, based on the frequency of a characteristic in a defined population. Commonly, the reference population is made up of people without disease, but this need not be the case. For example, we may say that it is normal to have pain after surgery or for eczema to itch.\n\nIt is tempting to be more specific by defining what is unusual in mathematical terms. One commonly used way of establishing a cutoff point between nonnal and abnormal is to agree, somewhat arbitrarily, that all values beyond 2 standard deviations from the mean are abnormal. On the assumption that the distribution in question approximates a normal (Gaussian) distribution, 2.5\u00b0/\" of observations would then appear in each tail of the distribution and be considered abnormal.\n\nOf course, as already pointed out most biologic measurements are not normally distributed. So it is better to describe unusual values, whatever the proportion chosen, as a fraction (or percentile) of the actual distribution. In this way, it is possible to make a direct statement about how infrequent a value is without making assumptions about the shape of the distribution from which it came.\n\nA statistical definition of normality is commonly used but there are several ways in which it can be ambiguous or misleading.\n\nFirst, if all values beyond an arbitrary statistical limit, say the 95th percentile, were considered abnormal, then the prevalence of all diseases would be the same, 5'%. This is inconsistent with our usual way of thinking about disease frequency.\n\nSecond, there is no general relationship between the degree of statistical unusualness and clinical disease. The relationship is specific to the disease in question. For some measurements, deviations from usual are associated with disease to an important degree only at quite extreme values, well beyond the 95th or even the 99th percentile."
    },
    {
      "title": "Example",
      "text": "The World Health Organization (WHO) considers anemia to be prcs<'nt when hemoglobin (lib) le\\'('ls are below 12 g/lOO mL in adult nonpregnant females. In a British survey of women aged 20-64, Hb was below 12 g/lOO mL in 11% of 920 nonpregnant women, twice as many as would be expected if the criterion for abnormality were excel;'ding 2 standard deviations  (5) . But were the women with Hb levels below 12 g/lOO mL \"diseased\" in any way because of their rl;'jiltively low llb? Two possibilities come to mind: The low I Ib may be ,1ssociated with symptoms or il may be a manifestation of serious underlying disease. Symptoms such as fatigue, dizziness, ilnd irritabilitv were not correlaled with Hb level, at least for women whose Hb was above 8.0. Moreover, oral iron, given to women with Hb between .s.o and 12.0, increased fib by an average of 2..iO g/100 mL but did not lead to any greater improvement in symptom::; than was experienced by women given placebo. As for serious underlying disease, it is lrue that occasionally low Hb may be a manifestation of cancer, chronic infection, or rheumatic disea::;es. But only il very small proportion of women with low Hb have these conditions_\n\nThus only at Hb level::; below 8.0, which occurred in less than 1':;, of these women, might anemia he an important health problem.\n\nThird, many laboratory tests are rl'lated to risk of disease over their entire range of vaIUl_'S, from low to high. for serum cholesterol, there is an almost threefold increase in risk from the \"low normal\" to the \"high normal\" range.\n\nFourth, some extreme values are distinctly unusual but preferable to more usual ones. This is particularly true at the low end of some distributions. Who would not be plea~ed to have a ~erum creatinine of 0.4 mg/ 100 mL or a ~y~tolic blood pressure of 105 mm Hg? Both are unusual1y low but they represent better than average health or risk.\n\nFinally, sometimes patients may have, for laboratory t{'~ts diagnostic of their disease, values in the usual range for healthy people, yet clearly be disea~ed. Examples include low pressure hydrocephalus, normal pressure glaucoma, and norm()Gllcemic hyperparJthyroidism."
    },
    {
      "title": "ABNORMAL --= ASSOCIATED WITH DISEASE",
      "text": "A sowlder approach to distingUishing normal from abnormal is to call abnormal those observations that Jfe regularly associated with disease, disability, or death, i.e., clinically meaningful departures from good health.\n\nExample What is a \"normal\" alcohol (ethanol) intake? S<.'veral studies have shown a U-shaped relationship between alcohol intake and mortality: high death rates in abstainers, lower rates in moderate drinkers, and high rates in heavy drinkers (Fig.  2 .10). It has been suggested lhat the lower death rates with increasing alcohol consumption, ilt the lower end of the curve, occur because alcohol raises high density lipoprotein levels, which protects against cardiovascular disease. Alternatively, when people become ill they reduce their alcohol consumption and this could explain the high rate of mortality assocbted with low alcohol intake (6)_ High deilth rales at high intake is less controversial: alcohol i::; a cause of several fatal diseases (heart disease, cancer, and stroke). The interprclation of the causes for the U-shaped curve determines whether it is as abnormal to abstain as it is to drink heavily."
    },
    {
      "title": "ABNORMAL -TREATABLE",
      "text": "Par some conditions, particularly those that are not troublesome in their own right (i.e., are asymptomatic), it is better to consider a measurement abnorm<ll only if treatment of the condition represented by the mC<lsure- ment leads to <l better outcome. This is because not everything that is <Issoci<lted with an increased risk can be successfully treated: the removal of the condition may not remove risk, either because the condition itself is not a cause of disease bu t is only related to il ca use or because irreversible damage has already occurred. Also, to label people abnormal can cause adverse psychological effects that ilre not justified if treatment cannot improve the outlook. What we consider treatable changes with time. At their best, therapeutic decisions are grotmded on evidence from well-conducted clinical trials (Chapter 8). As ne\"v knowledge is acquired from the results of clinical trials, the level at which treiltment is considered useful may change. For eX<lmple, accumulating evidence for treating hypertension has changed the definition of what level is treatilble. As more studies are conducted, successively lower levels of diaslolic blood pressure have been shown to be worth treating."
    },
    {
      "title": "Regression to the Mean",
      "text": "When clinicians encounter an unexpectedly abnormal lest result, they tend to repeat the test. Often the second test result is closer to normal. Why dm's this happen? Should it be reassuring 7  Patients selected because they represent an extreme value in a distribution can be expected, on the average, to have le,:;s extreme values on subsequent measurements, This occurs for purely statistical reasons, not because the patients have necessarily improved. The phenomenon is called regression to tile meall.\n\nRegression to the mean arises in the following way  (fig 2.11) . People are first selected for inclusion in a study or for further diagnosis or treatment because their initial measurement for a trait fell beyond an arbitrarily selected cutoff point in the t<lil of a distribution of values for all the patients examined. Some of these people will remain above the cutoff point on subsequent measurements, because their true v<llues are usually higher than average. But others who were found to have values above the cutoff point during the initial screening usually have lower values. They were selected only because they happened, through random variation, to have a high value at the time they were first measured. When the measurement is taken again, these people have lower values than they had during the first screening. This phenomenon tends to drag down the mean value of the subgroup originally found to have values above the cutoff point.\n\nThus patients who are singled out from others because of a laboratory test result that is unusually high or low can be expected, on average, to be closer to the center of the distribution if the test is repe<lted. Moreover, subsequent values are likely to be more accurate estimates of the true value, which could be obtained if measurements were repmted for a particular patient many times. So the time-honored pr.:;~tice of repeating laboratory tests that are found to be abnormal and of considering the second one, which is often within normal limits, the correct one is not just wishful thinking. It has a sound theoretical basis. It also has an empirical basis. For example, it has been shown that half of serum T 4 tests found to be outside normal limits on screening were within normal limits when repmtcd  (7) . However, the more extreme the initial reading is, the less likely it is to be normal if it is repeated."
    },
    {
      "title": "Summary",
      "text": "Clinical phenomena are measured on nominal, ordinal, and interval scales. Although many clinical observations fall on a continuum of values, for practical reasons they are often simplified into dichotomous (normal! abnormal) categories. Observations of clinical phenomena vary because of measurement error, differences in individuals from time to time, and differences among individuals. The performance of a method of measurement is characterized by validity (Does it measure what it intends to measure?), reliability (Do repeated measures of the same thing give the same result?), range, responsiveness, and interpretability.\n\nFrequency distributions for clinical variables have different shapes, which can be summarized by describing their central tendency and dispersion.\n\nLaboratory values from normal and abnormal people often overlap; because of this and the relatively lovv prevalence of abnormals, it is usually not possible to make a dean distinction between the two groups using the test result alone. Choice of a point at which normal ends and abnormal begins is arbitrary and is often related to one of three definitions of abnormality: statistically unusuaL associated with disease, or treatable. If patients with extreme values of a test are selected and the test is repeated, the second set of va lues is likely to fa 11 closer to the central (statistically normal) part of the frequency distribution, a phenomenon called regression to the mean."
    },
    {
      "title": "RHI+:RENCES",
      "text": "I. Feinstein AR. The need for humanized ~cience in eVJluating l1wdicJtion. Lancet 1972;2:421-423."
    },
    {
      "title": "2.",
      "text": "[Jay E, Maddern L, Wood c:. Auscultation of fnetal h\",ul ratc: an assessment of its error and significance, IJr Med j 196H;4:422424, 3. Morgamoth J, Michelson EL, Horowitz LN, Josephson ME, Pearlman AS, Dunkman WB.\n\nLimitations of routine long-term electrocardiographic monitoring to asses~ventricular ectopic frequency. Circubtion 1978; 58:408-414. 4. Flwhil(\u2022k 1.1'. Cuillin CI .. Kl'ating FR. H\"\"lth, normality, and the ghc\"t of <; auss. j; \\Mi\\ 1970; 211:69--75 ."
    },
    {
      "title": "DIAGNOSIS",
      "text": "Appearances to the mind are offour kinds.\n\nThings either arc what they appear to be; or they neither arc, nor appear to be; or they arc, and do not appear to be; or they are not, yet appear to be. Rightly to aim i/1 all these cases is the wise man's task Epictetus, 2nd century A.D.\n\nClinicians devote a great deal of time to detennining diagnoses for complaint!; or abnormalities presented by their patients. They arrive at the diilgnost.'s after applying various diagnostic tests. Most competent clinicians use good judgment, a thorough knowledge of the literature, and a kind of rough-and-ready approach to how the informiltion should be organized. However, there are also basic principles with which a clinician should be familiar when interpreting diagnostic tests. This chapter deals with those principles.\n\nA diagnostic test is ordinarily taken to mean a test performed in a laboratory. But the principles discussed in this chapter apply equally well to clinic<ll inform<ltion obtained from history, physical examination, and imaging procedures. They <llso apply where a constellation of findings serves as a diagnostic test. Thus one might speak of the value of prodromal neurologic symptoms, headache, nausea, and vomiting in diagnosing classic migraine or of hemoptysis and weight loss in a cigarette smoker as indicators of lung cancer."
    },
    {
      "title": "Simplifying Data",
      "text": "In Chapter 2, it was pointed out that clinical measurements, including data from diagnostic tests, are expressed on nominal, ordinal, or interval scales. Regardless of the kind of data produced by diagnostic tests, clinicians generally reduce the data to a simpler form to make them useful in pradice. Most ordinal scales are examples of this simplification process. Obviously, heart murmurs can vary from very loud to inaudible. But trying to express subtle gradations in the intensity of murmurs is unnecessary for clinical decision making. A simple ordinal scale-grades I to VI-43 serves just as welL More often, complex data are reduced to a simple dichotomy, e.g\" present/absent, <lbnormal/no,mal, or diseased/well. This is particularly done when test results Me used to decide on treatment. At any given point in time, therapeutic decisions are either/or decisions. Either treatment is begun or it is withheld. The use of blood pressure d<lt<l to decide about therapy is an example of how we simplify inform<ltion for practical clinical purposes. Blood pressure is ordin<lrily measured to the nearest 2 mm Hg, i.e\" on an interval scale. However, most hypertension treatment guidelines, such as those of the Joint National Committee on the Detection, Evaluation, and Treatment of Hypertension (1) and of most physicians, choose a particular level (e.g., % mm Hg diastolic pressure) at which to initiate drug treatment. In doing so, clinici<lns have transformed interval data into nominal (in this case, dichotomous) data. To take the example further, the Joint National Committee recommends that a physician choose a treatment plan according to whether the patient's diastolic blood pressure is \"mildly elevated\" (90-94 mm Hg), \"moderately elevated\" (95-114 mm Hg), or \"severely e]cvated\" (:2:115 mm Hg), an ordinal scale,"
    },
    {
      "title": "The Accuracy of a Test Result",
      "text": "Establishing diagnoses is an imperfect procei:is, resulting in a probability rather than a certainty of bei.ng right. In the past, the doctor's diagnostic certainty or uncertainty was expressed by using terms such as rule Ollt or possible before a clinical diagnosis. Increasingly, the modem cHllician expresses the likelihood that a patient has a disease by using a probability. Tha.t being the case, it behooves the clinician to become familiar with the mathematical relationships between the properties of diagnostic tests and the information they yield in v<lriom; clinical situations. In many in.<;tances, understanding these issues will help the clinician resolve some uncertainty surrounding the use of diagnostic tests. In other situations, it may only increase understanding of the uncertainty. Occasionally, it may convince the clinician to increase his or her level of uncertainty.\n\nA simple way of looking at the relationships between a test's results and the true diagnosis is shown in Pigure 3,1. The test is considered to be either positive (abnormal) or negative (normal), and the discai:ie is either present or absent. There are then four possible interpretations of the test results, two of which are correct and two wrong. The tei:it has given the corrc'Ct answer when it is positive in the presence of disease or negative in the absence of the disease. On the other hand, the test has been misleading if it is positive when the disease is absent (false positive) or negative when the disease is present (false negative). The relationship between a diagnostic lest result and the occurrence of disease, There are two possibilities for the test result to be correct (true positive and true negative) and two possibilities for the result to be incorrect (false positive and false negative),"
    },
    {
      "title": "THE GOLD STANDARD",
      "text": "A5sessment of the test's accuracy rest5 on its relationship to some way of knowing whether the disease is truly present or not-a sounder indication of the truth often referred to as the \"gold standard.\" As it turn5 out, the gold standard i5 often elusive. Sometimes the standard of accuracy is itself a relatively 5impk and inexpensive test, such a5 a throat culhtre for group A (:I-hemolytic streptococcus to validate the clinical impression of strep throat or an antibody test for human immunodeficiency virus. However, this is usually not the case. More often, one must turn to relatively elaborate, expensive, or risky tests to be certain whether the disease is present or absent. Among these are biopsy, surgical exploration, and of course, autop5Y.\n\nFor di5eases that are not self-limited and ordinarily become overt in a matter of a few years after they are first suspected, the results of followup can serve as a gold standard. Most cancers and chronic, degenerative diseases fall into this category. For them, validation is possible even if onthe-spot confirmation of a test's performance is not fea5ibk because the immediately available gold standard is too risky, involved, or expensive. Some care must be taken in deciding the length of the follow-up period, which must be long ('fi{lUgh for the disease to manifest but not so long that cases can arise after the original testing.\n\nl3ecause it is alm05t always more costly and more dangerous to use these more accurate ways of establishing the truth, clinicians and patients prefer simpler tests to the rigorous gold standard, at least initially. Chest x-rays and sputum smears are useo to determine the nature of pneumonia, r<lther than hmg biopsy vvith examination of :he diseased lung tissue. Similarly, electrocardiograms and serum enzymes are often used to establish the diagnosis of <lCute myocardial infarction, rather than catheterization or imaging procedures. The simpler tests arc used as proxies for more elaborate but more accurate ways of est<lblishing the presence of disease, with the understanding that some risk of misdassification results. This risk is justified by the safety and convenience of the simpler tests. But Simpler tests are only useful when the risks of misclassificaLion are known <'Ind fOlUld to be acceptably 1m,\\,. This requires sound data that compare their accuracy to an appropriate standard."
    },
    {
      "title": "LACK OF INFORMATION ON NEGATIVE TESTS",
      "text": "The goal of all clinical studies describing the value of diagnostic tests should be to obtain data for all four of the cells shown in Figure  3 .1. Without all these data, it is not possible to assess the risks of misdassification, the critical questions about the performance of the tests. Given that the goal is to fill in all four cells, it must be st<lted that sometimes this is difficult to do in the real world. It may be that an objective and valid means of establishing the diagnosis exists, but it is not available for the purposes of formally establishing the properties of a diagnostic test for ethical or practical reasons. Consider the situation in which most information about diagnostic tests is obtained. Published accounts come primarily from clinical, and not research, settings. Under these circumstances, physicians are using the test in the process of caring for patients. They feel justified in proceeding with more exhaustive evalu<ltion, in the patient's best interest, only when preliminary diagnostic tests arc positive. They are naturally reluctant to initi<lte an aggressive workup, with its associated risk and expense, when the test is negative. As a result, information on negative tests, whether true negative or false negative, tends to be much less complete in the medical literature.\n\nThis problem is illustrated by an influential study of the utility of the blood test that detects prostate specific antigen (PSA) in looking for prostate cancer  (2) . Patients with PSAs above a cutoff level \\vt're subjected to biopsy while patients with PSAs belmv the cutoff were not biopsied. The authors understandably were reluctant to subject men to an uncomfortable procedure without supporting evidellce. As J result, the study I('av('~us unable to determine the false-negative rate for PSA screening."
    },
    {
      "title": "LACK OF INFORMATION ON TEST RESULTS IN THE NONDISEASED",
      "text": "As discussed above, clinicians are understandably loath to perform elaborate testing on patients who do not have problems. An evalu<ltion of a test's performance can be grossly misleading if the test is only applied to patients with the condition.\n\nExample Magnetic resonance imaging (MI~I) of the lumbar spine is frequently used in the evaluation of patients with low L'ack pain. Many patients with back pain show herniated intervertebral disks on MRI, which often serves to explain the pain and guide treatment.\n\nMRls were performed on 98 asymptomatic volunteers  (3) . The studies were read by radiologists who did not know the symptom status of the patients. Bulging or protruding disks were found in nearly two-thirds of asymptomatic subjects, only slightly lower than the frequency of similar abnormality in patients with back pain. The authors concluded that such findings \"may frequently be coincidentaL\""
    },
    {
      "title": "LACK OF OBJECTIVE STANDARDS FOR DISEASE",
      "text": "For some conditions, there are simply no hard-and-fast criteria for diagnosis. Angina pectoris is one of these. The clinical manifestations were described nearly a century ago, Yet there is still no better way to substantiate the presence of angina pectoris than a carefully taken history. Certainly, a great many objectively measurable phenomena arc related to this clinical syndrome, for example, the presence of coronary artery stenoses seen on angiography, delayed perfusion on a thallium stress test, and characteristic abnormalities on electrocardiograms both at rest and with exercise. All are more commonly found in patients believed to have angina pectoris. But none is so closely tied to the clinical syndrome that it can serve as the standard by which the condition is considered present or absent.\n\nSometimes, usually in an effort to be \"rigorous,\" circular reasoning is applied. The validity of a laboratory test is established by comparing its results to a clinical diagnosis, based on a careful history of symptoms and a physical examination. Once established, the test is then used to validate the clinical diagnosis gained from history and physical examination! An example would be the use of milnometry to \"confirm\" irritable bowel syndrome, because the contraction pattern demonstrated by manometry and believed to be characteristic of irritilble bowel was validated by clinical impression in the first place."
    },
    {
      "title": "CONSEQUENCES OF IMPERFECT STANDARDS",
      "text": "Because of such difficulties as these, it is sometimes not possible for physicians in practice to find information on how well the tests they use compare with a thoroughly trustworthy standard. They must choose as their standard of validity another test that admittedly is imperfect but is considered the best available. This may force them into comparing one weak test against another, with one being taken as a stand<Hd of validity because it has had longer use or is considered superior by a consensus of experts. In doing so, a paradox may arise. If a new test is compared with an old (but inaccurate) standard test, the new test may seem worse even when it is actually bdte'. For example, if the new test is more sensitive than the standard test, the additional patients identified by the new test would be considered false positives in relation to the old test. Just such a situation occurred in a comparison of real-time ultrasonography and ora] cholecystography for the detection of gallstones (  4 ).]n five patients, ultrasound was positive for stones that were missed on an adequate chok'Cystogram. Two of the patients later underwent surgery and gallstones were found, so that for at least those two patients, the standard oral cholecystogram was actually less accurate than the newer real-time ultrasound. Similarly, if the new test is more often negative in patients who really do nnt have the disease, results for those patients will be considered false negatives compared with the old test. Thus, if an inaccurate standard of validity is used, a new test can perform no better than that standard and will seem inferior when it approximates the truth more closely. DISEASE Present Positive a a+b +pv\",\u00e3 +b TEST Negative d c+d -PV = ---<L c+d a+c b+d a+b+c+d Se\",~SP=\u00e3 +c b+d P a+c '\" a+b+c+d ---'L LR+ = a + c b+d -\"---LR_=a+c ---<L b+d Figure 3.2. Diagnostic test characteristics and definitions. Se -sensitivity; Sp -,-specificty; P \"\"\" prevalence; PV -predictive value."
    },
    {
      "title": "Sensitivity and Specificity",
      "text": "with these relationships in detail. Figure  3 .3 illustrates these relationships. The diagnostic test is housestaff's clinical impression of whether patients complaining of pharyngitis have a group A tJ-hemolytic streptococcus infection or not, and the gold standard is a throat culture."
    },
    {
      "title": "DEFINITIONS",
      "text": "As can be seen in Figure  3 .2 sensitivity is defined as the proportion of people with the disease who have a positive test for the disease. A sensitive test will rarely miss people with the disease. Specificity is the proportion of people without the disease who have a negative test. A specific test will rarely misdassify people without the disease as diseased.\n\nApplying these definitions to the pharyngitis example (Fig.  3 .\n\n3), we see that 37 of the 149 patients with sore throats had positive cultures, and Group A B = Hemolytic Streptococcus on Throat Culture Present Clinical Ves 27 62 + PV == 27 == 44% Diagnosis 62 of Strep Pharyngitis No 77 87 -pV== 77 =88% 87 37 112 149 Se ==~~== 73% Sp = 1~~== 69% p == ?I9 == 25% 27 LR+ == 27 + 10 == 2.3 35 35 + 77 10 10 + 27 LR -== ----== 0.39 77 77 + 35 housestaff correctly diagnosed 27 of these-for a sensitivity of 73%, On the other hand, 112 patients had negative culture results; housestaff correctly withheld antibiotics from 77, for a specificity of 69%."
    },
    {
      "title": "USES OF SENSITIVE TESTS",
      "text": "Clinicians should take the sensitivity and specificity of a diagnostic test into account when a test is selected. A sensitive test (Le., one that is usually positive in the presence of disease) should be chosen when there is an important penalty for missing a disease. This would be so, for example, when there is reason to suspect a dangerous but treatable condition, such as tuberculosis, syphilis, or Hodgkin's disease. Sensitive tests are also helpful during the early stages of a diagnostic workup, when a great many possibilities are being considered, to reduce the number of possibilities. Diagnostic tests are used in these situations to rule out diseases, i.e., to establish that certain diseases are unlikely possibilities. For example, one might choose an HIV antibody test early in the evaluation of lung infiltrates and weight loss to rule out an AIDS~related infection. In sum, a sensitive test is most helpful to the clinician when the test result is negative."
    },
    {
      "title": "USES OF SPECIFIC TESTS",
      "text": "Specific tests are useful to confinn (or \"rule in\") a diagnosis that has been suggested by other data. This is because a highly specific test is rarely positive in the absence of disease, i.e., it gives few false-positive results. Highly specific tests are particularly needed when false-positive results can harm the patient physica1ly, emotionally, or financially. Thus, before patients are subjected to cancer chemotherapy, with all its attendant risks, emotional trauma, and financial costs, tissue diagnosis is generally required instead of relying on less specific tests. In sum, a specific test is most helpful when the test result is positive."
    },
    {
      "title": "TRADE-OFFS BETWEEN SENSITIVITY AND SPECIFICITY",
      "text": "It is obviously desirable to have a test that is both highly sensitive and highly specific. Unfortunately, this is usually not possible, Instead, there is a trade-off between the sensitivity and specificity of a diagnostic test. This is true whenever clinical data take on a range of values. In those sihtations, the location of a cut-off point, the point on the continuum between normal and ,1bnormal, is an arbitrary decision. As a consequence, for any given test result expressed on a continuous scale, one characteristic (e.g., sensitivity) can be increased only at the expense of the other (e.g., specificity). Table  3 .1 demonstrates this interrelationship for the diagnosis of diabetes. If we require that a blood sugar taken 2 ill after eating be greater than 180 mg ''/0 to diagnose diabetes, all of the people diagnosed as \"diabetic\" would certainly have the disease, but many other people with diabetes would be missed using this extremely demanding definition of the disease. The test would be very specific at the expense of sensitivity. At the other extreme, if anyone with a blood sugar of greater than 70 mg ' X, were diagnosed as diabetic, very few people with the disease would be missed, but most normal people would be falsely labeled as having diabetes. The test would then be sensitive but nonspecific There is no way, using a single blood sugar determination under standard conditions, that one can improve both the sensitivity and specificity of the test at the same time.\n\nAnother way to express the relationship between sensitivity and specificity for a given test is to construct a curve, called a receiver operator characteristic (1{00 curve. An ROC curve for the use of a single blood sugar determination to diagnose diabetes mellitus is illustrated in Figure  3 .4. It is constructed by plotting the true-positive rate (sensitivity) against the false-positive rate (I-specificity) over a range of cut-off values. The values on the axes run from a probability of 0 to 1.0 (or, alternatively, from 0 to 100'};,). Figure  3 .4 illustrates the dilemma created by the trade-off between sensitivity and specificity. A blood sugar cutoff point of 100 will miss only 11% of diabetics, but 30'~o of normals will be alarmed by a false-positive report. Raising the cutoff to 120 reduces false-positives to less than 10% of normals, but at the expense of missing nearly 30% of cases.\n\nTests that discriminate well crowd toward the upper left comer of the ROC curve; for them, as the sensitivity is progressively incrmsed (the\n\nSPECIFICITY (%) 100 80 60 40 20 / '0 80 l\" \u2022 , 00 / 80 110/ / 20 -/ --\" / ;1! ;f''(U 'co Cutoff points -_. I (mg/l00 mL) / > 60 no / 40 >- > \" / >-> ''0 > -.-/ >\" '50 / >->-~,eo / '\" inc. 40 no / 60 z , '80 W z\" / '\" W , '\" / , '\" . ->-'00 / 20 / 80 / / / 0 -' 20 40 60 80 100 1-SPECIFICITY (%) (False-positive rate) -----Figure 3.4. A ROC curve. The accuracy of 2-hr postprandial blood sugar as a diagnostic test for diabetes mellitus. (I)ata Iron I Public Health Service, Diabetes program guide. PuhliC8tion no, 506 Washington, DC: U.S. Government Printing Office. 1960.)\n\ncutoff point is lowered) there is little or no loss in specificity until very high levels of sensitivity <Ire achieved. Tests that perform less well have curves that fall closer to the diagon<l] running from lower left to upper right. The diagonal shows the relationship between true-positive and falsepositive r<ltes that would occur for a test yielding no inform<ltion, e.g., if the clinician merely fljpped a coin.\n\nThe ROC curve shows how severe the trade-off between sensitivity and specificity is for a test and c<ln be used to help decide where the best cutoff point should be, Generally, the best cutoff point is at or near the \"shoulder\" of the ROC curve, unless there are clinic<ll reasons for minimizing either false negatives or false positives.\n\nROC curves are particularly valuable ways of comparing alternative tests for the same diagnosis. The overall accuracy of a test C<ln be described as the area under the ROC curve; thl' larger the area, thl' better the test. Figure  3 .5 compares the ROC curves for two questionnaire tests used to screen for alcoholism in elderly patients-the CAGE and the MAST (Michigan Alcoholism Screening Test)  (5) . The CAGE is both more sensitive and more specific than the MAST and includes a much larger area under its curve.\n\nObviously, tests that are both sensitive and specific are highly sought after and GlIl be of enormous value. However, practicing clinicians rarely work with tests that are both highly sensitive and specific. So for the present, we must use other means for circumventing the trade-off between sensitivity and specificity. The most common way is to use the results of several tests together (as discussed below)."
    },
    {
      "title": "Establishing Sensitivity and Specificity",
      "text": "Not infrequently, a new diagnostic test is described in glowing temlS when first introduced, only to be found wanting later when more experience with it has accumulated. Enthusiasm for the clinical value of scrum carcinoembryonic antigen (CEA) waxed and then waned in this way. At first, CEi\\ was considered a very promising means of diagnosing colon cancer. 13ut subsequently CEA was shown to be increased in a wide variety of other conditions as \\vell as in approximately 20% of smokers without cancer. This kind of confusion-initial enthusiilsm followed by disappointment-arises not from any dishonesty on the part of early investigators or unfair skepticism by the medical community later. Rather, it is related to limitations in the methods by 'which the properties of the test were established in the first place. At the crudest level, the properties of a diagnostic test-sensitivity and specificity, for examp!e-\u2022-may be inaccurately described because an improper standard of validity has been chosen, as discussed previously. However, two other issues related to the selection of diseased and nondiseased patients can profoundly affect the determination of sensitivity and specificity as well. They are the spectrum of patients to which the test is applied and bias in judging the test's performance. A third problem that can lead to inaccurate estim<:ltes of sensitivity and specificity is chance."
    },
    {
      "title": "SPECTRUM OF PATIENTS",
      "text": "Difficulties may arise \\vhen patients used to describe the test's properties arc different from those to whom the test will be applied in clinical practice, Early reports often assess the test's value among people who are deilfly diseased compared with people who are clearly not diseased, e.g., medical student volunteers. Thc tcst may be able to distinguish between these extremcs very well.\n\nEven patients with the disease in question can differ in severity, stage, or duration of the disease, and a test's sensitivity will tend to be higher in more severely affected patients.\n\nExample Pigure 3.6 illuslrCltes how th., performance of the test CEA vClries with the stage of (olmeda] cancer. CEA performs well for metastatic diseCise Jnd poorly for localized cancer. Thus the sensitivity (or \"colorecta! cancer\" depends on the pcHliculiH 111 ix of stagc'S of pCltic'nts with disease used to describe the test, C1nd its i1c(\"urCiCY is 1110f(-' stable within stages  (6) .\n\nSimila.r1y, some kinds of people without disease, such as those in whom disease is suspected, may have other conditions that cause a positive test, thereby increasing the false-positive rate and decreasing specificity. For example, CEA is also elevated in many patienls with ulcerative colitis or c;rrhosis. If patients with these diseases wcrc includcd in the nondiseased group when studying the performance or CEA for (oloreda! cancer, false positives would increase and the specificity of the test for cancer would fall.\n\nIn theory, the sensitivity and specificity of a test are said to be indepmdent of the prevalence of diseased individuals in the sample in which the test is being evaluilted. (Work wilh Pigurc 1.2 to confirm this for yourself.) In prac-\n\nSPECIFICITY > >-0.4 > >-'\" z 0.6 w '\" , --0.2 --0.8 0.2 0.4 0.6 , 1 \" -: : ~_1_ -;-;;f StageD _--....... ... ... --\". ... Stagec ... Cutoff Point ... 2.5 ng/mL \u2022 5.0 ng/rnL .10.0 ng/mL 0.8 , , , tice, however, several characteristics of patients, such as stage and severity of disease, may be related both to the sensitivity and specificity of <l test and to the prevalence, because different kinds of patients are fOlmd in high-and low-prevalence situations. Using a test to screen for disease illustrates this point (see Chapter 8 for a fuller discussion of screening). Screening involves the usc of the test in an <Jsymptom<Jtic population where the prevalence of the disease is generally low and the spectrum of disease favors earlier and less SeVlc'l'e cases. In such situations, sensitivity tends to be lower and specificity higher than when the same test is applied to patients suspected of having the disea'>e, more of whom have adv,lnced disease."
    },
    {
      "title": "BIAS",
      "text": "Sometimes the sensitivity and specificity of a test are not established independently of the means by which the true diagnosis is established, leading to a biased assessment of the test's properties. This may occur in several ways, As already pointed out, if the test is evaluated using data obtained during the course of a clinical evalu.;'ltion of patients suspected of having the disease in question, a positive test may prompt the clinician to continue pursuing the diagnosis, increasing the likelihood that the disease will be found, On the other hand, a negative test may cause the clinician to abandon further testing, making it more likely that the disease, if present, will be missed.\n\nIn other situations, the test result may be part of the information used to establish the diagnosis, or conversely, the results of the test may be interpreted taking other clinical information or the final diagnosis into account. Radiologists are frequently subject to this kind of bias when they read x-rays. Because x-ray interpretation is somewhat subjective, it is easy to be influenced by the clinical information provided. All clinicians experience the situation of having x-rays overread because of a clinical impression, or conversely, of going back over old x-rays in which a finding was missed because a clinical event was not known at the time, and therefore, attention was not directed to the particular area in the x-ray. Because of these biases, some radiologists prefer to read x-rays twice, first without and then with the clinical information. All of these biases tend to increase the agreement between the test and the stand<lTd of validity. That is, they tend to make the test seem more useful than it actually is, as, for example, when an MRJ of the lumbar spine shows a bulging disc in a patient with back pain (see earlier example in this chapter)."
    },
    {
      "title": "CHANCE",
      "text": "Values for sensitivity and specificity (or likelihood ratios, another characteristic of diagnostic tests, discussed below) arc usually estimated from observations on relatively small samples of people with and without the disease of interest. Because of chance (random variation) in anyone sample, particularly if it is small, the true sensitivity and specificity of the test can be misrepresented, even if there is no bias in the study. The particular values observed are compatible with a range of true values, typically characterized by the \"95% confidence intervals\"] (sec Chapter lJ). The width of this range of values defines the degree of precision of the estimates of sensitivity and specificity. Therefore, reported values for sensitivity and specificity should not be taken too literally if a small number of patients is studied.\n\nTl\", 9.\"'~\u2022;, confidence interval of a prop\"'lion is ~asily ~stim\"led by the following formula, b\"\"'-'d on the binomiol th\"orcm: wh\"\", {' i, th\" \"h-\",,,',,<I proportiOIl aml ,,,, i, the numbe, \"f people ol\"erved. Tn be more nearly cx\"c!, Illulliply by 1.Y6, FiguH  ' 3.7  shows how the precision of estimates of sensitivity increases as the number of people on which the estimate is b2sed increases. In this particular example, the observed sensitivity of the diagnostic test is 75'Yo. Figure  1 .7 shows that if this estimate is based on only 10 patients, by chance alone the true sensitivity could be as low as 4SO;;, and as high as nearly 100'];,. When more patients are studied, the 95\u00b0/., confidence interval narrows, i.e., the precision of the estimate increases."
    },
    {
      "title": "Predictive Value",
      "text": "As noted previously, sensitivity and specificity are properties of a test that are taken into aCCotlllt when a decision is made whether or not to order the test. But once the results of a diagnostic test are available, whether positive or negative, the sensitivity and specificity of the test are no longer relevant, because these values pertain to persons known to have or not to have the disease. But if one knew the disease status of the patient, it would not be necessary to order the test! For the clinician, the dilerruna is to determine whether or not the patient has the disease, given the results of a test."
    },
    {
      "title": "DEFINITIONS",
      "text": "The probability of disease, given the results of a test, is caned the predictive vallie of the test (see Fig. dictive value is the probability of not having the disease when the test result is negative (normal). Predictive value amwers the question, \"If my patient's test result is positive (negative) what are the chances that my patient does (does not) have the disease?\" Predictive value is sometimes called posterior (or posUest) probability, the probability of disease after the test result is known. Figure 3.3 illustrates these concepts. Among the pat ients treated with antibiotics for streptococcal pharyngitis, less than half (44%) had the condition by culture (positive predictive value). The negative predictive value of the housestaff's diagnostic impressions was better; of the 87 patients thought not to have streptococcal pharyngitis, the impression was correct for 77 (88~';,).\n\nTerms summarizing the overall value of a test have been described. One such term, accuracy, is the proportion of all test results, both positive and negative, that are correct. (For the pharyngitis example in Figure  3 .3, the accuracy of the hOllsestaff's diagnostic impressions was 70%.) The area under the ROC curve is another useful summary measure of the information provided by a test result. However, these summary measures are too crude to be useful clinically because specific information about the component parts-sensitivity, specificity, and predictive value at specific cutoff points-is lost when they are aggregated into a single index."
    },
    {
      "title": "DETERMINANTS OF PREDICTIVE VALUE",
      "text": "The predictive value of a test is not a property of the test alone. It is determined by the sensitivity and specificity of the test and the prevalence of disease in the population being tested, where prevalence has its customary meaning-the proportion of persons in a defined population at a given point in time with the condition in question. Prevalence is also called prior (or pretest) probability, the probability of disease before the test result is known. (For a full discussion of prevalence, see Chapter 4.)\n\nThe mathematical formula relating sensitivity, specificity, and prevalence to positive predictive value is derived from Bayes's theorem of conditional probabilities: Positive predictive = (Sensitivity value"
    },
    {
      "title": "Sensitivity x Prevalence",
      "text": "x Prevalence) + (I-Specificity) x (I-Prevalence)\n\nThe more sensitive a test is, the better will be its negative predictive value (the more confident the clinician can be that a negative test result rules out the disease being sought). Conversely, the more specific the test is, the better will be its positive predictive value (the more confident the clinician can be that a positive test confirms or rules in the diagnosis being sought). Because predictive value is also influenced by prevalence, it is not independent of the setting in which the test is used. Positive results even for a very specific test, when applied to patients with a low likelihood of having the disease, will be largely false positives. Similarly, negative results, even for a very sensitive test, when applied to patients with a high chance of having the disease, are likely to be false negatives. In sum, the interpretiltion of a positive or negative diagnostic test result varies from setting to setting, according to the estimated prevalence of disease in the particular setting.\n\nIt is not intuitively obvious what prevalence has to do with an individual patient. For those who arc skeptical it might help to consider how a test would perform at the extremes of prevalence. Remember that no matter how sensitive and specific a test might be (short of perfection), there will still be a small proportion of patients who are misdassified by it. Imagine a population in which no one has the disease. In such a group all positive results, even for a very specific test, will be false positives. Therefore, as the prevalence of disease in a population approaches zero, the positive predictive value of a test also approaches zero. Conversely, if everyone in a population tested has the disease, all negative results will be false negatives, even for a very sensitive test. As prevalence approaches 100%, negative predictive value approaches zero. Another way for the skeptic to convince himself or herself of these relationships is to work with Figure  3 .2, holding sensitivity and specificity constant, changing prevalence, and calcuhlting the resulting predictive values.\n\nThe effect of prevalence on positive predictive value, for a test at different but generally high levels of sensitivity and specificity, is illustrated in Figure  3 .8. When the prevalence of disease in the population tested is relatively high-more than several percent-the test performs well. But at lower prevalences, the positive predictive value drops to nearly zero, and the test is virtually useless for diagnosing disease. As sensitivity and specificity fall, the influence of changes in prevalence on predictive value becomes more acute.\n\nExample The predictive value of PSA for diagnosing carcinoma of the prostate has been studied in various clink'll situations, corresponding to different prevalences or prior probabilities. In older asymptomatic men, where the prevalence of prostatic carcinoma is estimated to be 6~12%, only about 15~~of men with a PSA of 4 m/!;/dL or more actually had cancer. In higher risk men (with symptoms or a suspiciolls rectal exam), where the prevalence of prostatic carcinoma is 26'%, 4()' Yo of men with positive l'SAs had cancer  (7) . If PSA were used as il screening test in asymptomatic men, 5 or 6 healthy men would have to undergo additional tests, often induding biopsy, to find one man with cancer. However, when there is a strong clinical sllspicion of mali/!;nancy, nearly 50% of men with a positive test will have prostatic cancer. Current efforts to prevent transmission of acquired immunodeficiency syndrome (AIDS) through blood products is another example of the effect of disease prevalence on positive predictive value.\n\nExample A blood test for antibodies to human immunodeficiency viru( HIV) is used to screen blood donors. At one cutoff point, the sensitivity is 97,8\u00b0/\" and the spl:'cificity is 90.4%. In 1985, the positive predictive value of the test was estimated from the prevalence of infectious lUlits to be no more than 1/10,000. Thus there would be 9,250 false-positive test results for every true-positive result  (8) . Almost 10,000 units would have to be discarded or investigated further to prevent one transfusion of contaminated blood. The authors concluded that, for this emotionally charged subject, \"careful adherence to the principles of diagnostic test evaluation will avoid unreali~tic expectations.\"\n\nBut the situation changed. As the prevalence of HIV infection increased in the general population, the positive predictive value of the screening test improved. In a publication a year later, the prevalence of infected units among 67,190 tested was 25/10,000, and at similar levels of sensitivity and specificity, the positive predictive value would be 2.5\u00b0;':\" much higher than a few years before  (9) ."
    },
    {
      "title": "ESTIMATING PREVALENCE",
      "text": "How can clinicians estimate the prevalence or probability of disease in a patient to determine the predictive value of a test result? There are several sources of infonnation: the medical literature, local databases, and clinical judgment. Although the resulting estimate of prevalence is seldom very precise, error is not likely to be so great as to change clinical judgments that are based on the estimate. In any case, the process is bound to be more accurate than implicit judgment alone.\n\nTn general, prevalence is more important than sensitivity and specificity in determining predictive value (see  fig. 3.8) . One reason why this is so is that prevalence commonly varies over a wider range. Prevalence of disease can vary from a fraction of a percent to near certainty in clinical settings, depending on the age, gender, risk factors, and clinical findings of the patient. Contrast the prevalence of liver disease in a healthy, young adult who uses no drugs, illicit or otherwise, and consumes only occasional alcohol, with that of a jaundiced intravenous drug user. By current standards, clinicians arc not particularly interested in tests with sensitivities and specificities much below 50'Yo, but if both sensitivity and specificity are 99\u00b0/;\" the test is considered a great one. In other words, in practical terms sensitivity and specificity rarely vary more than twofold."
    },
    {
      "title": "INCREASING THE PREVALENCE OF DISEASE",
      "text": "Considering the relationship between the predictive value of a test and prevalence, it is obviously to the physician's advantage to apply diagnostic tests to patients with an increased likelihood of having the disease being sought. In fact as Figure  3 .8 shows, diagnostic tests are most helpful when the presence of disease is neither very likely nor very unlikely.\n\nThere Me a variety of ways in which the probability of a disease can be increased before using a diagnostic test."
    },
    {
      "title": "Referral Process",
      "text": "The referral process is one of the most common ways in which the probability of disease is increased. Referral to teaching hospital wards, clinics, and emergency departments increases the chance that significant disease will tmderlie patients' complaints. Therefore, relatively more aggressive use of diagnostic tests might be justified in these settings. In primary care practice, on the other hand, and particularly among patients without complaints, the chance of finding disease is considerably smaller, and tests should be used more sparingly.\n\nExample While practicing in a military clinic, one of the authors saw hundreds of people with headache, rarely ordered diagnostic tests, and never encountered a patient with a severe underlying caUSl' of headache. (It is lUllikely that important conditions were missed bccause the clinic was virtu-.,lIy the only source of medical care for the~patients and proloneed followup was available.) However, during the first week back in a medical residency, a patient visiting the hospital's emergency department because of a headache similar to the ones managed in the military was found to have a cerebellar absCl':'s! Because clinicians may work at different extremes of the prevalence spectrum at various times in their clinical practices, they should bear in mind that the intensity of diagnostic evaluation may need to be adjusted to suit the specific situation."
    },
    {
      "title": "Selected Demographic Groups",
      "text": "In a given setting, physicians can increase the yield of diagnostic tests by applying them to demographic groups known to be at higher risk for a disease. 1\\ man of 65 is 15 times more likely to have coronary artery disease as the cause of atypical chest pain than a woman of 30i thus the electrocardiographic stress test, a particular diagnostic test for coronary disease, is less useful in confirming the diagnosis in the younger woman than in the older man  (10) . Similarly, a sickle-cell test would obviously have a higher positive predictive value among blacks than among whites."
    },
    {
      "title": "Specifics of the Clinical Situation",
      "text": "The specifics of the clinical situation are clearly the strongest influence on the decision to order tests. Symptoms, signs, and disease risk factors all raise or lower the probability of finding a disease. For example, a woman with chest pain is more likely to have coronary disease if she has typical angina and hypertension and she smokes. As a result, an abnormal electrocardiographic stress test is more likely to represent coronary disease in such a woman than in persons with nonspecific chest pain and no coronary risk factors.\n\nThe value of applying diagnostic tests to persons more likely to have a particular illness is intuitively obvious to most doctors. Nevertheless, with the increasing availability of diagnostic tests, it is easy to adopt a less selective appmach when ordering tests. However, the less selective the approach, the lower the prevalence of the disease is likely to be and the lower will be the positive predictive value of the test.\n\nThe magnitude of this effect can be larger than most of us might think.\n\nExample Factors that influence the interpretation of an abnormal electrocardiographic stress test arl:' illustrated in Figure  3 .9. It shows that the positive predictive value for coronary artery disease (CAD) associated with an abnormal test can vary from 1.7 to 99.8%, depending on age, symptoms, and the degree of abnormality of the test. Thus an exercise test in an asymptomatic 3.'i-year-old man showing 1 mm ST seh'lllent depression will be a falsepositive test in more than 98% of cases. The same test result in a 60-year-old man with typical l'mgina by history will be associated with coronary artery disease in more than 90% of cases  (10) .\n\nBecause of this effect, physicians must interpret similar test results differently in different clinical situations. A negative stress test in an asymptomatic 35-year-old man merely confirms the already low probability of coronary artery disease, but a positive test usually will be misleading if it is used to search for unsuspected disease, as has been done among joggers, airline pilots, and business executives. The opposite applies to the 65-\n\nL::'EI 0.5-1.0 mm _> 2.5 mm 100 gO w ::> 80 '\" > 70 w_ :=~6 0 I-0 0 -'\" 50 iilo a: a: 40 \"0 w\"-30 \" !:: 20 '\" 0 . . 10 0 Age Symptom Prevalence of CAD (%)\n\n30-39 None 1.g 60-69 60-69 None Atypical angina 60-69 Typical angina 94.3 Figure 3.9. Effect of disease prevalence on positive predictive value of a diagnostic test. Probability of coronary artery disease in men according to age, symptoms, and depression of $T segment on electrocardiogram. (Data from Diamond GA, Forrester JS. Analysis of probability as an aid in the clinical diagnosis of coronary artery disease. N Engl J Med 1979;300:1350-1358.) year-old man with typical angina. In this case, the test may be helpful in confirming disease but not in excluding disease. The test is most useful in intermediate situations, in which prevalence is neither very high nor very low. For example, a 60-year-old man with atypical chest p<lin h<ls a 6n:, chance of coronary artery disease before stress testing (see Fig. 3.9); but afterward, with gre<lter th<ln 2.5 mm ST segment depression, he has a 99% probability of coron<lry disease.\n\nBecause prevalence of disease is such <l powerful determinant of how useful a diagnostic test will be, clinicians must consider the probability of disease before ordering a test. Until recently, clinicians relied on clinical observations and their experience to estim<lte the pretest probability of a disease. Research using large clinical computer data b<lnks now provide quantitative estimates of the probability of disease, given various combinations of clinical findings  (11) ."
    },
    {
      "title": "IMPLICATIONS FOR THE MEDICAL LITERATURE",
      "text": "Published descriptions of diagnostic tests often include, in addition to sensitivity and specificity, some conclusions about the interpretation of a positive or negative test, i.e., predictive value. This is done, quite rightly, to provide information directly useful to clinicians. But the data for these publications are often gathered in university teaching hospitals where the prevalence of serious disease is relatively high. As a result, statements about predictive value in the medical literature may be misleading when the test is applied in less highly selected settings. What is worse, authors often compare the performance of a test in a number of patients known to have the disease and an equal number of patients without the disease. This is an efficient way to describe sensitivity and specificity. However, any reported positive predictive value from such shtdies means little because it has been determined for a group of patients in which the prevalence of disease was set by the investigators at 50()'0."
    },
    {
      "title": "Likelihood Ratios",
      "text": "Likelihood ratios are an alternative way of describing the performance of a diagnostic test. They summarize the same kind of information as sensitivity and specificity and can be used to calculate the probability of disease after a positive or negative test."
    },
    {
      "title": "ODDS",
      "text": "Because use of likelihood ratios depends on odds, to understand them it is first necessary to distinguish odds from probability. Probability-used to express sensitivity, specificity, and predictive value-is the proportion of people in whom a particular characteristic, such as a positive test, is present. Odds, on the other hand, is the ratio of two probabilities. Odds and probability contain the same information, but express it differently. The two can be interconverted using simple formulas: Odds = Probability of event -~1 -Probability of event Probability -Odds -' --I + Odds These terms should be familiar to most readers because they are used in everyday conversation. For example, we may say that the odds are 4:1 that the Seattle Supers\\mics will win tonight or that they have an 80% probability of wiruting."
    },
    {
      "title": "DEFINITIONS",
      "text": "The likelihood fIItio for a particular value of a diagnostic test is defined as the probability of that test result in people with the disease divided by the probability of the result in people without disease. I.ikelihood ratios express how many times more (or less) likely a test result is to be fmUld in diseased, compared with nondiseased, people. If a test is dichotomous (positive/negative) two types of likelihood ratios describe its ability to discriminate between diseased and nondiseased people: one is associated with a positive test and the other with a negative test (sec Fig.  3 .2).\n\nIn the pharyngitis example (see Fig.  3 .3), the data can be used to calculate likelihood ratios for streptococcal pharyngitis in the presence of a positive or negative test (clinical diagnosis). A positive test is about 2.5 times more likely to be made in the presence of streptococcal pharyngitis than in the absence of it. If the clinicians believed streptococcal pharyngitis was not present, the likelihood ratio for this negative test was 0.39; the odds were about 1:2.6 that a negative clinical diagnosis would be made in the presence of streptococcal pharyngitis compared with the absence of the disease."
    },
    {
      "title": "USES OF LIKELIHOOD RATIOS",
      "text": "Pretest probability (prevalence) can be converted to pretest odds using the formula presented earlier. Likelihood ratios can then be used to convert pretest odds to posttest odds, by means of the following formula:\n\nPretest odds X Likelihood ratio = Posttest odds Posttest odds can, in turn, be converted back to a probability, using the formula described earlier in this chapter. Tn these relationships, pretest odds contains the same information as prior probability (prevalence), likelihood ratios the same as sensitivity / specificity, and posttest odds the same as positive predictive value (posttest probability).\n\nThe main advi1ntage of likelihood ratios is that they make it easier for us to go beyond the simple i1nd clumsy classification of a test result as either abnormi1l or normal, as is usually done when describing the accuracy of a diagnostic test only in terms of sensitivity and specificity at a single cutoff point. Obviously, disease is more likely in the presence of an extremely abnorm<ll test result than it is for a marginal one. With likelihood ratios, it is possible to summarize the information contained in a test result at different levels. One can define likelihood ratios for any number of test results, over the entire range of possible values. In this way, information represented by the degree of abnormality, rather than the crude presence or absence of it, is not discarded. In computing likelihood ratios across a range of test results, sensitivity refers to the ability of that particular test result to identify people with the disease, not individuals with that result or worse. The Si1me is true for the calculation of specificity.\n\nThus likelihood ratios can accommodate tht.' common and reasonable clinical practice of putting more weight on extremely high (or low) test results than on borderline ones when estimating the probability (or odds) that a particular disease is present.\n\nExample How accurate is serum thyroxine (T4 ) alone as a test for hypothyroidism? This question was addressed in a study of 120 ambulatory general medical patients suspected of having hypothyroidism (' 2). Patients were diagnosed as being hypothyroid if serum thyrotropin (TSH) wa~elevated and if subsequent evaluations, including other thyroid tests and response to treatment, were consistent with hypothyroidism. The authors shtdied the initial T,lcvel in 27 patients with hypothyroidism and 93 patients whn we.re found not to llave it to determine how accurately the simple test alone might have diah'l1osed hypothyroidism.\n\nAs expected, likelihood ratios for hypothyroidism were highest for low levels of T 1 and lowest for high levels (Table  3 .2). The lowest value~in the distribution ofT,s \u00ab4.0 pg/dL) were only ~een in patients with hypothyroidism, i.e., these levds filled in the diagnosis. The highest levels (>8.0 pg/dL) were not seen in patients with hypothyroidism, i.e., the pre~nce of these levels ruled out the disease.\n\nThe authors concluded that \"it may be possible to achieve cost savings without loss of diagnostic accuracy by using a single total It meaSllrement for the initial evaluation of suspected hypothyroidism in selected patients.\"\n\nThe likelihood ratio has several other advantages over sensitivity and specificity as a description of test performance. The infonnation contributed by the test is summarized in 011e number instead of two. The calculations necessary for obtaining posttest odds from pretest odds arc easy.\n\nTable 3.2 Distribution of Values for Serum Thyroxine in Hypothyroid and Normal Patients, with Calculation of Likelihood Ratios' P;lt,eflts w',th Test Result Total Serum Illyroxine Ilypothyroid Nor\",,,1 likelihood l!-'gidLj (numbHr, pHrCHnt) rnuillber, percent) Ratio <11 2 (7.4) 1 1.1-2,0 3 (11.1) Ruled in ? 1\u2022-3,0 1 (3.7) J ::11-40 8 (29,6) 4,1-5,0 4 (14,8) 1 (11) 13,8 5,1-6.0 4 (148) 6 (6,5) 23 61 7.0 3 (11 1) 11 (11.8) 9 7,1-8.0 2 {7.41 19 (20.4) A 8,1-9.0 1/ (1S,:J) 1 91-10 20 (21,5) 101-11 11 (11,8) Ruled out 11.1-12 4 (43) j -,12 4 !'1.3) Tolal 27 (100) 93 (WO) , I,om Goldstein BJ, Musillin AI. Use 01 a 'linglH thyroxine test to evaluate ambulatory medical paliHnts for s1I5pecWd 11YlX}lIlyroidis\",. ,t Gellintern Med 19fJ7;2;20 2\u20221\n\nI\\lso, likelihood ratios are partku lady well suited far describing the overa 11 probability of disease when a serics of diagnostic tests is used (see below). Likelihood ratios (LR) also have disadvantages. One must use odds, not probabilities, and most of us find thinking in terms of odds more difficult than probabilities. Also, the conversion from probability to odds and back requires math or the use of a nomogram, which partly offsets the simplicity of calculating posttest odds using LRs. Finally, for tests with a range of results, LRs use measures of sensitivity and specificity that are different from those usually described."
    },
    {
      "title": "Multiple Tests",
      "text": "Because clinicians commonly use imperfect diagnostic tests, with less than IOO'/'o sensitivity and specificity and intermediate likelihood ratios, a single test frequently results in a probability of disease that is neither very high nor very low, e.g., somewhere between 10')'0 and 90%. Usually it is not acceptable to stop the diagnostic process at such a point. Would a physician or patient be satisfied with the conclusion that the patient has even a 20% chance of having carcinoma of the colon? Or that an asymptomatic 35-year~ald man with 2.5 mm 5T segment depression on a stress test has a 42% chance of coronary artery disease (see Fig.  3 .9)? Even for less deadly diseases, such as hypothyroidism, tests with intermediate posttest probabilities are of little help. The physician is ordill<lrily bound to raise or lower the probability of disease substantially in such situations-unless, of coursc, the diagnostic possibilities are all trivial, nothing could be done about the result, or the risk of proceeding further is prohibitive. When these exceptions do not apply, the doctor will want to proceed with further tcsts.\n\nWhen multiple tests are performed and all are positive or all are negative, the interpretation is straightforward. All too often, however, some are positive and others are negative. lnterpretation is then more complicated. This section discusses the principles by which multiple tests are applied and interpreted.\n\nMultiple tests can be applied in two general ways (Fig.  3 .10). They can be llsed in parallel (i.e., all at once), and a positive result of any test is considered evidence for disease. Or they can be done serially (i.e., consecutively), based on the results of the previolls test. for serial testing, all tests must give a positive result for the diagnosis to be made, because the diagnostic process is stopped when a negative result is obtained."
    },
    {
      "title": "PARALLEL TESTS",
      "text": "Physicians usually order tests in parallel when rapid as.';('Ssment is necessary, as in hospitalia>d or emergency patients, or for ambulatory patients who cannot rehm1. easily because they have come from a long distance for evaluation."
    },
    {
      "title": "STRATEGY SEQUENCE OF EVENTS CONSEQUENCES"
    },
    {
      "title": "Serial testing",
      "text": "Test J-Sensitivity tSpecificity tSensitivity tSpecificity\n\nMultiple tests in parallel generally increase the sensitivity and, therefore, the negative predictive value for a given disease prevalence above those of each individual test. On the other hand, specificity and positive predictive value are lowered. That is, disease is less likely to be missed (parallel testing is probably one reason referral centers seem to diagnose disease that local physicians miss), but false-positive diagnoses are also more likely to be made (thus the propensity for nvcrdiagnosing in such centers as well). The degree to which sensitivity and negative predictive value increases depends on the extent to which the tests identify patients with the disease missed by the other tests used. ]-lor example, if two tests are used in parallel with 60 and 8(),~{, sensitivities, the sensitivity of the parallel testing will be only 80% if the better test identifies all the cases found by the less sensitive test. If the two tests each detect all the cases missed by the other, the sensitivity of parallel testing is, of course, 10m!\". Tf the hvo tests are completely independent of each other, then the sensitivity of parallel testing would be 92'\\\"0.\n\nParallel testing is particularly useful when the clinician is faced with the need for a very sensitive test but has available only two or more relatively insensitive ones that measure different clinical phenomena. By using the tests in parallel, the net effect is a mere sensitive diagnostic strategy. The price, however, is evaluation or treatment of some patients without the disease.\n\nLxam}/Ie PSi\\. and digital reclal exam are both insensitive tests for the diagnosis of prostate cancer  (7) . Tahle 3.3 shows their sensitivity, specificity, and predictive values in the screening selling (men without symptoms). When the two tests arc used in parallel, the sensitivity increases but the specificity falls. The positive predictivl:' vlllue is lower thnn for PSA testing alone."
    },
    {
      "title": "SERIAL TESTING",
      "text": "Physicians most commonly use serial testing strategies in clinical situ<1tions where rapid assessment of patients is not required, such as in office practices and hospital clinics in which ambulatory patients are followed over time. Serial testing is also used when some of the tests are expensive or risky, these tests being employed only after simpler and safer tests suggest the presence of disease. For example, maternal age and blood tests (a-fetoprotein, chorionic gonadotropin and estriol) are used to identify pregnancies at higher risk of delivering a baby with Down's syndrome. Mothers found to be at high risk by those tests are then offered amniocentesis (D). Serial testing leads to less laboratory usc than parallel testing, because additional evaluation is contingent on prior test results. However, serial testing takes more time because additional tests are ordered only after the results of previous ones become available.\n\nSerial testing maximizes specificity and positive predictive value, but lowers sensitivity and the negative predictive value (sec Table  3 .3). One ends up surer that positive test results represent disease, but runs an increased risk that disease will be missed. Serial testing is particularly useful when none of the individual tests available to a clinician is highly specific.\n\n1\u00a3 a physicia11 is going to use two tests in series, the process will be\n\nTable 3.3 Tests Characteristics of PSA and Digital Rectal Examination (ORE)\" PSA 4,0 pg/lTlL Abnormal LJRE Abnormal PSA or ORE': Abrlormal PSA 8nd I)RE Sensitivily 0.67 0.50 OEl0 34 Specilicily 0,97 0.94 0.92 0.995 Positive Preddive Value Cl.43 0,24 0,28 0.49 \"I 'SI\\ and ORE, alono ond in combi\"alion (parallel and SG,illl lestinR) in tll\" liiJflnosis 01 pr08l11to mncer (l\\daptHd from Kramer RS et al Prostato cancer screc\u2022ning: what WH know and what we flood to know. Arm Int MO{j 1993;1199H 923,)\n\nmore efficient if the test with the highest specificity is used first. Table  3 .4\n\nshows the effect of sequence on serial testing. Test A is more specific than test B, whereas B is more sensitive than A. By using A first, fewer patients are subjected to both tests, even though equal numbers of diseased patients are diagnosed, regardless of the sequence of tests. However, if one test is much cheaper or less risky, it may be more prudent to use it first."
    },
    {
      "title": "ASSUMPTION OF INDEPENDENCE",
      "text": "When multiple tests are used, as discussed above, the accuracy of the result depends on whether the additional information contributed by each test is somewhat independent of that already available from the preceding ones, i.e., the next test does not simply duplicate known information. In fact, this premise underlies the entire approach to predictive value we have discussed. However, it seems unlikely that the tests for most diseases . . , Note that in both sequenG8S the samo number of patienfs aro idenlili\",d as diseased (160) arld the same number of true positives (t44) arp identified. But WllB\" tAst A (wrth tho higher specificity) is usod first, fewpr patIents am retest\"d. The lower sensitivity oJ test II does not ndwrs\"ly affect tll0 final result are fully independent of one another. If the assumption that the tests are completely independent is wrong, cillculation of the probilbility of disease from several tests would tend to overestimate the tests' value."
    },
    {
      "title": "SERIAL LIKELIHOOD RATIOS",
      "text": "When a series of tests is used, an overall probability can be ca1cul<lted, using the likelihood ratio for each test result, as shown in Figure  3 .11. The prevalence of disease before testing is first converted to pretest odds. As each test is done, the posttest odds of one becomes the pretest odds for the next. Tn the end, a new probability of disease is found that takes into account the information contributed by aU the tests in the series."
    },
    {
      "title": "Responsiveness",
      "text": "The clinical status of patients changes continually either in response to treatment or because of the effects of aging or illness. Clinicians regulilrly face the question, \"HilS my patient improved or deteriorated?\" The tests used to monitor the clinical course (e.g., symptom severity, functional st<ltus) are often somewh<lt different from those used to diagnose disease, but the assessment of their performance is very similar.\n\nThe ability of changes in the value of a test to identify correctly changes in clinical status is called its respollsiveness. It is conceptually related to the validity of a diagnostic test, except that the presence or absence of a meaningful change in clinical st<ltus, not the presence or absence of disease, is the gold standard. The m<lgnitude of a test's responsiveness can be expressed as sensitivity, specificity, and predictive value or as the ilreil under the ROC curve.\n\nExample Several self-report meaS\\Jres of health and. fWlctional status are commonly u;;ed to monitor the health of populations illld cvaluate the effects of trcatment. Two such measure;; are restricted activity days-number of ~jj\"ll!:i'iI!IIT \"PRC>&A8ILIH \"\n\nPretest odds x LRs = Posttest odds \"\n\nPC>i\"tTIiIlT PRC>IIA8ILIH CLINICAL FPIDEMIOLOGY dilYs on which usual ilctivities were limilt'd by illness or injury-ilnd sdfreported health-a question asking respond('nts to rilte their health from excellent to poor compared with others their age. The responsiveness of these measures administered 1 year apart was assessed by comparing changes in each measure between older adults who experienced a major illness during the year and those thai did not have a major illness (  14 ). The l.:OC curves in Figure  3 .12 show that the changes in self-reported health performed slightly bdkr than chaneI' in picking up changes in health associated with major illness, while changes in restricted activity days performed much better, accounting for 80''l;, of the area und('r the ReX: curve,"
    },
    {
      "title": "Summary",
      "text": "Diagnostic test performance is judged by comparing the results of the test to the presence of disease in a two-by-two table . All four cells of the\n\ntable must be filled. When estimating the sensitivity and specificity of a new diagnostic test from information in the medicalliteraturc, there mllst be a gold standard to which the accuracy of the test is compared. The diseased and nondiscilsed subjects should both resemble the kinds of pa-_ Restricted days 80 60 20 40 100 I-------~...,. ..\u2022If;:\" ..'/ ..../ ,.' / ..' / , / / --a, -Health ... / ,.' / / / / / / / / ' / : /  ----'----'---'-----'    1993;41 :241-248.) bents for whom the test might be useful in practice. In addition, knowledge of the final diagnosis should not bias the interpr('ta~ion of the test results or vice versa. Changing the cutoff point betwecn normal and abnormal changes sensitivity and specificity. Likelihood ratios are another way of describing the accuracy of a diagnostic test.\n\nThe predictive value of a test is the most relevant characteristic when clinicians interpret test results. It is determined not only by sensitivity and specificity of the test but also by the prevalence of the disease, which may change from setting to setting. Usually it is necessary to use several tests, either in parallel or in series, to achieve acceptable diagnostic certainty. Responsiveness, a test's ability to detect change in clinical status, is also judged by the same h\\'o-by-two table."
    },
    {
      "title": "FREQUENCY",
      "text": "In Chapter 1, we outlined the central questions facing clinicians as they caTC for patients. In this chapter, we define and describe the quantitative evidence that clinicians use to guide their diagnostic and therapeutic decisions. Let us introduce the subject with a patient.\n\ni\\ 72-year-old man presents with slowly progressive urinary frequency, hesitancy, and dribbling. Digital rectal examination Tevmls a symmetrically enlarged prostate gland. Urinary flow measurements show signWc<lnt reduction in flow rate and serum PSA is not elevated. A diagnosis of benign prostatic hyperplasia (I3PH) is made. In deciding on treatment, the clinician and patient must weigh the costs and benefits of various therapeutic options: for example, the risk<; of worsened symptoms or obstructive renal disease with medical treatment versus operative mortality or sexual dysfunction with surgery.\n\nThe decisions have traditionally been made by \"clinical judgment,\" which we learn at the bedside and in the clinics. In recent years, methods for quantitative clinical decision making have been introduced into medicine. The most commonly used cUnical strategies are decision analysis, cost-effectiveness analysis, and cost-benefit analysis. These methods usc quantitative data about the frequency of key clinical events and the consequences of those events to patients to derive the best course of action. The methods, described in more detail at the end of the chapter, are only as good as the estimates of the probability or frequency of clinical outcomes on which they rely.\n\nFor the patient with BPH, sound clinical judgment requires accurate information about the probability of symptom deterioration, acute retention or renal damage with medical treatment; and symptom relief, mortality, impotence, or retrograde ejaculation with surgery. These are, in general, the kinds of evidence needed to answer most clinical questions. Decisions are guided by the probability of outcomes under alternative circumstances: in the presence of a positive test versus a negative test or after treatment A versus treatment B. Because the probability of disease, improvement, deterioration, cure, or death forms the basis for answering most clinical questions, this chapter examines measures of clin.ical frequency."
    },
    {
      "title": "Assigning Numbers to Probability Statements",
      "text": "Physicians often communicate probabilities as words-usually, sometimes, rarely, etc.-rather than as numbers. Substituting words for numbers is convenient and avoids making a precise statement when one is uncertain about a probability. However, it has been shown that there is little agreement about the meanings of commonly used words for frequency.\n\nExample Physicians were asked to estimate the likelihood of disease for each of 30 expressions of probability found by reviewing radiology and laboratory reports. There was great difference of opinion for each expression. Probabilities for consistent with ranged from 0.18 to 0.98; for unlikely, the range was 0.01-0.9-1. These data support the authors' assertion that \"difference of opinion among physicians regarding: the management of a problem may reflect differences in the meaning ascribed to words used to define probability\"  (1) .\n\nPatients also assign widely varying values for expressions of probability. In another study, highly skilled and professional workers thought usually referred to probabilities of 0.35-1.0 (::'::2 standard deviations from the mean); rarely meant to them a probability of 0-0.15  (2) .\n\nThus substituting words for numbers diminishes the information conveyed. We advocate using numbers whenever possible."
    },
    {
      "title": "PERCEPTIONS OF FREQUENCY",
      "text": "Pcrsonal experience colors the clinician's perception of the probability of conditions and outcomes. I laving a recent patient experience an outcome will tend to make the clinician inflate the probability of that outcome. Conversely, dinicians tend to underestimate the frequency of occurrences that they have not yet experienced or that patients may be reluctant to discuss. For example, systematic interviews of patients after transurethral resection of the prostate gland (TUR. .P) reveal that more than 50% of men experience retrograde ejaculation  (3) . Most urologists would estimate the frequency to be much lower, since many mall' patients are reluctant to discuss sexual issues."
    },
    {
      "title": "Prevalence and Incidence",
      "text": "Tn general, clinically relevant measures of the frequency or probability of events are fractions in which the numerator is the number of patients experiencing the outcome (cases) and the denominator is the number of people in whom the outcome could have occurred. Such fractions are, of course, proportions; but by common usage, they are referred to as \"rates.\"\n\nClinicians encounter two meilsures of frequency-prevalence and incidence. A prevalCl/cc is the fraction (proportion) of a group of people possessing a clinical condition or outcome at a given point in time.\n\nPrevalence is measured by surveying a defined population containing people with and without the condition of interest, at a single slice in time. There are 1\\.vo kinds of prevalence. Point prevalencc is measured at the time of the survey for each person, although not necessarily the same point in time for all the people in the defined population. Period prevalcnce refers to cases that were present at any time during a specific period of time.\n\nAn incidCllce is the fra.ction or proportion of a group initially free of the condition that develops it over a given period of time. Incidence refers then to new cases of disease occurring in a population initially free of the disease or new outcomes, such as disability or death, occurring in patients with a specific disease. As described later in this chapter and in greater detail in Chapter 5, incidence is measured by identifying a susceptible group of people (i.e., people frec of the disease or the outcome) and examining them periodically over an interval of time to discover and count new cases that develop during the interval.\n\nExample To illustrate the di{ferenCl.'S between prevalence <md incidence, riguH' 4.1 shows the occurrence of disease in a group of 100 people over the course  of 3 years (1992-1994) . As time passes, individuals in the group de\u2022 velnp the disease. They remain in this shlle until they either recover or di<'. In the 3 y<'ars, In people suffer Ihe onset of disease and 4 alreCldy had it. The remClinin~80 people do not develop disease and do not appear in the figure.\n\nAt the beginning of 1992, there arc four CClses, so the prevalence at that point in lime is 4/H](I. If all 100 individuals, including prior cases, are ,'XCllllined at the beginning of each year, one can compute the prevCllence at those points in time. At the begiJming of 1993, the prevalence is 5/100 because two of the pre-1992 cases Iinger<'d on into 1993 and Iwo of the new cases developing in 1992 terminilted (hopefully in a cure) before the examination at th<' start of 1993. Prevalences can be computed for each of the other Iwo ilnnual examinations, and assuming that none of the original 100 people died, moved away, or refused examination, thes<' prevalences arc 7/100 at the beginning of 1':1':14 and 5/100 at the beginning of 1995.\n\nTo calculate the incidence of new cases developing in the populiltion, we consider only the 9h individuals frc{' of the disease at the beginning ()f  1'192  and what happens to them over th<, next 3 years. Five new cases developed in 1992; six new cascs developed in 1993, and five .ldditional new cases develop<'d in 1'194. The 3-year incidence of the diseas<' is all new cascs developing in the 3 years (which is In) divided by the number of susceptible individuals at the beginnin~of the follow-up period (% prople), or 16/% in 3 years. Whal are tlw Clnnual incidences for  1'192, 1'193, and 1994, respectively? Rememoc'ring to remove the previous c.ases from the denominator, we would caleu late the annual incidences as 5/% for 1992, 6/91 for 1993, and 5/85 for 1994.\n\nEvery measurc of disease frequency necessarily contains some indication of time. With measures of prevalence, time is assumed to be instanta~ neous, as in a single frame from a motion picture. Prevalence depicts the situation at that point in time for each p8tient, even though it may, in re8lity, have taken several weeks or months to collect observations on the various people in the group studied. For incidence, time is the essence becam;c it defines the interval during which susceptible subjects were monitored for the emergence of the event of interest. Table  4 .1 summarizes the characteristics of incidence and prevalence. Although the distinctions between the two seem clear, the literature is replete with misuses of the terms, particularly incidence  (4) .\n\nWhy is it important to know the difference between prevalence and incidence? Bec8use they answer two different questions: (n) What proportion of a group of people h8ve a condition? and (b) At what rate do new cases arise in 8 group of people as time passes? The anS\\'lier to one question cannot be obt8ined directly from the answer to the other."
    },
    {
      "title": "Measuring Prevalence and Incidence"
    },
    {
      "title": "PREVALENCE STUDIES",
      "text": "The prevalence of disease is meai;Ufed by surveying a group of people, some of whom are diseased at that point in time while others are healthy (Fig.  4 .2). The fraction or proportion of the group that is diseased (i.e., cases) constitutes the prevalence of the disease.\n\nSuch one-shot examinations or surveys of a population of individuals, including cases and noncases, are called prevalence studies. Another tcrm is cross-sectional studies, because people a re studied at a point (cross-section) in time. They are among the more common types of research designs reported in the medical literature.\n\nThe following is an example of a typical prevalence study.\n\nTable 4.1 Characteristics of Incidence and Prevalence CI,8rflClerislic Numerator Denominator Time How measured Inc,dence New cases occurring during a period of time among a group initially free at disease All susceptible people present at the heginninq of the period Duration ot the period Cohort study (sec Ch(lpj(~r 5) t'rcvalol1ce All cases counted on a single surveyor examination of Cl group All people examined. includirlg casas and nonC8S8S Single point Prevalence (clOss-sectional) study Defined Population Representative Sample Disease/Outcome Present? Figure 4.2. The design of a prevalence survey.\n\nExample What is the prevalence of dementia in the general population of older adults? To answer this question, 1965 people 75 years of age and older living in Cambridge, England, were surveyed. Each participant underwent an examination that induded the Mini-Mental State Examination (MMSE), a test for cognitive impairment. The presence of dementia was identified by a serial testing strategy: Those with MMSE scores of 25 or less were examined using a standardized protocol by a psychiatrist who made the final diagnosis. The prevalence of dementia was about 10% overall, and rates doubled in each 5-year age band  (5) ."
    },
    {
      "title": "INCIDENCE STUDIES",
      "text": "Tn contrast to prevalence, incidence is measured by first identifying a popubtion free of the event of interest and then following them through time with periodic examinations to determine occurrences of the event.\n\nThe popul<ltion under examination in <In incidence shldy, referred to as <I cohort, may be healthy individuals followed for the emergence of disease or diseased individuals followed for outcomes of the disease. This process, also called a cohort study, will be discussed in detail in Chapter 5.\n\nTo this point, the term incidence has been used to describe the r<lte of new events in a group of people of fixed size, all of whom are observed over a period of time. This is called cumulative incidCllcc, because new cases are accwnulated over time, Example To study the incidence of dementia, the Cambridge investigators identified a cohort by removing from the follow-up study population those older individuals diagnosed with dementia in the prevalence study described above  (6) . The remaining 1778 nondemented people were tracked. Of the::;e, 305 died, 190 refused further testing, and 88 could not be found or were ton ill to be examined. The remaining-II\\J5 were reexamined an aver,ig<' of 2.5 year::; after the original exnmination. Overall, the aJUUlal incidence rate of dcmention in thi::; cohort was 4.3')(, and exceeded 8')\\, per year for those who were over age 85 at the time of the prevalence examination.\n\nA second approach to estimating incidence is to measure the number of nev,,, cases emerging in an ever-changing population, where people are under study and susceptible for varying lengths of time. The incidence measure derived from shldies of this type is sometimes called incidence density. Typical examples are clinic<ll trials of chronic treatment in which eligible patients are enrolled over several years so that early enrollees are treated and followed longer than late enrollees. Tn an effort to keep the contribution of individual subjects commensurate with their follow-up interval, the denomin<ltor of an incidence density measure is not persons at risk for a specific time period but person-time at risk of the event. An individual followed for 10 years without becoming <I case contributes 10 person-years, whereas an individual followed for 1 year contributes only one person-year to the denominator. Incidence density is expressed as the number of IWW cases per tot<ll number of person-years at risk. The person-years approach is also useful for estimating the incidence of disease in large populations (If known size when an accurate count of new cases and an estimate of the population at risk are available, e.g., a population-based cancer registry.\n\nA disadvantage of the incidence density approach is that it lumps together different lengths of follow-up. A small number of patients followed for a long time can contribute as much to the denominator as a large number of patients followed for a short time. Tf these long-term follow-up patients are systematically different from short-term follow-up patients, the resulting incidence measures may be biased."
    },
    {
      "title": "Interpreting Measures of Clinical Frequency",
      "text": "To make sense of a prevalence or incidence rate, the first steps involve careful definition of both the numerator and the denominator."
    },
    {
      "title": "WHAT IS A CASE?-DEFINING THE NUMERATOR",
      "text": "Up to this point, the general term case has been used to indicate an individual suffering from the disease or outcome of interest. In classical epidemiology, cases tend to be individuals with a disease, and prevalence and incidence refer to the frequency of cases among population groups like the residents of a community. However, clinical decisions often depend on information about the frequency or rate of disease manifestations, such as symptoms, signs, or laboratory abnormalities, or the frequency of disease outcomes, such as death, disability, or symptomatic improvement. In clinical practice, then, \"cases\" are often those patients with a disease who manifest a particular clinical finding or experience a particular outcome.\n\nTo interpret rates, it is necessary to know the basis on which a case is defined, because the criteria used to define a case can strongly affect rates.\n\nExample One simple way to identify a case is to ask people whether they have a certain condition. How does this method compare to more rigorous methods? In the Commission on Chronic Illness study, the prevalences of various conditions, as determined by personal interviews in the home, were compared with the prevalences as determined by physician examination of the same individuals. The data illustrate that these two methods of defining a case can generate very different estimates of prevalence and in different directions, depending on the condition  (7) .\n\nFor some conditions, broadly accepted, explicit diagnostic criteria are available. The Centers for Disease Control and Prevention criteria for definite Lyme disease (Table  4 .2) can be used as an example  (8) . These criteria demonstrate the specificity required to define reliably a disease that is as much in the public eye as is Lyme disease. They also illustrate a trade-off between rigorous definitions and clinical reality. If only \"definite\" cases"
    },
    {
      "title": "Method of Defining Case",
      "text": "Clinical Examination Questionnaire Hernia Heart disease Peptic ulcer Diabetes Hypertension Arthritis Asthma/hayfever Chronic sinusitis I 10 I 8 6 4 2 o 2 4 6 PREVALENCE (%) Table 4.2 Criteria for Reporting L.yme Disease 8 Clinical Case Definition (Confirmerl) Erythema Migrans or At least one late manifestation and laboratory contirmation ot infection Late Manifesfation (VVhen Altcrnotive r.xplanation Not Found) Musculoskeletal Recurrent tJricf attacks of objective joint swelling Nervous system: any of the following Lymphocytic meningitis Cranial neuritis (particularly facial palsy) encephalomyelitis with antibody in CSF Cardiovdscular Acute onset 2 or 3\u00b0atrioventricular conduction defecls that resolve. Laboratory Confirmation (Any of fhe Following) Isolation of Borrelia burgdorfei Diagnostic levels of fgM 8.nd fgG antibodies to the spirochete in serum or CSF-Significant change in antibody responses in p8.ired 8.cute-and convalescent-phase serum ~;\"mples. were included in a rate, most patients who ordinarily would be considered to have the disease would not be included. On the other hand, including \"probable\" cases could overestimate the true rate of disease."
    },
    {
      "title": "Example",
      "text": "The incidence rate of Lyme disease was estimated in Olmstead County, :Minnesota  (9) . Between 1980 and 1990, 68 cases had been clinically diagnosed in residents of the COW1ty. Only 17 (25%) met CDC criteria. In Mirmesota, it is mandatory to report Lyme disease to a public health official, yet only 7 cases Wl're reported, of which four met CDC crikria. 'fhese data illustrate how difficult it is to make accurate estimates of the frel..juency of diseases whose diagnosis relies on multiple clinical criteria."
    },
    {
      "title": "WHAT IS THE POPULATION?-DEFINING THE DENOMINATOR",
      "text": "A rate is useful only to the extent that the individual practitioner can decide to which kinds of patients the rate applies. The size and characteristics of the group of individuals in which the cases arose must be known.\n\nCustomarily, the group included in the denominator of a rate is referred to as the population or, more particularly, the population at risk, where at risk means susceptible to the disease or outcome cmmted in the numerator.\n\nFor example, the incidence or prevalence of cervical cancer will be underestimated if the population includes women who have had hysterectomies or includes men.\n\nThe denominator of a rate should include the population relevant to the question being asked, or a representative sample of them. But what is relevant depends on one's perspective. For example, if we wanted to know the true prevalence of rheumatoid arthritis in Americans, we would prefer to include in the denominator a random sample of all people in the United States. But if we wanted to know the prevalence of rheumatoid arthritis in medical practice-perhaps to plan services-the relevant denominator would be patients seen in office practice, not people in the population at large. In one survey, only 25(~~of adults found to have arthritic and rheumatic complaints (not necessarily rheumatoid arthritis) during a community survey had received services for such complaints from any health professional or institution  (10) .\n\nIt is customary for epidemiologists to think of a population as consisting of all individuab residing in a geographic area. And so it should be for studies of cause and effect in the general population. But in studies of clinical questions, the relevant populations generally consist of patients suffering from certain diseases or exhibiting certain clinical findings and who are fotmd in clinical settings that are similar to those in which the information will be used. Commonly, such patients are assembled at a limited number of clinical facilities where academic physicians see patients. They may make up a small and peculiar subset of all patients with the findings in some geographic area and may even be an unusual group for office practice in general.\n\nWhat difference might the choice of a popubtion make? What is at issue is the generalizability of observed rates."
    },
    {
      "title": "SAMPLING",
      "text": "It is rarely possible to study all the people who have or might develop the condition of interest. Usually, one takes a sample, so that the number studied is of manageable size. This raises a question: Is the sample representative of the population?\n\nIn general, there are two ways to obtain a rL'Presentative sample. In a random samp!e, every individual in the population has an equal probability of being selected. The more general term probability sample is used if every person has a known (not necessarily equal) probability of being selected. It is often important that a study sample includes a sufficient number of members of particular subgroups of interest such as etlmic minorities. If these subgroups are small, a simple random sample of the entire population may not include enough subgroup members. To remedy this, a larger percentage of each of these subgroups is selected at random. TIle fina.l sample will still be representative of the entire population if the different sampling fractions are accounted for in the analysi.<;. On the <lverage, the characteristics of people in probability samples are similar to those of the population from which they were selected, particularly if a large sample is chosen.\n\nOther methods of selecting samples may well be biased and so do not necessarily represent the parent population. Most groups of patients described in the medical literature, and found in most clinicians' experience, arc bascd on biased s<lmples. Typically, patients are included in studies bccause they are under care in an academic institution, aV<lilable, willing to be studied, and perhaps <lIsa particularly interesting and/or severely affected. There is nothing wrong with this practice-as long as it is understood to whom the results do (or do not) apply."
    },
    {
      "title": "Relationship among Incidence, Prevalence, and Duration of Disease",
      "text": "Anything that increases the dur<ltion of the disease or clinical finding in a patient will increase the chance that that p<ltient will be identified in a pn.'v<llence study. A glance at Figurc 4.1 will confirm this. The relationship among incidence and prevalence and duration of disease in <I ste<ldy state-i.e., where none of the variables is changing much over time-is approximated by the following expression: Prevalence = Incidence x Average duration of the disease Example Table  4 .3 shows approximate annual incidence and prevalence rates for asthma. Incidence falls with increasing age, illustrating the fact thai the disease arises primarily in childhood. But prevalence stays fairly stable over the entire age span, indicating that asthma tends to be chronic and is especially chronic among older individuals. Also, because the pool of prevalent cases does not increase in ~ize, about the same number of patients are recovering from their asthma as new patients are acquiring it.\n\nIf we usc the following formula, we can determine that asthma has an average duration of 10 years:\n\nAverage duration = Prevalence -;-Incidence When the duration of asthma is determined for each age category by dividing the prevalences by the incidences, it is apparent that the duration of asthma increases with increasing age. This reflects the cliniCi:ll observation that childhood asthma often clears with time, whereas adult asthma tends to be more chronic."
    },
    {
      "title": "Bias in Prevalence Studies",
      "text": "Prevalence studies can be used to investigate potentially causal relationships between risk factors and a diseasc or prognostic factors and an outcome. For this purpose, they arc quick but inferior alternatives to incidencl' studies. Two characteristics of prcvalence studies are particularly troublesome: uncertainty about the temporal sequence and biases associated with the study of cases of longer duration-\"old\" cases."
    },
    {
      "title": "UNCERTAINTY ABOUT TEMPORAL SEQUENCES",
      "text": "In prevalence studies, disease and the possible factors responsible for the disease are measured simultaneously, and so it is often unclear which came first. The time sequence is obscured, and if it is important to the interpretation it must be inferred. If the risk or prognostic factor is certain to have preceded the onset of disease or outcome-e.g., family history or a genetic marker-interpretation of the cause-and-effect sequence is Jess worrisome. If the risk or prognostic factor can be a manifestation of the  disease or outcome-e.g., an abnormal laboratory test or a psychological state-determining the sequence of events is lruch more difficult. In conh'ast, studies of incidence have a built-in sequence of events because possible causes of disease are measured initially, before disease has occurred. These relationships are i1Justrated in Figure  4 .4."
    },
    {
      "title": "BIASES STUDYING \"OLD\" CASES",
      "text": "1be difference between cases found in the numerator of incidence rates and of prevalences rates is illustrated in Figure  45 . In an incidence study, all G1SeS are new and most cases OCCUlTing in the population at risk can be ascertained if followed carefully through time. Tn contrast, a prevalence stu.dy includes a mixture of old and ne,,,, cases that are available at the time of the single examination-that is, they identify cases that happen to be both active (i.e., diagnosable) and alive at the time of the survey. Obviously, prevalence rates will be dominated by those patients who are able to survive their disease without losing its manifestations. 1be differences between the kinds of cases included in the numerator of an incidence and the kimb of cases included in the numerator of a prevalence may influence how the rates are interpreted."
    },
    {
      "title": "Possible Causes Disease or Outcome",
      "text": "Incidence Study causes Measurement is development of new cases of disease over time Prevalence Study Measurement is past or present exposure to possible causes Enter population \\ \\TI~\\> Early Cures deaths Leave population: Severe disease Mild disease Prefer other care, etc. Prevalence is affected by the average duration of disease. Rapidly fatal episodes of a disease \u2022would be induded in an incidence study, but most would be missed by a prevalence sfudy. For example, 25-40~/;, of all deaths from coronary heart disease occur within 24 hr of the onset of symptoms in people with no prior evidence of disease. A prevalence study would, therdore, underestimate cases of coronary heart disease. On the other hand, diseases of long duration are well represented in prevalence surveys, even if their incidence is low. For example, although the incidence of Crohn's disease is only about 2 to 7 per 100,OOO/year, its prevalence is more than 100 per 100,000, reflecting the chronic nature of the disease  (11) .\n\nPrevalence rates also selectively include more severe cases of nonfatal diseases. For example, patients with quiescent rheumatoid arthritis might not be diagnosed in a study based on current symptoms and physical findings. Similarly, patients with recurrent but controllable illnesses, such as congestive heart failure or depression, may be well at a given point in time and, therefore, might not be discovered on a single examination. Unremitting disease, on the other hand, is less likely to be overlooked and, therefore, would contribute disproportionately to the pool of cases assembled by a prevalence shtdy."
    },
    {
      "title": "Uses of Incidence and Prevalence",
      "text": "What purposes do incidence and prevalence serve? Clinicians use them in three different ways: predicting the future course of a patient, assigning a probability to a patient, and making comparisons."
    },
    {
      "title": "PREDICTING THE FUTURE",
      "text": "Incidence is a description of the rate at which a disease or a disease outcome has arisen over time in a group of people known to be free of the disease at the beginning of follow-up. It can be used to predict the probability that similar people will develop the condition in the future.\n\nExample The probabilities of outcomes following TURI', needed to decide the most appropriate treatment for the man with BPH described at the opening of this chapter, were estimated from a large cohort shldy of older men in New England  (12) . Interviews with more than 300 men undergoing TURP revealed that symptom resolution varied with the severity of symptoms before surgery; 93'1., of lll('n with severe symptoms improved with surgery while only 79';;, of those with moderate baseline symptoms improved.\n\nOn the other hand, prevalence studies offer no sound basis for predicting the future. Tf a prevalence study finds that 30% of patients with stroke are depressed, this does not mean that 30% of nondepressed stroke patients will become depressed in the future. It may be that depression predisposes to stroke, that stroke predisposes to depression, or that nondepn:.\u2022ssed stroke patients recover quickly. To find out the percentage of stroke patients who become depressed, new stroke patients must be followed over time with repeat measures of depressive symptoms."
    },
    {
      "title": "ASSIGNING A PROBABILITY THAT A PATIENT HAS THE CONDITION",
      "text": "Prevalence studies are particularly useful in guiding decisions about diagnosis and treatment. As pointed out in Chapter 3, knowing that a patient with a combination of demographic and clinical characteristics has a given probability of having a disease influences the use and interpretation of diagnostic tests. It may also may affect the selection among various treatment options.\n\nA patient with pharyngitis illustmtes how variations in prevalence or prior probability can influence the approach to a clinical problem.\n\nExample A study compared three approaches to the treatment of pharyngitis. The villue of the approaches was judged by weighing the potential benefits of prevt'nting rheumatic fever against the costs of penicililn allergy. The three options \\'I'ere to obtain a throat culture and treat only those patit.\u2022nts with thrOill cultures positive for group A (I-hemolytic streptococcus, treat all patients without obtaining a culture. and neither culture nor treat any patient.\n\nThe analysis revealed that the optimill strategy depended on the likelihood that a patient would have a positive culture, which can be estimated from the prevalence of streptococcal infection in the community ill the time and the presence or absence of fever. The authors concluded that if the probability of a positive culture fm an individual patient exceeds 20'};), the patient sh(lU ld be trealed; if it is less than .S' :;\" the patient should not be cultured or treated; and if the probilbility lies between 5 and 20%, the patienl should be cultured first and tre<lted based on the result  (13) .\n\nThis study represents a rational approach to the use of prevalences as indicators of individual probabilities of disease in guiding clinical decision making."
    },
    {
      "title": "MAKING COMPARISONS",
      "text": "Although isolated incidences and prevalences are useful descriptions, they become much more powerful tools in support of decision making when used to make comparisons. It is the comparison between the frequencies of disease among individuals with certain characteristics and individuals not sharing those characteristics that provides the strongest evidence. For example, the risk (incidence) of lung cancer among males who smoke heavily is of the order of 0.17% pcr year, hardly a common event. Only when this incidence is contrasted with the incidence in nonsmokers (approximately 0.007':'0 per year) does the devastating effect of smoking emerge. Clinicians use measures of frequency as the ingredients in compar\u00e3 tivc measures of the association behveen a factor and the disease or disease outcome. Ways of comparing rates are described in more detail in Chapter 5."
    },
    {
      "title": "Clinical Decision Analysis",
      "text": "Quantitative approaches to assisting in decision making have been used to define the most effective and efficient way to deal with specific problems in individual patients (cliniCilI policy) or for allocating resources to larger groups of people, such as communities or political jurisdictions (public policy).\n\nIn decision analysis, one sets out alternative courses of <Jction (e.g., surgery versus medical treatment for BPII or culture then tre<Jt or tre<Jt everybody for streptococcal pharyngitis) and then cakul<Jtes which choice is likely to result in the most valued outcome, based on estimates of frequencies for each branch in the sequences of events and judgments about the relative value of the possible outcomes. The basic steps \"lre clearly presented elsewhere  (14)  and are described only briefly below.\n\n1. Create a decision tree. Clinical decision analysis begins with a patient who poses a dilemma. Which of the possible courses of action should be taken? The tree begins with these alternative dccisions, then branches out to include all of the important consequcnces of those decisions, and ends with the clinically important outcomes. Branch points involve either patient care decif;ions (\"choice nodes,\" indicated by squares) or spontaneous events (\"chemct' nodes,\" indicated by circles). Although there is an infinite number of sequences of events and outcomes, usually only a small number <Jf(' truly important and are reasonably likely to occur. To make the analysis manageable, it is necessary to \"prune\" the tree so that only the most important branches are included -typically no more than several branch points."
    },
    {
      "title": "Assign probabilities to chance nodes.",
      "text": "Th{'~e probabilities are assessments of the frequency of clinical events, which are usually derived from the medical literature. 3. Assign utilities to the oil/comes. Utilitie~are quantitative expressions of the relative value of the various outcomes considered. They are best obtained from patients who may confront the deci~ion. The units <Ire <lrbitrary, but mu~t be on an interval scale, e.g., () to 100. It may seem awkward to put <I number on the re~pective values of the various outcomes (death, suffering, loss of function), especially when they are mmsured in different units, such as the length and quality of life. But patients <lttach values to outcomes in any case, and the numbers only make the values explicit. 4. Calculate the expected utilities for the alternative courses of action. Starting with utilities (at the end of the branches, to the right), multiply utilities by probabilities for each branch and add branches at each node in succession until the expected utility at the main branch point, the decision that h<ls to be made, is reached. 5. Select the choice with the highest expected utility. 6. Sensitivity analysis. Estim<lte~of probabi[itie~and utilities are uncertain in the fir~t place. The final ~tep in decision <Ina lysis is to see how the results of the analysis change as these estimates are varied over a range of plausible values. That is, one must find out how \"sensitive\" the decision is to imprecision in the estimates. Sensitivity analysis indicatew hich point in the sequence of evcnt~have the most effecl on the decision and how large the effect might be."
    },
    {
      "title": "Example",
      "text": "The therapeutic options facing the older man with urinary symptoms from benign prostatic hyperplasia (described <It the opening of this chapter) have been evaluated using decision analysis  (15) . Before drugs and laser prostatectomy made the decision more complicated, the options were surgery (transurethral resection of the prostate, TURP) or careful followup, called \"watchful waiting.\" Figure  4 .6 shows the decision tree that the authors used lo evaluate the options. The frequencies of the various outcomes were derived in the incidence study of New England men described earlier in the chilptcr  (12)  and other published sources  (15) . Note that the optimal decision in this case is surgery (net utility 0.94). In this case, TURP is the favored treatment beciHlse the risk of operative death is low and the utilities i1ssigned 10 incontil1ence or impotence are the same as that assigned to living with stable moderate urinary symptoms. If stable moderate symptoms were preferred over incontinence or impotence, the balance would shift."
    },
    {
      "title": "Summary",
      "text": "Most clinical que~tions are an~w('red by reference to the frequency of events under varying circumstances. The frequency of clinical events is indicated by probabilities or fractions, the numerators of which include the number of cases and the denominators of which include the number of people from whom the cases arose.\n\nThere are two measures of frequency: prevalence and incidence. Prevalence is the proportion of a group with the disease at a single point in time. lncidt'nce is the proportion of a susceptible group th<Jt develops new cases of the disease over an interval of time.\n\nPrevalence is measured by a single survey of a group containing cases and noncases, whereas measurement of incidence requires examinations of a previously disease-free group over time. Thus prevalence studies identify only those cases who are alive and diagnosable at the time of the survey, whereas cohort (incidence) studies ascertain all new cases. Prevalent cases, therefore, may be a biased subset of all cases because they do not include those who have already succumbed (lr been cured. In addition, prevalence studies frequently do not permit a clear understanding of the temporal relationship between a causal factor and a disease.\n\nTo make sense of incidence and prev<Jknce, the clinician must understand the basis on which the disease is di<Jgnosed and the characteristics of the popul<Jtion represented in the denominator. The latter is of particul<Jr importance in trying to decide if a given measure of incidence or prevalence pertains to patients in one's own practice.\n\nIncidence is the most appropriate measure of frequency with which to predict the future. Prevalence serves to qua.ltitate the likelihood that a patient with certain characteristics has the disease at a single point in time and is used for decisions about diagnosis and screening. The most powerful use of incidence and prevalence, however, is to compare different clinical alternatives.\n\nMeasures of disease or outcome incidence are essential ingredients in methods for quantitative decision making. Approaches such as decision analysis define alternative clinical strategies and then evaluate those strategies quantitatively by comparing their expected utilities detennined from the frequencies and values assigned to the major outcomes associated with each strategy."
    },
    {
      "title": "Postscript",
      "text": "Counting clinical events as described in this chapter may seem to be the most mlUldane of tasks. It seems so obvious that examining counts of clinical events under various circumstances is the foundation of clinical science. It may be worth reminding the reader that Pierre Louis introduced the \"numerical method\" of evaluating therapy less than 200 years ago. Louis had the audacity to count deaths and recoveries from febrile illness in the presence and absence of blood-letting. He was vilified for allowing lifeless numbers to cast doubt on the healing powers of the leech, powers that had been amply confirmed by decades of astute qualitative clinical observation."
    },
    {
      "title": "RISK",
      "text": "Risk generally refers to the probability of some untoward event. Tn this chapter, the term risk is used in a more restricted sense to indicate the likelihood that people who aft' exposed to certam factors (\"risk factors\") will subsequently develop a particular disease.\n\nPeople have a strong interest in their risk of diseasc. This concern has spawned many popular books about risk reduction and is reflected in newspaper headlines about the risk of breast cancer from exposure to toxic chemicals, of AIDS from blood transfusions, or of prostatic cancer after vasectomy.\n\nThis chapter describes how investigators obtain estimates of risk by observing the relationship between exposure to possible risk factors and the subsequent incidence of disease. We discuss several ways of comparing risks, as they affect both individuals and populations."
    },
    {
      "title": "Risk Factors",
      "text": "Characteristics that are associated with an increased risk of becoming diseased are called risk factors. Some risk factors arc inherited. For example, having the haplotype HLA-B27 greatly increases one's risk of acquiring the spondylarthropathies. Work on the Human Genome Project has identified several other diseases for which specific genes are risk factors, including colon cancer, osteoporosis, and amyotropic lateral sclerosis. Other risk factors, such as infectious agents, drugs, and toxins, are fOlUld in the physical environment. Still others are part of the social environment. For example, bereavement due to the loss of a spouse, change in daily routines, and crowding all have been shown to increase rates of disease-not only emotional illness but physical illness as well. Some of the most powerful risk factors are behavioral; examples are smoking, drinking alcohol to excess, driving without seat belts, and engaging in unsafe sex.\n\nExposure to a risk factor means that a person has, before becoming ill, come in contact with or has manifested the factor in question. Exposure can take place at a single point in time, as when a community is exposed to radiation during a nuclear accident. More often, however, contact with risk factors for chronic disease takes place over a pl.-'riod of time. Cigarette smoking, hypertension, sexuill promiscuity, and SWl exposure are examples.\n\nThere are several different ways of characterizing the amount of exposure or contact with a putative risk factor: ever exposed, current dose, Jilrgest dose taken, total cumuliltive dose, yeMs of exposure, years since first contact, etc.  (1) . Although the various measures of dose tend to be related to each other, some may show iln exposure-disease relationship, whereas others do not. For example, cumulative doses of sun exposure constitute a risk factor for nonmelanoma skin cancer, whereas episodes of severe sunburn <He a better predictor of melanoma. Choice of an appropriate measure of exposure to a risk factor is usually based on all that is known about the biologic effects of the exposure and the pathophysiology of the disease."
    },
    {
      "title": "Recognizing Risk",
      "text": "Large risks associated with effects that occur rapidly after exposure are easy for anyone to recognize. Thus it is not difficult to ilppreciate the relationship between exposure and disease for conditions such as chickenpox, sunburn, and aspirin overdose, because these conditions follow exposure relatively rapidly and with obvious effects. But most morbidity and mortality is caused by chronic diseases. Por these, relationships between exposure and disease are far less obvious. It becomes virtually impossible for individual clinicians, however ilshtte, to develop estimates of risk based on their own experiences with patients. This is true for several reasons, which are discussed below."
    },
    {
      "title": "LONG LATENCY",
      "text": "Many diseases have long latency periods between exposure to risk factors and the first manifestations of disease. This is particulilrly true for certain cancers, such as thyroid cancer in ildults after radiiltion treatment for childhood tonsillitis. When patients experience the consequence of exposure to a risk factor years later, the original exposure may be all but forgotten. The link between exposure and disease is thereby obscured."
    },
    {
      "title": "FREQUENT EXPOSURE TO RISK FACTORS",
      "text": "Many risk factors, such as cigarette smoking or eating a diet high in cholesterol and saturated fats, are so common in our society that for many years they scarcely seemed dangerous. Only by comparing patterns of disease among people with and without these risk factors or by investigating special subgroups-e.g., Mormons (who do not smoke) and vegetari-ans (who eat diets low in cholesterol)~did we recognize risks that are, in fact, large."
    },
    {
      "title": "LOW INCIDENCE OF DISEASE",
      "text": "Most diseases, even ones thought to be \"common,\" are aetuaJly quite rare. Thus, although lung cancer is the mo~t common cause of cancer deaths in Americans, the yearly incidence of lung cancer even in heavy smokers is less than 2 in 1000. In the average physician's practice, years may pass between patients with new cases of lung cancer. It is difficult to draw conclusions about such infrequent events."
    },
    {
      "title": "SMALL RISK",
      "text": "If a factor confers only a small ri~k for a disease, a large number of people are required to observe a difference in disease rates between exposed and unexposed persons. This is so even if both the risk factor and the disease occur relatively frequently. for example, it is still uncertain whether birth control pills increase the risk of breast cancer, because estimate~of this risk are all small and, therefore, easily discounted as resulting from bias or chance. In contrast, it i~not controversial that hepatitis B infection i~il risk factor for hepatoma, because people with hepatitis B infection are hundreds of times more likely to get liver cancer than those without it."
    },
    {
      "title": "COMMON DISEASE",
      "text": "If a disease is c()mmon~heart diseilse, cancer, or stroke~and some of the ri~k factors for it are already known, it become~difficult to di~tinguish a new risk factor from the others. Also, there is les~incentive to look for new ri~k factors. For example, the ~yndrome of sudden, unexpected death in adults is a common way to die. Many cases secm related to coronary heart disease. However, it is entirely conceivable that there are other important causes, as yet unrecognized because an adequate explanation for most cases is available.\n\nOn the other hand, rare disease~and unusual clinical presentations invite efforts to find a cau~e. AIDS was ~uch an unusual syndrome that the appearance of just a few cases raised suspicion that ~ome new agent (as it turned out, a retrovirus) might be responsible. Similarly, physicians were quick to notice when several ca~es of carcinoma of the vagina, a very rare condition, began appearing. A careful search for an explanation was undertaken, and maternal exposure to diethylstilbestrol was found."
    },
    {
      "title": "MULTIPLE CAUSES AND EFFECTS",
      "text": "There is usually not a dose, one-to-one relationship between a risk factor and a particular disease. The relationship between hypertension and congestive f<lilure is an example (Fig. 1 ' i l l 1 K ' ' i : :I : i i mU I ] ! ' i ' ' ' \u2022 i f f i l l i i ; : ! ! ' i I , m ..\n\n..i . , . ' ! . . ! . , . \u2022: , \u2022 \" \" .. ! ! ' . f , ! . ' .\u2022 ~:.\" . . \u2022 \u2022 . ! , : . \u2022 . ! . , ' , . '. \" .. \" . ' : . ! \" \" : ' . ! 'iU!i~I\u2022:\u2022] ..\u2022'.'].~.\u2022'.'.\u2022 . . \" . \u2022 ' , ! ' , 1 ,:illffii:,:>,;:F;,:n;nHp<>\"\"'\" \"'-' > ' _ ~Coronary atherosclerosis ~Stroke Renal failure Cigaretles Cholesterol Diabetes Family history Myocardial infarction Figure 5.1. Relationship between risk factors and disease: hypertension (1 BP) Clnd congestive heart failure (CHF). Hypertension causes many diseases, including congestive heart failure, and congestive heart failure has many causes, including hypertension.\n\ndevelop congestive heart failure and many do not. Also, many people who do not have hypertension develop congestive heart failure, because there are several different causes. The relationship is also obscured because hypertension causes several diseases other than congestive heart failure. Thus, although people with hypertension are about 3 times more likely than those without hypertension to develop congestive heart failure and hypertension is the leading cause of the condition, physicians were not particularly attuned to this relationship until the 1970s, when adequate data became available after careful study of large numbers of people over many years. For all these reasons, individual clinicians are rarely in a position to confirm associations betvveen exposure and disease, though they may suspeet them. For accurate information, they mw;t tum to the ffiedicalliterature, particularly to studies th<lt are carefully constructed <lnd involve 01 large number of patients."
    },
    {
      "title": "Uses of Risk"
    },
    {
      "title": "PREDICTION",
      "text": "Risk factors are used, first and foremost, to predict the occurrence of disease. In fact, risk factors, by definition, predict some future event. The best available information for predicting disease in an individual person is past experience with a large number of people with a similar risk factor. The quality of such predictions depends on the similarity of the people on whom the estimate is based and the person for whom the prediction is made.\n\nIt is important to keep in mind that the presence of even a strong risk factor does not mean that an individual is very likely to get the disease. For example, studies have shown that a heavy smoker has a 20-fold greater risk of lung cancer compared with nonsmokers, but he or she shU has only a 1 in a 100 chance of getting lung cancer in the next 10 years.\n\nThere is a basic incompatibility betwecn the incidence of a disease in groups of people and the chance that an individual will contract that disease. Quite naturally, both patients and clinicians would like to answer questions about the future occurrence of disease as precisely as possible. They arc uncomfortable about assigning a probability, such as the chances that a person will get lung cancer or stroke in the next 5 years. Moreover, anyone person wilL at the end of 5 years, either have the disease or not. So in a sense, the average is always wrong because the two are expressed in different terms, a probability venms the presence or absence of disease. Nevertheless, probabilities can guide clinkal decision making. Even if a prediction does not come true in an individual patient, it will usually be borne out in many such patients."
    },
    {
      "title": "CAUSE",
      "text": "Just because risk factors predict disease, it docs not necessarily follow that they cause disease. A risk factor may mark a disease outcome indirectly, by virtue of an association with some other determinant(s) of disease, i.e., it may be confounded with a causal factor. For example, lack of maternal education is a risk factor for low birth weight infants. Yet, other factors related to education, such as poor nutrition, less prenatal care, cigarette smoking, etc., are more directly the causes of low birth weight.\n\nA risk factor that is not a cause of disease is called a marker, because it \"marks\" the increased probability of disease. Not being a cause does not diminish the value of a risk factor as a way of predicting the probability of disease, but it does imply that removing the risk factor might not remove the excess risk associated with it. For example, as pointed out in Chapter 1, although there is growing evidence that the human papillomavirus (HPV) is a risk factor for cervical cancer, the role of other sexually transmit-ted diseases, such as herpes simplex virus and Chlalllydia, is not as dear. Antibodies to these agents are more common among patients with cervical cancer than in women without cancer, but the agents may be markers for risk of cervical cancer rather than causes, If so, curing them would not necessarily prevent cervical cancer. On the other hand, decreasing promiscuity might prevent the acquisition of both the causative agent for cervical cancer and other sexually transmitted diseases  (2) .\n\nThere are several ways of deciding whether a risk factor is (I cause or merely a marker for disease. These are covered in Chapter 1L"
    },
    {
      "title": "DIAGNOSIS",
      "text": "Knowledge of risk can be used in the diagnostic process, since the presence of a risk factor increases the prevalence (probability) of disease among patients-one way of improving the positive predictive value of a diagnostic test.\n\nHowever, in individual patients, risk factors usually are not as strong predictors of disease as art' clinical findings of early disease. As Rose  (3)  put it:\n\nOften the best predictor of future major diseases is the presence of existing minor disease. A low ventilatory function today is the best predictor of its future rate of decline. A high blood pressure today is the best predictor of its future rate of rise. Early coronary heart disease is better than all of the conventional risk factors as a predictor of future fatal disease.\n\nRisk factors can provide the most help with diagnosis in situations where the factor confers a substantial risk and the prevalence of the disease is increased by clinical findings. For example, age and sex are relatively strong risk factors for coronary artery disease, yet the prevalence of disease in the most at risk age and sex group, old men, is only 12%. When specifics of the clinical sihtation, such as presence and type of chest pain and results of an electrocardiographic stress test, \"lre considered as we]], the prevalence of coronary disease can be raised to 99  '10 (4) .\n\nMore often, it is helpful to use the absence of a risk factor to help rule out disease, particularly when one factor is strong and predominant. Thus it is reasonable to consider mesothelioma in the differential diagnosis of a pleural mass in a patient who is an asbestos worker, but mesothelioma is a much less likely diagnosis for the patient who has never worked with asbestos.\n\nKnowledge of risk factors is also used to improve the efficiency of screening programs by selecting subgroups of patients at increased risk."
    },
    {
      "title": "PREVENTION",
      "text": "If a risk factor is also a cause of disease, its removal can be used to prevent disease whether or not the mechanism by which the disease takes place is known. Some of the classic successes in the history of epidemiology illustrate this point. For example, before bacteria were identified, Snow found an increased rate of cholera among people drinking water supplied by a particular company and controlJed an epidemic by cutting off that supply. More recently, even before HIV had been identified, studies showed that a lifestyle of multiple sexual partners among homosexual men was a risk factor for acquiring AIDS  (5) . The concept of cause and its relationship to prevention is discussed in Chapter 11."
    },
    {
      "title": "Studies of Risk",
      "text": "The most powerful way of determining whether exposure to a potentiill risk factor results in an increased risk of disease is to conduct an experiment. People currently without disease would be divided into groups of equal susceptibility to the disease in question. One group would be exposed to the purported risk factor and the other would not, but the groups would otherwise be treated the same. Later, any difference in observed rates of disease in the groups could be attributed to the risk factor.\n\nUnfortunately, the effects of most risk factors for humans cannot be studied with experimental studies, in which the researcher dett~mlines who is exposed. Consider some of the questions of risk that concern us today. I low much are inactive people at increased risk for cardiovascular disease, everything else being equal? Do cellular phones cause brain cancer? Does alcohol increase the risk of breast cancer? For such questions as these, it is usually not possible to conduct an experiment. first, the experiment would have to go on for decades. Second, it would be unethical to impose possible risk factors on a group of the people in the study. Finally, most people would balk at having their diets and behaviors determined by others for long periods of time. As a result, it is usually necessary to study risk in less obtrusive ways.\n\nClinical shtdies in which the researcher gathers data by simply observing events as they happen, without playing an active part in what takes place, are called observational studies. Most studies of risk are observational studies, either cohort studies, described in the rest of this chapter, or case control st1ldies, described in Chapter 10."
    },
    {
      "title": "COHORTS",
      "text": "The term cohort is used to describe a group of people who have something in common when they are first assembled and who are then observed for a period of time to sec what happens to them. Table  5 .1 lists some of the ways in which cohorts are used in clinical research. Whatever members of a cohort have in common, observations of them should fulfill two criteria if they are to provide sound information about risk.\n\nFirst, cohorts should be observed over a meaningful period of time in the natural history of the disease in question. This is so there will be sufficient time for the risk to be expressed. If we wish to learn whether neck irradiation during childhood results in thyroid neoplasms, as-year follow-up would not be a fair test of the hypothesis that thyroid cancer is associated with irradiation, because the usual time period between irradiation expusure and the onset of di.sease is considerably longer. Second, all members of the cohort should be observed over the full period of follow-up. To the extent that people drop out of the study and their reasons for dropping out are relilted in some way to the outcome, the information provided by an incomplete cohort can be il distortion of the true state of affairs."
    },
    {
      "title": "COHORT STUDIES",
      "text": "In a cohort study (Fig.  5 .2), a group of people (a cohort) is assembled, none of whom has experienced the outcome of interest, but all of whom could experience it. (for example, in a study of risk factors for endometrial Cilncer, each member of the cohort should have an intact uterus.) On entry to the study, people in the cohort are classified according to those charilcteristics (possible risk factors) that might be related to outcome. These people are then observed over time to see which of them experience the outcome. It is then possible to see how initial characteristics relate to subsequent outcome events. Other names for cohort studies are longitudinal (emphasizing that patients are followed over time), pmc.-p1'ctive (implying tht.' forward direction in which the patients are pursued), and iI/tide/Ice (calling attention to the basic measure of new disease events over time)."
    },
    {
      "title": "No Disease Exposure to Risk Factor",
      "text": "Exposed"
    },
    {
      "title": ". Design of a cohort study of risk",
      "text": "The following is a description of a classical cohort study, which has made important contributions to our understanding of cardiovascular disease.\n\nExample The Framingham Study  (6)  was begun in 1949 to identify factors associated with an increased risk of coronary heart dist;>ase (CI-ID). A reprt;>sentative sample of .'),209 men and women, aged 30-59, was selected from approximately] 0,000 persons of that age living in Framingham, a small town near Boston. Of tlwse, 5,127 were frcc of CHlJ when first examined <md, therdore, were at risk of developing CHD. These people were ret;>xamined biennially for evidenn' of coronary disease. The study ran for 30 yt;>ars and demonstrated that risk of developing CHD is associated with elevated blood prt;>ssure, high serum cholesterol, cigardte smoking, glucose intolerance, and left ventricular hypertrophy. There was a large difference in risk between those with none and those with all of these risk factors."
    },
    {
      "title": "HISTORICAL COHORT STUDIES",
      "text": "Cohort studies can be conducted in two ways (Fig.  5 .3). The cohort can be assembled in the present and followed into the future (a concurrent cohort study), or it can be identified from past records and followed forward from that time up to the present (an historical cohort study).\n\nMost of the advantages and disadvantages of cohort studies discussed below apply whether the study is concurrent or historical. However, the potential for difficulties with the quality of data is different for the two. In concurrent studies, data can be collected specifically for the purposes of the study and with full anticipation of what is needed. It is thereby possible to avoid biases that might undermine the accuracy of the data. On the other hand, data for historical cohorts arc often gathered for other purposes-usually as part of medical records for patient care. These data may not be of sufficient quality fnr rigorous research.\n\n.~PRESENT"
    },
    {
      "title": "FUTURE"
    },
    {
      "title": "Cohort assembled"
    },
    {
      "title": "Historical Cohort",
      "text": "\u2022\u2022~Follow-up"
    },
    {
      "title": "Concurrent",
      "text": "Cohort \"\"~?~'~'~~\"'~Follow-up assembled"
    },
    {
      "title": "ADVANTAGES AND DISADVANTAGES OF COHORT STUDIES",
      "text": "Some of the ildvantages and disadvantages of cohort studies, for the purpose of describing risk factors, are summarized in Table  5 .2. Cohort studies of risk are the best available substitutes for a true experiment when experimentation i~not possible. They follow the same logic as a clinical trial, and they allow determination of exposure to a possible risk factor while avoiding any possibility of bias that might occur if exposure is determined after the outcome is already known.\n\nThe principal disadvantage is that if the outcome is infrequent (which is usually the case) a large number of people must be entered in <J study and remain under observation for a long time before results are available. Pur example, the Pramingham Study of coronary heart disease-one of the most frequent of the chronic diseases in America-was the largest\n\nT<lble 5.2 Advantages and DiS<ldv<lntages of Cohort Studies Advantages The only WaY of establishing incidence (i,e., ubsolute risk) directly Follows tile same logic as tile clinical question: If persons exposed. then do they get the disease? Exposure Gan he elicited without the l)i,JS th<lt mighl occur if outcome wcre ,llreacJy known Carl 8ssess the relationship between exposure 8nd m<lny di~;(~ases rJbcHlvantagcs ___-==oc _ Inefficient because m\"lrly more subjects must be enrolled than experience the event of illterest; Iherefore, C[lnnol he u~;e{j (or rare dise8ses l:xpensive because of resources necessary to study many people over time Results not <Ivail<ltlle tor a long time Assessee; nl(o reldtionship between disease 8nd exposure tD only relatively few tClctors (ie, those recorded at the ouhet Df the ~;tlJdy)\n\nstudy of its kind when it began. Nevertheless, more than 5000 people had to be followed for several years before the first, preliminary conclusions could be published. Only 5% of the people had experienced a coronary event during the first oS years! A rd<lted problem with cohort studies results from the fact that the people being studied are usually \"free living\" and not under the control of researchers. 1\\ great deal of effort and money must be expended to keep track of them. Cohort studies, therefore, are expensive, sometimes costing many millions of dollars.\n\nBecause of the time and money required for cohort studies, this approach cannot be used for all clinical questions <lbout risk. For practical [('<I sons, the cohort approach has been reserved for only the most important questions. This has led to efforts to find more efficient, yet dependable, ways of assessing risk. (TIl(' most common of these, case control studies, is discussed in Chapter 10.)\n\nThe most important scientific disadvantage of observational shldies, including cohort studies, is that they are subject to a great many more potential biases than are experiments. People ,vho are exposed to a certain risk factor in the natural course of events arc likely to differ in a great many ways from a comparison group of people not exposed to the factor. 1\u00a3 these other differences arc also related to the disease in question, they could account for any association observed behveen the putative risk factor and the disease.\n\nThis leads to the main challenge of observational studies: to deal with extraneous differences between exposed and nonexposcd groups to mimic as closely as possible an experiment. The differences arc considered \"extraneous\" from the point of view of someone hying to determine callseand-effect relationships. The following example illustrates one approach to handling such differences.\n\nExample Although the presence of sickle-cell trait (HbAS) is generally regcuded as a benign condition, several studies have suggested that it is associated with defects in physical growth and cognitive d<'\\\u2022e1opment. A study was undertaken, therefore, to see if children born with HbAS experienced problems in growth and development more frequently than children with norm,ll hemoglobin (HbAA), everything else being equal  (7) . It WdS recogni,..,ed that a great many other factors are related to growth ,md develop-Ilwnt and also to having IIbAS, Among these are race, sex, birth date, birlh wei;;ht, gestntional age, 5-min Apgar score, and socioeconomic status. If these olher factors were not taken into <lccount, Ont,' or more of them cO\\Jld bias the results of the study, and it would not be possible to distinguish the dfects of HbAS, in and of itself, from the effects of the other factors. The authors chos<' to deal \\vith these other factors by matching. For each child with HbAS, th<'y selected a child with IfbAA who was similar with respect to the seven o[her factors. A toh,l of 100 newborns--50 with HbAS and 50 with HbAA-were followed from birth to 3-5 vei1rs old, No difference::; in growth and development were found.\n\n\u2022\n\nMajor biases in observational studies and ways of dealing them are described in Chapter 6."
    },
    {
      "title": "Comparing Risks",
      "text": "The basic expression of risk is incidence, defined in Chapter 4 as the number of new cases of disease arising in a defined population during a given period of time. But usually we want to compare the incidence of disease in two or more groups in a cohort that differ in exposure to a possible risk factor. To compare risks, several measures of the association between exposure and disease, called mf'llsures of effect, are commonly used.\n\nThey represent different concepts of risk and are used for different pur-pOses. four measures of effect are discussed below (Tables  5.3  and  5.4 )."
    },
    {
      "title": "ATTRIBUTABLE RISK",
      "text": "First, one might ask, \"What is the additional risk (incidence) of disease following exposure, over and above that experienced by people who are not exposed?\" The answer is expressed as attributable risk, the incidence of disease in exposed persons minus the incidence in nonexposed persons. Attributable risk is the additional incidence of disease related to exposure, taking into account the background incidence of disease, presumably from other causes. Note that this way of comparing rates implies that the risk factor is a cause and not just a marker. Because of the way it is calculated, attributable risk is also called risk differcllce.\n\nTable 5.3 Measures of Effect AR=I,,-li.-AR~=ARxP Expression Atlnbutable risk (risk difference) Relative risk (risk ratio) Population attributable risk Population attributable fraction Ouestion What is the incidence 01 disca.<;e llttrioutable to exposure? How many times mor(~likely are exposed persons to become diseasrxt, relative to nonexpo,,f:Jrl persons? Whal is the incidence of rlisease in a population, llssociated with the occurrence of a risk factor? What fractiol1 of disease in CI population is attributClble to exposure to a risk tactor? RR Definition\" Ie I, 'Where I, = incidonce in exposed persons; r;im;id,mce in nonoxposed pl1rscms; f' -prevalence of exposure to a nsk filetor; Clnd I,. -total inci<iHneH of disease ill a population, 106 CLINICAL EPIDEMIOLOGY On the other hand, one might ask, \"How many times are exposed per-son5 more likely to get the disease relative to nonexposed persons?\" To answer this question, we speilk of relative risk or risk ratio, the ratio of incidence in exposed persons to incidence in nonexposed persons. Relative risk tells us nothing about the magnitude of absolute risk (incidence). Even for larg;e relative risks, the absolute risk might be quite 5ma1l if the di5ease is uncommon. It does tell us the strength of the associ<ltion between exposure and disease <lnd so is a useful measure of effect for studies of disease etiology."
    },
    {
      "title": "INTERPRETING ESTIMATES OF INDIVIDUAL RISK",
      "text": "The clinical meaning attached to relative and attributable risk is often quite different, because the two expressions of risk stand for entirely different concepts. The appropriate expression of risk depends on which question is being <Isked.\n\nExample Risk factors for cardiovascular diseasl;' are generally thought to be weaker among the elderly than thl;' middle-aged. This assertion was examined by comparing the relative risks and attributable risks of conunon risk factors for cardiovascular disl;'ase among different agc groups  (8) . An l;'xample is thl;' risk of stroke from smoking (Table  5 ..'). The relative risk decreases with age, from 4.0 in persons ages 45\u202249 to 1.4 in persons aged 65-69. However, thl.' attributable risk increases slightly with age, mainly because stroke is more common in the elderly regardless of smoking status, Thus, although the causal link betwel;'n smoking and stroke decreases with age, ,m elderly individual who smokes increases his or her actual risk of stroke to a similar, indeed slightly greater, degree than a younger person.\n\nTable 5.5 Comparing Relative Risk and Attributable Risk in the Relationship of Smoking, Stroke, and Age~1 \"';idcllco (per 10001 Ilelative AttributablH A!JH Nonsmoker,; Smokers Risk Risk 45--49 7.4 297 4.0 22.3 50-54 1f.2 37.D 2.2 19.8 55-59 27.9 64./ 2.3 367 60-64 47,~76.9 1.6 29.5 65-69 1l0.2 110~14 30.2 'Adapted from F-'saty 8M el al. J Clin Epiderniol 1990; 43:961 -970\n\nTn most clinical situations, because attributable risk represents the actua I additional probability of disease in those exposed, it is a more meaningful expression of risk for individuals than is relative ri~k. On the other hand, relative risk is more useful for expressing the strength of a causal relationship."
    },
    {
      "title": "POPULATION RISK",
      "text": "Another way of looking at risk is to ask, \"How much does a risk factor contribute to the overall rates of disease in groups of people, rather than individuals?\" Thi~information is useful for deciding which risk factors are particularly important and which are trivial to the overall health of a community, and so it can inform those in policy positions how to choo~e priorities for the deployment of health care re~ources. A relatively weak risk factor (i.e., one with a small relative risk) that is quite prevalent in a community could account for more disease than a very strong, but rare, risk factor.\n\nTo estimate population risk, it is necessary to take into account the frequency with which members of a community are expo~ed to a ri~k factor. Population attributable risk i~the product of the attributable risk and the prevalence of the risk factor in a population. It measures the excess incidence of disease in a community that i~associated with a risk factor. One can also describe the fwction of disease occurrence in a population that is associated with a particular risk factor, the papulation attributa/JI1' fraction. It is obtained by dividing the population attributable risk by the total incidence of disease in the population.\n\nFigure  5 .4 illustrates how the prevalence of a risk factor determines the relationship between individual and population risk. Figure  5 .4A shows the attributable risk of death according to diastolic blood pressure. Risk increases with increasing blood pressure. However, few people have extremely high blood pressure (Fig.  4. Relationships among attributable risk, prevalence of risk factor, and population risk for hypertension, (Adapted from The Hypertension Detection and Follow-up Cooperative Group, Mild hypertensives in the hypertension detection and follow-up program. Ann NY Acad Sci 1978;304:254-266.) having a diastolic blood pressure >',10 mm Hg, most hypertensive people aTe just over 90 mm Hg, and very few are in the highest category (~115 mm Hg). As a result, the greatest percentage of excess deaths in the population (58.4\u00b0/<,) is attributable to relatively [ow-grade hypertension, 90-105 mm Hg (Fig. S.4C). Paradoxically, then, physicians could save more lives by effective treatment of mild hypertension than severe hypertension. This fact, so counterintuitive to clinical thinking, has been termed \"the prevention paradox\" (',I). Measures of population risk are less frequently encountered in the clini-cill literature thiln are measures of individual risk, e.g., attributable and relative risks. But a particular clinical practice i;: as much a population for the dodor as is a community for health poJicymakers. /\\Iso, how the pn.'valence of exposu re affects community risk can be imporlant in the care of individual patients. for instance, when patients cannot give a history or when exposure is difficult for them to recognize, we depend on the usual prevalence of exposure to estimate the likelihood of various diseases. When considering treatable causes of cirrhosis in a North American patient, for example, it would be more profitable to consider alcohol than schistosomes, inasmuch as few North Americilns are exposed to Schistosoma I1lllrlsoni. Of course, one might take a very different stance in the Nile delta, where schistosomes are prevalent and the people, who are mostly Musl ims, rilrdy drink alcohol."
    },
    {
      "title": "Summary",
      "text": "Risk filctors are characteristics that are associated with an increased risk of becoming diseased. Whether or not a particubr risk factor is a cause of disease, its presence allows one to predict the probability that disease will occur.\n\nMost suspected risk factors cannot be manipulated for the purposes of an experiment, so it is usually necessary to study risk by simply observing people's experience with risk factors and disease. One way of doing so is to select a cohort of people, some members of which are and some of which are not exposed to a risk factor, and observe the subsequent incidence of disease. Although it is scientifically preferable to study risk by means of cohort studies, this approach is not always feasible because of the time, e[fort, and expense it ent<lils.\n\nWhen diseilsc rates are compared among groups with different exposu res to a risk factor, the results can be expressed in several ways. Attributable risk is the excess incidence of diseilse related to exposure. Relative risk is the number of times more likely exposed people are to become diseased relative to nonexposed people. The impact of a risk factor on groups of people takes into account not only the risk related to exposure but the prevalence of exposure as well."
    },
    {
      "title": "PROGNOSIS",
      "text": "When people become sick, they have a great many questions about how their illness will affect them. Is it dangerous? Could I die of it? Will there be pain? How long will I be able to continue my present activities? Will it ever go away altogether? Most patients and their families want to know what to expect, even if little can be done about their illness.\n\nProfillOsis is a prediction of the future course of disease following its onset. In this chapter, we review the ways in which the course of disease can be described. We then consider the biases that can affect these descriptions and how these biases can he controlled. Our intention is to give readers a better lll1derstanding of a difficult but indispensable task-predicting patients' futures as closely as possible. The object is to avoid expressing prognosis with vagueness when it is unnecessary, and with certainty when it is misleading.\n\nDoctors and patients think about prognosis in severa] different ways. First, they want to know the general course of the illness the patient has. A young patient suffering from postherpetic neuralgia associated with herpes zoster can be assured that the pain usually resolves in less than a month. Second, they usually want to know, as much as possible, the prognosis in the particular case. Even though HIV infection is virtually universally f<ltal, individuals with the infection may live from a few months to more than a decade; a patient wants to know where on this continuum his or her particular case falls. Third, patients especially are interested to know how <In illness is likely to affect their lives, not only whether it will or will not kill them, but how it will change their ability to work, to walk, to talk, how it will alter their relationships with family and friends, how much pain and discomfort they will have to endure."
    },
    {
      "title": "Prognosis Studies",
      "text": "Studies of prognosis tackle these clinical questions in ways similar to cohort studies of risk. A gnup of patients having something in common (a particular medical disease or condition, in the case of prognostic studies) 111 are assembled and followed fonvard in time, and clinical outcomes are measured. Often, conditions that are associatrcd with a given outcome of the disease, i.e., prugnostic factors, are sought."
    },
    {
      "title": "CLINICAL COURSE/NATURAL HISTORY OF DISEASE",
      "text": "Disease prognosis can be described for either the clinical course or the natural history of Hlness. The term clinical course has been used to describe the evolution (prognosis) of disease that has come under medical care and is then treated in a variety of ways that might affect the subsequent course of events. Patients usually come under medical care at some time in the course of their illness when they have diseases that cause symptoms such as pain, failure to thrive, disfigurement, or unusual behavior. Examples include type 1 diabetes mellitus, carcinoma of the lung, and rabies. Once disease is recognized, it is also likely to be treated.\n\nThe prognosis of disease without medical intervention is termed the natural history of disease. Natural history describes how patients will fare if nothing is done for their disease. A great many medical conditions, even in countries with advanced medical care systems, often do not come under medical care. They remain unrecognized, perhaps because they are asymptomatic or are considered among the ordinary discomforts of daily living, Examples include mild depression, anemia, and cancers that are occult and slow growing (e.g., some cancers of the thyroid and prostate)."
    },
    {
      "title": "ZERO TIME",
      "text": "Cohorts in prognostic studies are observed starting from a point in time, called zero time. This point should be specified clearly and be the same well-defined location along the course of disease (e.g., the onset of symptoms, time of diagnosis, or beginning of treatment) for each patient. The Lerm inception cohurt is used to describe a group of people who are assembled near the onset (inception) of disease.\n\nTf observation is begun at different points in the course of disease for the various patients in the cohort, description of their subsequent course will lack precision. The relative timing of such events as recovery, recurrence, and death would be difficult to interpret or misleading.\n\nFor example, suppose we wanted to describe the clinical course of patients with lung cancer. We would assemble a cohort of people with the disease and follow them forward over time to such outcomes as complications and death. Hut what do we mean by \"with disease\"? If zero time was detection by screening for some patients, onset of symptoms for others, and hospitaliz<lLion or the beginning of treatment for still others, then observed prognosis would depend on the particular mix of zero times in the study. Worse, if we did not explicitly describe when in the course of disease patients entered the cohort, we would not know how to interpret or use the reported prognosis."
    },
    {
      "title": "DESCRIBING OUTCOMES OF DISEASE",
      "text": "Descriptions of prognosis should include the full range of manifestations that would be considered important to patients. This means not only death and disease but also consequences of disease such as pain, anguish, and inability to care for one's self or pursue usual activities. (The Five Os listed in Table  1 .2 are a simple way to summarize important clinical outcomes.)\n\nIn their efforts to be \"scientific,\" physicians sometimes value certain kinds of outcomes over others, at the expense of clinical relevance. Clinical effects that cannot be directly perceived by patients (e.g., reduction in tumor size, normalization of blood chemistries, or change in serology) are not ends in themselves. It is appropriate to substitute these biologic phenomena for clinical outcomes only if the two are known to be related to each other. Thus hypercalcemia is an important clinical outcome of hyperparathyroidism only if it causes symptoms such as drowsiness or thirst or if there is reason to believe that it will eventually lead to complications such as bone or kidney disease. If an outcome cannot be related to something patients will recognize, the information should not be used to guide patient care, although it may be of considerable value in understanding the origins and mechanisms of disease."
    },
    {
      "title": "HEALTH-RELATED QUALlTY\u2022OF~L1FE MEASURES",
      "text": "There is growing recognition that \"health\" involves more than the avoidance of negative aspects such as death and disease. Clinical activities should have a positive impiJct on how a person functions and lives. This concept has been referred to as health-related quality of life, health status, or functional status. Questionnaires have been developed to measure patients' quality of life. Sometimes their use strengthens arguments for certain clinical interventions. For example, a study showed that erythropoietin treatment of patients with chronic renal failure not only increased patients' hematocrits but improved their health-related quality of life  (1) . On the other hand, sometimes quality-of-life measurements reveal complicated trade-offs. A study of zidovudine (AZT) treatment in patients with mildly symptomatic HIV infection showed that although the drug delayed progression to AIDS by an average of 0.9 months, the positive result was offset by adverse effects of the drug. Thus patients receiving the drug had an average of 14.5 months without disease progression or severe symptomatic adverse effects from AZT compared with an average of 14.7 months for patients not receiving the drug  (2) . What looked like a small benefit in delayed progression to AIDS was not so clear when quality-of-life measures were added to the study."
    },
    {
      "title": "Prognostic Factors",
      "text": "Although most patients are interested in the course of their disease in general, they Me even more interested in a prediction for their given case. Prognostic factors help identify groups of patients with the same disease who have different prognoses."
    },
    {
      "title": "DIFFERENCES BETWEEN PROGNOSTIC FACTORS AND RISK FACTORS",
      "text": "Studies of risk factors usually deal with healthy people, whereas prognostic factors-conditions that are associated with an outcome of diseaseare, by definition, studied in sick people. There arc other important differences as well, outlined below."
    },
    {
      "title": "Different Factors",
      "text": "Factors associated with an increased risk are not necessarily the same as those marking a worse prognosis and are often considerably different for a given disease. for example, low blood pressure decreases one's chances of having an acute myocardial infarction, but it is a bad prognostic sign when present during the acute event (fig. 6 .1). Similarly, intake of exogenous estrogens during menopause increases women's risk of endometrial cancer, but the associated cancers are found ilt an earlier stage and seem to have a better-than-average prognosis. Some factors do have a similar effect on both risk and prognosis. For example, both the risk of experiencing an acute myocardial infarction and the risk of dying of it increase with age."
    },
    {
      "title": "Outcomes"
    },
    {
      "title": "Well"
    },
    {
      "title": "Onset of Acute Myocardia Infarction"
    },
    {
      "title": "Different Outcomes",
      "text": "Risk and prognosis describe different phenomena. For risk, the event being counted is the onset of disease. For prognosis, a variety of conscquences of disease are counted, including death, complications, disability, and suffering."
    },
    {
      "title": "Different Rates",
      "text": "Risk factors generally predict low probability events. Yearly rates for the onset of various diseases are on the order of 1/100 to 1/10,000. As a result, relationships between exposure and risk usually elude even astute clinicians unless they rely on carefully executed studies, often involving a large number of people over extended periods of time. Prognosis, on the other hand, describes relatively frcquent events. Clinicians often can form good estimates of prognosis on their own, from their personal experience. For example, they know that few patients with lung or pancreatic cancer survive as long as 5 years, whereas most with chronic lymphocytic leukemia survive much longer."
    },
    {
      "title": "MULTIPLE PROGNOSTIC FACTORS AND PREDICTION RULES",
      "text": "A combination of factors may give a more precise prognosis than each of the same factors taken one at a time. Clinical prediction rules estimate the probability of outcomes according to a set of patient characteristics.\n\n[xaml,le Once patients with HIV infection develop A[DS, the pHlI-,'l1osis is poor and survival time is short. Even so, and bdore antiviral and prophylactic therapy for opportunistic infections became standard treatment, it was clear that some patients with AIDS survived much longer than others. A study was done to determine which patient characteristics predicted survival  (3) . Each of several physiologic characteristics was found to be related to survival. Using these factors in combination, the investigators developed a prognostic staging system, with [ point for the presence of each of 7 factors: severe diarrhea or a serum albumin <2.0 gm/dL, any neurologic dl.'ficit, Pl.':2 less than or equal to 50 mm Hg, helllatocrit <30(}:\" lymphocyte count < 150/ mL, white COlmt <25001mL, and platelet count < 140,000/ mL. The total ;;core determined the prognostic stage (I, 0 points; II, 1 point; ][[, greater th;m or equal to 2 points). Figure  6 .2 shows the survival of AIDS patients in each prognostic stage. Using multiple prognostic factors together, the authors noted that prediction for median length of survival varied from [[.5 months for patients in stage I to 2.1 months for patients in stage Ill."
    },
    {
      "title": "Describing Prognosis"
    },
    {
      "title": "PROGNOSIS AS A RATE",
      "text": "It is convenient to summarize the course of disease as a single number, or rate: the proportion of people experiencing an event. Rates commonly used for this purpose are shown in Table  6 .1. These rates have in common the same basic components of incidence, events arising in a cohort of patients over time.\n\nAll the components of the rate must be specified: zero time, the specific clinical characteristics of the patients, definition of outcome events, and length of follow-up. Follow-up must be long enough for all the events to occur; otherwise, the observed rate will understate the true one."
    },
    {
      "title": "A TRADE-OFF: SIMPLICITY VERSUS MORE INFORMATION",
      "text": "Expressing prognosis as a rate has the virhte of simplicity. Rates can be committed to memory and communicated succinctly. Their drawback is that relatively little information is conveyed, and large differences in prognosis can be hidden within similar summary rates. Figure  6 .3 shows 5-year survival for patients with four conditions. For each condition, about 10\u00b0;;, of the patients are alive at 5 years. But similar"
    },
    {
      "title": "Recurrence",
      "text": "Percent of patients surviving 5 years from some point in the course of their disease Percent of patients with a disease who die of it Number of people per 10,000 {or 100,0(0) population dying of a specific disease Percent 01 patients showing some evidence of improvement following an intervention Percent of patients entering a phase in which disCilSlo is no longer detectable Percerlt ot patients who have return of disease after a disease-free interval \"Timo undor obsorvation is oithor stated or assumed to be \\OufticiArltly 10\"9 so tllil! \"II ffi'Arlls lila! will OcCur havo beon obSDlVed, summary rates of approximately 10% survival obscure differences of considerable importance to patients. Early survival in patients with dissecting (Ineurysms is very poor, but if they survive the first few months, their risk of dying is not <Iffected by having had the aneurysm (Eg. 6.3A). On the other hand, HIV positive patients who develop AIDS die throughout the .i ymrs (Fig.  6 .38). Chronic granulocytic leukemi<l is a condition that has relatively little effect on survival during the first few ymrs after diagnosis (Fig.  6 .3C). Later, there is an acceleration in mortality rate until nearly all patients are dead 5 years after diagnosis. Pigure 6.30 is presented as a benchmark. Only at age 100 do people in the general population have a 5-year survival rate comp<lrab1c to that of patients with the three diseases."
    },
    {
      "title": "SURVIVAL ANALYSIS",
      "text": "When interpreting prognosis, we would like to know the likelihood, on the average, that patients with a given condition will experience an outcome at any point in time. When prognosis is expressed as a summary rate it does not contain this information. However. there are methods for presenting inform<ltion about average time to event for any point in the course of disease."
    },
    {
      "title": "SURVIVAL OF A COHORT",
      "text": "The most str<lightforward way to learn about survival is to assemble a cohort of patients with the condition of interest at some point in the course of their illness (e.g., onset of symptoms, diagnosis, or beginning of treatment) and keep them under observation until all could have experienced the outcome of interest. The plot of survival against time displays steps, corresponding: to the death of each of the 10 patients in the cohort. If the number of patients were increased (Fig.  6 .48), the size of the steps would diminish. If a very large number of patients were represented, the figure would approximate a smooth curve. This information could then be used to predict the year-byyear, or even wl'ek-by-week, prognosis of similar patients.\n\nUnfortunately, obtaining the information in this way is impractical for several reasons. Some of the patients would undoubtedly drop out of the study before the end of the follow-up pt'riod, perhaps because of another illness, a move to a place where follow-up was imIJractical, or dissatisfaction with the study. These patients would have to be excluded from the cohort, even though considerable effort may have been exerted to gather data on them up to the point at which they dropped out. Also, it would be necessary to wait until all of the cohort's members had reached each point in time before the probability of surviving to that point could be calculated. Because patients ordinarily become available for a study over a period of time, at any point in calendar time there would be a relatively long follow-up for patients who entered the study first, but only brief experience with those who entered recently. The last patient who entered the study would have to reach each year of follow-up before any information on survival to that year would be available."
    },
    {
      "title": "SURVIVAL CURVES",
      "text": "To make efficient use of all available data from each patient in the cohort, a way of estimating the wrvival of a cohort over time, called survival analysis, has been developed. (The usual method is called a Kaplan-Meir analysis, after the originators.) The purpose of survival analysis is not (as its name implies) only to describe whether patients live or die. Any outcome that is dichotomous and occurs only once during follow-upe.g., time to coronary event or to recurrence of cancer-can be described in this way. 'When an event other than survival is described, the term timcto-c'vcnt analysis is sometimes used. Figure  6 .5 shows a typical survival curve. On the vertical axis is the 2l l:\n\n' \"\n\n\u00f1.\n\no 415=80% 112=50% 100% III 100% 11 100% Probability of Surviving Interval: =CQ .c> ...-.c0 ::> ~(J) 0. \"0_ 100 \"'->-2 Time (Years) Figure 6.5. A typical survival curve, with detail for ona part of the curve,\n\nprobability of surviving, ;;md on the horizontal axis is the period of time following the beginning of observation. Often, the numbers of patients at risk at various points in time are shown to give some idea of the contribution of chance to the observed rates.\n\nThe probability of surviving to any point in time is estimated from the cumulative probability of surviving each of the time intervals that preceded it. Time intervals can be made as small as necessary; in Kaplan-Meir an<llyses, the intervals are between each new event (death) and the preceding one. Most of the time, no one dies, and the probability of surviving is 1. When one or more patients die, the probability of surviving is calculated as the ratio of the number of patients surviving to the number at risk of dying at that time. Patients who have already died, dropped out, or have not yet been followed-up to that point are not at risk of dying and so are not used to estimate survival for that time. When patients are lost from the study at any point in time, for any reason, they are cCllsorcd, i.e., they arc no longer counted in the denominator. The probability of surviving does not change during intervals in which no one dies; so in pradicc, the probability of surviving is recalculated only for times when there is a death. Although the probability assigned at any given interval is not very accurate, because of the small number of events involved, the overall prob\u00e3 bility of surviving up to each point in time (which is the product of all preceding probabilities) is remarkably accurate.\n\nA part of the survival curve in Figure  65  (from 3 to 5 years after zero time) is presented in detail to illustrate the data used to estimate survival: patients at risk, patients no longer at risk (censored), and patients experiencing outcome events at each point in time."
    },
    {
      "title": "INTERPRETING SURVIVAL CURVES",
      "text": "Several points must be kept in mind when interpreting survival curves. First, the vertical axis represents the estimated probability of surviving for members of a hypothetical cohort, not the percent surviving for an actual cohort.\n\nSecond, points on a survival curve are the best estimate, for a given set of data, of the probability of survival for members of a cohort. However, the precision of these estimates depends, as do all observations on samples, on the number of observations on which the estimate is based. One can be mOTe confident that the estimates on the left-hand side of the curve are sound, because more patients are at risk during this time. But at the tail of the curve, on the right, the number of patients on whom estimates of survival are based often becomes relatively small because deaths, dropouts, and late entrants to the study result in fewer and fewer patients being followed for that length of time. As a result, estimates of survival toward the end of the follow-up period are imprecise and can be strongly affected by what happens to relatively few patients. For example, in Figure  6 .5, thc probability of surviving is 8'1\" at 5 years. If at that point the one remaining patient happens to die, the probability of surviving would fall to zcro. Clearly, this would be a too literal reading of the data. Estimates of survival at the tails of survival curves must, therefore, be interpreted with caution.\n\nFinally, the shape of some survival curves, particularly those in which most patients experience the event of interest, gives the impression that the event occurs more frequently early on than later, when the slope reaches a plateau and it appears that the risk of outcome events is considerably less. But this impression is deceptive. As time passes, rates of survival are being applied to a diminishing number of people, causing the slope of the curve to flatten even when the rate of outcome events does not change.\n\nVariations on the basic survival curve are found in the medical literature (Fig.  6 .(,). Often the proportion with, rather than without, the outcome event is indicated on the vertical axis; the curve then sweeps upv,'ard and to the right. Other variations increase the amount of information presented with the curve. The number of patients at risk at various points in time\n\n40 '\" 35 .0_ ~, ,-30 \"<II --Severe o \" ~25 (~75% stenosis) 1ijW c: .!:! 20 \" E \" \" 1ij.r:: 15\n\nE \" :;::::;.!? 81 10 Normal 5 (:'030\"1., stenosis) 6 12 18 24 30 36 42 Time from Detection of Asymptomatic Neck Bruit (months) N{severe 94 80 68 52 42 28 21 7 Normal 242 236 211 169 158 69 56 1 Figure 6.6. Survival curve showing comparison of two cohorts, number of people at risk, and 95% confidence intervals for obs8TVed rates. These curves show the cumulative probability of a cerebral ischemic event from time of diagnosis, according to the initial degree of carotid stenosis. (Data from Chambers SR, Norris, JW. Outcome in patients with asymptomatic neck bruits. N Engl J Med 1986; 315:860-865.) can be included under the horizontal axis; the precision of estimates of survival, which declines with time because fewer and fewer patients are still under observation as time passes, can be identified by confidence intervals (see Chapter 9); and survival curves for patients with different characteristics (e.g., patients with different prognostic factors or treatments) can be compared in the same figure. Sometimes tics (not shown in Fig. 6.6) are added to the survival curves, to indicate each time a patient is censored. Survival curves mn be constructed for combinations of prognostic fac-tors. This can be done by stratifying patients according to the presence or absence of a set of prognostic factors, as shown eadier in this chapter. A statistical technique called the Cox proportional hazards regression model can be used to identify a combination of factors that best predicts prognosis in the group of patients under study or the efft'ct of individual factors independently (Chapter 9)."
    },
    {
      "title": "Bias in Cohort Studies",
      "text": "Potential for bias exists in any observation. Bias in cohort studieswhether to study risk or prognosis-can create apparent differences when they do not actually exist in nature or obscure differences when they really do exist.\n\nBias can be recognized more easily when one knows where it is most likely to occur in the course of a study. First, it is important to determine if bias could be present under the conditions of the study. Second, determine if bias is actually present in the particular study being considered. Third, decide if the consequences of bias are sufficiently large that they distort the conclusions in a clinically important way. If damage to the study's conclusions is not very great, then the presence of bias will not lead to misleading results. Some of the characteristic locations of bias in cohort research are illustrated in Figure  6 .7 and described below. being; compared are not equally susceptible to the outcome of interest, other than the factor under study.\n\nSusceptibility bias in prognosis studies may be due to one or more differences among cohorts, including the extent of disease, the presence of other diseases, the point of time in the course of disease, and prior treatment. The following illustrates how susceptibility bias was assessed in a study of the prognostic value of carcinoembryonic antigen results in patients with colorectal cancer.\n\nExample Increased levels of carcinoembryonic antigen (CEA), a tumorassociated fetal antigen, arc found in sevl;'ral types of tumors, induding colon,dal e<mcer. /\\. study was undertaken to determine if preoperative CEA levels predict relapse of disease after surgical resection with the intent to cure (4). CEA levels Wl;'re found to correlate with the extent of disease (frequently categori7.ed according to \"Dukes classification\": A, tumors confined to the bowd wall; H, tumors extending through the bowel wall but not to the lymph nodes; C, tumors involving regional lymph nodes; and 0, tumors having distant metastases). Mean CEA levels varied with extent of disease: 4 for Dukes A, 9 for B, 32 for C, and 251 for D. Both Dukes classification and CEA level strongly predicted disease relapse. But did the CEA level prt-dict independently of the Dukes classification or was susceptibility of relapse explained by Dukes classification alone? To answer this question, the association of preoperativl;' CFA levels to disease relapse was examined for patients in l;'ach Dukes classification. Figure  6 .8 shows that for Dukes B classification,"
    },
    {
      "title": "125",
      "text": "CEA levels independently predicted relapse. Similar results were fOWld for patients with Dukes C tumors. Therefore, the ass()ciation beh'l'ecn CEA levels and likelihood of relapse could not be explained by susceptibility bias for patients with Dukes Hand C colorectal cancers, and CEA is an important independent prognostic factor."
    },
    {
      "title": "SURVIVAL COHORTS",
      "text": "True cohort studies should be distinguished from studies of survival cohorts in which patients ,Jfe included in a study because they both have a disease and are currently available-perhaps because they are being seen in a specialized clinic. Another term for such groups of patients is available patient cohorts. Reports of survival cohorts arc misleading if they are presented as true cohorts. Tn a survival cohort, people are assembled at various times in the course of their disease, rather than at the beginning, as in a true cohort study. Their clinical course is then described by going back in time and seeing how they have fared up to the present (Fig.  6 .9).\n\nThe experiences of survival cohorts are sometimes presented as if they"
    },
    {
      "title": "True Cohort",
      "text": "Assemble Measure outcomes cohort Improved:\n\n75 weTe descriptions of the course of disease from its inception. However, they may represent a biased view, because they include only those patients who are available for study some time after their disease began. For lethal conditions, the patients in a survival cohort are the ones who are fortunate enough to have survived and so are available for observation years later.\n\nFor diseases that remit, the patients aTe the ones who are unfortunate enough to have persistent disease. In effect, survival cohorts describe the past history of prevalent cases and not what one would expect over the time following the onset of disease. Thus a survival cohort is a special case of assembly bias.\n\nReports of survival cohorts are relatively common in the medical literature, particularly in the form of \"case series\" (discussed in  Chapter 10) . Such reports can make an important contribution, primarily by describing early experiences with newly defined syndromes, but they Tepresent tentative, not conclusive, observations.\n\nExample Concern has been raised about the possibility that siliconl;' breast implants may cause autoimmunl;' symptoms of rhl;'umatic diseasl;'. A study was, therefore, done of 156 women with silicone breast implants ,md rheumatic disease complaints  (5) . The patients were consecutive referrals to three rheumatologists who were known for their interest in silicone implants and rheumatic disease. Serologic tests in the women were compared to those of women without implants but with fibromyalgia and to tests in women with implants but no rheumatic symptoms. The clinical findings in the women with implants and complaints were described; most did not fulfill criteria for rheumatoid arthritis and most had normal immunologic tests. However, l4 patients had scleroderma-like iJJness and abnormal serology that was not found in the comparison groups. Because of the possible biases that can occur in the assembly of patients for this ca~e series, the authors were cautious about their findings, concluding that \"the hypotheses raised in this study and others should be tested in large, population-based studies.\" Publication of the first such study does not support the hypothesis  (6) ."
    },
    {
      "title": "MIGRATION BIAS",
      "text": "Migration bias, another form of selection bias, can occur when patients in one group leave their original group, dropping out of the study altogether or moving to one of the other groups under study. If these changes take place on a sufficiently large scale, they can affect the validity of conclusions.\n\nIn nearly all shldies, some members of an original group drop out over time. If these dropouts occur randomly, such that the characteristics of lost subjects in one group are on the average similar to those lost from the other, then no bias would be introduced. This is so whether or not the number of dropouts is large or the number is similar in the groups. But ordinarily the characteristics of lost subjects arc not the same in various groups. The rC<lsons for dropping out-death, recovery, side effects of treatment, etc.-are often related to prognosis and may also affect one group more than another. As a result, groups in a cohort that were comparable at the outset may become less so as time passes.\n\nAs the proportion of people in the cohort who are nnt followed up increases, the potential for bias increases. It is not difficult to estimate how large this bias could be. All one needs is the number of people in thc cohort, the number not accOlUlted for, and the observed outcome rate.\n\nExample  Thompson et al.  described the long-term outcomes of gastrogastrostomy {7)./\\ cohort of 123 morbidly obese patients was studied 19-47 months after surgery. Success was defined as hilving lost more than 30% of excess weight.\n\nOnly 103 patients (84%) could be located. In these, the success rate of surgery was 60/lO3 (58\u00b01<\u00bb. To dett'rmine the range within which the true success rate must lie, the authors did a best case/worst case analysis. Success rates were calculated, assuming that all of the patients losl to fol1;wv-up were, on the one hand, successes (best case) and, on the other hand, failures (worst case). Of the total cohort of 123 patients, 103 were followed up and 20 were lost to follow-up. The observed success rate was 60/103, or 58%. In the best case, all 20 patit'nts lost to follow-up would be counted as successes, and the success rate would be (60 + 20)/123, or 65':0. In the worst case, all 20 patients would be counted as failures, and the success rate would be 60/123, or 49\"/0. Thus the true rate must have been bdween 49 and 65%; probably, it was doser to 58%, the observed rate, because patients not followed up are unlikely to be all successes or all failures.\n\nPatients may also cross over from nne group to another in the cohort during their follow-up. Whenever this occurs, the original reasOIls for patients being in one group or the other no longer apply. Tf exchange of patients between groups takes place on a large scale, it can diminish the observed difference in risk compared to what might have been observed if the original groups had rcmained intact. Migration bias due to crossover is more often a problem in risk than in prognosis studies, because risk shldies often go on for many years. On the other hand, migration from one group to another can be used in the analysis of a study."
    },
    {
      "title": "Example",
      "text": "The reliltionship between lifestyle and mortality was studied by classifying 10,269 Harvard College aluIrcIl.i by physical activity, smoking status, weight, and blood pressure in 1966 and again in 1977  (8) . Mortality rates were tht'll observed over a 9-year period from 1977 to 1985. It was recognized that original classificatiol{s might change, obscuring any relationship that might exist between lifestyle and mortality. To deal with this, the investigators defined four categories: men who maintained high-risk life-style~, those who changed from low-to high-ri~k lifestyles, those who changed from high-to low-risk life~tyles, and those who maintained 101'.'risk lifestyles. After adjusting for other risk factors, mt'n who increast'd their physical activity from low to moderate amount~, '-luit smoking, lost weight to normal levels, and/or became normoten~ive all had lower mortality than men who maintained or adopted high-risk characteristic~, but not as low as the rates for alumni who never had any risk factors_"
    },
    {
      "title": "MEASUREMENT BIAS",
      "text": "Measurement hias is possible if patients in one ,jroup stand a better chance of having their outcome detected than those in another group. Obviously, some outcomes, such as death, cardiovascular catastrophes, and major cancers, arc so obtrusive that they are tmlikely to be missed. But for less dear-cut outcomes-the specific cause of death, subclinical disease, side effects, or disability-measurement bias can occur because of differences in the methods with which the outcome is sought or classified.\n\nMeasurement bias can be minimized in three general ways. One can ensure that those who make the observations are unaware of the group to which each patient belongs, can set careful rules for deciding whether or not an outcome event has occurred (and follow the rules), and can apply efforts to discover events equally in all groups in the study.\n\nExample Chambers and Norris studied the outcome of patients with asymptomatic neck bruits  (9) . A total of 500 asymptomatic piltients with cervical bnJils were observed for up to 4 years. I'atients were classified according to the degrec of initial carotid artery stenosis by Doppler ultrasonography. OlJtcomes were change in degree of carotid s!t.'nosis and incidence of cerebral ischemk events.\n\nTo avoid biased measurements, the authors estimated carotid sh.'llosis using established, explicit criterid fur interprding Doppler scans ,md made the readings without knowledge of the ausclJltatory or previous Doppler findings. Clinical and Doppler assessments were repeated every 6 months, and all noncomplying patients were telephoned to determine whether outcomes had occurred.\n\nThis study showed, among other things, that patients with >75'1\" carotid stenosis had a >2IY:;, incidence of cerebral ischemic events in 3 years, more than 4 times the rate of patients with <30% stenosis (see Fig."
    },
    {
      "title": "Dealing with Selection Bias",
      "text": "Tn determine how a factor is related to prognosis, ideiJlly we would like to compare cohorts with and without the factor, everything else being equal. But in Teal life \"everything else\" is usually not equal in cohort studies.\n\nWhat can be done about this problem? There are several possible ways of controlling for differences during either designing or analyzing research (Table  6 .2).1 For any observational study, if one or more of these strategies have not been applied, the reader should be skeptical. The basic question is, \"Are the differences in prognosis in the groups related to the particular factor under study or to some other fador(s)?\" I Co\"I,,,1 h,,, ,,'v,'r~1 m,'~nings in r\"\"'arch: I,,) gcner\"I term ror any Im,,-,',\" -_. n..stridion. !notching, ~l,\" lifi-Glth\",. \"djll'lrHt'!lt-~im\"d ~l ,,'mo,'in,. the' efi,'cts of exl,\"neo\", vari,'ble' while ,,,,,milling the' ind,'pen d,'nl di,'cts 01 one variabk. (bJ lhe non'''I\"\"\"d p~\"rl\" in\" cohort ,tudy (0 conlusing use of H\", It\"\",), (<.' ! th .. npnt\"',lt,'{i p\"tic,~ts i~\" clinical tl'i<11. \"nd (.1.1 ,,,,ndi,,',,,,\u2022d I'~\"pl,' (non,\u2022\"\",,) ;n ,1 (~\",' conll'ol study (sec Chapter \"111)."
    },
    {
      "title": "RANDOMIZATION",
      "text": "The only way to equalize aU extraneous factors, or \"everything else,\" is to assign patients to groups randomly so that each patient has an equal chance of falling into the exposed or unexposed group. A special feature of randomization is that it not only equalizes factors we think might affect prognosis, it also equalizes factors we do not know about. Thus randomization goes a long way in protecting: us from incorrect conclusions about prognostic factors. However, it is usually not possible to srudy prognosis in this way. The special simations in which it i[; possible to allocate exposure randomly, usually to study the eff{c'Cts of treatment on prognosis, will be discussed in Chapter 7."
    },
    {
      "title": "RESTRICTION",
      "text": "Patients who are enrolled in a study can be restricted to only those possessing a narrow rilnge of characteristics, to equalize important extraneous factors. For example, the effect of age on progno[;js after acute myocardial infarction could be studied in white males with uncomplicated anterior myocardial infarctions. However, one should keep in mind that although restriction on entry to a study can certainly produce homogeneous groups of patients, it does so at the expense of generalizability. In the course of excluding potential subjects, cohorts may be selected that are unusual and not representative of most patients with the condition."
    },
    {
      "title": "MATCHING",
      "text": "Patients can be matched as they enter a study so that for each patient in one group there are one or more patients in the comparison group with the same characteristics except for the factor of interest. Often patiellts are matched for age and sex, because these factors are strongly related to the prognosis of many diseases. But matching for other factors may be called for as well, such as stage or severity of disease, rate of progression, and prior treatments. An example of matching in a cohort study of sicklccell trait was presented in the discussion of observational studies in Chapter 5.\n\nAlthough matching is commonly used and can be very useful, it controls for bias only for those factors involved in the match. Also, it is usually not possible to match for more than a few factors, because of practical difficulties in finding patients who meet a]] the matching criteria. Moreover, if categories for matching are relatively crude, there may be room for substantial differences behveen matched groups. For example, if a study of risk for Down's syndrome were conducted in which there was matching for maternal age within 10 years, there could be a nearly lO-fold difference in frequency related to age if most of the womell in one group were 30 and most in the other 39. Also, once one restricts or matches on a variable, its effects on outcomes can no longer be evaluated in the study."
    },
    {
      "title": "STRATIFICATION",
      "text": "After data are collected, they can be analyzed and results presented according to subgroups of patients, or stmta, of similar characteristics.\n\nExample Let us suppose we want to compare the operative mortality rates for coronary bypass surgery at hospitals A and B. Overall, hospital A noted 48 deaths in 1200 bypass opemtiom (4'\\,), and hospital B experienced 64 deaths in 2400 operations (2.6%,).\n\nThe crude rales suggest that hospital 13 is superior. Or do they? Perhaps patients in the two hospitals were not otherwise of comparable prognosis. On the basis of age, myocardial function, extent of occlusive diseast', ,md other characteristics, the patients can be divided into subgroups based on preoperative risk (Table  6 .3); tht'n the operative mortality rates within each category Of stratum of risk can be compared. Table  6 .3 shows that when patients arc divided by preoperative risk, the operative mortality rates in each risk stratum afe identical in two hospitals: 6';;', in high-risk patients, 4 u j\" in medium-risk patients, and 0.67~j, in lowrisk patienls. The obvious source of the misleading impression created by examining only the crude rates is the important differences in the risk characteristics of the patients treated at the two hospitals: 42% of hospital I\\'s patients ilnd only 17% of hospital B's patients were high risk.\n\nStratification is one of the most common and most revealing ways of examining for bias,"
    },
    {
      "title": "STANDARDIZATION",
      "text": "Two rates can be compared without bias if they are adjusted so as to equalize the weight given to another factor that could be related to outcome, This process, called standardization (or adjustment), shows what the overall rate would be if strata-specific rates were applied to a population made up of similar proportions of people in each stratum. Tn the previous example, the mortality rate of 6% for high-risk patients receives a weight of 500/1200 in hospital A and a much lower weight of 400/2400 in hospital B, and so on, such that the crude rate for hospital A = (500/1200 x 0.06) + (400/1200 x 0.04) + (300/1200 -0.0067) = 0.04 and the crude rate for hospital 13 equals (400/2400 x 0.06) + (800/2400 x 0.04) + (1200/2400 x O. 0067) = 0.026.\n\nIf equal weights are used, let us say 1/3 (but they could be based on one or the other hospital or any reference population), then the standardized rate for hospital A = (1/3 x 0,(  6 ) + (1/3 x 0.(  4 ) + (1 /3 x 0.0067) = 0.036, which is exactly the same as the standardized r<lte for hospital B. The consequence of giving equal weight to strata in each group is to remove totally the apparent excess risk of hospital A.\n\nThe difference between the crude operative mortality rates in the two hospitals fesults from the bias introduced by the differences in patients' preoperative risk. We are only interested in differences attributable to the hospitals and their surgeons, not to the patients per se. The difference in the crude mortality rates is confounded by the differences in patients, whereas standardized mortality rates equalize the weight of patients' preoperative risk in the two hospitals. Standardization is found much more commonly in studies of risk (in which rates <Ire frequently stand<lrdized for <lge, sex, <lnd/or race) than in studies of prugnosis. In contrast to stratification (which is often used in prognosis studies), standardization removes the effect of the extraneous factor. With stratification, the effect can still be examined, even if controlled for. Thus, with standardization, we found th<lt patients had similar prognoses in hospitals A and 13. With stratification, we also learned the mortality rates among patients in different risk strata."
    },
    {
      "title": "MULTIVARIABLE ADJUSTMENT",
      "text": "In most clinical situations, many factors act together to produce effects. The associations among these variables are complex. They may be rdated to each other as well as to the outcome of interest, the effect of one might be modified by the presence of others, and the joint effects of two or more might be greater th<ln the sum of their individual effects.\n\nMultivariable analysis is a method for simultaneously considering the effects of many variables (Chapter  (1) . It is used to adjust (control) simultaneously for the effects of many variables to determine the independent effects of one. Also, the method can select from a large set of variables a smaller subset that independently and significantly contributes to the over-<111 variation in outcome and can arrange variables in order of the strength of their contribution. Cox's proportional hazard analysis is a type of multivariable <lnalysis used when the outcome is the time to an event (as in survival analyses).\n\nMultivariable analysis is the only feasible way to deal with many variables at one time during the analysis phase of a study. (Randomization also controls for mulhple variables, but during the design and conduct phases of a study.) Simpler methods, such as str<ltification or matching, can only consider <I few vari<lbles at a time and then only by sacrificing statistical power."
    },
    {
      "title": "SENSITIVITY ANALYSIS",
      "text": "When data on important prognostic factors are not available, it is possible to e~timate the potential effects on the study by assuming various degrees of maldistribution of the factors between the groups being compared and seeing how that would affect the results. The general term for this process is sensitivity analysis. The be~t case/worst case <lnalysis, described earlier in this chapter, i~a ~pecial type of sensitivity analysis in which one compares results assuming the best and w()r~t possible maldistribution of a prognostic variable. 2  Assuming the worst is a particubrly stringcnt test of how a factor might afk'Ct the conclusions of <I study. A less conserv<ltive approach is to a~sume th<lt the factor is distributed between the groups in an unlikely way.\n\n) Sen~itivit}' ;ll1~Jysis can ,,1.,0 lx, used to assess the )Jol,\u2022nti,,1 l'ifects of in\"eeur\"de, in the dat\" o,~d in J~(\"i-,ion analysi, '1-' discussed in Ch,'pkr 4."
    },
    {
      "title": "CHAPTER 6 / PROGNOSIS 133",
      "text": "Example A ~tudy of treatment for mild diabete~found that patilmts given the ~ulfonylun=a tolbutamide experienced '1 greater risk of dying from cardiovascular disease than th(l~<' given insulin or diet ;;Ilone. The results were criticized because data on smoking-known to be ;;Is~ociJled with cardiovascular death-were not collected and not taken into account in the analysis. It was suggested that if cigarette ~mokeTS were unequally distributed among the groups, such that there were more smokers among those receiving tolbutamide than in the other groups, then the difference in death rates might be related to smoking, not tolbutamide. Howev<'r, Cornfield (IO) pointed out that even if cigarette smokers in the tolbutamide group exceeded those in the control group by 20%, a situation that w{mld have been extremely unlikely by chance (1/50,000), an increased risk in the tolbutamide group would have persisted. Thus bias in the distribution of smoker~was unlikely to have ,KcolUlted for the observed differences."
    },
    {
      "title": "OVERALL STRATEGY",
      "text": "Except for randomization, all ways of dealing with extraneous differences between groups have a limitation: They are effective against only those factors that are singled out for consideration. They do not deal with prognostic factors that are not known at the time of the study or are known but not taken into account.\n\nOrdinarily, one does not rely on only one or another method of controlling for bias; one uses several methods together, layered one on another. Thus in a study of whether the presence of ventricular premature contractions decreases survival in the years following acute myocardial infarction, one might (a) restrict the study to pi;ltients who arc not very old or young and do not have unusual causes (e.g., mycotic aneurysm) for their infarction; (b) match for age, a factor strongly related to prognosis but extraneous to the main question; (c) examine the resull\" sepilriltely for strata of differing clinical severity (e.g., the presence or absence of congestive heart failure or other diseases, such as chronic obstructive pulmonary disease); and (d) using multivariable analysis, adjust the crude results for the effects of all the variables other than the arrhythmia, taken together, that might be rdated to prognosis."
    },
    {
      "title": "Generalizability and Sampling Bias",
      "text": "Published accounts of disease prognosis that are based on experience in special centers can paint a misleading picture of prognosis in less selected patients. This is so even if a study is well done, biases arc carefully controlled for, and the reported prognosis for a medical condition is correct for the particular sample of patients. Because of the sample of patients used, it may be that the study findings are not generalizable to most other patients with the condition, or to your patient.\n\nSometimes, patients in randomized controlled trials who are assigned to the control group are srudied to better determine the usual clinical course of a disease. But such patients may not be representative of most patients because volunteers for studies tend to do better than patients who do not volunteer. For example, in a large Cam.dian study of breast cancer screening among women in their 40s, 90'1\" of women who were in the control group and had invasive breast cancer were alive 7 years later, and the number of deaths from breast cancer were lower than for Canadian women generally  (11) ."
    },
    {
      "title": "Summary",
      "text": "Prognosis is a description of the course of disease from its onset. Compared to risk, prognostic events arc relatively frequent and often can be estimated by personal clinical experience. However, cases of disease ordinarily seen in medical centers and reported in the medical literature are often biased samples of all cases and tend to overestimate severity.\n\nPrognosis is best described by the probability of having experienced an outcome event at any time in the course of disease. Tn principle, this can be done by observing a cohort of patients until all who will experience the outcome of interest have done so. However, because this approach is inefficient, another method-called survival, or time-to-event analysisis often used. TIle onset of events over time is estimated by accumulating the rates for a]] patients at risk during the preceding time intervals.\n\nAs for any observations on cohorts, studies comparing prognosis in different groups of patients can be biased if differences arise because of the way cohorts arc assembled, if patients do not remain in their initial groups, and if outcome events arc not assessed equally. A variety of strategies arc available to deal with such differences as might arise, so as to allow fair (unbiased) comparisons. These include restriction, matching, stratification, standardization, multivariable analysis, and sensitivity analysis. One or more of these strategies should be found whenever comparisons are made."
    },
    {
      "title": "TREATMENT",
      "text": "Once the nature of a patient's illm.'bS has been established and its expected course predicted, the next question is, 'What can be done about it? Is there a treatment that improves the outcome of disease? This chilptcr describes the evidence used to decide whether a well-intentioned treatmcnt is effective."
    },
    {
      "title": "Ideas and Evidence",
      "text": "The discovery of new treatments requires both rich sources of promising possibilities and ways of establishing th8t the treatments aTe in fact usefuL IDEAS Tdeas (hypotheses) about what might be useful treatment arise from virtually any activity within medicine. Some therapeutic hypotheses are suggested by the mechanisms of disease at the cellular or molecular leveL Drugs against antibiotic resistant bacteria are developed through knowledge of the mechanism of resistance. Hormone analogues are based on the structure of native hormones. The effectiveness of afterload reduction in congestive heart failure was suggested by studies of the importance of afterload in the pathophysiology of heart failure.\n\nOther hypotheses about treatments have come from astute observations by clinicians. Two examples are the discovery that patients with Parkinson's disease who arc given amantadine to prevent influenza show improvement in their neurologic status and the reports that colchicine, given for gout, reduces the frequency of attacks of familial Mediterranean fever. The value of these treatments was not predicted by an understanding of the mechanism of these diseases, and the ways in which these drugs work arc not yet understood. Similarly, folk remedies from throughout the world, bolstered by centuries of experience but few scientific studies, are potentially useful treatments.\n\nOther ideas come from trial and error. Snme anticancer drugs have been found by methodically screening huge numbers of substances for activity.\n\nIdeas about treatment, but more often prevention, also come from epidemiologic studies of populations. Burkitt observed that colonic diseases are less frequent in African countries, where diet is high in fiber, than in developed countries, where intake of dietary fiber is low. This observation has led to efforts to prevent bowel diseases-irriL<Jble bowel syndrome, diverticulitis, appendicitis, and colorectal cancer-with high-fiber diets. Comparisons across countries have also suggested the value of red WlOe to prevent heart disease and fluoride to prevent dental caries."
    },
    {
      "title": "TESTING IDEAS",
      "text": "Some treatment effects are so prompt and powerful that their value is self-evident even without formal testing. Clinicians do not have resef\"l,'a-Hons about the value of penicillin for pneumonia, surgery for appendicitis, or colchicine for gout. CliniC<J1 experience has been sufficient.\n\nUsually, however, the effects of treatment are considerably less dramatic. Tt is then necessary to put ideas about treatments to a formal test, through clinical research, because a variety of conditions-coincidence, faulty comparisons, spontaneous changes in the course of disease, wishful thinking-can obscure the true relationship between treatment and effect. Sometimes knowledge of mechanisms of disease, based on work with laboratory modeli:i or phyi:iio[ogic studies in humans, has become so extensive that it is tempting to predict effects in humans without formal testing. However, relying solely on our current understanding of mechanisms, without testing ideas on intact humans, can lead to unpleasant surprises because the mechanisms are only partly understood.\n\n[xam\"le Many strokes are caused by cerebrill infarction in the area distal to an obstructed segment of the internal carotid artery. It should be possible to prt;>vt;>nt the manifestatiuns of disease in people with these lesions by bypassing the diseilsed segment so that blood can flow to the thrC'iltened area normillly. It is tedmimlly feasible to anastilmose the superficial temporal artery to the internal carotid diswJ to an obstruction. Because its value seemed self-evident on physiologic grounds and because of the documented success of an analogous proct;>dure, coronary artt;>ry bypass, tht;> surgery became widely used.\n\nThe EC/IC Bypass Study Croup Cl) conduded a randomized controlled trial of temporal artery bypass surgery. Patients with cerebral ischemia anJ an obstructed internal carotid ilrtery were randomly illlocated to surgical versus medical treiltment. The operation was a teclmical success; 96\u00b0;', of anastomoses were patent just after surgery_ Yel, the surgery did not help the patil.'llts. Mortality and stroke rates after 5 years were nearly identical in the surgically and medically treated patients, but deaths occurred earlier in the surgically treated patients.\n\nThis study illustriltes hmv treatments that make good sense, based on whilt we know ilbout the mechilnisms of disease, may be found ineffective in human terms when put to a rigorous test. Of course, it is not always the case that ideas arc debunked; the value of carotid l.'lldarterectomy, suggestt>d on similar grounds, has been confirmed  (2) . Therefore, it is almost always necessary to test therapeutic hypotheses by means of clinical research, in which datiJ are collected on the clinical course of treated and untreated patients. As one author (3) put it, treatments should be given \"not because they ought to work, but because they do work.\""
    },
    {
      "title": "Studies of Treatment Effects",
      "text": "Treatment is usually considered to be what physicians prescribe for patients with established disease: surgery, drugs, diet and exercise. But there are a great many other ways of intervening to improve health. Among these are efforts to prevent disease in individual patients (counseling and early detection with treatment, discussed in Chapter 8), intervention on communities and changes in the organization and financing of heiJlth care. Regardless of the nature of iJ well-intentioned intervention, the principles by which it is judged superior to its alternatives are the same.\n\nThere are tv.'o general ways to establish the effects of treatment: observational and experimental shtdies. They differ in their scientific strength and feasibility.\n\nObservational studies of treatment are a special case of studies of prognosis in general, where the prognostic factor of interest is a therapeutic intervention. What has been said about cohort studies (Chapters 5 and 6) applies to observational studies of treatment as well. The main advantage of these studies is that they are feasible. The main drawback is the likelihood that there are systematic differences in treatment groups other than the treatment itself, which lead to misleading conclusions about the effects of treatment.\n\nClinical trials arc a special kind of cohort study in which the conditions of study-selection of treatment groups, nature of interventions, miJnagement during follow-up, and measurement of outcomes-are specified by the investigator for the purpose of making unbiased comparisons. Clinical trials arc more highly controlled and managed than arc cohort shJdies. The investigators iJre conducting an experiment, analogous to those done in the laboratory. They have taken it upon themselves (with their patients' permission) to isolate for study the unique conhibution of one factor by holding constant, as much as possible, all other determinants of the outcome. Hence, other names for clinical trials are experimental and intervention studies.\n\nRandomized controlled trials are the standard of excellence for scientific studies of the effects of treatment. We will consider them in detail first, then consider alternative ways of answering the same question."
    },
    {
      "title": "Randomized Controlled Trials",
      "text": "The structure of a clinical trial is shown in Figure  7 .1. The patients to be studied arc first selected from a larger number of patients with the condition of interest. They are then divided, using randomization, into two Outcomes ,liiipr{>,,\" I l ~. IlOO1 I\"\"\" lITIpr<l\"\"\"~,"
    },
    {
      "title": "Experimental intervention",
      "text": "f'liflpriMill:.TI -Compariso';--c;~vOOl"
    },
    {
      "title": "Intervention",
      "text": ". , groups of comparable prognosis. One group, called the experimental or treated group, is exposed to an intervention that is believed to be helpfuL The other group, called a control or comparison group, is treated the same in all ways except that its members are not exposed to the intervention.\n\nThe clinical course of both groups is then observed and any differences in outcome are attributed to the intervention.\n\nThe main rcason for structuring clinical trials in this way is to avoid bias (systematic error) when comparing the respective value of the two or more kinds of treatments. The validity of clinical trials depends on how well they result in an equal distribution of all determinants of prognosis, other than the one being tested, in treated and control patients.\n\nIn the following discussion, we will describe the design and interpretation of clinical trials in detail, with reference to Figurc 7.2."
    },
    {
      "title": "SAMPLING",
      "text": "The kinds of patients that are included in a trial determine the extent to which conclusions can be gem'ralized to other patients. Of the many reasons why patients with the condition of interest may not be part of a trial, three account for most of the losses: They do not meet specific entry criteria, they rduse to participate, or they do not cooperate with the conduct of the trial.\n\nThe first, entry criteria, is intended to restrict the heterogeneity of patients in the trial. Common exclusion criteria are atypical disease, the presence of other diseases, an unusually poor prognosis (which may C<luse patients to drop out of the assigned treatment group), and evidence of unreliability. Patients with contra indications to one of the treatments arc also excluded, for obvious reasons. As heterogeneity is restricted in this way, the internal validity of the study is improved; there is less opportuni ty for differences in outcome that are not related to treatment itself. Also, generalizing the results is more precise because one knows exactly to whom"
    },
    {
      "title": "Generalizing",
      "text": ". the results apply. But exclusions come at the price of diminished scope of generalizability, because characteristics that exclude patients occur commonly among those ordinarily seen in clinical practice, limiting generalizability to these patients, the very ones for whom the information is needed. Second, patients can refuse to participate in a trial. They may not want a particular type of treatment or to have their medical care decided by a flip of a coin or by someone other than their own physician. Patients who refuse to participate are usually systematically different-in socioeconomic class, severity of disease, other health-related problems, and other waysfrom those who agree to enter the trial."
    },
    {
      "title": "Statistical analysis",
      "text": "Third, patients who are found to be unreliable during the early stages of the trial are excluded. This avoids wasted effort and the reduction in internal validity that would occur if patients moved in and out of treatment groups or out of the trial altogether.\n\nfor these reasons, patients in clinical trials are usually a highly selected, biased sample of all patients with the condition of interest (Fig.  7 .3). Because of the high degree of selection in trials, it often requires considerable faith to generalize the results of clinical trials to ordinary practice settings."
    },
    {
      "title": "INTERVENTION",
      "text": "The intervention itself can be described in relation to three general characteristics: generalizability, complexity, ilnd strength.\n\nFirst, Is the intervention in question one that is likely to be implemented"
    },
    {
      "title": "Percent of Patients",
      "text": ".IiIIIiIiIiIiIi 100 '1JI1J11J11J11J11J11J11PlIJln'"
    },
    {
      "title": "Population Sampled",
      "text": "Patients with noninsulindependent diabetes mellitus in one hospital"
    },
    {
      "title": "Inclusion Criteria",
      "text": "Age >40 years Diabetes diagnosed after 30 years old Require medication for hyperglycemia Plan to remain in practice >2 years Other illness, disability, etc. 24 13 12 Eligible Uncooperative Refused to participate Did not keep appointments Randomized Dropped Out Death Change of residence Illness, etc. Completed Study Figure 7.3. Sampling for a clinical trial. A study of the effectiveness of a program to reduce lower extremity problems in patients with diabetes, (Data from Litzelman OK, Slemenda CW, Langfeld CD, Hays LM, Welch MA, Bild DE, rord ES, Vinicor F, Reduction in lower extremity clinical abnormalities in patients with non-insulin dependent diabetes mellitus, A randomized controlled trial, Ann Intern Med 1993; 11 9: 36-41.)\n\nin usual clinical practice? In an effort to standardize therapy so it can be easily described and reproduced in other setting:\" some investigators end up srudying treatments that are so unlike those in usual practice that the results of the trial are not usefu L Second, single, highly specific interventions make for tidy science, because they can be described precisely and applied in a reproducible way. However, clinicians regularly make choices among alternative treatments that involvc many elements. Multifaceted intcrventions arc amenable to careful evaluation as long as their cssence can be communicated and reproduced in other settings.\n\nExample Falls are a major problem in the elderly, have a variety of musICS, and tend to recuT. Rubenstdn et al. (  4 ) studied the effects of a program to prevent falls in the elderly. Elderly people in a long-term residential care facility were randomized after a fall to a special progrilm or to usual care. The program included a detailed examination, laboratory tests, and envirunmental assessment; therapeutic recommendations were given to the patient's primary physician. Over the next 2 years, the intervention group had fewer falls, 26% fewer hospitalizations, and a 52% reduction in hospital days comp ared with controls.\n\nThird, Is the intervention in question sufficiently different from alternative managements that it is reasonable to expect that outcome will be affected? Some diseases can be reversed by treating a single, dominant cause, e.g., treating hyperthyroidism with radioisotope ablation or surgery. But most diseases arise from a combination of factors acting in concert.\n\nInterventions that change only one of them, and only a small amount, cannot be expected to show strong treatment effects. If the conclusion of a trial evaluating such interventions is that a new treatment is not effective, it should come as no surprise."
    },
    {
      "title": "COMPARISON GROUPS",
      "text": "The value of a treatment can only be judged by comparing the results of the treatment to those of some alternative course of action. rhe question is not whether a point of comparison is used, but how appropriate it is. Results among patients receiving an experimental treatment can be measured against one or morc of several kinds of comparison groups."
    },
    {
      "title": "No Intervention",
      "text": "Do patients receiving the cxperimental treatment end up better than those receiving nothing at all? Comparing treatment with no treatment measures the total effects of health care, both specific and nonspecific."
    },
    {
      "title": "Observation",
      "text": "Do treated patients do better than other patients who are simply observed? A great deal of special attention is directed toward patients 111 clinical trials, and they are well aware of it. People have a tendency to change their behavior because they are the target of special interest and attention in a shtdy, regardless of the specific nature of the intervention they might be receiving, a phenomenon called the Hawthorne effect. The reasons for this changed behavior are not clear. Patients are anxious to please their doctors and make them feel successful. Also, patients who volunteer for trials want to do their part to see that \"good\" results are obtained. Thus comparison of treatment with simple observation measures treatment effect over and above the Hawthorne effect."
    },
    {
      "title": "Placebo Treatment",
      "text": "Do treated patients do better than similar patients given a placebo, an intervention that is intended to be indistinguishable from the active treat-ment~in physical appearance, color, taste, and smell~but does not have a specific, known mechanism of action? Sugar pills and saline injections are examples of placebos. It has been shown that placebos, given with conviction, relieve severe, W1pleasant symptoms, such as postoperative pain, nausea, or itching, of about one-third of patients, a phenomenon called the placebo effect.\n\nExample Patients with chronic severe itching were entered in a trial of antipruritic drugs. During each of ::; weeks, 46 patients received in random order either cyproheptadine Hel, trimeprazine tartrate, or placebo. There was a I-week rest period, randomly introduced into the sequence, in which no pills were given. Results were assessed without knowledge of medication and expressed as \"itching scores\"; the higher the score, the worse the itching. Itching scores for the various treatments were cypmheptadine Hel, 28; trime-pra7ine tartrate, 35; placebo, 30; and no treatment, 50. The two active drugs and placebo were all similarly effective and all gave much better results than no treatment  (5) .\n\nPlacebo effects have different meaning for researchers and clinicians. Researchers are more likely to be interested in establishing specific effects-ones that are consistent with current theories about the causes of disease. They consider the placebo effect the baseline against which to measure specific effects. Clinicians, on the other hand, should welcome the placebo effect and attempt to maximize it or any other way of helping patients.\n\nMany clinical interventions have both specific and nonspecific effects (Fig.  7.4) . What is important to clinicians and their patients is the total effect of the intervention beyond what would have otherwise occurred in the course of disease without treatment. However, it is also useful to know what part of the total effect is specific and whiJt is nonspecific so as to avoid dangerous, uncomfo:table, or costly interventions when relatively little of their effect can be attributed to their specific actions. Effects i Specific treatment -I:"
    },
    {
      "title": "Action"
    },
    {
      "title": "Mostly specific"
    },
    {
      "title": "Examples",
      "text": ". ."
    },
    {
      "title": "Usual Treatment",
      "text": "Do patients given the experimental treatment do better than those receiving usual treahnent? This is the only meaningful (and ethical) question if the usual treatment is already known to be efficacious.\n\nThe cumulative effects of these various reasons for improvement in treated patients are diagrammed in Figure  7 .5."
    },
    {
      "title": "ALLOCATING TREATMENT",
      "text": "To study the effects of a clinical intervention free of other effects, the best way to allocate patients to treatment groups is by means of randomiwtion. Patients are given either the experimental or the control treatment by one of a variety of disciplined procedures-analogous to flipping a coinwhereby each patient has an equal (or at least known) chance of being assigned to anyone of the treatment groups.\n\nRandom allocation of patients is preferable to other methods of allocation, because randomization assigns patients to groups without bias. That is, patients in one group are, on the average, as likely to possess a given characteristic as patients in another. Only with randomization is this so for all factors related to prognosis, whether or not they are known before the srudy takes place.\n\nIn the long run, with a large number of patients in the trial, randomization usually works as described. above. However, random allocation does not guarantee that the groups will be similar. Although the process of random allocation is lUlbiased, the results may not be. Dissimilarities between groups can arise by chance alone, particularly when the number of patients randomized is small. To assess whether this kind of \"bad luck\" has occurred, authors of randomized controlled trials often present a table comparing the frequency of a variety of characteristics in the treated and control groups, espl.-\"CiaJly those known to be related to outcome. Tt is reassuring to see that important cha.racteristics have, in fact, fallen out nearly equally in the groups being compared. If they have not, it is possible to see what the differences are and attempt to control them in the analysis (see  Chapter 6) .\n\nSome investigators believe it is best to make sure, before randomization, that at least some of the characteristics known to be strongly associated with outcome appear equally in treated and control groups, to reduce the risk of bad luck. They suggest that patients first be gathered into groups (strata) of similar prognosis and then randomized separately within each stratum-a process called stratified randomizatioll. The groups arc then bound to be comparable, at least for the characteristics that were used to create the strata. Others argue that whatever differences arise by bad luck arc unlikely to be large and can be dealt with mathematically after the data are collected."
    },
    {
      "title": "DIFFERENCES ARISING AFTER RANDOMIZATION",
      "text": "Not all patients in a clinical trial participate as originally planned. Some are found not to have the disease they were thought to have when they entered the trial. Others drop out, do not take their medications, are taken out of the study because of side effects or other illnesses, or somehow obtain the other study treatment or treatments that are not part of the study at all. The result is comparison of treatment groups that might have been comparable just after randomization but have become less so by the time outcomes are counted."
    },
    {
      "title": "Patients Do Not Have the Disease",
      "text": "Tt may be necessary to decide which treatment to give (in a clinical trial or in practice) before it is certain the patient actually has the disease for which the trmtment is designed.\n\nExample To study whether a monoclonal antibody against endotoxin improve:; survival from sepsis, 543 patient~with sepsis and suspected Gramnegative infection were nmdomizcd to receive antiendotoxin or placebo  (6) . In the subgroup of patients who actually had Gram-negative bacteremia, death ratt' was reduced from 49 to 3ln:\" a large differem:e that was well beyond what could be accmmted for by dtance, lIowever, only 200 patients (37'1<,) had Gram\u00f1 egative bacteremia, confirmed by blood culture. There is no known reason why the other 63% would be helped by the drug. For all patients with sepsis (soml' of whom had bacteremia and others did not) mortality rate was 43)}~in the placebo group and 39'% in the group receiving antiendotoxin, a small difference that was not beyond that expected by chance alone. Thus, from this trial, there was evidence that the drug was effective against Cram-negative bacteremia, but not for sepsis. Hoth are important questions: the former for reSl'archers, who are interested in the biologic effed of antiendotoxin in bacteremia, and the latter for clinicians, who needed to know the clinical effects of their decision to give the drug to patients with sepsis--\u2022a decision that musl be made before it is known whether or not bacteremia is actually present.\n\nWhen patients suspected of having the specific disease in question later turn out not to have it, there is a price to pay. Studying additional patients who could not benefit from the specific action of the treatment decreases the efficiency of the trial; mOTe patients must be studied to see the effect. Looked at another way, because patients experiencing the speeific effect are mixed with others who cannot, the effect size is reduced relative to a trial including only patients with the disease. This decreases the chances, for a given number of patients in the trial, that an effect will be found (see  Chapter 9) . However, this kind of trial has the important advantage of providing information on the consequences of a decision as the clinician encounters it (see \"Management and Explanatory Trials,\" later in this chapter)."
    },
    {
      "title": "Compliance",
      "text": "Compliance is the extent to which patients follow medical advice. Some prder the term adherence, because it connotes a less subservient relationship beh\\'een patient and doctor. Compliance is another characteristic of patients that can arise after randomization. Although noncompliance suggests a kind of willful neglect of good advice, in medicine other factors also contribute. Patients may misunderstand which drugs and doses are intended, run out of prescription medications, confuse various preparations of the same drug, or have no money or insunnce to pay for drugs. Taken together, these may limit the usefulness of treatments that have been shown to work under specially favorable conditions.\n\nCompliance is particularly important in medical care outside the hospita 1. In the hospital, many factors act to constrain patients' personal behavior and render them compliant. Hospitalized patients are generally sicker and more frightened. They arc in strange surroundings, dependent on the skill and attention of the staff for everything-even their life. What is more, doctors, nurses, and pharmacists have developed a well-organized system for ensuring that patients receive what is ordered for them. As a result, clinical experience and a medical Iiterahtre developed on the wards may underestimate the importance of compliance outside the hospital, where most patients and doctors are and where doing what clinicians advise is more difficult.\n\nComparing responses among compliant and noncompliant patients in a randomized trial can be misleading.\n\nExample During a large study of the effects oi several lipid-lowering drugs on coronary hearl disease, 1103 men werc given clofibrate and 2789 mt'n Wt'yt' g-iven placebo. The 5-year mortality rate was 20.()')';, for the clofibrate group and 20.9'>;) for the placebo group, indicating that the drug \\Vas not effective.\n\nIt was recugnized that not all patients took their medications. Was clofibrate effective among patit'nts who actually took the drug? The answer appeared to be yes. Among patients given cloiibrate, 5-year mortality for patients taking most oi their prescribed dnl';; was 15.0%, compared with 24.m;, for the less cooperativt' patients (p < 10 '), Howt'ver, taking the prescribed drug was also related to lower mortality rates among patients prescribed placebo. For them, 5-year mortality was 15.1% ior patients taking most of their placebo medication and 28.3 ior patients who did not (I' < 10-15 ). Thus there was an ilssociation bdwe{'n dnJg taking and prognosis thilt was not related to tht' active drug itself.\n\nThe authors (  7 ) cautioned against evaluating treatment effects in subgroups determined by patient responscs to the treatment protocol after randomization."
    },
    {
      "title": "Cointerventions",
      "text": "After randomization, patients may receive a variety of interventions other than the ones being studied. If these occur unequally in the two groups and affect outcomes, they can introduce systematic differences (bias) between the groups compared."
    },
    {
      "title": "Example",
      "text": "The care of AIDS is emotional, in part because it affects young adults and is universally fatal within a few years of the onset of symptoms.\n\n['Horts to study the effectiveness of trcatmt'nt hilve been hinden'd by disruption of the usual procl;'dures of randomiz.ed trials, as patients try to maximize their chances of survival. Patients in randomized trials sometimes exchange the drugs being studied in the trial (researchers call the exchang(' of trCiltment regimens among study participants \"contamination\") or obtain drugs that are not part of the trial through\"drug clubs.\" Information about this behavior is usuallv not shared with the reseClrchers and so cannot be accounted for in the study_ The result is to bias the study toward observing no effect, since the contrast between the (reatment of the \"treated\" group and the comparison group is diminished."
    },
    {
      "title": "Comparing Responders with Nonresponders",
      "text": "In some c1inicill trials, particularly those ilbout cancer, the outcomes of piltients who initially improve after treatment (responders) ilT(' compared with outcomes in those who do not (nonresponders). The implication is that one Gill learn something ilbout the efficacy of treatment in this way.\n\nThis approach is scientifically unsound and often misleading:, because response and non response might be associated with milny characteristics related to the ultimate outcome: stage of disease, rate of progression, comp Uance, dose ilnd side effects of drugs, and the presence of other diseases. If no patient actually improved because of the treatment, and patients were destined to follow various clinical courses for other reasons, then some (the ones who happened to be doing well) would be called \"responders\" and others (the ones having a bad course) would be considered \"nonresponders.\" Responders 'Nould, of course, have a better outcome whether or not they received the experimental treatment."
    },
    {
      "title": "BLINDING",
      "text": "Participants in a trial may change their behavior in a systematic way (i.e., be biased) if they are aware of which patients receive which treatment. One way to minimize this effect is by blillding, an attempt to make the various participants in a study unaware of which treatment patients have been offered, so that the knovvledge does not cause them to act differently, thereby damaging: the internal validity of the study. \"Masking\" is a mOTe appropriate metaphor, but blinding is the time-honored term.\n\nBlinding can take place at four levels in a clinical trial. First, those responsible for allocating patients to treatment groups should not know which treatment will be assigned next so that the knowledge does not affect their willingness to enter patients in the trial or take them in the order they arrived. Second, patients should be unaware of which treatment they are takingi they arc thereby less likely to change their compliance or their reporting of symptoms because of this information. Third, physicians who take care of patients in the study should not know which treatment each patient has been given; then they will not, perhaps unconsciously, manage them differently. Finally, if the researchers who assess outcomes cannot distinguish treatment groups, that knowledge cannot affect their measurements.\n\nThe terms sil1xldllind (p(ltients) and dOl/ble-Mind (patients and research-ers) are sometimes used, but their meaning is ambiguous. Tt is better simply to describe what was done. A trial in which there is no attempt at blinding is called opcn or opcn label.\n\nWhen blinding is possible, mainly for studies of drug effects, it is usually accomplished by means of a placebo. Howevef, fOf many important clinical questions-the effects of surgery, radiotherapy, diet, or the organization of medical care-blinding of patients and m<lnaging physicians is not possible.\n\nEven when blinding appears to be possible, it is more often claimed than successful. Physiologic effects, such as lowered pulse rate with betablocking drugs, or bone marrow depression with canccr chemotherapy, are regular features of some medications. Symptoms may also be a clue."
    },
    {
      "title": "Example",
      "text": "In the Lipids Research Clinics (B) trial of the prim<lry prevention of cardiovascular disease, a nearly perfect placebo was llsed. Soml\" Pl.'Opie received cholestyramine <lnd others a powder of the same appearance, odor, and taste. However, side effects were substantially more common in the cholcstyramine group. At the end of theIst year of the trial, there were much higher rates in the experimental (cholestyramine) group th<ln the control group for constipation (39 versus 10%), heartburn (27 versus 1m:.), bdching and bloating (27 versus 16%), and nausea (16 versus 8'1.,). Patients might have been prompted by new symptoms to guess which treatment they \\vere getting.\n\nTIlere is also objective evidence that patients and physicians in some blinded trials can guess who received what treatment.\n\nExample A double-blind, randomized trial was conducted tu ~ee if propranolol could prevent another myocardial infarction in patients who hild already had one  (9) . At the conclusion of the trial, but before unblinding, patients and clinic personnel were asked to guess the treatment group assignment of each patient. For patients, 79.9% guessed propranolol correctly and ';7.2% placeho correctly. Physicians and clinic personnel were similarly accurate. Clinical personnel seemed to he aided in their guessing by observation of heart rate; it was unclear how patients knew."
    },
    {
      "title": "ASSESSMENT OF OUTCOMES",
      "text": "When the outcome of a trial is measured in unequivocal terms, such as being alive or dead, it is unlikely that patients will be misdassified. On the other h<lnd, when outcomes are decided by the opinion of one of the participants, there is much greater opportunity for bias. For example, although the fact of death is usually dear, the cause of death is often not. Most people die for a combination of reasons or for obscure reasons, allowing some room for judgment in assigning cause of death. This judgment can be influenced by knmvlcdge of Wh,lt went before, including the treatments that were given. Opportunities for bias are even greater when assessing symptoms such as pain, nause<!, or depression. Bias in assessing outcomes is avoided by searching for outcome events equally in all patients, using explicit criteria for when an outcome has occurred, and by blinding.\n\nShort-term, easily measurable \"outcomes\" may be substituted for clinical ones so as to speed the rate at which trials can be completed and reported. For example, it has been common in clinical trials of treatment of HIV infection to take as the main outcome measures biologic tests that reflect the extent of infection (such as ClJ4+ counts and p32 antigen) rather than clinical progression of disease (opportunistic infections and death). However, it has been shown that CD4+ counts are an imperfect marker of clinical treahnent effect. As discllssed in Chapter 1, the practice of substituting biologic outcomes for clinical ones in studies thilt Me to guide patient care is defensible only if the proxy is known to be itself strongly relilted to the clinical outcome.\n\nThere are several options for summarizing the relative effects of two treatments Cfable 7.1). It has been suggested that the most clinically relevant expression is number needed to treat, the number of patients that must be treated to prevent one outcome event  (10) . Number needed to treat is the reciprocal of ilbsolute risk reduction.\n\nPerception of the size of a treatment effect, both by patients and clinicians, is influenced by hO'w the effect is reported. In general, effects reported as relative risks seem larger than the same effects described as attributable risks, which in turn seem larger than reports of the number needed to treat  (11, 12) . Also, patients told their probability of survivill believe they have a better chance than those told the complement, their probability of dying  (13) . Thus, to understand and communicate treiltment effects, it is necessary to examine the main results of a trial in several ways. It is moot which is the \"correct\" statistic.\n\nTable 7.1 Summarizing Treatment Effects\" Summary Moasure\" Hel,llive risk reduction Absolute risk reduction Number needed to treat DHfi\"itiOrl Control evcnt rllte-Treated event rate Control event rate Control event rale -Treated evertt rdte 1 \" \" \"~c-'-~~\u00d5 Jiltrol event rdte I rcatcd event rate 'Loupacls A Sackelt DL llolJHrfs RS. An H~,*,~SrTlf1flt of clinically useful measures of the consequences of treatment. New Engl J Med t988;3 t8 t 728 t 733 I, ,or continuous data, when there are measurements at tXlseline and alter treotnlOnt, analogous rlIeilsurH\u00e3 re basHd Oil thH \"'Ha\" values for treated and control \"fOUp\" either aftof 1reatnx'nt or for the differenco between baseline and posttreatment \"llluo,;\n\nThe results of a randomized controlled trial can oe analyzed and presented in two ways: according to the treatment to which the patients were randomized or to the one they actually received. The correct presentation of results depends on the question being <lske'!.\n\nIf the question is which treahnent policy is best ilt the time the decision must be milde, then illlillysis according to the <Issigned (randomized) group is appropri<lte-whether or not some patients did not ilctually receive the treatment they were supposed to receive. Tri<lls analyzed in this way are called intention to treat or management trials  (14) . The <ldvantilges of this approach are that the question corresponds to the one actua]]y faced by clinicians and the patients compared are really randomized. The disadvant age is that if many patients do not receive the treatment to which they were randomized differences between experimental and control groups will tend to be obscured, increasing the chances of a negative study. Then if the study shows no difference, it is uncertain whether the experimental treatment is truly ineffective or was just not received.\n\nAnother question is whether the experimental treatment itself is better? For tills question, the proper analysis is according to the treahnent each patient actually received, reg<lrdlcss of the treatment to which they were randomized. Trials analyzed in this way are called explanatory trials because they emph<lsize the mechanism by which effects are exerted. The problem with this <Ipproach is that unless most patients receive the treatment to which they are assigned the study no longer represents a randomized trial; it is simply a cohort study. Therefore, one must be concerned about dissimilarities between groups, other than the experimental tn.'<Itment, and must use one or more methods (restriction, matching, stratification, or adjustment) to achieve comp<lrability, just as one would for any nonexperimental study. These two approaches are illustrated in Figure  7 .6."
    },
    {
      "title": "EFFICACY AND EFFECTIVENESS",
      "text": "A trial's results are judged in relation to two broad questions. Can the treatment work under ideal circumstances? Does it work in ordinary settings? The words efficacy and efj('cfivcl1e~s have been appHed to these concepts (Fig.  7 .7).\n\nThe question of whether a treatment can work is one of Ijficacy. An efficacious treatment is one that has the desired effects among those who receive it. Efficacy is established by restricting patients in a study to those who will cooperate fully with medical advice.\n\nIn contrast, a treahnent is l:(fectivf' if it does more good than harm in those to whom it is offered. Effectiveness is established by offering a treatment or program to patients and allowing them to accept or reject it as they might ordinarily do. Only a small proportion of clinical trials set out to answer\n\nIntention to Treat Analysis , . . . . . . . .4, -------Drop out , , , Cross over , , Drop out Explanatory Analysis Drop out ~/ Cross over .--.0.\"'\\ . questions of effectiveness. This is in part because of the risk that the result will be inconclusive. If a treatment is found to be ineffective, it could be because of a lack of efficacy, lack of patient acceptance, or both."
    },
    {
      "title": "Tailoring the Results of Trials to Individual Patients",
      "text": "Clinical trials involve pooling the experience of many patients who arc admittedly dissimilar and describing what happens to them on the average. How can we obtain more precise estimates for individual patients? Two ways are to examine subgroups and to study individual patients using rigorous methods similar to those in randomized trials."
    },
    {
      "title": "SUBGROUPS",
      "text": "The principal result of a clinical trial is a description of the most important outcome in each of the major treatment groups. But it is tempting to examine the results in more detail than the overall conclusions afford. We look at subgroups of patients with special characteristics or with particular outcomes. In doing so, however, there <lre some risks of being misled thi;lt <lre not present when examining the principal conclusions alone, and these should be taken into account when interpreting information from subgroups. (Some of the concepts on which this section is based are discussed in Chapter 9.) One danger in examining SUbgroups is the increased chance of finding effects in a particular subgroup that are not present, ill the long run, in nature. This arises because multiple comparisons lead to a greater chance of a false-positive finding than is estimated by the individual p value for that comparison alone (see Chapter 9). Table  7 .2 lists wme guidelines for deciding whether a finding in a subgroup is real.\n\nA second danger is of a false-negative conclusion. Examining subgroups in a clinical trial-either certain kinds of patients or specific kinds of outcomes-involves a great reduction in the dat<l avail<lble, so it is frequently impossible to come to firm conclusions. Nevertheless, the temptation to look is there, and some tentative information can be gleaned."
    },
    {
      "title": "Example",
      "text": "The Physicians' Health Study (  15 ) is a randomized controlled trial designed to assess whether daily aspirin prevents mortality from cardiovascutar disease in healthy male physicians. Another aspect of the trial is to Shldy the l:'ffl:'ct of l3-carotene on the incidence of cancer. Ttll;' aspirin part of the study was stoppl:'d kmg before there were enough deaths to dl;'\\l:'rmine if aspirin affected mortillity, because the physicians had a much lower thiln expected death rate. The trial was also stopped because there were fewer myocardial infarctions in the treated than the control group. The authors thought that the effect on myocardial infarction, although not the answer to a main study question at the outset, was real because it was biologically plausible, because it was found in other studies, and because the chance of a false-positive conclusion was estimated to be very small (1/10,000). On the other hand, although the authors observed a small increase in risk of stroke in the treated group, they could not be certain whether this effect was real or not, as there were too few physicians with this end point. Thus, in a study that could not address the main research question, the authors interpreted the validity of findings in subgroups (bolh positive and negative) in relation to the totality of information that might bear on the validity of these findings."
    },
    {
      "title": "EFFECTIVENESS IN INDIVIDUAL PATIENTS",
      "text": "A treatment that is effective on the average may not work on an individual patient. The results of valid clinical research provide a good reason to begin treating a patient, but experience with that patient is a better reason to continue therapy. Therefore, when conducting a treatment program it is useful to ask the following series of questions:\n\n\u2022 Is the treatment known to be efficacious for any patients?\n\n\u2022 Is the treatment known to be effective, on the average, in patients like mine? \u2022 Are the benefits worth the discomforts and risks? \u2022 Is the treiltment working in my piltient? By asking these questions, and not simply following the results of trials alone, one can guard against ill-fOlmded choice of treatment or stubborn persistence in the face of poor results.\n\nTable 7.2 Guidelines for Deciding Whether Apparent Differences in Effects within Subgroups Are Real\" From the stucly itself \u2022 b the magnitude of the observed difference clinically important? \u2022 How likely is the effect to have arisen by chance, taking into account The number of subgroups exanlined? rhe rTldgnitucJe ot the p value? \u2022 Was a ~lYP(JUlesis that the eltect would be observed\n\nMade before its discovery (or was justification for the effect argued for after it was found)? One of Cl smCll1 number of hypotheses') From other infOrrTkltiOrl\n\n\u2022 Was the difference suggesled by comparisons within rather than between studies? \u2022 Has the effect been observed in other studies?\n\n\u2022 Is tllere indirect evidence tllat supports the existence of the effect?\n\n. ., Adapled from OxrndO Arl. Guyatl GIL A corwurners glJidp. to subgrolJp arlHlysis A\"\" 1\"1\",,, M\"d 1992: 116:78 8~_"
    },
    {
      "title": "TRIALS OF N = 1",
      "text": "Rigorous clinic<ll trials, with proper attention to bias and chance, can be done with individual patients, one at a time  (16) . The method-called trials of N = 1-is an improvement in the more informal process of trial and error that is so common in clinical practice. A patient is given one or another treatment (e.g., active treatment or placebo) in random order, each for a brief period of time, such as a week or two. Patients and physicians are blind to which treatment is given. Outcomes (e.g., a simple preference for a treatment or a symptom score) are assessed after each period <lnd subjected to statistical analysis.\n\nThis method is useful when activity of disease is unpredictable, response to treatment is prompt, and there is no carryover effect from period to period. Examples of diseases for which the method can be used include migraine, bronchospasm, fibrositis, and functional bowel disease.\n\nN of 1 trials can be useful for guiding clinical decision making, although for a relatively sma]] proportion of patients. It can also be used to screen interesting clinical hypotheses to select some that are promising enough to be evaluated using a full randomized controlled trial involving many patients."
    },
    {
      "title": "Alternatives to Randomized Trials",
      "text": "Randomized, controlled, blinded trials are the standard of excellence for comparisons of treatment effects over time. They should be given precedence over other information about treatment effects whenever they are available. However, it is not always possible to rely on clinical trials."
    },
    {
      "title": "LIMITATIONS OF RANDOMIZED TRIALS",
      "text": "Clinical trials are limited for several reasons. There may not be enough patients with the disease of interest, at one time and place, to carry out a scientifically sound trial. Clinical trials are costly, more than $50-100 million for some large trials. Years pass before results are available, which may be politicalIy unacceptable for severe, emotion-laden diseases such as AIDS.\n\nSometimes a practice may h<lve become so well established, in the absence of conclusive evidence of its benefit, that it is difficult to convince physicians and potential participants that a trial is needed. It could be argued that if the treatment effect is not really known then the only ethic<ll thing is to do the study (and it is unethical to continue to use treatments of uncertain benefit), but this argument demands a level of analytic reasoning that is uncommon among patients and their physicians. Because of this problem, some physicians have advocated \"randomization from the first patient,\" beginning trials just after a new treatment is introduced. Others argue that it is better to conduct rigorous clinical trials somewhat later, after the best way to deliver the treatment has been worked out, so that a good example of the intervention is tested. h~any case, it is generally agreed that if a controlled trial is postponed too long, the opportunity to do it all may be lost.\n\nFor these reasons, guidance from clinical trials is not available for many treatment decisions. But the decisions must be made nonetheless. What are the alternatives and how credible are they?"
    },
    {
      "title": "ADVANTAGES AND DISADVANTAGES",
      "text": "Alternatives to randomized trials usually make use of large databases such as those collected for patient care, billing, or ad ministration. Sometime data collected to answer another research question are used. A research question, and a study to answer it, can be devised after the data have been collected so that most of the resources needed for the study go into analyses of the data. This process is called secondary data anI/lysis, because answering the research question was not the primary reason for collecting the data.\n\nUsing secondary data for rese<Jrch has several advantages, all of them practical. First, if the database includes experience from a large number of patients, as is often the case, then the research question can be answered with a high degree of confidence that the results are not just by chance. It may even be possible to examine subgroups (e.g., elderly women taking estrogens or young men with a first anterior myocardial infarction) with statistical confidence. Most clinical trials are not designed with such an abundance of patients because of the cost; the best trials are sufficient to answer the main research question for aU patients in the study but are rarely sufficient to answer questions about subgroups of patients.\n\nSecond, these databases are collected in more natural settings than clinical trials. They reflect experience in health care organizations or perhaps entire regions or nations, rather than a highly selected group of experimental subjects. Therefore, the results are more generalizable.\n\nThird, it costs less to use existing data than to collect new data in a clinical trial. Randomin~d trials cost thousands of dollars per patient to recruit, evaluate, L'IU\"oll, and follow up each patient, whereas analyses of existing data can be relatively inexpensive.\n\nFinally, by using existing data, it is possible to have an answer to an important question in a relatively short time. Clinical trials often take years from enrollment of the first patient to the end of follow-up. Sometimes clinicians need an answer, however imperfect, sooner because they are making high-stakes decisions on alternative treatments every day.\n\nBalanced against all of these practical advantages are disadvantages. The data are usually not collected and classified with as much care as they would be for a well-run clinical trial. For example, a claims data diagnosis of \"hypertellsion\" stands for whatever the responsible physicians believes hypertension is, whereas a research definition of hypertension would specify a level of blood pressure, method, and frequency, perhaps adjusted for age. Some important variables may be missing from the database because they were not important for the database's original purposes, though they arc important for the research. Of course, there is also the problem of making unbiased comparisons.\n\nThe trade-off behveen speed and ease, on the one himd, and validity, on the other, wj]] be discussed for each alternative design in the next sections."
    },
    {
      "title": "COMPARISONS ACROSS TIME AND PLACE",
      "text": "Control patients can be chosen from a time and place different from the experimental patients. For example, we may compare the prognosis of recent patients treated with current medications to experience with past patients who were treated when current medications were not available. Similarly, we may compare the results of surgery in one hospital to results in another, where a different procedure is used. This approach is convenient. The problem is that time and place are almost always strongly related to prognosis. Clinical trials that attempt to make fair comparisons between groups of patients arising in different eras, or in different settings, have a particularly difficult task.\n\nThe results of current treatment are sometimes compared with experience with similar patients in the past, called historical or nonconcurrent col/lmls. Although it may be done well, this design has many pitfalls. Methods of diagnosis change with time, and with them the average prognosis. It has been shown that new diagnostic technologies have created the impression that the prognosis of treated lung cancer have improved over time when it has not  (17) . With better ability to detect occult metastases, patients are classified in a worse stage than they would have been earlier, and this \"stage migration\" has resulted in a better prognosis in each stage than was reported in the past. Supporting treatments (e.g., antibiotics, nutritional supplementation and peptic ulcer prevention) also improve with time, creating a general improvement in prognosis that might not be attributable to the specific treatment given in a later time period.\n\nExample Sacb et al.  (18)  reviewed cJ;nical trials of six therapies 10 sec if lriab with concurrent controls produced different results than studies of the same treatments with historical cuntrols. They studied 50 r;::ndomized trials and 56 studies with historical controls. A total of 7';l'}:, of trials with historical conlrols but unly 20'%, of trials with a concurrent, randomized conlrol group found the experimental treatment to be better. Differences between the two kinds of trials occurred mainly because the control patients in the historical trials did worse. Adjustment for prognostic factors, when possible, did not change the results, i.e., the differences were prob<lhly because of gener<ll improvements in therapy or to selection of less ill patients.\n\nTherefore, if concurrent, randomized controlled trials <Ire taken as a standard of validity it seems that published historical trials are biased in favor of the experimental treatment and that the bias cannot be overcome by adjusting for known prognostic variables.\n\nIf historical controls arc used, the shorter the period of time between selection of treated and control groups and the less other aspects of medical care have changed during the interval, the safer the comparison. Thus some oncology centers study a succession of chemotherapeutic regimens by comparing results of the newest regimen with those of the immediately preceding one, often given as recently as the previous year. In general, however, choosing concurrent controls (i.e., patients treated during the same period of time) is a better way of avoiding bias.\n\nExperience in other settings, using different treattru'nts, can serve as a standard of comparison. However, it is prefer<:lble to choose both treated and control patients from the same setting, because a variety of factorsreferral patterns, organization and skill of staff, etc.-often result in very different prognoses in different settings, independently of the treatment under study."
    },
    {
      "title": "Example",
      "text": "The mortality rate for hospitals where coronary bypass surgery was done varied almost threefold across hospitals in central Pennsylvania (Fig.  7 .8)  (19) . The severity of illness, and therefore prognosis, of patients in these hospitals varied too. !\\fter taking into account the number of de<lths explXted, by considering patients' prognostic factors, one hospital had fewer than expected deaths, another the expected number, and a third more than expected. Any fair comparison of treatment effects across these hospitals would have to take into ilccount not only the differences in severity of the patients in these hospitals bllt also the skills of the surgeons."
    },
    {
      "title": "UNCONTROLLED TRIALS",
      "text": "Uncontrolled trials describe the course of disease in a single group of patients who have been exposed to the intervention of interest. Another name for this design is a \"before-after study.\" The assumption of this approach is that whatever improvement is observed after treatment is because of treatment. This assumption may be unwarranted for several reasons."
    },
    {
      "title": "Unpredictable Outcome",
      "text": "When the clinical course of a disease is quite predictable, a separate control group is less important. We know that subacute bacterial endocarditis without antibiotics and rabies without vaccine invariably lead to death, that most patients with hypothyroidism will only get worse without exogenous thyroid hormone, and that bawd infarction will rarely improve without surgery.\n\nHowever, most therapeutic decisions do not involve conditions with such predictable outcomes. In situations where the clinical course is extremely variable for a given patient and from one patient to another, assessing treatment effects by observing changes in the course of disease aftef treatment is unreliable.\n\nMany severe diseases that are not self-limited may nevertheless undergo spontaneous remissions in activity that call be misinterpreted as treatment effects. figure  7 .Y shows the clinical course of a patient with systemic lupus erythematosus over a  10-year period, 1955-1%4 (20) . Although powerful treatments were not given (because none was available during most of these years), the disease passed through dramatic periods of exacerbation, followed by prolonged remissions. Of course, exacerbations, such as those illustrated, are alarming to both patients and doctors, so there is often a feeling that something must be dune at these times. If treatment were begun at the peak of activity, improvement would have followed. Without any better comparison than the previous activity of the diseasE', the tfeatment vmuld h8\\'8 received credit for the improvement."
    },
    {
      "title": "Nonspecific Effects",
      "text": "In uncontrolled trials, there is no way of separating Hawthorne and placebo effects from treatment effects. But if there are control patients who receive the same attention as the treated ones and a placebo, then these effects cancel out in the comparison."
    },
    {
      "title": "Regression to the Mean",
      "text": "Treatments are often tried because a manifestation of disease, e.g., a pilrticuliHly high blood pressure or fever, is extreme or unusual. In this situiltion, subsequent measurements are likely to show improvement for purely statistical reasons. As discussed in Chapter 2, piltients selected because they represent an extreme high value in a distribution are likely, on the average, to have lower values for later measurements. If those patients are treated after first being found abnormal and the effects of treatment are assessed by subsequent measurements, improvement could be expected even if treahnent were ineffective."
    },
    {
      "title": "Predictable Improvement",
      "text": "The usual course of some diseases is to improve; if so, therapeutic efforts may coincide with improvement but not cause it. For example, patients tend to seek care for many acute, self-limited diseases, such as upper respiratory infections or gastroenteritis, when symptoms are at their worst. They often begin to recover after seeing the doctor because of the natural course of events regardless of what was done."
    },
    {
      "title": "NONRANDOM ALLOCATION OF TREATMENT",
      "text": "One way to allocate patients to treated and control groups is to have the physicians caring for the patients decide. When this is done, the study has all the advantages and disadvantages of cohort studies.\n\nStudies of treated cohorts take advantage of the fact thilt therilpeutic decisions must be made for sick patients regardless of the qUillity of existing evidence on the subject. In the absence of a clear-cut consensus favoring one mode of treatment over others, various treatments are often given. As a result, in the course of ordinary patient care large numbers of patients receive various treatments ilnd go on to manifest their effects. If experience with these patients Ciln be Cilptured and properly analyzed, it can be used to guide therapeutic decisions.\n\nUnfortunately, it is often difficult to be sure that observational studies of treatment involve unbiased compilfisons. Decisions about treatment are determined by a great many filctors-severity of illness, concurrent diseases, local preferences, piltient cooperation, etc. Patients receiving the different treatments are likely to differ not only in their treiltment but in other ways as well. Efforts to determine the results of treiltment illone, free from other factors, are thereby compromised."
    },
    {
      "title": "Phases of Studies of Treatment",
      "text": "For studies of drugs, it is customary to define three phases of triills, in the order they are undertaken  (21) . Phase [ trials arc intended to identify a dose range that is well tolerilted ilmi safe (at least for high-frequency, severe side effects) and include very small numbers of patients (perhaps il dozen), without a control group. Phase II trials provide preliminary information on whether the drug is efficacious and the relationship between dose and efficacy; these trials may be controlled but include too few patients in treatment groups to detect any but the lilTgest treiltment effects. They milY not be blinded. Phase III trials provide definitive evidence of efficilcy and the presence of common side effects. They include enough patients-~dozensto thousands-to detect clinically important treatment effects and are commonly published in clinical journals and lIsed by regulatory agencies to decide whether to license drugs.\n\nPhase III trials are not large enough to detect differences in the rate-or even the existence-of uncommon side effects. (See discussion of stiltistical power, Chapter Y.) For this, it is necessary to follow up very large numbers of patients after a drug is in general use, a process cillied \"postmarkcting surveillance\" or, sometimes, phase IV of drug development."
    },
    {
      "title": "Summary",
      "text": "Promising ideas about what might be good treatment should be put to a rigorous test before being used as a basis for clinical decisions. The best test is a randomized controlJed trial, a special case of a cohort study in which the intervention is allocated randomly and, therefore, without bias. Patients in clinical trials are usually highly selected, reducing gcneralizability. They are randomly allocated to receive either an experimental intervention or some comparison mamlgement: usual treatment, a placebo, or simple observation. On the average, the compared groups have a similar prognosis just after randomization (and before the interventions). However, differences not attributable to treatment can arise later, including not taking the assigned treatment, dropping out of the study, receiving the other treatment, being managed differently in other ways, or getting treatments that are not part of the study. Blinding all participants in the trial can help minimize bias in how patients are randomized, managed, and assessed for outcomes but is not always possible or successful.\n\nThe results of randomized trials can be summarized according to the treatment assigned; an intention-to-treat analysis, which is a test of the clinical decision and maintains a randomized trial design; or according to the treatment actually received, which bears on the biology of disease, but not directly on the clinical decision, and has the disadvantage that patients may not remain with the treatment they were originally assigned. To obtain information more closely tailored to individual patients than the main results of randomized trials afford, clinicians can use results in subgroups of patients, which carry the additional risk of being misleading, or do trials on their own patients, one at a time.\n\nFor many clinical qm'stions it is not possible, or not practical, to rely on a randomized controlled trial. Compromises with the ideal include making comparisons to experience with past patients, to past expericllce with the same patients, or to a concurrent group of patients who are not randomly allocated. When these compromises arc done, the internal validity of the study is weakened.\n\nREFIiRENCES l. ECjlC Ilyp~~~Study Group, Failun, \"f \",xtr~cranial-intracranialarterial hYr~~s to reduce the risk of ischemic ~troke. N Engl J Med 19S5;313:1191-1200, 2. M~j-'berg MR, Wilson E, Y~t~u F, Weiss DG, Messina I., Ht%hey LA, Colling C bkri(lgt' L Deykin D, Winn UK Carotid \",ndart\",r\",clomy and prevention of c\",r\",bral ischemic' in symptomatic carotid stenosis. JAMAI991 ;266:3289-3294. :I, Opie On the h\",artIEditoriall. LancctI9S0;1:692. 4, Rubenstein LZ, R(lhhin~AS, Josephson KI':, Schulm~n ilL, Osterweil 0. rlw valu\", of as~essing falls in an elderly population. A randomiz\",d controlled trial. Ann Intern Med 1990; 113:30t!-316. S. Fisch\"r RW Comparison of antipruritic drug~administered orally. JAMA 1968;2U3:4Hl-419. PREVENTION l.ivc sensibly-among Ii t!lol/sand people, only Dill' dies a natural dellth, tile rest succumb to irratiollal modes of living. Maimonides 1135-1204 A.I).\n\nMost doctors are attracted to medicine because they look forward to curing disease. But all things considered, most patients would prder never to contract a disease in the first place-Of, if they cannot i1void an illness, they prefer that it be caught early and stamped out before it causes them any harm. To accomplish this, procedures are performed on patients without specific complaints, to identify and modify risk factors to avoid the onset of disease or to find disease early in its course so that by intervening patients can remain well. Such activity is referred to as health mainlt'iWl1CI' or till' periodic health examination.\n\nHealth maintenance constitutes a large portion of clinical practice  (1) . Often, health maintenance activities can be incorporated into the ongoing care of patients, as whcn a doctor checks the blood pressure in a patient complaining of a sore throat; sometimes, a special visit just for health maintenance is scheduled.\n\nPhysicians should understand the conceptual basis and content of the periodic health eX<lmination. They should be prepared to answer questions from patients such <IS \"Why do J h<lve to get a Pap smear <lgain this year, Doctor?\" or \"My neighbor gets <I chest x-ray every year; why aren't you ordering one for me?\"\n\nThis ch<lpter concentrates on prevention activities clinicians undertake with individual patients. However, prevention at the community level is also effective. Immuniz<ltion requirements for students, no-smoking regu-l<ltions in public buildings, and legislation restricting the sale of firearms are examples of community wide prevention. For some problems, such as injury prevention from firearms, community prcvention works best. For others, such as colorectal cancer, screening in clinical settings works best. For still others, clinical efforts can complement commlUlitywide <lctivities, <IS in smoking prevention efforts by which clinicians help individual pa-165 tients stop smoking and public education, regulations, and taxes prevent teenagers fTOm starting to smoke. Much of the scientific approach to prevention in clinical medicine, particularly the principles underlying the use of a diagnostic tests, disease prognosis, and efrectiveness of interventions, has already been covered in this book. This chapter expands on those principles and strategies as they specifically relate to prevention."
    },
    {
      "title": "Levels of Prevention",
      "text": "Webster's (2) dictionary defines prevention as \"the act of keeping from happening.\" With this definition in mind, almost aU activities in medicine could be defined as prevention. After all, clinicians' efforts are aimed at preventing the untimely occurrences of death, disease, disability, discomfort, dissatisfaction, and destitution (Chapter 1). However, in clinical medicine, the definition of prevention is usually restricted, as outlined below. Although more prevention is practiced than ever before, clinicians still spend most of their time in diagnosing and trcating rather than in preventing diseasc.\n\nDepending on when in the coursc of disease interventions are made, three types of prevention are possible (pig. 8.1)."
    },
    {
      "title": "PRIMARY PREVENTION",
      "text": "Primary preventio/1 keeps dise<lse from occurring at a]], by removing its causes. Folic acid administration to prevent l1eura I tube defects, immunizations for many communicable diseases, and counseling patients to adopt healthy lifestyles (e.g., helping patients to stop smoking, to eat foods low in saturated f<lts and cholesterol and high in fiber, to exercise appropriately, and to engage in safe sexual practices) are examples of primary prevention. Primary prevention is often accomplished outside the health care system at the community level, as noted above. ChlorinaEon and fluorid<ltion of the water supply and laws mandating seat belt use in automobiles and helmets for motorcycle use <In' examples. Certain primary prevention activities occur in specific occupational settings (use of ear plugs or dust masks), in schools (immunizations), or in specialized health c<lre settings (usc of tests to detect the hepatitis B or HIV in blood domtions in blood banks)."
    },
    {
      "title": "Onset"
    },
    {
      "title": "SECONDARY PREVENTION",
      "text": "Secondary prevention detects disease early when it is asymptomatic and when early treatment can stop it from progressing; Pap smears, mammograms, and fecal occult blood tests are examples. Most second<lry prevention is done in clinical settings, and all physicians, especi,J11y those caring for adults, undertake secondary prevention. There <Ire a few communitywide programs (shopping mall fairs for glaucoma screening are an example)."
    },
    {
      "title": "SCREENING",
      "text": "Screening is the identification of <In unrecognized disease or risk factor by history taking (e.g., asking if the patient smokes), physical examination (e.g., a prostate examination), laboratory test (e.g., a serum phenylalanine determination), or other procedure (c.g., a sigmoidoscopy) that can be applied rapidly. Screening tests sort out apparently well persons who have a disease or a risk factor for a disease from those who do not. It is part of many primary and all secondary prevention activities. A screening test is not intended to be diagnostic. If the clinician is not COlllmitted to further investigation of abnormal results and trei:ltment, if necessary, the screening test should not be performed at alL"
    },
    {
      "title": "TERTIARY PREVENTION",
      "text": "Tertiary prevention refers to those clinical activities that prevent further deterioration or reduce complications after a disease has declared itself. An example is the use of bet<l-blocking drugs to decrease the risk of death in patients who have recovered from myocardial infarction. The boundaries of tertiary prevention blend into curative medicine, but weUperformed tertiary prevention goes beyond treating the problems patients present with. For example, in diabetic patients, tertiary prevention requires more than good control of blood glucose; patients need regular ophthalmologic examinations for early diabetic retinopathy, education for routine foot care, searches for and treatment of other cardiovascular risk factors, and monitoring for urinary protein so that angiotensin-converting enzyme inhibitors can be used to prevent renal failure.\n\nTerLiary prevention is particularly important in thl' management of patients with fatal disease. The goal here is not to prevent death but to maximize the amount of high-quality time a patient has left. For example, presently there is no specific therapy for patien~s with amyotrophic lateral sclerosis, a neurologic condition ending in paralysis of respiratory and swallowing muscles. But careful medical management C,In lead to early intervention with a gastrostomy for administering food and liquids to prevent dehydration and weakness from starvation, a tracheostomy for better suctioning to prevent pneumonia for as long as possible, and if the patient wishes, a portilble respirator to rest respiratory muscles. Without such a proilctive approach, the patient may present with acute respiratory failure due to the combined effects of the underlying disease, dehydration, and pneumonia. Patient, family, and physician are then faced with endotracheal intubation and admission to the intensivc care unit, with the hope of reversing enough of the processes to reestablish decent quality of life for a little longer. Tertiary prevention can help avoid this scenario.\n\nThere are few, if any, tertiary prevention programs outside the health care system, but many health care professionals in addition to physicians are active in these programs."
    },
    {
      "title": "Approach to the Periodic Health Examination",
      "text": "When considering what to do routinely for patients without specific symptoms for a given disease, the clinician must first decide which medical problems or diseases he or she should try to prevent. This statement is so straightforward that it would seem unnecessary. But the fact is that many preventive procedures, especially screening tests, are performed without a clear understanding of what is being sought. For instance, a urinalysis is frequently ordered by physicians performing routine checkups on their patients. However, a urinillysis might be used to search for ilny number of medical problems, including diabetes, asymptomatic urinary tract infections, and renal calculi. It is necessary to decide which, if any, of these conditions is worth screening for before undertaking the test.\n\nThree criteria are importilnt when deciding what condition to include in a periodic health examination (Table  8 , 1 ): (a) the burden of suffering: caused by thc condition, (b) the quality of screcning test if one is to be performed, and (c) the effectiveness of the intervention for primary prevention (e.g., cOlUlseling patients to practice safe sex) or the effectiveness of treatment for secondary prevention after the condition is found on screening (e.g., prostate cancer treatment)."
    },
    {
      "title": "Burden of Suffering",
      "text": "Is screening justified by the severity of the medical condition in terms of mortality, morbidity, and suffering caused by the condition? Only conditions posing threats to life or health (the six Os) should be sought. Dle severity of the medical condition is determined primarily by the risk it poses or its prognosis (discussed in Ch<lpters 5 and 6). For example, except during pregn<lncy and before urologic surgery, the health consequences of <lsymptomatic b<lcteriuria are not dear. We do not know if it causes ren<ll f<Jilure <lnd/or hypertension. Even so, bacteriuria is frequently sought in periodic health examinations. Burden of suffering takes into account the frequency of a condition. Often a particular condition causes great suffering for individuals unfortunate enough to get it, but occurs too r<lrely-perhaps in the individual's particular age group-for screening to be considered. Breast cancer and colorectal cancer are two such examples. I\\lthough both can occur in much younger people, they primarily occur in persons older than 50 years. For women in their early 20s, breast cancer incidence is 1 in 100,000 (one-fifth the rate for men in their e<ITly 70s)  (3) . I\\lthough breast cancer should be sought in periodic hmlth examinations in women over 50, it is too uncommon in 20-ye<IT-old women (or 70-year-old men) for screening. Screening for very rare diseases means not only that at most very few people will benefit but, because of false-positive tests, that many people may suffer harm from labeling and further workup (sec below).\n\nA particularly difficult dilemma faced by clinicians and patients is the sihtation in which a person is known to bc at high risk for a condition, but there is no evidence that early treatment is effective. What should the physician and patient do? For example, there is evidence that people with Barrett's esophagus (a condition in which the squamous mucosa in the distal esophagus is replaced by columll<lr epithelium) run a 30-to 40-fold greater risk of developing esoph<lgeal cancer than persons \\vithout Barrett's esophagus  (4) . However, the effectiveness of screening such people with periodic endoscopic examinations followed by early treatment if cancer occurs is unknown.\n\nThere is no easy answer to this dilemma. But if physicians remember that screening will not work unless early therapy is effective, they can weigh carefully the evidence about therapy with the patient. If the evidence is against effectiveness, they may hurt rather than help the patient by screening."
    },
    {
      "title": "Which Tests?",
      "text": "The following criteria for a good screening test apply to a]] types of screening tests, whether they are history, physical examination, laboratory tests or procedures."
    },
    {
      "title": "SENSITIVITY AND SPECIFICITY",
      "text": "The very nature of searching for a disease in people without symptoms for the disease means prevalence is usually very low, even among highrisk groups selected because of age, sex, and other characteristics. A good screening test must, therefore, have a high sensitivity, so it does not miss the few cases of disease that are present, and a high specificity, to reduce the number of people with false-positive results who require further workup.\n\nSensitivity and specificity arc determined for screening tests much as they are for diagnostic tests, except that the gold standard for the presence of disease uSU<llly is not another test but rather a period of follow-up. For example, in a study of fecal occult blood tests for colorectal cancer, the sensitivity of the test was determined by the ratio of the number of c010rectal cancers found during screening to that number plus the number of interval cancers, colorectal cancers subsequently discovered over the following year in the people with negative test results (the assumption being that interval cancers were present at screening but were missed, i.e., the test results were false negative)  (5) . Determination of sensitivity and specificity for screening tests in this way is sometimes referred to as the detection method.\n\nThe detection method for calculating sensitivity works well for many screening tests, but there are two difficulties with the method for some cancer screening tests. First, it requires that the appropriate amount of follow-up time is known; often it is not known and must be guessed. The method also requires thiJt the abnormalities detected by the screening test would go on to cause trouble if left alone. This second issue is a problem in screening for prostate cancer. Because histologic prostate cancer is so common in men (it is estimated that 25')'0 of 50-year-old men have histologic foci of prostate cancer, and by the age of 90, virtually all men do), scft'ening tests can find such cancers in milny men, but for most, the cancer will never become malignant. Thus, when the sensitivity of prostate cancer tests such as prostate-specific antigen (PSA) is determined by the detection method, the test may look quite good, since the numerator includes all cancers found, not just those with malignant potential.\n\nTo get around these problems, the illcidel/ce mcfhod, a new method, calculates sensitivity by using the incidence in persons not undergoing screening and the interval cancer rate in persons who are screened. The rationale for this approach is that the sensitivity of a test should affect interval cancer rates but not disease incidence. For prostate cancer, the incidence method defines sensitivity of the test as 1 minus the ratio of the interval prostate cancer rate in a group of men undergoing periodic screening to the incidence of prostate cancer in a group of men not undergoing screening (control group). The incidence method of caJculilting sensitivity gets around the problem of counting \"benign\" prostate cancers, but it may underestimate sensitivity because it excludes cancers with long lead times. True sensitivity of a test is, therefore, probably between the estimates of the two methods.\n\nBecause of the low prevalence of most diseases, the positive predictive value of most screening tests is low, even for tests with high specificity. Clinicians who practice preventive health care by performing screening tests on their patients must accept the fact that they will have to work up many patients who will not have disease. However, they can minimize the problem by concentrating their screening efforts on people with a higher prevalence for diSease.\n\nExample The incidt;'nce of breast cancer increases with age, from approximately 1 in 100,000/yl:'ar at age 20 tal in 200/year over age 71). Therefore, a lump found during screening in a young woman's breast is more likely Lo be nonmalignant than a lump in an older woman. In a large demonstration project 011 breast cancer scnX_'lling, biopsy results of breast masses varied markedly according to the age of women  (6) ; in women under age 40, more than 16 benign lesions Wl:'re found for ev,'ry malignancy, but in women over age 70 fewer than .' 1 benign lesions were found for every malignancy (Fig.  8 .2). Sensitivity and specificity of the clinical breilst examination and mammography arc better in older women ilS well, because of changl:'s in breast tis>lue as women grow older.\n\nThe yield of screening dc'Creases as screening is repeated over time in a group of people. Figure  8 .3 demonstrates why this is true. The first time that screening is carried out-the prevalence screen-cases of the medical condition will have been present for varying lengths of time. During the second round of screening, most cases found will have had their onset between the first and second screening. (A few will have been missed by the first screen.) Therefore, second and subsequent screenings are called incidence screens, Figure  8 .3 illustrates how, when a group of people are   CA 1982; 32:195-231.) periodically rescreened, the number of CJses of disease present in the group drops after the prevalence screen. This means that the positive predictive value for test results will decrease after the first round of screening."
    },
    {
      "title": "SIMPLICITY AND LOW COST",
      "text": "An ideal screening test should take only a few minutes to perform, require minimum preparation by the patient, depend on no special appointments, and be inexpensive.\n\nSimple, quick examinations such as blood pressure detenninations Jre ideal screening tests. Conversely, complicated diagnostic tests such as colonoscopy, which are expensive and require an appointment and bowel preparation, arc reJsonabJe in patients with symptoms and clinical indications but may be unacceptable as screening tests, especially if they must be repeated frequently. Other tests, such as visUJl field testing for the detection of glaucoma and audiograms for the detection of hearing loss, fall between these two extremes. Even if done carefully, such tests, <11-\n\nRound 2 3 D, (}--D, D, D, ~D, D, 0, 0 f-D P-~--D, 0, -D, 5 3 3"
    },
    {
      "title": "Number of Cases"
    },
    {
      "title": "Newly Detected",
      "text": "though not as difficult as colonoscopy, are probably too complex to be used as screening tests.\n\nThe financial \"cost\" of the test depends not only on the cost of (or charge for) the procedure itself but also on the cost of subsequent evaluations performed on patients with positive test results. Thus sensitivity, specificity, and predictive value affect cost. Cost is also affected by whether the test requires a special visit to the physician. Screening tests performed while the patient is seeing his or her physician for other reasons (as is frequently the case with blood pressure measurements) are much cheaper for patients thiln tests requiring special visits, extril time off from work, and additional trilnsportation."
    },
    {
      "title": "SAFETY",
      "text": "Tt is reasonable and ethical to accept a certain risk for diagnostic tests applied to sick patients seeking help for specific complaints. The patient comes asking for help, sometimes with a problem about which little is known.\n\nThe physician cannot postpone action and does his or her best. It is quite another matter to subject presumably well peoI_Ie to risks when there is no known problem. In such circumstances, the procedure should be especially safe. This is partly because the chilnces of finding disease in healthy people arc so low. Thus, illthough colonoscopy is hilrdly thought of as a \"dangerous\" procedure when used on patients \\vith gastrointestinal complaints, it may be too d'lllgerous to use as a screening procedure because of the possibility of bmvcl perforation. In f.xt, if colonoscopy, with a perforation rate of 0.2\u00b0,{\" were used to screen for colorect,,1 cancer in women in their 50s, almost two perforiltions would occur for every cancer found. For women in their 70s, the ratio would reverse, because colorectal cancer is so much more common  (7) ."
    },
    {
      "title": "ACCEPTABLE TO BOTH PATIENTS AND CLINICIANS",
      "text": "The importance of acceptability is iJ1ustrilted by experience with tests for early cervical cancer and early (olon Cilncer. Women at greatest risk for cervical cancer are least likely to get routine [',Ip smears. The same problem holds true for colorectal cancer. Studies indicilte there is a strong rductilnce among ilsymptomatic North Americans to submit to periodic examinations of their lower gilstrointestinal tracts-a finding that should be no surprise to any of us! Table  8 .2 shows acceptance of screening for colorectal cancer by various kinds of people. People who voluntarily attended a (olmeda I cancer screening clinic were very cooperative; they were willing to collect stool samples, smear the samples on guaiac-impregnated paper slides, and mail the slides to their doctors for clinical testing. Patients \\vho did not volunteer were less willing to participate. Older persons, who <lre at greatest risk for (olmectal cancer because of their age, were ]eilst willing to be screened. Substantial extra effort can result in getting more people (but still fewer than half) to participate. TIlt' acceptability of the tcst to clinicians is a criterion usually overlooked by all but the ones performing it. After one large, well-conducted study on the usefulness of screening, sigmoidoscopy was abandoned because the physicians performing the procedure-gastroenterologists, at that-found it too cumbersome and time-consuming to be justified by the yield  (8) . (Patient acceptancc, 1R Cl j,), was not good either.)"
    },
    {
      "title": "LABELING",
      "text": "The labl'lillg effect describes the psychological effect of test results or diagnoses on patients. Studies of labeling suggest that test results can sometimes have important psychological effects on patients.\n\nLabeling can either help or hurt patients. A positive labeling effect may occur when a patient is told that all the screening test results were normal. Most clinicians have heard such responses as, \"Great, that means I can keep working for another year.\" If being given a dean bill of health promotes a positive attitude toward one's daily activities, a positive labeling effect has occurred.\n\nOn the other hand, being told that something is abnormal may have an adverse psychological effect. A study of \"vomen who had false-positive mammograms (women with suspicious mammograms who on subsequent evaluation were found not to have cancer) found that several months later almost half reported mammography-related anxiety (47%) and worries about breast cancer (4l'~;,); 17'};, said the worries affected their daily function  (9) .\n\nLabeling effects of screening tests may become a major concern with progress made in genetic screening. A gene has been identified for Huntington's chorea, and relatives of affected individuals can be tested to sce if they carry the dominant, universally fatal gene. Such a test may help people who wonder if they should marry and have children. More complicated are the much more common situations in which genes are associated with a risk, not a certainty, of future disease. For example, several genes are known to be associated with colorectal and breast cancer. In these situations, many people with the genes will not get cancer, and many without the particular genes will get the cancer. Because the events are in the future, persons who have been told they have one of these genes will have to live with the possibility of a dire event for a long time.\n\nNegative labeling effects are particularly worrisome ethically when they occur among patients with false-positive tests. In such situations, screening efforts might promote a sen;e of vulnerability instead of health and might do more harm than good."
    },
    {
      "title": "RISK OF A FALSE-POSITIVE RESULT",
      "text": "The previous discussion applies to each of the individual screening tests that a clinician might consider performing during a periodic health examination. However, most clinicians do not perform only one or two tests on patients presenting for routine checkups. In one study, practicing internists believed that 57 different tests should be performed during periodic health examinations  (10) . Modern technology, and perhaps the threat of lawsuit, has fueled this propensity to \"cover an the bases.\" Automated blood tests allow physicians to order up to several dozen tests with a few checks in the appropriate boxes.\n\nWhen the measurements of screening tests are expressed on interval scales (as most are) and when normal is defined by the range covered by 95% of the results (as is usual), the more tests the clinician orders, the greater the risk of a false-positive result. In fact, as Table  8 .3 shows, if the physician orders enough tests, \"abnormalities\" will be discovered in virrnally all healthy patients."
    },
    {
      "title": "Effectiveness of Treatment",
      "text": "\"Treatments\" in primary prevention are immunizations, such as tetanus toxoid to prevent tetanus; drugs, such as aspirin to prevent myocardial infarction; and behavioral counseling, such as helping patients stop smoking or adopt low-cholesterol diets. Whatever the intervention, it should be efficacious (produce a beneficial result in ideal situations) and effective (produce a beneficial result under usual conditions). Efficacy and effectiveness of pharmaceuticals are usually better documented than they are for behavioral wunseling. Federal laws require rigorous evidence of efficacy before pharmaceuticals are approved for use. The same is not true for behavioral wunseling methods, but clinicians should require scientific evidence before incorporating routine counseling into health maintenance. Health behaviors are among the most important determinants of health in modern society; effective counseling methods could promote health more  Example Two different smoking cessation counseling strategiesweekly hour-long group counseling sessions for 8 weeks and weekly 10-to 20-min individual counseling sessions for 8 weeb-were combined with nicotine patch therapy and evaluated for their effectiveness in promoting smoking cessation  (11, 12) . Compared with patients randomized to control groups, the patients receiving the interventions did somewhat better, with a third of patients in the group colmseling sessions having stopped smoking at 6 months follow-up. llowever, fewer than 20% of patients receiving individual counseling had stopped smoking. furthermore, the authors found that most failures at fi months could be predicted by patients smoking at some time during the first 2 weeks after trying to stop. These findings suggest that counseling should be \"front loaded\" By carefully evaluating behavioral counseling, studies such as this are determining what approaches work.\n\nTreatments for secondary prevention are generally the same as treatments for curative medicine. Like interventions for primary prevention, they should be both efficacious and effective. If early treatment is not effective, it is not worth screening for a medical problem regardless of how easily it can be found, because early detection alone merely extends the length of time the disease is known to exist, without helping the patient.\n\nAnother criterion important for treatments in secondary prevention is that patient outcome must be better if the disease is found by screening, when it is asymptomatic, than when it is discovered later, after the condition becomes symptomatic and the person seeks medical care. If outcome in the two situations is the same, screening is not necessary.\n\nExample In a study of the use of chest x-rays and sputum cytology to screen for lung cancer, mille cigarette smokers who were screened every 4 months and treated promptly if cancer was found did no better than those not offered screening  (13) ; at the end of the study, death rates from lung cancer were the same in the two groups-3.2 per lOOO person-years in the screened men versus 3.0 per 1000 persons\u2022years in men not offered screening. Farly ddection and treiltment did nol help pilticnts with lung cancer more than treahnent of people at the time they presented with symptoms."
    },
    {
      "title": "BIASES",
      "text": "As discussed in Chapter 7, the best way to establish the efficacy of treatment is with a randomized controlled trial. This is true for all interventions but especially for early treatment after screening. To establish that a preventive intervention is effective typically takes years and requires large numbers of people to be studied. for example, early treatment after colorectal cancer screening can decrease colorectal cancer deaths by approximately one-third. But to show this effect, a study with 13 years of followup was required  (5) . A \"clinical impression\" of the effect of screening simply does not suffice in this situation. Careful studies an' also necessary because of biases that are specific to studies of the effectiveness of screening programs. Three such biases are described below. lead Time Bias read time is the period of time between the detection of a medical condit ion by screening and when it ordinarily would be diagnosed because a pati('nt experiences symptoms and seeks medical care (Fig.  8 .4). The amount of lead time for a given disease depends on both the biologic rate of progression of the disease and on the ability of the screening test to detect early disease. When lead time is very short, as is presently the case with lung cancer, treatment of medical conditions picked up on screening is likely to be no more effective than treatment after symptoms appear. On the other hand, when lead time is long, as is true for cervical cancer (on average, it takes approximately 30 years to progress from carcinoma in situ to clinically invasive disease), treatment of the medical condition found on screening can be very effective.\n\nHow can lead time cause biased results in a study of the efficacy of early treatment? As Figure  8 .4 shows, because of screening, a disease is found earlier than it would have been after the patient developed symptoms. As a result, people who are diagnosed by screening for a deadly disease will, on average, survive longer from the time of diagnosis than people who are diagnosed after they get symptoms, even if eilrly treatment is no more effective than. treatment at clinical presentation. Tn such a situation screening would appear to help people live longer, when in il reality they would be given not more \"survival time\" but more \"disease time.\" Screening 0 0, 0--0, 0 0, 0, 0 0, 0, 0, 0, 0-0, 0, 0, 0, An appropriate method of analysis to avoid lead time bias is to study both a screened group of people and a control group of people and compare agespecific mortaJity rates rather than survival rates from the time of diagnoses. We can be confident that early diagnoses and treatment of colorectal cancer are effective, because studies have shown that mortality rates of sLTecncd persons are lower than those of a comparable group of unscreened people  (5) ."
    },
    {
      "title": "Length Time Bias",
      "text": "Length lime bias (see  Figs. 8.5 and 8.6) , another bias that can affect studies of screening, occurs because the proportion of slow-growing lesions diagnosed during screening programs is greater than the proportion of those diagnosed during usual medical care. The effect of including a greater number of slow-growing cancers makes it seem that screening and early treatment are more effective than usual care.\n\nLength time bias occurs in the following way. Screening works best when a medical condition develops slowly. Most types of cancers, however, demonstrate a wide range of growth rates. Some cancers grow slowly, some very fast. Screening tests arc likely to find mostly slow-growing tumors because they are present for a longer period of time before they cause symptoms; fast-growing tumors are more likely to cause symptoms that lead to diagnosis in the interval between screening examinations. Screening, therefore, tends to find tumors with inherently better prognoses. As a result, the mortality rates of cancers found on screening may be better than those not fOlmd on screening, but it is not because of the screening itself."
    },
    {
      "title": "Compliance Bias",
      "text": "Compliance bias, the third major type of bias that can occur in effectiveness studies of presymptomatic treatment is the result of the extent to which p<Jtients follow medical advice. Compliant patients tend to have better prognoses regardless of screening. If a study compares disease outcomes among volunteers for a screening program with outcomes in a group of people who did not volunteer, better results for the volunteers might not be due to treatment but be the result of other factors related to compliance.\n\nExample In a study of the effect of a health maintenance prog:ram, one group nf patients was invited fur an annual periodic health examination and a comparable g:roup was not invited  (14) . Over the years, however, some of the control group ilsked for periodic heillth examinations. As seen in Figure  8 .7, those patients in the control group who ilctivdy sought out the examinations had betler mortality ratl'S lhi!l1 the patients who were invited for SCft't'lling. The latter group contained not only compliant patients but also ones who had to bl' persuaded to participate.\n\nBiases due to length time and patient compliance can be avoided by relying on randomized conLrolled trials thilt count all the outcomes in the groups, regardless of the method of diagnosis or degree of participation. Groups of patients that are randomly allocated wiJ] have comparable num- \u2022 \u2022 \u2022 \u2022 o CHAPTER 8 I PREVENTION 181 2 3 4 5 Number of MHCs Figure 8.7. Effect of patient compliance on a screening program. The control group of patients (e) had 8 lower standardized rnort81ity ratio (observed:expected deaths, stand8rdized for age) than the study group offered {OJ screening; but the control group included only patients who requested screening, wllereas the study group included all patients offered screening. MI-JCs, multiphasic health checkups, (Redrawn trom Friedman GO, Collen MF, Fireman BH, Multiphasic health checkup evaluation: a 16-year follow-up. J Chron Dis 1986; 39:453-463.)\n\nbers of s]ow-and fast-growing tumors and, on average, comparable levels of compliance. These groups then can be fol1owed over time with mortality rates, rather than survival rates to avoid lead time bias. Because randomized controlled trials are difficult to conduct, take so long:, and are expensive, investigators sometimes try to use other kinds of studies, such as cohort studies (Chapter 5) or case control studies (Chapter 10), to investigate preventive maneuvers and effectiveness of treatment after screening.\n\nExample To tl;'st whethl;'r pl;'riodic scrl;'ening with sigmoido:;copy rl;'duces mortality from colorectal Cilncer within the reach of the sigmoidoscope,  Selby et al. (15)  investigiltcd the frequency of screening sigmoidoscopy over the previOIlS 10 years alllong patients dying of colorcctal cancer and alllong well pdtil;'nt;;, matchl;'d for age and Sl;'X. To deal with ll;'ad timl;' and ll;'ngth time biasl;'s, they investigated scret'ning only in peuple who were known to hilve died (mse group) or not to hilve died (control group) from colorectal Cilncer. To deal with compliilnce biils, they adjusted their results for the number of generill periodic health examinations each person had. They also adjusted the res\\Jlts for the prescnCl' of medic-ill conditions thilt could have led to both increased screening and incn'ased likelihood of coloredal cancer.\n\nPatients dying of colOfectal cancef in the fectum Of distilnt sigmoid were less likely \\0 have undergone a screening sigmoidoscopy in the previous 10 years (8.8'\\.) than those jn the control group (24.2%), ilnd sigmoidoscopy foJJowed by early lherapy prevented a Imos\\ 60(:'~, of dealhs [rom distal colorectill cancer. Also, by showing thi1t there was no protection for colorectal cancers above the level reached by sigmoidoscopy, the authors suggested that \"it is difficult to conceive of how such ilnatomieal specificity of effect could be <'xplained by confounding.\"\n\nCase series, in which a group of people pilrticipating in il screening program arc followed over time, Me a common but inappropriate method of evaluating the effectiveness of screening progrilms; they Me subject to all the biilses discussed (see Chilpterl0 for more on case series)."
    },
    {
      "title": "How Much Harm for How Much Good?",
      "text": "Health promotion and disease prevention are becoming increasingly popular. The goal of keeping people as healthy as possible is liludable, but as this chapter points out, the concepts behind the goal are complex. Most important, health promotion activities can cause harm. In filet, it is probably bir to say that they usually do cause harm, even though totally lmintended.\n\nAt the ]eilst, they cost money, patients' time and often discomfort. At the worst, they can cause serious physical hilrm in the rMc piltient, either because of complications of the screening test itself or beciluse of adverse consequcnces of subsequent tests or treiltment, particulilfly in patients with false-positive test results. Fillse-positive tests can cause psychological damage as well. Thus it is importilnt thilt the c1iniriiln have solid evidence ilbout how much good ilncl how much harm heillth promotion activities accomplish. Good intentions are not enough.\n\nBefore undertaking il health promotion procedure on a patient, especially if the procedure is controversiill ilm(mg expert groups, the clinician should discuss both the pros (probilbility of known ilnd hoped-for health benefits) and cons (probability of unintended effects) of the procedure with the patient.\n\nExample Although clinical breast examinations and mammography screening for breasl cancer ,lTe universally recommended for older women, there is controversy about screening for women ages 40 to 49; rilndomized controlled trials show that screening does not work \\\\' 10' 11 in this age group, but il protective effect of about 15':;, may still be possible after many years. Expert groups are divided in their H'commend\"tions. When discussing this dilemma with\" patient, it is lJsdul to demonslrate bolh benefits <lnd harms resulting from screening  (Fig 8.8) . Such iln approach not only is more honest with the patient but helps clarify the situation for her so that her consent for whatever is chosen is trulv informed. (ost dfectiveness analvsis formalizes this approach for policymilkus  (16) .\n\n."
    },
    {
      "title": "Current Recommendations",
      "text": "With progress in the science of prevention, current recommendations on health maintenance are quite different from those of the past. Several groups have recommended abandoning routinc annual checkups in favor of a selective approach in which the Lests Lo be donc depend on a person's agc, sex, and clinical characteristics (thereby increasing prevalence and positive predictive value). They have also tended to recommend fewer tests than previously (thereby decreasing the percentage of patients with false-positive results). Several groups h,;1Ve turned their attention to the selection process for deciding what medical conditions should be sought. There is increasing concern for dear delineation of the criteria that tests should meet before they are incorporated into periodic health examinations. Croups with explicit criteria for selecting medical conditions are more conservative in their recommendations than groups without such criteria."
    },
    {
      "title": "Summary",
      "text": "Disease can be prevented by keeping it from occurring in the first place (primary prevention), with interventions such as immunization and behavioral counseling. Such interventions should be evaluated for effectiveness as rigorously as other kinds of clinical interventions.\n\nIl] effects from disease can also b(' prevented by conducting screening tests at a time when presymptomatic treatment is more effective than treatment when symptoms occur (secondary prevention). A disease is sought if the disease causes a substantial burden of suffering, if a good screcning test is available, and if presymptomatic treatment is more effective than treatment at the usual time. Screening tests should be sensitive enough to pick up most cases of the condition sought, specific enough that there are not too many false-positive results, inexpensive, safe, and well accepted by both patients and clinicians.\n\nIn secondary prevention, three potential biases threaten studies of the effectiveness of presymptomatic treatment: failure to account for the lead time gained by early detection, the tendency to dete'Ct a disproportionate number of slowly advancing cases when screening prevalent cases, and confounding the good prognosis associated with compliance with the effects of the preventive intervention itself.\n\nBased on these criteria, i\\ limited number of primary prevention interventions and screening tests for secondary prevention are recommended for health maintenance, according to the age, sex, and clinical status of the patient."
    },
    {
      "title": "CHANCE",
      "text": "When clinici<ln~attempt to learn from clinical experience, whether during forma] research or in the course of patient care, their efforts are impeded by two processes: bias and chance. As we discussed (Chapter 1), bias is systematic error, the result of any process that causes observations to differ systematically from the true values. In clinical research, a great deiJl of the effort is aimed at avoiding bias where possible and controlling for and estimating its effects when bias is unavoidable.\n\nRandom error, on the other hand, is inherent in all observations. It can be minimized but never avoided altogether. Random variation can arise from the process of measurement itself or the biologic phenomenon being measured (Chapter 2). This source of error is called \"random,\" because on average it is as likely to result in observed values being on one side of the true value as on the other.\n\nMost of us tend to overestimate the importance of chance relative to bias when interpreting data. We might say, in essence, \"If pis <0.001, a little bit of bias can't do much harm!\" However, if data are assembled with unrecognized bias, no amount of statistical elegance can save the day. As one scholar put it, perhaps taking an extreme position, \"A well designed, carefully executed study usually gives results that are obvious without a formal analysis and if there arc substantial flaws in design or execution a formal analysis will not help\"  (1) .\n\nIn this chapter, chance is discussed in the context of a controlled clinical trial, because that is a simple way of presenting the concepts. However, application of the concepts is not limited to comparisons of treatments in clinical trials. Statistics are used whenever one makes inferences about populations based on information obtained from samples."
    },
    {
      "title": "Random Error",
      "text": "The observed differences between treated and control patients in a clinical trial cannot be expected to represent the true differences exactly because of random variation in both of the groups being compared. Statistical tests help estimate how well the observed difference approximates the true one. Why not me<lsure the phenomenon directly and do away with this uncertainty? Because research must ordinarily be conducted on a sample of patients <lnd not all patients with the condition under study. As a result, there is always a possibility that the particular sample of patients in a study, even though selected in an unbiased way, might not be similar to the population of patients as a whole.\n\nTwo general approaches are used to assess the role of chance in clinical observations. The first, called hypothesis testillg, asks whether an effect (difference) is present or not by using statistical tests to eX<lmine the hypothesis that there is no differencc (the \"null hypothesis\"). This is the traditional way of assessing the role of chance, popular since statistical testing W<lS introduced at the beginning of this century and associated with the familiar \"p values.\" The other approach, called estimation, uses statistical methods to estimate the range of values that is likely to include the true value. This approach has gained popularity recently and is now favored by most journals for rea~:lOns that we describe below.\n\nWe begin with a description of the traditional approach."
    },
    {
      "title": "Hypothesis Testing",
      "text": "In the usual situation, where the principal conclusions of a trial are expressed in dichotomous terms (e.g., the treatment is considered to be either successful or not) and the results of the statistical test is also dichotomous (the result is either \"statistically significant\"~i.e., unlikely to oe purely by chance~or not), there are four ways in which the conclusions of the test might relate to reality (Fig.  9 .1).\n\nTwo of the four possibilities lead to correct conclusions: (a) when the trcatments really do have different effects and that is the conclusion of the study and (b) when the treatments really have similar effects and the shldy makes that conclusion.\n\nThere are also two ways of being wrong. The treatments under study may actually have similar effects, but it is concluded that the study treatment is better. Error of this kind, resulting in the \"false-positive\" conclusion that the treatment is effective, is referred to as an a or Type 1 error.\n\nAlpha is the probability of saying that there is a difference in treatment effects when there is not. On the other hand, treatment might be effective, but the study concludes that it is not. This \"false-negative\" conclusion is called a f3 or Type II error. Beta is the probability of saying that there is no difference in treatment effects when there is onc. \"No difference\" is a simplified way of saying that the true difference is unlikely to be larger than a certain size. It is not possible to establish that there is no differcnce at all between two treatments. diagnostic test to the true diagnosis (Chapter 3). Here the \"test\" is the conclusion of a clinical tri,ll, based on a statistical test of results from a sample of patients. Reality is the true relative merits of the treatments being compared-if it could be established, for example, by making observations on all patients with the illness under study or a large number of samples of these patients. Alpha error is analogous to a false-positive and (i error to a false-negative test result. [n the absence of bias, random variat ion is responsible for the uncertainty of the statistical conclusion.\n\nBecause random variation plays a part in all observations, it is an oversimplification to ask whether or not chance is responsible for the results. Rather, it is a question of how likely random variation is to account for the findings under the particular conditions of the study. The probability of error due to random variation is estimated by means of inferel1tial statistics, a quantitative science that, based on assumptions about the mathematical properties of the data, allows calculations of the probability that the results could have occurred by chance alone.\n\nStatistics is a specialized field with its own jargon-null hypothesis, variance, regression, power, and modeling-Lhat is unfamiliar to many clinicians. However, leaving aside the genuine complexity of statistical methods, inferential statistics should be regarded by the nonexpert as a useful means to an end. Sti-ltistical tests are the means by which the effects of random variation arc estimated.\n\nThe next two sectiolls discuss a and f3 error, respectively. We will attempt to place hypothesis testing, as it is used to estimate the probabilities of these errors, in context. However, we will make no attempt to deal with these subjectl; in a rigorous, quantitative fashion. for that, we i;uggest that readers consult any of a number of excellent textbooks of biostiltistics (see \"Suggested Readings,\" later in this chapter)."
    },
    {
      "title": "CONCLUDING THAT A TREATMENT WORKS",
      "text": "Most of the statistics encountered in the current medical literature concern the likelihood of an a error and are expressed by the familiar p value. The p value is a quantitiltive estimate of the probilbility that observed differences in treiltment effects in the particul;1r study at hand could have happened by chance alone, assuming that thcre is in fact no difference between the groupi;. Another way of expressing this is that p is an answer to the question, If there were no difference between treatments and the trial was repeated many times, what proportion of the triills would lead to the conclusion that a treatment is as or more effective thiln found in the study?\n\nWe will call the p value \"p,,\" to distinguish it from estimates of the other kind of error due to random variation, f3 error, which we will refer to as \"Pi/' When a simple Pis found in the scientific literature it ordinarily refers to what we call p\".\n\nThe kind of error estimated by p\" applies whenever it is concluded that one trmtment is more effective than another. If it is concluded that the p\" exceeds some limit and so there is no difference between treatments, then the particular value of p\" is not as relevant; in that situation, PiJ (probability of f3 error) applies."
    },
    {
      "title": "DICHOTOMOUS AND EXACT P VALUES",
      "text": "It has become customary to attach speciill significance to p values falling below 0.05 because it is generally agreed that less than 1 chance in 20 is a small risk of being wrong. A rate of 1 in 20 is so small, in fact, that it is reasonable to conclude that such an occurrence is unlikely to have arisen by chance alone. It could have arisen by chance, and 1 in 20 times it will. But it is unlikely.\n\nDifferences associated with p\" less than 0.05 are called \"statistically significant.\" Tt is important to remember, however, that setting a cutoff point at 0.05 is entirely arbitrary. Reilsonable people might accept higher villues or insist on lower ones, depending on the consequences of a falsepositive conclusion in a given situation.\n\nTo ilccommodate various opinions about what is and is not unlikely cnough, some researchers report the exact probabilities of p\"s (e.g., 0.03, 0.07, 0.11, etc.), rather thiln lumping them into two ciltegories, <U.05 or >0.05. The interpretation of what is statistically significant is then left to the reader. However, p Vil]ues greater than 1 in 5 ilre usually reported as simply p > U.20, becaui;e nearly everyone can agree that a probability of an a error that is grmter than one in five is unacceptably high. Simi]ilr]y, below very low Ii villues (such as p (l.OOl) chance if; il vcry unUkely explanation for the observed differenCl\" and little further information is imparted by describing this chJnce more precisely."
    },
    {
      "title": "STATISTICAL SIGNIFICANCE AND CLINICAL IMPORTANCE",
      "text": "A statisticaJJy f;ignificilnL difference, no matter how smJII the p, does not mean that the difference is dinicJlly important. A p < 0.0001, if it emerges from a well-def;igned study, conveys a high degree of confidence that a difference really exists. But this Ii villue tells us nothing about the magnitude of that difference or itf; dinic;:l1 importance. In fact, entirely trivial differences may be highly statistically significant if a large enough number of patients '''/(IS studied.\n\nExamplr In the carll' 1990s there was a hCillcd debate about which thrombolytic ilgt'nl, stt\u2022cptokinase or tissue plasmin0i-\\('n il(liv;;Jlor (tPA), is most effective during ilcote myocilfliiill infarction, Large trials had shov,in iI difference in reperfusion riltes but nol mortality. The two were (ompal\"('d (along with subcutaneous nr intrilVt'nous heparin) in a brge randomized controlled trial. called CUSTO, involvini-\\ 4'1,021 piltiel1ts in 15 countries (2), tl'A Ivas givcn by a more aggressive regimen than in carlier studies. The death rate at 30 days WilS lower among patients receiving: tl'A (63\\,) (h,ln among those receiving: streptokinil-Sl' (7.2 or 7.4%, depending on how heparin was given) and this difference was highly unlikely to be by chance (p ().OOI), However, the difference is not large; one would have to treat about 100 patients vl'ith tl'A inskad of with streptokinase tn pr('vent onl' short-term death. Because trA is Illuch Illore ('xpl'nsive than streptokinaseit would cost nearly $250 thousand to prevent that death (3)-and because trA is mOl\"(' likely to cause hemorrhagic strokes, smne have questioned whether the marginal bendit of tl' A is worl hwhi Ie, Le., whether the differem',' in mortality between trA and streptokinilse (reatment, all things considered, is \"clinically significant:\u2022 On the other hand, very unimpressive p values can result from studies showing strong treatment effects if there afe few patients in the study (sec the following section),"
    },
    {
      "title": "STATISTICAL TESTS",
      "text": "Commonly llsed statistical tests, familiar to many readers, are used to estimate the probability of an a error. The tests arc applied to the data to give a test statistic, which in turn can be used to omH' up with a probability of error (Pig. 9.2). The tests Me of the l1ul/ h.llpofhe.c.i.s, the proposition that there is no true difference in outcome benveen the 1\\'/0 treatment groups. This device is for mJthematici:ll reasons, not because \"no difference\" is the working f;cientifir hypothesis of the study. One ends up Yt'jeding the null hypothesis (concluding there is a difference) or failing to reject it (concluding there is no difference). Some commonly used st,ltisticallcsts are listed in\n\nTable 9.1. The validity Observed Rates I 'TT [xceedrng -rhw~h(Jld Nomogram SlanrJard care TotiJl Yes 60 3i 97 No , 11 13 rulHI 62 48 110\n\nHow likely would it be for a study of this size to observe a difference in rates al; great as thil; or greater if there were in fact no differences in effectivenel;S? That depends on how far the observed results depart from what might hilve been expected if the treatmentl; were of similar value ilnd only random variation caused them to differ in the samples studied.\n\nIf treatment had no effect on outcome, applying the success rate for the p<ltients as a whole (8W'!<,) to the number of patients in each treatment group gives the expected number of I;uccesses in each group:\n\nExpected Rates (Rounded to Nearest Integer) PTI I::xceedinq Threshold Nomogram Stand<Jrd care rotal Yes No Total 55 7 62 42 6 48 97 13 110\n\nThe X 2 st<Jtistic, which quantitates the difference betw\"een the observed and expected numbers, is the sum for all four ce]]s of:"
    },
    {
      "title": "Expected number",
      "text": "The magnitude of the X 2 statistic is determined by how different all of the observed numbers are from what would be expected if there were no treatment effect. Because they are squared, it does not matter whether the observed rates exceed or fall short of the expected. By dividing the squared difference in each cdl by the cxpl'cted number, the difference for that cell is adjusted for the number of patients in that cell.\n\nThe X 2 statistic for these data is\n\nThis X 2 is then compared to a t<lble rdating X 2 values to prob<lbilities (available in books and computer programs) for that number of cells, to obtain the probability ofaX2 that l<lrge or larger. It is intuitivdy obvious that the larger the X 2 , the less likely chance is to account for the observed differences.The result in this case is p = 0.004, which is the probability of a false-positive conclusion that the trcatments had different effects."
    },
    {
      "title": "CONCLUDING THAT A TREATMENT DOES NOT WORK",
      "text": "Some trials come to the conclusion tha.1 neither treatment is better than the other. There are some very influential examples, including shtdies showing that coronary artery bypass surgery does not prolong life in patients with chronic stable angina (except for those with left main coronary artery obstruction), that antioxidents do not prevent cancer, and that antibodies against endotoxin do not improve the prognosis of most patients with septic shock.\n\nThe question arises, could results like these have occurred by chance alone? Could the findings of such trials have misrepresented the truth because these particular studies had the bad luck to turn out in relatively unlikely ways? Specifically, what is the probability of a false-negative result (a f3 or Type II error)? The risk of a false-negative result is particularly large in studies with relatively few patients.\n\nBeta eITor has received less attention than a error for several reasons. It is more difficult to calculate. Also, most of us simply prefer things that work. Negative results arc unwelcome: authors are less likely to submit negative studies to journals and if negative studies are reported at all, the authors may prefer to emphasize subgroups of patients in which treahnent differences are found, even if the differences are not statistically significant. Authors may also emphasize reasons other than chance for why true differences might have been missed. Whatever the reason for not considering the probability of f3 error, it is the m<lin question that should be asked when the results of a study indicate no difference.\n\nThe probability that a trial will find a statistically significant difference when a difference really exists is called the statistical power of the trial."
    },
    {
      "title": "Statistical power = 1 --pf3",
      "text": "Power and prJ are complell1l'!ltary ways ofe:xpressing the saine collcept. Power is ana/ogolls to the sCllsitivity of a diasnostic test. 1n faet, one speaks of (j study being powe/illl if it has a high probability of ddectins as di;ffercnt treatments that rcally arc differenl."
    },
    {
      "title": "HOW MANY PATIENTS ARE ENOUGH?",
      "text": "Suppose you are reading about a clinical trial comparing a promising new therapy to the current form of treatment. You are aware that r<lndom variation can be the sourcc of whatever differences are observed, and you wonder if the number of piJtients (sample _~ize) in this study is large enough to make chance an unlikely explanation for wh\"t was found. How many patients would be necessary to make an adequate comparison of the effects of the two treatments? The answer depends on four characteristics of the study: the miJgnitude of the difference in outcome between treatment groups, p\", pfj, and the nahlre of the study's data. These are taken into account when the researcher plans the study and when the reader decides whether the study has a reasonable chance of giving a useful answer."
    },
    {
      "title": "Effect Size",
      "text": "Sample size depends on the magnitude of the difference to be detected. We are free to look for differences of any magnitude, and of course, we hope to be able to detect even very small differences. But more piJtients are needed to detect small differences, everything else being equal. So it is best to ask only that there is a sufficient number of patients to detect the smallest degree of improvement thiJt would be clinically meaningful. On the other hand, if we Me interested in detecting only very large differences between treated and control groups (i.e., strong treatment effects), then fewer patients need be studied."
    },
    {
      "title": "Alpha Error",
      "text": "Sample size is also related to the risk of an a error (conduding that treatment is effective when it is not). The acceptable size for a risk of this kind is a value judgment; the risk could be as large as 1 or as small as O.\n\nIf one is prepared to accept the consequences of a large chance of falsely concluding that the therapy is valuable, one can reach conclusions with relatively few patients. On the other hand, if one wants to take only a small risk of being wrong in this way, a larger number of patients will be required. As we discussed earlier, it is customary to set p\" at 0.05 (1 in 20) or sometimes 0.01 (I in 100)."
    },
    {
      "title": "Beta Error",
      "text": "The chosen risk of a /j error is another determinant of sample size. An acceptable probability of this error is also a judgment that can be freely made and changed, to suit individual tastes. Probability of 13 is often set at 0.20, a 20% chance of missing true differences in a particulM study. Conventional (J errors are much larger than a errors, reflecting the higher value usually placed on being sure an effect is really present when we say it is."
    },
    {
      "title": "Characteristics of the Data",
      "text": "The statistical power of a study is also determined by the nature of the data. When the outcome is expressed on a nominal scale and so is described by counts or proportions of events, its statistical power depends on the rate of events: the larger the number of events, the greater the statistic<ll power for a given number of people at risk. As Pete et al. (  5 ) put it,\n\nIn clinical trials of time to death (or of the time to some other particular \"evt'nt\" -rdapst', metastasis, first thrombosis, stroke, recurrence, or time to death from a particular cause), the ability of the trial to distinguish between thl;' merits of two treatments depends on how many patients die (or suffer a relevant event), rather than on the number of patil;'nts entered. A study of 100 patients, 50 of whom die, is about as sensitive as a study with 1000 patients, 50 of whom die.\n\nIf the outcome is a continuous variable, such as blood pressure or serum cholesterol, power is affected by the degree to which patients vary among themselves: The greater the variation from patient to patient with respect to the ch<lracteristic being measured, the more difficult it is to be confident that the observed differences (or lack of difference) ben\\'een groups is not because of this variation, rather than a true difference in treatment effects. In other words, the larger the variation among patients, the lower the statistical power.\n\nIn designing a study, the investigator chooses the size of treatment effect that is clinically important and the Type I and Type II errors he or she will accept. It is possible to design studies that maximize power for a given sample size-e.g., by choosing patients with a high event rate or similar characteristics-as long as they match the research question. But for a given data set and question the investigator cannot control the way that the characteristics of the data determine statistical power."
    },
    {
      "title": "INTERRELATIONSHIPS",
      "text": "The interrelationships among the four variables discussed above are summarized in Table  9 .2. The variables can be traded off against each other. Tn general, for any given number of patients in the study there is a trade-off between a and f3 error. Everything else being equaL the more\n\nTable 9,2 Determinants of Sample Size one is willing to accept one kind of error, the less it will be nece~sary to risk the other, Neither kind of error is inherenl1y Norse than the other. The consequencc~of accepting erroneous information depend on the dinical ~ituation. When a better treatment is badly needed (e.g., when the disease is very dangerous and no satisfactory alternative treatment is available) and the proposed trc<ltment is not dangerous, it would be reasonable to accept a rc1<ltively high risk of conduding a new treatment is effective when it really is not (large u enol') to minimize the pos~ibility of missing a valuable tn'<Itment (small /3 error). On the other hand, if the discilse is less serious, alternative tn'iltments are availablc, or the new treahnent is expen~ive or dangerous, one might want to minimize the risk of accepting the new treatment when it is not really efredive (low IX error), even at thc expense of d relatively large challce of mis~ing an effective treatment (large /3 error). Tt is of course possible to reduce both a and (i errors if the number of patients is incn'<lsed, outcome events <lre more frequent, variability is decreabcd, OJ a larger treatment effect is f>ought.\n\nFor conventional levels of p\" and Pi)' the relationship between the size of the treatment effect and the number of patientf> needed for a trial if> illustrated by the following examples, one representing d situation in which a relatively small number of patients was sufficient and the other in which a very large numbcr of patients WdS required.\n\nExample Small sample si7,c: Case s<'ries sugglCst thilt the nonsleroidal antiinflammatory drug sulindac is active \"gainSl colonic polyps. This possibility wa~te'5ted in a randomized tri<ll  (6) . A total of 22 patient'5 with famili<ll adenomatous polyposis were randomized; 11 r\"cdved sulind<lC and II pla-cebo_ After Y months, patients receiving 5ulindac had <1n Hv\"ragc of 44'1'0 fewer polyps than those receiving placebo. This difference was statistically significant (p =-0.(  14 )-Because of lhe larK\" effect size ,md tile large number of polyps per patient ('5ome had more than IOU), few patit'nts were needed to establish that the effecl was beyond cham:\". (In lhis ,l/M]ysis it was ne(l'Ss ary to assume that treatmenl affected polyps independently of vl'hich patient tht,y occurred in---an unlih'ly, but prohably not damilging, assumption.)\n\nExample Large sample size: The GUSTO lrial, dlCscribed above, WilS designed to include 41,000 patients to have a YO':;, chance of detecting a 15'%. reduction in mortality or a 1'%, decH'ilse in mortalilV rate, whichever was larger, betwlCen the experimental and conlrol treat!ll~nts with a pa of ll.05, assuming the lllOrtalily rate in the control paUents was at least R% (2). The sample si;>;e had to he so large h<'cause a relatively small proportion of Pilt ients experienced the outcome event (death), the effect size was small (L,)'~(,), and the investigators wanted a relatively high chance of detecting the efflCct if it were present (90%).\n\nFor m{lst of the therapeutic questions encountered today, a surprisingly large number of patients is required. The value of dramatic, powerful treiltments, such as insulin for diabetic ketoacidosis or surgery for append i-citis, could be established by studying a small number of patients. But such treatments come along rarely and many of them CHI.' already well established. We arc left with diseases, many of them chronic and with multiple, interacting causes, for which the effects of new treatments are generally small. This places special importance on whether the size of clinical trials is adequate to distinguish real from chance effects.\n\nClinicians should be able to estimate the power of published shldies. Toward that end, Figure  9 .3 shows the relationship between sample size and treatment difference for several baseline rates for outcome events. It is apparent that studies involving fewer than 100 patients have a rather c. poor chance of detecting statistically significant differences of even large treatment effects. Also, it is difficult to detect dfect sizes of less th;;m 25'\\,. Tn practice, statistic'll power can be estimJted by means of readily available formulas, tables, nomograms, or computer progTilms."
    },
    {
      "title": "Point Estimates and Confidence intervals",
      "text": "The effect size (e.g., treJtment dfect in a clinical trial or relative risk in a cohort study) observed in ,1 particular study is called the poiJlII'slimlllc of the effect. It is the best estimate from the study of the true effect size and is the summary statistic usually given the most emphasis in reports of research.\n\nf Towever, the true dfect size is unlikely to be exactly that observed in the study. Because of rJndom variation, Jny one study is likely to find il result higher or lovver thilll the true value. Therefore, a summary medsure of the extent of variation that might be expected by chance is needed.\n\nThe statistical precision (stability of the estimate) of an observed dfect size is expressed as a (ou(J'dencc il1term/, usually the 9.5'};, confidence interval, around the point estimate. Confidence intervals around an effect size are interpreted in the fol1mving mJnner: if the study is unbiased, there is ,1 95'\\,;, chance that the intprval includes the true dfect size. The narrower the confidence interval, the more certain one can be about the size of the true effect. The lrue value is most likely to be dose to the point estimate, less likely to be near the outer limits of the interval, and could (5 times out of 100) fall outside these limits altogether. Statistical precision increases with the statistical power of the stuJy.\n\nConfidence intervals cuntain information similar to statistical significance. If the value corresponding to no effect (such as a rdative risk of 1 or a treatment difference of 0) falls outside the 95'~;) confidence intervals for the observed effect, it is likely that the results are statisticillly si b 'llificant ilt the 0.05 level. If the confidence intl'rvJls include this point, the results are not statistically significant.\n\nBut confidence intervals have other advilntages. They put the emphasis where it belongs, on the size of the effect. Confidence intervals illlow the reader to sec the range of plausihle values and so to decide whether an effecl size they regard as clinically mpaningfuJ is consistent with or ruled out by the data  (7) . They also provide information about statistical power; if the confidence interval barely includes the value corresponding to no effect and is relatively wide, a signifiGll1t difference might have been found if the study had hJd more power.\n\nExample Figure  9 .4 illustrates point ('slinlates and confidence intervals for the estimJted relative risk of exogenous estrogens for three diseases: endometrial cancer, bn'asl CJncer, ,md hip frarlure. (!'-Joticc that the risk is on a log scale, giving the sUjlc!\u2022licial impression th;]l confident\"(' intervals for tille higher risks arc narrower lh<Jn they really are.) The estimate of risk lor endometrial cancer (illter 8 or mure year~of estrogens) is 8.22, but the true v,llue i~not precisely estimated and could easily be ,l~high <JS 10.61 or as low as 6.2,:;, In any case, it is unlikelv to be il~low ilS 1.0 (no ri~k). In contrast, this one study sLlggesls thilt e~lrog<'ns are unlikely to be a risk factor for breast cancer; the be~t <'stimak of relative risk is nearly 1.0, although the d,lt,1 Me consistent with either a small h.umful or a sm,l]J prolectiV<' dfeet. Finally, estrogens Me likely to protect again~l hip frilclure. That the upper boundary uf the confidence interval falls below ].0 is another way of indicating that the protectivc dfect is ~l,lli~tically significant at the 0.05 level.\n\nPoint estimates and confidence intervills are used to characterize the st<ltistical precision of any rate (incidence and prev<l1cnce), comparisons of T<lks (relative and attributable risks), and other summary statistics. l-ior example, individual studies have shown that :14% of U.s. adults have used unconventional therapy (95'X, confidence interval 31-37%)  (8) , that intensive treatment of insulin-dependcnt diabetes lowers the risk of development of retinopathy by 76(~;' (95\u00b0/', confidence interval 62-85%) relative to conventional therapy  (9) , and that the sensitivity of clinical examination for splenomegaly is 2n;, (95% confidence interval 19-36')';,)  (10) .\n\nConfidence intervals havc become the usual way of reporting the main results of clinical research because of their many advantages over the hypothesis testing (p value) approach. The p values are still used because of traditioll and as a convenience when many results are reported and it would not be feasible to include confidence intervals for all."
    },
    {
      "title": "Statistical Power before and after a Study Is Done",
      "text": "Ca lculation of statistical power based on the hypothesis testing approach is done by the researchers before a study is tmdertaken to ensure that enough patients will be entered to have a good chance of detecting a clinically meaningful effect if it is present. However, after the study is completed this approach is no longer as relevant  (11) . There is no need to estimate effect size, outcome event rates, and variability among patients; they are now known.\n\nTherefore, for researchers who report the results of clinical research and readers who try to understand their meaning, the confidence interval approach is more relevant. One's attention should shift from statistical power for a somewhat arbitrarily chosen effect size, which may be relevant in the planning stagc, to the actual effect size observed in the study and the statistical precision of that estimate of the true value."
    },
    {
      "title": "Detecting Rare Events",
      "text": "It is sometimes important to detect a relatively uncommon event (e.g., 1/1000), particularly if that event is severe, such as aplastic ,memia or Iifcthreatening arrhythmia following a drug. In such circumstances, a great many people must be observed in order to have a good chance of detecting ('ven one such event, much less to develop a rdatively stable estimate of its frequency.\n\nFigure  95  shows the probabHity of detecting an event as a function of the number of people under observation. A rule of thumb is as follows:\n\nTo have a good chance of detecting a l/x event one must observe 3x people  (12) . For example, to detect a 1/1 OUO event, one would need to observe 3000 people."
    },
    {
      "title": "Multiple Comparisons",
      "text": "The statistical conclusions of research have an aura of authority that defies challenge, particularly by nonexperts. But as many skeptics have suspected, it is possible to \"lie with statistics,\" even if unintentionally.\n\nCHAPTtJ-1 9 CHANCE 201 Risk 1 1 1 1 ----100 1,000 10,000 100,000 1 .0 . g u 0.8 -C 0.6 -0 >-'\" 0.4 s:l co s:l 0.2 0 D.\n\n-I I 1,000\n\n10,000 100,000 1,000,000 Size of Treatment Group Figure 9.5. The probability of detecting one event according to the rate of the event and the number of people observed, (From Guess HA, Rudnick SA, Use at cost effectiveness analysis in planning carlCRr chemoprophylaxis trials, Control Clin Trials 1983:4:89-100.)\n\nWhat is more, this is possible even if the research is well designed, the mathematics flawless, and the investigators' intentions beyond reproilch. Statistical conclusions can be mislmding because the strength of stiltistical tests depends on the number of research questions considered in the study and when those questions were asked. If many comparisons arc made among the variables in a large set of data, the p value associated with each individual comparison is an underestimate of how often the result of that comparison, ilmong the others, is likely to arise by chance. I\\s implausible as it might seem, the interpretation of the p value from a single statistical test depends on the context in which it is done.\n\nTo understand how this might happen, consider the following example. Suppose a large study has been done in which there ilrc multiple subgroups of patients and many different outcomes. ror instance, it might be a clinical trial of the value of a treatment for coronary artery disease for which patients arc in several clinically meaningful groups (e.g., 1-, 2-, and 3vessel disease; good and bad ventricular function; the presence or absence of arrhythmias; and various combinations of these) and several outcomes are considered (e.g., death, myocardial infarction, and angina). Suppose also that therc arc no true associations between treatment and outcome in any of the subgroups and for any of the outcomes. Finally, suppose that the effect~of treatment are as~e~~ed separately for each subgroup and for each outcome-a process that involves a great many comparisons. As pointed out earlier in this chapter, I in 20 of these comparisons is likely to be statisticillly significant at the 0.05 level. In the general case, if 20 comparison~ilre made, on the average, 1 would be found to be statistically significant; if 100 comparisons are made, about 5 would be likely to emerge as significant, ilnd so on. Thus, when a great many comparisons have been made, a few will be fOlUld that are unusual enough, because of random variation, to exceed the level of stati~tical significance even irno true assl}Ciations between variilbles exist in nature. The more comparisons that are made, the more likely that one of them wHl be found statistically significant.\n\nThis phenomenon i~referred to as the multiple comparisons problem.\n\nBecau~e of this problem, the strength of evidence from clinical research depends on how focu~ed its questions were at the outset.\n\nUnfortunately, when the results of research are presented, it i~not al-way~possible to know how many comparisons really were made. Often, intere~ting findings arc selected from a larger number of uninteresting one~. This process of deciding what is and is not important about a mass of data can introduce considerilble distortion of reality.\n\nHow can the statistical effects of multiple comparisons be taken into account when interpreting research? Although ways of ildjusting p\" have been proposed, probably the best advice is to be aware of the problem and to be cautious about ilccepting positive conclusions of studie~where multiple comparisons were made. As one statistician  (13)  put it:\n\nIf you dredge the data sufficiently deeply and sufficiently often, you will find something odd. M;my of these bizarre findings will be due to chance. I do not imply thai data dredging is not iln occupation for honorable persons, but rather that discoveries that wefe nol initially postulatl.'d as among the major objectives of the trial should be treated with extreme caution. Statistical theory milY in dul;' course show us how to allow for such incidental findings. At present, I think the best attitude to adopt is caution, coupled with an attempt to confirm or rdute the findings by further studies.\n\nAn approach to asse~sing the validity of ~tati~ticallysignificant findings in subgroups was presented in Chapter 7."
    },
    {
      "title": "Describing Associations",
      "text": "Statistics are also u~ed to describe the degree of association between variables, e.g., the re-lation~hip between body ma~s and blood pressure. Familiar expressions of a~sodation are l'earson'~product moment correlation (r) for interval data and Spearman's rank correlation for ordinal data. Each of these statistics expre~ses in quantitative terms the extent to which the value of one variable is associated with the value of another. Each has a corresponding statistical test to assess whether the observed association is greater than might have arisen by chance alone."
    },
    {
      "title": "Multivariable Methods",
      "text": "Most clinical outcomes are the result of many variables acting together in complex way,;. For example, coronary heart disease is the joint result of lipid abnormalities, hypertension, cigarette smoking, family history, diabetes, exercise, and perhaps personality. It is appropriate first to try to understand these relationships by examining relatively simple arrangements of the data, such as 2-by-2 tables (for one variable at a time) or contingency tables (stratified analyses, examining whether the effect of one variable is changed by the presence or absence of one or more other variables), because it is easy to understand the data when they arc displayed in this way. However, it is usually not possible to account for more than a few variables using this method, because there arc not enough patients with each combination of characteristics to allow stable estimates of rates. For example, if 120 patients were studied, 60 in each treatment group, and just one additional dichotomous variables were taken into account, there would only be at most about 15 patients in each subgroup; if patients were unevenly divided, there would be fewer in some.\n\nWhat is needed then, in addition to contingency tables, is a way of examining the effeels of several variables at a time. This is accomplished by multivariable modeling, developing a mathematical expression of the effects of many variables taken together. It is \"multi variable\" because it examines the effects of multiple variables simultaneously. It is \"modeling\" because it is a mathematical construct, calculated from the data but also based on simplifying assumptions about characteristics of the data (e.g., that the variables arc all normally distributed and have the same variance).\n\nMathematical models cun be used in studies of cause, when onc wants to define the independent effect of one variable by adjusting for the effects of several other, extraneous variables. They can also be used to give mOTe precise predictions than individual variables allow by including several variables together in a predictive model.\n\nThe basic structure of a multivariable model is Outcome variable = constant + (/31 X variable]) + (/32 X variabl(2) + .\n\nwhere /31, /32< . arc coefficients that are determined by the data; and variable\" variable\",. . are the predictor variables that might be related to outcome. The best estimates of the coefficients are determined mathematically, depending on the powerful calculating ability of modern computers.\n\nModeling involves severdl steps.\n\n\u2022 Identify and measure all the vilriilbles thilt might be related to the outcome of interest. \u2022 Reduce the number of viHiables to be considered in the model to a manageable number, usually no more than several. Often this is done by selecting variables that are, when taken one at a time, most strongly related to outcome. If a statistical criterion is used at this stage, it is usual to err on the side of including variables, e.g., by choosing all variables showing an association with the outcome of interest at a cutoff level of p < 0.10. Evidence for the biologic importance of the variable is also considered in making the selection. \u2022 Some variables may be strongly related to each other. If so, only one is included since both contain about the same information. \u2022 The remaining variables aIe entered in the model, with the strategy for the order in which they aIC tried determined by the research question. For example, if some are to be controlled for in a causal analysis, they are entered in the model first, followed by the variable of primary interest. The model will then identify thc independent effect of the main variable. On the other hand, if the investigator wants to make a prediction based on several variables, the variables can be entered in order of the strength of their association to the outcome variable, as determined by the model.\n\nModeling is now a regular feature of the medical literature, appearing in about 18% of articles in major journals  (14)  and in nearly all large studies of cause. Some commonly used kinds of the models are logistic regression (for dichotomous outcome variables such as occur in case-control studies) and Cox proportioned hazards models ({or time-to-event studies).\n\nMultivariable modeling is an essential part of many clinical studies; there is no other way to adjust for or to include many variables at the same time. Hmvever, this advantage comes at a price. Models tend to be black boxes, and it is difficult to \"get inside\" them and understand how they work. TIleir validity is based on assumptions about the data that may not be met. They are clumsy at recognizing effect modification (different effects in different subgroups of patients). An exposure variable may be strongly related to outcome yet not appear in the model because it occurs rarely-and there is little direct information on the statistical power of the model for that variable. Final1y, model results are easily affected by quirks In the datil, the results of random variaLion in the characteristics of patients from s<lmple to s<lmple. It has becn shown, for example, that a model frequently identified a different set of predictor variables ilnd produced a different ordering of variables on different random samples of the Silme data set  (15) . To protect against this possibility, a rule of thumb is that there should be at least 10 outcome events for each predictor variable in the model.\n\nfor these reasons, the models themselves cannot be taken as a standard of validity; they must be independently validated. Commonly, this is done by seeing if the model predicts what is found in another, independent sample of patients (see  Chapter 12) . The results of the first model are considered a hypothesis, to be tested by new data. If random variation is mainly responsible for the results of the first model, it is unlikely that the same random effects will occur in the validating data set too. Other evidence for the validity of a model is its biologic plausibility and its consistency with simpler, mOTC transparent analyses of the data such as stratified analyses."
    },
    {
      "title": "Summary",
      "text": "Clinical information is based on observations made on samples of patients. Even samples that are selected without bias may misrepresent events in a larger population of such patients because of random variation in its members.\n\nTwo general approaches to assessing the role of chance in clinical observations arc hypothesis testing and estimation. With the hypothesis testing approach, statistical tef;ts are used to estimate the probability that the observed result was by chance. Vv'hen two treahnents arc compared, there are two \u2022ways in which the conclusions of the trial can be WTOng: The treatments may be no different, and it is concluded one is better; or one treatment may be better, and it is concluded there is no difference. The probabilities that these errors will occur in a given situation arc called pI) and p~, respectively.\n\nThe power of a statistical test (1 -fill) is the probability of finding a statistically significant difference when a difference of a given size really exists. Statistical power is related to the number of patients in the trial, size of the treahnent effect, J!\", and the rate of outcome events or variability of responses among patients. Everything else being equal, power can be increased by increasing the number of patients in a trial, but that is not always feasible.\n\nEstimation involves using the data to define the range of values that is likely to include the true effect size. Point estimates (the observed effects) and confidence intervElls are used. This approach has many advantages over hypothesis testing: It emphasizes effect size, not II value; indicates the range of plausible values for the effect, which the user can relate to clinically meaningful effects; and provides information about power.\n\nlndividual studies run an increa~C'd risk of reporting a false-positive result if many subsets of the data are compared; they are at increased risk of a false-negative result if they lack statistical power, usually because they include too few patients or outcome events are ul':.common.\n\nMost clinical studies concern the effects of multiple interacting variables. With multivariable modeling, it is possible to take all into account simultaneously, either to control for extraneous variables in a causal study or to provide a stronger prediction than would be possible by including nne variable at a time. However, these models must be interpreted \\vith caution because their inner workings arc relatively inaccessible, they are sensitive to random variation, <Ind they are based on assumptions that may not be met."
    },
    {
      "title": "STUDYING CASES",
      "text": "Eacii case lias its lesson-a lesson which may be but is not always learned.\n\n-Sir William Osler\n\nMost medical knowledge has emanated from the intensive study of sick patients. The exhausted but engrossed physician at the bedside of the febrile child, chin in hand, is a f<lV(Jrite medical image. The presentation and discussion of a \"case\" is the foundation of modern medical education. Most clinicopathologic conferences and grand rounds begin with the presentation of an interesting case and then use the GHil;' to illustrate general principles and relationships. So, too, much of the medical literature is devoted to studying cases, whether narrative descriptions of a handful of cases (case reports), quantitative analyses of larger groups of patients (case series), or comparisons of groups of cases with noncases (cilse control studies)."
    },
    {
      "title": "Case Reports",
      "text": "Cilse reporls Me detailed presentations of il single case or a handful of Cilses. They represent an important way in which new or unfamiliar diseases, or milnifestations or ilssociations of disease Me brought to the attention of the medicill community. Approximately 20-30~;, of the original ilrticles published in miljor generill medical journals are studies of 10 or fewer patients."
    },
    {
      "title": "USES OF CASE REPORTS",
      "text": "Case reports serve sever,d different purposes. First, they ilre virtually our only means of describing rare clinical events. Therefore, they Me a rich source of ideas (hypotheses) about disease presentation, risk, prognosis, and treatment. Case reports rarely can be used to test these hypotheses, but they do place issues before the medical commlUlity and often trigger 208 more decisive studies. Some conditions that were first recognized through case reports include birth defects from thalidomide, fetal alcohol syndrome, toxic shock syndrome, Lyme disease, and HANTA virus infection. Case reports also serve to elucidate the mechanisms of disease and treatment by reporting highly detailed and methodologically sophisticated clinical and laboratory studics of a patient or small group of patients. In this instance, the complexity, cost, and often experimental nature of the investigations limit their application to small numbers of patients. Such studies have contributed a great deal to our understanding of the genetic, metabolic, and physiologic basis of human diseases. These studies represent the bridge between laboratory research and clinical rescarch and have a well-established place in the annals of medical progress.\n\nThe following is an example of how a report of a single case can reveal a great deal about the mechanism of a disease.\n\nExample The anesthetic halothane was suspected of causing hepatitis. However, because the frequency of hepatitis after exposure to ha lothane was low and there were many other causes of hcpatitis ilfter surgery, \"hillothane hepiltitis\" was controversial.\n\nExperience with a single individual helped clarify the problem (I). An anesthetist was found to have recurrent hepatitis, leading to cirrhosis. Attacks of hepatitis regularly occurred within hours of his rdurn to work. When he was exposed to small doses of halothane under experimental conditions, his hepatitis recurred and was well documented by clinical observiltions, biochemical tests, and liver histology.\n\nBecause of this unusual case, it was clear that halothane can cause hepatitis. But the Cilse report provided l1() inf()rmation as to \\v hether this reaction was rare or common. Subsequent studies showed that it was not a rare reaction, which contributed to the replacement of halothane with less hepatotoxic agents.\n\nAnother use of the case report is to describe unusual manifestations of disease. Sometimes this can becollle the medical version of Ripley'S Be/ie-ve l! or Not, an informal compendium of medical oddities, with the interest lying in the sheer unbelievability of the case. The larger the lesion and the more outrageous the foreign body, the more likely a case report is to find its way into the literature. Oddities that are simply bizarre aberrations from the usual course of events may titillate, but usually are less clinically important than other types of studies. Some so-caned oddities are, however, are the result of a fresher, more insightful look at a problem and prove to be the first evidence of a subsequently useful finding. nlC problem for the reader is how to distinguish between the freak and the fresh insight. There are no rules. When all else fails, one can only rely on common sense and a well-developed sense of skepticism."
    },
    {
      "title": "BIASED REPORTING",
      "text": "Because case reports involve a small and highly selected group of patients, they are particularly susceptible to bias. For example, case reports of successful therapy may be misleading because journals <lfe unlikely to receive or publish case reports of unsuccessful therapy. Perhaps the wisest stance to take when reviewing a case report is to use it as ,1 signal to look for further evidence of the described phenomenon in the literature or among your patients.\n\nExample A case report (  2 ) described a 23-year-old woman who deve!\" oped severe abdominal pain while on treatment with enalapril for essential hypertension. An elevated serum lipase led to a diagnosis of pancreatitis. Symptoms resolved, and the lipase returned to normal shortly after discontinuing the drug. The investigators found only one published case and began an exhaustive search of the published and unpublished literature. The search revealed an additional flO cases, the majority of which were unpublished cases reported to the drug manufacturl:'T. The i1dditional cases lent strength to the possibility of a causal association betwl:'en enalapril treatment and pancn.\u2022atitis.\n\nWith very few exceptions, case reports on their own should not serve as the basis for altering clinical practice because of their inability to estimate the frequency of the described occurrence or the role of bias or chance."
    },
    {
      "title": "THE JOINT OCCURRENCE OF RARE EVENTS",
      "text": "Case reports often describe the joint occurrence of uncommon events, particularly if the observed association lends itself to an interesting biologic explanation. But even rare events occur together by chance alone; simply observing thif; occurrence does not mean they are biologically related. As one author (3) put it, \"In a large population the issue is not whether rare events occur, but whether they occur more frequently than expected by chance.\" Table  10 .1 ilJustrates how often two relatively uncommon conditionsend-stage renal failure and use of a specific nonsteroidal antiinflammatory drug-might occur together by chance alone. If there were no biologic association between the two (and, as discussed later in this chapter, there may we]] be such an association), then the probability that they would occur together is the product of their separate frequencies. In the United States alone, 100 cases would occur annually, more than enough to spawn severnl case reports.\n\nThere an.' also reasons why such cases might be f;cen in medical centers and be reported in the literature out of proportion to their frequency in the population at large. Patients with two severe diseases might be more likely to come to hospitals than those with either disease alone, simply because they are sicker. It has also been shown that two discilses not"
    },
    {
      "title": "CLINICAL EPID[MIOlOGY",
      "text": "This report includes no comparison group of people without AIDS. Also, the definition of cases excluded some patiellts who have AIDS by later standards. Nevertheless, becilllse the complications arc so uncommon in otherwise well people and the pattern of at risk groups so striking, the report clarified our view of ATDS ilnd set the stage for m(lrc det<Jiled studies of its manifestations and risk factors.\n\nOn the other hand, often a rel<Jtively frequent associ<Jtion <Jnd the absence of a comparison group h<lve led to erroneous conclusions.\n\nExample ]\\;[;my physici,lIls iltlrihute low back pain to protrusion of one or more intervertebral disks. Several case series used magnetic resonance imaging (MI\\I) to define the anatomy of the lumbosacral spine in patients with low back pdin. Th~'se studies found that the majority of patients had disk ilbnormaiities, providing-ilppilren\\ support for the importance of disk abnormalities in low back pain. However, as described in Chapter 3, MI<.I studies of asymptomatic individuills revealed similar prevalences of disk abnormalities, undl'rmining the argument that protruding disks seen on MRT arc the cause of bdek pain  (6) .\n\nI\\nother limitation of case series is that they generally describe the clini-Gd manifestations of disease and its treiltments in a group of piltients assembled at one point in time, a survival cohort (see  Chapter 6) . They must be distinguished, therefore, from cohort studies or trials of treatment for which <In inception cohort of patients wilh a disease is followed over time with the purpose of looking for the outcomes of the disease. C<lse series often look bilckward in time and th<lt restricts their value as a me<lns of studying prognosis or GlUsl'-and-effect relationships."
    },
    {
      "title": "Case-Control Studies",
      "text": "To find out whether a finding or possible cause really is more common in patients with a given disease, olle needs a study with several features. First ilnd foremost, in addition to il series of cases there must be <I comparison group that does not have the disease. Second, there must be enough people in the study so that ch<lnce is less likely to playa large pilrt in the observed results. Third, the groups must be similar enough, even though one is nondiseasec!, lo produce a credible comparison. Finally, if one wants to show that a risk factor is independent of others-and, therefore, a possible c<luse-it is necessary to Gllltn,l for aII other important differences in the analysis of the findings.\n\nCase reports and case series cannot tilke us this far. Neither can cohort studies in many situations, because it is not feasible to accrue enough cases to rule out the pl<lY of chancC'. Case-control studies, studies that compare the frequency of a purported risk factor (generally cillied the \"exposure\") in a group of cases and it group of controls, have these features.\n\nUisease l\\'jj 1-INo 1 1 -----1\"t.M~> iYes 1 j\\lJl~.I"
    },
    {
      "title": "DESIGN",
      "text": "The basic design of a case-control study is diagrammed in Figure  10 .1. Patients who have the disease and a group of otherwise similar people who do not have the disease are selected. The researchers then look backward in time to determine the frequency of exposure in the two groups. These data can be used to estimate the relative risk of disease related to the characteristic of interest.\n\nExample Does the use of nonsteriodal antiinflammatory drugs (NSAJDs) incrmse the risk of renal dismse? Resmrchcrs have addressed this question using a Glse-control study  (7) . How did they go about it?\n\nFirst, they had to define renal disease and find a sizable group of cases available to he interviewed. For obvious reasons, they looked in tertiary care hospitals, where many such cases are gathered. The cases, of course, included only patients in whom the diagnosis had been made in the course of usual medical care. For example, asymptomatic patients with mild renal failure were much less likdy to be induded among the cases.\n\nOnce the Glses were assembled and the diagnosis confirmed, a comparison, or control,' group was selected. Before deciding which people to choose as controls, the investigators considered the purpose of the study. They wanted to ascertain whether patients with renal failure were more likely to have received NSAJD therapy in the past than a similar group of people with no evidence of renal disease.\n\nThe invesligiltors found thill thecslimiltcd rdiltive risk of NSAID exposure for renal failun' WilS 2.1, using d o lta on the rates of t'xposure in Cilses and controls, and that the excess risk was largely nmfined to older men.\n\nWhat is meant by similar? There is some controversy about this. In a cohort study of the risk of NSI\\IDs for reml disease, similarity would mean membership in the cohort from which the cases arose, all of whom were initially free of renal disease at the inception of the study, e.g., people residing in the same community or enrolled in the same HMO. Is there a natural cohort from which a group of cases receiving care at a given tertiary care hospital can emerge?\n\nBecause of referral pf<lctices, cases assembled at hospitals and other treatment centers usually reside in many communities, receive their care from many physicians, and belong to no common group before becoming ill. Therefore, there was no obviously similar group of people without renal disease, and one had to be created.\n\nThis was done by randomly sampling people who resided in the vicinity of each hospital. Tn this way, controls were assembled VI/ho, it was hoped, would provide an accurate estimate of the likely prevalence of NSAllJ usc ilmong the cases if there were no association behveen renal disease and the use of the drugs  (8) .\n\nOnce the cases and controls were selected and their consent obtained, the next step was to measure exposure to the risk factor of interest. The drug-taking history of each case and each control had to be reconstructed. As opposed to a cohort study where drug taking can be tracked over time, assessment of drug exposure in this Cdse-control study rdied on memory_ It is often the past that is important in case-contra] studies, and therein lies a potential for bias. it is difficult not to interpret the past in the light of nne's present condition. Pm cases, this is particularly so when the present includes a disease as serious as renal failure. Investigators can attempt to avoid bias by using objective data such as computerized pharmacy records, blinding subjects to the purpose of the study, blinding observers to case status if possible, and by using cMefully defined criteri,1 to decide which of the cases and controls received prior NSAIO therapy."
    },
    {
      "title": "COHORT VERSUS CASE-CONTROL RESEARCH",
      "text": "Cohort and case-control studies arc both observational sludies of risk factors. Sometimes the two are confused. A distinguishing feature of the case-control design is that cases have the outcome of interest at the time that information on risk factors is sought. In cohort research, on the other hand, people are free of disease at the beginning of obsen'ation when the measurement of the risk factors is made. Figure  10 .2 summarizes the differences behv('en case-control ,1Od cohort designs. Since the temporal relationship between putative Cduse and effect is ,10 important criterion for causality (sec Chapter 11), cohort studies provide ,1 stronger basis for a causal interpretation.\n\nTable  10 .2 summarizes the essential characteristics of cohort, case- controL and prevalence research designs and illustrates their differences.\n\nAs will be discussed later, it is these difrerellces that make the cilse-control study particularly susceptible to bias_"
    },
    {
      "title": "THE ODDS RATIO",
      "text": "How do we decide whether thefe is an increased risk? Figure  10 .3 shows the calculation of risk for cohort and case-control studies. In a cohort study, the susceptible population is divided into two groups-exposed to NS/\\lDs (/\\ + B) and unexposed (C t D)-at the outset. Cases of renal disease emefge naturally ovef time in the exposed group (A) and the  unexposed group (e). This provides us with appropriate numerators and denominators to calculate the incidences of renal disease in the exposed [A/(Al B)] and unexposed [C/(C + D)] cohorts. It is also possible to calculate the relative risk. Incidence of disease in the exposed Relative risk = Incidence of disease in the unexposed A/(A + B) C/(C + lJ)\n\nCase-control studies, on the other hand, begin 'Nith the selection of a group of cases of renal disease (A-I C) and another group of controls (B + 0). There is no way of knowing disease rates because these groups are determined not by nature but by the investigators' selection criteria. Therefore, an incidence rate of disease among those exposed to NSAIOs and those not exposed C8Ilnot be computed. Consequently, it is not possible to obtain a rdative risk by dividing incidence among users by incidence among nonusers. What does have meaning, however, are the relative frequencies of people exposed to NSAIDs among the cases and controls.\n\nIt has been demonstrated that one approach for comparing the frequency of exposure among cases and controls provides a ml'ilsure of risk that is conceptually and mathematically similar to thc relative risk. This is the odds ratio, defined as the odds 2 that a case is exposed divided by the odds that a control is exposed\n\nThe odds ratio simplifies to\n\nAs is seen in Figure  10 .3, the odds ratio can be obtained by multiplying diagonally <lcross the table and then dividing these cross-products.\n\nNote th<lt if the frequency of exposure is higher among cases, the odds r<ltio win exceed 1, indic<lting increased risk. Thus the stronger the association between the exposure and disease, the higher the odds ratio. Conversely, if the frequency of exposure is lower among C<lses, the odds ratio will be less than 1, indicating protection. The meaning of the odds ratio, therefore, is analogous to the relative risk obtained from cohort studies. The similarity of the information conveyed by the odds ratio and the relative risk h<ls led some investigators to report odds ratios as \"estimated relative risks\" or simply \"relative risks.\"\n\nThe odds ratio is approximately equal to the relative risk only when the incidence of disease is low, because of assumptions that must be made in the calculations. How low must the rates be? The answer depends in part on the size of the relative risk  (9) . In general, however, distortion of the relative risk becomes large enough to matter at disease rates in unexposed people of greater than about 1/100. Fortunately, most diseases, particularly those examined by means of case-control studies, are considerably less common than that rate."
    },
    {
      "title": "ADVANTAGES OF CASE-CONTROL STUDIES",
      "text": "The case-control design has become a common and important method used to study etiology and clinical questions. What are its advantages? first, the investigators can identify cases unconstrained by the natural frequency of disease and yet can still make a comparison. Cohort studies <Ire quite inefficient for this purpose. For example, to gather information <lbout the risk of NSAID use in 100 individu<lls with end-stage ren<ll disease, one would have to follow a cohort of 1,000,000 for about 2 1 / 2 years (see Table  10 .1). Obviously, because of the expense and logistic difficulties of such a study, it would usually not be feasible. In contrast, it has been relatively inexpensive and easy to assemble 100 or more cases from hasp i-tals and other treatment facilities, find simililf groups without the disease, and compare frequencies of past NSAID use. Tn this way, several hundred study subjects can be interviewed in a matter of weeks or months, and an answer can be obtained at a fraction of the cost of a cohort study.\n\nA real advantage of the case-control study in exploring the effect of some causal or prognostic factors is that one need not wait for a long time for the answer. Many diseases have a long latency-the period of time between exposure to a risk factor and the expression of its pathologic effects. For example, it has been estimated that at least 10-20 years must pass before the carcinogenicity of various chemicals becomes manifest. It would require an extremely patient investigator and scientific community to wait so many years to see if a suspected risk to health can be confirmed.\n\nBecause of their ability to address important questions rapidly and efficiently, case-control shtdies play an increasingly prominent role in the medical literature. If one wants to study cause and effect using a relatively strong method, the case-control approach is the only practical way to study some diseases. Case-control studies comprise a growing percentage of all original articles and the majority of epidemiologic articles. Their quickness and cheapness justify their popularity as long as their results are valid; and here is the problem, because case-control studies are particularly prone to biased results. These biases are discussed in the next section."
    },
    {
      "title": "Avoiding Bias in Case-Control Studies",
      "text": "In many case-control studies, the investigators create the comparison groups rather than allow nature to determine who in a population becomes a case and who remains a noncase or control as in cohort or prevalence studies. This element of manipulation is a necessary evil because the validity of a case~control study depends on the comparability of cases and controls.\n\nCases and controls are comparable if the controls would have been captured as cases if they developed the condition under study. In other words, to be comparable, cases and controls must be members of the same base population. A second, more controversial issue is whether to be comparable, cases and controls must have an equal opportunity to receive the exposure  (10) . For example, the opportunity to have received NSAIDs (discussed earlier) would presumably be greater among those who have received regular medical care and perhaps still greater among those with joint symptoms. Should both cases and controls have similar symptoms and medical care experiences. Opinions differ, but it is clear that if one insists that cases and controls have the same degree of arthritic symptoms and the same doctor, the opportunity to evaluate risk may be impossible if the doctors involved tend to either prescribe or not prescribe NSAIDs to most of their patients with common causes of musculoskeletal pain. Therefore, ensuring comparability between cases and controls requires careful consideration of the circumstances under which an individual becomes exposed."
    },
    {
      "title": "SELECTING CASES",
      "text": "In the past, most case groups in case-control studies were assembled from among patients receiving care in hospitals or other medical treatment facilities. The proliferation of disease registries, such as the National Cancer Institute's Cancer Surveillance System, and computerized diagnostic data from health plans has made it much more feasible to select all or a representative sample of all cases occurring in a defined population. Populationbased cases should be more typical and include a wider spectrum of disease severity.\n\nThe cases in case-control research should, if possible, be new (incident) cases, not existing (prevalent) ones. The reasons are based on the concepts discussed in Chapter 4. The prevalence of a disease at a point in time is a function of both the incidence and duration of that disease. Duration is in turn determined by the rate at which patients leave the disease state (because of recovery or death) or persist in it bf..>cause of a slow course or sllccessful palliation. Tt follows from these relationships that risk factors for prevalent disease may be risk factors for either incidence and duration or both; the relative contributions of the two cannot be distinguished. An exposure that causes a particularly lethal form of the disease, thereby lowering the proportion of prevalent cases that are exposed, would result in a lowered relative risk if prevalent cases were studied. The rcader can be somewhat reassured that the results of a case-control study are not biased by the selection of prevalent cases if the odds ratios obtained are similar in short-and long-duration cases."
    },
    {
      "title": "SELECTING CONTROLS",
      "text": "A major potential for bias exists in many case-control studies because the controls are not a naturally occurring group, but one constructed for the study by the investigators. Which controls are appropriate in relation to the cases?\n\nThere are several strategies for choosing the right controls. First, the best way to minimize selection bias is by selecting both cases and controls from the same defined population. If cases comprise all cases or an unbiased sample of all cases arising in the population, whether accrued in a cohort study or identified in a prevalence survey, then controls can be a random sample of all the other people in the same population. TIlis strategy is called a population-based or nested (in a cohort) case-control study. Controls should meet the same general inclusion/exclusion criteria as the cases and be sampled from the population or cohort ilt about the same times as the cases arose.\n\nExample Does habitual, vigorous physical activity protect against pri-mMy cardiac arrest in people without apparent heart disease? An emergency medical information system facilitated the conduct of a population-based case-control study to answer this question  (11) . Cases were selected from 1250 people living in Seattle and suburban King County, Washington, who had suffered out-of-hospital primary cardiac arrest (PCA) during a ddinl'd period of time. Cases were chosen from paramedic reports; paramedics attended nearly all instances of peA in the area at the time.\n\nControls were sell'cted by dialing randomly selected telephone numbers in the same area; most people in the area had telephones in their homes. Both cases and controb had to meet criteria for entry: ag-e 25-7.'i years; no clinically recognizable heart disease; no prior disease that limited activity; and a spouse who could provide information about habitual exercise, the exposure of interest. Controls were matched to cases on age, sex, marital status, and urban or suburban residence. Spouses of both cases and controls were asked about leisure-time aetivity_ The entry criteria sought to ensure that cases and controls were members of the same base population and hild opportunities to engage in physical activity_\n\nThe results, based on lb.') eligible Cilses and controls, confirmed previous studies. The risk of PCA ,vas 6_'i-75~;) lower in persons with high-intensity leisure-time activity than in more sedentary people.\n\nAlthough selecting cases and controls from a defined population or cohort is preferable, selecting both from hospitals or other health organizations is often more feasible. But studying people in health care settings is also more fallible because patients are usually a biased sample of all people in the community, the people to whom the results should apply.\n\nA second set of strategies for having controls who are comparable to cases include the ones illustrated by the examples in this chapter and presented in Chapter 6: restriction, matching, stratification, and adjustm ent. Matching poses the greatest challenges and will be discussed here,\n\nCases can be matched with controls so that for each case one or more controls are selected that possess characteristics in common with the case. Researchers commonly match for age, sex, and residence, because these are frequently related to disease. But matching often extends beyond these demographic characteristics when other factors are known to be important. Matching increases the useful information obtainable from a set of cases and controls because it reduces differences between groups in determinants of disease other than the one being considered and thereby allows for a more powerful (sensitive) test of association. But matching: carries a risk. If the investigator happens to match on a factor that is itself related to the exposure under study, there is an increased chance that the matched case and control will have the same history of exposure. For example, if cases and controls were matched for the presence of <lrthritic symptoms, which are commonly treated with NSA1Us, more matched pairs would likely have the same history of NSAJD use. This process, called OVlTltlufch\u2022 ing, will bias the odds ratio toward 1 and diminish the ability of a study to detect a significantly increased or deCfmsed cdds ratio. A third strategy is to choose more than one control group. Because of the difficulties attending the selection of truly comparable control groups, a systematic error in the odds ratio may arise for <lny one of them. One way to guard against this possibility is to choose more than one control group from different sources.:l One approach used when Cilses are drawn from a hospital is to choose one control group from other patients in the samc hospit<ll ilnd a second control group from the neighborhoods in which the cases livc. If similar odds ratios are obtained using different control groups, this is evidence ag<linst bias, because it is unlikely that bias would affect othenvise dissimilar groups in the same direction and to the same extent. If the estimates of relative risks arc different, thilt is a signal that one or both are biased, and an opportunity exists to investigate where the bias lies.\n\nExample In a case-control study of l:'strogl:'n and endometrial cancer, cases were identified from a single teclC\"hing hospitid. Two control groups wen' selected: one from among gynecologic admissions to the same hospital and the second from a random sample of women living in the area served by the hospital.\n\nThe presence of other diseases, such as hypertension, diabetes, and gallbladder disease, was much more common among the cast's and the hospital control group, presumably reflecting the various forces that lead to hospital-i7.ation. Despite these differences, the two control groups reported much less long-term t'strogen usc than did the cases and yielded very similar odds ratios  (4.1 and 16) .\n\nThe authors (l2l cOll{lud<,d that \"this consistency of results with two very different comparison groups suggests thilt neither is significantly biased and lhal the results .. are reasonably clccurate.\"\n\nOptions for selecting cases and controls are summarized in  Figure 10.4. If cases are all occurring in i1 defined populaLion (or a representative sample of all cases), then controls should be too. nlis is the optimal situation. If cases are a biased sample of all cases, as they arc in most hospital samples, then controls should be selected with similar biases."
    },
    {
      "title": "MEASURING EXPOSURE",
      "text": "Even if selection bias can be avoided in choosing cases and controls, the investigator faces problems associated with validly measuring exposure after the disease or outcome has occurred, i.e., avoiding measurement bias. Case-control studies are prone to three forms of mC<lsurement bias 1Ch\",.\"ing tw\" or more conlr,,1 gmup' ,'cr cose t;r0up, i, dilf~\"\u2022,,t f\",m ch\"'''ing Iw  (' or m(m.' c\"ntr, , 1s pcr case, Til., btkr i, d\"\", \u2022, to illn\", , , , , , r, lh, ti, al pow\"r (or prc\", i ,ion \"I the c,t,male of rd\"ti\"\" 'i,kl. Tn W'n\"ral, using mOl'e thon ,'n,' contr\"T ,uhi~ct T)(\" \"\"\", ,,-,ults in ,m\"IT I:>ulu,dul gain, in pnwer. bullherc i, Tittle u\",fuT ,d\"ant\"I:<' to \"dding mor,' controls ,'er C05C beyond thr~~<>r lour. disease on memory status, called reca]] bias, must be considered when measurement of exposure relics on memory.\n\nThere aTe two protections against biased remembering. First, there should be alternative sources of the same information, whether written documents, such as medical or other records, or interviews with rc!iJtives or other knowledgeable individuals. Second, the specific purpose of the study should be concealed from the study subjects. It would be unethical not to inform subjects of the general nature of the study question. But to provide detailed information to subjects about the specific hypotheses could so bias the resulting information obtiJined as to commit another breach of ethics-involving subjects in a worthless research project.\n\nThe third problem, whether the presence of the outcome influences the way in which the exposure is measured or recorded, should be understandable to all students of physical diagnosis. If a resident admitting a patient with renal disease to the hospital is aware of a possible link between NSAID usc and renal failure one could expect the resident to question the patient more intensely about previous analgesic use and to record the information mOTe carefully. lntcrvie\"wers who iJTe aware of a possible relationship between exposure and disease and also the outcome status of the interviewee would be remarkiJble indeed if they conducted identiCiJl interviews for cases and controls. The protections against these sources of biiJS iJre the same as those mentioned above: multiple sources of information and blinding the data gatherers, 1.('., keeping them in the dark as to the hypothesis under study."
    },
    {
      "title": "SCIENTIFIC STANDARDS FOR CASE-CONTROL RESEARCH",
      "text": "It has been suggested that one should judge the validity of a casecontrol study by first considering how a TiJndomized controlled trial of the SiJme question would have been conducted  (14) . Of course, one could not actually do the study that \\ViJY. But a randomized controlled trial would bl' the scientific standard against which to consider the effects of the various compromises that are inherent in a case-control study.\n\nOne would enter into a trial only those patients who could take the experimental intervention if it were offered, so in a case-control study one would select cases and controls who could have been exposed. For example, a study of whether NSl\\lDs are a cause of renal failure would include men and women who had no c(lntraindications to taking NSI\\IDs, such as peptic ulcer. Similarly, both cases and controls should have been subjected to equal efforts to discovcr renal disease if it were present. These and other piHalle1s betwcen clinical trials and case-control studies can be exploited whell trying to think through just what could go wrong, how serious a problem il; it, and what can be done about it.\n\nThere have also been efforts to set out criteria for sound case-control studies  (15) . To apply these guidelines requires an in-depth understanding of the lllany possible determinants of exposure and disease, as well as the detection of both, in actual clinical situations."
    },
    {
      "title": "USING CASE\u2022CONTROL STUDIES TO EXAMINE HEALTH CARE",
      "text": "The major use of case-control studies has been to tel;t hypotheses about the etiology of disease. More recently, investigatorl; have exploited the advantages of the case-control design to study questions related to the provision and quality of health care.\n\nExample 1s cerebral palsy and fetal death preventable? BTitish investigators (  16 ) used a caslO-control design to compUTe the antepartum care received by 141 babies developing cerebral palsy and 62 dying intrapartum or neonatally. Each case was matched with two healthy babies born at the same time and place. A failure to respond to signs of severe fetal distTess was more common among cases than controls but only accounted fOT a V,'Ty small percentage of babies with cerebral palsy.\n\nBecause most I;erious adverse effects of poor-quality medical care are relatively rare, the case-control design providel; an efficient strategy for examining the relationship between deviations from guidelines or other protocols and poor outcomes."
    },
    {
      "title": "Summary",
      "text": "Much of medical progress is derived from the careful study of sick individuals. Cal;l;' reports are studies of just a few patients, e.g., -dO. They are a useful means of describing unusual presentations of disease, examining the mechanisms of disease, and raising hypotheses about causes ilnd treatments. However, case reports are particularly prone to bias ilnd chance. Case series-studies of larger collections of patients-still I;uffer from the absence of a reference group with which to compare the C'xperience of the cases and from sampling cases at various times in the course of their disease.\n\nIn case-control studiel;, a group of cases is compared with a similar group of noncaSes (controls). A major advantage resides in the ability to assemble easel; from treatment centers or disease registries as opposed to finding them or waiting for them to develop in a defined populiltion at risk. Thus case-control studies are much less expensive and much quicker to perform than cohort studies and the only feasible strategy for studying risk factors for mrc diseases. Relative risk can be estimated by the odds ratio, although it is not possible to compute incidences or relative risk directly. The disadvantages of the case-control design all relate to its con-siderable sus~~eptibilityto bias. This problem is most related to two charact eristics of case-control research. First, the grouFs to be compared are commonly constructed by the researcher and are not constituted naturally; second, the exposure is measured after the disease has already occurred.\n\nGiven the vulnerability of case-control studies to bias, what place do they have in clinical epidemiologic research? To some, case-control studies are unscientific, illogical, and a curse. To others, they are viewed as the essential first step in studying many medically important questions. TIlere is nearly universal agreement that cohort studies provide stronger, more valid evidence and, if feasible, are the design of choice. But with appropriate attention to possible sources of bias, case-control studies can provide a valid and efficient method to answer many clinical and health services questions."
    },
    {
      "title": "CAUSE",
      "text": "Examf,Ie Some yf.'iHS ago, medical students were presented a study of the relationship betwlCen the cigarette smoking habits of obstetricians and the vigor of babies they delivered. Infant vigor is measured by an Apgar score; a high score  (9) (10)  indicates that the bahy is healthy, Wh<.'fCilS a low score indicates the baby might be in trouble and require close monitoring. The study suggested that smoking bv obstetricians (not in the delivery suite!) had an ,{dvcrse effect on Apgilf sCI)re:; in newborns. Tnt' medical studl'nts wefe then asked to (omment on what lVilS wrong with this study. Afkr many suggestions, someone finally said that the conclusion simply did not make sense, It W,lS then acknowledged thilt, altholJgh the study was rca!, the \"exposure\" and \"disease\" had been illtered for the presentation. Insteild of comparing smoking habils of obstetricians with Apgar scores of newborns, the study, published in 1R4.1 by Oliver Wendell Holmes (then professor of anatomy and physiology and later dean of Harvard Medical School), concerned hand washing habits by obstetricians and subsequent puerpeml sepsis in mothers. The observations led Holmes (1) to conclude: \"The disease kWl\\'m as puerperal fever is so far contagious, as to be frequently carried from patient to patient by physicians and nurses.\"\n\nOne mid-19th century response to Holmes's assertion that unwashed hands caused puerperal fever was remarkably similar to that of the medical students: The findings made no sense. \"1 prder to attribute them [puerperal sepsis casesl to accident, or Providence, of which I em form a umn'ption, rather than to conta/;ion of which I cannot form any dear idea, at least as to this particular malady,\" wrote Dr. Charll;'s D. Meigs, profl;'ssor of midwifery and the diseases of women and children at Jefferson Medical College (1).\n\nHolmes and Meigs wcrc confronted with a question iJbout cause. Uolmes was convinced by his data that the spread of puerperal sepsis was caused by obstetricians not washing their hands between deliveries. He could not, however, supply the pathogenetic mechanism by which hand washing was related to thc disease, as bacteria had not yet bcen discovered.\n\nMeigs, therefore, remained unconvinced that the cause of puerperal sepsis had been cstablished (and presumably did not bother to wash his hands).\n\nClinicians frequently arc confronted with information about possible causill relationships. Tn fact, most of this book has been about methods used to establish cause, although we have not c,,!led special attention to the term. Tn this chapter, we review concepts of Ciluse in clinical medicine. We then outline the kinds of evidence that, when present, strengthen the likelihood that an association represents a causal relationship. We illso deal briefly with a kind of research design not yet considered in this book: studies in which exposure to a possible cause is known only for groups and not specifically for individuals in the groups."
    },
    {
      "title": "Concepts of Cause",
      "text": "Webster's (2) defines cmlse ilS \"something that brings about an effect or a result.\" In medical textbooks, cause is usually discussed under such headings as \"etiology,\" \"pathogenesis,\" \"mechilnisms,\" or \"risk factors.\"\n\nCiluse is important to pfilcticing physicians primarily in guiding their approach to three clinical tasks: prevention, diagnosis, and treatment. The clinical example at the beginning of this chapter illustrates how knowledge of cause-and-effect relationships can lead to successful preventive strategies. Likewise, when we periodically check patients' blood pressures, ,ve are reacting to evidence that hypertension causes morbidity and mortality and that treatment of hypertension prevents strokes and myocardial infarction. The diagnostic process, especially in infectious disease, frequently involves a search for the causative agent. Less directly, the diagnostic process often depends on information about cause when the presence of risk factors is used to identify groups of patients in whom disease preva-lenn~is high (see Chapter 3). Finally, belief in a causal relation. . <;hip underlies every therapeutic maneuver in clinical medicine. Why give penicilHn for pneumococcal pneumonia unless we think it will cause a cure? Or advise a patient with metastatic cancer to undergo chemotherapy unless we beli('ve the antimetabolite will cause a regression of metastases and a prolongation of survival, comfort, and/or ability to carryon daily activities?\n\nBy and large, clinicians are more interested in treatable or reversible than immutable causes. Researchers, on the other hand, might also be interested in studying causal factors for which no efficacious treatment or prevention exists, in hopes of developing preventive or therapeutic interventions in the future."
    },
    {
      "title": "SINGLE AND MULTIPLE CAUSES",
      "text": "In 1882, 40 years after the Holmes-Meigs confrontation, Koch set forth postulates for determining that an infectious agent is the cause of a disease. Basic to his approach was the assumption that il pilrticular disease has one cause and a particular cause results in one disease. He stipulated that:\n\n1. The organism must be present in every case of the disease; 2. The organism must be isolated and grovvn in pure culture; 3. The organism must cause ,1 specific disease when inoculated into an illlimal; and 4. The organism mllst then be recovered from the ilnimal and identified. Interestingly, he did not consider the effect of treatment in establishing cause, something he might have added a century later when effective treatments had become more common in medicine.\n\nKoch's postulates contributed greatly to the concept of cauS(' in medicine. Before Koch, it was believed that many different bacteria caused any given disease. The application of his postulates helped bring oreler out of chaos. They are still useful today. That a given organism causes a given disease was the basis for the discovery in 1977 that Legionnaire's disease is caused by a Gram-negative bacterium, and the determination in the 1980s that the newly discovered HTV causes ATns.\n\nFor most diseases, however, cause cannot be established simply by Koch's rules. Sometimes, too much reliance on Koch's approach has gotten the medical community into trouble by narrowing our perspectives. Would that disease was so simple that we always had a single cause-single disease relationship. Smoking causes lung caIlcer, chronic obstructive pulmonary disease, peptic ukers, bladder cancer, and coronary artery disease. Coronary artery disease has multiple causes, including cigarette smoking, hypertension, hypercholesterolemia, and heredity. It is also possible to have coronary artery disease without any of these knuwn risk factors.\n\nUsually, many factors act together to cause disedse in what has been called the \"\",'eb of causation\"  (3) . A causal web is well understood in conditions such as coronary artery disease, but is also true for infectious diseases, where presence of the organism is necessary for disease to occur but not necessarily sufficicnt. ,\\Ins cannot occur without exposure to TTlV, but exposure to the virus does not necessarily result in disease. .For example, exposure to HIV rarely results in AIDS after needlesticks (3 or 4/10(0), because the virus is not nearly as infectious as, say, the hepatitis U virus."
    },
    {
      "title": "PROXIMITY OF CAUSE TO EFFECT",
      "text": "lNhen biomedical scientists study cause, they usually search for the underlying pathogenetic mechanism or final common pathway of disease. Sickle-cell anemia is an example, with the genetic change associated with hemoglobin S (HbS) leading to polymerization and erythrocytic sickling when fTbS gives up its oxygen. J::Iucidating pathogenesis of disease has played a crucial part in the advancement of medical science in this century.\n\nHowever, disease is abo determined by less specific, more remote causes, or risk factors, such as people's behavior or characteristics of their environments. These factors may be even more important causes of disease than are pilthogendic mechanisms. For eXilmp1c, a large proportion of cardiovascular and cancer deilths in the United States can be traced to behavioral and environment,l! factors; the spread of AIDS is due primarily to sexual behaviors and drug use; and deaths from violence and accidents are rooted in social conditions, acct.'ss to guns, and alcohol and :-;eatbelt ust.'.\n\nTo view cause in medicine exclusively as cellular and subcellular processes restricts the possibilities for useful cl i nical interventions. Tf the pathogenetic mechanism is not clear, knowledge of risk factors milY still lead to very effective treatments and preventions. Thus Holmes was right in his assertion that obstetricians should wash their hands, evell though he had little notion of bacteria.\n\nFor many diseases, both pathogclletic mechanisms <lnd nonspecific risk factors have been important in the spread and control of the diseases. Sometimes the many different causes interact in complicated ways.\n\nExamp!l' Koch's postulates were orig-inilily used to l.'stablish thilt tuberculosis is cilused by inoculiltion uf thl.' acid-fast bacillus Mycobacterium tuber-Cillosis into susceptible hosts_ TIll' final comrnon pathway of tuberculosis is the invasion of host tissue by the bilcteria_ horn a pathogenetic perspective, conquering the diseils<, required antibiolics or vaccines th,lt 'werl.' effective ilg-ainst the organism. Through bioml.'dical research efforts, both hilve been achieved.\n\nHowever, the develupment of the disease tuberculosis is h1r more complex. Other impurtant causes arc the susceptibility of the host and the degree of exposuH' (Fif;. 11.1). In fad, th,'se Ciluses delennim\" whether invilsion of host tissue cail occur. Some clinicians would be hesitant to label host susceptibility and level of exposure as causes of tuberculosis, but they <Ire very important components of cause. Tn fact, social ilnd economic improvements influencing-host susceptibility, such as less crovvded living space and better nutrition, may have played a more prominent role in the decline in tuberculosis rates in developed countries than treatments developed through the biomedicalpathogenetic research model. Figure  11 .2A shows that the death rate from tuberculosis had dropped dramatically long before antibiotics were introduced. (The vaccine came even later.)"
    },
    {
      "title": "Crowding",
      "text": "Since 1985 the number of TB cases in the United States has increased (4) (Fig.  11 .2B). 'Why is this so? A total of 60\u00b0/,) of the increase occurred in foreign-born persons. HIV infections arc also a factor, with an increasing number of susceptible people, as AIDS spreads and weakens the immune systems of its victims. These susceptible hosts are more likely than the general population to be exposed to tuberculosis, because both AIDS and tuberculosis are more common in economically depressed populations. FinalIy, changes have occurred in the baci1lus itself, with the evolution of multidrug resistant strains. To complicate the picture further, multidrug resistance also is caused by a wcb of circumstances. Genetic changes in the Mycobacterium are more likely to occur with medication noncompliance  (5) , which is more likely among-intravenous drug users, an important risk group for ATDS. Changes in the bacterium's genetic makeup may also be related to high replication rates in immunodeficient hosts. Thus the interplay of environment, behavior and subcellular biology may be incredibly complex when thinking about cause.\n\nAnother example of the importance of both pathogenetic and epidemiologic approaches to cause is the recent decline in deaths from coronary arkry disease in the United States.\n\nExample During the polsl two decades, the death rate from coronary artery disease has dropped more than a third. This decline accompanied decreclsed exposure, in the popUlation as a whole, to several risk factors for cardiovascular disease: A larger proportion of people with hypertension are being tn.'ated effectively, middle-aged Inen are smoking less, and fat and chok'stero! consumption has declined. These developments were, at least in part, the result of both epidemiologic and biOinedica Istudies and have spared tens of thousands of lives per year. It is doubtful that they would have occurred without understanding\" of both the proximal ml'cha\"nisms and the more remotl' origins of cardiovascular disease  (6) ."
    },
    {
      "title": "INTERPLAY OF MULTIPLE CAUSES",
      "text": "When more than one cause act together, the resulting risk may be greater or kss than would be expected by simply combining the effects of the separate causes. Clinicians call this phenomenon synergism if the joint III 400 ., ~317 <Xl 300 r:: r:: \" 200 ::;; 0 0 0 ~1 00 US \" 61 III ., 12 20 U 0 Serum cholesterol 185 185 185 ':l:;l!i q (mg %) Systolic blood 105 105 jill; 105 llli!; , ' \" ' ' pressure (mm Hg) Cigarette smoking 0 0 0 Figure 11.3. Interaction of multiple causes of disease, The risk of developing cardiovascular diseaso in men according to the level at several risk factors alone and in combination. Abnormal values are in shaded boxes. (Redrawn from Kannel WB, Prevontive cardiology. Postgrad Med 1977;61:74-85.)\n\neffect is grcilter than the sum of the effects of the individual causes, and antagonism if it is less,l\n\nExample  Figure 11.3  shows the probdbility of developing cardiovascular disease over an 8-pcilf period among men aged 40. Men who did not smoke cigarettes, had low serum cholesterol values, and had low systolic blood pressure readings were at low risk of developing disease (l2/IOOO). Risk increased, in the range of 20 to 61/1000, when the various factors were present individually. But when all three factors wen~present, the absolute risk of cardiovascular disease (317/1000) was ahnost three times greater than the sum of the individual risks  (7) .\n\nElucidation of cause is more difficult when many factors playa part than when a single one predominates. However, when multiple causative i Slnli,licu! ;\"lemc/ioll is pr~,~nt when combination, of \"ariahks in a malhemoti\"\"l modd add to the model's expldnah>ry power aller lhe nd ~fh~\u2022t, or the individual pr\",lict,,, variables have been t\"k~n into .m\"Ollllt. It is eoneeplu\"lly rt'btl'd to biologic SY\"~Tgy ond Jnla8oni,m but is \" m<1themillical con,trud, not <1n ob\"'rvabh' phenomenon in nalur<' factors are pre[;ent and interact, it may be possible to make a substantial impact on a patient's health by changing only one, or a small number, of the causes. Thus, in the previous example, getting patients to give up [;moking and treating hypertemion might substantially lower the risk of developing cardiovascular disea[;e in men, even in the continuing presence of other causative factors."
    },
    {
      "title": "EFFECT MODIFICATION",
      "text": "Effect modifiration is a special type of interaction. It is present when the strength of the relationship between two variables is different according to the level of some third variable, called an effect modifier.\n\nt;xample Because of conflicting results of studies evaluating the eHec\" tiveness of thia7ide diuretics in preventing coronary heart disease, a study was done to examine whether there was a relationship between the dose of thiazide and the risk of sudden death, and whether adding potassiumsparing therapy modified the effect. Figure  11 .4 summarizes the results. TIle dOSl' lif thiazide dell'rmint;>s its effect, with a low dose, 25 mg, protecting against sudden death and a high dose, IOU rng, increasing the chances of sudden death. Adding potassium-sparing tht;>rapy modifies the effect at several doses, adding a protective effect  (8) ."
    },
    {
      "title": "Establishing Cause",
      "text": "Tn clinical medicine, it is not possible to prove causal relationships beyond any doubt. It is only possible to increase one's conviction of a causeand-effect relationship, by means of empiric evidence, to the point at which, for all intents and purposes, cause is established. Conversely, evidence against a cau[;e can be mounted until a cause-and-effect relationship becomes implausible. The possibility of a postulated cause-and-effect relationship should be examined in as many different ways as pos[;ible. This usually means that several studies must be done to build evidence for or against cause."
    },
    {
      "title": "ASSOCIATION AND CAUSE",
      "text": "Two factors-the suspected cause and the effect-obviously must appear ttl be associated if they are to be considered as cause and effect. However, not all associations are causal. Figure  11 .5 outlines other kinds of associations that must be excluded. Fir[;t, a decision must be made as to whether an apparent association between a purported cause and an effect is real or merely all artifact because of bias or random variation. Selection and measurement biases and chance are most likely to give rise to apparent associations that do not exist in nature. If these problems can be considered unlikely, a true association exists. But before deciding that the association is causal, it is necessary to know if the association occurs indirectly, through another (confounding) fac- Example of effect moditication: how the risk of cardiac arrest in pa tients using thiazide diuretics (compamd with the risk of cardiac arrest in patients using beta-blockers) changes according to use of potassium-sparing diuretics, Odds ratios-with 95% confidence intervals (GI) ---increase with increasing dose of diumtic, suggesting that it is safer to use beta-blockers than thiazide diuretics. However, with the addition of potassium sparing diuretics, thiazide diuretics cause a lower risk of cardiac arrest than beta-blocker therapy, (Redrawn from Siscovick OS, et al. Diuretic therapy for hypertension and the risk of primary cardiac arrest. N Engl J Med  1994; 330:1852-1857,)  tor, or directly. If confounding is not found, a causal relationship is likely.\n\nAt some future time another factor may be found that is more directly causal. Por example, several studies found that women fared more ponrly than men after coronary bypass surgery and it was thought that sex was related to postoperative prognosis. On further study, small body surface area-which correlated with small-diameter coronary arteries-was found to be an important variable leading to heart failure and death, not being female per se  (9) . Thus factors that ,lTe considered Gluses at one time are sometimes found to be indirectly related to disease later, when more evidence is available."
    },
    {
      "title": "RESEARCH DESIGN",
      "text": "When considering a possible GlUsal relationship, the strength of the research design used to establish the relationship is an important piece of evidence.\n\nOf the research designs so far discussed in this book, well-conducted randomized controlled trials, with adequate numbers of patients; blinding of therapists, patients, and researchers; and carefully standardized methods of measurement and analysis are the best evidence for a Ciluse-andeffect relationship. Randomized controlled trials guard against differences in the groups being compared, both for factors already known to be important, which can be overcome by other methods, and for unknown confounding factors.\n\nWe ordinarily usc randomized controlled trials to provide evidence about causal relationships for treatments and prevention, However, as pointed out in Chapter 6, randomized controlled trials are rardy feasible when studying causes of disease. Observational studies must be used instead.\n\nIn general, the further one must depart from randomized trials, the less the research design protects against possible biases and the weaker the evidence is for a cause-and-effect relationship. Well-conducted cohort studies are the next best design, beGlUse they can be performed in a way that minimizes known confounding, selection and measurement biases. Crosssectional studies are vulnerable because they provide no direct evidence of the sequence of events. Trlle prevalence surveys-cross-sectional studies of a defined population-guard against selection bias but are subject to measurement and confounding biases. Case-control studies Me vulnerable to selection bias ZlS welL Weakest of all arc cases series, because they have no defined population and no comparison group. This hier.:Hchy of rese.:Hch designs is only ZI rough guide, based on extent of susceptibility to bias. The mZlllner in which an individual study is performed can do a great deal to increase or decrease its validity, reg.:Hdless of the type of design used."
    },
    {
      "title": "POPULATION STUDIES",
      "text": "Up until now, we have discussed evidence for cause when exposure and disease status are known for each individual in the study. In a different kind of research, most often used for epidemiologic studies of large populations, exposure is knovvn only for the groups, not for the individuals in the groups.\n\nStudies in which exposure to a risk factor is char<.lcterized by the average exposure of the group to which individuClls belong are called aggregate risk studi!'s. Another term is ecological studies, because people are classified by the general 1cvel of exposure in their environment.\n\nExample What factors are associilled with cilrdi,lC mortality in developed countries? 51. I.eger et al. (  10 ) gathencd dilla on rates of ischemic heart diseast' mortality in 18 developed countries to <'xplore the contribution of various economic, health services, and dic(Jry variables. One finding that was not ilnticipated WilS a strong neg<ltive association betwe,'n ischemic h,'art disease death and wine consumption  (Fig. 11.6) .\n\nThis study raist's thc hypothesis that alcohol protects against ischemic heart diseasc. Since then, studies on individuals have shown th,ll levels uf serum high-density lipoprotein. a prott'din' factor for cardiovascular disease, are increased by illcohol consumption.\n\nAggregate risk studies arc rardy definitive in and of themselves. TIle main problem is a potential bias (Cllled the ecological jI1/1I1(y: Affected individuals in a generally exposed group may not themselves have been exposed to the risk. Also, exposure may not be the only characteristic that distinguishes people in the exposed group from those in the nonexposed group, i.e., there may be confounding factors. Thus aggregate risk studies arc most useful in raising hypotheses, \\vhich must then be tested with more rigorous reseClrch."
    },
    {
      "title": "TIME SERIES STUDIES",
      "text": "Evidence from aggregate risk studies thilt a factor is iJetl/ally responsible for an effect can be strengthened if obserVAtions are m,:llie at more than two points in time (before and after) and in more than one place. In a time sail'S study, the effect is ml'asured at various points in time before and after the purported cause has been introduced. 1t is then possible to see if the effect varies as expected. If changes in the pu rported ca use arc followed\n\n11 3 \u2022 \u2022 Switzerland Italy 2 \u2022 France 0.40 0.80 1.20 1.60 2.00 E.B.W.\n\n\u2022 \u2022 Ireland _Norway \u2022 Netherlands \u2022 Denmark \u2022 eBelgium Sweden . \u2022 eAustrla West Germany \u2022 Finland \u2022 Australia \u2022 Canada U,S.A.\n\n\u2022 \u2022 N.Z. by changes in the purported effect, the association is less likely to be spurious."
    },
    {
      "title": "Example",
      "text": "The risk of CI(J$tridiulri difficiic-associated diarrhea and pseudomembranous col itis has been shown to be rebted to the use of antibiotics, particularly clindamycin, ampicillin, and cephalosporins. An epidemic of C. dijJicilc diarrhea broke out in a hospital in 1990 after usc of dindamycin increased sharply (Hg. 11.7) (Il). Education, inkction control, and environmental hygiene efforts were imnlcdiately instituted, but the epidemic continued unabiltcd. Clindamycin waS then removed fmm the hospital formulary, and its usc plummeted, along with the number of cases of C. d@cile-diarrhea.\n\nTo investigate the i1ssociation further, the authors conducted a case-control study, which corroborilted the findings of the timc series analysis.\n\nIn a multiple tilt/e series study, the suspected cause is introduced into several different groups at various times. Measurements of effect are then made among the groups to determine if the effect occurs in the same sequential manner in which the suspected cause was introduced. If the effect regularly follows introduction of the suspected cause at various times and places, there is stronger evidence for cause than if this phenomenon is observed only once, because it is even more improbable that the same extraneous factor(s) occurred at the same time in relation to the cause in many different places and eras.\n\nExample Hecause there were no randomized controlled trials of cervical cancer screening programs before they became widely accepted, their effectiveness must be evaluated by means of observational studies. A multiple time series study has provided some of the most convincing evidence of their effectiveness  (12) . Data were gathered on screening programs begun in the various Canadian provinces at various times during a 10-year period in the 1960s and 1970s. Reduction;; in mortality regularly followed the introduction of screening programs regardless of time and location. With these data, it was concluded that \"~creenill!;had a significant effect on reduction in mortality from carcinoma of the uterus.\""
    },
    {
      "title": "ELEMENTS FOR OR AGAINST CAUSE",
      "text": "In 1965, the British statistician Sir Austin Bradford Hill (  13 ) proposed a set of fcahtres that should be sought when deciding whether a relationship between a sickness and some environmental factor is causal or just an association. His proposals have been widely used, sometimes with modifications (Table  11 .1). We will comment briefly on the individual elements. They are not all of equal weight in deciding about cause."
    },
    {
      "title": "Temporal Relationships between Cause and Effect",
      "text": "Causes should obviously precede effects. This fundamental principle seems self-evident, but it can be overlooked when interpreting most crosssectional studies and case-control studies, in which both the purported cause and the effect are measured at the same point in time. It is sometimes assumed that one variable precedes another without actually establishing that this is so. In other cases, it may be difficult to establish which came first.\n\nExamplt' It has long been noted that overweight persons are at higher risk of death, especially cardiovascular death, than people with normal weight. Thus it is reasonable to assume that weight loss would be protective among overweight people_ Howevt'r, several cohort studies have found excess mortality among people who lose weight, even among people without any apparent preexisting disease. These distressing findings may be explained if a subtle, predinic<d effect of fatal il1ne~s is weight loss  (14) . Thus fatal conditions may precede and cause weight loss, not vice versa. (This possibility could be excluded if it was known whether the weight loss was voluntary in those losing weight.) Although it is absolutely necessary for a cause to precede an effed in clinical medicine-and, therefore, the lack of such a sequence is powerful evidence against cause-an appropriate temporal sequence alone is weak evidence for cause."
    },
    {
      "title": "Strength of the Association",
      "text": "A strong association between a purported cause and an effect, as expressed by a large relative or absolute risk, is better evidence for a causal relationship than a weak association. Thus the 4-to 16-fold higher incidence of lung cancer among smokers than nonsmokers in many different prospective studies is much stronger evidence that smoking causes lung cancer than the findings in these same studies that smoking may be related to renal cancer, for which the relative risks are much smaller (1.1-1.6) (15) . Similarly, that the relative risk of hepatitis B infection for hepatocellular cancer is nearly 300 leaves little doubt that the virus is D cause of liver cancer  (16) . Bias can sometimes result in large rc\\Dtive risks. However, unrecognized bias is less likely to produce large relative risks than to prod uce small ones."
    },
    {
      "title": "Dose-Response Relationships",
      "text": "A dose-response relationship is present when varying amounts of the purported cause are related to varying amounts of the effect. If a doseresponse relationship can be demonstrated, it strengthens the argument for cause and effect. Figure  11 .8 shows a clear dose-response curve when lung cancer death rates (responses) are plotted against number of cigarettes smoked (doses).\n\nAlthough a dose-response curve is good evidence for a causal relationship, especially when coupled with a large relative or absolute risk, its existence does not exclude confounding factors.\n\nExample Both the strong association between smoking and lung cancer and the dose-response relationship have been dismissed by the tobacco industry as examples of confounding. According to this argument, there is some lUlknown variable that both causes people to smoke i1nd increases their risk of developing lung cancer. The more the factor is present, the more both smoking and lung cancer are found-hence, the dose-response relationship_ Such an argument is it theoretically po~sible explanation for the association between smoking and lung cancer, i1Jthough just what the confounding factor might he hilS never been clarified. Short of iI randomized controlled triill (which would, on the ilverilge, allocate the people with the confounding filctor equally to smoking and nonsmoking groups) the confounding argument is difficult to rdute completl;'ly."
    },
    {
      "title": "Reversible Associations",
      "text": "A factor is more likely to be a cause of disease if its removal results in a decreased risk of disease, i.e, the association between suspected cause and effect is reversible. Figure  11 .9 shows that when people give up smoking they decrease their likelihood of getting lung cancer. Reversible associations are strong, but not infallible, evidence of a causal relationship. Confounding could conceivably explain a reversible association. For eX<lmple, in Figure  11 .9 it is possible (but unlikely) that people willing to give up smoking have smaller amounts of the unidentified factor th<ln those who continue to smoke."
    },
    {
      "title": "Consistency",
      "text": "When several studies conducted <It different times in different settings and with different kinds of patients <Ill come to the same conclusion, evidence for a causal relationship is strengthened. That screening for colorectal cancer is effective becomes more plausible when <I randomized controlled trial of fecal occult blood testing  (17)  and a case-control study of sigmoidoscopy  (18)  both find a protective effect. Causation is particularly supported when studies using several different research designs all lead to the same result, because studies using the same design can all make the samt' mistake.\n\nIt is often the case that different studies produce different results. Lack of consistency does not necessarily mean that the results of a particul<lr study are invalid. One good study should outvveigh several poor ones."
    },
    {
      "title": "Biologic Plausibility",
      "text": "Whether the assertion of cause and effect is .:::onsistent with our knowledge of the mechanisms of disease as they are currently understood is often given considerable weight when assessing causation. When we have absolutely no idea how an association might have arisen, we tend to be skeptical that the association is real. Such skepticism often serves us well. For example, the substance Laetrile was touted as a cure for cancer in the early 1980s. However, the scientific community was not convinced, because they could think of no biologic reason why an extract of apricot pits not chemically related to compounds with known anticancer activity should be effective against cancer cells. To nail down the issue, Laetrile was finally submitted to a randomized controlled trial in which it was shown that the substance was, in fact, without activity against the cancers studied  (19) .\n\nIt is important to remember, however, that what is considered biologically plausible depends on the state of medical knowledge at the time. In Meig's day, contagious diseases were biologically implausible. Today, a biologically plausible mechanism for puerperal sepsis, the effects of streptococcal infection, has made it easier for us to accept Holmes's observations. On the other hand, the mechanism by which acupuncture causes anesthesia is far Jess clear. To many scientists in the Western world, the suggestion that anesthesia is caused by sticking needles into the body and t\\virling them seems biologically implausible, and so they do llOt believe in the effectiveness of acupuncture.\n\nIn sum, biologic plausibility, whell present, strengthens the case for causation. When it is absent, other evidence for causation should be sought. If the other evidence is strong, the lack of biologic pl,lllsibility miJY ind iCiJte the limitations of medical knowledge, rather than the Jack of a causal association."
    },
    {
      "title": "Specificity",
      "text": "Specificity-one cause, one effect-is more often found for acute infectious diseases (such as poliomyelitis and tetanus) and for inborn errors of metabolism (such as gout, ochronosis, and familial hypercholesterolemia). I\\s we pointed out, for chronic, degenerative diseases there are often many causes for the same effect or many effects from the same cause. Lung cancer is caused by cigarette smoking, asbestos, and r<ldiation. Cigarettes cause not only lung cancer but also bronchitis, peptic ulcer disease, periodontal disease, and wrinkled skin. The presence of specificity is strong evidence for cause, but the absence of specificity is weak evidence iJgainst a cause-and-effect relationship."
    },
    {
      "title": "Analogy",
      "text": "The argument for a cause-and-effect relationship is strengthened if there arc examples of well-established CiJuses that arc analogous to the one in question. Thus if we know that a slow virus can cause iJ chronic, degeneril.t ive central nervous system dise<lse (subacute sclerosing panencephalitis), it is easier to accept that another virus might cause degeneration of the immunologic system (acquired immunodeficiency syndrome). Tn general, however, analogy is weak evidence for cause."
    },
    {
      "title": "Weighing the Evidence",
      "text": "Most of this chapter has been a discussion of whiJt to look for in individual studies when considering the possibility of a causal rel<ltionship. Hut, when deciding about cause, one must consider all the available evidence, from all available studies. I\\fter examining the pattern of evidence, the case for causality can be strengthened or eroded. This calls for a good deal of judgment, especially when the evidence from different studies is conflicting. In such cases, clinicians must decide where the weight of the evidence lies.\n\nFigure  11 .10 summarizes the different types of evidence for and against cause, depending on the research design, and features that strengthen or\n\nThe case for causation is usually built over time with several different studies. It rests primarily on the strength of the research designs used to establish it. Because 'we rarely have the opportunity to establish cause using randomized controlled trials, observational studies are necessary. Some studies of populations (time series and multiple time series studies) may suggest causal relationships when a given exposure of groups of people is followed by a given effect.\n\nfeatures that strengthen the argument for a cause-and-effect relationship include an appropriate temporil] relationship, a strong ilssociation between purported cause and effect, the existence of a dose-response re]at ionship, a fall in risk when the purported cause is removed, and consistent results among several studies. Bio]ogic plausibility and coherence with knmvn facts are other features that argue for a causal relationship."
    },
    {
      "title": "SUMMING UP",
      "text": "Where is the knowledge we hiJve lost in informlltiol/?\n\nT. S. Eliot, \"The l{ock\"\n\nThe usefulness of cliniCiJl research depends on its scientific credibilityits believability to thoughtful, unbiased scientists-and its relevance to the problems faced by clinicians and their patients. Both clinicians, \\vho base their decisions on the rnedicalliterature, and researchers, who cre<lLe it, need to understand \\'\\'h\"lt adds to and subtr<lcts from the strength of scientific research.\n\nTo judge scientific credibility, readers must take illl active role. They must decide what they wanL to discover from the lllcdicalliterature and then sec if the information is present and meets their standards of scientific credibility. By just reading: passively, without considering the basic scientific principles systematically and ill advance, they will be less likely to notice shortcomings and more likely to be misled.\n\nThis chapter describes hmv the methodolog-ic principles discussed in previous chapters can be applied by busy clinicians to thc lifelong task of trying to practice evidencc-based medicine. First, we discuss how research articles pertaining to a given clinical question are identified and how their numbers C,1ll be reduced to manageable proportions without sacrificing needed information. Next, vve summarize basic rules for judging the strength of individUill articles; that section deals with concepts th<lt have been discussed throughout the book. Third, we consider how the many articles on a given research question, as a group, are summarized to discover where the best available esLimate of the truth lies. It is on this estimate that clinicians must base their clinical decisions until better information becomes aVililable. Throughout the chapter we consider how these stepsarticle identification, study evaluation, and evidence synthesis-relate to strategies for keeping abreast of the literature throughout one's life as a c1iniciiln, Whatever the strength of the best available evidence, clinicians must use it <IS a basis for action-sometimes rather bold action-yet regard it as famble and subject to revision. One scholar (1) has distinguished behveen \"decisions\" and \"conclusions.\" We decide something is true if we will act as if it is so, for the present, until better infonnation COffies along. Conclusions, on the other hand, are settled issues and are expected to be more durable. Clinicians are mainly concerned with decisions. The integrity of the scientific enterprise rests on the willingness of its participants to engage in open-minded, welHnfonned arguments for and against a current view of the truth, to accept new evidence, and to change their minds."
    },
    {
      "title": "Approaches to Reading the Literature",
      "text": "Clinicians examine the medical literature from different perspectives, depending on their purpose. They browse to sec what is interesting, they read articles of clinical interest to keep up, they look up the answers to specific clinical questions, and they systematically review the literature about a clinical issue to develop or change a clinical policy. We mainly deal with the full review of the literahtre. We understand that clinicians rarely have the time to do a full-blown review of existing information. However, if they understand the basic principles by which literature searches <lTe done, they are in a better position to identify credible articles efficiently and judge the results for themselves when they browse, keep up, or look up information."
    },
    {
      "title": "WHICH ARTICLES ARE IMPORTANT FOR CLINICAL DECISION MAKING?",
      "text": "All articles are not equally important for clinical decision making. Thoughtful clinicians must find and value the soundest articles in the face of an almost overwhelming body of available infonnation. figure  12 .1 summarizes <In appro<lch to distinguishing articles of fundamental importance to clinical decision making from those that are not. Many articles-reviews, teaching articles, editorials-arc \\vritten to describe what is generally believed to be true but are not themselves reports of original rescarch aimed at establishing that truth. Thesc articles are a convenient source of summary information, but they are interpretations of the true knowledge base and arc not independent contributions to it. Moreover, they are usually written by people \\'lrith an established point of view, so that there is the potential for bias.\n\nExample How well do review artides and textbook chapters summarize the available body of scientific evidence about a dinical 1juestion7 Investigators produced estimates of the effectiveness of vdriuus interventions to reduce morbidity and mortality from myocardial infarction (MI) by performing mcta-ilnalyses (describl.\u2022d lakr in this chapter) of randomized cIinicdl tri cl1s (r~CTs)  (2) . The estimates were compared with expert recommendations published at the same point in time in review artick'S ,md textbook chapters. They found that \"expert opinion\" generally lagged behind the cumulative evidence by several year~and not infrequently disagreed with it. For exampie-by 1980 thl.'re were 12 RCTs in the literature that had examined the efficacy of prophylactic lidocaine in the treatment of acute MI. Essentially, all showed that treatment with lidocaine was no better and often worse than placebo, yet the majority of review articles and chapters published during the 19805 contl.nued to recommend routine or ;;elective use of Iiducaine.\n\nOther articles describe original research done in laboratories for the purpose of understanding the biology of disease. These shldies provide the richest source of hypotheses about health and disease. Yet, \"bench\" research carmot, in itself, establish with certainty what will happen in humans, because phenomena in actual patients, who are complex organisms in a similarly complex physical and social environment, involve variables that have been deliberately excluded from laboratory experiments.\n\nResearch involving intact humans and intended to guide clinical decision making (\"clinical research\") is, of course, conducted with varying degrees of scientific rigor. Even by crude standards, most shidies are relatively weak. For example, a recent review of the methods of clinical studies in three surgical journals revealed that more than 80% had no comparison group, much less a randomized control group  (3) .\n\nThroughout this book we have argued that the validity of clinical research depends on the strength of its methods (internal validity) and the extent to which it applies to a particular clinical setting (generalizability).\n\nIf this is so, a few good articles are more valuable than many weak or inappropriate ones. Thus the overall conclusion frun the medical literature often depends on how a relatively few articles are interpreted. A review of the literature should involve selecting these articles carefully, identifying their scientific strengths and 'weaknesses, and synthesizing the evidence when their conclusions differ."
    },
    {
      "title": "FINDING USEFUL ARTICLES",
      "text": "When systematically reviewing the literature, the first task is to locate articles that may be useful. This is most challenging when reviewing the literature, where it is first necessary to sort through a large number of titles, often thousands, to find the small number of articles that are useful. The objective is to reduce the literature to manageable proportions without missing important articles. The task can be intimidating and timeconsuming. We describe a plan of attack, starting first with the full review of the literature.\n\nThe first step is to develop a set of criteria for screening titles to select articles that may be relevant while excluding a much larger number that dearly are not. The criteria should provide a sellsitive test for the articles that one hopes to find in the same sense as a screening test should be sensitive for a disease, i.e., few useful articles should be missed. Initially, specificity can be sacrificed to achieve sensitivity, with the understanding that it will be necessary to evaluate many \"false-positive\" articles in more detail for each one that meets the final critC'ria. Often a useful screening algorithm is defined by the joint occurrence of a few key words in the title, e.g., sarcoidosis, pulmonary, and corticosteroid or ennea, pallcrClltic, and dillglwsis.\n\nSecond, the screening criteria are applied to a list of journal titles, generally the list maintained by the National Library of Medicine, MEDUNE. Although available in bound volumes, many clinicians are currently accessing the medical literature electronically via modem, CD-ROM, or other computer-b<lsed systems. Because computer searching usually misses some important articles, one should also identify articles from other sources of titles such as recent review articles, other articles on the same topic, textbooks, and suggestions from experts in the field. The result of this search is a large number of titles, some of which represent relevant <lrticles and many of which do not.\n\nThird, one must apply specific criteria to identify the articles that arc actually <lppropriate for the question <It hand. Three kinds of criteria are often used:\n\n\u2022 Does the article address the specific clinical question that was the reason for the search in the first place?\n\n\u2022 Does the article represent original research, not secondary information or opinion? \u2022 Is the research based on relatively strong methods?\n\nMany inappropriate articles can be excluded by examination of the full title. Often, however, more information is required, and the abstract serves this purpose well. Perusal of abstracts should revcal to the reader whether a study of treatment used a comparison group and random allocation, a study of prognosis was on an inception cohort, whether a study has sufficient statistical power or precision, and so on.\n\nStructured a/Jstracts  (4) , which have been adopted by many of the leading medical journals, provide a better opporhmity to judge potentially useful articles. The structured ah;tract summarizes in outline format those elements of a study-the research question, study design, setting, patients, interventions, measurements, results, and conclusions-required to distinguish valid and informative studies from the larger number that are not original or are inadequately rigorous.\n\nFina]]y, one must actually look at the articles that remain to see which meet the final criteria. By this time, the number of articles should havc been reduced enough that the task is feasible. Figure  12 .2 summarizes these steps and illustrates the search process for a specific question: the outcome of total knee replacement  (5) .\n\nIf there is not sufficient time for a full, broadly based search for articles or the reader is browsing or trying to stay abreast of important developments, the early steps of this process must be abbreviated. One can examine only those journals that publish original research with high methodologic standards. However, this is an insensitive strategy: one would have to examine at least 11 of the world's best journals just to find 80% of the best <lrticles on a question  (6) .\n\nAnother approach, is to have the screening of articles done by others. One would want them to be experts in both clinical medicine and clinical research methods, to examine all of the world's articles, and to make their criteria for inclusion explicit. The journal ACr Journal Club presents structured abstracts for the scientifically strong, clinically relevant original research in inkoMI medicine, selected by explicit criteria published in each issue. The results of selection in this way are powerful: in 1993, there were more than 6 million articles published in clinical journals, of which about 350-a manageable number-met the criteria. Another option, the Cochr ane Collaboration, is being developed. Expert groups from throughout the world are working together to select the best studies of clinical interventions, surrunarize them in a standard form, disseminate the information electronically, correct the database when errors arc found, and keep it up\n\nTable 12.2 Characteristics of a Study That Detennine Whethe, It Can Test or Only Raise Hypotheses Chmucteri'itic DeSign HypoUwses Comparisons p v81ue Results confirmed on separate data set Weak None (or 8fter data collected anej clrlalysed) Many Lflrge No Strong Smted before study begun Few Small Yes"
    },
    {
      "title": "RAISING OR TESTING A HYPOTHESIS",
      "text": "The conclusions of an individual piece of research fall on a spectrum of believability according to the decisiveness of the scientific strategy used (see  Chapter 11) . At one end of the spectrum are reports that only suggest relationships. albeit potentially useful ones, without putting these ideas to the test. Most case reports serve this function. The conclusions of these studies \"lre tentative; many are later refuted. At the other end of the spectrum are studies-e.g., large randomized controlled trials-that have put ideas to a rigorous test. Conclusions from these studies are more definitive. Most studies fall between these extremes.\n\nA priori hypotheses are important. Without them, false-positive findings can make their way into the literature in the following way. Suppose one examines a large number of variables in a data set none of which is associated with any of the others in nature. As discussed in Chapter 9, if a large number of associations between variables are examined, some of them will be extreme enough to appear \"rea!,\" even though the associations are only by chance. At a conventional level of statistical significance, p < 0.05, about I in 20 such comparisons will be statistically significant, by definition. Of course, the observed associ\"ltions are \"real\" for the particular data set <It hand-but not necessarily in the population-because the current sample may misrepresent all such samples from the population of interest. Now suppose that one of these comparisons is selected out of the larger set of all possible comparisons and given special emphasis, perhaps because it fits we]] with existing biomedical theories. Suppose the other comparisons are minimized in the final report. Then the association, taken out of context. can <lppe<Jr very important. This process-random (ch<lnce) occurrenCe of <lssociations followed by bi<lsed selection of interesting ones-is not unuSU<ll in published research.\n\nThere are several dues that signal the degree to which a given study is hypothesis testing rather th<ln hypothesis raising (T<lble 12.2).\n\nThe first, a strong research design, is not il strictly separate factor from the others. Making hypotheses in advance and limiting the number of comparisons examined reduce the number of apparently \"significant\" comparisons that emerge from a study. The exploration for effects in various subgroups of a larger study population is a common analytic strategy that may result in chance or spurious associations. When hypotheses made in advance, a priori hypotheses, are confirmed, one can place more confidence in the findings. Alternatively, investigators can simply limit the number of comparisons made after the fact, so that there is less chance of false-positive findings for the study as a whole. Or they can insist on a particularly small p value before ruling out the role of chance in explaining particular findings.\n\nAnother strategy to protect against the acceptance of spurious or chance associations is to raise hypotheses on one set of data and test them on a separate one (fig. 12. 3). The availability of large data sets and statistical computer software makes it relatively easy for the analysis to include multiple variables, considered either separately or together in models. The analysis of multiple variables should be viewed as raising hypotheses, as the investigators rarely specify in advance what the model will find, much less the weight given to each finding. 1\u00a3 the data set is large l'llough, it can be divided randomly in hillf, with one half being used to develop the model and the second half used to confirm it. Or it can be tested in a different setting. This latter process is illustrated in the follmving example.\n\nExample Investigators developed an index, including seven physical signs, for predicting the e'lrly recurrence of acute 'lsthm'l after discharge from 'In emergency dep'lrtment (tl). Among 20.S patients at the investigiltors' medic'll center, p<ltients from whom the index was developed, the index had a sensitivity of 9.S':,;, and a specificity of 97'1;,. The results were so striking that the index began to be put into dinic'li prilctice elsewhere.\n\nLiller, two other groups oC inVl'stigiltors independently tested the index in other settings  (9,1(] ). The results were disappointing. The sensitivity and sped ficity were 40% and 71 '~;\" respectively, in one study, ilnd 1K.l )~;) ami 82.4'::, in the other."
    },
    {
      "title": "Process"
    },
    {
      "title": "Data Set"
    },
    {
      "title": "Hypothesis Raising"
    },
    {
      "title": "Derivatidn"
    },
    {
      "title": "Hypothesis Testing",
      "text": "Validation These studies illustrate the dangers of placing too much confidence in a relationship that has been suggested in on\\.: data set but not tested in another, independent one. There are several possible rcasons for the difference in performance. Patients in the original sample might have been systematically different, the index might have been applied differently, or chance might have resulted in unusual findings in the initial study.\n\nWhatever the strategies used to increase the hypothesis-testing character of a srudy, it is the author's responsibility to make it dearwhere a particular study stands on the hypotheses-raising, hypothesis-testing: spectrum and why. The readers' task is to seek out this infomlation or reconstruct it, if it is not apparent. However, one should not eschew studies that mainly raise hypotheses; they are important, just not definitive."
    },
    {
      "title": "Summarizing the Results of Many Studies",
      "text": "The current state of knowledge on a question is usually decided by the pattern of results from all studies addressing the question, rather than by one definitive study. Until recently, the commonest way of establishing this pattern was by implicit judgment, i.e., opinion, without having stated in advance the ground rules by which the contributions of individual studies would be weighted. Judgments of this sort often take the form of a traditional (\"narrative\") review article by an expert in the relevant field or a consensus of scholars representing the many points of view that bear on a question, e.g., the National Institutes of Health's Consensus Development Conferences.\n\nA variety of more structured methods of summarizing published research is now used. These methods have the advantage of making explicit the assumptions behind the relative weights givcn to the various studies. They also follow the scientific mcthod more directly; setting criteria in advance, gathering data (in this case, the results of individual studies), analyzing the data, and allowing the conclusions to follow from the criteria and data.\n\nThe process of summing up the research on a question, lIsing structured methods, is referred to as meta-analysis-literally, analysis of analysis-or information synthesis. This approach is particularly useful when there is one specific question and at least a few relatively strong studies with apparently different conclusions. The use of these methods has exploded in the last fev,/ years. MEDLTNE listed nearly 2000 articles under the subject heading \"meta-analysis\" between 1990 and mid-1994.\n\nThere are three general steps in performing a meta-analysis. first is to identify the best articles from all possible articles, as described earlier in this chapter. Second is to evaluate each study according to how well it meets methodological criteria, which are decided on in advanee. In some meta~analyses, this evaluation results in the assignmcllt of an overall qual-"
    },
    {
      "title": "Relative Risk or Odds Ratio",
      "text": "Randomized trials ity score; in others, quality-related study characteristics of design, number and source of patients, and data collection methods are considered separately. The third step is to summarize, with numbers, the results of many studies to form, in effed, one large study with more statistical power than any of the individual studies alone. Each individual study is weighted by it~sample size, i.e., large studies get more weight than ones with smaller numbers of patients. In addition, many meta-analyses also include the quality senre as a weighting factor. Statistical mdhods, usually some form of regression analysis, arc then used to estimate an overall effect measure, such as a rdative risk or percentage reduction in mortality. Reports of meta-analyses include graphical displays of the results of the individual studies as well as the overall measure of effect.\n\nAlthough meta-analysis has become the standard against which other approaches to literature synthesis are judged, there continues to be controversy about many of its dements, particularly the evaluation of quality and its inclusion in the overall assessment. But quality measures, while lumping dispMate mcthodologic features in a single number, may help explain differences among studies.\n\nExample Although B'lCille Cahnettc-Guerin (HeG) vaccine has been used to prevent tuberculosis for more than 50 years and is required in many countries, iIs efficacy is contrnversial. In part this is hlxause the several Iargesca Ie clinical trials to eva luate Bee; have reported conflicting results. An early nwtil-analysis compared the methods used in these trials to their r<-'sults (11 j. The investigators found that the unbiased detection of tuh,'rcuJosis in Bee and control grnups was availilble only for the three trials H'porting 75'1,. or greater efficacy.\n\nA more recent meta-analysis of the same question summarized the results of studies examining vaccine efficacy  (12) . figure  12.4  shows the results of the seven randomized trials, six nonrandom trials, and the overall findings of the 10 case-control studies published as of 1YY4. Overall, in studies using mch of the three designs, the risk of tuberculosis was found to be reduced by about half for those receiving the vaccination compared with those who did not. To help explain. differences in observed magnitude of e[fect, the investigators developed overall scores fnr the quality of each study's methods. Using regression analysis, they found that better quality scores predicted findings of greater vaccine effect. The meta-analyses clearly establish the efficacy of BCe vaccine.\n\nOften, however, there is no dear relationship betwecn global quality ratings and their results. In this case, the meta-analysts must look at the specific methodolngic features of studies to see why they are reaching dispilfate conclusions  (13) ."
    },
    {
      "title": "POOLING",
      "text": "Not uncommonly, the results of various individual studies are indecisive because each study describes too few patients or too few outcome events to have sufficient statistical power or pre{:ision. Consequently, estimates of rates from these studies are unstable, and each study's comparison of rates runs an uniJcceptably high risk of missing true effects (Type II error).\n\nPooling refers to the process of aggregating the data from several relatively small studies of the same question to form, in effect, one large one.\n\nIt is permissible when it can be shown t11M the studies are sufficiently similar to each other (in patients, intervention and outcome measures) to treat them as if they are part of a single shldy. Pooling attempts to assemble enough observiltions to generate a precise overall estimate of effect, not to account for differences in conclusions among studies. The advantage of pooling is that it can result in adt.'quatc sbtistica1power to detect meaningful differences, if they exist. Pooling is particuhlrly useful when the disease and/or the outcome events of interest occur infrequently. Under these circumstances there are no other feasible ways to achieve statistical power.\n\nExample There arc many reports of peptic ulcer disease during corticosteroid therapy. Yet, it has been difficult to establish by means of observational studies whether corticosteroids cause ulcers, because manv or the situations in which they are given-e.g., during stress and in conjunction with gastric-irritating drugs-may themselves predispose to peptic ulcer disease. Abo, ulcers may be sought more diligently in patients receiving corticosteroids and go undetected in other patients.\n\nRandomized controlled trials ,He the best wav to determine cause and effect. There have been man\\, r,mdomi:led trials in ;. ...hich corticosteroids were used to tre<1l various lunditiolls and peptic ulcer disea,~e was a side effect. None of these studies was large enough in itself to test the corticosteroid! ulcer hypothesis. But together they provide an opportunity to examine the rate of rare event.\n\nIn one review of 71 controlled trials of corticosteroids in which patients were randomized (or its e4uiv,1lcnt) and plc'j)tic uker disease was considered, there were about 86 patients <md 1 case of peptic ulcer disease per study; only 31 of the trials reported any patients with ulcers  (14) . The investigators pooled the results of these 71 trials to increilse statistical power. In the pooled study, there were 6111 p,ltients and about 80 ulcer~;. The rate of peptic ulcer disease was 1.8 in the corticosteroid group and 0.8 in the control group  (relative risk, 2.3; 95\u00b0;;. confidence interval, 1.4-3.7) . The results were similar when examined separately according to the presence and absence of other risk factors; various doses, routes of administration, and duration of therapy; and whcther the disease was suspected, defined as bleeding, or specifically diagnosed.\n\nThus the combined results of many studies, each with relatively sound design but too small to answer the question, gave sufficient statistical power to detect risk.\n\nAdvocates of pooling point out that examination of the pattern of evidence, effectively summarized, can give new insights into the strengths and weaknesses of the evidence. For example, a single figure can show the number of strong shldies, the point estimate and statistical precision of each study's observed effect size, the relationship between dfed size and precision, and the point estimate and precision of their pooled effect (see  Fig. 12.4) .\n\nOpponents of pooling argue that the ways in which patients, interventions, and outcomes were selected in the various studies are so dissimilar that it is not reasonable to combine them. \"Splitters\" are not as satisfied with pooling as \"Jumpers.\" Also, pooling deals only with statistical power. It does not correct for whatever biases existed in the designs of the various individual studies, nor can it be assumed that these biases cancel each other out when the studies are aggregated. In any cast', meta-analyses only supplement and do not replJce the insights gained by examining each of the best studies of a clinical question carefully."
    },
    {
      "title": "PliblicaUon and Bias",
      "text": "Clinicians prder good news, as does everyone else. Thus such words as t:ffiCllcy, predicting, and corrclatilJ/l are the order of the day in journal titles. It is considerably less appealing to contemplate things that do not work. In fact, such observations arc often considered fOlilures. Researchers with the bad fortune to make such observations arc likely to be advised by their friends, \"vith gentle malicc, to seck publication in the /ol/I\"IUlI (~f Negative Resl/lts.\n\nIt may be that (lUr penchant for pl)sitive results leads to bias in the kinds of articles selected for publication in medical journals.\n\nExample The final disposition of 285 studies that had been reviewed by an English r~esearch Flhics Comrnittee and bmug-ht to nmclusion hy the inve~tigiltnrs WilS studied  (15) . Stillistically ~ignificant results were found in 54')'\" of ~tudics, a nonsignificant trend in 16'(;\" and null results in .'I()':;,. Of tht, studies with significant reS1J!ts, 85% were eitht'r published or pre~ented as opposed tu only 56':;, of studies with neg;ilivc resulls (odds l\"iltiO, 434; 95':;, confidence intl'rVill, 2.4-R6). Studies with nul! resulls were not of poorer quality, nor were they 1l101\u2022e likely 10 be unpublished because of editorial rejectiun.\n\nArticles actu<llly reaching publication arc a biased sample of all research findings, tending to represent efforts to find causes, diagnostic tests, <Ind treatments as being more effective than they actually are. For example, a meta-analysis of the relative effectiveness of single versus multiple drugs in ovarian cancer found a large survival adv<lntage with multiple drugs in published data. When the investig<ltor  (16)  <Idded unpublished results, the difference disappe<lfed. There is no reason to assert that biased judgments arc made deliberately. Everyone does his or her part to put the \"best\" work forward, but publication is not a random process. There are forces favoring positive over negative results that are quite independent of the relative proportions of these results among all research projects undertaken. Readers should be aware of this bias lest they become unrealistically impressed with the many new and promising findings that appear in medical journals.\n\nOne way to avoid this bias is to give more credibility to large studies than to small ones. Most large studies, having required great effort and expense in their execution, will be published regardless of \u2022whether they have a positive or negative finding. Smaller studies, on the other hand, require less investment and so are more easily discarded in the selection process.\n\nDifferCllt Answers: The Same Questions?\n\nUntil now, we have emphasized how studies can come to different conclusions because they have different methods, better for some than for others. Rut there is an alternative explanation: The research questions, although superficially the same, may actually be fundamentally different. Rather than one or the other study being misleading, both might be right. It may be that human biology, not research methods, accounts for the difference.\n\nExample Scveral authors  (17,lH)  have performed meta-analyses i1Ssessing the effectiveness of drug treatment for hyperk'nsion. Early trials demonstrated S\\Jbstantial and st,ltistically significant n'ductions in stroh'S but smaller and often not st,ltistically significant reductions in coronary heart discase (CHD) (Fig.  12 .5). The confidence inkrval for the pooled rdative risk for (HD across JII trials includes I.\n\nMore reccnt trials have focused on or at least included older adults. TheSto' neV\\'er trials, also summarized in Figure  12 .5, showed the saine degree of risk n.'ductim\\ for stroke but larger and consistently significant reductions in the risk of coronary heart diseilse. While the larger effectiveness of treatment observed in more recent triJIs suggests thill drug therapy for hypertension is more effective in older patients than WilS previously believed, these newer tri,ils tended to use diuretics and beta-blockers, the principal drugs in the trials, in lower dos,'s, This may illso have contributed to the greater eHect of treatment on (HD.\n\nStudies of cause and effect that seem to be asking similar questions can in fact present different questions in at least four ways: The patients, interventions, follow-up, and end results may not be the same. Differences among studies in anyone of these may be enough to give different results."
    },
    {
      "title": "Other Sources of Information",
      "text": "Until now the main source of information we have considered is journal articles reporting original research and meta-analyses based on them. What about other sources of information?\n\nTextbooks are convenient and trustworthy for reporting well-established faets. l3ut they have the disadvantage of being out of date (as much as 1 year old at time of publication) and reflecting the opinions of single authors, with little external review. Colleagues, especJa11y those specialized in the area of the clinical questions, <If(' also practical sources of informa-tion, but their opinions <Ire only as good <IS the consultant, who m<lY be biased by the beliefs <lnd financial interests of his or ~ler field. For example, it is natural for gastroenterologists to believe in endoscopy more than radiologic contrast studies and surgeons to believe in surgery over medical therapy.\n\nA growing number of dat<lbases are complete, up to date, and widely available by telephone, fax, floppy disks, CD-ROM, and e-mail, the Internet, and cmnpter bulletin board. Examples include a 24-hr telephone cormection to the Centers for Disease Control and Prevention for information about disease prevention offered to those traveling to any part of the world; Toxline for information on poisonings; PDQ for current recommendation for cancer chemotherapy; ,md an alTay of databases on drugs, their toxicities, and adjushlH:,nt of dose in renal failure. These databases contain information that is essential to the practice of medicine but are too infrequently needed and too extensive for clinicians to carry around in their heads. Clinicians should find ways to access them in their location. 'Ihey should also usc these databases with the lessons of this book in mind: The data are only as good as the methods used to select them. Many of the databases, such as guidelines of the Agency for Health Care Policy <Ind Research, the U.S. Preventive Services Task f.orce, and the American College of Physicians, are created by excellent methods and make the process clear. Some are the results of individui:lls or industries with conflict of interest, and they should be used with skepticism."
    },
    {
      "title": "Clinical Guidelines",
      "text": "Throughout the book we have argued that clinical research provides the soundest grounds for establishing one's 8pproach to dinical practice and making decisions about patients. The shift away from anecdote and personal experienn' has been called \"evidence-based medicine\"  (19) . An important element in evidence-based !nedicinc is the translation of research findings into cleM, unambiguous recommend<ltions for dinici8ns. Practice guidelines are system8tically developed statements to assist clinicians in deciding about appropriate health care for specific clinical problems  (19) . Their development and use are now commonplace in many organized medical settings. At their best, the validity of guidelines is established by including in the panel that prepZlres them people who represent all relevant aspects of the question (ranging from highly specialized resC<lrchers to clinicians, economists ,and patients) to cover all important aspects of the question and to balance, if not eliminate, the vested interests of anyone or another participant. The best guidelines are based on H'sc<lrch evidence, not just expert opinion, and so often usc formal processes of liter<lture review and synthesis, as described in this chapter  (20) .\n\nGuidelines are meant to guide, not prescribe clinical judgment There are good reasons not to follow guidelines ~n the care of some individual patients.\n\nDo guidelines change physicians' behavior? 1\\ meta-analysis identified and summarized 59 published articles that evaluated the impact of explicit guidelines using more rigorous research designs-randomized trials, nonrandomized comparative trials, and interrupted time series designs  (21) . More than 90% of the studies demonstrated significant changes in care in accordance with the guidelines, and 9 out of the 11 studies examining patient outcomes showed improvements.\n\n3. How likely is it th<lt the findings arc the result of bias?\n\nSystem<ltic differences between compared gf!.lUpS (e.g., in patients' characteristics, interventions, or risk f<lctors; outcomes; or measurement methods) diminish internil! validity. 4. How big is the effect?\n\nClinic<ll decisions depend on the magnitude (not just on the existance) of effect. 5. How likely is it th<lt the findings occurred by chance?\n\nClinicians need to know the range of values within which the true effect is likely to fan (confidence interval) or (less useful) how likely the observed effect is by ch<lnce alone (p value for \"positive\" results and power for \"neg<1!ive\" results).\n\nSTU DIES OF DIAGNOSTIC TESTS 1. Is the test clearly described (including the point at which it is considered abnormal)? ff the test result C<lll take on il range of values, the performance varies according to the choice of cutoff point. 2. Is the true presence or ilbsence of disl'ilse (>::old standard) estilblished for all patients? It is possible to know all important aspects of test performance only if there are d<ltil for all four cells of the 2 by 2 table. 3. Does the spectrum (~f patients with and without disease match the characteristics of patients for whom the test 'will be used? Sensitivity is often affected by the severity of disl'ilse and specificity by the characteristics of those in the study without the disl'ilse. 4. Ts there an Jmln'asl'd assessment of test and disease status?\n\nBias can occur if the test result is determined with knowledge of dise<lse status and vice versa. 5. Ts test p('~{i.mlJalJce summarized by sensitivity <lnd specificity or likelihood ratio? This information is needed to decide \\vhcther to use the test. 6. For tests with a range of valucs, how does mOI,ing Ih\" cutolfpoint affect test performance?\n\nThe information conveyed by the test depends on the degree of abnorm<llity. 7. 1\u00a3 predictive value is reported, is it in rl'1<1tion to a clinically sensible prevalence? Predictive value depends on prevaknce (as well as the sensitivity and specificity of the test). If people with and without the disease are chosen separately, without relation to the clinicaly occurring prevalence, the resulting predictive value has no dinic<ll meaning."
    },
    {
      "title": "PREVALENCE STUDIES",
      "text": "1. What ilre the criteriil for being a case? Previl!ence depends on what one calls a case. 2. In wh<lt population ilre the cases found?\n\nPrevalence depends on the group of people in which it is described. 3. Is prev<llence described for an unbiased sample of the population?\n\nPrevalence for the sample estimates prevalence for the population to the extent that the sample is unbiased."
    },
    {
      "title": "COHORT STUDIES",
      "text": "1. Arc all members of the cohort: a. Entered at the beginning of follow-up (inception cohor!)?\n\nOtherwise people who do unusually well or badly will not be counted in the result. b. At risk for d('veloping the outcome?\n\nIt makes no sense to describe how outcomes develop over time in people who already have the disease or cannot develop it. e. At a similar point (zero time) in the course of disease?\n\nPrognosis varies according to the point in the course of disease at which one begins counting outcome events. 2. Is there complete follow-up on all members?\n\nLJrop-outs can bias the results if they on average have a better or worse course than those who remain in the study. 3. Are <Ill members of the cohort assessed for outconu's with the same illll'nsity?\n\nOtherwise differences in outcome rates might be from measurement bias, not true differences. 4. Are comparisons unbiased? (would members of the cohorts have the same outcome rate except for the variable of interest?) To attribute outcome to the factor of interest other determinants of outcome must occur equally in the groups compared."
    },
    {
      "title": "KANDOMIZED TRIALS",
      "text": "1. Are the basic guidelines for cohort studies satisfied? Clinical trials are cohort studies 2. Were plltienl~randomly al/ocaled to treated and control groups? This is the only effective way to make a completely unbiased comparison of treatments. 3. Were patients, caregivers, and researchers unaware of the treatment group (masked) to which each patient belonged? Masking participants in a trial helps assure that they aTe unbiased. 4. Were cointervcntions the same in both groups?\n\nTreating patients differently can destroy the comparability that was achieved by randomization."
    },
    {
      "title": "5.",
      "text": "Were rc[;u Its described according to the trl'a/ment al/ocated or the treatmelIl actually received?\n\nIf not all patients receive the treatment assigned to them there are two kinds of analyses with different objectives and scientific strengths. \"Intention to treat\" analyses arc for management deci[;ions and are of the randomly constituted groups. \"Efficacy\" analyses <He to explain the effect of the intervention itself, are of the treatment actually received, and are a cohort study.\n\nCASE-CONTl~OL STU 1)1 ES 1. Were cases entered at the onsl'! of disease? Risk factors for pH'valent Gl[;CS may be rdlted to onset or duration of disease. 2. Were controls similar to cases except for exposure? A valid estimilte of relative risk depends on an unbiased comparison. 3. Were there similar and unbiased efforts to dl'kcf exposure in Glses and controls? Biased measurement of exposure can increase or decrease the estimate of relative risk. META-ANALYSFS 1. Is all relevant research (both published and unpublished studies) found? The objective is to summarize the results of OJ]] completed research, not a biased sample of it. 2. Does the meta-analysis include only sciflltijically strong studies (those with a low probability of bias)? The objective is to summarize the most credible evidence. 3. Tf a summary estimate of effect is calculated a. Are the studies Iwmogeneous (are patients, interventions, and outcomes similar)? It is inappropriate to seck a single, overall measure of effect from inherently dissimilar studies. b. Are the studies weigh/I'd by their size? Larger (more precise) studies deserve more weight than smaller (less precise) ones. 4. Are study quality and result relil/ed? Better studies arc more believable. Abnormality, 19-42 criteria for, 34-39, 35 overview, 41 Accuracy, of test result, 44-48, 45 Adher~m:e, randomized controlled trials, 146 Adjustment, multivariable, 132 Aggregate risk studies, 238 Allocation of treatment, 145 nonr,mdom, 16\"1 Alpha error, 187 Association causc and, 235-236, 237 describing, 202-203 n'Vl'r~ib1e, cause and, 242-243, 244 Bela error, 187 Bias, 7, 177-182 assembly, 123 in cast.'-control ~tudjes, 219-225 chance, 11 in cohort studies, 123, 123-128 confounding, 8-10, 9 compliilncc, 180--182, 181 diagno~i~and,~5-56 lead time, JiS, 17K-1i9 length time, 179, 179 180 measurement, 8, 128 migration, 126-127 overview, 7, 7t, 7-10 in prevalto'nce studies, HS-Hl publication and, 262-263 relationship with chance, 11 in reporting, case reports, 210 sampling, 1J, 133~134 sdection, 7-8, \"J2S-133,129t susceptibility, 123-12.'), 124 271 Biologic plausibility, 244-245 Blinding, 148-149 Burden of suffering, 168-170 Case defining, 81-83, 82t selection of, 220 Case reports, 208-211 biasl:'d rl:'porting, 210 uses of, 208-209 Case series, 211-212 Case-control studies, 212-225 advantages of, 211 t, 218-219 bias in, 219-n'i cases, selection of, 220 \\'s. cohort research, 214-215, 215, 2161 controls, selection of, 220\u2022\u2022222, 223 design, TI3, 213-214 exposure, measuring, 222-224 scientific standards, 224-225 Cause, 228-248, 246-247 analogy, 245 association, 235-236, 237, 242 reversibll:', 242-243, 244 biologic plausibility, 244-245 concepts of, 229-235 consistency, 243 dose-response relationships, 242 elements, for or against, 241t, 241-245 establishing,2:'t'i-245 evidence, weighing, 245-246, 246 multiple, 96-97, 97, 229-230, 232-235 interplay of, 1'12-235, 234 INDEX Cause-continued single, 229-230 ~pecificity, 245 temporal relation~hips, 241-242 Chance, 10-12, 11, 186-207, 189 diagnosis and, 56-57, 57 overview, 205-206 Clinical course, 112 Clinical data, summarization of, 20 Clinical epidemiology ba~ic principles of, 4-14 element~of, 3-4 health outcome~, 4-5, 5-6t need for, 3 overview, 2-4 ~ocial context, 4 uses of, 14-15 Clinical medicine, epidemiology and,2 Clinical perspective, traditional, 2-3 Cohort, 100-101 vs. case-control research, 214-215, n5,216t inceptions, 112 survival, 125-126, 125 Cohort studies, 100, 101-105, 102 advantages, l03t, 103-105 bi,,~in, 123-128, 123 disadvantages, 103t, 103-105 historical, 102, 103 Cointerventions, 147 -148 Comparison groups, randomized controlled trials,142-144 multiple, 200-202 Compliance, 146-147 Confidence interval, 198-200, 199 Confounding bias, 8-10, 9 Consistency, cause and, 243 Controls concurrent, 158 selection of, 220-222, 223 Cost, 172-173 Cox proportional hazards regression model, 123 Cut-off point, diagnosis and, 50 Data interval,21 nominal, 21 ordinal, 21 simplifying, 43-44 Lkcision, clinical, analysis, 89-90 Dt'lllographic groups, diagnosis and, 62 Diagnosis, 43-74 bias, 55-56 chance, 56-57, 57 cut-off point, 50 independence, assumption of, 70-71 multiple tests, 63, 67-71, 68 overview, 72-73 standards for disease, lack of, 47 imperfect, consequence~of, 47-48 Distribution abnormality and, 30, 30-34 actual, 32, 32-33, 32-33 describing, 30, 31 t, 32 frequency, 30 Gaussian, 34 normal, 33-34, 34 Dose-response relationships, 242 Double-blind, randomized controlled tria Is, 148 Duration of disease, incidence, prevalence, relationship, 78, 84-85, Wit Ecologic studies, 2.18 Effect, modification, 235, 236 Effectiveness, 151-152, 153 Efficacy, 151-152, 15,'! Error, random, 18fi-187 Explanatory trials, 151, 152 l'abe-positivlO rlOslllts, 44-45, 176, 17fit FrlOgulOncy, 7.')-93 distribution, 30 incidence, 76-89, 78 overview, 90-92 perceptions of, 76 Gaussian distribution, 34 Gold Standard, 45-41'> Guidelines c1inical,2h'J-21i1i detennining, validity of clinical studies, 267 -270 Hilwthorne effect, 143 Hypothesis testing, 187-19K raising, testing, 256-2S8, 257 ldeils, treiltment and, 131i-137 testing, 137 -138 Inception rohort, 112 Incidence, 76-78, 78, 79t, 80 cumulative, SO density, 80 measuring, 79-81 prevalence, duration of disease, relationship, 78, H4-KS, 85t studies of, 80-81 uses of, 87-89 Independence, assumption of, 7ll-71 Information, sources of, 21i3-2hS Intervention, 140-142 Kilplan-Mcir analysis, 119 labeling, 175 Latency,9S Likelihood ratios defined,64-65 serial, 71, 71 uses of, 6S-67, 66t Literature approaches to, 250-254 importance of, 25()-2S2, 251 IJsefulness of, 252-234, 254 Manageml'llt, trials, 151, 1.'i2 Matching, no Measurement, interpreting, 81-84 Multiple efft'cts, risk, 96-97, 97 INDEX 273 Multiple tests, diilgnosis and, 63, 67-71,68 Multivariilblc adjustml.'l1t, 132 :\\1ultivariilble methods, 203-20S Natural history, of disease, 112 Negative tests, lack of information on,46 Nonrt$ponders, in randomized controlled trials, 148 Normal distribution, 33-34, 34 Null hypothesis, 190 Number of patit>nts, hypothesis testing and, 193-198 Observation, 7, 142-143 Odds, h4 Odds ratio, 215-218, 217 Open label, 149 Outcome, 4-6 ilssessment of, randomized controlled trials, 149-150, L'iOt biologic, 6 clinical, 4, 5, 5t of diseilsc, describing, 113 rilndomized trials, 158-100, 160 I' \\',1Iucs,18,)-191l l'ar\"lIe! test~, 67-69, 69t I'eriodic ht'alth eXilminiltion, 168, 169t Phases of triills, 161 Place, compilfison across, \"157-158 Plilcebo treatment, 143, /44 I'lacebo effed, 143 Plausibility, biologic, cause ilnd, 244-245 Point estimates, 198-200, /99 Population, 6 defining, 83-84 risk and, 107-109, 108 samples and, 6 studies, 238, 239 Prediction prognosis and, 115, 116 of risk, 98 rules, 11.'), 116, INDEX Treatment-C(JIj Iinlied prevention and, 176-182 randomized controlled trial, 138-152,139-140 Trial explanatory, 151, 152 manageml'nt, 151, 152 phases, 161 randomized controlled, 138-152, 139-140 Uncontrolled trials, 15H--161 Validity, 22-23 clinical ~tudics, determining, guidelines for, 267-270 construct, 22 content, 22 criterion, 23  internal, external, 12, [12] [13] [14] 25t, [25] [26] [27] [28] [29] [30] [26] [27] [28] 28 effects of, 28, [28] [29] [30] [25] [26] 27 observer, 27 sources of, 25, 29 total, 28, 29 Zero time, [112] [113]"
    },
    {
      "text": "Figure 1.1.Confounding bias: Is herpesvirus 2 (HSV-2) a possible cause of cervical cancer? Only if its association with cervical cancer is independent of human papillomavirus (HPV) infection, known to be a cause of cervical cancer. Both viruses are related to increased sexual activity."
    },
    {
      "text": "Figure 1.2. Relationship between bias and chance: Blood pressure measurements by intraarterial cannula and sphygmomanometer."
    },
    {
      "text": "Figure 1.3. Internal and external validity,"
    },
    {
      "text": "Figure 1.4. Sampling bias: Range of risk of rupture (shaded area) in the next 5 years of abdominal aortic aneurysm \u00ab5.0 cm in diameter) according to whether the patient is from the general population or a referral center (6)."
    },
    {
      "text": "Figure 2.1. Validity and reliability. A, High validity and high reliability. B, Low validity and high reliability. C, High validity and low reliability, 0, Low validity and low reliability_ Tile dotted lines represent the true values."
    },
    {
      "text": "shows observations on one patient with"
    },
    {
      "text": "Figure 2.3. Biologic variability. The number of ventricular premature depolarizations (VPDs) for one untreated patient on 3 consecutive days, (Redrawn from Morganroth J, Michelson EL, HorowitL LN, Josephson ME, Pearlman AS, Dunkman WB, Limitations of routine long-term electrocardiographic monitoring to assess ventricular ectopic frequency, Circulation1978;58:408-414,)"
    },
    {
      "text": "Figure 2.4. Sources of variation. The measurement of diastolic (phase V) blood pressure, (Data from Fletcher RH and Fletcher SW; and Boe J, Humerfell S, Wedervang F, Oecon C, The blood pressure in a population [Special Issue]. Acta MedScand 1957;321:5\u2022-313.)"
    },
    {
      "text": "Figure 2.6. Actual clinical distributions. (Data from Martin HF, Gudzinowicz BJ, Fanger H. Normal values in clinical chemistry. New York: Marcel Dekker, 1975.)"
    },
    {
      "text": "Figure 2.7. The distribution of clinical variables changes with age: BUN for people aged 20-29 versus those 80 or older, (Data from Martin HF, Gudzinowicz BJ, Fanger H. Normal values in clinical chemistry. New York: Marcel Dekker, 1975.)"
    },
    {
      "text": "Figure 2.8. The normal (Gaussian) distribution."
    },
    {
      "text": "Figure 2.10. Abnormal as associated with disease. n,e relationship botween alcohol consumption and mortillity, (From Stlaper AG, Wannamethee G, Walker M, Alcohol and mortality in British men: explaining the U-shaped curve, Lancet 1888;2:12l';7-1 )73)"
    },
    {
      "text": "Figure 2.11. Regression to the mean."
    },
    {
      "text": "Figure 3.1. The relationship between a diagnostic lest result and the occurrence of disease, There are two possibilities for the test result to be correct (true positive and true negative) and two possibilities for the result to be incorrect (false positive and false negative),"
    },
    {
      "text": "Figure 3.2 summarizes some relationships between a diagnostic test and the actual presence of disease. It is an expansion of Figure 3.1, with the addition of some useful definitions. Most of the rest of this chapter deals"
    },
    {
      "text": "Figure 3.3. The accuracy of the clinical diagnosis of streptococcal pharyngitis compared with the results of throat culture, (Data from Fletcher SW, Hamann C. Emergency room management of patients with sore throats in a teaching hospital; influence of non-physician factors. J Comm Health1976; 1:196--204,)"
    },
    {
      "text": "Figure 3.5. ROC curves for the CAGE and MAST questionnaires in elderly patients with and without alcoholism. (Redrawn tram Jones TV, Lindsey BA, Yount P, Soltys R, Farani-Enayat B, Alcoholism screening questionnaires: arc they valid in elderly medical outpatients? J Gen Intern Med 1993;8:674-678,)"
    },
    {
      "text": "Figure 3.6. ROC curve for CEA as a diagnostic test for colorectal cancer, according to stage of disease. The sensitivity and sp8cificity of a test vary with the slage of disease. (Redrawn from Fletcher RH. Carcinoembryonic antigen, Ann Intern Med 1986; 104:66-73,)"
    },
    {
      "text": "Figure 3.7. The precision of an estimate of sensitivity, The 95% confidence interval for an observed sensitivity of 75%, according to the number of people observed,"
    },
    {
      "text": "Figure 3.8. Positive predictive value according to sensitivity, specificity, and-preva\u2022 lence of disease."
    },
    {
      "text": "Figure 3.10. Serial and parallel testing."
    },
    {
      "text": "Figure 3.11. Use of likelihood ratios in serial testing."
    },
    {
      "text": "Figure 3.12. Hle responsiveness ot two questionnaire measures of health status, Distinguishing between elderly patients with and without a major intervening illness. (Adapted from Wagner EH, LaCroix IV, Grothaus Le, Hecht JA. Responsiveness of health status measures to change among older adults. J Am Geriatr Soc1993;41 :241-248.)"
    },
    {
      "text": "Figure 4.1. Occurrence of disease in 100 people at risk from 1992 to 1994."
    },
    {
      "text": "3 illustrates the interview prevalences and the clinical examination prevalences for various conditions."
    },
    {
      "text": "Figure 4.3. Prevalence depends on the definition of a case. The prevalence of diseases in the general population based on people's opinions (survey) and clinical evaluation. (Data from Sanders BS. Have morbidity surveys been oversold? Am J Public Health 1962;52:1648-1659.)"
    },
    {
      "text": "Contors for lJisoaso ContlOl ami f'rovenliun crileria. (Adupled from U.S. OepHrtlTlHrlt of HeHlfh HnrllllJman Services. C\"\"e (!HrlrlitioflS for plJblic health SI.Jtv81I1ance.MMWR 198(1;c!Y;"
    },
    {
      "text": "\"Approxinll!tcd lronl severol Wur';es"
    },
    {
      "text": "Figure 4.4. Temporal relationship between possible causal factors and disease for incidence and prevalence studies."
    },
    {
      "text": "Figure 4.5. The difference in cases for inciderlce and prevalence studies."
    },
    {
      "text": "Figure 4.6. A decision tree. Management of a 70-year-old man with moderate symptoms from benign prostatic hyperplasia. (Data adapted lrom Barry MJ, Mulley AG, Fowler FJ, Wennberg JW. Watchful wailing Vg, immediate transurethral resection for symptomatic prostatism.JAMA 1988;259(20):3010-3017.)"
    },
    {
      "text": "5.1). Some people with hypertension"
    },
    {
      "text": "Figure 5.3. Historical and concurrent cohort studies."
    },
    {
      "text": "5.4B). When hypertension is defined asA o en 150 cc co ~----~J=r...r='=tUill1 -.. ~>;-100 .. .<:0 -. ."
    },
    {
      "text": "Hg01---,---,---,--1--,--,--,--"
    },
    {
      "text": "Figure 6.1. Differences between risk and prognostic factors for acute myocardial infarction"
    },
    {
      "text": "Figure 6.2. Survival of AIDS patients according to prognostic stage. Median survival times (in months): stage I, 11.6; stage II, 5.1, stage III, 2.1. (Adapted from JusliceAC, Feinstein AR, Weils CK. A new prognostic staging system for the acquired immunodeficiency syndrome. N Eng J Med 1989: 320:1388-1393,)"
    },
    {
      "text": "Figure 6.3. A limitation of 5-year survival rates: four conditions with the same tiyear survival rate of 10%. (Data from Anagnostopoulos CD et al. Aortic dissections and dissecting aneurysms. Am J Cardiology 1972:30:263-273; Sash JA, Hoover DR et al. Factors influencing survival after AIDS: mport from the Multicenter AIDS Cohort Study (MACS). J Acquir Immune Defic Syndr 1994;7:287-?95; Ksrdinal CG el al. Chronic [Jrsnulocytic leukemia, Review of 536 cases. Arch Intern Med 1976; 136:30tJ-313: and Americcln College of I ite Insurance. 1979 life insurance fact book, Washington, DC: ACLI 1979,)"
    },
    {
      "text": "Figure 6.4. Survival of two cohorts, small and large, when all members are observed for the full period of tallow-up."
    },
    {
      "text": "Figure 6.7. Locations of potential bias in cohort studies."
    },
    {
      "text": "Figure 6.8. Disease-free survival according to CEA levels in colorectal cancer patients with similar pathological staging (Dukes B). (Redrawn from Wolmark N et al. The prognostic significance of preoperative carcinoembryonic antigen levels in colorectal cancer. Results from NSABP clinical trials. Ann 8urg 1984; 199:375-382.)"
    },
    {
      "text": "Figure 6.9. Comparison of a true and a \"survival\" cohort: in the survival col1ort, some at the patients present at the beginning are not included in tile follow-up."
    },
    {
      "text": "fl.fl)."
    },
    {
      "text": "RFI'ERENCESI. Laupacis A. Changes in quality of lik ~nd functionlll copacity in hemodialysis patient.; treated with recombinant human erythropoietin. The C:,,\"~dian Erythropoietin Study Group, Semin '\\!~phroI199();2{SuppJ 1)1:1119. 2. Celbl'r RD ct al. Q\\J~ljly-of-lii\" (\"mlualion in \" clinical trial of zidovidine therapy in patients witl1 mildly ~ymrtomatic I IIV infl'clion, Ann Inkm 'vied 1992;116:961-'0166, 3. Justice AC, Feinstein AI{, Wells CK. A ,,,' W prognostic staging system for thl' acquired inununodefidency syndrome. N Fng ] Med 19S9;320:lJHH-1393 4. Wolmark N et \"I. Thl' prognostic significance of p'eoperativp carcino~mbr}'onicantigen IeveIs in coloredal nmcer. Results i\",m the f\\SABP dinicaltrillls, Ann Surg 19M; 199:375-382, 5, Bridg,,'s AI, Conley C. Wang G, BlIrn~DF. Vasey FIJ. A dinical and immunologic evaluation of women wilh silicone breast implants and s}'mpt()m~of rheumatic diseasl'. Ann Intern Med 1993;]]8:929 <HIi. Ii. Cabri~l SC, O\u2022FaIlon Wlvl, Kurland IT, Beard CM, Woods JE, Ml'iton LJ Ill. I;:i~k of"
    },
    {
      "text": "Figure 7.1. The structure of a clinical trial."
    },
    {
      "text": "Figure 7.2. Bias in clinical trials."
    },
    {
      "text": "Figure 7.4. The effects of most drugs are partly attributable to the placebo effect. (Redrawn from Fletcher RH. The clinical importance of placebo effects. Fam MedRev 1983; 1:40-48.)"
    },
    {
      "text": "Figure 7.5. Total effects of tmatment are the sum of spontaneous improvement, nonspecific responses, and the effocts of specific treatments."
    },
    {
      "text": "Figure 7.6. Intention to treat and explanatory trials."
    },
    {
      "text": "Figure 7.7. Efficacy and effectiveness."
    },
    {
      "text": "Figure 7.8. Severity of illness and skill of surgeons vary by location. Observed and expected (taking into account case mix) death rate from coronary bypass surgery in 1I1reB hospitals. (Data from Topol EJ, Califf RM. Scorecard cardiovascular medicine. Its impact and future direction.Ann Intern Med 1994; 120:65-70,)"
    },
    {
      "text": "Figure 7.9. The unpredictable course of disease, The natural history of systemic lupus erythematosus in a patient observed before the advent of immunosuppressive drugs, (Redrawn from Ropes M. Systemic lupus erythematosus. Cambridge, MA: Harvard University Press, 1976.)"
    },
    {
      "text": "Figure 8.1. Levels of prevention."
    },
    {
      "text": "Figure 8.2. Yiold of a screoning test according to patients' age. Ratio of nonmalignantmalignant biopsy results among women screened for breast cancer. (Data from Baker LH. Breast Cancer Detection DOrTlonstration Project: five-year summary report.CA 1982;32:195-231.)"
    },
    {
      "text": "romSackett OL, Clinical Jiagnosis Hmj the c1imcallaboratofY. C1in Invesl MH<t 19713: l:M -4:3,   than most anything else a clinician can do, but counseling that does not work wastes time, costs money, and may harm pati<:nts."
    },
    {
      "text": "Figure 8.4. How lead time affects sUNival lime after screening; shaded areas indicate length of sUNival after diagnosis (Ox)."
    },
    {
      "text": "Figure 8.5. Length time bias. Cases that progress rapidly from onset (0) to symptoms and diagnosis (Ox) are less likely 10 be detected during a screening examination."
    },
    {
      "text": "Length time bias. Rapidly growing tumors come to medical attention before screening is petiorrned, whereas more slowly growing tumors allow time for detection. D, diagnosis after symptoms; S, diagnosis after screening,"
    },
    {
      "text": "Figure 8.8. Weighing bcnefit and harm tl\"Om screening. What happens during a decade of annual mammography in 1OOll women starting at ago 40,"
    },
    {
      "text": "Figure 9.1. The relationship between the results of a statistical test and the true difference between two treatment groups. 'Absent is a simplification. It really means that the true difference is not greater than a specified amount.)"
    },
    {
      "text": "WllElre n = numr)(~r or patients studierl; .0. = size of rlifference in outcome between groups; P\" = probability of an\" !Type I) error, i.e., talse-positive results: p\" = probability of a {3 (Type II) error, i,e\" talse-negative result; V variability ot observations (tor inlerval data): and P proportion ot patients experiencing outcome of interest (for nominal data)"
    },
    {
      "text": "Figure 9.3.The number of people required in each of two treatment groups (of equal size) to have an 80% chance of detecting a difference (p = 0.05) in a given outcome rate (P) between treated and untreated patients, for various rates of outcome events in the untreated group, (Calculated from formula in Weiss NS, Clinical epidemiology. The study of the outcome of illness, New York: Oxford UniversityPress, 1986.)"
    },
    {
      "text": "Figure 9.4. Point estimates (0) and confidence intervals (1): the risks ami benefits of exogenous fJstrogens for postmenopausal women. (Data from Grady D, Rubin 8M, Petitti DB, Fox GS, Black lJ, tttinger R, Ernster VL, Cummings SR. Ilormonal thempy lo prevent disease and prolong life in postmenopausal women, Ann Intern Mod 1992; 117:1016-1037; Coldit7 GA, Starnpfer MJ, Willett we, Hennekens CH, Rosner [3, Speizer FE. Prospective study of estrogen replacement therapy and risk of broast cancer in postmenopausal women. JAMA 1990;264:2648-2653; and Paganini-Hill A, nos; RK, Gerkin::; VR, Ilcndcrson t)c, Arthur M, Mack TM Menopausal estrogen therapy and hip fractures. Ann Intern Med1981 ;95:?8-31.)"
    },
    {
      "text": "Figure 10.1. The design of case-control studies."
    },
    {
      "text": "Figure 10.2 A comparison of case-control alld cohort studies. Studies of NSAIDs as a risk factor for retial failure."
    },
    {
      "text": "Figure 10.3 Calculation at relative risk for Cl cohort study and odds ratio (estimated relative risk) for a case-control study."
    },
    {
      "text": "Figure 11.1. Causes of tuberculosis."
    },
    {
      "text": "Figure 11.2. A, Declining death rate from respirafory tuberculosis in England and Wales over the past 150 years. (From McKeown T The role of medicine: dream, mirage or nemesis. London: Nuffield Provincial Hospital Trust, 1976.) B, Excess tuberculosis cases in the United States, 1985-1992. Difference between expected and observed number of cases. Dotted line, observed cases; solid line, expected cases. (From Cantwell MF, et al. Epidemiology of tuberculosis in the United States, 1985 through 1992  . JAMA 1994;;272:535-539.)"
    },
    {
      "text": "Figure 11.4.Example of effect moditication: how the risk of cardiac arrest in pa tients using thiazide diuretics (compamd with the risk of cardiac arrest in patients using beta-blockers) changes according to use of potassium-sparing diuretics, Odds ratios-with 95% confidence intervals (GI) ---increase with increasing dose of diumtic, suggesting that it is safer to use beta-blockers than thiazide diuretics. However, with the addition of potassium sparing diuretics, thiazide diuretics cause a lower risk of cardiac arrest than beta-blocker therapy, (Redrawn fromSiscovick OS, et al. Diuretic"
    },
    {
      "text": "Figure 11.5. Association and cause."
    },
    {
      "text": "Figure 11.6. Example of an aggregate risk study: relationship between wine consumption and cardiac mortality in developed countries. (Drawn from 81. Leger AS, Cochrane AL, Moore F. Factors associaterl willl cardiac mortality in developed countries with particular reference to the consumption of wine.Lancet 19/9; 1.1017- 1020,)"
    },
    {
      "text": "Figure 11.7. A time-series study of the relationship of c1indamycin use and Clostrid\u2022 ium diffie/Ie-associated diarrhea (Redrawn from Pear SM, Williamson TH, Bettin KM, Gerding ON, Galgiani IN. Decrease in nosocomial Clos/ridium difficile-associated diarrhea by restricting c1indamycin use. Ann Intern Medl1 94;120:272--277_)"
    },
    {
      "text": "Figure 11.8. Example of a dose-response relationship: lung cancer deaths ac cording to dose of cigarettes in male physicians. (Drawn from Doll R, Peto R. Mortality in relation to smoking: 20 years' observations on male British doctors. Br Med J1976; 2: 1525-1536.)"
    },
    {
      "text": "Figure 11.9. Reversible association: declining mortality from lung cancer in excigarette smokers. The data exclude people who stopped smoking after gettin9 cancer. (Drawn from 0011 R, Petro R. Mortality in relation to smoking: 20 years' observations on male British doctors Br Med J 1976;2:1525-1536.)"
    },
    {
      "text": "Figure12.1. The literature on a research question: the relative value of various kinds of articles for answering a clinical question."
    },
    {
      "text": "Figure 12.3. Developing a IIYPotllesis on Orle data set and testing it Ofl anolhcr."
    },
    {
      "text": "Figure 12.4. Results of a meta-analysis of the effectiveness of BeG vaccination to prevent tuberculosis. C/, confidence interval. (Based on Colditz GA Brewer TF, Berkey es, Wilson ME, Burdick E. Fineberg HV, Mosteller F, Efficacy of BeG vaccine in the prevention of tuberculosis: meta-analysis of the published literature. JAMA1994;271 :698-702.)"
    },
    {
      "text": "2Outcomes of Disease {the Five Ds)B"
    },
    {
      "text": "1 Summarization of Clinical Data: A Patient's Problem List and the Data on Which It Is Based"
    },
    {
      "text": "Trade~Off between Sensitivity and Specificity when Diagnosing Diabetes\""
    },
    {
      "text": "Effect of Sequellce ill Serial Testing: A theil B versus B Theil A\""
    },
    {
      "text": "3The Relationships among Incidence, Prevalence, and Duration of Disease: Asthma in the United States R"
    },
    {
      "text": "1 Cohorts and Their pUl'll0SeS"
    },
    {
      "text": "4 Calculating Measures of Effect: Cigarette Smoking and Death from Lung CancerS Doll R, Hill A8. 8r Med J 196~; t 1399-1410,"
    },
    {
      "text": "1 Rates Commonly Used to Describe Prognosis"
    },
    {
      "text": "2 Methods for Controlling Selection Bias"
    },
    {
      "text": "3 Example of Stratification: Hypothetical Death Rates after Coronary BYP8SS Surgery in Two Hospitals, Stratified by Preoperative Risk"
    },
    {
      "text": "Criteria for Deciding Whether a Medical Condition Should Be Included in Periodic Health Examinations 1. How greflt is thc burden of $utterirlg caused by lhe condition in terms of:"
    },
    {
      "text": "2 Patients' Acceptance of Screening Tests: Reported Response Rates for Returning Guaiac-impregnated Slides in Different Settings\u2022"
    },
    {
      "text": "3 Relation between Number of Tests Ordered and Percentage of Normal People with at Least One Abnormal Test Resutt\""
    },
    {
      "text": "............."
    },
    {
      "text": "1Evidence That an Association Is Cause and Effect\""
    }
  ],
  "references": [
    {
      "title": "&chi&m. Epidemiology, medie;n\" ~nd public health",
      "authors": [
        "I Kl"
      ]
    },
    {
      "title": "Clinical medidne m\"\"\"t~modern epidemiology-and both profit",
      "authors": [
        "\" Fl"
      ],
      "year": 1992
    },
    {
      "title": "logic of medicine",
      "authors": [
        "E Murphy",
        "Th"
      ],
      "year": 1976
    },
    {
      "title": "Bias in analytic re~earch"
    },
    {
      "title": "Antibodi\"s to human papillomavirus and to other genital infectious agents and inva~iv\", cervical cancer risk",
      "authors": [
        "Pks Jha",
        "V Beral",
        "J Peto",
        "S Hack",
        "Hermon Deacon",
        "J Mant",
        "D Chilver~c",
        "\" Vess",
        "'y Mp",
        "Pik\" Me",
        "M Muller",
        "L Gissmailll"
      ],
      "year": 1993
    },
    {
      "title": "Abdominal aortic aneurysm II k'tterl",
      "authors": [
        "Ballard Df"
      ],
      "year": 1993,
      "doi": "10.1056/nejm199310213291715"
    },
    {
      "title": "Steering Committee of the Physicians\u2022 Ilealth Study I\u2022k~earch Group. Final report on the aspirin component of the ongoing Physicians' IleJlth Study",
      "year": 1989,
      "doi": "10.1056/nejm198907203210301"
    },
    {
      "title": "Collaborative overview of randomized trials of antiplatelet therapy-l. Prevention of d\"ath, myocardial infilretion, and stroke by prolonged antiplatdd therapy in various categories of patients",
      "year": 1994
    },
    {
      "title": "logical",
      "authors": [
        "B Ncs Andersen",
        "Mcthod"
      ],
      "year": 1990
    },
    {
      "title": "Clinical economics. A guide to the ,'nmomic analysis of clinical practices"
    },
    {
      "title": "glitter of the I table",
      "authors": [
        "T Jolley",
        "Th"
      ]
    },
    {
      "title": "MJking compari~on~. I.ane",
      "authors": [
        "J Grisso"
      ],
      "year": 1993
    },
    {
      "title": "You cannot exclude the expbnation you haven't considered",
      "authors": [
        "M Datla"
      ],
      "doi": "10.1016/0140-6736(93)91478-5"
    },
    {
      "title": "Estimating the effects of misclassification",
      "authors": [
        "Mert<m~te"
      ],
      "year": 1993
    },
    {
      "title": "Failed or misleading adjustment for confounding",
      "authors": [
        "D Le~m"
      ],
      "year": 1993
    },
    {
      "title": "Sitlhi-amorn C, 1\"oshachinJa V. Bia~",
      "year": 1993,
      "doi": "10.1016/0140-6736(93)91823-5"
    },
    {
      "title": "A question of attribution",
      "authors": [
        "J Glynn"
      ],
      "year": 1993
    },
    {
      "title": "study worth doing?",
      "authors": [
        "1m Carpenter",
        "Th"
      ],
      "doi": "10.1016/0140-6736(93)92304-c"
    },
    {
      "title": "Symptoms and circulating hemoglobin level",
      "authors": [
        "P Elwood",
        "W W~ters",
        "Wjw Greene"
      ],
      "doi": "10.1016/0021-9681(69)90034-4"
    },
    {
      "title": "Alcohol and mortality in British men: explaining the V-shaped curve",
      "authors": [
        "A Shaper",
        "C Wannamethee",
        "M Walker"
      ]
    },
    {
      "title": "The \u2022'abnormal\" screening serum thyroxine (T 4 ): una lysis of physician response. outcome, cost and health and dfediveness",
      "authors": [
        "K Epstein",
        "L Schneiderman",
        "Bush )ln",
        "A Zettner"
      ],
      "year": 1980
    },
    {
      "title": "partmenl of Clinical Epidemiology and Biostatistics, McMaster Uni~Trsity, Clinical disagreement II. How to avoid it and how to learn from on\"\u2022s mistakes",
      "year": 1980,
      "doi": "10.1097/00132586-198104000-00066"
    },
    {
      "title": "Clinical judgment",
      "authors": [
        "A Feinstein"
      ],
      "year": 1967
    },
    {
      "title": "Problems in measurement, dinieal biostatistics",
      "authors": [
        "A Feinstein"
      ],
      "year": 1977
    },
    {
      "title": "TIle reliability of dinical methods, data and judgment",
      "authors": [
        "L Koran"
      ],
      "year": 1975,
      "doi": "10.1056/nejm197510022931405"
    },
    {
      "title": "Remarks on clinical \"norms",
      "authors": [
        "D Mainland"
      ],
      "year": 1971
    },
    {
      "title": "logic of medicine",
      "authors": [
        "E Murphy",
        "Th"
      ],
      "year": 1976
    },
    {
      "title": "suring health-related quality of lif",
      "authors": [
        "Cj Cuy~tt",
        "I:Eeny Dh",
        "Di Patrick"
      ]
    },
    {
      "title": "aluation, and Treatment of High Blood Pres-MIre. The fifth report of the Joint National Committee on I:kkdinn, Evaluation, and Treatment of High J3l ood Pressure (JNC V)",
      "year": 1993,
      "doi": "10.1001/archinte.1993.00410020010002"
    },
    {
      "title": "Measuremenl of pro,tilk-sp\"cific antigen in serum as a screening kst for prostate Cilncer",
      "authors": [
        "W Catalona"
      ],
      "year": 1991
    },
    {
      "title": "Magnetic resonance imaging of the lumbar spine in people without back pain",
      "authors": [
        "Brant-Zawadzki Kmen Me",
        "Ml\\",
        "N Obuchowski",
        "M Modic",
        "D Millkasi~n",
        "I Ross"
      ]
    },
    {
      "title": "Ultrasonic \"nd radiographic cholecystography",
      "authors": [
        "R Bartrum",
        "I'oote Crow Lic",
        "Sr"
      ],
      "year": 1977,
      "doi": "10.1056/nejm197703102961004"
    },
    {
      "title": "Farani-EnilYilt 11 Alcoholism screening questionnaires: are th.,y vilild in elderly medical o\\ltpiltimts?",
      "authors": [
        "T Jones",
        "R Lindsey",
        "P Yount",
        "R Soltys"
      ],
      "year": 1993
    },
    {
      "title": "{J l. Carcinoembryonic antigen",
      "authors": [
        "Fldcher"
      ]
    },
    {
      "title": "Screening for HTI.V III antibodies: the rebtion between prevalPT1ce ilnd positive predictive value ~nd its social consequences",
      "authors": [
        "J Voss",
        "H Barry",
        "M Milii",
        "\" Ac",
        "D Singer"
      ],
      "year": 1994
    },
    {
      "title": "I ,ilboratory and epidemiologic evaluation of an enzyme immunoassay for antibodies t\" HTLV 111",
      "authors": [
        "Jw",
        "A Crindon",
        "P Feorino",
        "C Schable",
        "M Parvin",
        "J Allen"
      ]
    },
    {
      "title": "Analysis of probability il\" an aid in the clinical diagnosis of coronary artery disease",
      "authors": [
        "Hi",
        "G Diamond",
        "Forrester Js"
      ]
    },
    {
      "title": "Prilctice databases and their \\lOt's ill dinieal research",
      "authors": [
        "W Tierney",
        ": Mcdonald"
      ],
      "year": 1991
    },
    {
      "title": "Use of a single thyroxine lest to evaluate ambuliltory medical pillients for suspected hypothyroidi~m",
      "authors": [
        "Goldstein Ilj",
        "A Mushlin"
      ],
      "year": 1987
    },
    {
      "title": "1 sUt,<,ning for LAwm's syndrom\" with uS{' of maternal serum marker~",
      "authors": [
        "J Iladdow",
        "G Palomaki",
        "Knight Cj",
        "] Williams",
        "I Pulkkinen",
        "Ja Canick",
        "D:'j Saller",
        "Jr",
        "G Bowers",
        "Prenilt"
      ]
    },
    {
      "title": "cht JII. ]{esponsiveness of heilah stalus measures to change among older \"dulls",
      "authors": [
        "E Wagnn",
        "A Lacroix",
        "I Grolhau"
      ],
      "year": 1993
    },
    {
      "title": "Interprelation of diagnostic ,lilta. V, How to do it willl simple math",
      "authors": [
        "Suggested Readincs Cebul L{u",
        "L I3eck"
      ],
      "year": 1985,
      "doi": "10.1177/0272989x8600600411"
    },
    {
      "title": "Nomogrilm for Bayes' theorem",
      "authors": [
        "T Fagan"
      ],
      "year": 1975,
      "doi": "10.1056/nejm197507312930513"
    },
    {
      "title": "Selection and interpretdtion of diagnostic tests and procedures. Principles and applications",
      "authors": [
        "' Griner",
        "R Mu~hlin",
        "A Greenland"
      ],
      "year": 1981
    },
    {
      "title": "nland P. Clini<:al didgnosis and the laboratory: logi<:<ll strategies for common medical problems",
      "authors": [
        "P Criner",
        "R Panzer"
      ],
      "year": 1986,
      "doi": "10.1177/0272989x8700700412"
    },
    {
      "title": "Brigham and Women's Hospital handbook of diagnostic imaging",
      "authors": [
        "B Mcneil",
        "H Abr~ms"
      ],
      "year": 1986
    },
    {
      "title": "C1inicJI ilpplication of decision analysis: a detailed illustration",
      "authors": [
        "S Pauker"
      ],
      "year": 1978,
      "doi": "10.1016/s0001-2998(78)80018-x"
    },
    {
      "title": "The assessment of didgnostic tests. A survey of current medicdl research",
      "authors": [
        "Sh\"ps Si3",
        "M Schechter"
      ]
    },
    {
      "title": "Probability theory in the u~e of diagnostic tests. An introduction to critical study of the literature",
      "authors": [
        "H Sox"
      ],
      "doi": "10.7326/0003-4819-104-1-60"
    },
    {
      "title": "Clinical prediction rules. applications and methocloloj';icaJ standnnh",
      "authors": [
        "Sox He",
        "M Blatt",
        "Higgins Me",
        "Ki Marton",
        "Butterworth ; Wasson",
        "Sox Jil",
        "He",
        "R Neff",
        "L Goldman"
      ],
      "year": 1985
    },
    {
      "title": "Clinical decision analysis",
      "authors": [
        "Weinstein Me",
        "B Fineberg",
        "A Elstcin",
        "H Frazier",
        "D Neuhauser",
        "R Nculra",
        "B Mcneil"
      ],
      "year": 1980
    },
    {
      "title": "JOxpressions of probilbility: words and numbers",
      "authors": [
        ", Bryant"
      ],
      "year": 1980
    },
    {
      "title": "What do we mean by \"usually",
      "authors": [
        "J Toogood"
      ]
    },
    {
      "title": "Beni b 'l1 prostatic hyperplasia: diilgnosis and treatment. C1in Pract Guid",
      "authors": [
        "] ~cconn\"]l",
        "M Barry",
        "R Bruskewit~"
      ],
      "year": 1994
    },
    {
      "title": "Medical usag<' and abusage, \"prevalence\"' and \"'incidPnce",
      "authors": [
        "G Friedman"
      ],
      "year": 1976
    },
    {
      "title": "The prevalence of dementia as measured by the Cambridge Mental Disorders of the IJIderly Fxaminiation",
      "authors": [
        "D O'connor",
        "Poett Hyde",
        "}b Fellows",
        "J Miller",
        "N Brook",
        "Cpb Reiss",
        "B I~oth"
      ],
      "year": 1989
    },
    {
      "title": "Incidence of dementia in a popubtion older that 75 years in the United Kingdom",
      "authors": [
        "E Paykel",
        "C I3rilyne",
        "C Huppert 1 ; Cill",
        "C Barkley",
        "E Gehlham",
        "I Beardsalj",
        "O Girling",
        "' Pollitti",
        "O' Connor"
      ],
      "year": 1994
    },
    {
      "title": "Have morbidity surveys been oversold?",
      "authors": [
        "B Sanders"
      ],
      "year": 1962
    },
    {
      "title": "Case definitions for public health surveillunre"
    },
    {
      "title": "Epidemiology of Lyme diseilse in Olmsted COllnty",
      "authors": [
        "E Matteson",
        "Be<:Kett",
        "O Vl",
        "W ; 'fallon",
        "J Duffy"
      ],
      "year": 1975
    },
    {
      "title": "TIle arthritic complaint in primary care: prevalence, related di,abili!y, and l\"0sts",
      "authors": [
        "W Spitzer",
        "M Hilrth",
        "Cii Coldsmith",
        "C Norman",
        "C Dickie",
        "M} Bass",
        "Newell"
      ],
      "year": 1976
    },
    {
      "title": "Incidence of Crohn's dist'ase in Olmsted County, Minnesota, 1935-1975",
      "authors": [
        "R Sedlack",
        "J Whisnant",
        "I Elveback",
        "L Kurland"
      ]
    },
    {
      "title": "Symptom status ,md quality of life following prosMectorny",
      "authors": [
        "( Fowl",
        "J Wennlwrg",
        "J Timothy",
        "R Rarry",
        "\\1j Mulley",
        "A Hanky Lj"
      ],
      "year": 1988
    },
    {
      "title": "An analysis of the cost-dfecliveness of pharyngitis m,lnagement and acute rheumat;\": f\"ver prevention",
      "authors": [
        "R Tompkins",
        "W Cable"
      ],
      "year": 1977
    },
    {
      "title": "Watchful waiting vs. immediate transur,thral resection for symptomatic prostatism",
      "authors": [
        "He Sox",
        "M Blatt",
        "Higgins Me",
        "Marton Kl",
        "; Barry",
        "M Mulley",
        "A Fowler"
      ],
      "year": 1988
    },
    {
      "title": "Sample selection and the natural history of disease: studies of febrile seizures",
      "authors": [
        "J Suggested Keadings Fllmb<'rg",
        "K Nelson"
      ]
    },
    {
      "title": "Medical usage und abusage, \"prevalence\" and \"incidenc<",
      "authors": [
        "G Friedman"
      ],
      "year": 1976
    },
    {
      "title": "Kupper 1.1 , Measures of disease incidence used in epidemio_ logic research",
      "authors": [
        "H Ivlorgenstern",
        "U Kleinbaum"
      ],
      "year": 1980
    },
    {
      "title": "An'ounting for th\", multicausal n~tur~of diseJse in the design ~nJ analysi~of epidemiologic studies",
      "authors": [
        "N Weiss",
        "J Liff"
      ]
    },
    {
      "title": "Antibodies to hum~n papillomllvirus and to other genitol infectious ~gl'nls and invasive cervical c~ncer risk",
      "authors": [
        "Ksj Pr~bhat",
        "V Beral",
        "J Peto",
        "S H~ck",
        "Hermon Deacon"
      ],
      "year": 1993
    },
    {
      "title": "Sick individuals and sick populations",
      "authors": [
        "G Rose"
      ],
      "year": 1985
    },
    {
      "title": "Analysis of probability as ,m aid in the clinical diagnosis of coronary-artery disellse",
      "authors": [
        "G Diamond",
        "Forrester Js"
      ],
      "year": 1979
    },
    {
      "title": "National case-control study of Kaposi's S<lrcoma and Pncumocystis carini; pneumonin in homosexual men. Part 1, Fpidemio!qgic results",
      "authors": [
        "H Jaffe"
      ],
      "year": 1983
    },
    {
      "title": "Ih., epidemiology of athcro~cleroti,' di~ease. Cambridg",
      "authors": [
        "T Dawher"
      ],
      "year": 1980
    },
    {
      "title": "Growth and development in children with ~ickJe-cell trail",
      "authors": [
        "M Kramer",
        "Y Rooks",
        "H Pearson"
      ],
      "year": 1978
    },
    {
      "title": "Risk ratio~and risk differences in estimating the effect of risk factors for cardiovascular disease in the elderly",
      "authors": [
        "B P~aty",
        "Nl"
      ],
      "year": 1990
    },
    {
      "title": "~big id",
      "authors": [
        "A Hofmnn",
        "Geoffrey Vandenbroucke",
        "Rose"
      ],
      "year": 1992
    },
    {
      "title": "The hazards of using adive clinic patients as \" source of subjects for clinical stmlie~",
      "authors": [
        "A Detsky",
        "O 'rourke",
        "K Corey",
        "P Johnston",
        "N Fenton",
        "S Jeejecbhoy"
      ],
      "year": 1988,
      "doi": "10.1007/bf02596342"
    },
    {
      "title": "Kelsey JL Scientifk ~tandards of criticism: a reaction to \"Scientific standards in epidemiologic studies of the menace of daily life\" by Feinstein",
      "authors": [
        "A Sci",
        "D Savitz",
        "S Greenland",
        "P Stolley"
      ],
      "year": 1990
    },
    {
      "title": "The framing effect of rdative and absolute risk",
      "authors": [
        "D Malenka",
        "J Ban",
        "Johansen 5",
        "J Wahrenberger",
        "1m Ross"
      ],
      "year": 1993
    },
    {
      "title": "Measures of di~ease incidence used in epidemiologic re~eilrch",
      "authors": [
        "H Morganstern",
        "Lx~ Kleinbaum",
        "L Kupper"
      ],
      "year": 1980
    },
    {
      "title": "Measured enthusia~m: does the method of reporting trial result~alter perceptions of therapeutic effectiveness?",
      "authors": [
        "C Naylor",
        "Chen Straus~b"
      ],
      "year": 1992
    },
    {
      "title": "conneclive-ti~~ue ui~eascs and other di~(lrd..r~after breast implantalion",
      "year": 1994
    },
    {
      "title": "Long-term outcomes of morbidly obese patient~tr\"\"ted with gastroga~lrostomy",
      "authors": [
        "K Thompson",
        "()' Sw",
        "M I\\bli~y",
        "Buckwalt"
      ],
      "year": 1986
    },
    {
      "title": "The a~~ociati()n of changes in physical-activity level and other lifestyle chMacleri~lic~with mortality among men",
      "authors": [
        "H Rs",
        "R Hyde",
        "A Wing",
        "Jung Ljl",
        "J Kampert"
      ],
      "year": 1993
    },
    {
      "title": "Chambers 1m, Norri~JW Outcome in patients wilh a~ymrtom\"tic neck bruits"
    },
    {
      "title": "The University Croup Diabete~Pmgram, A further statistical analy~i~of the mortillity findings",
      "authors": [
        "J Cornfield"
      ],
      "year": 1971,
      "doi": "10.1001/jama.1971.03190120044009"
    },
    {
      "title": ",11 Co Canadian Nalional llr\"ast Screening Study. 1. Breast cancer detection \"nd death rates among wom\"n ,lged 40 to 49 year~",
      "authors": [
        "Mill\"r Ab",
        "W Teres~te"
      ],
      "year": 1992
    },
    {
      "title": "13oston",
      "authors": [
        "T Succested Readings C\"lton",
        "Statistic~in"
      ],
      "year": 1975
    },
    {
      "title": "111e risk of determining risk with multivariable models",
      "authors": [
        "J Cnncato",
        "I 'einstein",
        "Ai< Hulford"
      ]
    },
    {
      "title": "The INili I<og\"rs phenomenon-stage migration and new diJgn()~tic techniques as a source of misleading statistics for ~urvivJI in Cclnn",
      "authors": [
        "I'einstein Ai<",
        "D Sosin",
        "C Wells"
      ]
    },
    {
      "title": "v1easuring health-r,-,bt~d gu,dity of life",
      "authors": [
        "Cuyatt Cll",
        "D Feeny",
        "D P~trkk"
      ]
    },
    {
      "title": "xperimental pJradigm and observational studies of cause-died rdationships in dini~al medicine",
      "authors": [
        "R Horwitz",
        "Th"
      ]
    },
    {
      "title": "U8er~' guides to the medical literature. V Ho\\\\' to 118e ~n \"rticle about prognosis",
      "authors": [
        "C Wells",
        "S Rirhardson",
        "P Tugwell"
      ],
      "year": 1994
    },
    {
      "title": "ksign and analysb of r,mdumiz,xi dinic.lltrials requiring prolonged observation of each patient",
      "authors": [
        "L Peto R D Al",
        "Analy~is"
      ],
      "year": 1977
    },
    {
      "title": "oldman L. Clinical pn,dktion rules; applications and method\u2022 ological st.lndards",
      "authors": [
        "H Sox",
        "I~k Ndl"
      ]
    },
    {
      "title": "Treatment of gram neg\"tive bacteremia and septic shock with HA-IA human monoclonal antibody against endotoxin",
      "authors": [
        "Iegler Ej"
      ],
      "year": 1991
    },
    {
      "title": "The Lipid Research Clinics coronary primary prevention trial results. 1 Reduction in incidence of coronary heart disease",
      "authors": [
        "Coronmy Drug",
        "Project Research Croup ; R L ; Iyington"
      ],
      "year": 1985
    },
    {
      "title": "An ~~s;,~sment of clinically useful mea~UreS of the mnsequence~of treatment New Engl",
      "authors": [
        "S\"ckelt Dl",
        "R Roberb"
      ],
      "year": 1988
    },
    {
      "title": "u~s 1:1. Mea~ured enthusia~m: does the method of reporting trial re~ulb alter perceptions of tht'f~peutic effectiveness?",
      "authors": [
        "C Naylor"
      ],
      "year": 1992
    },
    {
      "title": "nberger jW, Ross .1M. nlC framing effect of rdative \"nd absolute rbk",
      "authors": [
        "O Malenka",
        "S Hamn",
        "Wahr"
      ],
      "year": 1993
    },
    {
      "title": "A. On th\" elicitation of preference~for <lliernative th\"rapies",
      "authors": [
        "Mcneil Hj",
        "S Pauker",
        "I Sox",
        "Ic Ir",
        "' Tvt",
        "Fsky"
      ]
    },
    {
      "title": "Controver~y in counting ~nd attributing events in clinical trials",
      "authors": [
        "D Sackett",
        "M Gent"
      ],
      "year": 1979
    },
    {
      "title": ":ering Commilte<:e of tile Physicians' Ht'alth Study R,~eMCh Group !'inal report of the aspirin component of the ongoing Physicians' Hl'alth Study",
      "authors": [
        "Ste<"
      ],
      "year": 1989
    },
    {
      "title": "Determining optimal th\",rapy-randomized trials in individual patients",
      "authors": [
        "C Guyatt",
        "D Sackett",
        "O T<lylor",
        "Rob Rts",
        "R Pugsley"
      ],
      "year": 1986,
      "doi": "10.1056/nejm198604033141406"
    },
    {
      "title": "The Will Roger~pht'nornenon, Stage migration ~l1d new diagnostic techniques as a source of misleading statistics for survival in cancer",
      "authors": [
        "A Feinstein",
        "D Sosin",
        "W\"lls Ck"
      ],
      "year": 1985,
      "doi": "10.1056/nejm198506203122504"
    },
    {
      "title": "Randomized ver~\\l~historical controls for clinical trials",
      "authors": [
        "S<:T\\k",
        "Ii",
        "T Chalmers",
        "I Smith"
      ],
      "year": 1982
    },
    {
      "title": "Scorecard cardiovascular medkin<:e. lis impa(\u2022t and future direction",
      "authors": [
        "Topol Fj",
        "R C~liff"
      ],
      "year": 1994
    },
    {
      "title": "Systemic lupus erythematosus",
      "year": 1976
    },
    {
      "title": "Guide to clinical interpretation of data",
      "authors": [
        "B Spilker"
      ]
    },
    {
      "title": "k 1:1, Mostelkr F. Reporting on mcthod~ill clinical trial~",
      "authors": [
        "R Dersimonian",
        "Charette Lj"
      ]
    },
    {
      "title": "An additional basic science for clinical medicine, J1: The limitations of r\"ndomized trial~",
      "authors": [
        "A Feinstein"
      ]
    },
    {
      "title": "undamt'ntllis of dinical trials",
      "authors": [
        "L Hiedman",
        "I'urberg Cd",
        "De Met~dl"
      ],
      "year": 1985
    },
    {
      "title": "How to read clinical journals. II: How tu use and article about ther~py or prevention. A: Are the results of the ~tudy valid?",
      "authors": [
        "Cii Guyatt",
        "D Sackett",
        "D Cook"
      ],
      "year": 1993
    },
    {
      "title": "How to read clinical journals. II: I low to use ilnd article about therapy or prevention, B: What were the n'~ult5 and will they help me in caring for my patient~?",
      "authors": [
        "C Guyatt",
        "Di\" Sackett",
        "D Cook"
      ],
      "year": 1994
    },
    {
      "title": "Determining optimal therapy-randomized trials in indiviuual patients",
      "authors": [
        "G Guyatl",
        "Sackett",
        "O Taylor",
        "J Chong",
        "I{ Roberts",
        "Pui-",
        "S Iey"
      ],
      "doi": "10.1056/nejm198604033141406"
    },
    {
      "title": "the medicalliteratun:, V: How to use an article about progno~is",
      "authors": [
        "Hdlman 5",
        "Ds ; H'j Hellman",
        "A Laupakis",
        "G Welb",
        "S Richardson",
        "; Tugwdl",
        "P Lavori",
        "I'a Louis",
        "Ljaiiar Je 1j1",
        "M Polan~ky"
      ],
      "year": 1994
    },
    {
      "title": "Clinical trials: design, conduct and analysis",
      "authors": [
        "Meinert"
      ],
      "year": 1986
    },
    {
      "title": "'porting ~tandards and research ~trategie~for controlled triab, Control CEn Trials I",
      "authors": [
        "F Mu~tell1er",
        "Mcpeek Gilbert]l'"
      ]
    },
    {
      "title": "A consumer's guide to ~ubgrOlJp analysis",
      "authors": [
        "A Oxman",
        "C Cuyutt"
      ],
      "year": 1992
    },
    {
      "title": "Design and analysi8 of randomized clinical triab requiring prolonged observation of each patient, part l",
      "authors": [
        "R Peto",
        "M Pike",
        "P Armitage",
        "N Bre~low",
        "D Cox",
        "S Howard",
        "N Mantel",
        "K Mcpherson",
        "J Pdo",
        "P Smith"
      ],
      "year": 1976
    },
    {
      "title": "Oe~ign and analysis of randomiz<,d clinical trials requiring prolong<,d observation of each patitnt, port 2",
      "authors": [
        "R Peto",
        "Pike Me",
        "P Armitage",
        "N Breslow",
        "D Cox",
        "S Howard",
        "N Mantel",
        "K Mrpher~on",
        "J Pelo",
        "Smith Pc"
      ]
    },
    {
      "title": "Clinical trials: a practical approach",
      "authors": [
        "5j Pocock"
      ],
      "doi": "10.1002/9781118793916"
    },
    {
      "authors": [
        "John Wiky",
        "& Son~"
      ],
      "year": 1983
    },
    {
      "title": "Why do we n\"ed ~ome large, simple randomized tria]s7",
      "authors": [
        "S Yusuf",
        "Collin~r",
        "R Peto"
      ]
    },
    {
      "title": "National arnbulJlory medical care survey: 1991 summary",
      "authors": [
        "I Schappert"
      ],
      "year": 1993
    },
    {
      "title": "Webskr's ninth new collegiate dictionary",
      "year": 1991
    },
    {
      "title": "SEER ,ancer statistics review",
      "authors": [
        "J Ries"
      ],
      "year": 1994
    },
    {
      "title": "The incidence of ad\"n\",'arcinoma in columnar-lined (l:Iarrdt's) esophagus",
      "authors": [
        ") Cameron",
        "B Ott",
        "Ws ; Payne",
        "J Mandel"
      ],
      "year": 1985
    },
    {
      "title": "r\"ening f\"r mlor\"d~1",
      "authors": [
        "O Eddy"
      ]
    },
    {
      "title": "valu~ting periodic multiphasic health ched(\"ups: a controlled trial",
      "authors": [
        "L Dales",
        "C Friedman"
      ]
    },
    {
      "title": "Psychological \"nd behavioral Impli\"atiom \"f ~hllormal mammograms",
      "authors": [
        "' Lerman C Trod: R",
        "Rimer Bk I:\\0ycc",
        "A Jepson",
        "C Engstrom"
      ]
    },
    {
      "title": "Romm 1'.1, l'ktcht'rSW, 1'lulL! llS, The periodic heallh examination: comparison \"fr\"'commendations and internists' performance",
      "authors": [
        "Lo"
      ],
      "year": 1981
    },
    {
      "title": "The nicotine patch; clinical effedivcn,~s with dlffewnt counbeling Ireatments",
      "authors": [
        "M Fiore",
        "S Kenford",
        "' Jorenby Dl",
        "O Weller",
        "S5 Smith"
      ],
      "doi": "10.1378/chest.105.2.524"
    },
    {
      "title": "Prediding sm\"klng (ess~ti\"n: who will quit with and without the nicotine patch",
      "authors": [
        "S Kenford",
        "M Fiore",
        "D Jorcnby",
        "S5 Smitl1",
        "\" Vetter",
        "Baker Tel ; Woolner",
        "L Taylor",
        "W Miller We",
        "J Muhm"
      ],
      "year": 1986
    },
    {
      "title": "Multiphabic health checkup evaluation: il 16-yeilr follow-up",
      "authors": [
        "G Friedman",
        "M Collen",
        "' Fin",
        "B Jilan"
      ]
    },
    {
      "title": "A cilse-control study of screening slgm\"ido~c()pyand mortality from colorectal cancer",
      "authors": [
        "J Sdhy",
        "Quesenberry Frledm",
        "Ct>",
        "O Ns ; Ddy",
        "V Hilsselhbd",
        "W Mcgivney",
        "W Hendee"
      ],
      "year": 1988
    },
    {
      "title": "al Iiter~hJre. 11: How to use an article about therapy or prevenlion, A: Are the results of tl1<' sh\"ly valid? jAylA 1",
      "authors": [
        "Pr< Goldbloom Lui, Lawn'n ; Rs ; Ds"
      ]
    },
    {
      "title": "Users' guide\" to th\", medical li(eralure, II: I low to use an arlic1e abolll Iherapy or prcvention, 5: What w,,e the resultb and will they help me in eming for my patlenh 7",
      "authors": [
        "G Guyall",
        "D Sackelt",
        "O Cook"
      ],
      "year": 1994
    },
    {
      "title": "I'reventiv",
      "authors": [
        "; Slelnherg",
        "I De",
        "Mi Roizen",
        "K I~oach"
      ]
    },
    {
      "title": "Cancer screening. Cambridg",
      "authors": [
        "Miller All",
        "J Chamberlain",
        "N Oay",
        "M Prorok"
      ],
      "year": 1991
    },
    {
      "title": "FEREl\\'CES 1, Johnson AF. Beneath the technological fix. Outliers and prohability stclkments",
      "authors": [
        "L Russell"
      ],
      "year": 1989
    },
    {
      "title": "An international randomized tri,1 comparing fpur thrombolytk strategies for acute myocardiill infJrdion",
      "authors": [
        "Gusto The",
        "Investigators"
      ],
      "doi": "10.1056/nejm199309023291001"
    },
    {
      "title": "Sackett lJl Thrombolytic agents: till' science of the art of choosing the better treatment",
      "authors": [
        "M Farkouh",
        "Langjd"
      ],
      "year": 1994,
      "doi": "10.7326/0003-4819-120-10-199405150-00011"
    },
    {
      "title": "The \\\\'cight-based heparin dosing nomogram compared with\" \"standard care\" nomof\\'ram. A randomized controlled trial",
      "authors": [
        "R Raschke",
        "8m Reilly",
        "J Guidry",
        "Fontanj Jr",
        "Srinivas"
      ],
      "year": 1993,
      "doi": "10.7326/0003-4819-119-9-199311010-00002"
    },
    {
      "title": "Design and annlysis of randol11i7ed clinic'll trials requiring: prolonged observation of each patient l. Introduction and dpsign",
      "authors": [
        "R Peto",
        "M Pike",
        "P Armitage",
        "; Breslow",
        "\\e Cox",
        "D Howard",
        "S Mantel",
        "N Mcpherson",
        "K Peto",
        "Smith Pc"
      ],
      "year": 1976,
      "doi": "10.1038/bjc.1976.220"
    },
    {
      "title": "Tr<'cltm~nl of colonic and rectal adenomas \\vith suJindac in familial adenomatous polyposis",
      "authors": [
        "Giardiel ; Flvl",
        "S Hamilton",
        "A Krush",
        "S Piantadosi",
        "Hylind \\1",
        "P Celano",
        "Sv",
        "C Robinson",
        "Offerhjus Gja"
      ],
      "year": 1993
    },
    {
      "title": "Confidence intervals assess both clinical significance and Mutistical significance",
      "authors": [
        "L Braitman"
      ],
      "year": 1991
    },
    {
      "title": "Cillkins OK Delbilnco TL. Unconventional medicine in the United StJte~. Prevalence, costs and piltterns of liS",
      "authors": [
        "O Eisenberg",
        "R Kessler",
        "C Foster"
      ],
      "year": 1993
    },
    {
      "title": "LJiabeles Control and Complications Trial Rc'search Croup. The effect of intensive treotment of diabetes on the d\"vdopl1lent ane! progression of long-term complications in insulin-dependent diabetes mellitis New lingl"
    },
    {
      "title": "Does the pcltient have spl<'nomegaly?",
      "authors": [
        "S Grover",
        "A\"-; Sockett"
      ],
      "year": 1993,
      "doi": "10.1001/jama.1993.03510180088040"
    },
    {
      "title": "The usc of predicted confidence intervals when planning experiments and the l11isuse of power when interpreting results",
      "authors": [
        "Goodm\"n Si\\",
        "Ja Berlin"
      ]
    },
    {
      "title": "Monitoring for drug safety",
      "authors": [
        "D Sackett",
        "\\1 Gent",
        "T ; Jkc"
      ]
    },
    {
      "title": "Importance of prognostic f\"ctors in the ;m\"ly~is of d\"t\" from clinical trials",
      "authors": [
        "Armitage 1"
      ]
    },
    {
      "title": "The risk of determilling risk with mllitivariabl",
      "authors": [
        "Ar",
        "T Ilolford"
      ]
    },
    {
      "title": "Future iJllpl'rf<'ct: the limit\"tipns or clinical prc'dicli\"n [llo<!\"b and thl' limits of clinical pr\"dktion"
    },
    {
      "title": "l guidelines ~or contributors 10 medical jOllrnJIs",
      "authors": [
        "M Gjrdner",
        "S Pocock",
        "Statisti"
      ],
      "year": 1983
    },
    {
      "title": "Mostdler r, cds..V1edical uses of statistics",
      "authors": [
        "Je Ilailer",
        "Ill"
      ],
      "year": 1986
    },
    {
      "title": "Multiple kbting uf hypotheses in comparing two groups",
      "authors": [
        "L Cupples",
        "T Heeren",
        "A Schatzkin",
        "T Colton"
      ],
      "year": 1984,
      "doi": "10.7326/0003-4819-100-1-122"
    },
    {
      "title": "When WclS\" \"negJtive\" clinical trial big enough? How many patients you net'd dep\"nd~on whclt you found",
      "authors": [
        "A Detsky",
        "Sackett 01"
      ],
      "year": 1985,
      "doi": "10.1001/archinte.1985.00360040141030"
    },
    {
      "title": "You cannot exclude the explanJlion you haven't considered",
      "authors": [
        "M Dalla"
      ],
      "year": 1993
    },
    {
      "title": "Clyrl1l JI\\. A question of attribution",
      "year": 1993
    },
    {
      "title": "laking comparisons",
      "authors": [
        "J Crisso",
        "I\\"
      ],
      "year": 1993
    },
    {
      "title": "TIle glitter of the I table",
      "authors": [
        "T Jolley"
      ],
      "year": 1993,
      "doi": "10.1016/0140-6736(93)91886-q"
    },
    {
      "title": "Failed or mi~leading 'ldJustment for confounding",
      "authors": [
        "D Leon"
      ],
      "year": 1993
    },
    {
      "title": "Estimating the effccts of misclassification",
      "authors": [
        "T Mertens"
      ]
    },
    {
      "title": "Silthi-amorn C I'oshachinda V. Bias",
      "year": 1993
    },
    {
      "title": "~Vhat's the denominator?",
      "authors": [
        "C Victoria"
      ],
      "year": 1993
    },
    {
      "title": "Primer of epidemiology",
      "authors": [
        "G Friedman"
      ],
      "year": 1994
    },
    {
      "title": "The usc of predicted confidence intervJIs when pbnning expnim'mts Jnd the mibuse of power when inte'lweting r~SIlIts",
      "authors": [
        "Gardner Mj",
        "S Altman Dg ; Ooks ; Coodman"
      ],
      "year": 1989
    },
    {
      "title": "ioslatistics in clinical medicine, New York: Ma\"milklll, 1983, Moses 1\u00a3 StatistiGll concepts fundamental to inVl'stigJtion",
      "authors": [
        "C Hl'nnekens",
        "If ; Bllring",
        "Little"
      ],
      "year": 1985
    },
    {
      "title": "udying and stLldy ~nd testing a tebt. 2nd",
      "authors": [
        "I{k \\iegclman",
        "R Hirsch",
        "Si"
      ],
      "year": 1989
    },
    {
      "title": "A bhow of confidence",
      "authors": [
        "K Rothman"
      ]
    },
    {
      "title": "Sample size nomograms for interpreting negative clinic,1 studie~",
      "authors": [
        "Young L\\ilj",
        "E Bresnitz",
        "Strom Ill"
      ]
    },
    {
      "title": "Recurrent hepatitis atlrihut~hle to halothane sensitization in <In anesthetist",
      "authors": [
        "C Klatskin",
        "Kimherg Nv"
      ],
      "year": 1969
    },
    {
      "title": "TIle adverse effect dilpmma: quest far accessible information",
      "authors": [
        "\\1k Roush",
        "R Mcnutt",
        "T Crily"
      ],
      "year": 1991,
      "doi": "10.7326/0003-4819-114-4-298"
    },
    {
      "title": "Clinical ecogpndics. Cancer in families,?",
      "authors": [
        "J Mulvihill"
      ]
    },
    {
      "title": "ll\"rk-,on 1. 1,imitations of the application of fourfold table analysis to ho,pital d>lta",
      "year": 1946,
      "doi": "10.2307/3002000"
    },
    {
      "title": "Acquired immune deficiency syndrome in the United St>lks: the first 1,000 cases",
      "authors": [
        "H Jaffe",
        "D Selik"
      ],
      "year": 1983
    },
    {
      "title": "\\lagnetic resonanc\" im>lging of the lumbar spine in p<,opl\" without back pain",
      "authors": [
        "~1c Jemen",
        "L3ri1nt-Zawadzkimn",
        "N Obuchowski",
        "M Modic",
        "D Malkasian"
      ],
      "year": 1994
    },
    {
      "title": "Non-aspirin nonsteroidal antiinfiammMory drugs and risk of chronic renal disease",
      "authors": [
        "Sandler Dr",
        "Burr Lr Weinb\"rg Cr"
      ],
      "year": 1991
    },
    {
      "title": "ss\"lm<ln jJ. Case control studies; d\"sign, nmduct, analysis",
      "authors": [
        "H Schl"
      ]
    },
    {
      "title": "Thl' biils caused by high values of incid\",'ce for P, in the odds rati\" as,umption that 1 I",
      "authors": [
        "Ai Feinstein"
      ],
      "year": 1986
    },
    {
      "title": "tion of ,onlrob in case-,\"ontrol ~hJdies",
      "authors": [
        "S Wacholder",
        "J Mcllughlin",
        "D Silverman",
        "J Mandel"
      ]
    },
    {
      "title": "Physical activity and primary cardiac arrest",
      "authors": [
        "I Sisulvick",
        "S Weis~ns",
        "A Hallstrom",
        "I T~",
        "; En;On Dr"
      ],
      "year": 1982
    },
    {
      "title": "r: C>l~es and two control groups from North Carolina",
      "authors": [
        "B Hulka",
        "Fowler We Jr",
        "D Kaufman",
        "Greenberg Be",
        "Hogue Cjr",
        "G Berger",
        "C Pulliam",
        "E~lrogen",
        "Cann"
      ],
      "year": 1980,
      "doi": "10.1016/0002-9378(80)90391-9"
    },
    {
      "title": "fS, I3etil-blockers and primary prevention of coronary h\"art dbease in patients with high blood pressure",
      "authors": [
        "B Psaty",
        "T Koepsdl",
        "J Locerfo",
        "U I Wagner"
      ],
      "year": 1989
    },
    {
      "title": "I~, F<:in~teil1 AR Melhodologic standanJs and contrildictary results in caS<' control research",
      "authors": [
        "F< ; Inskin Ar",
        "Rj ; Horwitz",
        "Horwitz"
      ],
      "year": 1979
    },
    {
      "title": "Case-control study of intrapartum car\". c\"r,'hrill palsy. and perinatal d\"ath",
      "authors": [
        "G Gaffney",
        "S Sellers",
        "V Flav<:Ll",
        "M Squier"
      ],
      "year": 1994
    },
    {
      "title": "Clinical biostatistics XX: th(, epidemiologic trnhoc, the ablatiw risk ratio, and \"rdrospective TtN,arch",
      "authors": [
        "A <einstein"
      ],
      "year": 1973
    },
    {
      "title": "Coffee and pancreatic cancer: the problems of etiologic science and epidemiological case-(:ontrol research",
      "authors": [
        "A Feinstein",
        "Horwitz Rl",
        "W Spitzer"
      ]
    },
    {
      "title": "The case-control study. A practical review for the clinician",
      "authors": [
        "G Ilayden",
        "M Kramer",
        "R Horwitz"
      ],
      "year": 1982
    },
    {
      "title": "Spitzer WOo 1he case-control study: consensus and controver",
      "authors": [
        "M Ibrahim"
      ],
      "year": 1979
    },
    {
      "title": "Modern epidemiology. Doston",
      "authors": [
        "K Rothman"
      ],
      "year": 1986
    },
    {
      "title": "Oil the conl,'giouslll'SS of puerpelill fever. r",
      "authors": [
        "O Holmes"
      ],
      "year": 1936
    },
    {
      "title": "Epidemiology of tuberculosis in lhe Un;led Stale~",
      "year": 1985
    },
    {
      "title": "ff\"d of directly \"bs\"rved therapy (\\11 thl' rat(,s of dmg rt'si~tan(\"(' ilnd relapse in luberculosis",
      "authors": [
        "S Wds",
        "Th"
      ]
    },
    {
      "title": "lyzing Ihe decline in the CAD dl'alh rail",
      "authors": [
        "An Goldman"
      ],
      "year": 1988
    },
    {
      "title": "Si'>Covick LlS, ct aL Lliuretic therapy for hyperknsion \"nd the risk of primary cardi\"e arrest",
      "authors": [
        "' Kimnl",
        "\u0128 Wb ; L"
      ],
      "year": 1977
    },
    {
      "title": "-11, Olmslead f'1\\1, Coffin LH, Levy DC-Differences bdw,'cn ml'n and wumen in Iw~pital mortality \"ot'o(\"iil!t'd ,--ilh \"on>l1\"ry artery byp\"~g raft ~urg",
      "authors": [
        "G O'conner",
        "Jr",
        "Diehl"
      ]
    },
    {
      "title": "\" E, I'adors as~\"ciilted with cardi,, mortality ill developed countries with pJrticular rd\"r\"nee tn th\" consumpti\"n of wine",
      "authors": [
        "I St",
        "\" Cochra",
        "A Moor"
      ],
      "year": 1979
    },
    {
      "title": "Gllgiill1lN. DeCfl'il~e in no~ocomiJI Clo,/ridilUlI difH('il\"-asso\"i,tcd diilrrlw;, by r\"stridillg din<\\;Hnycin US",
      "authors": [
        "; William~",
        "Th",
        "K Ilettin",
        "' Cl",
        "Dn"
      ],
      "year": 1994
    },
    {
      "title": "Cervical Cancer &:reening Programs. I. Epidemiology and n,1Illlill hislory of carcinoma \"f th"
    },
    {
      "title": "The \"l1vironn\",nt and dis\"ase, a.%llciati\"n Or causation",
      "authors": [
        "Ijradford-J Lill All"
      ]
    },
    {
      "title": "Weigh I loss and mortalily",
      "authors": [
        "\" Kullel",
        "R Wing"
      ],
      "year": 1993,
      "doi": "10.7326/0003-4819-119-7_part_1-199310010-00015"
    },
    {
      "title": "Cc, Hwal1g I.Y, Chit'n CS. H\"patocellular c,m,inmna and hepatitis lJ virus",
      "authors": [
        "Cenlers For",
        "Dbeilse Control"
      ]
    },
    {
      "title": "Reducing mortality from coloreclal cancer by screening for fecal occult blood",
      "year": 1993
    },
    {
      "title": "A ca~e-control study of screening sigmoidoscllPY and mortality from coiorectai cancer",
      "authors": [
        "J Selby",
        "G Friedman",
        "C Quesenberry",
        "N Weiss"
      ],
      "year": 1992
    },
    {
      "title": "et aL A clinical triai llf amygdalin (laetriie) in the treatment of human cancer",
      "authors": [
        "C Moertei"
      ],
      "year": 1982
    },
    {
      "title": "Pllpper's phiiosophy for epidemiologists",
      "authors": [
        "Suggested",
        "C Buck"
      ],
      "year": 1975
    },
    {
      "title": "What Is this Thing Calied Science? 2nd ed",
      "authors": [
        "A Chalmers"
      ],
      "year": 1982
    },
    {
      "title": "How to read clinical journals. iV, To determine etiology or causation",
      "year": 1981
    },
    {
      "title": "Causal inference",
      "year": 1988,
      "doi": "10.1002/sim.4780100324"
    },
    {
      "title": "Conclusions ~l1d decisions",
      "authors": [
        "I Referrnces",
        "I Tukey"
      ]
    },
    {
      "title": "A '.-omparison of n'~ults of mct~-,maly~es of randomized trials and recommendalions of clinical experts: treatment of myocardiJI infarclion",
      "authors": [
        "E Antrn~n",
        "J Lau",
        "B Kupelnick",
        "Chalmers Mosteller 1'",
        "Te"
      ]
    },
    {
      "title": "Clinic~1 studies in surgic~1 journ~ls-have 'A'\" improved",
      "authors": [
        "Soloman Mj",
        "R Mcleod"
      ],
      "year": 1993
    },
    {
      "title": "More informative ~b~lracts revisited",
      "authors": [
        "R H~ynes",
        "C Mulmw",
        "E Huth",
        "O Altm~n",
        "' Gardn<",
        "Ml"
      ],
      "year": 1990
    },
    {
      "title": "l'atientoulcome following tficompartnwnt~l lolal knee repJncenlenL A mctd-an~lysis",
      "authors": [
        "Em Callahjn",
        "Drake Be",
        "H ('('k Da",
        "R Diuus"
      ],
      "year": 1994
    },
    {
      "title": "Where'~the meat in dinicnl journals?",
      "authors": [
        "R Hnynes"
      ],
      "year": 1993,
      "doi": "10.7326/acpjc-1993-119-3-a22"
    },
    {
      "title": "cr Jr, Wei.% NS, A case control ~t\\ldy of screl'ning ~igmoidoscopy and 'nortality from coloreclal canc<,r",
      "authors": [
        "J Selby",
        "G Friedman",
        "Qu<",
        "Nherry"
      ],
      "year": 1992
    },
    {
      "title": "An ind\",x predicting relap~e and need for h()spit~li7a tion in p~tienls with acute bronchial asthma",
      "authors": [
        "Ii",
        "M Fisrhl",
        "A Pitchenik",
        "L Gardner"
      ]
    },
    {
      "title": "Performance of an index predicting the response of palienls with 'Kuk bronchial asthma to inlensive emergency department treatment",
      "authors": [
        "Rose Cc",
        "J Murphy",
        "Schwmtz Js"
      ]
    },
    {
      "title": "Inability to predict feldPSe in acute asthma",
      "authors": [
        "R Centor",
        "Yarbrough Il",
        "Wood Jr"
      ],
      "year": 1984,
      "doi": "10.1056/nejm198403013100907"
    },
    {
      "title": "The l:lCC controversy: a methodological and statislical reapprnis<lL",
      "authors": [
        "I Clemens Jd",
        "Chuong Jii",
        "A Feinstein"
      ],
      "doi": "10.1001/jama.1983.03330410048027"
    },
    {
      "title": "Ufica(y of BCG vaccin,' in the prevention of tuberculosis: meta-,mil[v~i5 of the published lilerature",
      "authors": [
        ": Coldit>",
        "Ga",
        "T Brewer",
        "C Berkey",
        "M Wilson",
        "F Burdick",
        "Iiv Fineberg"
      ],
      "year": 1994
    },
    {
      "title": "IS, Smith H jr, Chalmers TC A~50ciation of ddwnocorlicosleroid therapy and peptic-ulcer disease",
      "authors": [
        "S It Greenland",
        "H Messer J, R\"itmnn",
        "D Sacks"
      ]
    },
    {
      "title": "Publication hias in clinicalres",
      "authors": [
        "( E~st",
        "J 'rhrook I'j, L:Lerlin",
        "Gopalan Matthews"
      ],
      "year": 1991
    },
    {
      "title": "Confronting public~tion bias: a cohlll't design for meta\u2022~naly~i~. Slat",
      "authors": [
        "R Simes"
      ],
      "year": 1987
    },
    {
      "title": "I'ublic health issues in hyperten~ion controL whal has b<'en learned from clinical trials",
      "authors": [
        "J Cutler",
        "I Macmahon",
        "S Furberg"
      ],
      "year": 1995
    },
    {
      "title": "The community ba~\"d rJndomized trial~of phJrmacological tr,'atment of mild-tlHnoderate hyperten~ion",
      "authors": [
        "Pi{ Hebert",
        "Nh",
        "K Eberlein",
        "T<lylor Jo",
        "Henneken~ch"
      ]
    },
    {
      "title": "bJsecl medicine working group. Evid\"nce based medicine: a ne\\\\' approach to teJching the practice of m,,licine",
      "authors": [
        "Evidenn"
      ],
      "year": 1992
    },
    {
      "title": "More informiltive ab~tracts of article~d\",~nibing clinical pra,\u2022ti\"e gUideline~",
      "authors": [
        "[ Hayward",
        "{sa",
        "M Wilbon",
        "S Tunis",
        ") Bj~~ei",
        "H Rubin",
        "R Haynes"
      ],
      "year": 1993
    },
    {
      "title": "Effect of clinical guidelin~8 on medical practk~. A systematic revi\",w of rigorous evaluJtion~",
      "authors": [
        "J Crimshaw",
        "I Russell"
      ],
      "year": 1993
    },
    {
      "title": "SUGGESTED lUiADING Epidemiology Work Croup of the lnkragency RegulJtory Liaison Group. Cuiddines [or documentation of epidemiologi, studies"
    },
    {
      "title": "\"tt OL. liow to keep up with the medical literature. I: Why try to 1<\",1\" up and how to get started",
      "authors": [
        "Hayne~rll Mckibbon",
        "Fit~ Gllyjll",
        "Walker Cj",
        "Sjck"
      ]
    },
    {
      "title": "How to keep up with the m.,dical literature. 11: I:kciding which jOlJrnJls to read regulJrly",
      "authors": [
        "R Iijynes",
        "K Mckibbon",
        "G Cuyatt",
        "Walker Cj",
        "M Sackett"
      ]
    },
    {
      "title": "How to keep up with the medicJI lit('rature. III: Expanding the number of journals you read regubrly",
      "authors": [
        "R Haynes",
        "K Mckibbon",
        "D Fitzgerald",
        "C Guyutt",
        "Walker Cj",
        "O Sackett"
      ]
    },
    {
      "title": "Sackett 01 .. How to keep up with the medical literaturc. IV: Using th., literature to solve clinical problems",
      "authors": [
        "R Ilaynes",
        "K Mckibbon",
        "D Cuyatl",
        "Walker Cj"
      ],
      "year": 1986
    },
    {
      "title": "uching of th~medical literature: an evaluation of MFDLlNE searching systems",
      "authors": [
        "R Ilaynes",
        "\\ \u2022kkibbon",
        "Walker Ka",
        "Cj",
        "J Mousseau",
        "I Baker",
        "D Gl-Lyatt",
        "Norman Cr Computer Se"
      ]
    },
    {
      "title": "Mostellar f. Cuiddines for meta-analyses eVilluating diagnostic te~ts",
      "authors": [
        "A Lrwig I\" Tosteson",
        "C Gastonis",
        "J Lau",
        "C Colditz"
      ]
    },
    {
      "title": "Meta-analysis in clinical research",
      "authors": [
        "K I 'abbe",
        "A Detbky",
        "O' Rourke"
      ],
      "year": 1987
    },
    {
      "title": "Summing up, The science of reviewing reseJr",
      "authors": [
        "R Light",
        "Pillmer Oil"
      ]
    },
    {
      "title": "Stale of the ~;cience [The Medical Review Articlel",
      "authors": [
        "C Mulrow"
      ],
      "year": 1987,
      "doi": "10.7326/0003-4819-106-3-485"
    },
    {
      "title": "CJn meta-analyses be lru~ted?",
      "authors": [
        "S Thompson",
        "5j Po<ock"
      ]
    }
  ],
  "num_references": 244
}
