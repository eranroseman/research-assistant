{
  "paper_id": "5PPKYL8I",
  "title": "Rigorous and rapid evidence assessment in digital health with the evidence DEFINED framework",
  "abstract": "Dozens of frameworks have been proposed to assess evidence for digital health interventions (DHIs), but existing frameworks may not facilitate DHI evidence reviews that meet the needs of stakeholder organizations including payers, health systems, trade organizations, and others. These organizations may benefit from a DHI assessment framework that is both rigorous and rapid. Here we propose a framework to assess Evidence in Digital health for EFfectiveness of INterventions with Evaluative Depth (Evidence DEFINED). Designed for real-world use, the Evidence DEFINED Quick Start Guide may help streamline DHI assessment. A checklist is provided summarizing high-priority evidence considerations in digital health. Evidence-to-recommendation guidelines are proposed, specifying degrees of adoption that may be appropriate for a range of evidence quality levels. Evidence DEFINED differs from prior frameworks in its inclusion of unique elements designed for rigor and speed. Rigor is increased by addressing three gaps in prior frameworks. First, prior frameworks are not adapted adequately to address evidence considerations that are unique to digital health. Second, prior frameworks do not specify evidence quality criteria requiring increased vigilance for DHIs in the current regulatory context. Third, extant frameworks rarely leverage established, robust methodologies that were developed for non-digital interventions. Speed is achieved in the Evidence DEFINED Framework through screening optimization and deprioritization of steps that may have limited value. The primary goals of Evidence DEFINED are to a) facilitate standardized, rapid, rigorous DHI evidence assessment in organizations and b) guide digital health solutions providers who wish to generate evidence that drives DHI adoption.",
  "year": 2021,
  "date": "2021",
  "journal": "NPJ Digital Med",
  "publication": "NPJ Digital Med",
  "authors": [
    {
      "forename": "Jordan",
      "surname": "Silberman",
      "name": "Jordan Silberman",
      "affiliation": "1  Office of Medical Policy and Technology Assessment , Elevance Health , Palo Alto , CA , USA. \n\t\t\t\t\t\t\t\t Office of Medical Policy and Technology Assessment \n\t\t\t\t\t\t\t\t Elevance Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Palo Alto \n\t\t\t\t\t\t\t\t\t CA \n\t\t\t\t\t\t\t\t\t USA",
      "email": "jordan.silberman@elevancehealth.com",
      "orcid": "0000-0001-7965-3722"
    },
    {
      "forename": "Paul",
      "surname": "Wicks",
      "name": "Paul Wicks",
      "affiliation": "2  Wicks Digital Health , Lichfield , UK. \n\t\t\t\t\t\t\t\t Wicks Digital Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Lichfield \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0002-2293-9284"
    },
    {
      "forename": "Smit",
      "surname": "Patel",
      "name": "Smit Patel",
      "affiliation": "3  Digital Medicine Society , Boston , MA , USA. \n\t\t\t\t\t\t\t\t Digital Medicine Society \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Boston \n\t\t\t\t\t\t\t\t\t MA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Siavash",
      "surname": "Sarlati",
      "name": "Siavash Sarlati",
      "affiliation": "1  Office of Medical Policy and Technology Assessment , Elevance Health , Palo Alto , CA , USA. \n\t\t\t\t\t\t\t\t Office of Medical Policy and Technology Assessment \n\t\t\t\t\t\t\t\t Elevance Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Palo Alto \n\t\t\t\t\t\t\t\t\t CA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Siyeon",
      "surname": "Park",
      "name": "Siyeon Park",
      "affiliation": "5  Geisinger Health System , Danville , PA , USA. \n\t\t\t\t\t\t\t\t Geisinger Health System \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Danville \n\t\t\t\t\t\t\t\t\t PA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Igor",
      "surname": "Korolev",
      "name": "Igor Korolev",
      "affiliation": "6  UConn Health , Farmington , CT , USA. \n\t\t\t\t\t\t\t\t UConn Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Farmington \n\t\t\t\t\t\t\t\t\t CT \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Jenna",
      "surname": "Carl",
      "name": "Jenna Carl",
      "affiliation": "7  Big Health Inc. , San Francisco , CA , USA. \n\t\t\t\t\t\t\t\t Big Health Inc \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t San Francisco \n\t\t\t\t\t\t\t\t\t CA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Jocelynn",
      "surname": "Owusu",
      "name": "Jocelynn Owusu",
      "affiliation": "8  Lyra Health , Burlingame , CA , USA. \n\t\t\t\t\t\t\t\t Lyra Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Burlingame \n\t\t\t\t\t\t\t\t\t CA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Vimal",
      "surname": "Mishra",
      "name": "Vimal Mishra",
      "affiliation": "9  Department of Medicine and Health Administration , Virginia Commonwealth University , Richmond , VA , USA. \n\t\t\t\t\t\t\t\t Department of Medicine and Health Administration \n\t\t\t\t\t\t\t\t Virginia Commonwealth University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Richmond \n\t\t\t\t\t\t\t\t\t VA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Manpreet",
      "surname": "Kaur",
      "name": "Manpreet Kaur",
      "affiliation": "1  Office of Medical Policy and Technology Assessment , Elevance Health , Palo Alto , CA , USA. \n\t\t\t\t\t\t\t\t Office of Medical Policy and Technology Assessment \n\t\t\t\t\t\t\t\t Elevance Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Palo Alto \n\t\t\t\t\t\t\t\t\t CA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Vincent",
      "surname": "Willey",
      "name": "Vincent Willey",
      "affiliation": "10  HealthCore, Inc. , Wilmington , DE , USA. \n\t\t\t\t\t\t\t\t HealthCore, Inc \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Wilmington \n\t\t\t\t\t\t\t\t\t DE \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Madalina",
      "surname": "Sucala",
      "name": "Madalina Sucala",
      "affiliation": "11  AstraZeneca, Inc. , NY , NY , USA. \n\t\t\t\t\t\t\t\t AstraZeneca, Inc \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t NY NY \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Tim",
      "surname": "Campellone",
      "name": "Tim Campellone",
      "affiliation": "12  Click Therapeutics , New York , NY , USA. \n\t\t\t\t\t\t\t\t Click Therapeutics \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t New York \n\t\t\t\t\t\t\t\t\t NY \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Cindy",
      "surname": "Geoghegan",
      "name": "Cindy Geoghegan",
      "affiliation": "3  Digital Medicine Society , Boston , MA , USA. \n\t\t\t\t\t\t\t\t Digital Medicine Society \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Boston \n\t\t\t\t\t\t\t\t\t MA \n\t\t\t\t\t\t\t\t\t USA",
      "orcid": "0000-0003-0992-3728"
    },
    {
      "forename": "Isaac",
      "surname": "Rodriguez-Chavez",
      "name": "Isaac Rodriguez-Chavez",
      "affiliation": "14  ICON plc , Blue Bell , PA , USA. \n\t\t\t\t\t\t\t\t ICON plc \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Blue Bell \n\t\t\t\t\t\t\t\t\t PA \n\t\t\t\t\t\t\t\t\t USA",
      "orcid": "0000-0003-1787-8381"
    },
    {
      "forename": "Benjamin",
      "surname": "Vandendriessche",
      "name": "Benjamin Vandendriessche",
      "affiliation": "15  Department of Electrical, Computer and Systems Engineering , Case Western Reserve University , Cleveland , OH , USA. \n\t\t\t\t\t\t\t\t Department of Electrical, Computer and Systems Engineering \n\t\t\t\t\t\t\t\t Case Western Reserve University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Cleveland \n\t\t\t\t\t\t\t\t\t OH \n\t\t\t\t\t\t\t\t\t USA",
      "orcid": "0000-0003-0672-0327"
    },
    {
      "forename": "Jennifer",
      "surname": "Goldsack",
      "name": "Jennifer Goldsack",
      "affiliation": "3  Digital Medicine Society , Boston , MA , USA. \n\t\t\t\t\t\t\t\t Digital Medicine Society \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Boston \n\t\t\t\t\t\t\t\t\t MA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "affiliation": "UC Davis Health , Sacramento , CA , USA. \n\t\t\t\t\t\t\t\t UC Davis Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Sacramento \n\t\t\t\t\t\t\t\t\t CA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "affiliation": "4Biosolutions Consulting , Rockville , MD , USA. \n\t\t\t\t\t\t\t\t 4Biosolutions Consulting \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Rockville \n\t\t\t\t\t\t\t\t\t MD \n\t\t\t\t\t\t\t\t\t USA"
    }
  ],
  "doi": "10.1038/s41746-023-00836-5",
  "sections": [
    {
      "title": "INTRODUCTION",
      "text": "Digital health (DH) has proliferated in recent years  1, 2  , with >300,000 health apps and over 300 wearables now available  1  . Organizations like the American Medical Association 3 and American Psychiatric Association 4 encourage digital health adoption, and more than half of U.S. adults use DH to track their health  5  . While digital health holds promise, current practices in DH have been described as the \"Wild West\"  6  , with misleading claims being common  [7] [8] [9]  , and clinical evidence quality often poor  2, 7, [10] [11] [12] [13] [14]  .\n\nBuilding on prior work  15  , we define digital health interventions (DHIs) as digital technologies intended to improve health outcomes and change health behaviors. Digital health interventions include products within the digital health, digital medicine, and digital therapeutic categories (see Table  1  for details). DHIs are often implemented using smartphone apps, wearables, and other technologies. Regulators have had a limited role in evaluating DHIs  7, 13  , though this may change due to new functional areas within regulatory agencies (e.g., the FDA's Digital Health Center of Excellence)  16, 17  .\n\nFollowing a preliminary search to identify existing frameworks for DHI evidence assessment (78 frameworks identified; see Supplementary Table  1 ), no framework was identified that met the needs of specific types of stakeholder organizations. The organizations that may benefit from an improved DHI assessment framework include payers, pharmacy benefit managers (PBMs), health systems, pharmaceutical companies, trade organizations, and professional medical societies. Throughout this article, the term stakeholder organizations refers to these organization types. Such organizations may benefit from a framework that is rigorous enough to identify clinically valuable DHIs reliably, yet rapid enough to accommodate the fast pace at which new DHIs enter the market.\n\nCritical gaps (detailed below) were identified in extant DHI assessment frameworks, making them poorly suited for rigorous and rapid evaluation of clinical evidence. A multidisciplinary workgroup of leading experts was assembled to develop a careful and efficient strategy for DHI evidence evaluation in stakeholder organizations. The workgroup developed a novel framework to assess Evidence in Digital health for EFfectiveness of INterventions with Evaluative Depth (Evidence DEFINED). The Evidence DEFINED Framework builds on extant approaches, but differs in its inclusion of unique elements that are designed to increase rigor and speed. Efficiency in DHI assessment is critical given the ballooning number of DH technologies available  1, 2  .\n\nEvidence DEFINED is a digital health evidence assessment process comprised of four steps, which are outlined in a Quick Start Guide (Fig.  1 ). The steps are (1) screen for failure to meet absolute requirements (e.g., compliance with data privacy standards), (2) apply an established evidence assessment methodology that was developed for non-digital interventions (e.g., GRADE  18  ), (3) apply the Evidence DEFINED supplementary checklist (Supplementary Table  2 ), and (4) use evidence-torecommendation guidelines (Table  2 ) to provide a recommendation regarding adoption levels that may be appropriate for the relevant DHI.\n\nThe Evidence DEFINED framework has two primary goals. First, it will facilitate rigorous and rapid DH evidence assessment within the stakeholder organizations listed in Fig.  1 , and thereby The product falls into one of the three classes of digital health technologies that were defined in a collaboration  15  of stakeholders representing digital health trade organizations."
    },
    {
      "title": "Product Class Product Class Definition",
      "text": "Digital Health \"Digital health includes technologies, platforms, and systems that engage consumers for lifestyle, wellness, and healthrelated purposes; capture, store or transmit health data; and/ or support life science and clinical operations\"  15  .\n\nDigital Medicine \"Digital medicine includes evidence-based software and/or hardware products that measure and/or intervene in the service of human health\"  15  ."
    },
    {
      "title": "Digital Therapeutics",
      "text": "\"Digital therapeutic (DTx) products deliver evidence-based therapeutic intervention to prevent, manage, or treat a medical disorder or disease\"  15  .\n\n2. The product is designed to change one or more health behaviors.\n\n3. The value of the product to the evaluator is contingent on the degree to which it improves one or more health outcomes. These can include clinical outcomes (e.g., incidence of diabetic retinopathy) or surrogate outcomes (e.g., HbA 1C ).\n\nFollowing others  15, 33  , we define digital health interventions as patient-facing products that meet the three criteria shown. DHIs are often implemented using smartphone apps, web platforms, consumer-grade wearables, and other digital technologies. encourage adoption of DHIs that are most likely to improve health outcomes. Second, Evidence DEFINED will provide guidance to digital health solutions providers (DHSPs) who wish to generate evidence that drives adoption of their products. This may allow DHSPs to launch high-quality clinical trials with greater confidence that the investment is worthwhile. With clear and aligned evidence standards, DHSPs may face less uncertainty regarding the return on investment of clinical research."
    },
    {
      "title": "THE NEED TO ASSESS EVIDENCE FOR DIGITAL HEALTH INTERVENTIONS",
      "text": "There is an urgent need to improve health outcomes and reduce costs, particularly for chronic conditions like diabetes, hypertension, depression, and many others  [19] [20] [21]  . Given the high prevalence of these conditions  22  , patient-centric and scalable solutions are needed to support condition self-management. Digital health interventions are one promising approach to help address this challenge  23  . But to realize that potential, only DHIs that are equitable, effective, and safe should be adopted  10, 14  . DHI adoption within the aforementioned types of organizations may sometimes be driven by marketing-not by evidence  14  . Criteria for DHI assessment often vary across and within stakeholder organizations. A \"check the box\" approach may be employed, where any DHSP presenting clinical outcomes may be deemed \"validated\", whether or not this is an appropriate description, and irrespective of evidence quality. Where evidence quality is assessed, evaluative depth varies. Critical details may be overlooked, including risk for harm to patients. More rigorous and standardized evidence assessment methods are needed.\n\nCURRENT EVIDENCE ASSESSMENT FRAMEWORKS Dozens of frameworks have been proposed to assess evidentiary support for DHIs  13, [24] [25] [26] [27] [28]  . A comprehensive review is outside the scope of this paper, but a preliminary catalogue of frameworks Feasibility pilot: focus is on enrollment, engagement, user experience, safety.\n\nAll of the following:\n\n\u2022 Meets or exceeds all criteria for Actionability Level 1\n\n\u2022 Low-to-moderate quality evidence (per GRADE 41 definitions). Real-world evidence may be included. \u2022 No or minimal uncertainty (per GRADE  41  ) around value to stakeholders (often patients and their families) \u2022 Acceptable or likely acceptable (per GRADE  41  ) to stakeholders Small clinical pilot: primary outcomes are clinical.\n\nUp to several hundred."
    },
    {
      "title": "3",
      "text": "All of the following:\n\n\u2022 Meets or exceeds all criteria for Actionability Levels 1-2\n\n\u2022 Moderate-to-high quality evidence (per GRADE  41  ). Realworld evidence may be included.\n\nLarge clinical pilot: primary outcomes are clinical.\n\nAll of the following:\n\n\u2022 Meets or exceeds all criteria for Actionability Levels 1-3\n\n\u2022 Two or more high-quality RCTs support efficacy and safety \u2022 Preferred: one or more RCTs have 3rd-party data monitoring and analysis \u2022 Preferred: real-world evidence of safety and effectiveness May be appropriate to scale.\n\nNo limit for appropriate patients.\n\nThese guidelines suggest degrees to which adoption of digital health interventions (DHIs) may be warranted by clinical evidence. Evidence is one of many critical assessment domains; others include patient experience, cost, health equity, etc. DHIs should be screened for failure to meet absolute requirements (e.g., HIPAA compliance). Enrollment targets are guidelines and should have statistical justification. For conditions with few treatments or urgent need, consider increasing rating by 1-2 actionability levels, without exceeding Level 3. DHI Digital Health Intervention, RCT Randomized Controlled Trial, HIPAA Health Insurance Portability and Accountability Act.\n\ninvestigated for this initiative is provided in Supplementary Table  1  (see also Supplementary Figure  1  and Supplementary Note 1). Seventy-eight prior frameworks were identified. Some of these may be useful, though many prior frameworks are underdeveloped in the key domain of clinical outcomes assessment  8  .\n\nPrior DHI evidence assessment frameworks are typically sections of broader DHI assessment guides, often containing just a few, superficial questions, with minimal evaluation of evidence quality or bias  [29] [30] [31] [32]  .\n\nTo increase rigor in DHI evidence assessment, it may be helpful to address three gaps in prior frameworks. First, prior frameworks are not adapted to address evidence quality criteria that are unique to, or arise more commonly, in digital health interventions. For example, poor user experiences with digital health interventions can cause attrition of all but the most motivated patients. Such patients often show favorable outcomes, irrespective of any treatment effect. Thus, poorly-designed DHIs may sometimes retain only a biased subset of patients, who tend to show relatively strong outcomes. This may skew low-quality DHIs toward favorable clinical evaluations in per-protocol analyses of uncontrolled studies  33  . Such considerations may receive inadequate attention in routine DHI assessment.\n\nSecond, prior frameworks do not specify evidence quality criteria that may require increased vigilance given the current regulatory landscape in digital health. For example, in many cases, DHSPs may be nonadherent to trial registration and reporting best practices, which are detailed elsewhere  34  . This nonadherence is reflected in the 11% rate of public results reporting for registered DH trials  35  , despite the NIH recommending reporting within 12 months  36  . Even if some registered DH trials were within the 12month reporting window at time of assessment, the low reporting percentage suggests that many negative results of DH trials may not be reported publicly, which could prevent appropriate evidence evaluation  34  . If a DHSP completed trials but did not report results publicly, this should impact assessments of evidence quality (see Supplementary Table  2  for specific recommendations). Adherence to other best practices should also be considered. Concerns around trial registration may be more common in DH, relative to therapeutic modalities (e.g., drugs) where trial registration is more regulated. Registration is one of many areas where increased vigilance regarding evidence quality may be appropriate for assessment of DHIs.\n\nTo address the first two gaps, Evidence DEFINED provides a supplementary checklist of evidence quality criteria that are recommended for DHI evidence assessments. This checklist (Supplementary Table  2 ) addresses evidence quality criteria that are unique to digital health, as well as evidence quality considerations that may require enhanced vigilance for assessment of digital health interventions.\n\nThe third gap in extant frameworks is that they fail to leverage established evidence evaluation methodologies that were developed for non-digital interventions (e.g., GRADE  18  ). Such methodologies have undergone extensive development, with contributions from leading experts. Although many established evidence evaluation methodologies were designed for non-digital products (e.g., drugs), the principles pertain to DHIs. Rather than \"reinventing the wheel\", the Evidence DEFINED framework utilizes established evidence assessment methodologies wherever possible."
    },
    {
      "title": "SCOPE OF DIGITAL HEALTH PRODUCTS CONSIDERED",
      "text": "A prior initiative, organized by the Digital Medicine Society (DiMe), developed a checklist to assess the evidence supporting fit-forpurpose biometric monitoring technologies (BioMeTs)  37  . Here we build on this work and develop a framework that may help organizational stakeholders assess digital health interventions. BioMeTs are out of scope, as are products that serve monitoring and diagnostic functions exclusively. The Evidence DEFINED Framework is not intended to support individual patient or clinician decisions; other frameworks (e.g., the App Evaluation Model of the American Psychiatric Association 4 ) may be useful for this purpose.\n\nWe focus here on assessing clinical evidence for DHIs. Though out of scope for this initiative, other domains should also be evaluated. For example, DHI assessment should address patient experience, provider experience, product design, cost effectiveness, interoperability, etc. Data governance is a high-priority assessment domain, as inappropriate handling of health data can lead to serious patient harms  10  . DH equity is another critical domain; considerations may include language support, literacy, health literacy, digital literacy, numeracy, cultural appropriateness, and technical accessibility. Other frameworks have been proposed to assess these important domains  7, [38] [39] [40]  .\n\nNote that DHIs may be in scope even if they are early in development and have yet to generate pivotal trial evidence. The potential value of young, innovative DH products should not be overlooked. Partnerships that help develop promising DH interventions should be encouraged, to spur needed innovation in healthcare. However, it is often appropriate to adjust adoption levels based on the maturity of a DHI's clinical evidence. DHIs that have compelling evidence from high-quality trials may be appropriate to consider for widespread use, while those earlier in clinical development may be more appropriate to test in a limited number of patients. To guide DHI adoption levels that may be appropriate across varying levels of clinical evidence maturity, an evidence-to-recommendation framework is incorporated in Evidence DEFINED (Table  2 ). An actionability level is assigned, reflecting the degree to which clinical evidence may justify adoption of a digital health intervention."
    },
    {
      "title": "RAPID ASSESSMENT",
      "text": "The aforementioned types of stakeholder organizations often require quick decisions to meet deadlines and move faster than competitors. Two key strategies are incorporated to achieve efficiency. First, the Framework uses screening items to determine whether a DHI meets absolute requirements. Assessment ends if the DHI fails to meet any absolute requirement. For example, time is not invested in evaluating evidence for a DH product that is not an adoption candidate due to non-compliance with privacy and security requirements. Second, as detailed below, a streamlined approach is used, avoiding information gathering that may have limited value."
    },
    {
      "title": "EVIDENCE DEFINED IMPLEMENTATION",
      "text": "Evidence DEFINED uses the following steps to facilitate rapid and rigorous evaluation of DHI evidence. We assume here that the DHIs under consideration have been identified. See Fig.  1  for a Quick Start Guide.\n\nStep 1. Screen for failure to meet absolute requirements To avoid investing effort in DHIs that are not candidates for adoption, screen relevant DHIs for failure to meet absolute requirements. The screening step is applied flexibly; each stakeholder organization specifies their own requirements, per the organization's needs. Screening requirements might include (a) a privacy policy that confirms compliance with HIPAA, (b) patient-facing language written at a targeted reading level (e.g., to comply with Medicaid guidelines), and (c) if subject to FDA regulation (detailed elsewhere  19  ), the appropriate clearance or approval has been obtained. The screening step is similar to procedures recommended in the American Psychiatric Association's App Evaluation Model 4 .\n\nStep 2. Apply an established evidence assessment framework Apply an established evidence assessment framework that was developed for non-digital interventions (e.g., GRADE  41  ). Many stakeholder organizations already use such frameworks routinely.\n\nStep 3. Apply the Evidence DEFINED supplementary checklist (Supplementary Table  2 ) Apply the Evidence DEFINED supplementary checklist to address evidence quality considerations that are unique to digital health interventions, or that may require greater vigilance in digital health.\n\nStep 4. Make actionable, defensible recommendations Apply evidence-to-recommendation guidelines (Table  2 ) to generate a recommendation around levels of adoption that may be appropriate. This guideline may help stakeholders generate defensible and actionable recommendations regarding appropriate adoption levels for digital health interventions.\n\nThese steps should be performed by evaluators with appropriate expertise, such as physicians, psychologists, pharmacists, researchers, clinical trialists, and biostatisticians. Organizations that do not have appropriate expertise internally may wish to partner with others. Any such partnerships should be conducted in an efficient manner. Organizations might consider service level agreements that specify assessment delivery dates."
    },
    {
      "title": "EXCLUSIONS FROM EVIDENCE DEFINED",
      "text": "Evidence DEFINED is a streamlined framework. Many frameworks employ extensive feature lists  4, 30, 42, 43  , and investigate which DHIs have which features. Such frameworks may be helpful where evidence is not available, and the goal is to determine which DHI is most likely to be effective and safe. A feature-focused approach may also be appropriate for a provider who seeks a digital health product meeting the needs of a specific patient. However, when applied to organizational decisions around DHI adoption, lengthy feature checklists may have at least two unfavorable consequences.\n\nFirst, feature checklists can greatly increase the time required to evaluate DHIs. Using feature checklists in the evaluation process may require drafting feature lists and requesting information from digital health solutions providers. Cycles of information gathering often take months.\n\nSecond, feature checklists may yield misleading assessments of clinical value. Checking more boxes does not necessarily indicate that a DHI is effective and safe. Many DHSPs are sophisticated in their approach to requests for proposals (RFPs) and may prioritize \"checking the box\" over developing a feature that has genuine value. There is often a wide gap between the minimum level of effort required to claim defensibly that a product has a given feature, and the effort required to develop the feature to a degree that contributes meaningfully to improved clinical outcomes. It is common for DHSPs to develop \"minimum viable product\" (MVP) versions of a feature  44  . This may be appropriate, but evaluators should be aware of and adapt to this common practice in product development. In many cases, DHI features may be implemented at a level of refinement that permits \"checking the box,\" but does not provide clinical value.\n\nIf stakeholder organizations have a strong preference for specific features, then a small number of features can be assessed. We recommend, however, keeping feature checklists short. Assessments organized around feature lists may incent DH solutions providers to offer numerous, low-quality features, encouraging an unfavorable ratio of breadth to depth. Given these limitations, Evidence DEFINED focuses on evidence of safety and effectiveness-critical considerations to assess clinical value.\n\nNote also that information sometimes gathered for DHSP assessment may have limited impact on decisions. Such information includes which venture capital firms fund the DHSP, the software development methods employed, corporate reporting structure, etc. Stakeholders should consider carefully how each piece of information will be used, and should consider foregoing information gathering that is unlikely to impact decisions."
    },
    {
      "title": "UPDATING THE EVIDENCE DEFINED FRAMEWORK",
      "text": "Digital health is an evolving multidisciplinary field that itself is part of a large, complex healthcare ecosystem. Evidence DEFINED is agile and flexible to keep up with the pace of digital health innovation. As a leading professional organization in digital health, the Digital Medicine Society (DiMe) is an appropriate body to coordinate the updating process for the Evidence DEFINED Framework. Following others  37  , DiMe will establish a public website and collaborate with interested partners to update and disseminate the Evidence DEFINED Framework. The website will provide a suggestion form to gather input from the digital health community. Latest versions will be posted for the following Evidence DEFINED resources: the supplementary checklist of evidence quality criteria (Supplementary Table  2 ), evidence-torecommendation guidelines (Table  2 ), and the Quick Start Guide (Fig.  1 ).\n\nGiven rapid evolution in digital health, Evidence DEFINED updates will be implemented every 6-12 months. Suggested modifications will be evaluated by article authors and other subject matter experts from the Society. Following a comment period, updated versions of the aforementioned key resources will be posted. See Supplementary Discussion for details."
    },
    {
      "title": "DEVELOPMENT OF THE EVIDENCE DEFINED FRAMEWORK Development of this Framework was organized by the Research",
      "text": "Committee of the Digital Medicine Society, a nonprofit dedicated to advancing \"safe, effective, equitable, and ethical use of digital medicine\" 45 . The senior author (J.S.) facilitated the workgroup process and drafted initial materials, which were supplemented substantially and iterated upon by the multidisciplinary workgroup.\n\nSeventeen experts with diverse backgrounds were assembled, representing academic medical centers, health plans, pharmaceutical companies, DH solutions providers, professional societies, patient advocacy organizations, and contract research organizations. Expertise within the workgroup spans clinical care, scientific research, biostatistics, health plan administration, regulatory affairs, and corporate strategy. Group members hold senior leadership positions in their organizations. A patient perspective representative (C.G.) was also included.\n\nThe workgroup agreed early in the process to develop a supplement-not a replacement-for established evidence assessment frameworks. Iterative feedback from workgroup members was solicited via asynchronous communications, four live workshops, and one-on-one discussions among workgroup members. The Evidence DEFINED Framework was refined based on edits and comments received during and following each live session. All group members provided feedback during at least one of the review cycles, and approved the final version."
    },
    {
      "title": "DISCUSSION",
      "text": "Herein we have proposed the Evidence DEFINED Framework-a rigorous, rapid approach to assess the effectiveness and safety of digital health interventions. Evidence DEFINED may be appropriate for use by stakeholder organizations including payers, PBMs, health systems, pharmaceutical companies, trade organizations, and professional medical societies. The primary goal of the Evidence DEFINED Framework is to support high-quality, evidence-based decisions around adoption of digital health interventions, and thereby encourage use of safe and effective DHIs. Evidence DEFINED improves rigor by rectifying key gaps in prior approaches. The Framework achieves efficiency through screening steps and avoidance of information gathering that may have limited impact on decisions.\n\nWhen assessing clinical evidence in digital health, details matter. Careful evidence assessment can mean the difference between identifying critical evidence flaws and failing to do so. This can, in turn, impact countless patients, by dictating whether patients get access to digital health interventions that are effective and safe. For some patients, rigorous DHI evidence assessment may mean the difference between medication adherence and nonadherence; between overcoming nicotine dependence and developing lung cancer; between resolution of affective symptoms and chronic emotional struggles. Because DHIs are scalable, relevant impacts may be magnified."
    },
    {
      "title": "FUTURE DIRECTIONS",
      "text": "Best practices should be developed for coordinated, interdisciplinary DHI assessment, integrating well-developed methodologies across domains. Key assessment domains may include patient experience, provider experience, product design, cost effectiveness, data governance, interoperability, and health equity, as well as clinical evidence. Templates should be developed to summarize findings of Evidence DEFINED assessments and broader evaluations. The interrater reliability of Evidence DEFINED should be quantified in future research, and adjustments should be implemented if necessary. The Evidence DEFINED Checklist (Supplementary Table  2 ) may be adapted in the future for use in peer review.\n\nFinally, best practices should be established that adapt trial design and statistical methods to accommodate the iterative nature of DHI development. Evidence DEFINED may facilitate initial assessments regarding appropriate adoption levels for a digital health intervention. More work is needed to establish best practices for monitoring post-trial DHI modifications (e.g., due to software updates), as well as any changes in safety or effectiveness, throughout the product lifecycle. Ultimately, DHI assessment will need to comply with an emerging regulatory framework, as well as quality assurance processes, to ensure consistency, appropriate evidence standards, and quality of the DHIs used by patients."
    },
    {
      "title": "CONCLUSIONS",
      "text": "To realize the potential of digital health, we need stronger, standardized frameworks for DHI evidence assessment  46  . We should encourage DH solutions providers to follow high standards -and hold DHSPs accountable to deliver the clinical value they promise. Evidence DEFINED may help guide DHSPs that wish to develop compelling evidence and drive adoption of digital health products.\n\nEvidence DEFINED may also allow stakeholder organizations to assess DHI evidence in a more rapid, rigorous, and standardized manner. We hope this will promote evidence-based decision making, encourage adoption of effective DHIs, and thereby improve health outcomes across a range of conditions and populations."
    },
    {
      "title": "METHODS"
    },
    {
      "title": "Literature search overview",
      "text": "Scoping review methods  47  were used to identify prior evidence assessment frameworks for digital health interventions (DHIs). A scoping approach was consistent with our goal to generate a preliminary assessment of relevant literature and its gaps  48  . Evidence assessment frameworks were identified from (a) 4 prior reviews  [25] [26] [27] 49  , (b) updating of MEDLINE searches performed for these reviews (to be current through October, 2022) and (c) a grey literature search performed per best practices detailed elsewhere 50 (see Supplementary Figure  1 ). Du  to differences in review scope, prior reviews included some assessment frameworks that did not address clinical evidence; such frameworks were excluded from this search. Following others  27  , we did not aim for and are unable to guarantee an exhaustive search, given the dynamic nature of this literature."
    },
    {
      "title": "Objectives of literature search",
      "text": "A literature search was performed with the objectives to (a) generate a preliminary list of relevant frameworks proposed previously, (b) provide a preliminary assessment regarding key characteristics of prior frameworks, and (c) assess the degree to which prior frameworks meet criteria that the Workgroup believed may facilitate rigorous and rapid assessment of digital health interventions. The criteria were (a) leveraging established evidence assessment methods that had been developed initially for non-digital interventions (e.g., GRADE  18  ), (b) addressing evidence quality criteria that are specific to digital health interventions, (c) specifying evidence quality criteria that may require increased vigilance in digital health (given the current regulatory context), and (d) providing evidence-to-recommendation guidelines that state what levels of DHI adoption may be appropriate for varying degrees of evidence quality."
    },
    {
      "title": "Eligibility criteria",
      "text": "Frameworks were eligible for inclusion if they (a) were published in peer-reviewed or grey literature during or before October, 2022; (b) were described in one or more English documents; (c) recommended at least one criterion or question to assess evidentiary support for the safety, efficacy, or effectiveness of digital health interventions; (d) addressed clinical evidence either exclusively or in addition to other assessment domains (e.g., user experience, data security, etc.); and (e) were intended for application to either DHIs broadly or to a subgroup of DHIs (e.g., mental health apps). Frameworks were excluded that (a) addressed quality of health information but not evidence of safety/efficacy/effectiveness or b) were proprietary frameworks with minimal description of methods available publicly."
    },
    {
      "title": "Information sources and search strategy",
      "text": "Search strategies and information sources utilized in prior reviews are described elsewhere  [25] [26] [27] 49  . MED INE updates of prior searches were performed, to be current through October, 2022. Search strategies used for updating were the same as those described in the prior reviews  [25] [26] [27] 49  . Sources used for grey literature are detailed elsewhere  50  . These include Google Scholar as well as the websites of health technology assessment organizations, government agencies, and trade associations."
    },
    {
      "text": "Fig. 1 Quick start guide. A process overview for the Evidence DEFINED Framework."
    },
    {
      "text": "Criteria defining digital health interventions (DHIs)."
    },
    {
      "text": "Evidence-to-recommendation guidelines."
    }
  ],
  "references": [
    {
      "title": "Digital health trends 2021: innovation, evidence, regulation, and adoption",
      "authors": [
        "Iqvia"
      ],
      "year": 2021,
      "doi": "10.1002/cprt.30949"
    },
    {
      "title": "Challenges for the evaluation of digital health solutions-a call for innovative evidence generation approaches",
      "authors": [
        "C Guo"
      ],
      "year": 2020,
      "doi": "10.1038/s41746-020-00314-2"
    },
    {
      "title": "AMA unveils playbook to speed digital health adoption",
      "year": 2018,
      "doi": "10.1001/jama.1991.03470160127048"
    },
    {
      "title": "The App Evaluation Model",
      "year": 2021,
      "doi": "10.3389/fdgth.2022.1003181"
    },
    {
      "title": "Digital Health Consumer Adoption Report",
      "year": 2020
    },
    {
      "title": "Digital health-the need to assess benefits, risks, and value on apple podcasts",
      "authors": [
        "G Ginsburg"
      ],
      "year": 2021
    },
    {
      "title": "Digital health: a path to validation",
      "authors": [
        "S Mathews"
      ],
      "year": 2019,
      "doi": "10.1038/s41746-019-0111-3"
    },
    {
      "title": "Mobile app validation: a digital health scorecard approach",
      "authors": [
        "R Sedhom",
        "M Mcshea",
        "A Cohen",
        "J Webster",
        "S Mathews"
      ],
      "year": 2021,
      "doi": "10.1038/s41746-021-00476-7"
    },
    {
      "title": "Understanding the quality, effectiveness and attributes of top-rated smartphone health apps",
      "authors": [
        "H Wisniewski"
      ],
      "year": 2019,
      "doi": "10.1136/ebmental-2018-300069"
    },
    {
      "title": "Digital health-The need to assess benefits, risks, and value",
      "authors": [
        "E Perakslis",
        "G Ginsburg"
      ],
      "year": 2020,
      "doi": "10.1001/jama.2020.22919"
    },
    {
      "title": "Evaluating patient-centered mobile health technologies: definitions, methodologies, and outcomes",
      "authors": [
        "C Bruce"
      ],
      "year": 2020,
      "doi": "10.2196/17577"
    },
    {
      "title": "Diabetes digital app technology: benefits, challenges, and recommendations. A consensus report by the European Association for the Study of Diabetes (EASD and the American Diabetes Association (ADA) Diabetes Technology Working Group",
      "authors": [
        "G Fleming"
      ],
      "year": 2020,
      "doi": "10.1007/s00125-019-05034-1"
    },
    {
      "title": "Actionable health app evaluation: translating expert frameworks into objective metrics",
      "authors": [
        "S Lagan"
      ],
      "year": 2020,
      "doi": "10.1038/s41746-020-00312-4"
    },
    {
      "title": "Opening the black box of digital health care: making sense of \"evidence",
      "authors": [
        "K Gupta",
        "D Frosch",
        "R Kaplan"
      ],
      "year": 2021
    },
    {
      "title": "Digital health, digital medicine, digital therapeutics (DTx): what's the difference?",
      "authors": [
        "J Goldsack"
      ],
      "year": 2019
    },
    {
      "title": "FDA launches the Digital Health Center of Excellence",
      "year": 2020
    },
    {
      "title": "Digital Health Center of Excellence",
      "year": 2022,
      "doi": "10.14448/frameless.01.006"
    },
    {
      "title": "GRADE: an emerging consensus on rating quality of evidence and strength of recommendations",
      "authors": [
        "G Guyatt"
      ],
      "year": 2008,
      "doi": "10.1136/bmj.39489.470347.ad"
    },
    {
      "title": "HHS Interagency Workgroup on Multiple Chronic Conditions. Managing multiple chronic conditions: a strategic framework for improving health outcomes and quality of life",
      "authors": [
        "A Parekh",
        "R Goodman",
        "C Gordon",
        "H Koh"
      ],
      "year": 2011
    },
    {
      "title": "The growing burden of major depressive disorders (MDD): implications for researchers and policy makers",
      "authors": [
        "D Proudman",
        "P Greenberg",
        "D Nellesen"
      ],
      "year": 2021,
      "doi": "10.1007/s40273-021-01040-7"
    },
    {
      "title": "Health and economic costs of chronic diseases | CDC",
      "year": 2022
    },
    {
      "title": "The growing burden of chronic disease in America",
      "authors": [
        "G Anderson",
        "J Horvath"
      ],
      "year": 2004
    },
    {
      "title": "Grand challenges in human factors and digital health",
      "authors": [
        "S Schueller"
      ],
      "year": 2021
    },
    {
      "title": "Scoping review: Development and assessment of evaluation frameworks of mobile health apps for recommendations to consumers",
      "authors": [
        "M Hensher"
      ],
      "year": 2021
    },
    {
      "title": "Suitability of current evaluation frameworks for use in the health technology assessment of mobile medical applications: a systematic review",
      "authors": [
        "M Moshi",
        "R Tooher",
        "T Merlin"
      ],
      "year": 2018,
      "doi": "10.1017/s026646231800051x"
    },
    {
      "title": "A design and evaluation framework for digital health interventions",
      "authors": [
        "T Kowatsch",
        "L Otto",
        "S Harperink",
        "A Cotti",
        "H Schlieter"
      ],
      "year": 2019,
      "doi": "10.1515/itit-2019-0019"
    },
    {
      "title": "Evaluating evaluation frameworks: a scoping review of frameworks for assessing health apps",
      "authors": [
        "S Lagan",
        "L Sandler",
        "J Torous"
      ],
      "year": 2021
    },
    {
      "title": "Decision makers need an approach to determine digital therapeutic product quality, access, and appropriate use",
      "authors": [
        "B Parcher",
        "M Coder"
      ],
      "year": 2021
    },
    {
      "title": "Enlight: a comprehensive quality and therapeutic potential evaluation tool for mobile and webbased eHealth interventions",
      "authors": [
        "A Baumel",
        "K Faber",
        "N Mathur",
        "J Kane",
        "F Muench"
      ],
      "year": 2017
    },
    {
      "title": "Effective? Engaging? Secure? Applying the ORCHA-24 framework to evaluate apps for chronic insomnia disorder",
      "authors": [
        "S Leigh",
        "J Ouyang",
        "C Mimnagh"
      ],
      "year": 2017,
      "doi": "10.1136/eb-2017-102751"
    },
    {
      "title": "What makes a good clinical app? Introducing the RCP Health Informatics Unit checklist",
      "authors": [
        "J Wyatt"
      ],
      "year": 2015,
      "doi": "10.7861/clinmedicine.15-6-519"
    },
    {
      "title": "AppScript | discover, deliver & track digital health",
      "authors": [
        "Iqvia"
      ],
      "year": 2021
    },
    {
      "title": "Chapter 23-Outcomes assessment for digital health interventions in diabetes: a payer perspective",
      "authors": [
        "J Silberman",
        "S Sarlati",
        "M Kaur",
        "W Bokhari"
      ]
    },
    {
      "authors": [
        "D Klonoff",
        "D Kerr",
        "E Weitzman"
      ],
      "year": 2022,
      "doi": "10.1016/B978-0-323-90557-2.00023-6"
    },
    {
      "title": "Clinical trial registration and reporting: a survey of academic organizations in the United States",
      "authors": [
        "E Mayo-Wilson"
      ],
      "year": 2018
    },
    {
      "title": "Characteristics of digital health studies registered in ClinicalTrials",
      "authors": [
        "C Chen",
        "R Harrington",
        "S Desai",
        "K Mahaffey",
        "M Turakhia"
      ],
      "year": 2019,
      "doi": "10.1001/jamainternmed.2018.7235"
    },
    {
      "title": "Summary table of HHS/NIH initiatives to enhance availability of clinical trial Information",
      "year": 2016
    },
    {
      "title": "EVIDENCE publication checklist for studies evaluating connected sensor technologies: explanation and elaboration",
      "authors": [
        "C Manta"
      ],
      "year": 2021,
      "doi": "10.1159/000515835"
    },
    {
      "title": "Return on health: moving beyond dollars and cents in realizing the value of virtual care",
      "year": 2021,
      "doi": "10.4135/9781412950602.n33"
    },
    {
      "title": "The need for a privacy standard for medical devices that transmit protected health information used in the precision medicine initiative for diabetes and other diseases",
      "authors": [
        "D Klonoff",
        "W Price"
      ],
      "year": 2017
    },
    {
      "title": "World Economic Forum. Shared guiding principles for digital health inclusion",
      "year": 2021,
      "doi": "10.62891/ded13d5d"
    },
    {
      "title": "What is GRADE?",
      "authors": [
        "R Siemieniuk",
        "G Guyatt"
      ],
      "year": 2020
    },
    {
      "title": "Mobile App Rating Scale: a new tool for assessing the quality of health mobile apps",
      "authors": [
        "S Stoyanov"
      ],
      "year": 2015
    },
    {
      "title": "Development of a multidimensional app-quality assessment tool for health-related apps (AQUA)",
      "authors": [
        "T O'rourke",
        "R Pryss",
        "W Schlee",
        "T Probst"
      ],
      "year": 2020,
      "doi": "10.24989/dp.v1i2.1816"
    },
    {
      "title": "EMPOWERED: Ordinary People, Extraordinary Products",
      "authors": [
        "M Cagan",
        "C Jones"
      ],
      "year": 2021
    },
    {
      "title": "Digital therapeutics should be regulated With gold-standard evidence",
      "authors": [
        "C Espie",
        "J Torous",
        "T Brennan"
      ],
      "year": 2022,
      "doi": "10.1377/forefront.20220223.739329"
    },
    {
      "title": "PRISMA extension for scoping reviews (PRISMA-ScR): checklist and explanation",
      "authors": [
        "A Tricco"
      ],
      "year": 2018,
      "doi": "10.7326/m18-0850"
    },
    {
      "title": "A typology of reviews: an analysis of 14 review types and associated methodologies",
      "authors": [
        "M Grant",
        "A Booth"
      ],
      "year": 2009,
      "doi": "10.1111/j.1471-1842.2009.00848.x"
    },
    {
      "title": "Criteria for assessing the quality of mHealth apps: a systematic review",
      "authors": [
        "R Nouri",
        "S R Niakan Kalhori",
        "M Ghazisaeedi",
        "G Marchand",
        "M Yasini"
      ],
      "year": 2018
    },
    {
      "title": "Grey matters: a practical tool for searching health-related grey literature",
      "year": 2019,
      "doi": "10.1515/9783598441493.2.199"
    }
  ],
  "num_references": 50
}
