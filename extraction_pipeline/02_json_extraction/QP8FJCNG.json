{
  "paper_id": "QP8FJCNG",
  "title": "Atrial fibrillation detection via Apple Watch Arterys",
  "abstract": "edicine is at the crossroad of two major trends. The first is a failed business model, with increasing expenditures and jobs allocated to healthcare, but with deteriorating key outcomes, including reduced life expectancy and high infant, childhood, and maternal mortality in the United States 1,2 . This exemplifies a paradox that is not at all confined to American medicine: investment of more human capital with worse human health outcomes. The second is the generation of data in massive quantities, from sources such as high-resolution medical imaging, biosensors with continuous output of physiologic metrics, genome sequencing, and electronic medical records. The limits on analysis of such data by humans alone have clearly been exceeded, necessitating an increased reliance on machines. Accordingly, at the same time that there is more dependence than ever on humans to provide healthcare, algorithms are desperately needed to help. Yet the integration of human and artificial intelligence (AI) for medicine has barely begun. Looking deeper, there are notable, longstanding deficiencies in healthcare that are responsible for its path of diminishing returns. These include a large number of serious diagnostic errors, mistakes in treatment, an enormous waste of resources, inefficiencies in workflow, inequities, and inadequate time between patients and clinicians  3, 4  . Eager for improvement, leaders in healthcare and computer scientists have asserted that AI might have a role in addressing all of these problems. That might eventually be the case, but researchers are at the starting gate in the use of neural networks to ameliorate the ills of the practice of medicine. In this Review, I have gathered much of the existing base of evidence for the use of AI in medicine, laying out the opportunities and pitfalls. \n Artificial intelligence for clinicians Almost every type of clinician, ranging from specialty doctor to paramedic, will be using AI technology, and in particular deep learning, in the future. This largely involved pattern recognition using deep neural networks (DNNs) (Box 1) that can help interpret medical scans, pathology slides, skin lesions, retinal images, electrocardiograms, endoscopy, faces, and vital signs. The neural net interpretation is typically compared with physicians' assessments using a plot of true-positive versus false-positive rates, known as a receiver operating characteristic (ROC), for which the area under the curve (AUC) is used to express the level of accuracy (Box 1). \n Radiology. One field that has attracted particular attention for application of AI is radiology 5 . Chest X-rays are the most common type of medical scan, with more than 2 billion performed worldwide per year. In one study, the accuracy of one algorithm, based on a 121-layer convolutional neural network, in detecting pneumonia in over 112,000 labeled frontal chest X-ray images was compared with that of four radiologists, and the conclusion was that the algorithm outperformed the radiologists. However, the algorithm's AUC of 0.76, although somewhat better than that for two previously tested DNN algorithms for chest X-ray interpretation 5 , is far from optimal. In addition, the test used in this study is not necessarily comparable with the daily tasks of a radiologist, who will diagnose much more than pneumonia in any given scan. To further validate the conclusions of this study, a comparison with results from more than four radiologists should be made. A team at Google used an algorithm that analyzed the same image set as in the previously discussed study to make 14 different diagnoses, resulting in AUC scores that ranged from 0.63 for pneumonia to 0.87 for heart enlargement or a collapsed lung 6 . More recently, in another related study, it was shown that a DNN that is currently in use in hospitals in India for interpretation of four different chest X-ray key findings was at least as accurate as four radiologists 7 . For the narrower task of detecting cancerous pulmonary nodules on a chest X-ray, a DNN that retrospectively assessed scans from over 34,000 patients achieved a level of accuracy exceeding 17 of 18 radiologists 8 . It can be difficult for emergency room doctors to accurately diagnose wrist fractures, but a DNN led to marked improvement, increasing sensitivity from 81% to 92% and reducing misinterpretation by 47% (ref.  9 ). Similarly, DNNs have been applied across a wide variety of medical scans, including bone films for fractures and estimation of aging  [10] [11] [12]  , classification of tuberculosis 13 , and vertebral compression fractures 14 ; computed tomography (CT) scans for lung nodules 15 , liver masses 16 , pancreatic cancer 17 , and coronary calcium score 18 ; brain scans for evidence of hemorrhage 19 , head trauma 20 , and acute referrals 21 ; magnetic resonance imaging 22 ; echocardiograms  23, 24  ; and mammographies  25, 26  . A unique imaging-recognition study focusing on the breadth of acute neurologic events, such as stroke or head trauma, was carried out on over 37,000 head CT 3-D scans, which the algorithm analyzed for 13 different anatomical findings versus gold-standard labels (annotated by expert radiologists) and achieved an AUC of 0.73 (ref.  27 ). A simulated prospective, double-blind, randomized control trial was conducted with real cases from the dataset and showed that the deep-learning algorithm could interpret scans 150 times faster than radiologists (1.2 versus 177 seconds). But the conclusion that the algorithm's diagnostic accuracy in screening acute neurologic scans was poorer than human \n High-performance medicine: the convergence of human and artificial intelligence Eric J. Topol The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient-doctor relationship or facilitate its erosion remains to be seen.",
  "year": 2019,
  "date": "2019-01-07",
  "journal": "Health Aff. (Millwood)",
  "publication": "Health Aff. (Millwood)",
  "authors": [
    {
      "affiliation": "7  Department of Molecular Medicine , Scripps Research , La Jolla , CA , USA. \n\t\t\t\t\t\t\t\t Department of Molecular Medicine \n\t\t\t\t\t\t\t\t Scripps Research \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t La Jolla \n\t\t\t\t\t\t\t\t\t CA \n\t\t\t\t\t\t\t\t\t USA"
    }
  ],
  "doi": "https://doi.org/10.13039/100000002",
  "sections": [
    {
      "title": "FOCUS | Review ARticle",
      "text": "NaTure MedIcINe performance was sobering and indicates that there is much more work to do.\n\nFor each of these studies, a relatively large number of labeled scans were used for training and subsequent evaluation, with AUCs ranging from 0.99 for hip fracture to 0.84 intracranial bleeding and liver masses to 0.56 for acute neurologic case screening. It is not possible to compare DNN accuracy from one study to the next because of marked differences in methodology. Furthermore, ROC and AUC metrics are not necessarily indicative of clinical utility or even the best way to express accuracy of the model's performance  28, 29  . Furthermore, many of these reports still only exist in preprint form and have not appeared in peer-reviewed publications. Validation of the performance of an algorithm in terms of its accuracy is not equivalent to demonstrating clinical efficacy. This is what Pearse Keane and I have referred to as the ' AI chasm'-that is, an algorithm with an AUC of 0.99 is not worth very much if it is not proven to improve clinical outcomes  30  . Among the studies that have gone through peer review (many of which are summarized in Table  1 ), the only prospective validation studies in a real-world setting have been for diabetic retinopathy  31, 32  , detection of wrist fractures in the emergy room setting  33  , histologic breast cancer metastases  34, 35  , very small colonic polyps  36, 37  , and congenital cataracts in a small group of children  38  . The field clearly is far from demonstrating very high and reproducible machine accuracy, let alone clinical utility, for most medical scans and images in the real-world clinical environment (Table  1 )."
    },
    {
      "title": "Pathology",
      "text": "Pathologists have been much slower at adopting digitization of scans than radiologists  39  -they are still not routinely converting glass slides to digital images and use whole-slide imaging (WSI) to enable viewing of an entire tissue sample on a slide. Marked heterogeneity and inconsistency among pathologists' interpretations of slides has been amply documented, exemplified by a lack of agreement in diagnosis of common types of lung cancer (\u039a = 0.41-0.46)  40 . Deep learning of digitized pathology slides offers the potential to improve accuracy and speed of interpretation, as assessed in a few retrospective studies. In a study of WSI of breast cancer, with or without lymph node metastases, that compared the performance of 11 pathologists with that of multiple algorithmic interpretations, the results varied and were affected in part by the length of time that the pathologists had to review the slides  41  . Some of the five algorithms performed better than the group of pathologists, who had varying expertise. The pathologists were given 129 test slides and had less than 1 minute for review per slide, which likely does not reflect normal workflow. On the other hand, when one expert pathologist had no time limits and took 30 hours to review the same slide set, the results were comparable with the algorithm for detecting noninvasive ductal carcinoma  42  ."
    },
    {
      "title": "Box 1 | deep learning",
      "text": "While the roots of AI date back over 80 years from concepts laid out by Alan Turing  204, 205  and Warren McCulloch and Walter Pitts 206 , it was not until 2012 that the subtype of deep learning was widely accepted as a viable form of AI  207  . A deep learning neural network consists of digitized inputs, such as an image or speech, which proceed through multiple layers of connected 'neurons' that progressively detect features, and ultimately provides an output. By analyzing 1.2 million carefully annotated images from over 15 million in the ImageNet database, a DNN achieved, for that point in time, an unprecedented low error rate for automated image classification. That report, along with Google Brain's 10 million images from YouTube videos to accurately detect cats, laid the groundwork for future progress. Within 5 years, in specific large data-labeled test sets, deep-learning algorithms for image recognition surpassed the human accuracy rate  208, 209  , and, in parallel, suprahuman performance was demonstrated for speech recognition.\n\nThe basic DNN architecture is like a club sandwich turned on its side, with an input layer, a number of hidden layers ranging from 5 to 1,000, each responding to different features of the image (like shape or edges), and an output layer. The layers are 'neurons,' comprising a neural network, even though there is little support of the notion that these artificial neurons function similarly to human neurons. A key differentiating feature of deep learning compared with other subtypes of AI is its autodidactic quality; the neural network is not designed by humans, but rather the number of layers (Fig.  1 ) is determined by the data itself. Image and speech recognition have primarily used supervised learning, with training from known patterns and labeled input data, commonly referred to as ground truths. Learning from unknown patterns without labeled input data-unsupervised learning-has very rarely been applied to date. There are many types of DNNs and learning, including convolutional, recurrent, generative adversarial, transfer, reinforcement, representation, and transfer (for review see refs.  210, 211 ). Deep-learning algorithms have been the backbone of computer performance that exceeds human ability in multiple games, including the Atari video game Breakout, the classic game of Go, and Texas Hold' em poker. DNNs are largely responsible for the exceptional progress in autonomous cars, which is viewed by most as the pinnacle technological achievement of AI to date. Notably, except in the cases of games and self-driving cars, a major limitation to interpretation of claims reporting suprahuman performance of these algorithms is that analytics are performed on previously generated data in silico, not prospectively in real-world clinical conditions. Furthermore, the lack of large datasets of carefully annotated images has been limiting across various disciplines in medicine. Ironically, to compensate for this deficiency, generative adversarial networks have been used to synthetically produce large image datasets at high resolution, including mammograms, skin lesions, echocardiograms, and brain and retina scans, that could be used to help train DNNs  [212] [213] [214] [215] [216]  ."
    },
    {
      "title": "Data"
    },
    {
      "title": "Input layer",
      "text": "Output layer"
    },
    {
      "title": "Hidden layers",
      "text": "Fig.\n\n1 | A deep neural network, simplified. Credit: Debbie Maizels/Springer Nature FOCUS | Review ARticle  https://doi.org/10.1038/s41591-018-0300-7"
    },
    {
      "title": "FOCUS | Review ARticle"
    },
    {
      "title": "NaTure MedIcINe",
      "text": "Other studies have assessed deep-learning algorithms for classifying breast cancer  43  and lung cancer  40  without direct comparison with pathologists. Brain tumors can be challenging to subtype, and machine learning using tumor DNA methylation patterns via sequencing led to markedly improved classification compared with pathologists using traditional histological data  44, 45  . DNA methylation generates extensive data and at present is rarely performed in the clinic for classification of tumors, but this study suggests another potential for AI to provide improved diagnostic accuracy in the future. A deep-learning algorithm for lung cancer digital pathology slides not only was able to accurately classify tumors, but also was trained to detect the pattern of several specific genomic driver mutations that would not otherwise be discernible by pathologists  33  .\n\nThe first prospective study to test the accuracy of an algorithm classifying digital pathology slides in a real clinical setting was an assessment of the identification of presence of breast cancer micrometastases in slides by six pathologists compared with a DNN (that had been retrospectively validated  34  ). The combination of pathologists and the algorithm led to the best accuracy, and the algorithm markedly sped up the review of slides  35  . This study is particularly notable, as the synergy of the combined pathologist and algorithm interpretation was emphasized instead of the pervasive clinician-versus-algorithm comparison. Apart from classifying tumors more accurately by data processing, the use of a deep-learning algorithm to sharpen outof-focus images may also prove useful  46  . A number of proprietary algorithms for image interpretation have been approved by the Food and Drug Administration (FDA), and the list is expanding rapidly (Table  2 ), yet there have been few peer-reviewed publications from most of these companies. In 2018, the FDA published a fast-track approval plan for AI medical algorithms."
    },
    {
      "title": "Dermatology.",
      "text": "For algorithms classifying skin cancer by image analysis, the accuracy of diagnosis of deep-learning networks has been compared with that of dermatologists. In a study using a large training dataset of nearly 130,000 photographic and dermascopic digitized images, 21 US board-certified dermatologists were at least matched in performance by an algorithm, which had an AUC of 0.96 for carcinoma  47  and of 0.94 for melanoma specifically. Subsequently, the accuracy of melanoma skin cancer diagnosis by a group of 58 international dermatologists was compared with a convolutional neural network; the mean ROCs were 0.79 versus 0.86, respectively, reflecting an improved performance of the algorithm compared with most of the physicians  48  . A third study carried out algorithmic assessment of 12 skin diseases, including basal cell carcinoma, squamous cell carcinoma, and melanoma, and compared this with 16 dermatologists, with the algorithm achieving an AUC of 0.96 for melanoma  49  . None of these studies were conducted in the clinical setting, in which a doctor would perform physical inspection and shoulder responsibility for making an accurate diagnosis. Notwithstanding these concerns, most skin lesions are diagnosed by primary care doctors, and problems with inaccuracy have been underscored; if AI can be reliably shown to simulate experienced dermatologists, that would represent a significant advance.\n\nOphthalmology. There have been a number of studies comparing performance between algorithms and ophthalmologists in diagnosing\n\nTable 1 | Peer-reviewed publications of Ai algorithms compared with doctors Specialty images Publication Radiology/ neurology CT head, acute neurological events Titano et al. 27 CT head for brain hemorrhage Arbabshirani et al. 19 CT head for trauma Chilamkurthy et al. 20 CXR for metastatic lung nodules Nam et al. 8 CXR for multiple findings Singh et al. 7 Mammography for breast density Lehman et al. 26 Wrist X-ray* Lindsey et al. 9 Pathology Breast cancer Ehteshami Bejnordi et al. 41 Lung cancer ( + driver mutation) Coudray et al. 33 Brain tumors ( + methylation) Capper et al. 45 Breast cancer metastases* Steiner et al. 35 Breast cancer metastases Liu et al. 34 Dermatology Skin cancers Esteva et al. 47 Melanoma Haenssle et al. 48 Skin lesions Han et al. 49 Ophthalmology Diabetic retinopathy Gulshan et al. 51 Diabetic retinopathy* Abramoff et al. 31\n\nDiabetic retinopathy* Kanagasingam et al.  32  Congenital cataracts Long et al.  38  Retinal diseases (OCT) De Fauw et al.  56  Macular degeneration Burlina et al.  52  Retinopathy of prematurity Brown et al.  60  AMD and diabetic retinopathy Kermany et al.  53  Gastroenterology Polyps at colonoscopy* Mori et al.  36  Polyps at colonoscopy Wang et al.  37  Cardiology Echocardiography Madani et al.  23  Echocardiography Zhang et al.  24  Prospective studies are denoted with an asterisk.\n\nTable 2 | FdA Ai approvals are accelerating company FdA Approval indication Apple September 2018 Atrial fibrillation detection Aidoc August 2018 CT brain bleed diagnosis iCAD August 2018 Breast density via mammography Zebra Medical July 2018 Coronary calcium scoring Bay Labs June 2018 Echocardiogram EF determination Neural Analytics May 2018 Device for paramedic stroke diagnosis IDx April 2018 Diabetic retinopathy diagnosis Icometrix April 2018 MRI brain interpretation different eye conditions. After training with over 128,000 retinal fundus photographs labeled by 54 ophthalmologists, a neural network was used to assess over 10,000 retinal fundus photographs from more than 5,000 patients for diabetic retinopathy, and the neural network's grading was compared with seven or eight ophthalmologists for all-cause referable diagnoses (moderate or worse retinopathy or macular edema; scale: none, mild, moderate, severe, or proliferative). In two separate validation sets, the AUC was 0.99 (refs.  50, 51 ). In a study in which retinal fundus photographs were used for the diagnosis of age-related macular degeneration (AMD), the accuracy for DNN algorithms ranged between 88% and 92%, nearly as high as for expert ophthalmologists  52  . Performance of a deep-learning algorithm for interpreting retinal optical coherence tomography (OCT) was compared with ophthalmologists for diagnosis of either of the two most common causes of vision loss: diabetic retinopathy or AMD. After the algorithm was trained on a dataset of over 100,000 OCT images, validation was performed in 1,000 of these images, and performance was compared with six ophthalmologists. The algorithm's AUC for OCT-based urgent referral was 0.999 (refs.  [53] [54] 4] [55]  ).\n\nAnother deep-learning OCT retinal study went beyond the diagnosis of diabetic retinopathy or macular degeneration. A group of 997 patients with a wide range of 50 retinal pathologies was assessed for urgent referral by an algorithm (using two different types of OCT devices that produce 3-D images) and results were compared with those from experts: four retinal specialists and four optometrists, with an AUC for accuracy of urgent referral triage to replace false alarm of 0.992. The algorithm did not miss a single urgent referral case. Notably, the eight clinicians agreed on only 65% of the referral decisions. Errors on the correct referral decision were reduced for both types of clinicians by integrating the fundus photograph and notes on the patient, but the algorithm's error rate (without notes or fundus photographs) of 3.5% was as good or better than all eight experts  56  . One unique aspect of this study was the transparency of the two neural networks used, one for mapping the eye OCT scans into a tissue schematic and the other for the classifier of eye disease. The user (patient) can watch a video that shows what portions of his or her scan were used to reach the algorithm's conclusions along with the level of confidence it has for the diagnosis. This sets a new bar for future efforts to unravel the 'black box' of neural networks.\n\nIn a prospective trial conducted in primary care clinics, 900 patients with diabetes but no known retinopathy were assessed by a proprietary system (an imaging device combined with an algorithm) made by IDx (Iowa City, IA) that obtained retinal fundus photographs and OCT and by established reading centers with expertise in interpreting these images  30, 31  . The algorithm was used at primary care clinics up until the clinical trial was autodidactic and thus locked for testing, but it achieved a sensitivity of 87% and specificity of 91% for the 819 patients (91% of the enrolled cohort) with analyzable images. This trial led to FDA approval of the IDx device and algorithm for autonomous detection, that is, without the need for a clinician, of 'more than mild' diabetic retinopathy. The regulatory oversight in dealing with deep-learning algorithms is tricky because it does not currently allow continued autodidactic functionality but instead necessitates fixing the software to behave like a non-AI diagnostic system  30  . Notwithstanding this point along with the unknown extent of uptake of the device, the study represents a milestone as the first prospective assessment of AI in the clinic. The accuracy results are not as good as the aforementioned in silico studies, which should be anticipated. A small prospective real-world assessment of a DNN for diabetic retinopathy in primary care clinics, with eye exams performed by nurses, led to a high falsepositive diagnosis rate  32  .\n\nWhile the studies of retinal OCT and fundus images have thus far focused on eye conditions, recent work suggests that these images can provide a window to the brain for early diagnosis of dementia, including Alzheimer's disease  57  .\n\nThe potential use of retinal photographs also appears to transcend eye diseases per se. Images from over 280,000 patients were assessed by DNN for cardiovascular risk factors, including age, gender, systolic blood pressure, smoking status, hemoglobin A1c, and likelihood of having a major adverse cardiac event, with validation in two independent datasets. The AUC for gender at 0.97 was notable, indicating that the algorithm could identify gender accurately from the retinal photo, but the others were in the range of 0.70, suggesting that there may be a signal that, through further pursuit, could be useful for monitoring patients for control of their risk factors  58, 59  .\n\nOther less common eye conditions that have been assessed by neural networks include congenital cataracts  38  and retinopathy of prematurity in newborns  60  , both with accuracy comparable with that of eye specialists.\n\nCardiology. The major images that cardiologists use in practice are electrocardiograms (ECG) and echocardiograms, both of which have been assessed with DNNs. There is a nearly 40-year history of machine-read ECGs using rules-based algorithms with notable inaccuracy  61  . When deep learning was used to diagnose heart attack in a small retrospective dataset of 549 ECGs, a sensitivity of 93% and specificity of 90% were reported, which was comparable with cardiologists  62  . Over 64,000 one-lead ECGs (from over 29,000 patients) were assessed for arrhythmia by a DNN and six cardiologists, with comparable accuracy across 14 different electrical conduction disturbances  63  . For echocardiography, a small set of 267 patient studies (consisting of over 830,000 still images) were classified into 15 standard views (such as apical 4-chamber or subcostal) by a DNN and by cardiologists. The overall accuracy for single still images was 92% for the algorithm and 79% for four board-certified echocardiographers, but this does not reflect the real-world reading of studies, which are in-motion video loops  23  . An even larger retrospective study of over 8,000 echocardiograms showed high accuracy for classification of hypertrophic cardiomyopathy (AUC, 0.93), cardiac amyloid (AUC, 0.87), and pulmonary artery hypertension (AUC, 0.85)  24  .\n\nGastroenterology. Finding diminutive (< 5 mm) adenomatous or sessile polyps at colonoscopy can be exceedingly difficult for gastroenterologists. The first prospective clinical validation of AI was performed in 325 patients who collectively had 466 tiny polyps, with an accuracy of 94% and negative predictive value of 96% during realtime, routine colonoscopy  36, 64  . The speed of AI optical diagnosis was 35 seconds, and the algorithm worked equally well for both novice and expert gastroenterologists, without the need for injecting dyes. The findings of enhanced speed and accuracy were replicated in another independent study  37  . Such results are thematic: machine vision, at high magnification, can accurately and quickly interpret specific medical images as well as or better than humans.\n\nMental health. The enormous burden of mental health, such as the 350 million people around the world battling depression  74  , is especially noteworthy, as there is potential here for AI to lend support to the affected patients and the vastly insufficient number of clinicians. Various tools that are in development include digital tracking of depression and mood via keyboard interaction, speech, voice, facial recognition, sensors, and use of interactive chatbots  [75] [76] [77] [78] [79] [80]  . Facebook posts have been shown to predict the diagnosis of depression later documented in electronic medical records  81  .\n\nMachine learning has been explored for predicting successful antidepressant medication  82  , characterizing depression  [83] [84] [85]  , predicting suicide  83, [86] [87] [88]  , and predicting bouts of psychosis in schizophrenics  89  ."
    },
    {
      "title": "FOCUS | Review ARticle",
      "text": "https://doi.org/10.1038/s41591-018-0300-7"
    },
    {
      "title": "FOCUS | Review ARticle"
    },
    {
      "title": "NaTure MedIcINe",
      "text": "The use of AI algorithms has been described in many other clinical settings, such as facilitating stroke, autism or electroencephalographic diagnoses for neurologists  65, 66  , helping anesthesiologists avoid low oxygenation during surgery  67  , diagnosis of stroke or heart attack for paramedics  68  , finding suitable clinical trials for oncologists  69  , selecting viable embryos for in vitro fertilization  70  , help making the diagnosis of a congenital condition via facial recognition  71  and pre-empting surgery for patients with breast cancer  72  . Examples of the breadth of AI applications across human lifespan is shown in Fig.  2 .There is considerable effort across many startups and established tech companies to develop natural language processing to replace the need for keyboards and human scribes for clinic visits  73  . The list of companies active in this space includes Microsoft, Google, Suki, Robin Healthcare, DeepScribe, Tenor.ai, Saykara, Sopris Health, Carevoice, Orbita, Notable, Sensely and Augmedix."
    },
    {
      "title": "Artificial intelligence and health systems",
      "text": "Being able to predict key outcomes could, theoretically, make the use of hospital palliative care resources more efficient and precise. For example, if an algorithm could be used to estimate the risk of a patient's hospital readmission that would otherwise be undetectable given the usual clinical criteria for discharge, steps could be taken to avert discharge and attune resources to the underlying issues. For a critically ill patient, a very high likelihood of short-term survival might help this patient and their family and doctor make decisions regarding resuscitation, insertion of an endotracheal tube for mechanical ventilation, and other invasive measures. Similarly, it is possible that deciding which patients might benefit from palliative care and determining who is at risk of developing sepsis or septic shock could be ameliorated by AI predictive tools. Using electronic health record data, machine-and deep-learning algorithms have been able to predict many important clinical parameters, ranging from Alzheimer's disease to death (Table  3 )  86, [90] [91] [92] [93] [94] [95] [96] [97] [98] [99] [100] [101] [102] [103] [104] [105] [106] [107]  . For example, in a recent study, reinforcement learning was retrospectively carried out on two large datasets to recommend the use of vasopressors, intravenous fluids, and/or medications and the dose of the selected treatment for patients with sepsis; the treatment selected by the ' AI Clinician' was on average reliably more effective than that chosen by humans 108 . Both the size of the cohorts studied and the range of AUC accuracy reported have been quite heterogeneous, and all of these reports are retrospective and yet to be validated in the real-world clinical setting. Nevertheless, there are many companies that are already marketing such algorithms, such as Careskore, which is providing health systems with estimated of risk of readmission and mortality based on EHR data 109 . Beyond this issue, there are the differences between the prediction metric for a cohort and an individual prediction metric. If a model's AUC is 0.95, which most would qualify as very accurate, this reflects how good the model is for predicting an outcome, such as death, for the overall cohort. But most models are essentially classifiers and are not capable of precise prediction at the individual level, so there is still an important dimension of uncertainty.\n\nIn addition to data from electronic health records, imaging has been integrated to enhance predictive accuracy  98  . Multiple studies have attempted to predict biological age  110, 111  , and this has been shown to best be accomplished using DNA methylation-based biomarkers  112  . With respect to the accuracy of algorithms for prediction of biological age, the incompleteness of data input is noteworthy, since a large proportion of unstructured data-the free text in clinician notes that cannot be ingested from the medical recordhas not been incorporated, and neither have many other modalities such as socioeconomic, behavioral, biologic '-omics' , or physiologic sensor data. Further, concerns have been raised about the potential Table 3 | Selected reports of machine-and deep-learning algorithms to predict clinical outcomes and related parameters Prediction n Auc Publication (reference number) In-hospital mortality, unplanned readmission, prolonged LOS, final discharge diagnosis 216,221 0.93*0.75 + 0.85 # Rajkomar et al. 96 All-cause 3-12 month mortality 221,284 0.93 ^Avati et al. 91 Readmission 1,068 0.78 Shameer et al. 106 Sepsis 230,936 0.67 Horng et al. 102 Septic shock 16,234 0.83 Henry et al. 103 Severe sepsis 203,000 0.85 @ Culliton et al. 104 Clostridium difficile infection 256,732 0.82 ++ Oh et al. 93 Developing diseases 704,587 range Miotto et al. 97 Diagnosis 18,590 0.96 Yang et al. 90 Dementia 76,367 0.91 Cleret de Langavant et al. 92 Alzheimer's Disease ( + amyloid imaging) 273 0.91 Mathotaarachchi et al. 98 Mortality after cancer chemotherapy 26,946 0.94 Elfiky et al. 95 Disease onset for 133 conditions 298,000 range Razavian et al. 105 Suicide 5,543 0.84 Walsh et al. 86 Delirium 18,223 0.68 Wong et al. 100 LOS, length of stay; n, number of patients (training+ validation datasets). For AUC values: *, in-hospital mortality; + , unplanned readmission; #, prolonged LOS; ^, all patients; @, structured + unstructured data; + + , for University of Michigan site. Review ARticle | FOCUS  https://doi.org/10.1038/s41591-018-0300-7\n\nReview\n\nto overfit data owing to small sample sizes in some instances. It has also been pointed out how essential it is to have \u03ba -fold cross-validation of a model through successive, mutually exclusive validation datasets, which is missing from most of these publications. There is also considerable debate about using AUC as the key performance metric, since it ignores actual probability values and may be particularly misleading in regard to the sensitivity and specificity values that are of clinical interest  113  . In summary, it is not yet known how well AI can predict key outcomes in the healthcare setting, and this will not be determined until there is robust validation in prospective, real-world clinical environments, with rigorous statistical methodology and analysis."
    },
    {
      "title": "Machine vision. Machine vision (also known as computer vision)",
      "text": ", which uses data from ambient sensors, is attracting considerable attention in health systems for promoting safety by monitoring such activities as proper clinician handwashing 114 , critically ill patients in the intensive care unit 115 , and risk of falling for patients  116  . Weaning patients in the intensive care unit from mechanical ventilation is often haphazard and inefficient; a reinforcement-learning algorithm using machine vision has shown considerable promise in this regard 117 . There are also ongoing efforts to digitize surgery that include machine vision observation of the team and equipment in the operating room and performance of the surgeon; real-time, high-resolution, AI-processed imaging of the relevant anatomy of a patient; and integration of all of a patient's preoperative data, including full medical history, labs, and scans  118, 119  . Extremely delicate microsurgery, such as that inside the eye, has now been performed with AI assistance 120 . There is considerable promise in markedly reducing the radiation and time requirements for image acquisition and segmentation in preparation for radiotherapy via the use of deep-learning algorithms for image reconstruction 121 and of generative adversarial networks to improve the quality of medical scans. These improvements will, when widely implemented, promote safety, convenience, and lower cost  [122] [123] [124]  .\n\nWearables. Of the more than $3.5 trillion per year (and rising) expenditures for healthcare in the United States, almost a third is related to hospitals. With FDA-approved wearable sensors that can continuously monitor all vital signs-including blood pressure, heart rate and rhythm, blood oxygen saturation, respiratory rate, and temperature-there is the potential to preempt a large number of patients being hospitalized in the future. There has not yet been algorithmic development and prospective testing for remote monitoring, but this deserves aggressive pursuit as it could reduce the costs of care without sacrificing convenience and comfort for a patient and family. The reduction of nosocomial infections alone would be an alluring path for promoting safety.\n\nIncreased efficiencies. It has been estimated that, per day, AI would process over 250 million images for the cost of about $1,000 (ref.  125 ), representing a staggering hypothetical savings of billions of dollars. Besides the productivity and workflow gains that can be derived from AI-assisted image interpretation and clinician support, there is potential to reduce the workforce for many types of back-office, administrative jobs such as coding and billing, scheduling of operating rooms and clinic appointments, and staffing. At Geisinger Health in Pennsylvania, over 100,000 patients have undergone exome sequencing; the results are provided via an AI chatbot (Clear Genetics), which is well-received by most patients and reduces the need for genetic counselors. This demonstrates how a health system can leverage AI tools to provide complex information without having to rely on expansion of highly trained personnel.\n\nPerhaps the greatest long-term potential of AI in health systems is the development of a massive data infrastructure to support nearest-neighbor analysis, another application of AI used to identify 'digital twins. ' If each person's comprehensive biologic, anatomic, physiologic, environmental, socioeconomic, and behavioral data, including treatment and outcomes, were entered, an extraordinary learning system would be created. There have been great benefits derived from jet engine 126 digital twins that use an ultrahigh-fidelity model engine to simulate the flight conditions of a particular jet, but such a model has yet to be completed at any scale for patients, who theoretically could benefit from being informed of the best prevention methods, treatments, and outcomes for various conditions by their relevant twin's data 127 ."
    },
    {
      "title": "Artifical intelligence and patients",
      "text": "The work for developing deep-learning algorithms to enable the public to take their healthcare into their own hands has lagged behind that for clinicians and health systems, but there are a few such algorithms that have been FDA-cleared or are in latestage clinical development. In late 2017, a smartwatch algorithm was FDA-cleared to detect atrial fibrillation 128 , and subsequently in 2018 Apple received FDA approval for their algorithm used with the Apple Watch  Series 4 (refs. 129, 130  ). The photoplethysmography and accelerometer sensors on the watch learn the user's heart rate at rest and with physical activity, and when there is a significant deviation from expected, the user is given a haptic warning to record an ECG via the watch, which is then interpreted by FOCUS | Review ARticle  https://doi.org/10.1038/s41591-018-0300-7"
    },
    {
      "title": "FOCUS | Review ARticle"
    },
    {
      "title": "NaTure MedIcINe",
      "text": "an algorithm. There are legitimate concerns that the widescale use of such an algorithm, particularly in the low-risk, young population who wear Apple watches, will lead to a substantial number of false-positive atrial fibrillation diagnoses and prompt unnecessary medical evalautions 131 . In contrast, the deep learning of the ECG pattern on the smartwatch, which can accurately detect whether there is high potassium in the blood, may provide particular usefulness for patients with kidney disease. This concept of a 'bloodless' blood potassium level (Fig.  2 ) reading via a smartwatch algorithm embodies the prospect of an algorithm able to provide information that was not previously obtainable or discernible without the technology. Smartphone exams with AI are being pursued for a variety of medical diagnostic purposes, including skin lesions and rashes, ear infections, migraine headaches, and retinal diseases such as diabetic retinopathy and age-related macular degeneration. Some smartphone apps are using AI to monitor medical adherence, such as AiCure (NCT02243670), which has the patient take a selfie video as they swallow their prescribed pill. Other apps use image recognition of food for calorie and nutritional content  132  . In what may be seen as an outgrowth of dating apps that use AI nearest-neighbor analysis to find matches, there are now efforts to use the same methodology for matchmaking patients with primary care doctors to engender higher levels of trust  133  .\n\nOne study has recently achieved the continuous sensing of blood-glucose (for 2 weeks) along with assessment of the gut microbiome, physical activity, sleep, medications, all food and beverage intake, and a variety of lab tests  [134] [135] [136]  . This multimodal data collection and analysis has led to the ability to predict the glycemic response to specific foods for an individual, a physiologic pattern that is remarkably heterogeneous among people and significantly driven by the gut microbiome. The use of continuous glucose sensors, which now are factory-calibrated, preempting the need for finger-stick glucose calibrations, has shown that post-prandial glucose spikes commonly occur, even in healthy people without diabetes  137, 138  . It remains uncertain whether the glucose spikes indicate a higher risk of developing diabetes, but there are data suggesting this possibility 139 along with mechanistic links to gastrointestinal barrier dysfunction  140, 141  in experimental models. Nevertheless, the use of AI with multimodal data to guide an individualized diet is a precedent for virtual medical coaching in the future. In the present, simple rules-based algorithms, based upon whether glucose values are rising or falling, are used for glucose management in people with diabetes. While these have helped avert hypoglycemic episodes 142 , smart algorithms that incorporate an individual's comprehensive data are likely to be far more informative and helpful. In this manner, most common chronic conditions, such as hypertension, depression, and asthma, could theoretically be better managed with virtual coaching. With the remarkable progress in the accuracy of AI speech recognition and the accompanying soaring popularity of smart speakers, it is easy to envision that this would be performed via a voice platform, with or without an avatar. Eventually, when all of an individual's data and the corpus of medical literature can be incorporated, a holistic, prevention approach would be possible (Fig.  3 )."
    },
    {
      "title": "Artificial intelligence and data analysis",
      "text": "While upstream from clinical practice, AI progress in life science has been notably faster, with extensive peer-reviewed publication, an easier path to validation without regulatory oversight, and far more willingness among the scientific community for implementation. As the stethoscope is the icon of doctors, the microscope is the icon of scientists. Using AI, Christiansen et al.  143  developed in silico labeling. Instead of the routine fluorescent staining of microscopic images, which can harm and kill cells and involves a complex preparation, this machine-learning algorithm predicts the fluorescent labels, ushering in 'image-free' microscopy  [143] [144] [145]  . Soon thereafter,  Ota et al. 146  reported another image-free flow AI analytic method that they called 'ghost cytometry' to accurately identify rare cells, a capability that was replicated and extended by  Nitta et al. 147  with image-activated AI cell sorting. This use of machine learning addresses the formidable problem of identifying and isolating rare cells by rapid, high-throughput, and accurate sorting on the basis of cell morphology that does not require the use of biomarkers. Besides promoting image-free microcopy and cytometry, deep-learning AI has been used to restore or fix outof-focus images 148 . And computer vision has made possible highthroughput assessment of 40-plex proteins and organelles within a single cell  149, 150  .\n\nAnother challenge confronted by machine and deep learning has been in the analytics of genomic and other -omics biology datasets. Open-source algorithms have been developed for classifying or analyzing whole-genome sequence pathogenic variants  [151] [152] [153] [154] [155] [156] [157] [158]  , somatic cancer mutations 159 , gene-gene interactions 160 , RNA sequencing data 161 , methylation 162 , prediction of protein structure and proteinprotein interactions 163 , the microbiome 164 , and single cells  165  . While these reports have generally represented a single -omics approach, there are now multi-omic algorithms being developed 166,167 that integrate the datasets. The use of genome editing has also been facilitated by algorithmic prediction of CRISPR guide RNA activity 168 and off-target activities  169  .\n\nNoteworthy is the use of AI tools to enhance understanding of how cancer evolves via application of a transfer-learning algorithm to multiregional tumor-sequencing data 170 and of machine vision for analysis of live cancer cells at single-cell resolution via microfluidic isolation 171 . Both of these novel approaches may ultimately be helpful in both risk stratification of patients and guiding therapy.\n\nWith the AI descriptor of neural networks, it is not surprising that there is bidirectional inspiration: biological neuroscience impacting AI and vice versa 172 . A couple of examples in Drosophila are noteworthy. Robie et al. 173  took videos of 400,00 flies and used machine learning and machine vision to map phenotype with gene expression and neuroanatomy. Whole-brain maps were generated for movement, female aggression, and many other traits. In another study, nearest-neighbor analysis was used to understand how odors are sensed by the flies, that is, their smell algorithm  174  .\n\nAI has been used to reconstruct neural circuits, allowing an understanding of connectomics, from electron microscopy 175 . One of the most impressive advances facilitated by AI has been in understanding the human brain's grid cells-which enable perception of the speed and direction of movement of the body, i.e., its place in space  176, 177  . Reciprocally, neuromorphic computing, or reverse-engineering of the brain to make computer chips, is not only leading to more efficient computing, but also helping Review ARticle | FOCUS  https://doi.org/10.1038/s41591-018-0300-7\n\nReview\n\nresearchers understand brain circuitry and build brain-machine interfaces  172, 178, 179  . Machine vision tracking of human and animal behavior with a transfer-learning algorithm is yet another example of the progress being made 180 . Drug discovery is being revamped with the use of AI at many levels, including sophisticated natural language processing searches of the biomedical literature, data mining of millions of molecular structures, designing and making new molecules, predicting offtarget effects and toxicity, predicting the right dose for experimental drugs, and developing cellular assays at a massive scale  [181] [182] [183] [184]  . There is new hope that preclinical animal testing can be reduced via machine-learning prediction of toxicity 185 . AI cryptography has been used to combine large proprietary pharmaceutical company datasets and discover previously unidentified drug interactions 186 . The story of the University of Cambridge and Manchester's robot 'Eve' and how it autonomously discovered an antimalarial drug that is a constituent of toothpaste has galvanized interest in using AI to accelerate the process, with a long list of start-ups and partnerships with major pharmaceutical firms  181, 187, 188  ."
    },
    {
      "title": "Limitations and challenges",
      "text": "Despite all the promises of AI technology, there are formidable obstacles and pitfalls. The state of AI hype has far exceeded the state of AI science, especially when it pertains to validation and readiness for implementation in patient care. A recent example is IBM Watson Health's cancer AI algorithm (known as Watson for Oncology). Used by hundreds of hospitals around the world for recommending treatments for patients with cancer, the algorithm was based on a small number of synthetic, nonreal cases with very limited input (real data) of oncologists 189 . Many of the actual output recommendations for treatment were shown to be erroneous, such as suggesting the use of bevacizumab in a patient with severe bleeding, which represents an explicit contraindication and 'black box' warning for the drug 189 . This example also highlights the potential for major harm to patients, and thus for medical malpractice, by a flawed algorithm. Instead of a single doctor's mistake hurting a patient, the potential for a machine algorithm inducing iatrogenic risk is vast. This is all the more reason that systematic debugging, audit, extensive simulation, and validation, along with prospective scrutiny, are required when an AI algorithm is unleashed in clinical practice. It also underscores the need to require more evidence and robust validation to exceed the recent downgrading of FDA regulatory requirements for medical algorithm approval  190  .\n\nThere has been much written about the black box of algorithms, and much controversy surrounding this topic  [191] [192] [193]  ; especially in the case of DNNs, it may not be possible to understand the determination of output. This opaqueness has led to both demands for explainability, such as the European Union's General Data Protection Regulation requirement for transparency-deconvolution of an algorithm's black box-before an algorithm can be used for patient care 194 . While this debate of whether it is acceptable to use nontransparent algorithms for patient care is unsettled, it is notable that many aspects of the practice of medicine are unexplained, such as prescription of a drug without a known mechanism of action.\n\nInequities are one of the most important problems in healthcare today, especially in the United States, which does not provide care for all of its citizens. With the knowledge that low socioeconomic status is a major risk factor for premature mortality 195 , the disproportionate use of AI in the 'haves, ' as opposed to the 'have-nots, ' could widen the present gap in health outcomes. Intertwined with this concern of exacerbating pre-existing inequities is embedded bias present in many algorithms due to lack of inclusion of minorities in datasets. Examples are the algorithms in dermatology that diagnose melanoma but lack inclusion of skin color  47  and the use\n\n0 No automation The absence of any assistive features such as adaptive cruise control. 1 Driver assistance Systems that help drivers maintain speed or stay in lane but leave the driver in control. 2 Partial automation The combination of automatic speed and steering control-for example, cruise control and lane keeping. Human driver monitors environment Humans and machine doctors 3 Conditional automation Automated systems that drive and monitor the environment but rely on a human driver for backup. 4 High automation Automated systems that do everythingno human backup required-but only in limited circumstances. 5 Full automation The true electronic chauffeur: retains full vehicle control, needs no human backup, and drives in all conditions. System monitors environment 0 1 2 3 4 5 Now Unlikely FOCUS | Review ARticle  https://doi.org/10.1038/s41591-018-0300-7\n\nof the corpus of genomic data, which so far has seriously underrepresented minorities 196 . While there are arguments that algorithm bias is exceeded by human bias 197 , much work is needed to eradicate embedded prejudice and strive for medical research that provides a true representative cross-section of the population.\n\nAn overriding issue for the future of AI in medicine rests with how well privacy and security of data can be assured. Given the pervasive problems of hacking and data breaches, there will be little interest in use of algorithms that risk revealing the details of patient medical history 198 . Moreover, there is the risk of deliberate hacking of an algorithm to harm people at a large scale, such as overdosing insulin in diabetics or stimulating defibrillators to fire inside the chests of patients with heart disease. It is increasingly possible for an individual's identity to be determined by facial recognition or genomic sequence from massive databases, which further impedes protection of privacy. At the same time, the blurring of truth made possible by generative adversarial networks, with seemingly unlimited capacity to manipulate content, could be highly detrimental for health  198, 199  . New models of health data ownership with rights to the individual, use of highly secure data platforms, and governmental legislation, as has been achieved in Estonia, are needed to counter the looming security issues that will otherwise hold up or ruin the chances for progress in AI for medicine  [200] [201] [202]  ."
    },
    {
      "title": "Future considerations",
      "text": "A key point that I have emphasized throughout this Review it that the narrative of bringing AI to medicine is just beginning. There has been remarkably little prospective validation for tasks that machines could perform to help clinicians or predict clinical outcomes that would be useful for health systems, and even less for patient-centered algorithms. The field is certainly high on promise and relatively low on data and proof. The risk of faulty algorithms is exponentially higher than that of a single doctor-patient interaction, yet the reward for reducing errors, inefficiencies, and cost is substantial. Accordingly, there cannot be exceptionalism for AI in medicine-it requires rigorous studies, publication of the results in peer-reviewed journals, and clinical validation in a real-world environment, before roll-out and implementation in patient care (Fig.  4 ). With these caveats, it is also important to have reasonable expectations for how AI will ultimately be incorporated. Piercing through today's widespread hype that doctors will be replaced by machines is the analogy of the self-driving car model for reality testing. Most would agree that autonomous cars represent the pinnacle technical achievement of AI to date, but the term autonomous is misleading. The Society of Automotive Engineers (SAE) has defined five levels of autonomy, with Level 5 indicating full control by the car under all conditions, without any possibility for human backup or taking control of the vehicle (Fig.  5 ). It is now accepted that this definition of full autonomy is likely to never be attained, as certain ambient or road conditions will prohibit the safe use of such vehicles  203  . By the same token, medicine will unlikely ever surpass Level 3, a conditional automation, for which humans will indeed be required for oversight of algorithmic interpretation of images and data. It is hard to imagine very limited human backup across the board of caring for patients (Level 4). Human health is too precious-relegating it to machines, except for routine matters with minimal risk, seems especially far-fetched.\n\nThe excitement that lies ahead, albeit much further along than many have forecasted, is for software that will ingest and meaningfully process massive sets of data quickly, accurately, and inexpensively and for machines that will see and do things that are not humanly possible. This capability will ultimately lay the foundation for high-performance medicine, which is truly data-driven, decompressing our reliance on human resources, and will eventually take us well beyond the sum of the parts of human and machine intelligence. This symbiosis will be preceded by the upstream advances that are already being made in biomedical science and discovery, which have a far less tortuous path to be accepted and widely implemented."
    },
    {
      "text": "Fig. 2 | Examples of Ai applications across the human lifespan. dx, diagnosis; IVF, in vitro fertilization K + , potassium blood level. Credit: Debbie Maizels/ Springer Nature"
    },
    {
      "text": "Fig. 3 | The virtual medical coach model with multi-modal data inputs and algorithms to provide individualized guidance. A virtual medical coach that uses comprehensive input from an individual that is deep learned to provide recommendations for preserving the person's health. Credit: Debbie Maizels/ Springer Nature"
    },
    {
      "text": "Fig. 4 | call for due process of Ai studies in medicine. The need to publish results in peer-reviewed journals with validation in real-world medicine must be addressed before implementation in patient care can take place. Credit: Debbie Maizels/Springer Nature"
    },
    {
      "text": "Fig. 5 | The analogy between self-driving cars and medicine. Level 5, full automation with no potential for human backup of clinicians, is not the objective.Nor is Level 4, with human backup in very limited conditions. The goal is for synergy, offsetting functions that machines do best combined with those that are best suited for clinicians. Credit: Debbie Maizels/Springer Nature"
    }
  ],
  "references": [
    {
      "title": "Child mortality in the US and 19 OECD comparator nations: a 50-year time-trend analysis",
      "authors": [
        "A Thakrar"
      ],
      "year": 2018,
      "doi": "10.1377/hlthaff.2017.0767"
    },
    {
      "title": "Link between health spending and life expectancy: US is an outlier",
      "authors": [
        "M Roser"
      ],
      "year": 2017,
      "doi": "10.1787/888932804339"
    },
    {
      "title": "The frequency of diagnostic errors in outpatient care: estimations from three large observational studies involving US adult populations",
      "authors": [
        "H Singh"
      ],
      "year": 2014
    },
    {
      "title": "Eliminating waste in US health care",
      "authors": [
        "D Berwick",
        "A Hackbarth"
      ],
      "year": 2012
    },
    {
      "title": "ChestX-ray8: hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases",
      "authors": [
        "X Wang"
      ],
      "year": 2017
    },
    {
      "title": "Thoracic disease identification and localization with limited supervision",
      "authors": [
        "Z Li"
      ],
      "year": 2017
    },
    {
      "title": "Deep learning in chest radiography: detection of findings and presence of change",
      "authors": [
        "R Singh"
      ],
      "year": 2018,
      "doi": "10.1371/journal.pone.0204155"
    },
    {
      "title": "Development and validation of deep learning-based automatic detection algorithm for malignant pulmonary nodules on chest radiographs",
      "authors": [
        "J Nam"
      ],
      "year": 2018,
      "doi": "10.1148/radiol.2018180237"
    },
    {
      "title": "Deep neural network improves fracture detection by clinicians",
      "authors": [
        "R Lindsey"
      ],
      "year": 2018
    },
    {
      "title": "Detecting hip fractures with radiologist-level performance using deep neural networks",
      "authors": [
        "W Gale"
      ],
      "year": 2017
    },
    {
      "title": "MURA dataset: towards radiologist-level abnormality detection in musculoskeletal radiographs",
      "authors": [
        "P Rajpurkar"
      ],
      "year": 2017
    },
    {
      "title": "Deep learning shows promise for bone age assessment",
      "authors": [
        "E Ridley"
      ],
      "year": 2017
    },
    {
      "title": "Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks",
      "authors": [
        "P Lakhani",
        "B Sundaram"
      ],
      "year": 2017
    },
    {
      "title": "Compression fractures detection on CT",
      "authors": [
        "A Bar"
      ],
      "year": 2017,
      "doi": "10.1117/12.2249635"
    },
    {
      "title": "Deep-learning algorithm can stratify lung nodule risk",
      "authors": [
        "E Ridley"
      ],
      "year": 2017
    },
    {
      "title": "Deep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced CT: a preliminary study",
      "authors": [
        "K Yasaka"
      ],
      "year": 2018
    },
    {
      "title": "Joint shape representation and classification for detecting PDAC in abdominal CT scans",
      "authors": [
        "F Liu"
      ],
      "year": 2018
    },
    {
      "title": "Fully-convolutional deep-learning based system for coronary calcium score prediction from non-contrast chest CT",
      "authors": [
        "R Shadmi"
      ],
      "year": 2018,
      "doi": "10.1109/isbi.2018.8363515"
    },
    {
      "title": "Advanced machine learning in action: identification of intracranial hemorrhage on computed tomography scans of the head with clinical workflow integration",
      "authors": [
        "M Arbabshirani"
      ],
      "year": 2018
    },
    {
      "title": "Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study",
      "authors": [
        "S Chilamkurthy"
      ],
      "year": 2018,
      "doi": "10.1016/s0140-6736(18)31645-3"
    },
    {
      "title": "Development and validation of deep learning algorithms for detection of critical findings in head CT ccans",
      "authors": [
        "S Chilamkurthy"
      ],
      "year": 2018
    },
    {
      "title": "FastVentricle: cardiac segmentation with ENet",
      "authors": [
        "J Lieman-Sifry"
      ],
      "year": 2017
    },
    {
      "title": "Fast and accurate view classification of echocardiograms using deep learning",
      "authors": [
        "A Madani"
      ],
      "year": 2018,
      "doi": "10.1038/s41746-017-0013-1"
    },
    {
      "title": "Fully automated echocardiogram interpretation in clinical practice feasibility and diagnostic accuracy",
      "authors": [
        "J Zhang"
      ],
      "year": 2018
    },
    {
      "title": "AI algorithm matches radiologists in breast screening exams",
      "authors": [
        "K Yee"
      ],
      "year": 2017,
      "doi": "10.1038/s41591-018-0300-7"
    },
    {
      "title": "Mammographic breast density assessment using deep learning: clinical implementation",
      "authors": [
        "C Lehman"
      ],
      "year": 2018,
      "doi": "10.1148/radiol.2018180694"
    },
    {
      "title": "Automated deep-neural-network surveillance of cranial images for acute neurologic events",
      "authors": [
        "J Titano"
      ],
      "year": 2018,
      "doi": "10.1038/s41591-018-0147-y"
    },
    {
      "title": "The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets",
      "authors": [
        "T Saito",
        "M Rehmsmeier"
      ],
      "year": 2015,
      "doi": "10.1371/journal.pone.0118432"
    },
    {
      "title": "AUC: a misleading measure of the performance of predictive distribution models",
      "authors": [
        "J Lobo"
      ],
      "year": 2007,
      "doi": "10.1111/j.1466-8238.2007.00358.x"
    },
    {
      "title": "With an eye to AI and autonomous diagnosis",
      "authors": [
        "P Keane",
        "E Topol"
      ],
      "year": 2018,
      "doi": "10.1038/s41746-018-0048-y"
    },
    {
      "title": "Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices",
      "authors": [
        "M Abramoff"
      ],
      "year": 2018,
      "doi": "10.1038/s41746-018-0040-6"
    },
    {
      "title": "Evaluation of artificial intelligence-based grading of diabetic retinopathy in primary care",
      "authors": [
        "Y Kanagasingam"
      ],
      "year": 2018,
      "doi": "10.1001/jamanetworkopen.2018.2665"
    },
    {
      "title": "Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning",
      "authors": [
        "N Coudray"
      ],
      "year": 2018,
      "doi": "10.1038/s41591-018-0177-5"
    },
    {
      "title": "Artificial intelligence-based breast cancer nodal metastasis detection",
      "authors": [
        "Y Liu"
      ],
      "year": 2018,
      "doi": "10.5858/arpa.2018-0147-oa"
    },
    {
      "title": "Impact of Deep Learning Assistance on the Histopathologic Review of Lymph Nodes for Metastatic Breast Cancer",
      "authors": [
        "D Steiner"
      ],
      "year": 2018
    },
    {
      "title": "Real-time use of artificial intelligence in identification of diminutive polyps during colonoscopy",
      "authors": [
        "Y Mori"
      ],
      "year": 2018,
      "doi": "10.7326/m18-0249"
    },
    {
      "title": "Development and validation of a deep-learning algorithm for the detection of polyps during colonoscopy",
      "authors": [
        "P Wang"
      ],
      "year": 2018,
      "doi": "10.1038/s41551-018-0301-3"
    },
    {
      "title": "An artificial intelligence platform for the multihospital collaborative management of congenital cataracts",
      "authors": [
        "E Long"
      ],
      "year": 2017
    },
    {
      "title": "Not just digital pathology, intelligent digital pathology",
      "authors": [
        "B Acs",
        "D Rimm"
      ],
      "year": 2018
    },
    {
      "title": "Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features",
      "authors": [
        "K Yu"
      ],
      "year": 2016
    },
    {
      "title": "Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer",
      "authors": [
        "B Ehteshami Bejnordi"
      ],
      "year": 2017
    },
    {
      "title": "Deep learning algorithms for detection of lymph node metastases from breast cancer: helping artificial intelligence be seen",
      "authors": [
        "J Golden"
      ],
      "year": 2017
    },
    {
      "title": "Accurate and reproducible invasive breast cancer detection in whole-slide images: a deep learning approach for quantifying tumor extent",
      "authors": [
        "A Cruz-Roa"
      ],
      "year": 2017
    },
    {
      "title": "Machine learning classifies cancer",
      "authors": [
        "D Wong",
        "S Yip"
      ],
      "year": 2018,
      "doi": "10.1038/d41586-018-02881-7"
    },
    {
      "title": "DNA methylation-based classification of central nervous system tumours",
      "authors": [
        "D Capper"
      ],
      "year": 2018
    },
    {
      "title": "Assessing microscope image focus quality with deep learning",
      "authors": [
        "S Yang"
      ],
      "year": 2018,
      "doi": "10.1186/s12859-018-2087-4"
    },
    {
      "title": "Dermatologist-level classification of skin cancer with deep neural networks",
      "authors": [
        "A Esteva"
      ],
      "year": 2017,
      "doi": "10.1038/nature21056"
    },
    {
      "title": "Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists",
      "authors": [
        "H Haenssle"
      ],
      "year": 2018
    },
    {
      "title": "Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm",
      "authors": [
        "S Han"
      ],
      "year": 2018,
      "doi": "10.1016/j.jid.2018.01.028"
    },
    {
      "title": "Artificial intelligence with deep learning technology looks into diabetic retinopathy screening",
      "authors": [
        "T Wong",
        "N Bressler"
      ],
      "year": 2016
    },
    {
      "title": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs",
      "authors": [
        "V Gulshan"
      ],
      "year": 2016,
      "doi": "10.1001/jama.2016.17216"
    },
    {
      "title": "Automated grading of age-related macular degeneration from color fundus images using deep convolutional neural networks",
      "authors": [
        "P Burlina"
      ],
      "year": 2017,
      "doi": "10.1001/jamaophthalmol.2017.3782"
    },
    {
      "title": "Identifying medical diagnoses and treatable diseases by image-based deep learning",
      "authors": [
        "D Kermany"
      ],
      "year": 2018
    },
    {
      "title": "AI for medical imaging goes deep",
      "authors": [
        "D Ting"
      ],
      "year": 2018
    },
    {
      "title": "Learning from everyday images enables expert-like diagnosis of retinal diseases",
      "authors": [
        "L Rampasek",
        "A Goldenberg"
      ],
      "year": 2018,
      "doi": "10.1016/j.cell.2018.02.013"
    },
    {
      "title": "Clinically applicable deep learning for diagnosis and referral in retinal disease",
      "authors": [
        "J De Fauw"
      ],
      "year": 2018,
      "doi": "10.1038/s41591-018-0107-6"
    },
    {
      "title": "Association of retinal neurodegeneration on optical coherence tomography with dementia: a population-based study",
      "authors": [
        "U Mutlu"
      ],
      "year": 2018
    },
    {
      "title": "Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning",
      "authors": [
        "R Poplin"
      ],
      "year": 2018
    },
    {
      "title": "All eyes are on AI",
      "year": 2018
    },
    {
      "title": "Automated diagnosis of plus disease in retinopathy of prematurity using deep convolutional neural networks",
      "authors": [
        "J Brown"
      ],
      "year": 2018
    },
    {
      "title": "The diagnostic performance of computer programs for the interpretation of electrocardiograms",
      "authors": [
        "J Willems"
      ],
      "year": 1991
    },
    {
      "title": "Detecting and interpreting myocardial infarctions using fully convolutional neural networks",
      "authors": [
        "N Strodthoff",
        "C Strodthoff"
      ],
      "year": 2018
    },
    {
      "title": "Cardiologist-level arrhythmia detection with convolutional neural networks",
      "authors": [
        "P Rajpurkar"
      ],
      "year": 2017
    },
    {
      "title": "Making colonoscopy smarter with standardized computer-aided diagnosis",
      "authors": [
        "\u00d8 Holme",
        "L Aabakken"
      ],
      "year": 2018
    },
    {
      "title": "FDA approves stroke-detecting AI software",
      "authors": [
        "J Petrone"
      ],
      "year": 2018
    },
    {
      "title": "AI could make detecting autism easier",
      "authors": [
        "J Hsu",
        "Spectrum"
      ],
      "year": 2018
    },
    {
      "title": "Explainable machine-learning predictions for the prevention of hypoxaemia during surgery",
      "authors": [
        "S Lundberg"
      ],
      "year": 2018
    },
    {
      "title": "Having a heart attack? This AI helps emergency dispatchers find out",
      "authors": [
        "A Peters"
      ],
      "year": 2018
    },
    {
      "title": "Enhancing next-generation sequencing-guided cancer care through cognitive computing",
      "authors": [
        "N Patel"
      ],
      "year": 2018
    },
    {
      "title": "Will Al replace fertility doctors? Why computers are the only ones that can end the agony of failed IVF cycles, miscarriages, and risky multiple birth",
      "authors": [
        "M De Graaf"
      ],
      "year": 2018
    },
    {
      "title": "DeepGestalt-identifying rare genetic syndromes using deep learning",
      "authors": [
        "Y Gurovich"
      ],
      "year": 2017
    },
    {
      "title": "High-risk breast lesions: a machine learning model to predict pathologic upgrade and reduce unnecessary surgical excision",
      "authors": [
        "M Bahl"
      ],
      "year": 2018
    },
    {
      "title": "The digital scribe",
      "authors": [
        "E Coiera"
      ],
      "year": 2018
    },
    {
      "title": "The burden of depression",
      "year": 2014
    },
    {
      "title": "DeepMood: modeling mobile phone typing dynamics for mood detection",
      "authors": [
        "B Cao"
      ],
      "year": 2018
    },
    {
      "title": "A solution-focused research approach to achieve an implementable revolution in digital mental health",
      "authors": [
        "D Mohr"
      ],
      "year": 2018
    },
    {
      "title": "How artificial intelligence could help diagnose mental disorders",
      "authors": [
        "J Frankel"
      ],
      "year": 2016
    },
    {
      "title": "Digitising the mind",
      "authors": [
        "P Barrett"
      ],
      "year": 2017
    },
    {
      "title": "The efficacy of smartphone-based mental health interventions for depressive symptoms: a meta-analysis of randomized controlled trials",
      "authors": [
        "J Firth"
      ],
      "year": 2017
    },
    {
      "title": "Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial",
      "authors": [
        "K Fitzpatrick"
      ],
      "year": 2017
    },
    {
      "title": "Facebook language predicts depression in medical records",
      "authors": [
        "J Eichstaedt"
      ],
      "year": 2018
    },
    {
      "title": "Cross-trial prediction of treatment outcome in depression: a machine learning approach",
      "authors": [
        "A Chekroud"
      ],
      "year": 2016
    },
    {
      "title": "Evaluating the diagnostic utility of applying a machine learning algorithm to diffusion tensor MRI measures in individuals with major depressive disorder",
      "authors": [
        "D Schnyer"
      ],
      "year": 2017
    },
    {
      "title": "Instagram photos reveal predictive markers of depression",
      "authors": [
        "A Reece",
        "C Danforth"
      ],
      "year": 2017
    },
    {
      "title": "Imaging biomarkers and biotypes for depression",
      "authors": [
        "T Wager",
        "C Woo"
      ],
      "year": 2017
    },
    {
      "title": "Predicting risk of suicide attempts over time through machine learning",
      "authors": [
        "C Walsh"
      ],
      "year": 2017,
      "doi": "10.1177/2167702617691560"
    },
    {
      "title": "Risk factors for suicidal thoughts and behaviors: a meta-analysis of 50 years of research",
      "authors": [
        "J Franklin"
      ],
      "year": 2017
    },
    {
      "title": "Machine learning of neural representations of suicide and emotion concepts identifies suicidal youth",
      "authors": [
        "M Just"
      ],
      "year": 2017
    },
    {
      "title": "Use of machine learning to determine deviance in neuroanatomical maturity associated with future psychosis in youths at clinically high risk",
      "authors": [
        "Y Chung"
      ],
      "year": 2018
    },
    {
      "title": "Clinical assistant diagnosis for electronic medical record based on convolutional neural network",
      "authors": [
        "Z Yang"
      ],
      "year": 2018
    },
    {
      "title": "Improving palliative care with deep learning",
      "authors": [
        "A Avati"
      ],
      "year": 2017
    },
    {
      "title": "Unsupervised machine learning to identify high likelihood of dementia in population-based surveys: development and validation study",
      "authors": [
        "L Cleret De Langavant"
      ],
      "year": 2018
    },
    {
      "title": "A generalizable, data-driven approach to predict daily risk of Clostridium difficile infection at two large academic health centers",
      "authors": [
        "J Oh"
      ],
      "year": 2018
    },
    {
      "title": "AI can predict when we'll die-here's why that's a good thing",
      "authors": [
        "J Bennington-Castro"
      ],
      "year": 2018
    },
    {
      "title": "Development and application of a machine learning approach to assess short-term mortality risk among patients with cancer starting chemotherapy",
      "authors": [
        "A Elfiky"
      ],
      "year": 2018
    },
    {
      "title": "Scalable and accurate deep learning with electronic health records",
      "authors": [
        "A Rajkomar"
      ],
      "year": 2018
    },
    {
      "title": "Deep patient: an unsupervised representation to predict the future of patients from the electronic health records",
      "authors": [
        "R Miotto"
      ],
      "year": 2016
    },
    {
      "title": "Identifying incipient dementia individuals using machine learning and amyloid imaging",
      "authors": [
        "S Mathotaarachchi"
      ],
      "year": 2017
    },
    {
      "title": "Development and validation of an electronic health record-based machine learning model to estimate delirium risk in newly hospitalized patients without known cognitive impairment",
      "authors": [
        "J Yoon"
      ],
      "year": 2018
    },
    {
      "title": "Prognostication and risk factors for cystic fibrosis via automated machine learning",
      "authors": [
        "A Alaa",
        "M Van Der Schaar"
      ],
      "year": 2018
    },
    {
      "title": "Creating an automated trigger for sepsis clinical decision support at emergency department triage using machine learning",
      "authors": [
        "S Horng"
      ],
      "year": 2017
    },
    {
      "title": "A targeted real-time early warning score (TREWScore) for septic shock",
      "authors": [
        "K Henry"
      ],
      "year": 2015
    },
    {
      "title": "Multi-task prediction of disease onsets from longitudinal lab tests",
      "authors": [
        "N Razavian"
      ],
      "year": 2016
    },
    {
      "title": "Predictive modeling of hospital readmission rates using electronic medical record-wide machine learning: a case-study using Mount Sinai Heart Failure Cohort",
      "authors": [
        "K Shameer"
      ],
      "year": 2017
    },
    {
      "title": "Modeling and prediction of clinical symptom trajectories in Alzheimer's disease using longitudinal data",
      "authors": [
        "N Bhagwat"
      ],
      "year": 2018
    },
    {
      "title": "The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care",
      "authors": [
        "M Komorowski"
      ],
      "year": 2018
    },
    {
      "title": "AI is transforming medical diagnosis, prosthetics, and vision aids",
      "authors": [
        "D Zaidi"
      ]
    },
    {
      "title": "Deep biomarkers of human aging: application of deep neural networks to biomarker development",
      "authors": [
        "E Putin"
      ],
      "year": 2016
    },
    {
      "title": "Predicting age by mining electronic medical records with deep learning characterizes differences between chronological and physiological age",
      "authors": [
        "Z Wang"
      ],
      "year": 2017
    },
    {
      "title": "DNA methylation-based biomarkers and the epigenetic clock theory of ageing",
      "authors": [
        "S Horvath",
        "K Raj"
      ],
      "year": 2018
    },
    {
      "title": "Machine Learning for Prediction in Electronic Health Data",
      "authors": [
        "S Rose"
      ],
      "year": 2018
    },
    {
      "title": "Towards vision-based smart hospitals: a system for tracking and monitoring hand hygiene compliance",
      "authors": [
        "A Haque"
      ],
      "year": 2017
    },
    {
      "title": "Clinical intervention prediction and understanding with deep neural networks",
      "authors": [
        "H Suresh"
      ],
      "year": 2017
    },
    {
      "title": "Human fall detection on embedded platform using depth maps and wireless accelerometer",
      "authors": [
        "B Kwolek",
        "M Kepski"
      ],
      "year": 2014
    },
    {
      "title": "A reinforcement learning approach to weaning of mechanical ventilation in intensive care units",
      "authors": [
        "N Prasad"
      ],
      "year": 2018
    },
    {
      "title": "Surgical data science for next-generation interventions",
      "authors": [
        "L Maier-Hein"
      ],
      "year": 2017
    },
    {
      "title": "Automated performance metrics and machine learning algorithms to measure surgeon performance and anticipate clinical outcomes in robotic surgery",
      "authors": [
        "A Hung"
      ],
      "year": 2018
    },
    {
      "title": "Robotic surgery for the eye",
      "authors": [
        "P Gehlbach"
      ],
      "year": 2018
    },
    {
      "title": "Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy",
      "authors": [
        "S Nikolov"
      ],
      "year": 2018
    },
    {
      "title": "Image reconstruction by domain-transform manifold learning",
      "authors": [
        "B Zhu"
      ],
      "year": 2018
    },
    {
      "title": "Can AI enable a 10 minute MRI?",
      "authors": [
        "H Harvey"
      ]
    },
    {
      "title": "Artificial intelligence guides lower PET tracer dose",
      "authors": [
        "E Ridley"
      ],
      "year": 2018
    },
    {
      "title": "Translating artificial intelligence into clinical care",
      "authors": [
        "A Beam",
        "I Kohane"
      ],
      "year": 2016
    },
    {
      "title": "Reengineering aircraft structural life prediction using a digital twin",
      "authors": [
        "E Tuegel"
      ],
      "year": 2011
    },
    {
      "title": "Monitoring the health of jet engines and people",
      "authors": [
        "L Tarassenko",
        "E Topol"
      ],
      "doi": "10.1001/jama.2018.16558"
    },
    {
      "title": "FDA clears AliveCor's Kardiaband as the first medical device accessory for the Apple Watch",
      "authors": [
        "S Buhr"
      ],
      "year": 2017
    },
    {
      "title": "That new apple watch EKG feature? There are more downs than ups",
      "authors": [
        "A Carroll"
      ],
      "year": 2018
    },
    {
      "title": "Onduo delivers diabetes clinic and coaching to your smartphone",
      "authors": [
        "B Levine",
        "A Brown"
      ],
      "year": 2018
    },
    {
      "title": "A hybrid recommender system for patient-doctor matchmaking in primary care",
      "authors": [
        "Q Han"
      ],
      "year": 2018
    },
    {
      "title": "Taking it personally: personalized utilization of the human microbiome in health and disease",
      "authors": [
        "N Zmora"
      ],
      "year": 2016
    },
    {
      "title": "Bread affects clinical parameters and induces gut microbiome-associated personal glycemic responses",
      "authors": [
        "T Korem"
      ],
      "year": 2017
    },
    {
      "title": "Personalized nutrition by prediction of glycemic responses",
      "authors": [
        "D Zeevi"
      ],
      "year": 2015
    },
    {
      "title": "Glucotypes reveal new patterns of glucose dysregulation",
      "authors": [
        "H Hall"
      ],
      "year": 2018
    },
    {
      "title": "Glucose patterns during an oral glucose tolerance test and associations with future diabetes, cardiovascular disease and all-cause mortality rate",
      "authors": [
        "D Albers"
      ],
      "year": 2017
    },
    {
      "title": "Hyperglycemia drives intestinal barrier dysfunction and risk for enteric infection",
      "authors": [
        "C Thaiss"
      ],
      "year": 2018
    },
    {
      "title": "Glucose-regulated phosphorylation of TET2 by AMPK reveals a pathway linking diabetes to cancer",
      "authors": [
        "D Wu"
      ],
      "year": 2018
    },
    {
      "title": "Closed-loop insulin delivery for glycemic control in noncritical care",
      "authors": [
        "L Bally"
      ],
      "year": 2018
    },
    {
      "title": "In silico labeling: predicting fluorescent labels in unlabeled images",
      "authors": [
        "E Christiansen"
      ],
      "year": 2018
    },
    {
      "title": "Seeing more: a future of augmented microscopy",
      "authors": [
        "D Sullivan",
        "E Lundberg"
      ],
      "year": 2018
    },
    {
      "title": "Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy",
      "authors": [
        "C Ounkomol"
      ],
      "year": 2018
    },
    {
      "title": "Ghost cytometry",
      "authors": [
        "S Ota"
      ],
      "year": 2018
    },
    {
      "title": "Intelligent image-activated cell sorting",
      "authors": [
        "N Nitta"
      ],
      "year": 2018,
      "doi": "10.1038/s41591-018-0300-7"
    },
    {
      "title": "Content-aware image restoration: pushing the limits of fluorescence microscopy",
      "authors": [
        "M Weigert"
      ],
      "doi": "10.1101/236463"
    },
    {
      "title": "Multiplexed protein maps link subcellular organization to cellular states",
      "authors": [
        "G Gut"
      ],
      "year": 2018
    },
    {
      "title": "Deep learning is combined with massive-scale citizen science to improve large-scale image classification",
      "authors": [
        "D Sullivan"
      ],
      "year": 2018
    },
    {
      "title": "Creating a universal SNP and small indel variant caller with deep neural networks",
      "authors": [
        "R Poplin"
      ],
      "doi": "10.1101/092890"
    },
    {
      "title": "Predicting the clinical impact of human mutation with deep neural networks",
      "authors": [
        "L Sundaram"
      ],
      "year": 2018
    },
    {
      "title": "Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk",
      "authors": [
        "J Zhou"
      ],
      "year": 2018
    },
    {
      "title": "Predicting effects of noncoding variants with deep learning-based sequence model",
      "authors": [
        "J Zhou",
        "O Troyanskaya"
      ],
      "year": 2015
    },
    {
      "title": "Clairvoyante: a multi-task convolutional deep neural network for variant calling in single molecule sequencing",
      "authors": [
        "R Luo"
      ],
      "doi": "10.1101/310458"
    },
    {
      "title": "Machine learning in genomic medicine: a review of computational problems and data sets",
      "authors": [
        "M Leung"
      ],
      "year": 2016
    },
    {
      "title": "A universal SNP and small-indel variant caller using deep neural networks",
      "authors": [
        "R Poplin"
      ],
      "year": 2018
    },
    {
      "title": "Deep generative models of genetic variation capture the effects of mutations",
      "authors": [
        "A Riesselman"
      ],
      "year": 2018
    },
    {
      "title": "A machine learning approach for somatic mutation discovery",
      "authors": [
        "D Wood"
      ],
      "year": 2018,
      "doi": "10.1126/scitranslmed.aar7939"
    },
    {
      "title": "Machine learning identifies interacting genetic variants contributing to breast cancer risk: a case study in Finnish cases and controls",
      "authors": [
        "H Behravan"
      ],
      "year": 2018
    },
    {
      "title": "Using neural networks for reducing the dimensions of single-cell RNA-seq data",
      "authors": [
        "C Lin"
      ],
      "year": 2017
    },
    {
      "title": "DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning",
      "authors": [
        "C Angermueller"
      ],
      "year": 2017
    },
    {
      "title": "End-to-end differentiable learning of protein structure",
      "authors": [
        "M Alquraishi"
      ],
      "doi": "10.1101/265231"
    },
    {
      "title": "Machine learning for tackling microbiota data and infection complications in immunocompromised patients with cancer",
      "authors": [
        "J Espinoza"
      ],
      "doi": "10.1111/joim.12746"
    },
    {
      "title": "Recovering gene interactions from single-cell data using data diffusion",
      "authors": [
        "D Van Dijk"
      ],
      "year": 2018,
      "doi": "10.1016/j.cell.2018.05.061"
    },
    {
      "title": "Machine learning for integrating data in biology and medicine: principles, practice, and opportunities",
      "authors": [
        "M Zitnik"
      ],
      "doi": "10.1111/joim.12746"
    },
    {
      "title": "Next-generation machine learning for biological networks",
      "authors": [
        "D Camacho"
      ],
      "year": 2018
    },
    {
      "title": "Deep learning improves prediction of CRISPR-Cpf1 guide RNA activity",
      "authors": [
        "H Kim"
      ],
      "year": 2018,
      "doi": "10.1038/nbt.4061"
    },
    {
      "title": "Prediction of off-target activities for the end-to-end design of CRISPR guide RNAs",
      "authors": [
        "J Listgarten"
      ],
      "year": 2018
    },
    {
      "title": "Detecting repeated cancer evolution from multi-region tumor sequencing data",
      "authors": [
        "G Caravagna"
      ],
      "year": 2018
    },
    {
      "title": "Live-cell phenotypic-biomarker microfluidic assay for the risk stratification of cancer patients via machine learning",
      "authors": [
        "M Manak"
      ],
      "year": 2018
    },
    {
      "title": "Neuroscience-inspired artificial intelligence",
      "authors": [
        "D Hassabis"
      ],
      "year": 2017
    },
    {
      "title": "Mapping the neural substrates of behavior",
      "authors": [
        "A Robie"
      ],
      "year": 2017
    },
    {
      "title": "A neural algorithm for a fundamental computing problem",
      "authors": [
        "S Dasgupta"
      ],
      "year": 2017,
      "doi": "10.1126/science.aam9868"
    },
    {
      "title": "High-precision automated reconstruction of neurons with flood-filling networks",
      "authors": [
        "M Januszewski"
      ],
      "year": 2018
    },
    {
      "title": "AI mimics brain codes for navigation",
      "authors": [
        "F Savelli",
        "J Knierim"
      ],
      "year": 2018
    },
    {
      "title": "Vector-based navigation using grid-like representations in artificial agents",
      "authors": [
        "A Banino"
      ],
      "year": 2018,
      "doi": "10.1038/s41586-018-0102-6"
    },
    {
      "title": "Two artificial synapses are better than one",
      "authors": [
        "G Adam"
      ],
      "year": 2018
    },
    {
      "title": "Phase-change devices: crystal-clear neuronal computing",
      "authors": [
        "C Wright"
      ],
      "year": 2016
    },
    {
      "title": "DeepLabCut: markerless pose estimation of user-defined body parts with deep learning",
      "authors": [
        "A Mathis"
      ],
      "year": 2018
    },
    {
      "title": "AI-powered drug discovery captures pharma interest",
      "authors": [
        "E Smalley"
      ],
      "year": 2017
    },
    {
      "title": "Automating drug discovery",
      "authors": [
        "G Schneider"
      ],
      "year": 2018
    },
    {
      "title": "Predictable response: finding optimal drugs and doses using artificial intelligence",
      "authors": [
        "S Chakradhar"
      ],
      "year": 2017,
      "doi": "10.1038/nm1117-1244"
    },
    {
      "title": "AI designs organic syntheses",
      "authors": [
        "D Lowe"
      ],
      "year": 2018
    },
    {
      "title": "Machine learning of toxicological big data enables read-across structure activity relationships (RASAR) outperforming animal test reproducibility",
      "authors": [
        "T Luechtefeld"
      ],
      "year": 2018
    },
    {
      "title": "Realizing private and practical pharmacological collaboration",
      "authors": [
        "B Hie"
      ],
      "year": 2018,
      "doi": "10.1126/science.aat4807"
    },
    {
      "title": "IBM's Watson supercomputer recommended 'unsafe and incorrect' cancer treatments, internal documents show",
      "authors": [
        "E Bilsland"
      ],
      "year": 2015
    },
    {
      "title": "Can we open the black box of AI?",
      "authors": [
        "D Castelvecchi"
      ],
      "year": 2016
    },
    {
      "title": "The dark secret at the heart of AI",
      "authors": [
        "W Knight",
        "D Weinberger"
      ],
      "year": 2017
    },
    {
      "title": "be taught to explain itself?",
      "authors": [
        "C Kuang",
        "A Can"
      ],
      "year": 2017
    },
    {
      "title": "Socioeconomic status and the 25 \u00d7 25 risk factors as determinants of premature mortality: a multicohort study and meta-analysis of 1.7 million men and women",
      "authors": [
        "S Stringhini"
      ],
      "year": 2017
    },
    {
      "title": "Cancer scientists have ignored African DNA in the search for cures",
      "authors": [
        "J Wapner"
      ],
      "year": 2018
    },
    {
      "title": "Want less-biased decisions? Use algorithms",
      "authors": [
        "A Miller"
      ]
    },
    {
      "title": "The malicious use of artificial intelligence: forecasting, prevention, and mitigation",
      "authors": [
        "M Brundage"
      ],
      "year": 2018
    },
    {
      "title": "Adversarial attacks against medical deep learning systems",
      "authors": [
        "S Finlayson"
      ],
      "year": 2018
    },
    {
      "title": "The health data conundrum",
      "authors": [
        "K Haun",
        "E Topol"
      ],
      "year": 2017
    },
    {
      "title": "Unpatients-why patients should own their medical data",
      "authors": [
        "L Kish",
        "E Topol"
      ],
      "year": 2015
    },
    {
      "title": "the digital republic",
      "authors": [
        "N Heller",
        "Estonia"
      ],
      "year": 2017
    },
    {
      "title": "The truth about \"self-driving\" cars",
      "authors": [
        "S Shladover"
      ],
      "year": 2016
    },
    {
      "title": "On computable numbers with an application to the Entscheidungsproblem",
      "authors": [
        "A Turing"
      ],
      "year": 1936
    },
    {
      "title": "Computing machinery and intelligence",
      "authors": [
        "A Turing"
      ],
      "year": 1950
    },
    {
      "title": "A logical calculus of the ideas immanent in nervous activity",
      "authors": [
        "W Mcculloch",
        "W Pitts"
      ],
      "year": 1943
    },
    {
      "title": "ImageNet classification with deep convolutional neural networks",
      "authors": [
        "A Krizhevsky"
      ],
      "year": 2012
    },
    {
      "title": "Squeeze-and-excitation networks",
      "authors": [
        "J Hu"
      ],
      "year": 2017,
      "doi": "10.1109/cvpr.2018.00745"
    },
    {
      "title": "ImageNet Large Scale Visual Recognition Challenge",
      "authors": [
        "O Russakovsky"
      ],
      "year": 2014
    },
    {
      "title": "Deep Learning",
      "authors": [
        "I Goodfellow"
      ],
      "year": 2016
    },
    {
      "title": "Artificial intelligence in healthcare",
      "authors": [
        "K.-H Yu"
      ],
      "year": 2018
    },
    {
      "title": "High-resolution mammogram synthesis using progressive generative adversarial networks",
      "authors": [
        "D Korkinof"
      ],
      "year": 2018
    },
    {
      "title": "Generating highly realistic images of skin lesions with GANs",
      "authors": [
        "C Baur"
      ],
      "year": 2018
    },
    {
      "title": "GANs for medical image analysis",
      "authors": [
        "S Kazeminia"
      ],
      "year": 2018
    },
    {
      "title": "VIEWS! Synthetic medical images for machine learning",
      "authors": [
        "H Harvey",
        "Fake"
      ],
      "year": 2018
    },
    {
      "title": "Deep echocardiography: data-efficient supervised and semisupervised deep learning towards automated diagnosis of cardiac disease",
      "authors": [
        "A Madani"
      ],
      "year": 2018
    }
  ],
  "num_references": 207
}
