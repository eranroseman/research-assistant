{
  "paper_id": "YZM8Y99V",
  "title": "VIEWPOINT",
  "abstract": "Big Data and Machine Learning in Health Care Nearly all aspects of modern life are in some way being changed by big data and machine learning. Netflix knows what movies people like to watch and Google knows what people want to know based on their search histories. Indeed, Google has recently begun to replace much of its existing non-machine learning technology with machine learning algorithms, and there is great optimism that these techniques can provide similar improvements across many sectors. Itisnosurprisethenthatmedicineisawashwithclaims of revolution from the application of machine learning to big health care data. Recent examples have demonstrated that big data and machine learning can create algorithms that perform on par with human physicians. 1 Though machine learning and big data may seem mysterious at first, they are in fact deeply related to traditional statistical models that are recognizable to most clinicians. It is our hope that elucidating these connections will demystify these techniques and provide a set of reasonable expectations for the role of machine learning and big data in health care. Machine learning was originally described as a program that learns to perform a task or make a decision automatically from data, rather than having the behavior explicitlyprogrammed.However,thisdefinitionisverybroad and could cover nearly any form of data-driven approach. For instance, consider the Framingham cardiovascular risk score,whichassignspointstovariousfactorsandproduces a number that predicts 10-year cardiovascular risk. Should this be considered an example of machine learning? The answer might obviously seem to be no. Closer inspection oftheFraminghamriskscorerevealsthattheanswermight not be as obvious as it first seems. The score was originally created 2 by fitting a proportional hazards model to data frommorethan5300patients,andsothe\"rule\"wasinfact learnedentirelyfromdata.Designatingariskscoreasamachine learning algorithm might seem a strange notion, but this example reveals the uncertain nature of the original definition of machine learning. It is perhaps more useful to imagine an algorithm as existing along a continuum between fully human-guided vs fully machine-guided data analysis. To understand the degree to which a predictive or diagnostic algorithm can said to be an instance of machine learning requires understanding how much of its structure or parameters were predetermined by humans. The trade-off between human specificationofapredictivealgorithm'spropertiesvslearning those properties from data is what is known as the machine learning spectrum. Returning to the Framingham study, to create the original risk score statisticians and clinical experts worked together to make many important decisions, such as which variables to include in the model, therelationshipbetweenthedependentandindependent variables, and variable transformations and interactions. Since considerable human effort was used to define these properties, it would place low on the machine learning",
  "year": 2016,
  "date": "2016",
  "authors": [
    {
      "name": "Andrew Beam",
      "email": "andrew_beam@hms.harvard.edu",
      "affiliation": {
        "organization": "Department of Biomedical Informatics",
        "department": "Department of Biomedical Informatics",
        "institution": "Harvard Medical School",
        "address": "Boston, Massachusetts"
      }
    },
    {
      "name": "Isaac Kohane",
      "affiliation": {
        "organization": "Department of Biomedical Informatics",
        "department": "Department of Biomedical Informatics",
        "institution": "Harvard Medical School",
        "address": "Boston, Massachusetts"
      }
    }
  ],
  "doi": "10.1001/jama.2017.18391",
  "md5": "90D74F15AC1BB560EE2A824A5A93C7AD",
  "publication": {
    "journal": "JAMA",
    "journal_inferred": true
  },
  "sections": [
    {
      "text": "spectrum (#19 in the Figure and Supplement). Many evidence-based clinical practices are based on a statistical model of this sort, and so many clinical decisions in fact exist on the machine learning spectrum (middle left of Figure ). On the extreme low end of the machine learning spectrum would be heuristics and rules of thumb that do not directly involve the use of any rules or models explicitly derived from data (bottom left of Figure ).\n\nSuppose a new cardiovascular risk score is created that includes possible extensions to the original model. For example, it could be that risk factors should not be added but instead should be multiplied or divided, or perhaps a particularly important risk factor should square the entire score if it is present. Moreover, if it is not known in advance which variables will be important, but thousands of individual measurements have been collected, how should a good model be identified from among the infinite possibilities?\n\nThis is precisely what a machine learning algorithm attempts to do. As humans impose fewer assumptions on the algorithm, it moves further up the machine learning spectrum. However, there is never a specific threshold wherein a model suddenly becomes \"machine learning\"; rather, all of these approaches exist along a continuum, determined by how many human assumptions are placed onto the algorithm.\n\nAn example of an approach high on the machine learning spectrum has recently emerged in the form of so-called deep learning models. Deep learning models are stunningly complex networks of artificial neurons that were designed expressly to create accurate models directly from raw data. Researchers recently demonstrated a deep learning algorithm capable of detecting diabetic retinopathy (#4 in the Figure, top center) from retinal photographs at a sensitivity equal to or greater than that of ophthalmologists.  1  This model learned the diagnosis procedure directly from the raw pixels of the images with no human intervention outside of a team of ophthalmologists who annotated each image with the correct diagnosis. Because they are able to learn the task with little human instruction or prior assumptions, these deep learning algorithms rank very high on the machine learning spectrum (Figure, light blue circles).\n\nThough they require less human guidance, deep learning algorithms for image recognition require enormous amounts of data to capture the full complexity, variety, and nuance inherent to real-world images. Consequently, these algorithms often require hundreds of thousands of examples to extract the salient image features that are correlated with the outcome of interest. Higher placement on the machine learning spectrum does not imply superiority, because different tasks require different levels of human involvement. While algorithms high on the spectrum are often very flexible and can learn many tasks, they are often uninterpretable and function mostly as \"black boxes.\" In contrast, algorithms lower on the spectrum often produce outputs that are easier for humans to understand and interpret. Also, the flexibility offered by the high end of the spectrum requires vast amounts of computational resources must be used to develop and deploy these algorithms.\n\nIt is precisely because there is access to much larger sources of clinical data and faster computers in the last decade that algorithms on the high end of the machine learning spectrum have become practical and useful. Health care data can come from a diverse set of sources, including the electronic health care record (which includes laboratory results, imaging studies, and diagnosis codes), fitness trackers, genetic testing, among many others.  3 At its core, big data represents an opportunity, and this is especially true for applications in health care. Machine learning is one such tool to integrate and make sense of health care data at this scale.\n\nMachine learning is not a magic device that can spin data into gold, though many news releases would imply that it can. Instead, it is a natural extension to traditional statistical approaches. Machine learning is a valuable and increasingly necessary tool for the modern health care system. Considering the vast amounts of information a physician may need to evaluate 3 -such as the patient's personal history, familial diseases, genomic sequences, medications, activity on social media, admissions to other hospitals-deriving insight to guide clinical decision may be an overwhelming task for any one person. As more control is ceded to algorithms, it is important to note that these new algorithmic decision-making tools come with no guarantees of fairness, equitability, or even veracity. Although we are reluctant to repeat the clich\u00e9, even with the best machine learning algorithms the maxim of \"garbage in, garbage out\" remains true. Whether an algorithm is high or low on the machine learning spectrum, best analytic practices must be used to ensure that the end result is robust and valid. This is especially true in health care because these algorithms have the potential to affect the lives of millions of patients. Deep learning Generative adversarial networks (2014) 1 ATM check readers (1998) 3 Facebook Photo Tagger (2015) 7 Google diabetic retinopathy (2016) 4 Google AlphaGo Zero (2017) 2 Google AlphaGo (2015) 6 Prediction of 1-y all-cause mortality (2017) 8 ImageNet computer vision models (2012-2017) 5 Classic machine learning EHR-based CV risk prediction (2017) 10 Amazon product recommendation (2003) 13 Netflix Prize winner (2006) 11 Google Search (1998) 12 Diffuse large B-cell lymphoma outcome prediction by gene-expression profiling (2002) 9 Expert AI systems MYCIN (1975) 14 CASNET (1982) 15 DXplain (1986) 16 Risk calculators CHA 2 DS 2 -VASc Score for atrial fibrillation stroke risk (2017) 17 MELD end-stage liver disease risk score (2001) 18 Framingham CV risk score (1998) 19 Other Clinical wisdom 22 Mortality rate estimates from US Census (2010) 23 Randomized Clinical Trials Celecoxib vs nonsteroidal anti-inflammatory drugs for osteoarthritis and rheumatoid arthritis (2002) 20 Use of estrogen plus progestin in healthy postmenopausal women (2002) 21 1 10 10 2 10 3 10 4 10 5 10 7 10 10 10 6 10 9 10 8 Relative Human-to-Machine Decision-Making Effort Data (Sample) Size, No."
    },
    {
      "text": "Figure. The Axes of Machine Learning and Big Data"
    },
    {
      "text": "Traditional clinical studies analyze data from hundreds or thousands of patients using a carefully designed statistical model and thus are low on the machine learning spectrum. Deep learning models are at the top of the spectrum. At the very top are generative adversarial networks, which can learn to generate new images by examining a large database of existing images. See the Supplement for details including supporting references and expansions of abbreviations."
    }
  ],
  "references": [
    {
      "title": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs",
      "authors": [
        "V Gulshan",
        "L Peng",
        "M Coram"
      ],
      "year": 2016,
      "doi": "10.1001/jama.2016.17216",
      "journal": "JAMA",
      "volume": "316",
      "issue": "22",
      "raw": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs \n\t\t \n\t\t\t V Gulshan \n\t\t \n\t\t \n\t\t\t L Peng \n\t\t \n\t\t \n\t\t\t M Coram \n\t\t \n\t\t 10.1001/jama.2016.17216 \n\t \n\t \n\t\t JAMA \n\t\t \n\t\t\t 316 \n\t\t\t 22 \n\t\t\t \n\t\t\t 2016 \n\t\t \n\t \n\t Gulshan V, Peng L, Coram M, et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA. 2016;316(22):2402-2410."
    },
    {
      "title": "Multivariate prediction of coronary heart disease in the Western Collaborative Group Study compared to the findings of the Framingham study",
      "authors": [
        "R Brand",
        "R Rosenman",
        "R Sholtz"
      ],
      "year": 1976,
      "doi": "10.1161/01.cir.53.2.348",
      "journal": "Circulation",
      "volume": "53",
      "issue": "2",
      "raw": "Multivariate prediction of coronary heart disease in the Western Collaborative Group Study compared to the findings of the Framingham study \n\t\t \n\t\t\t R J Brand \n\t\t \n\t\t \n\t\t\t R H Rosenman \n\t\t \n\t\t \n\t\t\t R I Sholtz \n\t\t \n\t\t 10.1161/01.cir.53.2.348 \n\t \n\t \n\t\t Circulation \n\t\t \n\t\t\t 53 \n\t\t\t 2 \n\t\t\t \n\t\t\t 1976 \n\t\t \n\t \n\t Brand RJ, Rosenman RH, Sholtz RI, et al. Multivariate prediction of coronary heart disease in the Western Collaborative Group Study compared to the findings of the Framingham study. Circulation. 1976;53(2):348-355."
    },
    {
      "title": "Finding the missing link for big biomedical data",
      "authors": [
        "G Weber",
        "K Mandl",
        "I Kohane"
      ],
      "year": 2014,
      "doi": "10.1001/jama.2014.4228",
      "journal": "JAMA",
      "volume": "311",
      "issue": "24",
      "raw": "Finding the missing link for big biomedical data \n\t\t \n\t\t\t G M Weber \n\t\t \n\t\t \n\t\t\t K D Mandl \n\t\t \n\t\t \n\t\t\t I S Kohane \n\t\t \n\t\t 10.1001/jama.2014.4228 \n\t \n\t \n\t\t JAMA \n\t\t \n\t\t\t 311 \n\t\t\t 24 \n\t\t\t \n\t\t\t 2014 \n\t\t \n\t \n\t Weber GM, Mandl KD, Kohane IS. Finding the missing link for big biomedical data. JAMA. 2014;311 (24):2479-2480."
    }
  ],
  "num_references": 3,
  "figures": [
    {
      "caption": "Figure",
      "description": "Figure. The Axes of Machine Learning and Big Data"
    },
    {
      "description": "Traditional clinical studies analyze data from hundreds or thousands of patients using a carefully designed statistical model and thus are low on the machine learning spectrum. Deep learning models are at the top of the spectrum. At the very top are generative adversarial networks, which can learn to generate new images by examining a large database of existing images. See the Supplement for details including supporting references and expansions of abbreviations."
    }
  ],
  "num_figures": 2,
  "num_citations": 2,
  "cited_references": [
    "b0",
    "b2"
  ],
  "notes": [
    "[raw_affiliation] Department of Biomedical Informatics , Harvard Medical School , Boston , Massachusetts.",
    "[raw_affiliation] Department of Biomedical Informatics , Harvard Medical School , Boston , Massachusetts.",
    "[raw_affiliation] Department of Biomedical Informatics , Harvard Medical School , Boston , Massachusetts.",
    "JAMA April 3, 2018 Volume 319, Number 13 (Reprinted) jama.com \u00a9 2018 American Medical Association. All rights reserved. Downloaded from jamanetwork.com by University of Iowa user on 08/16/2025",
    "[raw_reference] Gulshan V, Peng L, Coram M, et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA. 2016;316(22):2402-2410.",
    "[raw_reference] Brand RJ, Rosenman RH, Sholtz RI, et al. Multivariate prediction of coronary heart disease in the Western Collaborative Group Study compared to the findings of the Framingham study. Circulation. 1976;53(2):348-355.",
    "[raw_reference] Weber GM, Mandl KD, Kohane IS. Finding the missing link for big biomedical data. JAMA. 2014;311 (24):2479-2480."
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  }
}
