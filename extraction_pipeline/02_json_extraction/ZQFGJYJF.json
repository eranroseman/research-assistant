{
  "paper_id": "ZQFGJYJF",
  "title": "Ethical evaluation of artificial intelligence applications in radiotherapy using the Four Topics Approach",
  "abstract": "Artificial Intelligence is the capability of a machine to imitate intelligent human behavior. An important impact can be expected from Artificial Intelligence throughout the workflow of radiotherapy (such as automated organ segmentation, treatment planning, prediction of outcome and quality assurance). However, ethical concerns regarding the binding agreement between the patient and the physician have followed the introduction of artificial intelligence. Through the recording of personal and social moral values in addition to the usual demographics and the implementation of these as distinctive inputs to matching algorithms, ethical concerns such as consistency, applicability and relevance can be solved. In the meantime, physicians' awareness of the ethical dimension in their decision-making should be challenged, so that they prioritize treating their patients and not diseases, remain vigilant to preserve patient safety, avoid unintended harm and establish institutional policies on these issues.",
  "year": 2016,
  "date": "2016",
  "journal": "Radiother Oncol",
  "publication": "Radiother Oncol",
  "authors": [
    {
      "forename": "Eda",
      "surname": "Erkal",
      "name": "Eda Erkal",
      "affiliation": "a  Kocaeli University , Faculty of Medicine , Department of Radiation Oncology , Kocaeli , 41380 , Turkey \n\t\t\t\t\t\t\t\t Faculty of Medicine \n\t\t\t\t\t\t\t\t Department of Radiation Oncology \n\t\t\t\t\t\t\t\t Kocaeli University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 41380 \n\t\t\t\t\t\t\t\t\t Kocaeli \n\t\t\t\t\t\t\t\t\t Turkey"
    },
    {
      "forename": "Asl\u0131han",
      "surname": "Akp\u0131nar",
      "name": "Asl\u0131han Akp\u0131nar",
      "affiliation": "b  Kocaeli University , Faculty of Medicine , Department of Medical History and Ethics , Kocaeli , 41380 , Turkey \n\t\t\t\t\t\t\t\t Faculty of Medicine \n\t\t\t\t\t\t\t\t Department of Medical History and Ethics \n\t\t\t\t\t\t\t\t Kocaeli University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 41380 \n\t\t\t\t\t\t\t\t\t Kocaeli \n\t\t\t\t\t\t\t\t\t Turkey"
    },
    {
      "forename": "Haldun",
      "surname": "\u00b8\u00fckr\u00fc Erkal",
      "name": "Haldun \u00b8\u00fckr\u00fc Erkal",
      "affiliation": "c  Sakarya University , Faculty of Medicine , Department of Radiation Oncology , Sakarya , 54100 , Turkey \n\t\t\t\t\t\t\t\t Faculty of Medicine \n\t\t\t\t\t\t\t\t Department of Radiation Oncology \n\t\t\t\t\t\t\t\t Sakarya University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 54100 \n\t\t\t\t\t\t\t\t\t Sakarya \n\t\t\t\t\t\t\t\t\t Turkey"
    },
    {
      "affiliation": "Kocaeli University , Faculty of Medicine , Department of Radiation Oncology , Kocaeli , 41380 , Turkey. \n\t\t\t\t\t\t\t\t Faculty of Medicine \n\t\t\t\t\t\t\t\t Department of Radiation Oncology \n\t\t\t\t\t\t\t\t Kocaeli University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 41380 \n\t\t\t\t\t\t\t\t\t Kocaeli \n\t\t\t\t\t\t\t\t\t Turkey"
    }
  ],
  "doi": "10.1016/j.artmed.2021.102055",
  "sections": [
    {
      "title": "Introduction",
      "text": "Artificial Intelligence (AI) is the capability of a machine to imitate intelligent human behavior  [1] . Before the existence of large data sets, AI systems were programmed to follow the rules of their human inventors. However, advances in technology have evolved AI systems to \"learn\" and \"make decisions\" without being programmed. AI systems pair the series of steps for solving a problem (an algorithm) with a large pool of information (the big data) to construct a model. AI systems are promising in a variety of fields in medicine and can impact the radiotherapy workflow such as automated organ segmentation, treatment planning, prediction of outcome and quality assurance (QA). Radiotherapy-related big data involves prognostic factors defining treatment management, symptom management and treatment outcome. AI systems learn from the new data from the latest patients and aim to quantitatively inform decision-making for optimized treatment planning, delivery and outcome  [2] [3] [4] .\n\nThe binding agreement between the patient and the physician (as stakeholders) is defined using the rules, principles and considerations of ethics  [5] . With the introduction of AI, the stakeholders in this agreement have become less obvious. The possibility of the components (such as hardware, software and data) or the manpower creating AI to take over the place of the physician is concerning, triggering ethics experts to draw clinicians' attention to this area. The areas of ethical concerns include beneficence, do no harm, privacy, informed consent, voluntary participation, confidentiality, fairness, justice, trustworthiness, responsibility and respect  [6] . Due to the complex ethical issues surrounding AI systems, it might be useful to include ethics experts to develop regulatory guidelines to provide solutions for the potential challenges before incorporating these into clinical routine  [7] .\n\nEven though ethical concerns on AI systems in medicine have been evaluated, no attempts have been made to do the ethical analysis of AI systems in radiotherapy. As AI systems become a larger part of the clinical routine in radiotherapy, an ethical discussion is required."
    },
    {
      "title": "Radiotherapy workflow",
      "text": "Radiotherapy workflow includes volumetric imaging, target volume and organ-at-risk (OAR) segmentation, treatment planning, treatment delivery and follow-up. To facilitate processes and augment efficiency, AI systems are involved in automated organ segmentation (defining target volumes and OARs), treatment planning, outcome predictions and QA  [8] [9] [10] [11] . However, challenges such as data heterogeneity, lack of standardization in terminology and issues of (computer or workflow) incompatibility make the implementation of AI systems somewhat difficult  [12] ."
    },
    {
      "title": "Automated organ segmentation",
      "text": "Manual delineation of target volumes and OARs is time-consuming and leads to intra-observer and inter-observer variability  [13] . Auto-segmentation algorithms are the state of the art and are applied to a variety of sites to reduce inter-observer and intra-observer variability. For auto-segmentation tools, the highest level of patient safety can be achieved by proper authorization of segmentation workstations and QA testing  [14] . Auto-segmentation tools differ in performance, especially in patients presenting with anatomical variations that are not accurately represented within the pertinent dataset, resulting in inaccurate, incomplete or unusable information. This requires time-consuming manual post-processing. Therefore, it is important to understand the case limitations of AI tools and restrict their use to validated patient populations."
    },
    {
      "title": "Treatment planning and outcome predictions",
      "text": "The earliest applications of AI systems in radiotherapy focused on predicting treatment-related toxicity and treatment response. develop improved models that can serve as aids for the selection between various radiotherapy options, databases with adequate information on radiotherapy physics parameters should be available  [12, 15, 16] ."
    },
    {
      "title": "Quality assurance",
      "text": "Considering radiotherapy workflow, QA is the last checkpoint for verification of treatments in terms of clinical acceptability and defines the efficiency of the workflow overall. QA is carried out by the radiotherapy physicists and almost all QA steps require their manual input. Due to the increase in the involvement of software and the contribution of AI systems, increasingly more steps in QA are being implemented either through automation (which can be more accurate due to negligent human error) or with the input of radiotherapy technologists (who may lack relevant expertise and qualifications)  [17, 18] ."
    },
    {
      "title": "Ethical evaluation of artificial intelligence applications in radiotherapy using the Four Topics Approach",
      "text": "The importance of ethics from a radiation oncologists' viewpoint was recently highlighted by Tepper  [19] , who notes that the ethical principles described by Beauchamp and Childress  [20]  guide how one should think about patient management, such as establishing the duty of a physician to seek the best interest of the patient, but do not specifically answer the thorny ethical issues. Ethical rules, principles and considerations are used to define the binding agreement between the patient and the physician as competent partners. However, the individual parts of the agreement have become less obvious following the introduction of AI applications as non-humans. Radiation oncologists are challenged by this \"brand-new party\" since it is not only an important part of their clinical routine but also one of the leading causes of unforeseen ethical pitfalls  [21] .\n\nThe language of biomedical theory has been different from that of clinicians and the capability of bioethical theory has been suboptimal in resolving their practical dilemmas. As a result, clinical medical ethics (CME) was established in 1972 at the University of Chicago as a transformative field, aiming to provide excellent clinical and ethical care in ordinary encounters with patients through identifying, analyzing and contributing to the resolution of ethical problems. Unlike biomedical ethics practiced mainly by bioethicists, humanists or social scientists, CME is not a theoretical undertaking but an intrinsic component of decision-making to be practiced by licensed clinicians in real-life terms in every encounter with cases  [22] . CME proposes an alternative method of clinical analysis, The Four Topics Approach. This is closer to the reasoning of clinicians than to the speculation of philosophers  [23] . Mentioned for the first time in the book titled \"Clinical Ethics: A Practical Approach to Ethical Decisions in Clinical Medicine\" by Jonsen, Siegler and Winslade  [24] , The Four Topics Approach attempts to analyze clinical problems based on medical indications (beneficence and non-maleficence), patient preferences (respect for autonomy), quality of life (QoL) (beneficence, non-maleficence and respect for autonomy) and contextual features (justice and fairness). Based on its comprehensive nature, The Four Topics Approach can provide an appropriate framework for the \"non-philosopher\" radiation oncologists on the use of AI systems in their clinical routine."
    },
    {
      "title": "Medical indications (beneficence and non-maleficence)",
      "text": "Medical indications refer to diagnostic, therapeutic and educational interventions and cover the goals of AI applications in radiotherapy, the probabilities of success for the elected radiotherapy options based on AI input and the potential benefits and harms to be gained or avoided through AI applications. The first step in clinical decision-making is to define the problem by its characteristics (acute versus chronic, critical versus reversible or emergent versus terminal). The already distressed patients request professional assistance and guidance from their physicians in making treatment-related decisions. A shared decision-making process is essential for a healthy patient-physician relationship and it reflects the physicians' moral obligations to respect both their patients' autonomy and their fundamental commitment to utilize their knowledge, skills and experience in improving the clinical and ethical patient outcomes  [25] . Humanitarian values and principles might not be adequately addressed by AI, given its \"black box\" nature. If physicians are outpaced by the rapid advances in AI, clinical decision-making will no longer be a holistic and personalized process.\n\nClinical medicine has been described as \"a science of uncertainty and an art of probability.\" The process by which a clinician attempts to make consistently good decisions in the face of uncertainty is called \"clinical judgment.\" The primary task of clinicians is to minimize uncertainty by using clinical evidence and reasoning to arrive at a diagnosis and propose a plan of care  [24] . The use of AI is a promising approach to integrate the overwhelming amount of medical information and patient data into routine care and decision-making  [26] . However, AI can fail to draw causal relationships despite being able to define a large number of correlations between various parameters. Since AI systems that are built on potentially inaccurate, incomplete and prejudiced data can lead to inappropriate assumptions, clinicians heavily reliant on AI systems can easily make clouded judgments as a result of their diminishing professional abilities  [27] .\n\nWith the introduction of AI applications into routine use either as supportive measures or as time-saving alternatives, the clinician's role in supervising these applications is gaining importance. However, supervision is time consuming and might even result in the loss of any time saved. AI developers might consider collaborating with clinical ethicists to improve the functionality of AI algorithms in terms of humanitarian values and principles such as insight, consciousness or empathy, while slowly relieving clinicians of their supervisory role.\n\nThe physicians' skills in using AI applications during shared decision-making processes depends on their educational background as well as experience with these applications. Conflicts might arise in patient-physician agreements and the physicians' professional liabilities if superior outcomes are suggested in favor of the competing AI software options installed elsewhere. The physicians' efforts to offer \"what is available at home\" as opposed to the \"best available elsewhere\" could violate justice and fairness, as well as beneficence and non-maleficence.\n\nIn radiotherapy, decision support mechanisms using AI applications establish a bond between the \"present-day patient\" and the former decisions, providing expert opinions at a reduced cost of labor and results based on former decisions relevant to the subject in question  [28] . AI attempts to forecast radiotherapy results, make assumptions on survival expectancy and make decisions about the radiotherapy technique to be used  [29] [30] [31] . AI applications have also been used to facilitate the selection of radiotherapy doses and radiotherapy machines  [32, 33] . A major problem of AI in supporting (or possibly replacing) physicians for the individualization of patient care is the obscure nature of responsibilities that will be attributed to both parties. The responsibility of the physicians as the ultimate decision makers in the process should never be overlooked."
    },
    {
      "title": "Patient preferences (respect for autonomy)",
      "text": "Showing respect for a person parallels showing respect for her/his autonomy. Since having a preference is an integral part of human nature, the moral rights of an individual to choose and follow a certain plan of life and action should be acknowledged. Patient preferences refer to informed consent, decisional capacity, truth and transparency in medical communication as well as cultural and religious beliefs and assist patients as well as their physicians in treatment-related decision-making processes  [5] .\n\nPatients reach an agreement with their physicians not with an AI system as they seek treatment. Physicians are expected to question patient preferences in the context of their clinical judgment. Although it is common sense that the use of clinical evidence would better inform physicians when planning for their patients' treatments, Boory et al. point out that patient preferences should also be respected since patients, and not only their diseases, are at stake  [34] . The different natures of AI and clinical evidence are a major concern for the physicians who expect a certain, but finite, level of uncertainty  [26] . The increasing perception (owing largely to sponsored media presentations) of AI being superior to the physicians' clinical judgments in terms of accuracy will probably result in a declined level of confidence for the physicians or an exaggerated level of confidence for AI from the patients' perspective. These areas of concern can only be eliminated through patient-physician relationships that are built on mutual trust. During consenting, physicians should inform their patients about their clinical judgment process, the available clinical evidence (or evidence-based medicine) and the reasons for their decision being the \"most appropriate\" based on their clinical expertise. To what extent should physicians inform their patients at the time of consenting on the possible roles of AI in their decision-making process is debatable. A good way to move forward might be to broaden the discussion on both evidence-based medicine (where the clinical decision-making process is based on the results of the most objective and unbiased medical research available to deliver the most satisfactory outcome for the patient) and the use of AI (where the black box nature precludes the insight in the clinical decision-making process).\n\nThere is a lack of input for the preferences made by a mentally capable patient following an adequate procedure of informed consent in the decision-making tree powered by AI. Ethical concerns can arise about automated segmentation tools for organs at risk and atlas-based segmentation tools for target volumes provided by treatment planning systems and powered by AI. As part of the consent, patients should be informed about the possibilities of anatomical variations and their representation in the big data. They should also discuss with their physicians the influence of these variations on their treatment in terms of disease control and side effects.\n\nMoreover, the principle of autonomy should be addressed during consenting and patients should be informed about tasks typically assigned to physicians which are carried out using AI. Overseeing the QA aspect of the radiotherapy workflow from an ethical perspective, the omission of radiation oncologists or replacement of radiotherapy physicists by radiotherapy technologists have a negative effect on the patient-physician and/or patient-health professional relationships in terms of trustworthiness. Furthermore, patient integrity can also be compromised in the absence of accurate, accessible and transparent information on the overall workflow. Therefore, when trying to decide on the \"best\" treatment approach, patients should have an idea about the unexpected results and less than perfect prediction possibilities offered by AI."
    },
    {
      "title": "Quality of life (beneficence, non-maleficence and respect for autonomy)",
      "text": "Defined as a state of satisfaction, QoL expresses a value judgment: the experience of living, as a whole or in some aspect, is judged to be good or bad, better or worse  [24] . The subjective nature of the evaluation of QoL and the inter-observer differences in terms of rating certain forms of living leads to concerns for clinical ethics. There are several predictive models, and AI algorithms, designed to forecast radiotherapy-related toxicities and accordingly guide physicians  [35] [36] [37] [38] . Alternate means of treatment-related toxicity evaluation (objective versus subjective) might result in considerable variations depending on the area to be treated. These variations are explained using differences in terms of sex, race, geography, social and economic status as well as social norms and attitudes  [39] . AI-based models of radiotherapy workflow are designed to assist treatment-related decisions using forecasts of treatment-related toxicity  [32, 40] . Given the variations between objective and subjective treatment-related toxicity evaluations and the subjective nature of QoL evaluations, the emerging problem is the selection of relevant data as input to be used by AI algorithms to forecast a personalized QoL prediction that will formalize treatment plans taking these into account. To overcome this problem, subjective treatment-related toxicity evaluation should be better incorporated into AI algorithms.\n\nThe foremost aim of AI algorithms should be the treatment of patients and not their diseases. Therefore, the algorithms should be able to recognize patients as individuals, observe them in their own personalized ways in a holistic manner and make treatment-related recommendations in accordance with treatment-related toxicity predictions. Due to the absence of patient input in the big data, the treatment-related decision-making process of AI algorithms can be in contradiction with the patients' autonomy."
    },
    {
      "title": "Contextual features (justice and fairness)",
      "text": "Contextual features define cultural, religious and familial issues, investigational and educational factors and institutional conflicts of interests that might contribute to treatment-related decision making  [24] . Most AI models are developed using data from large academic systems representing a predominantly affluent patient population. Inequalities in the treatment of certain types of cancer (less care and increased mortality) have been consistently documented over decades for patients of color, compared to similar white patients  [2] [3] [4] 7] , even after controlling for confounding factors such as comorbidity, health insurance and socioeconomic status  [2, 3, 10, 11] . These possibly result from factors such as implicit bias, mistrust and poor communication  [15, 16] . Therefore, this may introduce bias into systems and may cause them to perform poorly in lower socioeconomic populations. Despite the eradication of the more visible racial barriers, the present effects from \"institutional racism\" are subtle  [24] . Given the disparities in treatment, a multi-faceted approach aiming at transparency and accountability of the supportive clinical data might achieve the highest probability of success through a race-specific audit.\n\nRadiation oncology is a highly technical, device-oriented specialty driven by iterative innovation. Despite valid concerns of employment security and compensation based on the spread of AI technologies, the marketed AI products should be utilized as aids rather than substitutes by clinicians to improve efficiency and reduce workload. Although collaboration with the industry is pivotal for the advancement of radiotherapy, financial ties between physicians and radiotherapy equipment manufacturers might create conflicts of interest. Highly specialized and technologically focused physicians are ideal targets for niche industry marketing  [26] . Despite the expansion of regulations protecting patient welfare from industry influence, conflicts might arise among radiation oncologists while deciding on the optimal software for their clinics from an ever-growing list of alternatives available  [41] . Technical functionality rather than clinical practicability of software components is an important consideration for state-of-the-art radiotherapy. Although technical features and clinical implementations are described by the vendor in detail, the integration into radiotherapy workflow is far from optimal. Therefore, some radiotherapy tools have limited applicability and are difficult to be analyzed in detail by the customer  [42] .\n\nAlthough software development is usually rapid and the upgraded systems are mostly faster and safer, those systems that have not been upgraded might be incompatible with any newly purchased tool. Therefore, since the investment in the periodical upgrades is not always justified, clinics trying to allocate their scarce resources face the ethical dilemma of weighing the added value of AI tools in their practices against the cost of upgrades before deciding on purchases. Further questions arise concerning the allocation of patients into competing AI systems existing within a clinic. These questions are also important for comparisons between competing clinics, both on national and international levels.\n\nThe big data has traditionally been limited by the perception and cognition of humans. However, the scope of the big data has grown exponentially following automated and autonomous collection, so that more personal and highly detailed information can be collected and analyzed. The assumption that AI tools trained on \"expert-annotated\" data are superior in terms of performance brings the question of prioritizing the clinical, research or educational point of view during the selection process among the commercially available AI technologies and, keeping the ethical concerns in mind, how this decision will impact the clinical decision-making process. The future workforce should thus be provided with not only the technical skills but also the underpinning philosophical understanding, helping them direct the future role of AI in radiotherapy. However, the adoption of AI technology requires a shift in the current training paradigm for the future workforce, training them to have competent oversight and retain the human perspective to be able to demonstrate proficiency in tasks using AI technologies. This would mean a reduction in knowledge-based learning and an increase in soft skills training with the introduction of AI technologies, so that clinicians can devote more time to patient interactions and care."
    },
    {
      "title": "Conclusions",
      "text": "The use of AI in radiotherapy includes concerns about the \"dimensions\" and \"quality\" of the big data  [43] . Databases that feed the big data pool are mostly associated with radiotherapy plans that have already been approved for treatment. These plans and their respective patients are unavoidably heterogeneous in terms of quality. On the other hand, the lack of the presentation of \"almost identical\" cases in the databases can result in suboptimal matching of present-day patients with the information available in the databases. Therefore, data with larger dimensions (especially collected from a variety of clinics from all around the world) can result in more realistic matches with better plan quality. Through the recording of individual and social moral values in addition to the usual demographics such as gender and race and the implementation of these as distinctive inputs to matching algorithms, solutions can also be provided for ethical concerns such as consistency, applicability and relevance.\n\nAnother matter of debate, involving the principle of justice, is the lack of information on actual circumstances (such as motives and attitudes), observed both by the patients and the physicians throughout the data collection process. Researchers, clinicians, patients and patient advocacy groups should closely collaborate in order to avoid the danger of dehumanization of patient information during its conversion into data points. Before introducing AI into clinical routine, more evidence is needed from comprehensive studies to address ethical concerns and to revise ethical policies protecting patient privacy without compromising the utilization of data. Further, physicians should consider the ethical dimension in their decision-making process, prioritize treating their patients and not their diseases, remain vigilant to preserve patient safety, avoid unintended harm and establish institutional policies on AI ethics."
    }
  ],
  "references": [
    {
      "title": "Artificial Intelligence"
    },
    {
      "title": "Radiomic phenotype features predict pathologic response in non-small cell lung cancer",
      "authors": [
        "T Coroller",
        "V Agrawal",
        "V Narayan"
      ],
      "year": 2016
    },
    {
      "title": "A quantitative CT imaging signature predicts survival and complements established prognosticators in stage I non-small cell lung cancer",
      "authors": [
        "J Lee",
        "B Li",
        "Y Cui"
      ],
      "year": 2018,
      "doi": "10.1016/j.ijrobp.2018.01.006"
    },
    {
      "title": "CT-based radiomic analysis of stereotactic body radiation therapy patients with lung cancer",
      "authors": [
        "E Huynh",
        "T Coroller",
        "V Narayan"
      ],
      "year": 2016,
      "doi": "10.1016/j.radonc.2016.05.024"
    },
    {
      "title": "Resolving ethical dilemmas: a guide for clinicians",
      "authors": [
        "B Lo"
      ],
      "year": 2020
    },
    {
      "title": "Principles of clinical ethics and their application to practice",
      "authors": [
        "B Varkey"
      ],
      "year": 2020,
      "doi": "10.1159/000509119"
    },
    {
      "title": "Ethical challenges of machine learning and deep learning algorithms",
      "authors": [
        "S Prabhu"
      ],
      "year": 2019,
      "doi": "10.1016/s1470-2045(19)30230-x"
    },
    {
      "title": "What is machine learning?",
      "authors": [
        "I Naqa",
        "M Murphy"
      ],
      "year": 2015,
      "doi": "10.1007/978-3-319-18305-3_1"
    },
    {
      "title": "Machine learning in radiation oncology: opportunities, requirements, and needs",
      "authors": [
        "M Feng",
        "G Valdes",
        "N Dixit",
        "T Solberg"
      ],
      "year": 2018,
      "doi": "10.3389/fonc.2018.00110"
    },
    {
      "title": "Artificial intelligence in radiation oncology: a specialty-wide disruptive transformation?",
      "authors": [
        "R Thompson",
        "G Valdes",
        "C Fuller",
        "C Carpenter",
        "O Morin",
        "S Aneja"
      ],
      "year": 2018,
      "doi": "10.1016/j.radonc.2018.05.030"
    },
    {
      "title": "Deep learning in medical imaging and radiation therapy",
      "authors": [
        "B Sahiner",
        "A Pezeshk",
        "L Hadjiiski",
        "X Wang",
        "K Drukker",
        "K Cha"
      ],
      "year": 2018,
      "doi": "10.1002/mp.13264"
    },
    {
      "title": "Overview of the American Society for Radiation Oncology-National Institutes of Health-American Association of Physicists in Medicine Workshop 2015: exploring opportunities for radiation oncology in the era of big data",
      "authors": [
        "S Benedict",
        "K Hoffman",
        "M Martel"
      ],
      "year": 2016,
      "doi": "10.1016/j.ijrobp.2016.03.006"
    },
    {
      "title": "Vision 20/20: perspectives on automated image segmentation for radiotherapy",
      "authors": [
        "G Sharp",
        "K Fritscher",
        "V Pekar",
        "M Peroni",
        "N Shusharina",
        "H Veeraraghavan"
      ],
      "year": 2014,
      "doi": "10.1118/1.4871620"
    },
    {
      "title": "Advances in Autosegmentation",
      "authors": [
        "C Cardenas",
        "J Yang",
        "B Anderson",
        "L Court",
        "K Brock"
      ],
      "year": 2019,
      "doi": "10.1016/j.semradonc.2019.02.001.Review"
    },
    {
      "title": "El Naqa I Big data analytics for prostate radiotherapy",
      "authors": [
        "J Coates",
        "L Souhami"
      ],
      "year": 2016,
      "doi": "10.3389/fonc.2016.00149"
    },
    {
      "title": "Impact of model and dose uncertainty on model-based selection of oropharyngeal cancer patients for proton therapy",
      "authors": [
        "R Bijman",
        "S Breedveld",
        "T Arts"
      ],
      "year": 2017,
      "doi": "10.1080/0284186x.2017.1355113"
    },
    {
      "title": "Deep learning for patient-specific quality assurance: identifying errors in radiotherapy delivery by radiomic analysis of gamma images with convolutional neural networks",
      "authors": [
        "M Nyflot",
        "P Thammasorn",
        "L Wootton",
        "E Ford",
        "W Chaovalitwongse"
      ],
      "year": 2018,
      "doi": "10.1002/mp.13338"
    },
    {
      "title": "IMRT QA using machine learning: a multi-institutional validation",
      "authors": [
        "G Valdes",
        "M Chan",
        "S Lim",
        "R Scheuermann",
        "J Deasy",
        "T Solberg"
      ],
      "year": 2017,
      "doi": "10.1002/acm2.12161"
    },
    {
      "title": "Ethics in clinical care",
      "authors": [
        "J Tepper"
      ],
      "year": 2017,
      "doi": "10.1016/j.ijrobp.2017.03.036"
    },
    {
      "title": "Principles of biomedical ethics",
      "authors": [
        "T Beauchamp",
        "J Childress"
      ],
      "year": 2019
    },
    {
      "title": "Assessing the role of artificial intelligence (AI) in clinical oncology: utility of machine learning in radiotherapy target volume delineation",
      "authors": [
        "I Boon",
        "Au Yong",
        "Tpt Boon"
      ],
      "year": 2018,
      "doi": "10.3390/medicines5040131"
    },
    {
      "title": "Clinical medical ethics: its history and contributions to American Medicine",
      "authors": [
        "M Siegler"
      ],
      "year": 2019,
      "doi": "10.1086/jce2019301017"
    },
    {
      "title": "The birth of bioethics",
      "authors": [
        "A Jonsen"
      ],
      "year": 1998
    },
    {
      "title": "Clinical ethics: a practical approach to ethical decisions in clinical medicine",
      "authors": [
        "A Jonsen",
        "M Siegler",
        "W Winsade"
      ],
      "year": 2010
    },
    {
      "title": "Barriers and facilitators to shared decision-making in oncology: a systematic review of the literature",
      "authors": [
        "J Covvey",
        "K Kamal",
        "E Gorse",
        "Z Mehta",
        "T Dhumal",
        "E Heidari"
      ],
      "year": 2019,
      "doi": "10.1007/s00520-019-04675-7"
    },
    {
      "title": "Machine learning and evidence-based medicine",
      "authors": [
        "I Scott"
      ],
      "year": 2018,
      "doi": "10.7326/M18-0115"
    },
    {
      "title": "Machine learning in medicine",
      "authors": [
        "R Deo"
      ],
      "year": 1920,
      "doi": "10.1161/CIRCULATIONAHA.115.001593"
    },
    {
      "title": "Clinical decision support of radiotherapy treatment planning: a data-driven machine learning strategy for patient-specific dosimetric decision making",
      "authors": [
        "G Valdes",
        "C Simone",
        "Chen Lin",
        "A Yom",
        "S Pattison"
      ],
      "year": 2017,
      "doi": "10.1016/j.radonc.2017.10.014"
    },
    {
      "title": "Using machine learning to predict radiation pneumonitis in patients with stage I non-small cell lung cancer treated with stereotactic body radiation therapy",
      "authors": [
        "G Valdes",
        "T Solberg",
        "M Heskel",
        "L Ungar",
        "Simone Cb2nd"
      ],
      "year": 2016,
      "doi": "10.1088/0031-9155/61/16/6105"
    },
    {
      "title": "Rapid Learning health care in oncology' -an approach towards decision support systems enabling customised radiotherapy",
      "authors": [
        "P Lambin",
        "E Roelofs",
        "B Reymen",
        "E Velazquez",
        "J Buijsen",
        "C Zegers"
      ],
      "year": 2013,
      "doi": "10.1016/j.radonc.2013.07.007"
    },
    {
      "title": "A prospective study comparing the predictions of doctors versus models for treatment outcome of lung cancer patients: a step toward individualized care and shared decision making",
      "authors": [
        "C Oberije",
        "G Nalbantov",
        "A Dekker",
        "L Boersma",
        "J Borger",
        "B Reymen"
      ],
      "year": 2014,
      "doi": "10.1016/j.radonc.2014.04.012"
    },
    {
      "title": "Selection of patients for radiotherapy with protons aiming at reduction of side effects: the model-based approach",
      "authors": [
        "J Langendijk",
        "P Lambin",
        "De Ruysscher",
        "D Widder",
        "J Bos",
        "M Verheij"
      ],
      "year": 2013,
      "doi": "10.1016/j.radonc.2013.05.007"
    },
    {
      "title": "Interactive decision-support tool for risk-based radiation therapy plan comparison for Hodgkin lymphoma",
      "authors": [
        "N Brodin",
        "M Maraldo",
        "M Aznar",
        "I Vogelius",
        "P Petersen",
        "S Bentzen"
      ],
      "year": 2013,
      "doi": "10.1016/j.ijrobp.2013.10.028"
    },
    {
      "title": "Evidence-based medicine and its role in ethical decision-making",
      "authors": [
        "P Borry",
        "P Schotsmans",
        "K Dierickx"
      ],
      "year": 2006
    },
    {
      "title": "Normal tissue complication probability (NTCP) modelling using spatial dose metrics and machine learning methods for severe acute oral mucositis resulting from head and neck radiotherapy",
      "authors": [
        "J Dean",
        "K Wong",
        "L Welsh",
        "A Jones",
        "U Schick",
        "K Newbold"
      ],
      "year": 2016,
      "doi": "10.1016/j.radonc.2016.05.015"
    },
    {
      "title": "Deep convolutional neural network with transfer learning for rectum toxicity prediction in cervical cancer radiotherapy: a feasibility study",
      "authors": [
        "X Zhen",
        "J Chen",
        "Z Zhong",
        "B Hrycushko",
        "L Zhou",
        "S Jiang"
      ],
      "year": 2017,
      "doi": "10.1088/1361-6560/aa8d09"
    },
    {
      "title": "Late rectal bleeding after 3D-CRT for prostate cancer: development of a neural-network-based predictive model",
      "authors": [
        "S Tomatis",
        "T Rancati",
        "C Fiorino",
        "V Vavassori",
        "G Fellin",
        "E Cagna"
      ],
      "year": 2012,
      "doi": "10.1088/0031-9155/57/5/1399"
    },
    {
      "title": "Artificial intelligence in radiation oncology",
      "authors": [
        "C Deig",
        "A Kanwar",
        "R Thompson"
      ],
      "year": 2019,
      "doi": "10.1016/j.hoc.2019.08.003"
    },
    {
      "title": "Assessment of early and late dysphagia using videofluoroscopy and quality of life questionnaires in patients with head and neck cancer treated with radiation therapy",
      "authors": [
        "E Erkal",
        "D Canoglu",
        "A Kaya",
        "G Aksu",
        "B Sarper",
        "G Akansel"
      ],
      "year": 2014,
      "doi": "10.1186/1748-717X-9-137"
    },
    {
      "title": "Normal tissue complication probability (NTCP) models for modern radiation therapy",
      "authors": [
        "G Palma",
        "S Monti",
        "M Conson",
        "R Pacelli",
        "L Cella"
      ],
      "year": 2019,
      "doi": "10.1053/j.seminoncol.2019.07.006"
    },
    {
      "title": "Artificial intelligence and machine learning in software as a medical device",
      "year": 2020,
      "doi": "10.31032/ijbpas/2025/14.8.9309"
    },
    {
      "title": "Are we for sale? Awareness of industry-related financial conflicts of interest in radiation oncology",
      "authors": [
        "K Tringale",
        "J Hattangadi-Gluth"
      ],
      "year": 2017,
      "doi": "10.1016/j.ijrobp.2017.06.2445"
    },
    {
      "title": "A Review on application of deep learning algorithms in external beam radiotherapy automated treatment planning",
      "authors": [
        "M Wang",
        "Q Zhang",
        "S Lam",
        "J Cai",
        "R Yang"
      ],
      "year": 2020,
      "doi": "10.3389/fonc.2020.580919"
    }
  ],
  "num_references": 43
}
