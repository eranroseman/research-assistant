{
  "paper_id": "CF4NAHEX",
  "title": "Large Language Models for Mental Health Applications: A Systematic Review",
  "abstract": "Background Large language models (LLMs) are advanced artificial neural networks trained on extensive datasets to accurately understand and generate natural language. While they have received much attention and demonstrated potential in digital health, their application in mental health, particularly in clinical settings, has generated considerable debate. \n Objective: This systematic review aims to critically assess the use of LLMs in mental health, specifically focusing on their applicability and efficacy in early screening, digital interventions, and clinical settings. By systematically collating and assessing the evidence from current studies, our work analyzes the models, methodologies, data sources, and outcomes, thereby highlighting the potential of LLMs in mental health, the challenges they present, and the prospects for their clinical use.",
  "year": 2022,
  "date": "2022-04-15",
  "authors": [
    {
      "name": "Zhijun Guo",
      "affiliation": {
        "organization": "Institute of Health Informatics",
        "department": "Institute of Health Informatics",
        "institution": "University College London"
      }
    },
    {
      "name": "Alvina Lai",
      "affiliation": {
        "organization": "Institute of Health Informatics",
        "department": "Institute of Health Informatics",
        "institution": "University College London"
      }
    },
    {
      "name": "Johan Hilge Thygesen",
      "affiliation": {
        "organization": "Institute of Health Informatics",
        "department": "Institute of Health Informatics",
        "institution": "University College London"
      }
    },
    {
      "name": "Joseph Farrington",
      "affiliation": {
        "organization": "Institute of Health Informatics",
        "department": "Institute of Health Informatics",
        "institution": "University College London"
      }
    },
    {
      "name": "Thomas Keen",
      "affiliation": {
        "organization": "Institute of Health Informatics",
        "department": "Institute of Health Informatics",
        "institution": "University College London"
      }
    },
    {
      "name": "Kezhi Li",
      "affiliation": {
        "organization": "Institute of Health Informatics",
        "department": "Institute of Health Informatics",
        "institution": "University College London"
      }
    }
  ],
  "doi": "10.2471/b09329",
  "md5": "E8492F5853D8881C9E5CF153DAC27A81",
  "publication": {
    "journal": "eBioMedicine Elsevier",
    "journal_inferred": true
  },
  "keywords": [
    "Large language models",
    "Mental health",
    "Digital healthcare",
    "ChatGPT",
    "BERT __________________________________________________________________________________________ 7. Multimedia Appendix"
  ],
  "sections": [
    {
      "title": "1.. Introduction and Background"
    },
    {
      "title": "1.1. Mental Health",
      "text": "Mental health, a critical component of overall well-being, is at the forefront of global health challenges  [1] . In 2019, an estimated 970 million individuals worldwide suffered from mental illness, accounting for 12.5% of the global population  [2] . Anxiety and depression are among the most prevalent psychological conditions, affecting 301 million and 280 million individuals respectively  [2] . Additionally, 40 million people were afflicted with bipolar disorder, 24 million with schizophrenia, and 14 million experienced eating disorders  [3] . These mental disorders collectively contribute to an estimated USD 5 trillion in global economic losses annually  [4] . Despite the staggering prevalence, many cases remain undetected or untreated, with the resources allocated to the diagnosis and treatment of mental illness far less than the negative impact it has on society  [5] . Globally, untreated mental illnesses account for 5% in high-income countries and 19% in low-and middle-income countries  [3] . The COVID-19 pandemic has further exacerbated the challenges faced by mental health services worldwide  [6] , as the demand for these services increased while access was decreased  [7] . This escalating crisis underscores the urgent need for more innovative and accessible mental health care approaches.\n\nMental illness treatment encompasses a range of modalities including medication, psychotherapy, support groups, hospitalization, and complementary & alternative medicine  [8] . However, societal stigma attached to mental illnesses often deters people from seeking appropriate care  [9] . Many people with mental illness avoid or delay psychotherapy  [10] , influenced by fears of judgment and concerns over costly, ineffective treatments  [11] . The COVID-19 crisis and other global pandemics have underscored the importance of digital tools, such as telemedicine and mobile apps, in delivering care during critical times  [12] . In this evolving context, LLMs present new possibilities for enhancing the delivery and effectiveness of mental health care.\n\nRecent technological advancements have revealed some unique advantages of LLMs in mental health. These models, capable of processing and generating text akin to human communication, provide accessible support directly to users  [13] . A study analyzing 2,917 Reddit user reviews found that CAs powered by LLMs are valued for their non-judgmental listening and effective problem-solving advice. This aspect is particularly beneficial for socially marginalized individuals, as it enables them to be heard and understood without the need for direct social interaction  [14] . Moreover, LLMs enhance the accessibility of mental health services, which are notably undersupplied globally  [15] . Recent data reveals substantial delays in traditional mental health care delivery: 23% of individuals with mental illnesses report waiting over 12 weeks for face-to-face psychotherapy sessions  [16] , with 12% waiting more than six months, and 6% over a year  [16] . In addition, 43% of adults with mental illness indicate that such long waits have exacerbated their conditions  [15] .\n\nTelemedicine, enhanced by LLMs, offers a practical alternative that expedites service delivery and could flatten traditional healthcare hierarchies  [17] . This includes real-time counseling sessions through CAs that are not only cost-effective but also accessible anytime and from any location. By reducing the reliance on physical visits to traditional healthcare settings, telemedicine has the potential to decentralize access to medical expertise and diminish the hierarchical structures within the healthcare system  [17] . Mental health chatbots developed using language models, have been gaining recognition, such as Woebot  [18]  and Wysa  [19] . Both chatbots follow the principles of Cognitive Behavioural Therapy principles and are designed to equip users with self-help tools for managing their mental health issues  [20] . In clinical practice, LLMs hold the potential to support the automatic assessment of therapists' adherence to evidence-based practices and the development of systems that offer real-time feedback and support for patient homework between sessions  [21] . These models also have the potential to provide feedback on psychotherapy or peer support sessions, which is especially beneficial for clinicians with less training and experience  [21] . Currently, these applications are still in the proposal stage. Although promising, they are not yet widely used in routine clinical settings, and further evaluation of their feasibility and effectiveness is necessary.\n\nThe deployment of LLMs in mental health also poses several risks, particularly for vulnerable groups. Challenges such as inconsistencies in the content generated and the production of 'hallucinatory' content may mislead or harm users  [22] , raising serious ethical concerns. In response, authorities like the World Health Organization (WHO) have developed ethical guidelines for Artificial Intelligence (AI) research in healthcare, emphasizing the importance of data privacy, human oversight, and the principle that AI tools should augment, rather than replace, human practitioners  [23] . These potential problems with LLMs in healthcare have gained considerable industry attention, underscoring the need for a comprehensive and responsible evaluation of LLMs' applications in mental health. The following section will further explore the workings of LLMs, and their potential applications in mental health, and critically evaluate the opportunities and challenges they introduce."
    },
    {
      "title": "1.2. Large Language Models",
      "text": "LLMs represent advancements in machine learning (ML), characterized by their ability to understand and generate human-like text with high accuracy  [24] . The efficacy of these models is typically evaluated using benchmarks designed to assess their linguistic fidelity and contextual relevance. Common metrics include BLEU for translation accuracy and ROUGE for summarization tasks  [25] . LLMs are characterized by their scale, often encompassing billions of parameters, setting them apart from traditional language models  [26] . This breakthrough is largely due to the Transformer architecture, a deep neural network structure that employs a 'self-attention' mechanism, developed by  Vaswani et al. in 2017. This allows LLMs to process information in parallel rather than sequentially, greatly enhancing speed and contextual understanding  [27] . To clearly define the scope of this study concerning LLMs, we specify that an LLM must utilize the Transformer architecture and contain a high number of parameters, traditionally at least one billion, to qualify as 'large'  [28] . This criterion encompasses models such as Generative Pre-trained Transformers (GPT) and Bidirectional Encoder Representations from Transformers (BERT). Although the standard BERT model, with only 0.34 billion parameters  [29] , does not meet the traditional criteria for 'large', its sophisticated bidirectional design and pivotal role in establishing new natural learning processing (NLP) benchmarks justify its inclusion among notable LLMs  [30] . The introduction of ChatGPT in 2022 generated substantial public and academic interest in LLMs, underlining their transformative potential within the field of AI  [31] . Other state-of-the-art LLMs include LLaMA and PaLM, as illustrated in Figure  1 . represents the number of parameters in billions for various language models by date of publication, with the oldest models at the top. The legend is color-coded by the development entity. Data was summarized with the latest models up to June 2024, with data for parameters and developers from GPT to LLaMA adapted from the work of Thirunavukarasu AJ et al  [32] . Details on release dates, parameter sizes, and developer entities for the most recent LLMs are sourced from references  [33] [34] [35] .\n\nLLMs are primarily designed to learn fundamental statistical patterns of language  [36] . Initially, these models were used as the basis for fine-tuning task-specific models rather than training those models from scratch, offering a more resource-efficient approach  [37] . This fine-tuning process involves adjusting a pre-trained model to a specific task by further training it on a smaller, task-specific dataset  [38] . However, developments in larger and more sophisticated models have reduced the need for extensive fine-tuning in some cases. Notably, some advanced LLMs can now effectively understand and execute tasks specified through natural language prompts without extensive task-specific finetuning  [39] . Instruction fine-tuned models undergo additional training on pairs of user requests and appropriate responses. This training allows them to generalize across various complex tasks, such as sentiment analysis, which previously required explicit fine-tuning by researchers or developers  [40] . A key part of the input to these models, like ChatGPT and Gemini, includes a system prompt, often hidden from the user, which guides the model on how to interpret and respond to user prompts. For example, it might direct the model to act as a helpful mental health assistant. Additionally, 'prompt engineering' has emerged as a crucial technique in optimizing model performance. Prompt engineering involves crafting input texts that guide the model to produce the desired output without additional training. For example, refining a prompt from 'Tell me about current events in healthcare' to 'Summarize today's top news stories about technology in healthcare' provides the model with more specific guidance, which can enhance the relevance and accuracy of its responses  [41] . While prompt engineering can be highly effective and reduce the need to retrain the model, it is important to be wary of 'hallucinations', a phenomenon where models confidently generate incorrect or irrelevant outputs  [42] . This can be particularly challenging in high-accuracy scenarios, such as healthcare and medical applications  [43] [44] [45] [46] . Thus, while prompt engineering reduces the reliance on extensive fine-tuning, it underscores the need for thorough evaluation and testing to ensure the reliability of model outputs in sensitive applications.\n\nThe existing literature includes a review of the application of ML and NLP in mental health  [47] , analyses of LLMs in medicine  [32] , and a scoping review of LLMs in mental health. These studies have demonstrated the effectiveness of NLP for tasks such as text categorization and sentiment analysis  [47]  and provided a broad overview of LLM applications in mental health  [48] . However, a gap remains in systematically reviewing state-of-the-art LLMs in mental health, particularly in the comprehensive assessment of literature published since the introduction of the Transformer architecture in 2017. This systematic review addresses these gaps by providing a more in-depth analysis, evaluating the quality and applicability of studies, and exploring ethical challenges specific to LLMs, such as data privacy, interpretability, and clinical integration. Unlike previous reviews, this study excludes preprints, follows a rigorous search strategy with clear inclusion and exclusion criteria (e.g., using Cohen's kappa to assess inter-reviewer agreement), and employs a detailed assessment of study quality and bias (e.g., using the Risk of Bias 2 tool) to ensure the reliability and reproducibility of the findings.\n\nGuided by specific research questions, this systematic review critically assesses the use of LLMs in mental health, focusing on their applicability and efficacy in early screening, digital interventions, and clinical settings, as well as the methodologies and data sources employed. Our findings highlight the potential of LLMs in enhancing mental health diagnostics and interventions, while also identifying key challenges, such as inconsistencies in model outputs and the lack of robust ethical guidelines. These insights suggest that, while LLMs hold promise, their use should be supervised by physicians, and they are not yet ready for widespread clinical implementation."
    },
    {
      "title": "2.. Methods",
      "text": "This systematic review followed the Preferred Reporting Items for Systematic Review and Meta-analysis (PRISMA) guidelines  [49] . The protocol was registered on PROSPERO under the ID: CRD42024508617."
    },
    {
      "title": "2.1. Search Strategies",
      "text": "The search was initiated on August 3, 2024, and completed on August 6, 2024, by one author (ZG). This author systematically searched four databases: MEDLINE, IEEE Xplore, Scopus, JMIR, and ACM using the following search keywords: (mental health OR mental illness OR mental disorder OR psychiatry) AND (large language models). These keywords were consistently applied across each database to ensure a uniform search strategy. To conduct a comprehensive and precise search for relevant literature, strategies were tailored for different databases. ' All Metadata' was searched in MEDLINE and IEEE Xplore, while the search in Scopus was confined to titles, abstracts, and keywords. The JMIR database utilized the 'Criteria Exact Match' feature to refine search results and enhance precision. In the ACM database, the search focused on 'Full text'. The screening of all citations involved four steps:\n\n1) Initial Search: All relevant citations were imported into a Zotero citation manager library.\n\n2) Preliminary Inclusion: Citations were initially screened based on predefined inclusion criteria.\n\n3) Duplicate Removal: Citations were consolidated into a single group, from which duplicates were eliminated."
    },
    {
      "title": "4) Final Inclusion:",
      "text": "The remaining references were carefully evaluated against the inclusion criteria to determine their suitability."
    },
    {
      "title": "2.2. Study Selection and Eligibility Criteria",
      "text": "All the articles that matched our search criteria were double-screened by two independent reviewers (ZG, KL) to ensure each article fell within the scope of LLMs in mental health. This process involved the removal of duplicates followed by a detailed manual evaluation of each article to confirm adherence to our predefined inclusion criteria, ensuring a comprehensive and focused review. To quantify the agreement level between the reviewers and ensure objectivity, inter-rater reliability was calculated using Cohen's kappa, with a score of 0.84 indicating a good level of agreement. In instances of disagreement, a third reviewer (AL) was consulted to achieve consensus.\n\nTo assess the risk of bias, we utilized the Risk of Bias 2 tool, as recommended for Cochrane Reviews. The results have been visualized in Multimedia Appendix 1. We thoroughly examined each study for potential biases that could impact the validity of the results. These included biases from the randomization process, deviations from intended interventions, missing outcome data, inaccuracies in outcome measurement, and selective reporting of results. This comprehensive assessment ensures the credibility of each study.\n\nThe criteria for selecting articles were as follows: We limited our search to Englishlanguage publications, focusing on articles published between January 1, 2017, and April 30, 2024. This timeframe was chosen considering the significant developments in the field of LLMs in 2017, marked notably by the introduction of the Transformer architecture, which has greatly influenced academic and public interest in this area.\n\nIn this review, the original research articles and available full-text papers have been carefully selected aiming to focus on the application of LLMs in mental health. To comply with PRISMA guidelines, articles that have not been published in a peer-reviewed venue, including those only available on a preprint server, were excluded. Due to the limited literature specifically addressing the mental health applications of LLMs, we included review articles to ensure a comprehensive perspective. Our selection criteria focused on direct applications, expert evaluations, and ethical considerations related to the use of LLMs in mental health contexts, with the goal of providing a thorough analysis of this rapidly developing field."
    },
    {
      "title": "2.3. Information Extraction",
      "text": "The data extraction process was jointly conducted by two reviewers (ZG, KL), focusing on examining the application scenarios, model architecture, data sources, methodologies used, and main outcomes from selected studies on LLMs in mental health.\n\nInitially, we categorized each study to determine its main objectives and applications. The categorization process was conducted in two steps. First, after reviewing all the included articles, we grouped them into three primary categories: detection of mental health conditions and suicidal ideation through text, LLM usage for mental health CAs, and other applications and evaluation of the LLMs in mental health. In the second step, we performed a more detailed categorization. After a thorough, in-depth reading of each article within these broad categories, we refined the classifications based on the specific goals of the studies. Following this, we summarized the main model architectures of the LLMs used and conducted a thorough examination of data sources, covering both public and private datasets. We noted that some review articles lacked detail on dataset content, and therefore, we focused on providing comprehensive information on public datasets, including their origins and sample sizes. We also investigated the various methods employed across different studies, including data collection strategies and analytical methodologies. We examined their comparative structures and statistical techniques to offer a clear understanding of how these methods are applied in practice.\n\nFinally, we documented the main outcomes of each study, recording significant results and aligning them with relevant performance metrics and evaluation criteria. This included providing quantitative data where applicable to underscore these findings. The synthesis of information was conducted using a narrative approach, where we integrated and compared results across different studies to highlight the efficacy and impact of LLMs on mental health. This narrative synthesis allowed us to highlight the efficacy and impact of LLMs in mental health, providing quantitative data where applicable to underscore these findings. The results of our analysis are presented in three tables, each corresponding to one of the primary categories."
    },
    {
      "title": "3.. Results"
    },
    {
      "title": "3.1. Strategy and Screening Process",
      "text": "The PRISMA diagram of the systematic screening process can be seen in Figure  2 . Our initial search across four academic databases: MEDLINE, IEEE Xplore, Scopus, JMIR, and ACM yielded 14265 papers: 907 from MEDLINE, 102 from IEEE Xplore, 204 from Scopus, 211 from JMIR, and 12,841 from ACM. After duplication, 13,967 unique papers were retained. Subsequent screening is based on predefined inclusion and exclusion criteria, narrowing down the selection to 40 papers included in this review. The reasons for the full-text exclusion of 61 papers can be found in Multimedia Appendix 2. In our review of the literature, we classified the included articles into three broad categories: detection of mental health conditions and suicidal ideation through text (n=15), LLMs usage for mental health CAs (n=7), and the other applications and evaluation of the LLMs in mental health (n=18). The first category investigates the potential of LLMs for the early detection of mental illness and suicidal ideation via social media and other textual sources. Early screening is highlighted as essential for preventing the progression of mental disorders and mitigating more severe outcomes. The second category assesses LLM-supported CAs used as teletherapeutic interventions for mental health issues, such as loneliness, with a focus on evaluating\n\nabout mental health (n ) -ot about LLMs (n ) -uplicate (n ) -ot an academic paper too short (n ) -reprint (n ) i. Mental health conditions and suicidal ideation detection throu h te t (n ) ii. LLMs usa e for mental health conversational a ents (n ) iii. ther applications and evaluation of the LLMs in mental health (n ) their effectiveness and validity. The third category covers a broader range of LLM applications in mental health, including clinical uses such as decision support and therapy enhancement. It aims to assess the overall effectiveness, utility, and ethical considerations associated with LLMs in these settings. All selected articles are summarized in Table 1-3 according to the three categories. Table 1. Summary of the 15 selected articles from the literature on LLMs in mental health conditions and suicidal ideation detection through text. Ref. Cases Models Data Sources Methodology Used Main Outcomes (Verma et al., 2023) [50] Detecting depression using LLMs through textual data oB Ta [ ] Mental health corpus [ ]; Depression Reddit cleaned [53] This paper used two datasets focused on mental health to train a deep learning model, RoBERTa, for depression detection. Data preprocessing included text cleaning, tokenization, and vectorization, followed by model training with fine-tuning of hyperparameters for binary classification of depression. The study successfully used a RoBERTa-base model to detect depression with a high accuracy of 96.86%, showcasing the potential of AI in identifying mental health issues through linguistic analysis. ( iniz et al., ) [ ] Detecting suicidal ideation using LLMs through Twitter texts B T model for ortu uese [ ]; Multilin ual B T (base) [ ]; B Timbau [ 6] on-clinical te ts from tweets (user posts of the online social network Twitter) This paper developed the Boamente system through a codesign approach with psychologists, creating a virtual keyboard for text collection and a web platform for data analysis. Texts were collected from Twitter, annotated for suicidal ideation, and processed with LLM techniques. ML and DL models were then trained on this data, allowing mental health professionals to access analysis results without retaining sensitive text data. The Boamente system demonstrated effective text analysis for suicidal ideation with high privacy standards and actionable insights for mental health professionals. The bestperforming BERTimbau Large model (accuracy: 0.955; precision: 0.961; Fscore: 0.954; AUC: 0.954) significantly excelled in detecting suicidal tendencies, showcasing robust accuracy and recall in model evaluations. (Danner et al., 2023) [57] Detecting depression using LLMs through clinical interviews B T; G T-3. ; hatG T-A -W Z [ ]; tended-A [ ]; simulated data The method employed deep learning to detect depression symptoms using multimodal datasets. It pre-processed data, addressed class imbalance, finetuned the model, and evaluated performance using metrics like precision, recall, and F1 score. The study assessed the abilities of GPT-3.5-turbo and ChatGPT-4 on the DAIC-WOZ dataset, which yielded F1 scores of 0.78 and 0.61 respectively, and a custom BERT model, extendedtrained on a larger dataset, which achieved an F1 score of 0.82 on the Extended-DAIC dataset, in recognizing depression in text. (Tao et al., 3) [6 ] Detecting anxiety and depression using LLMs through dialogs in real-life scenarios hatG T peech data from nine Q&A tasks related to daily activities ( patients with an iety and 6 patients with depression) The study developed a virtual framework utilizin LLMs to nonintrusively support mental health treatments by analyzin behavioral data and speech features like rate and pitch. This approach, tested with patients from ekin University i th Hospital, aimed to detect an iety and depression symptoms throu h hatG T analysis, facilitatin personalized therapeutic strate ies. This paper introduced a virtual interaction framework usin LLMs to miti ate ne ative psycholo ical states. Analysis of Q&A dialo ues demonstrated hatG T's potential in identifyin depression and an iety. To enhance classification, four lan ua e features, includin prosodic and speech rate, positively impacted classification. (Hayati et al., ) [6 ] Detecting depression by Malay dialect speech using LLMs G T-3 nterviews with 3 adults fluent in Kuala Lumpur (KL), ahan , or Teren anu Malay dialects articipants were interviewed, their responses transcribed and classified for depression usin G T-3 on a dataset minimally processed to standardize pronouns and remove frequent stop words, with an %-% trainin -testin split. G T-3 was tested on three different dialectal Malay datasets (combined, KL, and non-KL), performin best on the KL dataset with a ma _e ample value of , which achieved the hi hest overall performance. espite the promisin results, the non-KL dataset showed the lowest performance, su estin that lar er or more homo eneous datasets mi ht be necessary for improved accuracy in depression detection tasks. (Wan et al., ) [6 ] Detecting depression using LLMs through microblogs B T; oB Ta [ ]; L et [63] 3, 3 microblo s collected from the ina Weibo [6 ] The study utilized a dataset from ina Weibo, annotated for varyin levels of depression risk, to evaluate the effectiveness of B T, oB Ta, and L T models in classifyin depression risk throu h fine-tunin and domain-specific pretrainin . oB Ta achieved the hi hest macroavera ed F score of . for depression classification, while B T scored the hi hest micro-avera ed F score of . 6. retrainin on an indomain corpus improved model performance. (Metzler et al., ) [6 ] Detecting suicidal ideation using LLMs through Twitter texts B T; L et [63] 3 n lish tweets The study involved manually labelin 3, n lish tweets accordin to a novel scheme, leadin to trainin various machine learnin models, includin deep learnin (B T, L et), for multiclass and binary classification tasks aimed at suicide prevention. B T achieved F -scores of . 3 for accurately labelin tweets as about suicide and . for off-topic tweets in the binary classification task. ts performance was similar to or e ceeded human performance and matched that of state-of-the-art models on similar tasks. (Sadeghi et al., 2023) [66] Detecting depression using LLMs through interviews G T-3. -Turbo; oB Ta [ ] E-DAIC ( participants) [67] The study utilized G T-3. -Turbo to transform interview transcripts, makin them more informative for detectin depression. t then employed the ep oB Ta lan ua e model, fine-tuned on these transformed transcripts, to predict an individual's atient Health Questionnaire ( HQ) score based on te t analysis. The study achieved its lowest error rates, a Mean Absolute rror (MA ) of 3.6 on the dev set and . 6 on the test set, by fine-tunin ep oB Ta with a specific prompt, outperformin manual methods and hi hli htin the potential of automated te t analysis for depression detection. (Zhan et al., ) [68] Detecting depression trends using LLMs through Twitter texts oB Ta [ ]; L et [63] Twitter users with depression identified via tweets and profiles The study identified depressionrelated content on Twitter usin re ular e pressions, built a dataset of users, trained transformerbased models to classify depression, e plored a fusion classifier, and demonstrated the model's ability to monitor depression trends durin V -. This study developed a fusion model that accurately classified depression amon Twitter users with . % accuracy. t identified key lin uistic and behavioral indicators of depression and demonstrated that depressive users responded to the pandemic later than controls. The findin s su est the model's effectiveness in noninvasively monitorin mental health trends durin major events like V -. (Vajre et al., 2021) [69] Detecting mental health using LLMs through social media texts PsychBERT Twitter hashtags and Subreddit (6 domains: anxiety, mental health, suicide, etc) The paper developed a taxonomy based on HiTOP, implemented a two-stage framework for mental health text identification and behavior detection, and incorporated interpretability components. The study identified PsychBERT as the highest-performing model, achieving an F1 score of 0.98 in a binary classification task and 0.63 in a more challenging multi-class classification task, indicating its superiority in handling complex mental healthrelated data. Additionally, PsychBERT's explainability was enhanced by using the Captum library, which confirmed its ability to accurately identify key phrases indicative of mental health issues. (Levkovich & Elyoseph, 2023) [70] Detecting suicidal ideation using LLMs through text vignette hatG T-3. ; ChatGPT-4 ChatGPT's response to the text vignette from Levi-Belz and Gamliel [71]\n\nChatGPT-4 and ChatGPT-3.5 evaluated a vignette depicting suicide risk, compared to mental health professionals' assessments.\n\nChatGPT-4's assessments of suicide attempts aligned closely with mental health professionals with an average Z score of 0.01, while ChatGPT-3.5 significantly underestimated these risks with a Z score of -0.83.ChatGPT-4 reported higher rates of suicidal ideation and psychache with Z scores of 0.47 and 1.00, respectively, but assessed resilience levels lower than professionals with Z scores of -0.89 and -0.90.\n\n(Howard et al., ) [ ] Detecting suicidal ideation using LLMs through social media texts eepMoji [ 3]; Universal entence ncoder [ ]; G T-1588 labeled posts from the Computational Linguistics and Clinical Psychology 2017 shared task The study utilized sentiment analysis and lin uistic tools, alon with pre-trained neural network models, to process posts from a clinical psycholo y forum. t then used automated machine learnin to enerate classifiers for efficiently cate orizin these posts. The top-performin system, utilizin features derived from the G T-model fine-tuned on over , unlabeled eachout.com posts, achieved a new state-of-the-art macro-avera ed F score of . on the L sych task without relyin on metadata or precedin posts. However, error analysis indicated that this system frequently misses e pressions of hopelessness. ( ti all et al., ) [ ] motion lassification usin LLMs moB TTin y A collection of publicly available This paper used a parallel multitask learnin approach with a sin le loss function for motion moB TTiny outperformed pretrained and state-of-the-art models in all metrics and computational throu h social media texts datasets hosted on Ka le and Hu in face [ 6, ] lassification and entiment Analysis. t analyzed the finetuned B TTiny model, moB TTiny, comparin its performance to baseline models and B parameter models, benchmarkin it a ainst Llama--B-chat and Mistral-B-nstruct in terms of accuracy, F -score, precision-recall curves, and inference speed. efficiency, achievin 3. % accuracy in sentiment analysis and . % in emotion classification. t processes a 6-token conte t window in . ms post-tokenization and . 3ms total processin speed. (Ghanadian et al., ) [ ] uicidal ideation detection usin LLMs throu h social media texts ALB T; istilB T; hatG T; Flan-T [ ]; Llama UM ataset [ ]; ynthetic atasets (Generated usin LLMs like Flan-T and Llama , these datasets au ment the UM dataset to enhance model performance) This paper detailed a methodolo y that first e tracted social factors from psycholo y literature to inform GLLM-based data synthesis prompts. t then used three GLLMs to enerate synthetic data on suicide-related topics and trained classifiers on real, synthetic, and au mented datasets, testin their performance on both real and synthetic test sets. The synthetic data-driven method achieved consistent F -scores of . , comparable to real-world data models yieldin F -scores between . and . . When 3 % of the real-world UM dataset was combined with the synthetic data, the performance si nificantly improved, reachin an Fscore of . on the UM test set. This result hi hli hts the effectiveness of synthetic data in addressin data scarcity and enhancin model performance. (Lossio-Ventura et al., ) [ ] Evaluations of LLMs for sentiment analysis through social media texts hatG T; pen re-Trained Transformers ( T) H ata et [ ]; tanford ata et  [ 3]  This paper created old standard labels for a subset of each dataset usin a panel of human raters. t compared state-of-the-art sentiment analysis tools on both datasets to evaluate variability and disa reement. Additionally, it e plored few-shot learnin by fine-tunin T usin a small annotated subset and zero-shot learnin usin hatG T. This paper revealed hi h variability and disa reement amon sentiment analysis tools when applied to healthrelated survey data.\n\nT and hatG T demonstrated superior performance, outperformin all other tools. Moreover, hatG T outperformed T, achievin 6% hi her accuracy and a % to % hi her F-measure.\n\nTable 2. Summary of the 7 selected articles from the literature on LLMs in mental health CAs. Ref. Cases Models Data Sources Methodology Used Main Outcomes (Beredo & n , ) [ ] Mental health interventions using CAs supported by LLMs [ ]; MHBot [ 6]; MA [ ] mpatheticdialo ues ( , conversations) [ ]; Well-Bein onversations [ ]; erma Le ica [ ] This study evaluated LLMs involves automated evaluation, where metrics like perplexity measure a model's ability to predict unseen test sets, and human evaluation, assessing the chatbot's human-likeness and response quality through criteria like performance, humanity, and affect, evaluated by experts in psychology. Additionally, experts were recruited to assess chatbot interactions based on specific quality attributes, providing a comprehensive understanding of the model's conversational abilities. This study successfully demonstrated a hybrid conversation model, which combines enerative and retrieval approaches to improve lan ua e fluency and empathetic response eneration in chatbots. This model, tested throu h both automated metrics and human evaluation, showed that the medium variation of the FT model outperformed the vanilla ialoG T in perple ity and that the human-likeness, relevance, and empathetic qualities of responses were si nificantly enhanced, makin VHope a more competent A with empathetic abilities. (Crasto et al., 2021) [91] Mental health interventions using CAs supported by LLMs DialoGPT Counselchat (includes tags of illness); question answers from 100 college students Recognized mental health questionnaires (PHQ-9 & WHO-5) were completed. The DialoGPT fine-tuned with Counselchat data, was employed for chatbot interaction. Microinterventions were suggested based on identified issues, and a student survey was administered. The DialoGPT model, demonstrating higher perplexity and preferred by 63% of college participants for its human-like and empathetic responses, was chosen as the most suitable system for addressing student mental health issues. (Zygadlo, 2021) [92] Mental health interventions using Polishlanguage CA supported by LLMs Rasa [93]; spaCy [94]; Transformers; BERT EmpatheticDialogues [88]; DailyDialog [95] The paper entailed developin a chatbot with asa and an emotion reco nition model, creatin a bilin ual olishn lish corpus from e istin datasets, and employin machine translation for olish. This approach facilitated sentiment and emotion classification usin B T models, demonstratin the effective use of machine translation for data-scarce lan ua es. The successful setup of an initial chatbot dialo ue framework usin asa and the development of a bilin ual ( n lish and olish) corpus for emotion reco nition. The research has advanced to trainin B T-based models for emotion reco nition, achievin hi h accuracy in sentiment and emotion classification, demonstratin the feasibility of inte ratin machine translation to work with less-resourced lan ua es like olish for emotional understandin in chatbots. (Ma et al., ) [ ] Evaluation of mental health intervention CAs supported by LLMs G T-3 eddit posts ( 3 user comments) The study utilized a qualitative content analysis of eddit posts from the r eplika subreddit to e plore user e periences with the A -based A eplika, focusin on mental well-bein support. By employin a twosta e codin process with a developed codebook, researchers analyzed a representative sample of posts and comments to identify key benefits and challen es. The study hi hli hted that As like eplika, powered by LLMs, offered crucial mental health support by providin immediate, unbiased assistance and fosterin self-discovery. However, they stru led with content filterin , consistency, user dependency, and social sti ma, underscorin the importance of cautious use and improvement in mental wellness applications. (Heston, 3) [ 6] Evaluation of mental health intervention CAs supported by LLMs hatG T-3. Public AI mental health CAs from FlowGPT.com valuated hatG T-3. mental health a ents with simulations for reco nizin suicidality, trackin referral to humans, and shutdown at risk levels. This study evaluated as from FlowG T.com, findin that they referred to human intervention at moderate depression levels ( HQ-score of ) and shut down at severe levels (score of ). nly two a ents provided crisis resources, and most resumed dialo ue if the risk level decreased. (Alessa and Al-Khalifa, 3) [ ] Mental health interventions using CAs for the elderly supported by LLMs hatG T; Goo le loud A ecord of interactions with A; results of the human e perts' assessment This paper e plored usin hatG T to create a chatbot for providin support to older adults and socially isolated seniors. The system incorporated Goo le's loud A for speech reco nition and te t-to-speech, and personalized prompts based on user information collected throu h a questionnaire. The chatbot en a ed users in empathetic conversations, quizzes, and health tips, with prompt en ineerin optimized throu h three e periments. The proposed hatG T-based system effectively serves as a companion for elderly individuals, helpin to alleviate loneliness and social isolation. reliminary evaluations showed that the system could enerate relevant responses tailored to elderly personas. (He et al., ) [ ] Evaluation of CAs handling counseling for people with autism supported by LLMs ChatGPT Public available data from the web-based medical consultation platform DXY [99] This paper selected 100 patient consultation samples related to autism from January 2018 to August 2023. The questions and responses were anonymized and randomized. Three chief physicians assessed the responses across four dimensions: relevance, accuracy, usefulness, and empathy, completing 717 evaluations. The responses were then compared using a Likert scale to gauge their quality. The study found that 46.86% of assessors preferred responses from physicians, 34.87% favored ChatGPT, and 18.27% favored ERNIE Bot. Physicians and ChatGPT showed higher accuracy and usefulness compared to ERNIE Bot, while ChatGPT outperformed both in empathy. The study concluded that while physicians' responses were generally superior, LLMs like ChatGPT can provide valuable guidance and greater empathy, though further optimization and research are needed for clinical integration.\n\nTable 3. Summary of the 18 selected articles from the literature on other applications and evaluation of the LLMs in mental health. . C Model D M U M O (Franco ' ouza et al., 2023) [100] valuation of hatG T's responses to clinical vi nettes in psychiatry hatG T 3. ases in sychiatry [ ]; hatG T 3. responses to cases hatG T 3. responded to psychiatric case vi nettes, evaluated by e pert faculties across cate ories usin mean scores, and represented raphically. hatG T 3. received mostly \"Grade A\" ratin s in 6 out of cases, e cellin in mana ement strate ies and dia noses across psychiatric conditions. Few responses received \"Grade \" due to minor discrepancies, but no dia nostic errors were noted. ( pallek et al., 3) [ ] valuation of hatG T in mental health education G T-eal-world data from ' racks in the ce' [ 3] and ' ositive hoices' [ ] The study utilized G T-and realworld queries and factsheets from two health portals, assessin LLMs' potential in eneratin mental health education content within ethical uidelines. G T-'s outputs seemed valid but were substandard compared to e pert materials, lackin in readin level and adherence to uidelines, requirin careful human editin . Althou h not suitable for direct consumer queries, G T-can be cautiously used by educators and researchers to develop educational materials, which should disclose A use and be evaluated for efficacy. (Farhat et al., 3) [ ] valuation of hatG T as a complementary mental health resource hatG T esponses enerated by hatG T The study evaluated hatG T's effectiveness in mental health support by analyzin its responses and cross-questionin , particularly focusin on issues related to an iety and depression and its su estions re ardin medications. hatG T displayed si nificant inconsistencies and low reliability when providin mental health support for an iety and depression, underlinin the necessity of validation by medical professionals and cautious use in mental health conte ts. (Wei et al., 3) [106] valuation of hatG T in psychiatry ChatGPT Theoretical analysis and literature reviews The study investi ated hatG T's application in psychiatry, evaluatin its capabilities in screenin , dia nosis, and patient support. The paper found hatG T useful in psychiatry, stressin ethical use and human oversi ht, while notin challen es in accuracy and bias, positionin A as a supportive tool in care. (Yon satian chot et al., 3) [ ] valuation of LLMs' perception of emotion Textdavinci-003 [108]; ChatGPT; GPT-4 esponses from three penA LLMs to the tress and opin rocess Questionnaire\n\nThe study assessed the emotional understandin of LLMs like hatG T usin the tress and opin rocess Questionnaire ( Q) across three penA models (davinci-3, hatG T, G T-) to compare their appraisal and copin reactions a ainst human data and appraisal theory predictions.\n\nThe study applied the Q to three penA LLMs-davinci-3, hatG T, and G T--and found that while their responses ali ned with human dynamics of appraisal and copin , they did not vary across key appraisal dimensions as predicted and differed si nificantly in response ma nitude. otably, all models reacted more ne atively than humans to ne ative scenarios, potentially influenced by their trainin processes. (Grabb, 3)  [ ] valuation of prompt en ineerin by LLMs and its impact on mental health hatG T ."
    },
    {
      "title": "hatG T's answers to unique questions",
      "text": "The study tested hatG T . 's response variability to four uniquely framed questions about happiness, each asked five times in distinct roles and conte ts, to e plore the model's adaptability and advice consistency.\n\nThe study found hatG T . 's advice varied widely based on prompt desi n, emphasizin careful prompt craftin in mental healthcare conte ts to ensure safety and relevance. ( Hadarhoval et al., 3) [ ] valuation of hatG T's mentalizin abilities in borderline personality disorder ( B ) and schizoid hatG T 3. atin of Levels of motional Awareness cale (L A ) scenarios for B and by hatG T The study evaluated hatG T's emotional awareness throu h modified L A scenarios for B and , scorin responses and analyzin differences in emotion identification and intensity. hatG T was able to accurately describe the emotional reactions of individuals with B as more intense, comple , and rich than those with . personality disorder ( ) ( ez in et al., 3) [111] valuation of clinical accuracy in LLMs' responses to postpartum depression ( ) questions G T-(usin hatG T); LaM A (usin Bard) [ ] -related patient-focused frequently asked questions sourced from the American olle e of bstetricians and Gynecolo ists The study compared responses from G T-, LaM A, and Goo le earch a ainst A G's FAQs on postpartum depression, evaluated by two board-certified physicians usin a G A -informed scale. tatistical analyses were performed usin software, includin interrater reliability and differences in response quality. hatG T outperformed Bard and Goo le earch in providin hi hquality, clinically accurate responses to postpartum depression questions, with si nificant statistical support and perfect rater a reement on its responses. (Tanana et al., 2021) [113] valuation of LLM's ability to rate emotions in psychotherapy B T; L W [ ] sychotherapy transcripts that were published by Ale ander treet ress [ ]; the human ratin s from a database of , utterances from psychotherapy The paper utilized psychotherapy transcripts to e tract utterances for sentiment analysis, employin ram models, a recurrent neural network, L W , and B T for comparison. valuation metrics included overall accuracy, F score, and ohen's kappa. Ma nt models surpassed L W , with B T achievin the hi hest performance (kappa . ). The best model e ceeded human performance on the test set by %. (Wan et al., ) [ 6] nhancin depression dia nosis and treatment throu h the use of LLMs LLaMA-7B; ChatGLM-6B; Alpaca; LLMs+Kno wledge hinese ncremental re-trainin dataset [ ] The paper customized a Chinese language model for depression, using datasets and a knowledge graph. Techniques included data augmentation, generating instruction data from the knowledge graph, finetuning the model, and reinforcement learning with expert feedback. The study assessed LLMs' performance in mental health, emphasizing safety, usability, and fluency and integrating mental health knowledge to improve model effectiveness, enabling more tailored dialogues for treatment while ensuring safety and usability. ( chubert et al., 3) [ ] valuation of LLMs' performance on neurolo y board-style e aminations ChatGPT 3.5; ChatGPT 4.0 A question bank from an educational company with 36 questions that resemble neurolo y board questions [ ] The study evaluated two LLMs using a neurology question bank, categorizing questions into lower and higher-order types. Statistical analysis compared model performance with human performance. ChatGPT 4.0 excelled over ChatGPT 3.5, achieving 85.0% accuracy versus 66.8%. It surpassed human performance in specific areas and exhibited high confidence in responses. Longer questions tended to result in more incorrect answers for both models. (Friedman & Ballentine, 3) [ ] valuation of LLMs in datadriven discovery: correlatin sentiment chan es with psychoactive e periences BERTowid [29]; BERTiment [121] rowid testimonials [ ]; dru receptor affinities [ 3]; brain ene e pression data [ ]; K annotated eddit posts [ ] This paper used BERT and 11,816 testimonials to predict sentiments and demographics, then linked drug effects to words, identifying 11 key factors on a 3D brain model. This paper found that LLM methods can create unified and robust quantifications of subjective experiences across various psychoactive substances and timescales. The representations learned are evocative and mutually confirmatory, indicating significant potential for LLMs in characterizing psychoactivity. (Wu et al., 3) [ 6] Expanding dataset of Post-Traumatic Stress Disorder (PTSD) using LLMs G T-3. Turbo -A ( participants) [6 ] This paper developed two te t au mentation frameworks utilizin LLMs to address data imbalance in L tasks for T dia nosis. The methodolo ies applied were zeroshot, which enerated standardized transcripts, and few-shot, which rephrased e istin trainin samples within the -A . This paper demonstrated that two novel te t au mentation frameworks usin LLMs si nificantly improved T dia nosis by addressin data imbalances in L tasks. The zeroshot approach, which enerated new standardized transcripts, achieved the hi hest performance improvements, while the few-shot approach, which rephrased e istin trainin samples, also surpassed the ori inal dataset's efficacy. (Kumar et al., 3) valuation of G T 3 in mental health intervention G T 3 participants responses, with valid responses after filterin This paper conducted a pilot e periment usin a factorial desi n to compare LLM-based chatbot interventions with videobased methods for improvin mental health awareness. G T-3 was used to create chatbots for providin mindfulness information and reflection, and participants were This paper found that interaction with either of the chatbots improved participants' intent to practice mindfulness a ain, while the tutorial video enhanced their overall e perience of the e ercise. These findin s hi hli hted the potential promise and outlined directions for e plorin the use of LLM-based recruited from Amazon Mechanical Turk. chatbots for awareness-related interventions. (Elyoseph et al., 2024) [128] valuation of LLMs in mental health intervention ChatGPT3. 5; ChatGPT4; Claude; Bard ChatGPT 3.5, ChatGPT 4, Claude, Bard, and mental health professionals' responses to text vignettes about depression This paper conducted a comparative analysis using case vignettes to evaluate the performance of different LLMs against mental health professionals and the general public. The focus was on the LLMs' ability to generate prognoses, anticipated outcomes with and without intervention, and long-term consequences for individuals with depression. This paper found that ChatGPT-4, Claude, and Bard aligned closely with mental health professionals and the general public in diagnosing depression and recommending combined treatment, while ChatGPT-3.5 had a more pessimistic prognosis. The study highlighted AI's potential to complement mental health professionals but raised concerns about ChatGPT-3.5's impact on patient motivation. (Perlis et al., 2024) [129] Evaluation of GPT-4 for clinical decision support in bipolar depression GPT-4 turbo (gpt-4-1106preview) Recommendations generated by the augmented GPT-4 model and responses from clinicians treating bipolar disorder This paper generated 50 vignettes of bipolar disorder cases and had expert clinicians rank treatment options. It then compared these rankings with recommendations from an augmented GPT-4 model using specific guidelines and also evaluated responses from a community clinician group. This paper found that the augmented GPT-4 model had a Cohen's kappa of 0.31 with expert consensus, identifying the optimal treatment in 50.8% of cases and placing it in the top 3 in 84.4% of cases. In contrast, the base model had a Cohen's kappa of 0.09 and identified the optimal treatment in 23.4% of cases, highlighting the enhanced performance of the augmented model in aligning with expert recommendations. (Blease et al., 2024) [130] Evaluation of psychiatrists' perceptions of the LLMs ChatGPT; Bard; Bing AI Survey responses from 138 APA members on LLM chatbot use in psychiatry This paper surveyed APA members who attended an \"AI in Psychiatry\" informational session to explore their experiences and opinions on using LLM-powered chatbots in clinical practice. Participants provided feedback through a threeminute survey divided into sections on chatbot usage, its effects on clinical practice, and patient interactions, with responses analyzed using descriptive statistics and thematic analysis. This paper found that over half of psychiatrists used AI tools like ChatGPT for clinical questions, with nearly 70% agreeing on improved documentation efficiency and almost 90% indicating a need for more training while expressing mixed opinions on patient care impacts and privacy concerns. (Berrezueta -Guzman et al., ) [ 3 ] Evaluation of the efficacy of ChatGPT in mental intensive treatment hatG T valuations from attention deficit hyperactivity disorder (A H ) therapy e perts and interactions between therapists and the custom hatG T This paper developed a custom ChatGPT based on a literature review and validated it with therapeutic experts before implementing it in a robotic assistant for ADHD therapies. The Delphi method was used with a panel of ten e perts to assess the hatG T's performance across various therapeutic categories, ensuring a thorough, expert-driven evaluation. This paper found that the custom hatG T demonstrated stron capabilities in en a in lan ua e use, maintainin interest, promotin active participation, and fosterin a positive atmosphere in A H therapy sessions, with hi h ratin s in communication and lan ua e. However, areas needin improvement were identified, particularly in confidentiality and privacy, cultural and sensory sensitivity, and handlin nonverbal cues."
    },
    {
      "title": "3.2. Mental health conditions and suicidal ideation detection through text",
      "text": "Early intervention and screening are crucial in mitigating the global burden of mental health issues  [132] . We examined the performance of LLMs in detecting mental health conditions and suicidal ideation through textual analysis. Six articles assessed the efficacy of early screening for depression using LLMs  [50, 57, 60, 61, 66, 68] , while another simultaneously addressed both depression and anxiety  [60] . One comprehensive study examined various psychiatric conditions, including depression, social anxiety, loneliness, anxiety, and other prevalent mental health issues  [69] . Two articles assessed and compared the ability of LLMs to perform sentiment and emotion analysis  [75, 81] . Five articles focused on the capability of LLMs to analyze textual content for detecting suicidal ideation  [54, 65, 70, 72, 78] . Most studies employed BERT and its variants as one of the primary models (n=10)  [ 50,54,57,62,65,66,68,69,75,78], while GPT models were also commonly used (n=8) [57,60,61,66,70,72,78,81]. The majority of training data comprised social media posts (n=10) [50,54,62,65,68,69,72,75,78,81] from platforms like Twitter, Reddit, and Sina Weibo, covering languages such as English, Malay dialects, Chinese, and Portuguese. Additionally, five studies utilized datasets consisting of clinical transcripts and patient interviews [50,57,60,61,66], providing deeper insights into LLM applications in clinical mental health settings.\n\nIn studies focusing on early screening for depression, comparing results horizontally is challenging due to variations in datasets, training methods, and models across different investigations. Nonetheless, substantial evidence supports the significant potential of LLMs in detecting depression from text-based data. For example, Danner et al. conducted a comparative analysis using a Convolutional Neural Network (CNN) on the DAIC-WOZ dataset, achieving F1 scores of 0.53 and 0.59; however, their use of GPT-3.5 demonstrated superior performance, with an F1 score of 0.78  [57] . Another study involving the E-DAIC dataset (an extension of DAIC-WOZ) used DepRoBERTa to predict the PHQ-8 scores from textual data. This approach identified three levels of depression and achieved the lowest MAE of 3.65 in PHQ-8 scores [66].\n\nLLMs play an important role in sentiment analysis [75,81], which categorizes text into overall polarity classes such as positive, neutral, negative, and occasionally mixed, and emotion classification, which assigns labels like 'joy,' 'sadness,' 'anger,' and 'fear'  [75] . These analyses enable the detection of emotional states and potential mental health issues from textual data, facilitating early intervention  [133] . Stigall et al. demonstrated the efficacy of these models, with their study showing that EmoBERTTiny, a fine-tuned variant of BERT, achieved an accuracy of 93.14% in sentiment analysis and 85.46% in emotion analysis. This performance surpasses that of baseline models, including BERT-Base Cased and Prak-wal1 pre-trained BERTTiny [75], underscoring the advantages and validity of fine-tuning in enhancing model performance. LLMs have also demonstrated robust accuracy in detecting and classifying a range of mental health syndromes, including social anxiety, loneliness, and generalized anxiety. Vajre et al. introduced PsychBERT, developed using a diverse training dataset from both social media texts and academic literature, which achieved an F1 score of 0.63, outperforming traditional deep learning approaches such as CNNs and Long Short-Term Memory Networks (LSTMs), which recorded F1 scores of 0.57 and 0.51, respectively  [69] . In research on detecting suicidal ideation using LLMs, Diniz et al. showcased the high efficacy of the BERTimbau Large model within a non-English (Portuguese) context, achieving an accuracy of 0.955, precision of 0.961, and an F-score of 0.954  [54] . Metzler et al.'s assessment of the BERT model found it correctly identified 88.5% of tweets as suicidal or off-topic, performing comparably to human analysts and other leading models [65]. However, Inbar Levkovich et al. noted that while ChatGPT-4 assessments of suicide risk closely aligned with those by mental health professionals, it overestimated suicidal ideation  [70] . These results underscore that while LLMs have the potential to identify tweets reflecting suicidal ideation with accuracy comparable to psychological professionals, extensive follow-up studies are required to establish their practical application in clinical settings."
    },
    {
      "title": "3.3. LLMs in mental health CAs",
      "text": "In the growing field of mental health digital support, the implementation of LLMs as CAs has exhibited both promising advantages  [14, 84, 91, 96]  and significant challenges [92,96]. The studies by Ma et al. and Heston et al. both demonstrate the effectiveness of CAs powered by LLMs in providing timely, non-judgmental mental health support  [14, 96] . This intervention is particularly important for those who lack ready access to a therapist due to constraints such as time, distance, and work, as well as for certain socially marginalized populations, such as older adults who experience chronic loneliness and a lack of companionship  [14, 97] . Ma et al.'s qualitative analysis of user interactions on Reddit highlights that LLMs encourage users to speak up and boost their confidence by providing personalized and responsive interactions  [14] . Additionally, VHope, a DialoGPT-enabled mental health CA, was evaluated by three experts who rated its responses as 67% relevant, 78% human-like, and 79% empathetic  [84] . Another study found that after 717 evaluations by 100 participants on 239 autism-specific questions, 46.86% of evaluators preferred responses of the chief physicians, whereas 34.87% preferred ChatGPT-4 (OpenAI), and 18.27% favored ERNIE Bot (version 2.2.3; Baidu, Inc). Moreover, ChatGPT (mean score: 3.64, 95% CI 3.57-3.71) outperformed physicians (mean score: 3.13, 95% CI 3.04-3.21) in terms of empathy  [98] , indicating that LLM-powered CAs are not only effective but also acceptable by users. These findings highlight the potential for LLMs to complement mental health intervention systems and provide valuable medical guidance.\n\nThe development and implementation of a non-English CA for emotion capture and categorization was explored in a study by Zygadlo et al. Faced with a scarcity of Polish datasets, the study adapted by translating an existing database of personal conversations from English into Polish, which decreased accuracy in tasks from 90% in English to 80% in Polish  [92] . While the performance remained commendable, it highlighted the challenges posed by the lack of robust datasets in languages other than English, impacting the effectiveness of CAs across different linguistic environments. However, findings by He et al. suggest that the availability of language-specific datasets is not the sole determinant of CA performance. In their study, although ERNIE Bot was trained in Chinese and ChatGPT in English, ChatGPT demonstrated greater empathy for Chinese users  [98] . This implies that factors beyond the training language and dataset availability, such as model architecture or training methodology, can also affect the empathetic responsiveness of LLMs, underscoring the complexity of human-AI interaction.\n\nMeanwhile, the reliability of LLM-driven CAs in high-risk scenarios remains a concern  [14, 96] . An evaluation of 25 CAs found that in tests involving suicide scenarios, only two included suicide hotline referrals during the conversation  [96] . This suggests that while these CAs can detect extreme emotions, few are equipped to take effective preventive measures. Furthermore, CAs often struggle with maintaining consistent communication due to limited memory capacity, leading to disruptions in conversation flow and negatively affecting user experience  [14] ."
    },
    {
      "title": "3.4. The other applications and evaluation of the LLMs in mental health",
      "text": "ChatGPT has gained attention for its unparalleled ability to generate human-like text and analyze large amounts of textual data, attracting the interest of many researchers and practitioners  [ 100]. Numerous evaluations of LLMs in mental health have focused on ChatGPT, exploring its utility across various scenarios such as clinical diagnosis [100,106,111], treatment planning [106,128,131], medication guidance [105,109,129], patient management [106], psychiatry examinations [118], and psychology education [102], among others [107,110,127,130]. Research has highlighted ChatGPT's accuracy in diagnosing various psychiatric conditions [106,110,111,126]. For example, Franco D'Souza et al. evaluated ChatGPT's responses to 100 clinical psychiatric cases, awarding it an ' A' rating in 61 cases, with no errors in the diagnoses of different psychiatric disorders and no unacceptable responses, underscoring ChatGPT's expertise and interpretative capacity in psychiatry [100]. Further supporting this, research from Schubert et al. assessed ChatGPT 4.0's performance using neurology board-style exam questions, finding that it answered 85% of the questions correctly, surpassing the average human performance of 73.8% [118]. Meanwhile, in a study of LLMs regarding the prognosis and long-term outcomes of depression, ChatGPT-4, Claude, and Bard showed strong agreement with mental health professionals. They all recommended a combination of psychotherapy and antidepressant medication in every case [130]. This not only proves the reliability of LLMs for mental health assessment but also highlights their usefulness in providing valuable support and guidance for individuals seeking information or coping with mental illness. However, the direct deployment of LLMs such as ChatGPT in clinical settings carries inherent risks. The outputs of LLMs are heavily influenced by prompt engineering, which can lead to inconsistencies that undermine clinical reliability [102,105,106,107,109]. For example, Farhat et al. conducted a critical evaluation of ChatGPT's ability to generate medication guidelines through detailed cross-questioning and noted that altering prompts substantially changed the responses [105]. While ChatGPT typically provided helpful advice and recommended seeking expert consultation, it occasionally produced inappropriate medication suggestions. Perlis et al. verified this, showing that GPT-4 Turbo suggested medications that were considered poor choices or contraindicated by experts in 12% of cases [129]. Moreover, LLMs often lack the necessary clinical judgment capabilities. This issue was highlighted by Grabb's study, which revealed that despite built-in safeguards, ChatGPT remains susceptible to generating extreme and potentially hazardous recommendations [109]. A particularly alarming example was ChatGPT advising a depressed patient to engage in high-risk activities like bungee jumping as a means of seeking pleasure [109]. These LLMs depend on prompt engineering [102,105,109]\n\n, which means their responses can vary widely depending on the wording and context of the prompts given. The system prompts, which are predefined instructions given to the model, and the prompts used by the experimental team, such as those in Farhat's study, guide the behavior of ChatGPT and similar LLMs. These prompts are designed to accommodate a variety of user requests within legal and ethical boundaries. However, while these boundaries are intended to ensure safe and appropriate responses, they often fail to align with the nuanced sensitivities required in psychological contexts. This mismatch underscores a significant deficiency in the clinical judgment and control of LLMs within sensitive mental health settings.\n\nFurther research into other LLMs in the mental health sector has shown a range of capabilities and limitations. For example, a study by Sezgin et al. highlighted LaMDA's proficiency in managing complex inquiries about PPD that require medical insight or nuanced understanding, yet pointed out its challenges with straightforward, factual questions, such as \"What are antidepressants?\" [111] . Assessments of LLMs like LLaMA-7B, ChatGLM-6B, and Alpaca, involving 50 interns specializing in mental illness, received favorable feedback regarding the fluency of these models in a clinical context, with scores above 9.5 out of 10. However, the results also indicated that the responses of these LLMs often failed to address mental health issues adequately, demonstrated limited professionalism, and resulted in decreased usability  [116] . Similarly, a study on psychiatrists' perceptions of using LLMs such as Bard and Bing AI in mental health care revealed mixed feelings. While 40% of physicians indicated that they would use such LLMs to assist in answering clinical questions, some expressed serious concerns about their reliability, confidentiality, and potential to damage the patient-physician relationship  [130] .\n\nTable 4. Summary of main strengths, limitations, and suggestions of LLMs in mental health from the selected articles. CAT GO Y T NGTH L M TAT ON UGG T ON M D \u2022 Hi h etection Accuracy: Advanced LLMs achieve hi h accuracy in detectin depression and other mental health issues from te tual data [ , ]. \u2022 arly etection apabilities: LLMs effectively enable early detection of suicidal ideation and depression, crucial for timely interventions [ ,66, ]. \u2022 Multilin ual and iverse ata Handlin : emonstrated capability of LLMs in handlin data across different lan ua es and cultural conte ts, improvin lobal mental health monitorin [6 ,6 ]. \u2022 rivacy and thical oncerns: thical concerns due to the passive collection of sensitive te t data, underscore the need for improved privacy controls [ ,6 ]. \u2022 onte tual and motional Understandin eficits: Limitations in missin deeper conte tual and emotional nuances critical for accurate mental health assessments [6 ,6 , ]. \u2022 Generalizability hallen es: hallen es in eneralizin across diverse populations due to trainin on specific datasets [6 ,6 , , ]. \u2022 mprove rivacy and thics: Focus on enhancin privacy controls and adherin to ethical standards in future developments [ ,6 ]. \u2022 nhance onte tual Understandin : ncorporate multimodal data to improve models' understandin of conte t and emotions [6 ,6 ]. \u2022 pand ross-cultural and Multilin ual esearch: Advance models with diverse datasets to improve universality and adaptability [6 ,6 , ]. M H CA \u2022 nhanced mpathy and n a ement: LLMs like VHope and eplika offer empathetic and human-like interactions [ , , ]. \u2022 Accessibility and each: LLMs can provide support at scale and across different lan ua es, makin mental health support more accessible to diverse populations [ , ]. \u2022 omple nquiry Handlin : LLMs are adept at handlin comple medical and emotional inquiries, providin nuanced responses based on e tensive datasets [ , ]. \u2022 nconsistency and eliability: LLMs like hatG T can produce inconsistent and sometimes unreliable outputs, especially in hi h-stakes scenarios such as dia nosin or mana in mental health conditions [ 6]. \u2022 Lack of eep Understandin : LLMs stru le with understandin conte t deeply and can ive inappropriate responses, lackin the sensitivity required for certain mental health interactions [ ]. \u2022 nadequate risis esponse and afety rotocols: LLMs may not adequately identify or respond appropriately to severe mental health crises, which can be dan erous if the system fails to refer users to human intervention in a timely and effective manner [ 6]. \u2022 nhanced Model Testin and Validation: mplement comprehensive testin protocols and simulations of mental health scenarios to improve the consistency and reliability of LLM outputs [ 6, ]. \u2022 Advanced onte tual Understandin : evelop and inte rate advanced al orithms for LLMs to enhance their ability to comprehend and respond appropriately to the comple nuances of mental health conversations [ , ]. \u2022 obust risis Mana ement nte ration: nte rate sophisticated al orithms for crisis detection and escalation within LLMs, workin in partnership with healthcare professionals to ensure these systems ali n with clinical standards [ 6]. O A LLM M H \u2022 iverse Applications: LLMs have shown broad applications in mental health, e cellin in dia nostic aid, therapeutic strate y development, and educational material creation, which could enhance both patient care and medical trainin . [ , , 6, , , , , , 3 , 3 ]. \u2022 motional and Behavioral nsi hts: ome LLMs effectively mimic and understand human emotional and behavioral patterns, supportin their use in psychotherapy to analyze and respond to patient emotions accurately [ , 3, ]. \u2022 nhance the Quality and iversity of atasets: LLMs can enerate synthetic clinical data throu h advanced te t enhancement techniques and knowled eenhanced trainin , reducin costs and increasin data availability [ 6, 6]. \u2022 Generalizability and Bias oncerns: The specific dataset or conte t used and inherent biases in the trainin data may affect the fairness and accuracy of LLM outputs [ , , 6, , , 3 ]. \u2022 onsistency and eliability ssues: The outputs of LLMs mi ht vary when eneratin dia nostic recommendations or treatment strate ies, requirin thorou h validation and supervision [ , ]. \u2022 thical and afety isks: The deployment of LLMs in mental health conte ts introduces si nificant concerns, includin the risk of violatin data privacy, the potential for eneratin harmful advice, and the challen es of adherin to ethical standards [ , 6, 3 ]. \u2022 pandin esearch cope and iversity: ncreasin application research in different datasets, different populations, and clinical settin s to ensure the eneralizability and applicability of LLMs [ , , , , , 3 ]. \u2022 Human versi ht and Annotation: reatin specialized, clinically relevant trainin datasets with e pert input and oversi ht to ensure accurate and stable model outputs [ , , 6, , ]. \u2022 evelopin nte ration and e ulatory Frameworks: evelopin detailed uidelines and frameworks to ensure the ethical and safe use of A in clinical practices and to complement rather than replace human healthcare providers [ 6, , 3 ]."
    },
    {
      "title": "4.. Discussion"
    },
    {
      "title": "4.1. Principal findings",
      "text": "In the context of the wider prominence of LLMs in the literature  [14, 50, 57, 60, 61, 69, 96, 130] , our research supports the assertion that interest in LLMs is growing in the field of mental health. Figure  3  indicates a rising trend in the number of mental health studies employing LLMs, with a notable surge observed in 2023 following the introduction of ChatGPT in late 2022. Although we included articles only up to the end of April 2024, it is evident that the number of articles related to LLMs in the field of mental health continues to show a steady increase in 2024. This trend marks a substantial shift in the discourse around LLMs, reflecting their broader acceptance and integration into various aspects of mental health research and practice. The progression from text analysis to a diverse range of applications highlights the academic community's recognition of the multifaceted uses of LLMs. LLMs are increasingly employed for complex psychological assessments, including early screening, diagnosis, and therapeutic interventions.\n\nOur findings demonstrate that LLMs are highly effective in analyzing textual data to assess mental states and identify suicidal ideation  [50, 54, 57, 60, 61, 65, 66, 68, 69, 72, 78] , although their categorization often tends to be binary  [50, 54, 65, 68, 69, 72, 78] . These LLMs possess extensive knowledge in the field of mental health and are capable of generating empathic responses that closely resemble human interactions  [97, 98, 107 ]. They show great potential for providing mental health interventions with improved prognoses  [50, 96, 110, 127, 128, 131] , with the majority being recognized by psychologists for their appropriateness and accuracy [98,100,129]. The careful and rational application of LLMs can enhance mental health care efficiently and at a lower cost, which is crucial in areas with limited healthcare capacity. However, there are currently no studies available that provide evaluative evidence to support the clinical use of LLMs."
    },
    {
      "title": "4.2. Limitations"
    },
    {
      "title": "4.2.1. Strengths and Limitations of Using LLMs in Mental Health",
      "text": "Based on the works of literature the strengths and weaknesses of applying the LLMs in mental health are summarized in Table  4 .\n\nLLMs have a broad range of applications in the mental health field. These models excel in user provide empathy and anonymity, and help reduce the stigma associated with mental illness  [14, 107] , potentially encouraging more patients to participate in treatment. They also offer a convenient, personalized, and cost-effective way for individuals to access mental health services at any time and from any location, which can be particularly helpful for socially isolated populations, especially the elderly  [60, 84, 97] . Additionally, LLMs can help reduce the burden of care during times of severe healthcare resource shortages and patient overload, such as during the COVID-19 pandemic  [68] . Although previous research has highlighted the potential of LLMs in mental health, it is evident that they are not yet ready for clinical use due to unresolved technical risks and ethical issues.\n\nThe use of LLMs in mental health, particularly those fine-tuned for specific tasks such as ChatGPT, reveals clear limitations. The effectiveness of these models heavily depends on the specificity of user-generated prompts. Inappropriate or imprecise prompts can disrupt the conversation's flow and diminish the model's effectiveness  [75, 96, 105, 107, 109] . Even small changes in the content or tone of prompts can sometimes lead to significant variations in responses, which can be particularly problematic in healthcare settings where interpretability and consistency are critical  [14, 105, 107] . Furthermore, LLMs lack clinical judgment and are not equipped to handle emergencies  [95, 108] . While they can generally capture extreme emotions and recognize scenarios requiring urgent action, such as suicide ideation  [54, 65, 70, 72, 78] , they often fail to provide direct, practical measures, typically only advising users to seek professional help  [96] . In addition, the inherent bias in LLM training data [66,106] can lead to the propagation of stereotypical, discriminatory, or biased viewpoints. This bias can also give rise to hallucinations, where LLMs produce erroneous or misleading information  [105, 131] . Hallucinations also may stem from overfitting the training data or a lack of context understanding  [134] . Such inaccuracies can have serious consequences, such as providing incorrect medical information, reinforcing harmful stereotypes, or failing to recognize and appropriately respond to mental health crises  [131] . For example, an LLM might reinforce a harmful belief held by a user, potentially exacerbating their mental health issues, or it could generate non-factual, overly optimistic, or pessimistic medical advice, delaying appropriate professional intervention. These issues could undermine the integrity and fairness of social psychology [102,105,106,110].\n\nAnother critical concern is the 'black box' nature of LLMs  [105, 107, 131] . This lack of interpretability complicates the application of LLMs in mental health, where trustworthiness and clarity are important. When we talk about neural networks as black boxes, we know what they were trained with, how they were trained, what the weights are, etc. However, with many new LLMs like GPT-3.5/4, researchers and practitioners often access the models via web interfaces or APIs without complete knowledge of the training data, methods, and model updates. This situation not only presents the traditional challenges associated with neural networks but also has all these additional problems that come from the \"hidden\" model. Ethical concern is another significant challenge associated with applying LLMs in mental health. Debates are emerging around issues like digital personhood, informed consent, the risk of manipulation, and the appropriateness of AI in mimicking human interactions  [60, 102, 105, 106, 135] . A primary ethical concern is the potential alteration of the traditional therapist-patient relationship. Individuals may struggle to fully grasp the advantages and disadvantages of LLM derivatives, often choosing these options for their lower cost or greater convenience. This trend could lead to an increased reliance on the emotional support provided by AI  [14] , inadvertently positioning AI as the primary diagnostician and decision-maker for mental health issues, thereby undermining trust in conventional healthcare settings. Moreover, therapists may become overly reliant on LLM-generated answers and use them in clinical decision-making, overlooking the complexities involved in clinical assessment. This reliance could compromise their professional judgment and reduce opportunities for in-depth engagement with patients  [17, 129, 130] . Furthermore, the dehumanization and technocratic nature of mental health care has the potential to depersonalize and dehumanize patients  [136] , where decisions are more driven by algorithms than by human insight and empathy. This can lead to decisions becoming mechanized, lacking empathy, and detached from ethics  [137] . AI systems may fail to recognize or adequately interpret the subtle and often non-verbal cues critical in traditional therapeutic settings  [136] , such as tone of voice, facial expressions, and the emotional weight behind words, which are essential for comprehensively understanding a patient's condition and providing empathetic care.\n\nAdditionally, the current roles and accuracy of LLMs in mental health are limited. For instance, while LLMs can categorize a patient's mood or symptoms, most of these categorizations are binary, such as 'depressed' or 'not depressed'  [50, 65] . This oversimplification can lead to misdiagnoses. Data security and user privacy in clinical settings are also of utmost concern  [14, 54, 60, 96, 130] . Although nearly 70% of psychiatrists believe that managing medical documents will be more efficient using LLMs, many still have concerns about their reliability and privacy  [97, 130, 131] . These concerns could have a devastating impact on patient privacy and undermine the trust between physicians and patients if confidential treatment records stored in LLM databases are compromised. Beyond the technical limitations of AI, the current lack of an industrybenchmarked ethical framework and accountability system hinders the true application of LLMs in clinical practice [131]."
    },
    {
      "title": "4.2.2. Limitations of the Selected Articles",
      "text": "Several limitations were identified in the literature review. A significant issue is the age bias present in the social media data used for depression and mental health screening. Social media platforms tend to attract younger demographics, leading to an underrepresentation of older age groups  [65] . Furthermore, most studies have focused on social media platforms primarily used by English-speaking populations, such as Twitter, which may result in a lack of insight into mental health trends in non-Englishspeaking regions. Our review included studies in Polish, Chinese, Portuguese, and Malay, all of which highlighted significant limitations of LLMs caused by the availability and size of databases  [54, 61, 92, 98, 116] . For instance, due to the absence of a dedicated Polishlanguage mental health database, a Polish study had to rely on machine-translated English databases  [92] . While the LLMs achieve 80% accuracy in categorizing emotions and moods in Polish, this is still lower than the 90% accuracy observed in the original English dataset. This discrepancy highlights that the accuracy of LLMs can be affected by the quality of the database.\n\nAnother limitation of our review is the low diversity of LLMs studied. Although we used 'large language models' as keywords in our search phase, most identified studies primarily focused on BERT and its variants, as well as GPT models. Therefore, this review provides only a limited picture of the variability we might expect in applicability between different LLMs. Additionally, the rapid development of LLM technologies presents a limitation; our study can only reflect current trends and may not encompass future advances or the full potential of LLMs. For instance, in tests involving psychologically relevant questions and answers, ChatGPT 3.5 achieved an accuracy of 66.8%, while ChatGPT 4.0 reached an accuracy of 85%, compared to an average human score of 73.8%  [118] . Evaluating ChatGPT at different stages separately and comparing its performance to that of humans can lead to varied conclusions. In the assessment of prognosis and treatment planning for depression using LLMs, ChatGPT 3.5 demonstrated a distinctly pessimistic prognosis that differed significantly from those of ChatGPT-4, Claude, Bard, and mental health professionals  [128] . Therefore, continuous monitoring and evaluation are essential to fully understand and effectively utilize the advancements in LLM technologies."
    },
    {
      "title": "4.3. Opportunities and Future Work",
      "text": "Implementing technologies involving LLMs within the healthcare provision of real patients demands thorough and multi-faceted evaluations. It is imperative for both industry and researchers to not let rollout exceed proportional requirements for evidence on safety and efficacy. At the level of the service provider, this includes providing explicit warnings to the public to discourage mistaking LLM functionality for clinical reliability. For example, ChatGPT-4 introduced the ability to process and interpret image inputs within conversational contexts, leading OpenAI to issue an official warning that ChatGPT-4 is not approved for analyzing specialized medical images, such as CT scans  [138] .\n\nA key challenge to address in LLM research is the tendency to produce incoherent text or hallucinations. Future efforts could focus on training LLMs specifically for mental health applications, using datasets with expert labeling to reduce bias and create specialized mental health lexicons  [84, 102, 116] . The creation of specialized datasets could take advantage of the customizable nature of LLMs, fostering the development of models that cater to the distinct needs of varied demographic groups. For instance, unlike models designed for healthcare professionals which assist in tasks like data documentation, symptom analysis, medication management, and postoperative care, LLMs intended for patient interaction might be trained with an emphasis on empathy and comfortable dialogue.\n\nAnother critical concern is the problem of outdated training data in LLMs. Traditional LLMs, such as GPT-4 (with a cut-off in October 2023), rely on potentially outdated training data, limiting their ability to incorporate recent events or information. This can compromise the accuracy and relevance of their responses, leading to the generation of uninformative or incorrect answers, known as 'hallucinations  ' [139] . RAG (Retrieval-Augmented Generation) technology offers a solution by retrieving facts from external knowledge bases, ensuring that LLMs use the most accurate and up-to-date information  [140] . By searching for relevant information from numerous documents, RAG enhances the generation process with the most recent and contextually relevant content  [141] . Additionally, RAG includes evidence-based information, increasing the reliability and credibility of LLM responses  [139] .\n\nTo further enhance the reliability of LLM content and minimize hallucinations, recent studies suggest adjusting model parameters, such as the 'temperature' setting  [142] [143] [144] . The 'temperature' parameter influences the randomness and predictability of outputs  [145] . Lowering the temperature typically results in more deterministic outputs, enhancing coherence and reducing irrelevant content  [146] . However, this adjustment can also limit the model's creativity and adaptability, potentially making it less effective in scenarios requiring diverse or nuanced responses. In mental therapy, where nuanced and sensitive responses are essential, maintaining an optimal balance is crucial. While a lower temperature can ensure accuracy, which is important for tasks like clinical documentation, it may not suit therapeutic dialogs where personalized engagement is key. Low temperatures can lead to repetitive and impersonal responses, reducing patient engagement and therapeutic effectiveness. To mitigate these risks, regular updates of the model incorporating the latest therapeutic practices and clinical feedback are essential. Such updates could refine the model's understanding and response mechanisms, ensuring it remains a safe and effective tool for mental health care. Nevertheless, determining the 'optimal' temperature setting is challenging, primarily due to the variability in tasks and interaction contexts which require different levels of creativity and precision.\n\nData privacy is another important area of concern. Many LLMs, such as ChatGPT and Claude, involve sending data to third-party servers, which poses the risk of data leakage. Current studies have found that LLMs can be enhanced by Privacy Enhancing Techniques, such as zero-knowledge proofs, differential privacy, and federated learning  [147] . Additionally, privacy can be preserved by replacing identifying information in textual data with generic tokens. For example, when recording sensitive information (e.g., names, addresses, or credit card numbers), using alternatives to mask tokens can help protect user data from unauthorized access  [148] . This obfuscation technique ensures that sensitive user information is not stored directly, thereby enhancing data security.\n\nThe lack of interpretability in LLM decision-making is another crucial area for future research on healthcare applications. Future research should examine the models' architecture, training, and inferential processes for clearer understanding. Detailed documentation of training datasets, sharing of model architectures, and third-party audits would ideally form part of this undertaking. Investigating techniques like attention mechanisms and modular architectures could illuminate aspects of neural network processing. The implementation of knowledge graphs might help in outlining logical relationships and facts  [149] . Additionally, another promising approach involves creating a dedicated embedding space during training, guided by an LLM. This space aligns with a causal graph and aids in identifying matches that approximate counterfactuals  [150] .\n\nBefore deploying LLMs in mental health settings, a comprehensive assessment of their reliability, safety, fairness, abuse resistance, interpretability, compliance with social norms, robustness, performance, linguistic accuracy, and cognitive ability is essential. It is also crucial to foster collaborative relationships among mental health professionals, patients, AI researchers, and policymakers. LLMs, for instance, have demonstrated initial competence in providing medication advice, yet their responses can sometimes be inconsistent or include inappropriate suggestions. As such, LLMs require professional oversight and should not be used independently. However, when utilized as decision aids, LLMs have the potential to enhance healthcare efficiency. We call on developers of LLMs to collaborate with authoritative regulators in actively developing ethical guidelines for AI research in healthcare. These guidelines should aim to adopt a balanced approach that considers the multifaceted nature of LLMs and ensures their responsible integration into medical practice. They are expected to become industry benchmarks, facilitating the future development of LLMs in mental health."
    },
    {
      "title": "4.4. Conclusion",
      "text": "This review examines the use of LLMs in mental health applications, including text-based screening for mental health conditions, detection of suicidal ideation, CAs, clinical use, and other related applications. Despite their potential, challenges such as the production of hallucinatory or harmful information, output inconsistency, and ethical concerns remain. Nevertheless, as technology advances and ethical guidelines improve, LLMs are expected to become increasingly integral and valuable in mental health services, providing alternative solutions to this global healthcare issue."
    },
    {
      "title": "4.5. Contributors",
      "text": "ZG and KL contributed to the conception and design of the study. ZG, KL, and AL also contributed to the development of the search strategy. Database search outputs were screened by ZG, and data were extracted by ZG and KL. An assessment of the risk of bias in the included studies was performed by ZG and KL. ZG completed the literature review, collated the data, performed the data analysis, interpreted the results, and wrote the first draft of the manuscript. KL, AL, JHT, JF, and TK reviewed the manuscript and provided multiple rounds of guidance in the writing of the manuscript. All authors read and approved the final version of the manuscript."
    },
    {
      "title": "6.. Multimedia Appendix 2 Supplementary material 2: List of studies excluded at the full-text screening stage",
      "text": "T A ovel A -based chatbot Application for ersonalized Medical ia nosis and review usin Lar e Lan ua e Models ( et al., 3) ot about mental health An ntroduction to Generative Artificial ntelli ence in Mental Health are: onsiderations and Guidance (Kin et al., 3) ot only for mental health 3 Artificial ntelli ence Based Analysis of ositive and e ative Tweets Towards V -Vaccines (Umair & Masciari, ) ot about mental health Artificial ntelli ence in sychiatry (Bri anti, 3) ot about LLMs Assessin the Accuracy of esponses by the Lan ua e Model hatG T to Questions e ardin Bariatric ur ery ( amaan et al., 3) ot about mental health 6 hatG T and Bard hibit pontaneous itation Fabrication durin sychiatry Literature earch (McGowan et al., 3) ot about mental health hatG T and mental healthcare: balancin benefits with risks of harms (Blease & Torous, 3) t's a review paper, too short hatG T in Answerin Queries elated to Lifestyle-elated iseases and isorders (Mondal et al., 3) ot about mental health hatG T on T: an Lar e Lan ua e Models upport sychoeducation? (Lundin et al., 3) t's a letter, t's too short hatG T vs Goo le for Queries elated to ementia and ther o nitive ecline: omparison of esults (Hristidis et al., 3) ementia is not considered a mental illness hatG T vs. Human Annotators: A omprehensive Analysis of hatG T for Te t Annotation (Aldeen et al., 3) ot about mental health onversational A ents in Health are: pert nterviews to nform the efinition, lassification, and onceptual Framework (Martinen o et al., 3) ot about LLMs 3 ia nosin sychiatric isorders from History of resent llness Usin a Lar e-cale Lin uistic Model ( tsuka et al., 3) ot about LLMs iscourse-Level epresentations an mprove rediction of e ree of An iety ( uhn et al., 3) uplicate mpathy and quity: Key onsiderations for Lar e Lan ua e Model Adoption in Health are (Koranten et al., 3) ot about mental health 6 thical hallen es in A Approaches to atin isorders ( harp et al., 3) ot about LLMs valuatin the Application of Lar e Lan ua e Models in linical esearch onte ts ( erlis & Fihn, 3) t's a review paper, too short aminin the Utility of ocial Media in V -Vaccination: Unsupervised Learnin of 6 , 33 Twitter osts (Liew & Lee, ) ot about LLMs Global Mental Health ervices and the mpact of Artificial ntelli enceowered Lar e Lan ua e Models (van Heerden et al., 3) t's a review paper, too short Grateful hatbots: ublic ensemakin throu h ndividual Gratitude nterventions ( chuler & ortmann, 3) ot about mental health dentifyin are ircumstances recedin Female Firearm uicides: Validatin A Lar e Lan ua e Model Approach (Zhou et al., 3) ot about mental health The mpact of Multimodal Lar e Lan ua e Models on Health are's Future (Mesk\u00f3, 2023) ot about mental health 3 Lar e Lan ua e Models in Medical ducation: pportunities, hallen es, and Future irections (Abd-alrazaq et al., 3) ot about mental health Lin uistic Features of lients and ounselors for arly etection of Mental Health ssues in nline Te t-based ounselin ( hidara et al., ) ot about LLMs Mental Health rediction from ocial Media Te t Usin Mi ture of perts ( antos et al., 3) uplicate 6 e atively orrelated oisy Learners for At-isk User etection on ocial etworks: A tudy on epression, Anore ia, elf-Harm, and uicide ( a heb et al., 3) uplicate erformance of hatG T on the ituational ud ement Test-A rofessional ilemmas-Based amination for octors in the United Kin dom (Borchert et al., 3) ot about mental health redictin Generalized An iety isorder from mpromptu peech Transcripts Usin onte t-Aware Transformer-Based eural etworks: Model valuation tud (Teferra & ose, 3) ot about LLMs sycholo ical nsi hts into The esearch and ractice of mbodied onversational A ents, hatbots and ocial Assistive obots: A ystematic Meta-eview (Kiuchi et al., 3) ot about LLMs 3 Automatic ratin of therapist facilitative interpersonal skills in te t: A natural lan ua e processin application (Zech et al., ) ot about mental health 3 ocial Media ma es an redict uicide isk Usin nterpretable Lar e Lan ua e-Vision Models (Badian et al., 3) uplicate 3 ystematic review and meta-analysis of A -based conversational a ents for promotin mental health and well-bein (Li et al., 3) ot about LLMs 33 Te t ialo ue Analysis for rimary creenin of Mild o nitive mpairment: evelopment and Validation tudy ( . Wan et al., 3) ot about mental health 3 The mpact of Multimodal Lar e Lan ua e Models on Health are's Future (Mesk\u00f3, 2023) ot about mental health 3 Transformer-based deep neural network lan ua e models for Alzheimer's disease risk assessment from tar eted speech ( oshanzamir et al., ) ot about mental health 36 Understandin ysle ia Throu h ersonalized Lar e-cale omputational Models ( erry et al., ) ot about mental health 3 Usin Generative Artificial ntelli ence to lassify rimary ro ressive Aphasia from onnected peech ( ezaii et al., 3) t's preprint 3 Waitin for A i ital Therapist: Three hallen es on the ath to sychotherapy elivered by Artificial ntelli ence (Grodniewicz & Hohol, 3) ot about LLMs 3 A Transfer Learnin Method for etectin Alzheimer's isease Based on peech and atural Lan ua e rocessin (Liu et al., ) ot about mental health Acoustic and Lin uistic Analyses to Assess arly-nset and Genetic Alzheimer's isease ( \u00e9rez-Toro et al., ) ot about mental health Usin a hatbot to rovide Formative Feedback: A Lon itudinal tudy of ntrinsic Motivation, o nitive Load, and Learnin erformance (Yin et al., ) uplicate Levera in Lar e Lan ua e Models for mproved atient Access and elf-Mana ement: Assessor-Blinded omparison Between pert-and A -Generated ontent (Lv et al., ) ot about mental health 3 valuation of rompts to implify ardiovascular isease nformation Generated Usin a Lar e Lan ua e Model: ross-ectional tudy (Mishra et al., ) ot about mental health valuation of the erformance of Generative A Lar e Lan ua e Models hatG T, Goo le Bard, and Microsoft Bin hat in upportin vidence-Based entistry: omparative Mi ed Methods tudy (Giannakopoulos et al., 3) ot about mental health Beyond iscrimination: Generative A Applications and thical hallen es in Forensic sychiatry (Tortora, ) ot about LLMs 6 Assessin the Ali nment of Lar e Lan ua e Models With Human Values for Mental Health nte ration: ross-ectional tudy Usin chwartz's Theory of Basic Values (Hadar-hoval et al., ) ot about mental health epression and eciprocal Lan ua e tyle Matchin in Te t Messa es (Weinstein and ensen, ) ot about LLMs \" Have a ifferent erspective as Am Workin Throu h This\" peech-Lan ua e atholo ist eflections on Autism ( eThorne et al., ) ot about LLMs Artificial ntelli ence in Medical ducation: omparative Analysis of hatG T, Bin , and Medical tudents in Germany ( oos et al., 3) ot about mental health An ntity traction ipeline for Medical Te t ecords Usin Lar e Lan ua e Models: Analytical tudy (Wan et al., ) ot about mental health A Transformer based Approach for nterpretin epressed and uicidal User Behavior on nline ocial etworks (Malhotra and indal, ) uplicate University tudents' Acceptance and Usa e of Generative A ( hatG T) from a sycho-Technical erspective (Faruk et al., 3) ot about mental health 3 Fairness valuation Within Lar e Lan ua e Models throu h the Lens of epression (Han, ) Too short A Machine Learnin nabled Approach for Mental and hysical Health Mana ement Usin pen V, L and T ( ane et al., ) ot about LLMs Machine Feelin by Knowled e Acquisition with motion Map (Lim et al., ) ot about LLMs 6 valuatin motional etection & lassification apabilities of G T-& G T-eo Usin Te tual ata ( ain et al., ) uplicate evelopment of erious Game Theory Framework in Virtual eality for Alzheimer's atients (Zuo et al., ) ot about LLMs alibration of Transformer-Based Models for dentifyin tress and epression in ocial Media ( lias et al., 3) uplicate ALT U T: a ython packa e to emulate a Virtual i ital ohort tudy usin social media data (Bour et al., ) ot about LLMs 6 Lar e Lan ua e Models and Healthcare Alliance: otential and hallen es of Two epresentative Use ases (Garc\u00eda-M\u00e9ndez and de Arriba-\u00e9rez, ) ot about mental health 6 A latform for onnectin ocial Media ata to omain-pecific Topics Usin Lar e Lan ua e Models: An Application to tudent Mental Health ( uocco et al., ) uplicate Table : tudies e cluded after full-te t screenin . LLMs lar e lan ua e models INTRODUCTION Rationale 3 Describe the rationale for the review in the context of existing knowledge. Introduction-Pg 2-6 Objectives 4 Provide an explicit statement of the objective(s) or question(s) the review addresses. Introduction-Pg 6"
    },
    {
      "title": "METHODS"
    },
    {
      "title": "Eligibility criteria",
      "text": "5 Specify the inclusion and exclusion criteria for the review and how studies were grouped for the syntheses.\n\nMethods-Pg 7-8\n\nInformation sources 6 Specify all databases, registers, websites, organisations, reference lists and other sources searched or consulted to identify studies. Specify the date when each source was last searched or consulted.\n\nMethods-Pg 7-8\n\nSearch strategy 7 Present the full search strategies for all databases, registers and websites, including any filters and limits used.\n\nMethods-Pg 6-7\n\nSelection process 8 Specify the methods used to decide whether a study met the inclusion criteria of the review, including how many reviewers screened each record and each report retrieved, whether they worked independently, and if applicable, details of automation tools used in the process.\n\nMethods-Pg 7-8 Data collection process\n\n9 Specify the methods used to collect data from reports, including how many reviewers collected data from each report, whether they worked independently, any processes for obtaining or confirming data from study investigators, and if applicable, details of automation tools used in the process.\n\nMethods-Pg 8-9\n\nData items 10a List and define all outcomes for which data were sought. Specify whether all results that were compatible with each outcome domain in each study were sought (e.g. for all measures, time points, analyses), and if not, the methods used to decide which results to collect.\n\nMethods-Pg 8\n\n10b List and define all other variables for which data were sought (e.g. participant and intervention characteristics, funding sources). Describe any assumptions made about any missing or unclear information."
    },
    {
      "title": "Methods-Pg 8",
      "text": "Study risk of bias assessment\n\n11 Specify the methods used to assess risk of bias in the included studies, including details of the tool(s) used, how many reviewers assessed each study and whether they worked independently, and if applicable, details of automation tools used in the process.\n\nMethods-Pg 7; Multimedia Appendix 1"
    },
    {
      "title": "Effect measures",
      "text": "12 Specify for each outcome the effect measure(s) (e.g. risk ratio, mean difference) used in the synthesis or presentation of results."
    },
    {
      "title": "Methods-Pg 8",
      "text": "Synthesis methods 13a Describe the processes used to decide which studies were eligible for each synthesis (e.g. tabulating the study intervention characteristics and comparing against the planned groups for each synthesis (item #5)).\n\nMethods-Pg 7-8\n\n13b Describe any methods required to prepare the data for presentation or synthesis, such as handling of missing summary statistics, or data conversions.\n\nMethods-Pg 8\n\n13c Describe any methods used to tabulate or visually display results of individual studies and syntheses.\n\nMethods-Pg 7-8\n\n13d Describe any methods used to synthesize results and provide a rationale for the choice(s). If metaanalysis was performed, describe the model(s), method(s) to identify the presence and extent of statistical heterogeneity, and software package(s) used.\n\nMethods-Pg 7-8\n\n13e Describe any methods used to explore possible causes of heterogeneity among study results (e.g. subgroup analysis, meta-regression).\n\nMethods-Pg 8\n\n13f Describe any sensitivity analyses conducted to assess robustness of the synthesized results."
    },
    {
      "title": "Reporting bias assessment",
      "text": "14 Describe any methods used to assess risk of bias due to missing results in a synthesis (arising from reporting biases)."
    },
    {
      "title": "Methods-Pg 7",
      "text": "Certainty assessment\n\n15 Describe any methods used to assess certainty (or confidence) in the body of evidence for an outcome.\n\nMethods-Pg 7-8"
    },
    {
      "title": "RESULTS"
    },
    {
      "title": "Study selection",
      "text": "16a Describe the results of the search and selection process, from the number of records identified in the search to the number of studies included in the review, ideally using a flow diagram.\n\nResults-Pg 9-10 and other materials 27 Report which of the following are publicly available and where they can be found: template data collection forms; data extracted from included studies; data used for all analyses; analytic code; any other materials used in the review.\n\nData sharing statement-Pg 30"
    },
    {
      "text": "Figure 1. Comparative analysis of LLMs by parameter size and developer entity. The bar chart"
    },
    {
      "text": "Figure 2. PRISMA flow of selection process."
    },
    {
      "text": "Figure 3. Number of articles included in this literature review, grouped by year of publication and application field. The black line indicates the total number of articles in each year."
    },
    {
      "text": ", Birrell L, Kershaw , evine K, Thornton L. an we use hatG T for mental health and substance use education? e aminin its quality and potential harms. M Medical ducation M ublications nc.; 3; . M :3 3 103. racks in the ce. vidence-Based nformation for the ommunity. racks in the ce.Available from: https: cracksintheice.or .au [accessed Apr , ] 104. ositive hoices: ru and Alcohol ducation -Get informed, stay smart, stay safeositive hoices. Available from: https: positivechoices.or .au [accessed Apr , ] 105. Farhat F. hatG T as a complementary mental health resource: a boon or a bane. Ann"
    },
    {
      "text": "/www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset [accessed Aug 6, 2024] 78. Ghanadian H, Nejadgholi I, Al Osman H. Socially aware synthetic data generation for suicidal ideation detection using large language models. IEEE Access 2024 Jan 22;PP. doi: 10.1109/ACCESS.2024.3358206 79. FLAN-T5. Available from: https://huggingface.co/docs/transformers/model_doc/flan-t5 [accessed Aug 6, 2024] 80. H. Ghanadian, . ejad holi and H. Al sman, \" hatG T for suicide risk assessment on social media: Quantitative evaluation of model performance potentials and limitations\", arXiv:2306.09390, 3 81. Lossio-Ventura JA, Weger R, Lee AY, Guinee EP, Chung J, Atlas L, Linos E, Pereira F. A comparison of ChatGPT and fine-tuned open pre-trained transformers (OPT) against widely used sentiment analysis tools: sentiment analysis of COVID-19 survey data. JMIR Ment Health 2024 Jan 25;11:e50150. PMID:38271138 82. hun Y, Gibbons A, Atlas L, Ballard , rnst M, apee , et al. V -and mental health: predicted mental health status is associated with clinical symptoms and pandemic-related psycholo ical and behavioral responses. med iv. ct . [ reprint] 83. elson LM, imard F, luyomi A, ava V, osas LG, Bondy M, et al. U public concerns about the V -pandemic from results of a survey iven via social media. -A, n , esurreccion . Therapist vibe: children's e pressions of their emotions throu h storytellin with a chatbot. roceedin s of the nteraction esi n and hildren onference ew York, Y, U A: Association for omputin Machinery; . p. 3-. doi: . 33 63.33 86. odri o M. Towards buildin mental health resilience throu h storytellin with a chatbot. roceedin s of the th nternational onference on omputers in ducation Montene ro , n . nvesti atin the acceptability and perceived effectiveness of a chatbot in helpin students assess their well-bein . roceedin s of the Asian H ymposium ew York, Y, U A: Association for omputin Machinery; . p. 3 -. doi: . 3 36 .3 6 90. H. A. chwartz, M. ap, M. L. Kern, . . ichstaedt, A. Kapelner, M. A rawal, et al., \" redictin individual well-bein throu h the lan ua e of social media\", Biocomputin 6: roceedin s of the acific ymposium, pp. 6-, 6 91. rasto , ias L, Miranda , Kayande . areBot: A mental health chatbot. A latform. uperior ustomer periences tart Here. Available from: https: rasa.com [accessed Apr , ] 94. spa y \u2022 ndustrial-stren th atural Lan ua e rocessin in ython. Available from: https: spacy.io [accessed Apr , ] 95. Li Y, u H, hen , Li W, ao Z, iu . aily ialo : A manually labelled multi-turn dialo ue dataset. ar iv; . doi: . ar iv. . 3 [ reprint] 96. Heston TF. afety of lar e lan ua e models in addressin depression. ureus ( ):e . M :3 3 97. Alessa A, Al-Khalifa H. Towards designing a ChatGPT conversational companion for elderly people. Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments New York, NY, USA: Association for Computing Machinery; 2023. p. 667-674. doi: 10.1145/3594806.3596572 98. He W, Zhang W, Jin Y, Zhou Q, Zhang H, Xia Q. Physician versus large language model chatbot responses to web-based questions from autistic patients in Chinese: cross-sectional comparative analysis. J Med Internet Res 2024 Apr 30;26:e54706. PMID:38687566 99. Deng Z, Liu S, Evans R. Knowledge transfer between physicians from different geographical regions in China's online health communities. Inf Technol Manag. 2023.:1-18 100. Franco ' ouza , Amanullah , Mathew M, urapaneni KM. Appraisin the performance of hatG T in psychiatry usin clinical case vi nettes. Asian ournal of sychiatry 3 ov ; : 3 . doi: . 6 j.ajp. 3. 3 101. Wri ht B, ave , o ra . cases in psychiatry. nd ed. Boca aton: ress; . doi: ."
    },
    {
      "title": "Availability of data, code"
    },
    {
      "title": "4.6. Acknowledgements",
      "text": "This work was funded by the UKRI Centre for Doctoral Training in AI-enabled healthcare systems (grant EP/S021612/1). The funders were not involved in the study design, data collection, analysis, publication decisions, or manuscript writing. The views expressed in the text are those of the authors and not those of the funder."
    },
    {
      "title": "4.7. Conflicts of Interest",
      "text": "The authors declare no conflict of interest."
    },
    {
      "title": "4.8. Data sharing statement",
      "text": "The authors ensure that all pertinent data have been incorporated within the article and/or its supplementary materials. For access to the research data, interested parties may contact the corresponding author, Kezhi Li (ken.li@ucl.ac.uk), subject to a reasonable request."
    },
    {
      "title": "4.9. Abbreviations"
    },
    {
      "title": "5.. Multimedia Appendix 1 Supplementary material 1: Risk of bias assessment"
    }
  ],
  "references": [
    {
      "title": "Mental health: strengthening our response",
      "year": 2022,
      "raw": "Mental health: strengthening our response \n\t\t \n\t\t\t World Health Organization \n\t\t\t 2022. Apr 15, 2024 \n\t\t \n\t \n\t World Health Organization. Mental health: strengthening our response. 2022. Available from: https://www.who.int/news-room/fact-sheets/detail/mental-health-strengthening- our-response [accessed Apr 15, 2024]"
    },
    {
      "title": "Mental disorders",
      "year": 2022,
      "doi": "10.2471/b09329",
      "raw": "Mental disorders \n\t\t 10.2471/b09329 \n\t\t \n\t\t \n\t\t\t 2022. Apr 15, 2024 \n\t\t\t World Health Organization \n\t\t \n\t \n\t World Health Organization. Mental disorders. 2022. Available from: https://www.who.int/news-room/fact-sheets/detail/mental-disorders [accessed Apr 15, 2024]"
    },
    {
      "title": "MHPSS worldwide: facts and figures -Mental health and psychosocial support in crisis situations",
      "year": 2023,
      "doi": "10.1007/978-94-015-3598-4_5",
      "raw": "MHPSS worldwide: facts and figures -Mental health and psychosocial support in crisis situations \n\t\t \n\t\t\t Zaken M Van A \n\t\t \n\t\t 10.1007/978-94-015-3598-4_5 \n\t\t \n\t\t \n\t\t\t 2023. Apr 15, 2024 \n\t\t\t Ministerie van Algemene Zaken \n\t\t \n\t \n\t Zaken M van A. MHPSS worldwide: facts and figures -Mental health and psychosocial support in crisis situations. Ministerie van Algemene Zaken; 2023. Available from: https://www.government.nl/topics/mhpss/mhpss-worldwide-facts-and-figures [accessed Apr 15, 2024]"
    },
    {
      "title": "Quantifying the global burden of mental disorders and their economic value",
      "authors": [
        "D Arias",
        "S Saxena",
        "S Verguet"
      ],
      "year": 2022,
      "doi": "10.1016/j.eclinm.2022.101675",
      "journal": "eClinicalMedicine Elsevier",
      "volume": "54",
      "raw": "Quantifying the global burden of mental disorders and their economic value \n\t\t \n\t\t\t D Arias \n\t\t \n\t\t \n\t\t\t S Saxena \n\t\t \n\t\t \n\t\t\t S Verguet \n\t\t \n\t\t 10.1016/j.eclinm.2022.101675 \n\t\t 36193171 \n\t \n\t \n\t\t eClinicalMedicine Elsevier \n\t\t \n\t\t\t 54 \n\t\t\t 2022 Dec 1 \n\t\t \n\t \n\t Arias D, Saxena S, Verguet S. Quantifying the global burden of mental disorders and their economic value. eClinicalMedicine Elsevier; 2022 Dec 1;54. PMID:36193171"
    },
    {
      "title": "Detecting individuals with severe mental illness using artificial intelligence applied to magnetic resonance imaging",
      "authors": [
        "W Zhang",
        "C Yang",
        "Z Cao",
        "Z Li",
        "L Zhuo",
        "Y Tan",
        "Y He",
        "L Yao",
        "Q Zhou",
        "Q Gong",
        "J Sweeney",
        "F Shi",
        "S Lui"
      ],
      "year": 2023,
      "doi": "10.1016/j.ebiom.2023.104541",
      "journal": "eBioMedicine Elsevier",
      "volume": "90",
      "raw": "Detecting individuals with severe mental illness using artificial intelligence applied to magnetic resonance imaging \n\t\t \n\t\t\t W Zhang \n\t\t \n\t\t \n\t\t\t C Yang \n\t\t \n\t\t \n\t\t\t Z Cao \n\t\t \n\t\t \n\t\t\t Z Li \n\t\t \n\t\t \n\t\t\t L Zhuo \n\t\t \n\t\t \n\t\t\t Y Tan \n\t\t \n\t\t \n\t\t\t Y He \n\t\t \n\t\t \n\t\t\t L Yao \n\t\t \n\t\t \n\t\t\t Q Zhou \n\t\t \n\t\t \n\t\t\t Q Gong \n\t\t \n\t\t \n\t\t\t J A Sweeney \n\t\t \n\t\t \n\t\t\t F Shi \n\t\t \n\t\t \n\t\t\t S Lui \n\t\t \n\t\t 10.1016/j.ebiom.2023.104541 \n\t\t 36996601 \n\t \n\t \n\t\t eBioMedicine Elsevier \n\t\t \n\t\t\t 90 \n\t\t\t 2023 Apr 1 \n\t\t \n\t \n\t Zhang W, Yang C, Cao Z, Li Z, Zhuo L, Tan Y, He Y, Yao L, Zhou Q, Gong Q, Sweeney JA, Shi F, Lui S. Detecting individuals with severe mental illness using artificial intelligence applied to magnetic resonance imaging. eBioMedicine Elsevier; 2023 Apr 1;90. PMID:36996601"
    },
    {
      "title": "Mental health and COVID-19: Early evidence of the pandemic's impact: cientific brief",
      "year": 2022,
      "doi": "10.2471/b09131",
      "raw": "10.2471/b09131 \n\t\t \n\t\t Mental health and COVID-19: Early evidence of the pandemic's impact: cientific brief \n\t\t \n\t\t\t World Health Organization \n\t\t\t 2022 Mar 2. Apr 15, 2024 \n\t\t \n\t \n\t World Health Organization. Mental health and COVID-19: Early evidence of the pandemic's impact: cientific brief . 2022 Mar 2. Available from: https://www.who.int/publications/i/item/WHO-2019-nCoV-Sci_Brief-Mental_health- 2022.1 [accessed Apr 15, 2024]"
    },
    {
      "title": "Global impact of the COVID-19 pandemic on mental health services: A systematic review",
      "authors": [
        "G Duden",
        "S Gersdorf",
        "K Stengler"
      ],
      "year": 2022,
      "doi": "10.1016/j.jpsychires.2022.08.013",
      "journal": "J Psychiatr Res",
      "volume": "154",
      "raw": "Global impact of the COVID-19 pandemic on mental health services: A systematic review \n\t\t \n\t\t\t G S Duden \n\t\t \n\t\t \n\t\t\t S Gersdorf \n\t\t \n\t\t \n\t\t\t K Stengler \n\t\t \n\t\t 10.1016/j.jpsychires.2022.08.013 \n\t\t 36055116 \n\t \n\t \n\t\t J Psychiatr Res \n\t\t \n\t\t\t 154 \n\t\t\t \n\t\t\t 2022 Oct \n\t\t \n\t \n\t Duden GS, Gersdorf S, Stengler K. Global impact of the COVID-19 pandemic on mental health services: A systematic review. J Psychiatr Res 2022 Oct;154:354-377. PMID:36055116"
    },
    {
      "title": "Mental health treatments",
      "year": 2023,
      "doi": "10.7748/mhp2011.10.15.2.4.p6451",
      "raw": "Mental health treatments \n\t\t 10.7748/mhp2011.10.15.2.4.p6451 \n\t\t \n\t\t \n\t\t\t 2023. Apr 15, 2024 \n\t\t\t Mental Health America \n\t\t \n\t \n\t Mental Health America. Mental health treatments. 2023. Available from: https://mhanational.org/mental-health-treatments [accessed Apr 15, 2024]"
    },
    {
      "title": "Stigma, prejudice and discrimination against people with mental illness",
      "year": 2024,
      "doi": "10.1093/med/9780198570981.003.0009",
      "raw": "10.1093/med/9780198570981.003.0009 \n\t\t \n\t\t Stigma, prejudice and discrimination against people with mental illness \n\t\t \n\t\t\t Apr 15, 2024 \n\t\t \n\t \n\t Stigma, prejudice and discrimination against people with mental illness. Available from: https://www.psychiatry.org:443/patients-families/stigma-and-discrimination [accessed Apr 15, 2024]"
    },
    {
      "title": "Why do people avoid mental health treatment? Thriveworks",
      "year": 2019,
      "raw": "Why do people avoid mental health treatment? Thriveworks \n\t\t \n\t\t\t 2019. Apr 15, 2024 \n\t\t \n\t \n\t Why do people avoid mental health treatment? Thriveworks. 2019. Available from: https://thriveworks.com/blog/why-people-avoid-mental-health-treatment/ [accessed Apr 15, 2024]"
    },
    {
      "title": "Almost half of Americans don't seek professional help for mental disorders",
      "year": 2024,
      "doi": "10.1037/e616352011-114",
      "raw": "10.1037/e616352011-114 \n\t\t \n\t\t Almost half of Americans don't seek professional help for mental disorders \n\t\t \n\t\t\t Apr 15, 2024 \n\t\t \n\t \n\t Almost half of Americans don't seek professional help for mental disorders. Available from: https://www.forbes.com/sites/michaeltnietzel/2021/05/24/why-so-many- americans-do-not-seek-professional-help-for-mental-disorders/?sh=55b4ec4b3de7 [accessed Apr 15, 2024]"
    },
    {
      "title": "Digital mental health and COVID-19: using technology today to accelerate the curve on access and quality tomorrow",
      "authors": [
        "J Torous",
        "K Myrick",
        "N Rauseo-Ricupero",
        "J Firth"
      ],
      "year": 2020,
      "journal": "JMIR Ment Health",
      "volume": "7",
      "issue": "3",
      "pages": "18848",
      "raw": "Digital mental health and COVID-19: using technology today to accelerate the curve on access and quality tomorrow \n\t\t \n\t\t\t J Torous \n\t\t \n\t\t \n\t\t\t K J Myrick \n\t\t \n\t\t \n\t\t\t N Rauseo-Ricupero \n\t\t \n\t\t \n\t\t\t J Firth \n\t\t \n\t \n\t \n\t\t JMIR Ment Health \n\t\t \n\t\t\t 7 \n\t\t\t 3 \n\t\t\t 18848 \n\t\t\t 2020 \n\t\t \n\t \n\t Torous J, Myrick KJ, Rauseo-Ricupero N, Firth J. Digital mental health and COVID- 19: using technology today to accelerate the curve on access and quality tomorrow. JMIR Ment Health. 2020;7(3):e18848."
    },
    {
      "title": "Largelanguage-models (LLM)-based AI chatbots: architecture, in-depth analysis and their performance evaluation",
      "authors": [
        "V Kumar",
        "P Srivastava",
        "A Dwivedi",
        "I Budhiraja",
        "D Ghosh",
        "V Goyal",
        "R Arora"
      ],
      "year": 2024,
      "doi": "10.1007/978-3-031-53085-2_20",
      "raw": "Largelanguage-models (LLM)-based AI chatbots: architecture, in-depth analysis and their performance evaluation \n\t\t \n\t\t\t V Kumar \n\t\t \n\t\t \n\t\t\t P Srivastava \n\t\t \n\t\t \n\t\t\t A Dwivedi \n\t\t \n\t\t \n\t\t\t I Budhiraja \n\t\t \n\t\t \n\t\t\t D Ghosh \n\t\t \n\t\t \n\t\t\t V Goyal \n\t\t \n\t\t \n\t\t\t R Arora \n\t\t \n\t\t 10.1007/978-3-031-53085-2_20 \n\t \n\t \n\t\t Recent Trends in Image Processing and Pattern Recognition Cham \n\t\t \n\t\t\t K Santosh \n\t\t \n\t\t \n\t\t\t A Makkar \n\t\t \n\t\t \n\t\t\t M Conway \n\t\t \n\t\t \n\t\t\t A K Singh \n\t\t \n\t\t \n\t\t\t A Vacavant \n\t\t \n\t\t \n\t\t\t Abou El Kalam \n\t\t \n\t\t \n\t\t\t A Bouguelia \n\t\t \n\t\t \n\t\t\t M-R Hegadi \n\t\t \n\t\t \n\t\t\t R \n\t\t \n\t\t Switzerland \n\t\t \n\t\t\t Springer Nature \n\t\t\t 2024 \n\t\t\t \n\t\t \n\t \n\t Kumar V, Srivastava P, Dwivedi A, Budhiraja I, Ghosh D, Goyal V, Arora R. Large- language-models (LLM)-based AI chatbots: architecture, in-depth analysis and their performance evaluation. In: Santosh K, Makkar A, Conway M, Singh AK, Vacavant A, Abou el Kalam A, Bouguelia M-R, Hegadi R, editors. Recent Trends in Image Processing and Pattern Recognition Cham: Springer Nature Switzerland; 2024. p. 237- 249. doi: 10.1007/978-3-031-53085-2_20"
    },
    {
      "title": "Understanding the benefits and challenges of using large language model-based conversational agents for mental well-being support",
      "authors": [
        "Z Ma",
        "Y Mei",
        "Z Su"
      ],
      "year": 2024,
      "doi": "10.1145/3613904.3642482",
      "journal": "AMIA Annu Symp Proc",
      "volume": "2023",
      "raw": "Understanding the benefits and challenges of using large language model-based conversational agents for mental well-being support \n\t\t \n\t\t\t Z Ma \n\t\t \n\t\t \n\t\t\t Y Mei \n\t\t \n\t\t \n\t\t\t Z Su \n\t\t \n\t\t 10.1145/3613904.3642482 \n\t\t 38222348 \n\t \n\t \n\t\t AMIA Annu Symp Proc \n\t\t \n\t\t\t 2023 \n\t\t\t \n\t\t\t 2024 Jan 11 \n\t\t \n\t \n\t Ma Z, Mei Y, Su Z. Understanding the benefits and challenges of using large language model-based conversational agents for mental well-being support. AMIA Annu Symp Proc 2024 Jan 11;2023:1105-1114. PMID:38222348"
    },
    {
      "title": "Towards interpretable mental health analysis with large language models",
      "authors": [
        "K Yang",
        "S Ji",
        "T Zhang",
        "Q Xie",
        "Z Kuang",
        "S Ananiadou"
      ],
      "doi": "10.48550/arXiv.2304.03347",
      "raw": "Towards interpretable mental health analysis with large language models \n\t\t \n\t\t\t K Yang \n\t\t \n\t\t \n\t\t\t S Ji \n\t\t \n\t\t \n\t\t\t T Zhang \n\t\t \n\t\t \n\t\t\t Q Xie \n\t\t \n\t\t \n\t\t\t Z Kuang \n\t\t \n\t\t \n\t\t\t S Ananiadou \n\t\t \n\t\t 10.48550/arXiv.2304.03347 \n\t\t arXiv. 2023 \n\t\t \n\t\t \n\t \n\t Preprint \n\t Yang K, Ji S, Zhang T, Xie Q, Kuang Z, Ananiadou S. Towards interpretable mental health analysis with large language models. arXiv. 2023. https://doi.org/10.48550/arXiv.2304.03347 [Preprint]"
    },
    {
      "title": "NHS mental health patients wait times",
      "year": 2022,
      "raw": "NHS mental health patients wait times \n\t\t \n\t\t \n\t\t\t 2022. Apr 16, 2024 \n\t\t\t The Guardian \n\t\t \n\t \n\t The Guardian. NHS mental health patients wait times. 2022. Available from: https://www.theguardian.com/society/2022/oct/10/nhs-mental-health-patients-wait- times [accessed Apr 16, 2024]"
    },
    {
      "title": "An ethical perspective on the democratization of mental health with generative artificial intelligence",
      "authors": [
        "Z Elyoseph",
        "T Gur",
        "Y Haber",
        "T Simon",
        "T Angert",
        "Y Navon",
        "A Tal",
        "O Asman"
      ],
      "year": 2024,
      "doi": "10.2196/preprints.58011",
      "raw": "An ethical perspective on the democratization of mental health with generative artificial intelligence \n\t\t \n\t\t\t Z Elyoseph \n\t\t \n\t\t \n\t\t\t T Gur \n\t\t \n\t\t \n\t\t\t Y Haber \n\t\t \n\t\t \n\t\t\t T Simon \n\t\t \n\t\t \n\t\t\t T Angert \n\t\t \n\t\t \n\t\t\t Y Navon \n\t\t \n\t\t \n\t\t\t A Tal \n\t\t \n\t\t \n\t\t\t O Asman \n\t\t \n\t\t 10.2196/preprints.58011 \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Elyoseph Z, Gur T, Haber Y, Simon T, Angert T, Navon Y, Tal A, Asman O. An ethical perspective on the democratization of mental health with generative artificial intelligence. 2024. doi: 10.2196/preprints.58011"
    },
    {
      "title": "Delivering Cognitive Behavior Therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial",
      "authors": [
        "K Fitzpatrick",
        "A Darcy",
        "M Vierhile"
      ],
      "year": 2017,
      "doi": "10.2196/mental.7785",
      "journal": "JMIR Mental Health",
      "volume": "4",
      "issue": "2",
      "pages": "7785",
      "raw": "Delivering Cognitive Behavior Therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial \n\t\t \n\t\t\t K K Fitzpatrick \n\t\t \n\t\t \n\t\t\t A Darcy \n\t\t \n\t\t \n\t\t\t M Vierhile \n\t\t \n\t\t 10.2196/mental.7785 \n\t \n\t \n\t\t JMIR Mental Health \n\t\t \n\t\t\t 4 \n\t\t\t 2 \n\t\t\t 7785 \n\t\t\t 2017 Jun 6 \n\t\t \n\t \n\t Fitzpatrick KK, Darcy A, Vierhile M. Delivering Cognitive Behavior Therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial. JMIR Mental Health 2017 Jun 6;4(2):e7785. doi: 10.2196/mental.7785"
    },
    {
      "title": "Wysa -Everyday mental health",
      "year": 2024,
      "doi": "10.2196/preprints.41913",
      "raw": "10.2196/preprints.41913 \n\t\t \n\t\t Wysa -Everyday mental health \n\t\t \n\t\t\t Wysa-Everyday Mental Health \n\t\t\t Apr 16, 2024 \n\t\t \n\t \n\t Internet \n\t Wysa-Everyday Mental Health. n.d. Wysa -Everyday mental health [Internet]. Available from: https://www.wysa.com/ [accessed Apr 16, 2024]"
    },
    {
      "title": "An overview of chatbot-based mobile mental health apps: insights from App description and user reviews",
      "authors": [
        "Mdr Haque",
        "S Rubya"
      ],
      "year": 2023,
      "doi": "10.2196/44838",
      "journal": "JMIR Mhealth Uhealth",
      "volume": "11",
      "pages": "e44838",
      "raw": "An overview of chatbot-based mobile mental health apps: insights from App description and user reviews \n\t\t \n\t\t\t Mdr Haque \n\t\t \n\t\t \n\t\t\t S Rubya \n\t\t \n\t\t 10.2196/44838 \n\t\t 37213181 \n\t \n\t \n\t\t JMIR Mhealth Uhealth \n\t\t \n\t\t\t 11 \n\t\t\t e44838 \n\t\t\t 2023 May 22 \n\t\t \n\t \n\t Haque MDR, Rubya S. An overview of chatbot-based mobile mental health apps: insights from App description and user reviews. JMIR Mhealth Uhealth 2023 May 22;11:e44838. PMID:37213181"
    },
    {
      "title": "Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation",
      "authors": [
        "E Stade",
        "S Stirman",
        "L Ungar",
        "C Boland",
        "H Schwartz",
        "D Yaden",
        "J Sedoc",
        "R Derubeis",
        "R Willer",
        "J Eichstaedt"
      ],
      "year": 2024,
      "doi": "10.1038/s44184-024-00056-z",
      "journal": "npj Mental Health Res",
      "volume": "3",
      "issue": "1",
      "raw": "Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation \n\t\t \n\t\t\t E C Stade \n\t\t \n\t\t \n\t\t\t S W Stirman \n\t\t \n\t\t \n\t\t\t L H Ungar \n\t\t \n\t\t \n\t\t\t C L Boland \n\t\t \n\t\t \n\t\t\t H A Schwartz \n\t\t \n\t\t \n\t\t\t D B Yaden \n\t\t \n\t\t \n\t\t\t J Sedoc \n\t\t \n\t\t \n\t\t\t R J Derubeis \n\t\t \n\t\t \n\t\t\t R Willer \n\t\t \n\t\t \n\t\t\t J C Eichstaedt \n\t\t \n\t\t 10.1038/s44184-024-00056-z \n\t \n\t \n\t\t npj Mental Health Res \n\t\t \n\t\t\t 3 \n\t\t\t 1 \n\t\t\t \n\t\t\t 2024 Apr 2 \n\t\t\t Nature Publishing Group \n\t\t \n\t \n\t Stade EC, Stirman SW, Ungar LH, Boland CL, Schwartz HA, Yaden DB, Sedoc J, DeRubeis RJ, Willer R, Eichstaedt JC. Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation. npj Mental Health Res Nature Publishing Group; 2024 Apr 2;3(1):1-12. doi: 10.1038/s44184-024-00056-z"
    },
    {
      "title": "Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine",
      "authors": [
        "S Harrer"
      ],
      "year": 2023,
      "doi": "10.1016/j.ebiom.2023.104512",
      "journal": "eBioMedicine Elsevier",
      "volume": "90",
      "raw": "Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine \n\t\t \n\t\t\t S Harrer \n\t\t \n\t\t 10.1016/j.ebiom.2023.104512 \n\t\t 36924620 \n\t \n\t \n\t\t eBioMedicine Elsevier \n\t\t \n\t\t\t 90 \n\t\t\t 2023 Apr 1 \n\t\t \n\t \n\t Harrer S. Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine. eBioMedicine Elsevier; 2023 Apr 1;90. PMID:36924620"
    },
    {
      "title": "Ethics and governance of artificial intelligence for health: guidance on large multi-modal models",
      "year": 2024,
      "doi": "10.17160/josha.11.1.956",
      "raw": "Ethics and governance of artificial intelligence for health: guidance on large multi-modal models \n\t\t 10.17160/josha.11.1.956 \n\t\t \n\t\t \n\t\t\t 2024. Apr 16, 2024 \n\t\t\t World Health Organization \n\t\t \n\t \n\t World Health Organization. Ethics and governance of artificial intelligence for health: guidance on large multi-modal models. 2024. Available from: Available from: https://iris.who.int/bitstream/handle/10665/375579/9789240084759-eng.pdf? [accessed Apr 16, 2024]"
    },
    {
      "title": "What are large language models (LLMs)? IBM",
      "year": 2024,
      "doi": "10.6019/tol.basics-llm-w.2025.00001.1",
      "raw": "10.6019/tol.basics-llm-w.2025.00001.1 \n\t\t \n\t\t What are large language models (LLMs)? IBM \n\t\t \n\t\t\t Apr 16, 2024 \n\t\t \n\t \n\t What are large language models (LLMs)? IBM. Available from: https://www.ibm.com/topics/large-language-models [accessed Apr 16, 2024]"
    },
    {
      "title": "LLM evaluation: Large language models performance metrics",
      "authors": [
        "A Nucci"
      ],
      "year": 2023,
      "raw": "LLM evaluation: Large language models performance metrics \n\t\t \n\t\t\t A Nucci \n\t\t \n\t\t \n\t \n\t \n\t\t Aisera: best Generative AI Platform For Enterprise \n\t\t \n\t\t\t 2023. Apr 16, 2024 \n\t\t \n\t \n\t Nucci A. LLM evaluation: Large language models performance metrics. Aisera: best Generative AI Platform For Enterprise. 2023. Available from: https://aisera.com/blog/llm-evaluation/ [accessed Apr 16, 2024]"
    },
    {
      "title": "Better language models",
      "year": 2023,
      "raw": "Better language models \n\t\t \n\t\t\t Openai \n\t\t \n\t\t \n\t\t \n\t\t\t 2023. Apr 16, 2024 \n\t\t \n\t \n\t OpenAI. Better language models. 2023. Available from: https://openai.com/research/better-language-models [accessed Apr 16, 2024]"
    },
    {
      "title": "Attention is all you need",
      "authors": [
        "A Vaswani",
        "N Shazeer",
        "N Parmar",
        "J Uszkoreit",
        "L Jones",
        "A Gomez",
        "L Kaiser",
        "I Polosukhin"
      ],
      "year": 2017,
      "doi": "10.48550/arXiv.1706.03762",
      "raw": "Attention is all you need \n\t\t \n\t\t\t A Vaswani \n\t\t \n\t\t \n\t\t\t N Shazeer \n\t\t \n\t\t \n\t\t\t N Parmar \n\t\t \n\t\t \n\t\t\t J Uszkoreit \n\t\t \n\t\t \n\t\t\t L Jones \n\t\t \n\t\t \n\t\t\t A N Gomez \n\t\t \n\t\t \n\t\t\t L Kaiser \n\t\t \n\t\t \n\t\t\t I Polosukhin \n\t\t \n\t\t 10.48550/arXiv.1706.03762 \n\t\t \n\t\t \n\t\t\t 2017 \n\t\t \n\t \n\t Preprint \n\t Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. Attention is all you need. 2017. Available from: https://doi.org/10.48550/arXiv.1706.03762 [Preprint]"
    },
    {
      "title": "What are Large Language Models? Definition from TechTarget",
      "year": 2024,
      "doi": "10.31235/osf.io/23x4m",
      "raw": "10.31235/osf.io/23x4m \n\t\t \n\t\t What are Large Language Models? Definition from TechTarget \n\t\t \n\t\t\t WhatIs \n\t\t\t May 16, 2024 \n\t\t \n\t \n\t What are Large Language Models? Definition from TechTarget. WhatIs. Available from: https://www.techtarget.com/whatis/definition/large-language-model-LLM [accessed May 16, 2024]"
    },
    {
      "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
      "authors": [
        "J Devlin",
        "M-W Chang",
        "K Lee",
        "K Toutanova"
      ],
      "year": 2019,
      "doi": "10.48550/arXiv.1810.04805",
      "raw": "BERT: pre-training of deep bidirectional transformers for language understanding \n\t\t \n\t\t\t J Devlin \n\t\t \n\t\t \n\t\t\t M-W Chang \n\t\t \n\t\t \n\t\t\t K Lee \n\t\t \n\t\t \n\t\t\t K Toutanova \n\t\t \n\t\t 10.48550/arXiv.1810.04805 \n\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Devlin J, Chang M-W, Lee K, Toutanova K. BERT: pre-training of deep bidirectional transformers for language understanding. arXiv; 2019. doi: 10.48550/arXiv.1810.04805"
    },
    {
      "title": "A primer in BERTology: what we know about how BERT works",
      "authors": [
        "A Rogers",
        "O Kovaleva",
        "A Rumshisky"
      ],
      "year": 2020,
      "doi": "10.48550/arXiv.2002.12327",
      "raw": "A primer in BERTology: what we know about how BERT works \n\t\t \n\t\t\t A Rogers \n\t\t \n\t\t \n\t\t\t O Kovaleva \n\t\t \n\t\t \n\t\t\t A Rumshisky \n\t\t \n\t\t 10.48550/arXiv.2002.12327 \n\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Rogers A, Kovaleva O, Rumshisky A. A primer in BERTology: what we know about how BERT works. arXiv; 2020. doi: 10.48550/arXiv.2002.12327"
    },
    {
      "title": "ChatGPT turns 1: How the AI chatbot has completely changed the world",
      "year": 2023,
      "doi": "10.1038/d41586-024-03940-y",
      "raw": "10.1038/d41586-024-03940-y \n\t\t \n\t\t ChatGPT turns 1: How the AI chatbot has completely changed the world \n\t\t \n\t\t\t euronews \n\t\t\t 2023. Apr 16, 2024 \n\t\t \n\t \n\t ChatGPT turns 1: How the AI chatbot has completely changed the world. euronews. 2023. Available from: https://www.euronews.com/next/2023/11/30/chatgpt-a-year-on- 3-ways-the-ai-chatbot-has-completely-changed-the-world-in-12-months [accessed Apr 16, 2024]"
    },
    {
      "title": "Large language models in medicine",
      "authors": [
        "A Thirunavukarasu",
        "Dsj Ting",
        "K Elangovan",
        "L Gutierrez",
        "T Tan",
        "Dsw Ting"
      ],
      "year": 2023,
      "doi": "10.1038/s41591-023-02448-8",
      "journal": "Nat Med",
      "volume": "29",
      "issue": "8",
      "raw": "Large language models in medicine \n\t\t \n\t\t\t A J Thirunavukarasu \n\t\t \n\t\t \n\t\t\t Dsj Ting \n\t\t \n\t\t \n\t\t\t K Elangovan \n\t\t \n\t\t \n\t\t\t L Gutierrez \n\t\t \n\t\t \n\t\t\t T F Tan \n\t\t \n\t\t \n\t\t\t Dsw Ting \n\t\t \n\t\t 10.1038/s41591-023-02448-8 \n\t \n\t \n\t\t Nat Med \n\t\t \n\t\t\t 29 \n\t\t\t 8 \n\t\t\t 2023 \n\t\t \n\t \n\t Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med. 2023;29(8):Article 8. DOI: 10.1038/s41591- 023-02448-8"
    },
    {
      "title": "The best large language models (LLMs) of 2024",
      "authors": [
        "G Updated"
      ],
      "year": 2024,
      "raw": "The best large language models (LLMs) of 2024 \n\t\t \n\t\t\t G H Updated \n\t\t \n\t\t \n\t\t\t Last \n\t\t \n\t\t \n\t\t \n\t\t\t 2024. Aug 8, 2024 \n\t\t\t TechRadar \n\t\t \n\t \n\t Updated GH from JC last. The best large language models (LLMs) of 2024. TechRadar. 2024. Available from: https://www.techradar.com/computing/artificial- intelligence/best-llms [accessed Aug 8, 2024]"
    },
    {
      "title": "AIMultiple: High Tech Use Cases & Tools to Grow Your Business",
      "year": 2024,
      "doi": "10.55277/researchhub.0ps6xenm",
      "raw": "10.55277/researchhub.0ps6xenm \n\t\t \n\t\t AIMultiple: High Tech Use Cases & Tools to Grow Your Business \n\t\t \n\t\t\t 2024. Apr 16, 2024 \n\t\t \n\t \n\t Top large language model examples in \n\t Top large language model examples in 2024. AIMultiple: High Tech Use Cases & Tools to Grow Your Business. Available from: https://research.aimultiple.com/large- language-models-examples/ [accessed Apr 16, 2024]"
    },
    {
      "title": "Timeline of AI and language models",
      "year": 2021,
      "doi": "10.2139/ssrn.4972795",
      "raw": "10.2139/ssrn.4972795 \n\t\t \n\t\t Timeline of AI and language models \n\t\t \n\t\t\t Dr Alan D Thompson -Life Architect \n\t\t\t 2021. Apr 16, 2024 \n\t\t \n\t \n\t Public-facing-username-for-plugin \n\t Public-facing-username-for-plugin. Timeline of AI and language models. Dr Alan D Thompson -Life Architect. 2021. Available from: https://lifearchitect.ai/timeline/ [accessed Apr 16, 2024]"
    },
    {
      "title": "Large language models explained",
      "authors": [
        "M Priest"
      ],
      "year": 2023,
      "raw": "Large language models explained \n\t\t \n\t\t\t M Priest \n\t\t \n\t\t \n\t \n\t \n\t\t Boost.ai \n\t\t \n\t\t\t 2023. Apr 16, 2024 \n\t\t \n\t \n\t Priest M. Large language models explained. Boost.ai. 2023. Available from: https://boost.ai/blog/llms-large-language-models [accessed Apr 16, 2024]"
    },
    {
      "title": "Efficient Fine-Tuning of BERT Models on the Edge",
      "authors": [
        "D Vucetic",
        "M Tayaranian",
        "M Ziaeefard",
        "J Clark",
        "B Meyer",
        "W Gross"
      ],
      "year": 2022,
      "doi": "10.1109/iscas48785.2022.9937567",
      "raw": "Efficient Fine-Tuning of BERT Models on the Edge \n\t\t \n\t\t\t D Vucetic \n\t\t \n\t\t \n\t\t\t M Tayaranian \n\t\t \n\t\t \n\t\t\t M Ziaeefard \n\t\t \n\t\t \n\t\t\t J J Clark \n\t\t \n\t\t \n\t\t\t B H Meyer \n\t\t \n\t\t \n\t\t\t W J Gross \n\t\t \n\t\t 10.1109/iscas48785.2022.9937567 \n\t \n\t \n\t\t IEEE International Symposium on Circuits and Systems (ISCAS) \n\t\t \n\t\t\t 2022. 2022 \n\t\t\t \n\t\t \n\t \n\t Vucetic D, Tayaranian M, Ziaeefard M, Clark JJ, Meyer BH, Gross WJ. Efficient Fine- Tuning of BERT Models on the Edge. 2022 IEEE International Symposium on Circuits and Systems (ISCAS) 2022. p. 1838-1842. doi: 10.1109/ISCAS48785.2022.9937567"
    },
    {
      "title": "Understanding large language models and fine-tuning for business scenarios: a simple guide",
      "authors": [
        "M Kumar"
      ],
      "year": 2023,
      "raw": "Understanding large language models and fine-tuning for business scenarios: a simple guide \n\t\t \n\t\t\t M Kumar \n\t\t \n\t\t \n\t\t \n\t\t\t 2023. Apr 16, 2024 \n\t\t\t Medium \n\t\t \n\t \n\t Kumar M. Understanding large language models and fine-tuning for business scenarios: a simple guide. Medium. 2023. Available from: https://medium.com/@careerInAI/understanding-large-language-models-and-fine- tuning-for-business-scenarios-a-simple-guide-42f44cb687f0 [accessed Apr 16, 2024]"
    },
    {
      "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
      "authors": [
        "S Mishra",
        "D Khashabi",
        "C Baral",
        "H Hajishirzi"
      ],
      "year": 2022,
      "doi": "10.18653/v1/2022.acl-long.244",
      "volume": "1",
      "raw": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions \n\t\t \n\t\t\t S Mishra \n\t\t \n\t\t \n\t\t\t D Khashabi \n\t\t \n\t\t \n\t\t\t C Baral \n\t\t \n\t\t \n\t\t\t H Hajishirzi \n\t\t \n\t\t 10.18653/v1/2022.acl-long.244 \n\t \n\t \n\t\t Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics \n\t\t \n\t\t\t S Muresan \n\t\t \n\t\t \n\t\t\t P Nakov \n\t\t \n\t\t \n\t\t\t A Villavicencio \n\t\t \n\t\t the 60th Annual Meeting of the Association for Computational Linguistics Dublin, Ireland \n\t\t \n\t\t\t Association for Computational Linguistics \n\t\t\t 2022 \n\t\t\t 1 \n\t\t\t \n\t\t \n\t \n\t Long Papers \n\t Mishra S, Khashabi D, Baral C, Hajishirzi H. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. In: Muresan S, Nakov P, Villavicencio A, editors. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) Dublin, Ireland: Association for Computational Linguistics; 2022. p. 3470-3487. doi: 10.18653/v1/2022.acl-long.244"
    },
    {
      "title": "Instruction Tuning for Large Language Models: A Survey",
      "year": 2024,
      "raw": "Instruction Tuning for Large Language Models: A Survey \n\t\t \n\t\t \n\t\t\t May 13, 2024 \n\t\t \n\t \n\t Instruction Tuning for Large Language Models: A Survey. Available from: https://arxiv.org/html/2308.10792v5 [accessed May 13, 2024]"
    },
    {
      "title": "A developer's uide to prompt en ineerin and LLMs. The GitHub Blog",
      "year": 2023,
      "raw": "A developer's uide to prompt en ineerin and LLMs. The GitHub Blog \n\t\t \n\t\t\t Berryman Az Ohn \n\t\t \n\t\t \n\t\t \n\t\t\t 2023. Apr 15, 2024 \n\t\t \n\t \n\t Preprint \n\t Berryman AZ ohn. A developer's uide to prompt en ineerin and LLMs. The GitHub Blog. 2023. Available from: https://github.blog/2023-07-17-prompt-engineering- guide-generative-ai-llms/ [accessed Apr 15, 2024] [Preprint]"
    },
    {
      "title": "Climbing towards NLU: on meaning, form, and understanding in the age of data",
      "authors": [
        "E Bender",
        "A Koller"
      ],
      "year": 2020,
      "doi": "10.18653/v1/2020.acl-main.463",
      "raw": "Climbing towards NLU: on meaning, form, and understanding in the age of data \n\t\t \n\t\t\t E M Bender \n\t\t \n\t\t \n\t\t\t A Koller \n\t\t \n\t\t 10.18653/v1/2020.acl-main.463 \n\t\t \n\t \n\t \n\t\t Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics \n\t\t the 58th Annual Meeting of the Association for Computational Linguistics \n\t\t \n\t\t\t 2020 \n\t\t\t \n\t\t \n\t \n\t Bender EM, Koller A. Climbing towards NLU: on meaning, form, and understanding in the age of data. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020;5185-5198. https://doi.org/10.18653/v1/2020.acl- main.463"
    },
    {
      "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
      "authors": [
        "J Lee",
        "W Yoon",
        "S Kim",
        "D Kim",
        "S Kim",
        "C So",
        "J Kang"
      ],
      "year": 2019,
      "doi": "10.1093/bioinformatics/btz682",
      "journal": "Bioinformatics",
      "volume": "36",
      "issue": "4",
      "raw": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining \n\t\t \n\t\t\t J Lee \n\t\t \n\t\t \n\t\t\t W Yoon \n\t\t \n\t\t \n\t\t\t S Kim \n\t\t \n\t\t \n\t\t\t D Kim \n\t\t \n\t\t \n\t\t\t S Kim \n\t\t \n\t\t \n\t\t\t C H So \n\t\t \n\t\t \n\t\t\t J Kang \n\t\t \n\t\t 10.1093/bioinformatics/btz682 \n\t \n\t \n\t\t Bioinformatics \n\t\t \n\t\t\t 36 \n\t\t\t 4 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, Kang J. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics. 2019;36(4):1234-1240. DOI: 10.1093/bioinformatics/btz682"
    },
    {
      "title": "Clinicalbert: Modeling clinical notes and predicting hospital readmission",
      "authors": [
        "K Huang",
        "J Altosaar",
        "R Ranganath"
      ],
      "raw": "Clinicalbert: Modeling clinical notes and predicting hospital readmission \n\t\t \n\t\t\t K Huang \n\t\t \n\t\t \n\t\t\t J Altosaar \n\t\t \n\t\t \n\t\t\t R Ranganath \n\t\t \n\t\t arXiv. 2020 \n\t\t \n\t\t \n\t \n\t Preprint \n\t Huang K, Altosaar J, Ranganath R. Clinicalbert: Modeling clinical notes and predicting hospital readmission. arXiv. 2020. Available from: https://arxiv.org/abs/1904.05342 [Preprint]."
    },
    {
      "title": "Clinically applicable AI system for accurate diagnosis, quantitative measurements, and prognosis of COVID-19 pneumonia using computed tomography",
      "authors": [
        "K Zhang",
        "X Liu",
        "J Shen",
        "Z Li",
        "Y Sang",
        "X Wu",
        "Y Zha"
      ],
      "year": 2020,
      "doi": "10.1016/j.cell.2020.08.029",
      "journal": "Cell",
      "volume": "182",
      "issue": "5",
      "pages": "1360",
      "raw": "Clinically applicable AI system for accurate diagnosis, quantitative measurements, and prognosis of COVID-19 pneumonia using computed tomography \n\t\t \n\t\t\t K Zhang \n\t\t \n\t\t \n\t\t\t X Liu \n\t\t \n\t\t \n\t\t\t J Shen \n\t\t \n\t\t \n\t\t\t Z Li \n\t\t \n\t\t \n\t\t\t Y Sang \n\t\t \n\t\t \n\t\t\t X Wu \n\t\t \n\t\t \n\t\t\t Y Zha \n\t\t \n\t\t 10.1016/j.cell.2020.08.029 \n\t \n\t \n\t\t Cell \n\t\t \n\t\t\t 182 \n\t\t\t 5 \n\t\t\t 1360 \n\t\t\t 2020 \n\t\t \n\t \n\t Zhang K, Liu X, Shen J, Li Z, Sang Y, Wu X, Zha Y, et al. Clinically applicable AI system for accurate diagnosis, quantitative measurements, and prognosis of COVID-19 pneumonia using computed tomography. Cell. 2020;182(5):1360. DOI: 10.1016/j.cell.2020.08.029"
    },
    {
      "title": "esponse to \"Attention is not all you need: the complicated case of ethically usin lar e lan ua e models in healthcare and medicine",
      "authors": [
        "M Trengove",
        "L Goetz"
      ],
      "year": 2023,
      "doi": "10.1016/j.ebiom.2023.104671",
      "journal": "eBioMedicine Elsevier",
      "volume": "93",
      "raw": "esponse to \"Attention is not all you need: the complicated case of ethically usin lar e lan ua e models in healthcare and medicine \n\t\t \n\t\t\t M Trengove \n\t\t \n\t\t \n\t\t\t Vandersluis \n\t\t \n\t\t \n\t\t\t L Goetz \n\t\t \n\t\t 10.1016/j.ebiom.2023.104671 \n\t\t 37327676 \n\t \n\t \n\t\t eBioMedicine Elsevier \n\t\t \n\t\t\t 93 \n\t\t\t 2023 Jul 1 \n\t\t \n\t \n\t Trengove M, Vandersluis , Goetz L. esponse to \"Attention is not all you need: the complicated case of ethically usin lar e lan ua e models in healthcare and medicine.\" eBioMedicine Elsevier; 2023 Jul 1;93. PMID:37327676"
    },
    {
      "title": "Machine learning and natural language processing in mental health: systematic review",
      "authors": [
        "Le Glaz",
        "A Haralambous",
        "Y Kim-Dufor",
        "D Lenca",
        "P Billot",
        "R Ryan",
        "T Marsh",
        "J Devylder",
        "J Walter",
        "M Berrouiguet",
        "S Lemey"
      ],
      "year": 2021,
      "doi": "10.2196/15708",
      "journal": "J Med Internet Res",
      "volume": "23",
      "issue": "5",
      "pages": "15708",
      "raw": "Machine learning and natural language processing in mental health: systematic review \n\t\t \n\t\t\t Le Glaz \n\t\t \n\t\t \n\t\t\t A Haralambous \n\t\t \n\t\t \n\t\t\t Y Kim-Dufor \n\t\t \n\t\t \n\t\t\t D Lenca \n\t\t \n\t\t \n\t\t\t P Billot \n\t\t \n\t\t \n\t\t\t R Ryan \n\t\t \n\t\t \n\t\t\t T C Marsh \n\t\t \n\t\t \n\t\t\t J Devylder \n\t\t \n\t\t \n\t\t\t J Walter \n\t\t \n\t\t \n\t\t\t M Berrouiguet \n\t\t \n\t\t \n\t\t\t S Lemey \n\t\t \n\t\t \n\t\t\t C \n\t\t \n\t\t 10.2196/15708 \n\t\t 33944788 \n\t\t PMC8132982 \n\t \n\t \n\t\t J Med Internet Res \n\t\t \n\t\t\t 23 \n\t\t\t 5 \n\t\t\t 15708 \n\t\t\t 2021 \n\t\t \n\t \n\t Le Glaz A, Haralambous Y, Kim-Dufor D, Lenca P, Billot R, Ryan TC, Marsh J, DeVylder J, Walter M, Berrouiguet S, Lemey C. Machine learning and natural language processing in mental health: systematic review. J Med Internet Res. 2021;23(5):e15708. DOI: 10.2196/15708. PMID: 33944788. PMCID: PMC8132982"
    },
    {
      "title": "Large Language Models in Mental Health Care: a Scoping Review",
      "authors": [
        "Y Hua",
        "F Liu",
        "K Yang",
        "Z Li",
        "Y Sheu",
        "P Zhou",
        "L Moran",
        "S Ananiadou",
        "A Beam"
      ],
      "year": 2024,
      "doi": "10.48550/arXiv.2401.02984",
      "raw": "Large Language Models in Mental Health Care: a Scoping Review \n\t\t \n\t\t\t Y Hua \n\t\t \n\t\t \n\t\t\t F Liu \n\t\t \n\t\t \n\t\t\t K Yang \n\t\t \n\t\t \n\t\t\t Z Li \n\t\t \n\t\t \n\t\t\t Y Sheu \n\t\t \n\t\t \n\t\t\t P Zhou \n\t\t \n\t\t \n\t\t\t L V Moran \n\t\t \n\t\t \n\t\t\t S Ananiadou \n\t\t \n\t\t \n\t\t\t A Beam \n\t\t \n\t\t 10.48550/arXiv.2401.02984 \n\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Preprint \n\t Hua Y, Liu F, Yang K, Li Z, Sheu Y, Zhou P, Moran LV, Ananiadou S, Beam A. Large Language Models in Mental Health Care: a Scoping Review. arXiv; 2024. doi: 10.48550/arXiv.2401.02984 [Preprint]"
    },
    {
      "title": "Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement",
      "authors": [
        "D Moher"
      ],
      "year": 2009,
      "doi": "10.7326/0003-4819-151-4-200908180-00135",
      "journal": "Ann Intern Med",
      "volume": "151",
      "issue": "4",
      "pages": "264",
      "raw": "Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement \n\t\t \n\t\t\t D Moher \n\t\t \n\t\t 10.7326/0003-4819-151-4-200908180-00135 \n\t \n\t \n\t\t Ann Intern Med \n\t\t \n\t\t\t 151 \n\t\t\t 4 \n\t\t\t 264 \n\t\t\t 2009 \n\t\t \n\t \n\t Moher D. Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement. Ann Intern Med. 2009;151(4):264. DOI: 10.7326/0003-4819-151- 4-200908180-00135"
    },
    {
      "title": "AI-enhanced mental health diagnosis: leveraging Transformers for early detection of depression tendency in textual data",
      "authors": [
        "S Verma",
        "R Joshi",
        "M Dutta",
        "S Jezek",
        "R Burget"
      ],
      "year": 2023,
      "doi": "10.1109/icumt61075.2023.10333301",
      "raw": "AI-enhanced mental health diagnosis: leveraging Transformers for early detection of depression tendency in textual data \n\t\t \n\t\t\t S Verma \n\t\t \n\t\t \n\t\t\t Vishal \n\t\t \n\t\t \n\t\t\t R C Joshi \n\t\t \n\t\t \n\t\t\t M K Dutta \n\t\t \n\t\t \n\t\t\t S Jezek \n\t\t \n\t\t \n\t\t\t R Burget \n\t\t \n\t\t 10.1109/icumt61075.2023.10333301 \n\t \n\t \n\t\t 15th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops \n\t\t ICUMT \n\t\t \n\t\t\t 2023. 2023 \n\t\t\t \n\t\t \n\t \n\t Verma S, Vishal, Joshi RC, Dutta MK, Jezek S, Burget R. AI-enhanced mental health diagnosis: leveraging Transformers for early detection of depression tendency in textual data. 2023 15th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT) 2023. p. 56-61. doi: 10.1109/ICUMT61075.2023.10333301"
    },
    {
      "title": "RoBERTa: a robustly optimized BERT pretraining approach",
      "authors": [
        "Y Liu",
        "M Ott",
        "N Goyal",
        "J Du",
        "M Joshi",
        "D Chen",
        "O Levy",
        "M Lewis",
        "L Zettlemoyer",
        "V Stoyanov"
      ],
      "doi": "10.48550/arXiv.1907.11692",
      "raw": "RoBERTa: a robustly optimized BERT pretraining approach \n\t\t \n\t\t\t Y Liu \n\t\t \n\t\t \n\t\t\t M Ott \n\t\t \n\t\t \n\t\t\t N Goyal \n\t\t \n\t\t \n\t\t\t J Du \n\t\t \n\t\t \n\t\t\t M Joshi \n\t\t \n\t\t \n\t\t\t D Chen \n\t\t \n\t\t \n\t\t\t O Levy \n\t\t \n\t\t \n\t\t\t M Lewis \n\t\t \n\t\t \n\t\t\t L Zettlemoyer \n\t\t \n\t\t \n\t\t\t V Stoyanov \n\t\t \n\t\t 10.48550/arXiv.1907.11692 \n\t\t arXiv. 2019 \n\t\t \n\t\t \n\t \n\t Preprint \n\t Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M, Zettlemoyer L, Stoyanov V. RoBERTa: a robustly optimized BERT pretraining approach. arXiv. 2019. Available from: https://doi.org/10.48550/arXiv.1907.11692 [Preprint]"
    },
    {
      "title": "Mental Health Corpus",
      "year": 2024,
      "doi": "10.5040/9781350059207.0007",
      "raw": "10.5040/9781350059207.0007 \n\t\t \n\t\t Mental Health Corpus \n\t\t \n\t\t\t Apr 17, 2024 \n\t\t \n\t \n\t Mental Health Corpus. Available from: https://www.kaggle.com/datasets/reihanenamdari/mental-health-corpus [accessed Apr 17, 2024]"
    },
    {
      "title": "Depression: Reddit Dataset (Cleaned)",
      "year": 2024,
      "doi": "10.7717/peerj.7013/supp-2",
      "raw": "10.7717/peerj.7013/supp-2 \n\t\t \n\t\t Depression: Reddit Dataset (Cleaned) \n\t\t \n\t\t\t Apr 17, 2024 \n\t\t \n\t \n\t Depression: Reddit Dataset (Cleaned). Available from: https://www.kaggle.com/datasets/infamouscoder/depression-reddit-cleaned [accessed Apr 17, 2024]"
    },
    {
      "title": "Boamente: a natural language processing-based digital phenotyping tool for smart monitoring of suicidal ideation",
      "authors": [
        "Ejs Diniz",
        "J Fontenele",
        "A De Oliveira",
        "V Bastos",
        "S Teixeira",
        "Rab\u00ea Lo",
        "R Cal\u00e7",
        "Ada Db",
        "Dos Santos",
        "R De Oliveira",
        "A Teles"
      ],
      "year": 2022,
      "journal": "Healthcare",
      "volume": "10",
      "issue": "4",
      "pages": "698",
      "raw": "Boamente: a natural language processing-based digital phenotyping tool for smart monitoring of suicidal ideation \n\t\t \n\t\t\t Ejs Diniz \n\t\t \n\t\t \n\t\t\t J E Fontenele \n\t\t \n\t\t \n\t\t\t A C De Oliveira \n\t\t \n\t\t \n\t\t\t V H Bastos \n\t\t \n\t\t \n\t\t\t S Teixeira \n\t\t \n\t\t \n\t\t\t Rab\u00ea Lo \n\t\t \n\t\t \n\t\t\t R L Cal\u00e7 \n\t\t \n\t\t \n\t\t\t Ada Db \n\t\t \n\t\t \n\t\t\t Dos Santos \n\t\t \n\t\t \n\t\t\t R M De Oliveira \n\t\t \n\t\t \n\t\t\t A K Teles \n\t\t \n\t\t \n\t\t\t A S \n\t\t \n\t\t 35455874 \n\t \n\t \n\t\t Healthcare \n\t\t \n\t\t\t 10 \n\t\t\t 4 \n\t\t\t 698 \n\t\t\t 2022 Apr 8 \n\t\t\t Basel \n\t\t \n\t \n\t Diniz EJS, Fontenele JE, de Oliveira AC, Bastos VH, Teixeira S, Rab\u00ea lo RL, Cal\u00e7 ada DB, Dos Santos RM, de Oliveira AK, Teles AS. Boamente: a natural language processing-based digital phenotyping tool for smart monitoring of suicidal ideation. Healthcare (Basel) 2022 Apr 8;10(4):698. PMID:35455874"
    },
    {
      "title": "Transformers: State-of-the-Art natural language processing",
      "authors": [
        "T Wolf",
        "L Debut",
        "V Sanh",
        "J Chaumond",
        "C Delangue",
        "A Moi",
        "P Cistac",
        "T Rault",
        "R Louf",
        "M Funtowicz",
        "J Davison",
        "S Shleifer",
        "P Von Platen",
        "C Ma",
        "Y Jernite",
        "J Plu",
        "C Xu",
        "Le Scao",
        "T Gugger",
        "S Drame",
        "M Lhoest",
        "Q Rush"
      ],
      "year": 2020,
      "doi": "10.18653/v1/2020.emnlp-demos",
      "raw": "Transformers: State-of-the-Art natural language processing \n\t\t \n\t\t\t T Wolf \n\t\t \n\t\t \n\t\t\t L Debut \n\t\t \n\t\t \n\t\t\t V Sanh \n\t\t \n\t\t \n\t\t\t J Chaumond \n\t\t \n\t\t \n\t\t\t C Delangue \n\t\t \n\t\t \n\t\t\t A Moi \n\t\t \n\t\t \n\t\t\t P Cistac \n\t\t \n\t\t \n\t\t\t T Rault \n\t\t \n\t\t \n\t\t\t R Louf \n\t\t \n\t\t \n\t\t\t M Funtowicz \n\t\t \n\t\t \n\t\t\t J Davison \n\t\t \n\t\t \n\t\t\t S Shleifer \n\t\t \n\t\t \n\t\t\t P Von Platen \n\t\t \n\t\t \n\t\t\t C Ma \n\t\t \n\t\t \n\t\t\t Y Jernite \n\t\t \n\t\t \n\t\t\t J Plu \n\t\t \n\t\t \n\t\t\t C Xu \n\t\t \n\t\t \n\t\t\t Le Scao \n\t\t \n\t\t \n\t\t\t T Gugger \n\t\t \n\t\t \n\t\t\t S Drame \n\t\t \n\t\t \n\t\t\t M Lhoest \n\t\t \n\t\t \n\t\t\t Q Rush \n\t\t \n\t\t \n\t\t\t A \n\t\t \n\t\t 10.18653/v1/2020.emnlp-demos \n\t \n\t \n\t\t Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations Online: Association for Computational Linguistics \n\t\t \n\t\t\t Q Liu \n\t\t \n\t\t \n\t\t\t D Schlangen \n\t\t \n\t\t the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations Online: Association for Computational Linguistics \n\t\t \n\t\t\t 2020 \n\t\t\t \n\t\t \n\t \n\t Wolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A, Cistac P, Rault T, Louf R, Funtowicz M, Davison J, Shleifer S, von Platen P, Ma C, Jernite Y, Plu J, Xu C, Le Scao T, Gugger S, Drame M, Lhoest Q, Rush A. Transformers: State-of-the-Art natural language processing. In: Liu Q, Schlangen D, editors. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations Online: Association for Computational Linguistics; 2020. p. 38-45. doi: 10.18653/v1/2020.emnlp-demos."
    },
    {
      "title": "BERTimbau: pretrained BERT models for Brazilian Portuguese",
      "authors": [
        "F Souza",
        "R Nogueira",
        "R Lotufo"
      ],
      "year": 2020,
      "doi": "10.1007/978-3-030-61377-8_28",
      "raw": "BERTimbau: pretrained BERT models for Brazilian Portuguese \n\t\t \n\t\t\t F Souza \n\t\t \n\t\t \n\t\t\t R Nogueira \n\t\t \n\t\t \n\t\t\t R Lotufo \n\t\t \n\t\t 10.1007/978-3-030-61377-8_28 \n\t \n\t \n\t\t Intelligent Systems Cham \n\t\t \n\t\t\t R Cerri \n\t\t \n\t\t \n\t\t\t R C Prati \n\t\t \n\t\t \n\t\t\t Springer International Publishing \n\t\t\t 2020 \n\t\t\t \n\t\t \n\t \n\t Souza F, Nogueira R, Lotufo R. BERTimbau: pretrained BERT models for Brazilian Portuguese. In: Cerri R, Prati RC, editors. Intelligent Systems Cham: Springer International Publishing; 2020. p. 403-417. doi: 10.1007/978-3-030-61377-8_28"
    },
    {
      "title": "Advancing mental health diagnostics: GPT-based method for depression detection",
      "authors": [
        "M Danner",
        "B Hadzic",
        "Gerhardt Ludwig",
        "S Uslu",
        "I Shao",
        "P Weber",
        "T Shiban",
        "Y Ratsch"
      ],
      "year": 2023,
      "doi": "10.23919/SICE59929.2023.10354236",
      "raw": "Advancing mental health diagnostics: GPT-based method for depression detection \n\t\t \n\t\t\t M Danner \n\t\t \n\t\t \n\t\t\t B Hadzic \n\t\t \n\t\t \n\t\t\t Gerhardt S Ludwig \n\t\t \n\t\t \n\t\t\t S Uslu \n\t\t \n\t\t \n\t\t\t I Shao \n\t\t \n\t\t \n\t\t\t P Weber \n\t\t \n\t\t \n\t\t\t T Shiban \n\t\t \n\t\t \n\t\t\t Y Ratsch \n\t\t \n\t\t \n\t\t\t M \n\t\t \n\t\t 10.23919/SICE59929.2023.10354236 \n\t \n\t \n\t\t Annual Conference of the Society of Instrument and Control Engineers (SICE) \n\t\t \n\t\t\t 2023. 2023 \n\t\t\t \n\t\t \n\t \n\t Danner M, Hadzic B, Gerhardt S, Ludwig S, Uslu I, Shao P, Weber T, Shiban Y, Ratsch M. Advancing mental health diagnostics: GPT-based method for depression detection. 2023 62nd Annual Conference of the Society of Instrument and Control Engineers (SICE) 2023. p. 1290-1296. doi: 10.23919/SICE59929.2023.10354236"
    },
    {
      "title": "The distress analysis interview corpus of human and computer interviews. 59. tended A atabase ownload -A -W Z",
      "authors": [
        "Artstein Gratch",
        "G Lucas",
        "L Morency"
      ],
      "raw": "Artstein Gratch \n\t\t \n\t\t \n\t\t\t G Lucas \n\t\t \n\t\t \n\t\t\t Wood \n\t\t \n\t\t \n\t\t\t Bober \n\t\t \n\t\t \n\t\t\t Marsella \n\t\t \n\t\t \n\t\t\t Traum \n\t\t \n\t\t \n\t\t\t L Morency \n\t\t \n\t\t \n\t\t The distress analysis interview corpus of human and computer interviews. 59. tended A atabase ownload -A -W Z \n\t\t \n\t\t\t Apr \n\t\t \n\t \n\t Gratch , Artstein , Lucas G, tratou G, cherer , azarian A, Wood , Bober , eVault , Marsella , Traum , izzo , Morency L-. The distress analysis interview corpus of human and computer interviews. 59. tended A atabase ownload - A -W Z. . Available from: https: dcapswoz.ict.usc.edu e tended-daic-database-download [accessed Apr , ]"
    },
    {
      "title": "Classifying anxiety and depression through LLMs virtual interactions: a case study with ChatGPT",
      "authors": [
        "Y Tao",
        "M Yang",
        "H Shen",
        "Z Yang",
        "Z Weng",
        "B Hu"
      ],
      "year": 2023,
      "doi": "10.1109/bibm58861.2023.10385305",
      "raw": "Classifying anxiety and depression through LLMs virtual interactions: a case study with ChatGPT \n\t\t \n\t\t\t Y Tao \n\t\t \n\t\t \n\t\t\t M Yang \n\t\t \n\t\t \n\t\t\t H Shen \n\t\t \n\t\t \n\t\t\t Z Yang \n\t\t \n\t\t \n\t\t\t Z Weng \n\t\t \n\t\t \n\t\t\t B Hu \n\t\t \n\t\t 10.1109/bibm58861.2023.10385305 \n\t \n\t \n\t\t IEEE International Conference on Bioinformatics and Biomedicine \n\t\t \n\t\t\t BIBM \n\t\t\t 2023. 2023 \n\t\t\t \n\t\t \n\t \n\t Tao Y, Yang M, Shen H, Yang Z, Weng Z, Hu B. Classifying anxiety and depression through LLMs virtual interactions: a case study with ChatGPT. 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2023. p. 2259- 2264. doi: 10.1109/BIBM58861.2023.10385305"
    },
    {
      "title": "epression detection on Malay dialects usin G T-3",
      "authors": [
        "Mfm Hayati",
        "Ali Mamd"
      ],
      "journal": "MB onference on Biomedical n ineerin and ciences",
      "raw": "epression detection on Malay dialects usin G T-3 \n\t\t \n\t\t\t Mfm Hayati \n\t\t \n\t\t \n\t\t\t Ali Mamd \n\t\t \n\t\t \n\t\t\t Md \n\t\t \n\t \n\t \n\t\t MB onference on Biomedical n ineerin and ciences \n\t\t \n\t\t\t \n\t\t \n\t \n\t B ) \n\t Hayati MFM, Ali MAMd, osli A Md. epression detection on Malay dialects usin G T-3. -MB onference on Biomedical n ineerin and ciences ( B ) . p. 36 -36 . doi: . B . ."
    },
    {
      "title": "epression risk prediction for hinese microblo s via deep-learnin methods: ontent Analysis",
      "authors": [
        "T Li",
        "W Li",
        "Y Zhou",
        "Tan Yan"
      ],
      "journal": "M Med nform ul",
      "raw": "epression risk prediction for hinese microblo s via deep-learnin methods: ontent Analysis \n\t\t \n\t\t\t Wan \n\t\t \n\t\t \n\t\t\t T Li \n\t\t \n\t\t \n\t\t\t W Li \n\t\t \n\t\t \n\t\t\t Y Zhou \n\t\t \n\t\t \n\t\t\t Zhen \n\t\t \n\t\t \n\t\t\t Tan B Yan \n\t\t \n\t \n\t \n\t\t M Med nform ul \n\t\t \n\t\t\t \n\t\t \n\t \n\t Wan , hen , Li T, Li W, Zhou Y, Zhen , hen Q, Yan , Tan B. epression risk prediction for hinese microblo s via deep-learnin methods: ontent Analysis. M Med nform ul ; ( ):e . M :3 3"
    },
    {
      "title": "Generalized autore ressive pretrainin for lan ua e understandin",
      "authors": [
        "Z Yan",
        "Z Yan",
        "Le Et"
      ],
      "journal": "Biomed n May",
      "raw": "Generalized autore ressive pretrainin for lan ua e understandin \n\t\t \n\t\t\t Z Yan \n\t\t \n\t\t \n\t\t\t Z Yan \n\t\t \n\t\t \n\t\t\t Y \n\t\t \n\t\t \n\t\t\t Le Qv L Et \n\t\t \n\t \n\t \n\t\t Biomed n May \n\t\t \n\t\t\t \n\t\t \n\t \n\t ar iv \n\t Yan Z, ai Z, Yan Y, arbonell , alakhutdinov , Le QV. L et: Generalized autore ressive pretrainin for lan ua e understandin . ar iv; . doi: Biomed n May; ( ): - . M :3 106."
    },
    {
      "title": "hatG T: pportunities, risks and priorities for psychiatry",
      "authors": [
        "Y Wei",
        "L Guo"
      ],
      "journal": "Asian ournal of sychiatry",
      "volume": "3",
      "issue": "3",
      "raw": "hatG T: pportunities, risks and priorities for psychiatry \n\t\t \n\t\t\t Y Wei \n\t\t \n\t\t \n\t\t\t L Guo \n\t\t \n\t\t \n\t\t\t Lian \n\t\t \n\t\t \n\t\t\t Hen \n\t\t \n\t\t ajp. 3. 3 107 \n\t \n\t \n\t\t Asian ournal of sychiatry \n\t\t \n\t\t\t 3 \n\t\t\t 3 \n\t\t \n\t \n\t Wei Y, Guo L, Lian , hen . hatG T: pportunities, risks and priorities for psychiatry. Asian ournal of sychiatry 3 ec ; : 3 . doi: . 6 j.ajp. 3. 3 107"
    },
    {
      "title": "nvesti atin lar e lan ua e models' perception of emotion usin appraisal theory",
      "authors": [
        "Yon Satianchot",
        "G Torshizi"
      ],
      "volume": "3",
      "raw": "nvesti atin lar e lan ua e models' perception of emotion usin appraisal theory \n\t\t \n\t\t\t Yon Satianchot \n\t\t \n\t\t \n\t\t\t G Torshizi \n\t\t \n\t\t \n\t\t\t Marsella \n\t\t \n\t \n\t \n\t\t 3 th nternational onference on Affective omputin and ntelli ent nteraction Workshops and emos \n\t\t \n\t\t\t 3 \n\t\t \n\t \n\t Yon satianchot , Torshizi G, Marsella . nvesti atin lar e lan ua e models' perception of emotion usin appraisal theory. 3 th nternational onference on Affective omputin and ntelli ent nteraction Workshops and emos (A W) 3. p. -. doi: ."
    },
    {
      "title": "The impact of prompt en ineerin in lar e lan ua e model performance: a psychiatric e ample",
      "authors": [
        "A Grabb"
      ],
      "doi": "10.21037/jmai-23-71",
      "volume": "3",
      "raw": "The impact of prompt en ineerin in lar e lan ua e model performance: a psychiatric e ample \n\t\t \n\t\t\t A W Grabb \n\t\t \n\t\t 10.21037/jmai-23-71 \n\t\t 3 jmai-3- 110 \n\t\t \n\t\t \n\t\t\t 3 \n\t\t\t \n\t\t \n\t \n\t enova te t-davinci-3. Hu in Face . ournal of Medical Artificial ntelli ence AM ublishin ompany; 3 ct 3 ;6 \n\t A W . 3. 3 108. enova te t-davinci-3. Hu in Face. Available from: https: hu in face.co enova te t-davinci-3 [accessed Apr , ] 109. Grabb . The impact of prompt en ineerin in lar e lan ua e model performance: a psychiatric e ample. ournal of Medical Artificial ntelli ence AM ublishin ompany; 3 ct 3 ;6( ). doi: . 3 jmai-3- 110."
    },
    {
      "title": "linical accuracy of lar e lan ua e models and Goo le search responses to postpartum depression questions: cross-sectional study",
      "authors": [
        "Z Hadar",
        "M ; Lvovsky",
        "F Hekeni"
      ],
      "journal": "ournal of Medical nternet esearch",
      "volume": "3",
      "issue": "3",
      "raw": "linical accuracy of lar e lan ua e models and Goo le search responses to postpartum depression questions: cross-sectional study \n\t\t \n\t\t\t Z Hadar \n\t\t \n\t\t \n\t\t\t M ; Lvovsky \n\t\t \n\t\t \n\t\t\t F Hekeni \n\t\t \n\t\t \n\t\t\t Lee \n\t\t \n\t\t \n\t\t\t Keim \n\t\t \n\t\t doi: . 6 112 \n\t\t \n\t \n\t \n\t\t ournal of Medical nternet esearch \n\t\t \n\t\t\t 3 \n\t\t\t 3 \n\t\t\t \n\t\t \n\t \n\t The plasticity of hatG T's mentalizin abilities: personalization for personality structures Front sychiatry technolo y ai lamda [accessed Apr , ] 113 \n\t Hadar-hoval , lyoseph Z, Lvovsky M. The plasticity of hatG T's mentalizin abilities: personalization for personality structures. Front sychiatry 3; : 3 3 . M :3 111. ez in , hekeni F, Lee , Keim . linical accuracy of lar e lan ua e models and Goo le search responses to postpartum depression questions: cross-sectional study. ournal of Medical nternet esearch 3 ep ; ( ):e . doi: . 6 112. LaM A: our breakthrou h conversation technolo y. Goo le. . Available from: https: blo . oo le technolo y ai lamda [accessed Apr , ] 113."
    },
    {
      "title": "How do you feel? Usin natural lan ua e processin to automatically rate emotion in psychotherapy",
      "authors": [
        "M Tanana",
        "Berta Kuo",
        "V Nolli"
      ],
      "journal": "Behavior esearch Methods Mar",
      "volume": "3",
      "raw": "How do you feel? Usin natural lan ua e processin to automatically rate emotion in psychotherapy \n\t\t \n\t\t\t M Tanana \n\t\t \n\t\t \n\t\t\t Berta Kuo \n\t\t \n\t\t \n\t\t\t V Nolli \n\t\t \n\t\t \n\t\t\t Atkins \n\t\t \n\t\t doi: .3 s 3 --3 -z 114 \n\t \n\t \n\t\t Behavior esearch Methods Mar \n\t\t \n\t\t\t 3 \n\t\t \n\t \n\t Tanana M, oma , Kuo , Berta nolli , embe A, ace B, rikumar V, Atkins , mel Z. How do you feel? Usin natural lan ua e processin to automatically rate emotion in psychotherapy. Behavior esearch Methods Mar ; 3: -. doi: .3 s 3 --3 -z 114."
    },
    {
      "title": "and te t library databases that promote research, teachin , and learnin across disciplines, includin music, counselin , history, business and more| Ale ander treet",
      "pages": "116",
      "raw": "Welcome To L W - \n\t\t \n\t\t \n\t\t and te t library databases that promote research, teachin , and learnin across disciplines, includin music, counselin , history, business and more| Ale ander treet \n\t\t \n\t\t\t Apr \n\t\t\t 116 \n\t\t \n\t \n\t accessed Apr , ] 115. ublisher of streamin video, audio \n\t Welcome to L W -. Available from: https: www.liwc.app [accessed Apr , ] 115. ublisher of streamin video, audio, and te t library databases that promote research, teachin , and learnin across disciplines, includin music, counselin , history, business and more| Ale ander treet. Available from: https: ale anderstreet.com [accessed Apr , ] 116."
    },
    {
      "title": "Knowled e-enhanced pre-trainin lar e lan ua e model for depression dia nosis and treatment. 3 th nternational onference on loud omputin and ntelli ent ystems",
      "authors": [
        "K Liu"
      ],
      "volume": "3",
      "pages": "118",
      "raw": "Knowled e-enhanced pre-trainin lar e lan ua e model for depression dia nosis and treatment. 3 th nternational onference on loud omputin and ntelli ent ystems \n\t\t \n\t\t\t Wan \n\t\t \n\t\t \n\t\t\t K Liu \n\t\t \n\t\t \n\t\t\t Wan \n\t\t \n\t\t 3. 63 117 \n\t\t \n\t\t L docs lan ua e_modelin \n\t\t \n\t\t\t Apr \n\t\t\t 3 \n\t\t\t 118 \n\t\t \n\t \n\t Wan , Liu K, Wan . Knowled e-enhanced pre-trainin lar e lan ua e model for depression dia nosis and treatment. 3 th nternational onference on loud omputin and ntelli ent ystems ( ) 3. p. 3 -36. doi: . . 3. 63 117. hinese L docs lan ua e_modelin .md at master \u2022 didi hinese L . GitHub. Available from: https: ithub.com didi hinese L blob master docs lan ua e_modelin .md [accessed Apr , ] 118."
    },
    {
      "title": "erformance of lar e lan ua e models on a neurolo y board-style e amination",
      "authors": [
        "M Chubert",
        "W Wick",
        "V Venkataramani"
      ],
      "doi": "10.1186/s13033-020-00356-9",
      "journal": "AMA etw pen 3 ec",
      "volume": "6",
      "issue": "3 6",
      "pages": "133",
      "raw": "erformance of lar e lan ua e models on a neurolo y board-style e amination \n\t\t \n\t\t\t M Chubert \n\t\t \n\t\t \n\t\t\t W Wick \n\t\t \n\t\t \n\t\t\t V Venkataramani \n\t\t \n\t\t 10.1186/s13033-020-00356-9 \n\t\t \n\t \n\t \n\t\t AMA etw pen 3 ec \n\t\t \n\t\t\t 6 \n\t\t\t 3 6 \n\t\t\t 133 \n\t\t \n\t \n\t eurolo y Board eview Questions BoardVitals Health yst \n\t chubert M , Wick W, Venkataramani V. erformance of lar e lan ua e models on a neurolo y board-style e amination. AMA etw pen 3 ec ;6( ):e 3 6 . M :3 6 3 119. eurolo y Board eview Questions [ ] -BoardVitals. Available from: Health yst. ; : 3. https: doi.or . 6 s 3 33--3 6- 133."
    },
    {
      "title": "A review on sentiment analysis and emotion detection from text",
      "authors": [
        "P Nandwani",
        "R Verma"
      ],
      "year": 2021,
      "journal": "Soc Netw Anal Min",
      "volume": "11",
      "issue": "1",
      "pages": "81",
      "raw": "A review on sentiment analysis and emotion detection from text \n\t\t \n\t\t\t P Nandwani \n\t\t \n\t\t \n\t\t\t R Verma \n\t\t \n\t\t 34484462 \n\t \n\t \n\t\t Soc Netw Anal Min \n\t\t \n\t\t\t 11 \n\t\t\t 1 \n\t\t\t 81 \n\t\t\t 2021 \n\t\t \n\t \n\t Nandwani P, Verma R. A review on sentiment analysis and emotion detection from text. Soc Netw Anal Min 2021;11(1):81. PMID:34484462 134"
    },
    {
      "title": "A survey on hallucination in large language models: principles, taxonomy, challenges, and open questions",
      "authors": [
        "L Huang",
        "W Yu",
        "W Ma",
        "W Zhong",
        "Z Feng",
        "H Wang",
        "Q Chen",
        "W Peng",
        "X Feng",
        "B Qin",
        "T Liu"
      ],
      "year": 2023,
      "doi": "10.48550/arXiv.2311.05232",
      "pages": "135",
      "raw": "A survey on hallucination in large language models: principles, taxonomy, challenges, and open questions \n\t\t \n\t\t\t L Huang \n\t\t \n\t\t \n\t\t\t W Yu \n\t\t \n\t\t \n\t\t\t W Ma \n\t\t \n\t\t \n\t\t\t W Zhong \n\t\t \n\t\t \n\t\t\t Z Feng \n\t\t \n\t\t \n\t\t\t H Wang \n\t\t \n\t\t \n\t\t\t Q Chen \n\t\t \n\t\t \n\t\t\t W Peng \n\t\t \n\t\t \n\t\t\t X Feng \n\t\t \n\t\t \n\t\t\t B Qin \n\t\t \n\t\t \n\t\t\t T Liu \n\t\t \n\t\t 10.48550/arXiv.2311.05232 \n\t\t \n\t\t\t 2023 \n\t\t\t 135 \n\t\t \n\t \n\t reprint \n\t Huang L, Yu W, Ma W, Zhong W, Feng Z, Wang H, Chen Q, Peng W, Feng X, Qin B, Liu T. A survey on hallucination in large language models: principles, taxonomy, challenges, and open questions. arXiv; 2023. doi: 10.48550/arXiv.2311.05232 [ reprint] 135"
    },
    {
      "title": "GPT-4, and other large language models: the next revolution for clinical microbiology?",
      "authors": [
        "A Egli"
      ],
      "year": 2023,
      "journal": "Clin Infect Dis",
      "volume": "77",
      "issue": "9",
      "raw": "GPT-4, and other large language models: the next revolution for clinical microbiology? \n\t\t \n\t\t\t A Egli \n\t\t \n\t\t \n\t\t\t Chatgpt \n\t\t \n\t\t 37399030 \n\t \n\t \n\t\t Clin Infect Dis \n\t\t \n\t\t\t 77 \n\t\t\t 9 \n\t\t\t \n\t\t\t 2023 Jul 3 \n\t\t \n\t \n\t Egli A. ChatGPT, GPT-4, and other large language models: the next revolution for clinical microbiology? Clin Infect Dis 2023 Jul 3;77(9):1322-1328. PMID:37399030 136."
    },
    {
      "title": "Beneficent dehumanization: employing artificial intelligence and Carebots to mitigate shame-induced barriers to medical care",
      "authors": [
        "A Palmer",
        "D Schwan"
      ],
      "year": 2022,
      "doi": "10.1111/bioe.12986137",
      "journal": "Bioethics",
      "volume": "36",
      "issue": "2",
      "raw": "Beneficent dehumanization: employing artificial intelligence and Carebots to mitigate shame-induced barriers to medical care \n\t\t \n\t\t\t A Palmer \n\t\t \n\t\t \n\t\t\t D Schwan \n\t\t \n\t\t 10.1111/bioe.12986137 \n\t \n\t \n\t\t Bioethics \n\t\t \n\t\t\t 36 \n\t\t\t 2 \n\t\t\t \n\t\t\t 2022 \n\t\t \n\t \n\t Palmer A, Schwan D. Beneficent dehumanization: employing artificial intelligence and Carebots to mitigate shame-induced barriers to medical care. Bioethics 2022;36(2):187-193. doi: 10.1111/bioe.12986 137"
    },
    {
      "title": "Dehumanization in medicine: causes, solutions, and functions",
      "authors": [
        "O Haque",
        "A Waytz"
      ],
      "year": 2012,
      "doi": "10.1177/1745691611429706138",
      "volume": "7",
      "pages": "142",
      "raw": "Dehumanization in medicine: causes, solutions, and functions \n\t\t \n\t\t\t O S Haque \n\t\t \n\t\t \n\t\t\t A Waytz \n\t\t \n\t\t 10.1177/1745691611429706138 \n\t\t \n\t \n\t \n\t\t What Is Retrieval Augmented Generation (RAG)? Google Cloud \n\t\t \n\t\t\t SAGE Publications Inc \n\t\t\t 2012 Mar 1. Aug 8, 2024. Aug 8, 2024. Aug 8, 2024 \n\t\t\t 7 \n\t\t\t 142 \n\t\t \n\t \n\t ma e inputs for hatG T -FAQ What is RAG? -Retrieval-Augmented Generation Explained \n\t Haque OS, Waytz A. Dehumanization in medicine: causes, solutions, and functions. Perspect Psychol Sci SAGE Publications Inc; 2012 Mar 1;7(2):176-186. doi: 10.1177/1745691611429706 138. penA Help enter. ma e inputs for hatG T -FAQ. Available at: https: help.openai.com en articles -ima e-inputs-for-chat pt-faq [accessed Apr , ] 139. What is RAG? -Retrieval-Augmented Generation Explained -AWS. Available from: https://aws.amazon.com/cn/what-is/retrieval-augmented-generation/ [accessed Aug 8, 2024] 140. Models -OpenAI API. Available from: https://platform.openai.com/docs/models/gpt- 4-turbo-and-gpt-4 [accessed Aug 8, 2024] 141. What Is Retrieval Augmented Generation (RAG)? Google Cloud. Available from: https://cloud.google.com/use-cases/retrieval-augmented-generation [accessed Aug 8, 2024] 142"
    },
    {
      "title": "Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation",
      "authors": [
        "N M\u00fcndler",
        "J He",
        "S Jenko",
        "M Vechev"
      ],
      "year": 2024,
      "doi": "10.48550/arXiv.2305.15852",
      "pages": "143",
      "raw": "Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation \n\t\t \n\t\t\t N M\u00fcndler \n\t\t \n\t\t \n\t\t\t J He \n\t\t \n\t\t \n\t\t\t S Jenko \n\t\t \n\t\t \n\t\t\t M Vechev \n\t\t \n\t\t 10.48550/arXiv.2305.15852 \n\t\t \n\t\t\t 2024 \n\t\t\t 143 \n\t\t \n\t \n\t reprint \n\t M\u00fcndler N, He J, Jenko S, Vechev M. Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation. arXiv; 2024. doi: 10.48550/arXiv.2305.15852 [ reprint] 143"
    },
    {
      "title": "Metric Ensembles For Hallucination Detection",
      "authors": [
        "G Forbes",
        "P Katlana",
        "Z Ortiz"
      ],
      "year": 2023,
      "doi": "10.48550/arXiv.2310.10495",
      "raw": "Metric Ensembles For Hallucination Detection \n\t\t \n\t\t\t G C Forbes \n\t\t \n\t\t \n\t\t\t P Katlana \n\t\t \n\t\t \n\t\t\t Z Ortiz \n\t\t \n\t\t 10.48550/arXiv.2310.10495 \n\t\t 144 \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Preprint \n\t Forbes GC, Katlana P, Ortiz Z. Metric Ensembles For Hallucination Detection. arXiv; 2023. doi: 10.48550/arXiv.2310.10495 [Preprint] 144"
    },
    {
      "title": "Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications",
      "authors": [
        "R Bhayana"
      ],
      "year": 2024,
      "doi": "10.1148/radiol.232756145",
      "volume": "310",
      "pages": "147",
      "raw": "Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications \n\t\t \n\t\t\t R Bhayana \n\t\t \n\t\t 10.1148/radiol.232756145 \n\t\t \n\t \n\t \n\t\t LLM Optimization Parameters. Generative AI Wiki \n\t\t \n\t\t\t 2024 Jan. Apr 27, 2024. Apr 27, 2024 \n\t\t\t 310 \n\t\t\t 147 \n\t\t \n\t \n\t What is LLM Temperature \n\t Bhayana R. Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications. Radiology Radiological Society of North America; 2024 Jan;310(1):e232756. doi: 10.1148/radiol.232756 145. What is LLM Temperature. Iguazio. Available from: https://www.iguazio.com/glossary/llm-temperature/ [accessed Apr 27, 2024] 146. LLM Optimization Parameters. Generative AI Wiki. Available from: https://attri.ai/generative-ai-wiki/llm-optimization-parameters [accessed Apr 27, 2024] 147"
    },
    {
      "title": "A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly",
      "authors": [
        "Y Yao",
        "J Duan",
        "K Xu",
        "Y Cai",
        "Z Sun",
        "Y Zhang"
      ],
      "year": 2024,
      "doi": "10.1016/j.hcc.2024.100211148",
      "journal": "High-Confidence Computing",
      "volume": "4",
      "issue": "2",
      "pages": "100211",
      "raw": "A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly \n\t\t \n\t\t\t Y Yao \n\t\t \n\t\t \n\t\t\t J Duan \n\t\t \n\t\t \n\t\t\t K Xu \n\t\t \n\t\t \n\t\t\t Y Cai \n\t\t \n\t\t \n\t\t\t Z Sun \n\t\t \n\t\t \n\t\t\t Y Zhang \n\t\t \n\t\t 10.1016/j.hcc.2024.100211148 \n\t \n\t \n\t\t High-Confidence Computing \n\t\t \n\t\t\t 4 \n\t\t\t 2 \n\t\t\t 100211 \n\t\t\t 2024 Jun 1 \n\t\t \n\t \n\t Yao Y, Duan J, Xu K, Cai Y, Sun Z, Zhang Y. A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly. High-Confidence Computing 2024 Jun 1;4(2):100211. doi: 10.1016/j.hcc.2024.100211 148"
    },
    {
      "title": "Recovering from privacy-preserving masking with large language models",
      "authors": [
        "A Vats",
        "Z Liu",
        "P Su",
        "D Paul",
        "Y Ma",
        "Y Pang",
        "Z Ahmed",
        "O Kalinli"
      ],
      "year": 2024,
      "doi": "10.1109/ICASSP48485.2024.10448234149",
      "raw": "Recovering from privacy-preserving masking with large language models \n\t\t \n\t\t\t A Vats \n\t\t \n\t\t \n\t\t\t Z Liu \n\t\t \n\t\t \n\t\t\t P Su \n\t\t \n\t\t \n\t\t\t D Paul \n\t\t \n\t\t \n\t\t\t Y Ma \n\t\t \n\t\t \n\t\t\t Y Pang \n\t\t \n\t\t \n\t\t\t Z Ahmed \n\t\t \n\t\t \n\t\t\t O Kalinli \n\t\t \n\t\t 10.1109/ICASSP48485.2024.10448234149 \n\t\t \n\t \n\t \n\t\t The Black Bo roblem: opaque inner workin s of lar e lan ua e models. rompt n ineerin . 3 ct 3. Available from: https: prompten ineerin .or the \n\t\t \n\t\t\t ICASSP \n\t\t\t 2024. Apr. Apr 27, 2024 \n\t\t\t \n\t\t \n\t \n\t ICASSP 2024 -2024 IEEE International Conference on Acoustics, Speech and Signal Processing -blackbo -problem-opaque-inner LLM Optimization Parameters. Generative AI Wiki \n\t Vats A, Liu Z, Su P, Paul D, Ma Y, Pang Y, Ahmed Z, Kalinli O. Recovering from privacy-preserving masking with large language models. ICASSP 2024 -2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2024. p. 10771-10775. doi: 10.1109/ICASSP48485.2024.10448234 149. The Black Bo roblem: opaque inner workin s of lar e lan ua e models. rompt n ineerin . 3 ct 3. Available from: https: prompten ineerin .or the-black- bo -problem-opaque-inner-workin s-of-lar e-lan ua e-models [accessed Apr , ] 150. LLM Optimization Parameters. Generative AI Wiki. Available from: https://attri.ai/generative-ai-wiki/llm-optimization-parameters [accessed Apr 27, 2024]"
    }
  ],
  "num_references": 80,
  "figures": [
    {
      "caption": "Figure 1 .",
      "description": "Figure 1. Comparative analysis of LLMs by parameter size and developer entity. The bar chart"
    },
    {
      "caption": "Figure 2 .",
      "description": "Figure 2. PRISMA flow of selection process."
    },
    {
      "caption": "Figure 3 .",
      "description": "Figure 3. Number of articles included in this literature review, grouped by year of publication and application field. The black line indicates the total number of articles in each year."
    },
    {
      "description": ", Birrell L, Kershaw , evine K, Thornton L. an we use hatG T for mental health and substance use education? e aminin its quality and potential harms. M Medical ducation M ublications nc.; 3; . M :3 3 103. racks in the ce. vidence-Based nformation for the ommunity. racks in the ce.Available from: https: cracksintheice.or .au [accessed Apr , ] 104. ositive hoices: ru and Alcohol ducation -Get informed, stay smart, stay safeositive hoices. Available from: https: positivechoices.or .au [accessed Apr , ] 105. Farhat F. hatG T as a complementary mental health resource: a boon or a bane. Ann"
    },
    {
      "type": "table",
      "caption": "Table 3",
      "description": "/www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset [accessed Aug 6, 2024] 78. Ghanadian H, Nejadgholi I, Al Osman H. Socially aware synthetic data generation for suicidal ideation detection using large language models. IEEE Access 2024 Jan 22;PP. doi: 10.1109/ACCESS.2024.3358206 79. FLAN-T5. Available from: https://huggingface.co/docs/transformers/model_doc/flan-t5 [accessed Aug 6, 2024] 80. H. Ghanadian, . ejad holi and H. Al sman, \" hatG T for suicide risk assessment on social media: Quantitative evaluation of model performance potentials and limitations\", arXiv:2306.09390, 3 81. Lossio-Ventura JA, Weger R, Lee AY, Guinee EP, Chung J, Atlas L, Linos E, Pereira F. A comparison of ChatGPT and fine-tuned open pre-trained transformers (OPT) against widely used sentiment analysis tools: sentiment analysis of COVID-19 survey data. JMIR Ment Health 2024 Jan 25;11:e50150. PMID:38271138 82. hun Y, Gibbons A, Atlas L, Ballard , rnst M, apee , et al. V -and mental health: predicted mental health status is associated with clinical symptoms and pandemic-related psycholo ical and behavioral responses. med iv. ct . [ reprint] 83. elson LM, imard F, luyomi A, ava V, osas LG, Bondy M, et al. U public concerns about the V -pandemic from results of a survey iven via social media. -A, n , esurreccion . Therapist vibe: children's e pressions of their emotions throu h storytellin with a chatbot. roceedin s of the nteraction esi n and hildren onference ew York, Y, U A: Association for omputin Machinery; . p. 3-. doi: . 33 63.33 86. odri o M. Towards buildin mental health resilience throu h storytellin with a chatbot. roceedin s of the th nternational onference on omputers in ducation Montene ro , n . nvesti atin the acceptability and perceived effectiveness of a chatbot in helpin students assess their well-bein . roceedin s of the Asian H ymposium ew York, Y, U A: Association for omputin Machinery; . p. 3 -. doi: . 3 36 .3 6 90. H. A. chwartz, M. ap, M. L. Kern, . . ichstaedt, A. Kapelner, M. A rawal, et al., \" redictin individual well-bein throu h the lan ua e of social media\", Biocomputin 6: roceedin s of the acific ymposium, pp. 6-, 6 91. rasto , ias L, Miranda , Kayande . areBot: A mental health chatbot. A latform. uperior ustomer periences tart Here. Available from: https: rasa.com [accessed Apr , ] 94. spa y \u2022 ndustrial-stren th atural Lan ua e rocessin in ython. Available from: https: spacy.io [accessed Apr , ] 95. Li Y, u H, hen , Li W, ao Z, iu . aily ialo : A manually labelled multi-turn dialo ue dataset. ar iv; . doi: . ar iv. . 3 [ reprint] 96. Heston TF. afety of lar e lan ua e models in addressin depression. ureus ( ):e . M :3 3 97. Alessa A, Al-Khalifa H. Towards designing a ChatGPT conversational companion for elderly people. Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments New York, NY, USA: Association for Computing Machinery; 2023. p. 667-674. doi: 10.1145/3594806.3596572 98. He W, Zhang W, Jin Y, Zhou Q, Zhang H, Xia Q. Physician versus large language model chatbot responses to web-based questions from autistic patients in Chinese: cross-sectional comparative analysis. J Med Internet Res 2024 Apr 30;26:e54706. PMID:38687566 99. Deng Z, Liu S, Evans R. Knowledge transfer between physicians from different geographical regions in China's online health communities. Inf Technol Manag. 2023.:1-18 100. Franco ' ouza , Amanullah , Mathew M, urapaneni KM. Appraisin the performance of hatG T in psychiatry usin clinical case vi nettes. Asian ournal of sychiatry 3 ov ; : 3 . doi: . 6 j.ajp. 3. 3 101. Wri ht B, ave , o ra . cases in psychiatry. nd ed. Boca aton: ress; . doi: ."
    }
  ],
  "num_figures": 5,
  "tables": [
    {
      "content": ": MA hecklist"
    }
  ],
  "num_tables": 1,
  "formulas": [
    {
      "text": "i. M L (n ) ii. plore (n ) iii. M (n ) iv. copus (n ) v. A M (n ) -ot"
    }
  ],
  "num_formulas": 1,
  "num_citations": 218,
  "cited_references": [
    "b3",
    "b13",
    "b39",
    "b41",
    "b18",
    "b44",
    "b49",
    "b2",
    "b58",
    "b14",
    "b17",
    "b36",
    "b25",
    "b59",
    "b9",
    "b1",
    "b35",
    "b20",
    "b43",
    "b21",
    "b47",
    "b40",
    "b12",
    "b42",
    "b30",
    "b31",
    "b29",
    "b16",
    "b37",
    "b46",
    "b15",
    "b23",
    "b32",
    "b5",
    "b19",
    "b28",
    "b45",
    "b10",
    "b38",
    "b27",
    "b24",
    "b4",
    "b56",
    "b33",
    "b7",
    "b48",
    "b11",
    "b8",
    "b53",
    "b22",
    "b34",
    "b6",
    "b0",
    "b26"
  ],
  "notes": [
    "[raw_affiliation] 1  Institute of Health Informatics , University College London",
    "[raw_affiliation] 1  Institute of Health Informatics , University College London",
    "[raw_affiliation] 1  Institute of Health Informatics , University College London",
    "[raw_affiliation] 1  Institute of Health Informatics , University College London",
    "[raw_affiliation] 1  Institute of Health Informatics , University College London",
    "[raw_affiliation] 2  GOS Institute of Child Health , University College London Institute of Health Informatics University College London 222 Euston Road London United Kingdom",
    "[raw_affiliation] 1  Institute of Health Informatics , University College London",
    "[raw_reference] World Health Organization. Mental health: strengthening our response. 2022. Available from: https://www.who.int/news-room/fact-sheets/detail/mental-health-strengthening- our-response [accessed Apr 15, 2024]",
    "[raw_reference] World Health Organization. Mental disorders. 2022. Available from: https://www.who.int/news-room/fact-sheets/detail/mental-disorders [accessed Apr 15, 2024]",
    "[raw_reference] Zaken M van A. MHPSS worldwide: facts and figures -Mental health and psychosocial support in crisis situations. Ministerie van Algemene Zaken; 2023. Available from: https://www.government.nl/topics/mhpss/mhpss-worldwide-facts-and-figures [accessed Apr 15, 2024]",
    "[raw_reference] Arias D, Saxena S, Verguet S. Quantifying the global burden of mental disorders and their economic value. eClinicalMedicine Elsevier; 2022 Dec 1;54. PMID:36193171",
    "[raw_reference] Zhang W, Yang C, Cao Z, Li Z, Zhuo L, Tan Y, He Y, Yao L, Zhou Q, Gong Q, Sweeney JA, Shi F, Lui S. Detecting individuals with severe mental illness using artificial intelligence applied to magnetic resonance imaging. eBioMedicine Elsevier; 2023 Apr 1;90. PMID:36996601",
    "[raw_reference] World Health Organization. Mental health and COVID-19: Early evidence of the pandemic's impact: cientific brief . 2022 Mar 2. Available from: https://www.who.int/publications/i/item/WHO-2019-nCoV-Sci_Brief-Mental_health- 2022.1 [accessed Apr 15, 2024]",
    "[raw_reference] Duden GS, Gersdorf S, Stengler K. Global impact of the COVID-19 pandemic on mental health services: A systematic review. J Psychiatr Res 2022 Oct;154:354-377. PMID:36055116",
    "[raw_reference] Mental Health America. Mental health treatments. 2023. Available from: https://mhanational.org/mental-health-treatments [accessed Apr 15, 2024]",
    "[raw_reference] Stigma, prejudice and discrimination against people with mental illness. Available from: https://www.psychiatry.org:443/patients-families/stigma-and-discrimination [accessed Apr 15, 2024]",
    "[raw_reference] Why do people avoid mental health treatment? Thriveworks. 2019. Available from: https://thriveworks.com/blog/why-people-avoid-mental-health-treatment/ [accessed Apr 15, 2024]",
    "[raw_reference] Almost half of Americans don't seek professional help for mental disorders. Available from: https://www.forbes.com/sites/michaeltnietzel/2021/05/24/why-so-many- americans-do-not-seek-professional-help-for-mental-disorders/?sh=55b4ec4b3de7 [accessed Apr 15, 2024]",
    "[raw_reference] Torous J, Myrick KJ, Rauseo-Ricupero N, Firth J. Digital mental health and COVID- 19: using technology today to accelerate the curve on access and quality tomorrow. JMIR Ment Health. 2020;7(3):e18848.",
    "[raw_reference] Kumar V, Srivastava P, Dwivedi A, Budhiraja I, Ghosh D, Goyal V, Arora R. Large- language-models (LLM)-based AI chatbots: architecture, in-depth analysis and their performance evaluation. In: Santosh K, Makkar A, Conway M, Singh AK, Vacavant A, Abou el Kalam A, Bouguelia M-R, Hegadi R, editors. Recent Trends in Image Processing and Pattern Recognition Cham: Springer Nature Switzerland; 2024. p. 237- 249. doi: 10.1007/978-3-031-53085-2_20",
    "[raw_reference] Ma Z, Mei Y, Su Z. Understanding the benefits and challenges of using large language model-based conversational agents for mental well-being support. AMIA Annu Symp Proc 2024 Jan 11;2023:1105-1114. PMID:38222348",
    "Preprint",
    "[raw_reference] Yang K, Ji S, Zhang T, Xie Q, Kuang Z, Ananiadou S. Towards interpretable mental health analysis with large language models. arXiv. 2023. https://doi.org/10.48550/arXiv.2304.03347 [Preprint]",
    "[raw_reference] The Guardian. NHS mental health patients wait times. 2022. Available from: https://www.theguardian.com/society/2022/oct/10/nhs-mental-health-patients-wait- times [accessed Apr 16, 2024]",
    "[raw_reference] Elyoseph Z, Gur T, Haber Y, Simon T, Angert T, Navon Y, Tal A, Asman O. An ethical perspective on the democratization of mental health with generative artificial intelligence. 2024. doi: 10.2196/preprints.58011",
    "[raw_reference] Fitzpatrick KK, Darcy A, Vierhile M. Delivering Cognitive Behavior Therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial. JMIR Mental Health 2017 Jun 6;4(2):e7785. doi: 10.2196/mental.7785",
    "Internet",
    "[raw_reference] Wysa-Everyday Mental Health. n.d. Wysa -Everyday mental health [Internet]. Available from: https://www.wysa.com/ [accessed Apr 16, 2024]",
    "[raw_reference] Haque MDR, Rubya S. An overview of chatbot-based mobile mental health apps: insights from App description and user reviews. JMIR Mhealth Uhealth 2023 May 22;11:e44838. PMID:37213181",
    "[raw_reference] Stade EC, Stirman SW, Ungar LH, Boland CL, Schwartz HA, Yaden DB, Sedoc J, DeRubeis RJ, Willer R, Eichstaedt JC. Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation. npj Mental Health Res Nature Publishing Group; 2024 Apr 2;3(1):1-12. doi: 10.1038/s44184-024-00056-z",
    "[raw_reference] Harrer S. Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine. eBioMedicine Elsevier; 2023 Apr 1;90. PMID:36924620",
    "[raw_reference] World Health Organization. Ethics and governance of artificial intelligence for health: guidance on large multi-modal models. 2024. Available from: Available from: https://iris.who.int/bitstream/handle/10665/375579/9789240084759-eng.pdf? [accessed Apr 16, 2024]",
    "[raw_reference] What are large language models (LLMs)? IBM. Available from: https://www.ibm.com/topics/large-language-models [accessed Apr 16, 2024]",
    "[raw_reference] Nucci A. LLM evaluation: Large language models performance metrics. Aisera: best Generative AI Platform For Enterprise. 2023. Available from: https://aisera.com/blog/llm-evaluation/ [accessed Apr 16, 2024]",
    "[raw_reference] OpenAI. Better language models. 2023. Available from: https://openai.com/research/better-language-models [accessed Apr 16, 2024]",
    "Preprint",
    "[raw_reference] Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I. Attention is all you need. 2017. Available from: https://doi.org/10.48550/arXiv.1706.03762 [Preprint]",
    "[raw_reference] What are Large Language Models? Definition from TechTarget. WhatIs. Available from: https://www.techtarget.com/whatis/definition/large-language-model-LLM [accessed May 16, 2024]",
    "[raw_reference] Devlin J, Chang M-W, Lee K, Toutanova K. BERT: pre-training of deep bidirectional transformers for language understanding. arXiv; 2019. doi: 10.48550/arXiv.1810.04805",
    "[raw_reference] Rogers A, Kovaleva O, Rumshisky A. A primer in BERTology: what we know about how BERT works. arXiv; 2020. doi: 10.48550/arXiv.2002.12327",
    "[raw_reference] ChatGPT turns 1: How the AI chatbot has completely changed the world. euronews. 2023. Available from: https://www.euronews.com/next/2023/11/30/chatgpt-a-year-on- 3-ways-the-ai-chatbot-has-completely-changed-the-world-in-12-months [accessed Apr 16, 2024]",
    "[raw_reference] Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med. 2023;29(8):Article 8. DOI: 10.1038/s41591- 023-02448-8",
    "[raw_reference] Updated GH from JC last. The best large language models (LLMs) of 2024. TechRadar. 2024. Available from: https://www.techradar.com/computing/artificial- intelligence/best-llms [accessed Aug 8, 2024]",
    "Top large language model examples in",
    "[raw_reference] Top large language model examples in 2024. AIMultiple: High Tech Use Cases & Tools to Grow Your Business. Available from: https://research.aimultiple.com/large- language-models-examples/ [accessed Apr 16, 2024]",
    "Public-facing-username-for-plugin",
    "[raw_reference] Public-facing-username-for-plugin. Timeline of AI and language models. Dr Alan D Thompson -Life Architect. 2021. Available from: https://lifearchitect.ai/timeline/ [accessed Apr 16, 2024]",
    "[raw_reference] Priest M. Large language models explained. Boost.ai. 2023. Available from: https://boost.ai/blog/llms-large-language-models [accessed Apr 16, 2024]",
    "[raw_reference] Vucetic D, Tayaranian M, Ziaeefard M, Clark JJ, Meyer BH, Gross WJ. Efficient Fine- Tuning of BERT Models on the Edge. 2022 IEEE International Symposium on Circuits and Systems (ISCAS) 2022. p. 1838-1842. doi: 10.1109/ISCAS48785.2022.9937567",
    "[raw_reference] Kumar M. Understanding large language models and fine-tuning for business scenarios: a simple guide. Medium. 2023. Available from: https://medium.com/@careerInAI/understanding-large-language-models-and-fine- tuning-for-business-scenarios-a-simple-guide-42f44cb687f0 [accessed Apr 16, 2024]",
    "Long Papers",
    "[raw_reference] Mishra S, Khashabi D, Baral C, Hajishirzi H. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. In: Muresan S, Nakov P, Villavicencio A, editors. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) Dublin, Ireland: Association for Computational Linguistics; 2022. p. 3470-3487. doi: 10.18653/v1/2022.acl-long.244",
    "[raw_reference] Instruction Tuning for Large Language Models: A Survey. Available from: https://arxiv.org/html/2308.10792v5 [accessed May 13, 2024]",
    "Preprint",
    "[raw_reference] Berryman AZ ohn. A developer's uide to prompt en ineerin and LLMs. The GitHub Blog. 2023. Available from: https://github.blog/2023-07-17-prompt-engineering- guide-generative-ai-llms/ [accessed Apr 15, 2024] [Preprint]",
    "[raw_reference] Bender EM, Koller A. Climbing towards NLU: on meaning, form, and understanding in the age of data. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020;5185-5198. https://doi.org/10.18653/v1/2020.acl- main.463",
    "[raw_reference] Lee J, Yoon W, Kim S, Kim D, Kim S, So CH, Kang J. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics. 2019;36(4):1234-1240. DOI: 10.1093/bioinformatics/btz682",
    "Preprint",
    "[raw_reference] Huang K, Altosaar J, Ranganath R. Clinicalbert: Modeling clinical notes and predicting hospital readmission. arXiv. 2020. Available from: https://arxiv.org/abs/1904.05342 [Preprint].",
    "[raw_reference] Zhang K, Liu X, Shen J, Li Z, Sang Y, Wu X, Zha Y, et al. Clinically applicable AI system for accurate diagnosis, quantitative measurements, and prognosis of COVID-19 pneumonia using computed tomography. Cell. 2020;182(5):1360. DOI: 10.1016/j.cell.2020.08.029",
    "[raw_reference] Trengove M, Vandersluis , Goetz L. esponse to \"Attention is not all you need: the complicated case of ethically usin lar e lan ua e models in healthcare and medicine.\" eBioMedicine Elsevier; 2023 Jul 1;93. PMID:37327676",
    "[raw_reference] Le Glaz A, Haralambous Y, Kim-Dufor D, Lenca P, Billot R, Ryan TC, Marsh J, DeVylder J, Walter M, Berrouiguet S, Lemey C. Machine learning and natural language processing in mental health: systematic review. J Med Internet Res. 2021;23(5):e15708. DOI: 10.2196/15708. PMID: 33944788. PMCID: PMC8132982",
    "Preprint",
    "[raw_reference] Hua Y, Liu F, Yang K, Li Z, Sheu Y, Zhou P, Moran LV, Ananiadou S, Beam A. Large Language Models in Mental Health Care: a Scoping Review. arXiv; 2024. doi: 10.48550/arXiv.2401.02984 [Preprint]",
    "[raw_reference] Moher D. Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement. Ann Intern Med. 2009;151(4):264. DOI: 10.7326/0003-4819-151- 4-200908180-00135",
    "[raw_reference] Verma S, Vishal, Joshi RC, Dutta MK, Jezek S, Burget R. AI-enhanced mental health diagnosis: leveraging Transformers for early detection of depression tendency in textual data. 2023 15th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT) 2023. p. 56-61. doi: 10.1109/ICUMT61075.2023.10333301",
    "Preprint",
    "[raw_reference] Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M, Zettlemoyer L, Stoyanov V. RoBERTa: a robustly optimized BERT pretraining approach. arXiv. 2019. Available from: https://doi.org/10.48550/arXiv.1907.11692 [Preprint]",
    "[raw_reference] Mental Health Corpus. Available from: https://www.kaggle.com/datasets/reihanenamdari/mental-health-corpus [accessed Apr 17, 2024]",
    "[raw_reference] Depression: Reddit Dataset (Cleaned). Available from: https://www.kaggle.com/datasets/infamouscoder/depression-reddit-cleaned [accessed Apr 17, 2024]",
    "[raw_reference] Diniz EJS, Fontenele JE, de Oliveira AC, Bastos VH, Teixeira S, Rab\u00ea lo RL, Cal\u00e7 ada DB, Dos Santos RM, de Oliveira AK, Teles AS. Boamente: a natural language processing-based digital phenotyping tool for smart monitoring of suicidal ideation. Healthcare (Basel) 2022 Apr 8;10(4):698. PMID:35455874",
    "[raw_reference] Souza F, Nogueira R, Lotufo R. BERTimbau: pretrained BERT models for Brazilian Portuguese. In: Cerri R, Prati RC, editors. Intelligent Systems Cham: Springer International Publishing; 2020. p. 403-417. doi: 10.1007/978-3-030-61377-8_28",
    "[raw_reference] Danner M, Hadzic B, Gerhardt S, Ludwig S, Uslu I, Shao P, Weber T, Shiban Y, Ratsch M. Advancing mental health diagnostics: GPT-based method for depression detection. 2023 62nd Annual Conference of the Society of Instrument and Control Engineers (SICE) 2023. p. 1290-1296. doi: 10.23919/SICE59929.2023.10354236",
    "[raw_reference] Gratch , Artstein , Lucas G, tratou G, cherer , azarian A, Wood , Bober , eVault , Marsella , Traum , izzo , Morency L-. The distress analysis interview corpus of human and computer interviews. 59. tended A atabase ownload - A -W Z. . Available from: https: dcapswoz.ict.usc.edu e tended-daic-database-download [accessed Apr , ]",
    "[raw_reference] Tao Y, Yang M, Shen H, Yang Z, Weng Z, Hu B. Classifying anxiety and depression through LLMs virtual interactions: a case study with ChatGPT. 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2023. p. 2259- 2264. doi: 10.1109/BIBM58861.2023.10385305",
    "B )",
    "[raw_reference] Hayati MFM, Ali MAMd, osli A Md. epression detection on Malay dialects usin G T-3. -MB onference on Biomedical n ineerin and ciences ( B ) . p. 36 -36 . doi: . B . .",
    "[raw_reference] Wan , hen , Li T, Li W, Zhou Y, Zhen , hen Q, Yan , Tan B. epression risk prediction for hinese microblo s via deep-learnin methods: ontent Analysis. M Med nform ul ; ( ):e . M :3 3",
    "ar iv",
    "[raw_reference] Yan Z, ai Z, Yan Y, arbonell , alakhutdinov , Le QV. L et: Generalized autore ressive pretrainin for lan ua e understandin . ar iv; . doi: Biomed n May; ( ): - . M :3 106.",
    "[raw_reference] Wei Y, Guo L, Lian , hen . hatG T: pportunities, risks and priorities for psychiatry. Asian ournal of sychiatry 3 ec ; : 3 . doi: . 6 j.ajp. 3. 3 107",
    "[raw_reference] Yon satianchot , Torshizi G, Marsella . nvesti atin lar e lan ua e models' perception of emotion usin appraisal theory. 3 th nternational onference on Affective omputin and ntelli ent nteraction Workshops and emos (A W) 3. p. -. doi: .",
    "enova te t-davinci-3. Hu in Face . ournal of Medical Artificial ntelli ence AM ublishin ompany; 3 ct 3 ;6",
    "[raw_reference] A W . 3. 3 108. enova te t-davinci-3. Hu in Face. Available from: https: hu in face.co enova te t-davinci-3 [accessed Apr , ] 109. Grabb . The impact of prompt en ineerin in lar e lan ua e model performance: a psychiatric e ample. ournal of Medical Artificial ntelli ence AM ublishin ompany; 3 ct 3 ;6( ). doi: . 3 jmai-3- 110.",
    "The plasticity of hatG T's mentalizin abilities: personalization for personality structures Front sychiatry technolo y ai lamda [accessed Apr , ] 113",
    "[raw_reference] Tanana M, oma , Kuo , Berta nolli , embe A, ace B, rikumar V, Atkins , mel Z. How do you feel? Usin natural lan ua e processin to automatically rate emotion in psychotherapy. Behavior esearch Methods Mar ; 3: -. doi: .3 s 3 --3 -z 114.",
    "accessed Apr , ] 115. ublisher of streamin video, audio",
    "[raw_reference] Welcome to L W -. Available from: https: www.liwc.app [accessed Apr , ] 115. ublisher of streamin video, audio, and te t library databases that promote research, teachin , and learnin across disciplines, includin music, counselin , history, business and more| Ale ander treet. Available from: https: ale anderstreet.com [accessed Apr , ] 116.",
    "[raw_reference] Wan , Liu K, Wan . Knowled e-enhanced pre-trainin lar e lan ua e model for depression dia nosis and treatment. 3 th nternational onference on loud omputin and ntelli ent ystems ( ) 3. p. 3 -36. doi: . . 3. 63 117. hinese L docs lan ua e_modelin .md at master \u2022 didi hinese L . GitHub. Available from: https: ithub.com didi hinese L blob master docs lan ua e_modelin .md [accessed Apr , ] 118.",
    "eurolo y Board eview Questions BoardVitals Health yst",
    "[raw_reference] chubert M , Wick W, Venkataramani V. erformance of lar e lan ua e models on a neurolo y board-style e amination. AMA etw pen 3 ec ;6( ):e 3 6 . M :3 6 3 119. eurolo y Board eview Questions [ ] -BoardVitals. Available from: Health yst. ; : 3. https: doi.or . 6 s 3 33--3 6- 133.",
    "[raw_reference] Nandwani P, Verma R. A review on sentiment analysis and emotion detection from text. Soc Netw Anal Min 2021;11(1):81. PMID:34484462 134",
    "reprint",
    "[raw_reference] Huang L, Yu W, Ma W, Zhong W, Feng Z, Wang H, Chen Q, Peng W, Feng X, Qin B, Liu T. A survey on hallucination in large language models: principles, taxonomy, challenges, and open questions. arXiv; 2023. doi: 10.48550/arXiv.2311.05232 [ reprint] 135",
    "[raw_reference] Egli A. ChatGPT, GPT-4, and other large language models: the next revolution for clinical microbiology? Clin Infect Dis 2023 Jul 3;77(9):1322-1328. PMID:37399030 136.",
    "[raw_reference] Palmer A, Schwan D. Beneficent dehumanization: employing artificial intelligence and Carebots to mitigate shame-induced barriers to medical care. Bioethics 2022;36(2):187-193. doi: 10.1111/bioe.12986 137",
    "ma e inputs for hatG T -FAQ What is RAG? -Retrieval-Augmented Generation Explained",
    "reprint",
    "[raw_reference] M\u00fcndler N, He J, Jenko S, Vechev M. Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation. arXiv; 2024. doi: 10.48550/arXiv.2305.15852 [ reprint] 143",
    "Preprint",
    "[raw_reference] Forbes GC, Katlana P, Ortiz Z. Metric Ensembles For Hallucination Detection. arXiv; 2023. doi: 10.48550/arXiv.2310.10495 [Preprint] 144",
    "What is LLM Temperature",
    "[raw_reference] Yao Y, Duan J, Xu K, Cai Y, Sun Z, Zhang Y. A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly. High-Confidence Computing 2024 Jun 1;4(2):100211. doi: 10.1016/j.hcc.2024.100211 148",
    "ICASSP 2024 -2024 IEEE International Conference on Acoustics, Speech and Signal Processing -blackbo -problem-opaque-inner LLM Optimization Parameters. Generative AI Wiki"
  ],
  "editors": [
    "K Santosh",
    "A Makkar",
    "M Conway",
    "A K Singh",
    "A Vacavant",
    "Abou El Kalam",
    "A Bouguelia",
    "M-R Hegadi",
    "R",
    "S Muresan",
    "P Nakov",
    "A Villavicencio",
    "Q Liu",
    "D Schlangen",
    "R Cerri",
    "R C Prati",
    "L docs lan ua e_modelin"
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  }
}
