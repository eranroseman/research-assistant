{
  "paper_id": "RCDR49T9",
  "title": "Systematic Review and Critique of Methods for Economic Evaluation of Digital Mental Health Interventions",
  "abstract": "Objectives Investment in digital interventions for mental health conditions is growing rapidly, offering the potential to elevate systems that are currently overstretched. Despite a growing literature on economic evaluation of digital mental health interventions (DMHIs), including several systematic reviews, there is no conclusive evidence regarding their costeffectiveness. This paper reviews the methodology used to determine their cost-effectiveness and assesses whether this meets the requirements for decision-making. In doing so we consider the challenges specific to the economic evaluation of DMHIs, and identify where consensus and possible further research is warranted. Methods A systematic review was conducted to identify all economic evaluations of DMHIs published between 1997 and December 2018. The searches included databases of published and unpublished research, reference lists and citations of all included studies, forward citations on all identified protocols and conference abstracts, and contacting authors researchers in the field. The identified studies were critiqued against a published set of requirements for decision-making in healthcare, identifying methodological challenges and areas where consensus is required. \n Results The review identified 67 papers evaluating DMHIs. The majority of the evaluations were conducted alongside trials, failing to capture all relevant available evidence and comparators, and long-term impact of mental health disorders. The identified interventions are complex and heterogeneous. As a result, there are a number of challenges specific to their evaluation, including estimation of all costs and outcomes, conditional on analysis viewpoint, and identification of relevant comparators. A taxonomy for DMHIs may be required to inform what interventions can reasonably be pooled and compared. Conclusions This study represents the first attempt to understand the appropriateness of the methodologies used to evaluate the value for money of DMHIs, helping work towards consensus and methods' harmonisation on these complex interventions.",
  "year": 2020,
  "date": "2020-08-17",
  "journal": "Health Econ",
  "publication": "Health Econ",
  "authors": [
    {
      "forename": "Dina",
      "surname": "Jankovic",
      "name": "Dina Jankovic",
      "affiliation": "1  Centre for Health Economics , The University of York , Alcuin College , A Block , York YO10 5DD , UK \n\t\t\t\t\t\t\t\t Centre for Health Economics \n\t\t\t\t\t\t\t\t The University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Alcuin College A Block \n\t\t\t\t\t\t\t\t\t YO10 5DD \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "email": "dina.jankovic@york.ac.uk",
      "orcid": "0000-0002-9311-1409"
    },
    {
      "forename": "Laura",
      "surname": "Bojke",
      "name": "Laura Bojke",
      "affiliation": "1  Centre for Health Economics , The University of York , Alcuin College , A Block , York YO10 5DD , UK \n\t\t\t\t\t\t\t\t Centre for Health Economics \n\t\t\t\t\t\t\t\t The University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Alcuin College A Block \n\t\t\t\t\t\t\t\t\t YO10 5DD \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0001-5381-003X"
    },
    {
      "forename": "David",
      "surname": "Marsh",
      "name": "David Marsh",
      "affiliation": "2  Centre for Reviews and Dissemination , University of York , York , UK \n\t\t\t\t\t\t\t\t Centre for Reviews and Dissemination \n\t\t\t\t\t\t\t\t University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0001-5969-9539"
    },
    {
      "forename": "Pedro",
      "surname": "Goncalves",
      "name": "Pedro Goncalves",
      "affiliation": "1  Centre for Health Economics , The University of York , Alcuin College , A Block , York YO10 5DD , UK \n\t\t\t\t\t\t\t\t Centre for Health Economics \n\t\t\t\t\t\t\t\t The University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Alcuin College A Block \n\t\t\t\t\t\t\t\t\t YO10 5DD \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0001-9063-8590"
    },
    {
      "forename": "Rachel",
      "surname": "Churchill",
      "name": "Rachel Churchill",
      "affiliation": "2  Centre for Reviews and Dissemination , University of York , York , UK \n\t\t\t\t\t\t\t\t Centre for Reviews and Dissemination \n\t\t\t\t\t\t\t\t University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0002-1751-0512"
    },
    {
      "forename": "Hollie",
      "surname": "Melton",
      "name": "Hollie Melton",
      "affiliation": "2  Centre for Reviews and Dissemination , University of York , York , UK \n\t\t\t\t\t\t\t\t Centre for Reviews and Dissemination \n\t\t\t\t\t\t\t\t University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0003-3837-510X"
    },
    {
      "forename": "Sally",
      "surname": "Brabyn",
      "name": "Sally Brabyn",
      "affiliation": "3  Department of Health Sciences , University of York , York , UK \n\t\t\t\t\t\t\t\t Department of Health Sciences \n\t\t\t\t\t\t\t\t University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "orcid": "0000-0001-5381-003X"
    },
    {
      "forename": "Lina",
      "surname": "Gega",
      "name": "Lina Gega",
      "affiliation": "4  Department of Health Sciences and Hull York Medical School , University of York , York , UK \n\t\t\t\t\t\t\t\t Department of Health Sciences and Hull York Medical School \n\t\t\t\t\t\t\t\t University of York \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t York \n\t\t\t\t\t\t\t\t\t UK",
      "email": "lina.gega@york.ac.uk",
      "orcid": "0000-0003-2902-9256"
    }
  ],
  "doi": "10.1007/s40258-020-00607-3",
  "sections": [
    {
      "title": "Introduction",
      "text": "In the UK, NHS investment in digital technologies is growing rapidly  [1] . According to the National Information Board's strategy for Personalised Health and Care 2020  [2] , a digital health service will use technology to improve patient choices, access to services, clinical outcomes and better self-care through online services, rather than having to visit a health professional. In the treatment of patients with mental health conditions, this can offer the potential to elevate a system that is currently overstretched, with long waiting times for face-to-face contacts and poor provision of services in some areas. Digital interventions (DIs) for mental health conditions are wide ranging, from computerised cognitive behavioural therapy (cCBT) with or without added support from clinicians, to exposure therapy for the treatment of phobias, and text-based motivational support for smoking cessation.\n\nHowever, digitalisation of mental healthcare can only be regarded as a positive change if the delivery of interventions through remote/digital mechanisms offer value for money. Commissioners are particularly concerned with delivering a quality service for lower costs. Cost-effectiveness analyses (CEAs) can provide evidence to support or refute the assumption that digital mental health interventions (DMHIs) are good value for money, by comparing the costs and outcomes of DMHIs relative to the costs and outcomes of relevant alternatives. DMHIs are, however, complex interventions, which may require complex methodology to evaluate cost-effectiveness appropriately  [3] . Despite a growing literature on economic evaluation of DMHIs, the appropriateness of the methodology used to determine cost-effectiveness has not been considered. In addition, reviews conducted to date have tended to focus on a specific range of conditions and interventions, and comment only on cost-effectiveness results rather than consistency and appropriateness of methodology used. Indeed, the majority of the reviews fail to conclude on cost-effectiveness because of heterogeneity in the interventions, the conditions they target, and the methods used to evaluate them. Furthermore, reviews even interpret the same studies differently.\n\nWithout a consensus on the appropriate methods for evaluation of DMHIs, evidence will continue to be generated that is difficult to compare with the existing evidence base. For a decision-maker concerned with which DMHIs offer value for money and achieve good patient outcomes, it is difficult to interpret the body of evidence that currently exists. Existing reviews have not considered how CEAs for DMHIs meet the requirements for decision-making. Specifically, does the economic analysis estimate costs and effects, based on all the available evidence, for the full range of possible alternative interventions and clinical strategies and over an appropriate time horizon, for the mental health conditions of interest  [4] ?\n\nIn pursuit of a consensus framework or agreed methodology for evaluating DMHIs, this paper reviews all literature on economic evaluation of DMHIs and identifies common themes, focussing on the methods used and their appropriateness for decision-making. Finally, the paper considers where methods have yet to be developed or utilised, and where further research is required in the context of DMHIs."
    },
    {
      "title": "Methods"
    },
    {
      "title": "Scope",
      "text": "This systematic review aimed to identify economic evaluations of DMHIs. DIs were defined as software-based systems and technology platforms designed for patient-facing delivery of a mental health intervention (i.e. an intervention to improve mental health outcomes). Studies could be performed on participants with both symptoms or risk of mental health problems. Mental health problems were defined by the ICD-11 criteria for mental, behavioural or neurodevelopmental disorders with the exception of the conditions listed under the categories of neurodevelopmental, neurocognitive and disruptive behaviour or dissocial disorders. All study designs that have the potential to inform decision-making were included in the searches, including modelling studies, clinical trials and observational studies.\n\nThe review was conducted in line with PRISMA guidelines, excluding the Risk of Bias (RoB) assessment. This is because our aim was to review the appropriateness of methods used in the economic evaluation of DMHIs, rather than to synthesise their results, and so broad RoB measures are unlikely to provide a useful contribution. Instead, broader principles were used to critique the studies (see Sect. 2.6 for details)."
    },
    {
      "title": "Searches",
      "text": "In December 2018, the following databases were searched to identify published and unpublished studies in any language: MEDLINE, PsycINFO, Cochrane Central Register of Controlled Trials (CENTRAL), Cochrane Database of Systematic Reviews (CDSR), Cumulative Index to Nursing and Allied Health (CINAHL Plus), Database of Abstracts of Reviews of Effects (DARE), EMBASE, Web of Science Core Collection, NHS Economic Evaluation Database (NHS EED); Health Technology Assessment database and the NIHR Journals Library; Database of Promoting Health Effectiveness Reviews (DoPHER). The full MEDLINE search strategy is presented in Online Supplementary File 1.\n\nWe also searched two clinical trial registries for ongoing studies: ClinicalTrials.gov and the WHO International Clinical Trials Registry Platform portal, searched the NIHR portfolio, and conducted web searches using Google and Google Scholar using simplified search terms. After searches were completed we searched the lists of included studies of relevant systematic reviews identified by the searches and the reference lists of all included studies, and conducted forward citation chasing on all identified protocols, conference abstracts and the included studies using Google Scholar for"
    },
    {
      "title": "Key Points for Decision Makers",
      "text": "Despite a growing literature on economic evaluation of digital mental health interventions (DMHIs), the existing studies may not satisfy the requirements for decision making.\n\nFurther research is required to understand the stickiness of the treatment effect of digital interventions, and to synthesise multiple sources of evidence on key parameters, such as the treatment effect, in a way that takes into account the complexity of these interventions.\n\nUnderstanding the appropriateness of the methodologies used to evaluate DMHIs' value for money helps work towards consensus and methods harmonisation on these complex interventions. any relevant publications. We also contacted researchers in the field and searched the citations of identified studies.\n\nThe searches were conducted from 1997, as any relevant studies of DMHIs could not have been published before this date. Searches were restricted to those written in English, as we anticipated that most economic studies written in other languages would also have a version published in English (e.g. the South Asia Cochrane Group  [5] )."
    },
    {
      "title": "Selection Criteria",
      "text": "Eligible studies included participants with symptoms or risk of mental health problems. Studies were excluded where the primary diagnosis of the participants was a physical or other condition other than those listed (e.g. cancer or insomnia). All digital interventions that expressly targeted mental health and patient rather than was service oriented were included with the exception of those that were simply a communication medium (e.g. phones or videoconferencing). A broad range of studies was considered in the review, including economic evaluations conducted alongside trials, modelling studies and analyses of administrative databases. Only full economic evaluations that compared two or more options and considered both costs and consequences (i.e. cost-minimisation, cost-effectiveness, cost-utility, costconsequence and cost-benefit analyses) were included in the review. No studies were excluded on the basis of their comparator group. Study protocols, abstracts and reviews were marked to allow for following up on as described in the searches section (Sect. 2.2)."
    },
    {
      "title": "Study Selection",
      "text": "Studies were screened by a team of four researchers (DM, DJ, PS, HM). Each title and abstract was independently assessed for eligibility by two reviewers, one of whom had expertise in health economics. If either reviewer indicated a study could be relevant, the full text for that study was sought and again assessed independently by two reviewers, with disagreements resolved through discussion or via a third reviewer (LG or LB)."
    },
    {
      "title": "Data Extraction",
      "text": "The purpose of data extraction was to summarise methodology and identify challenges common in the evaluation of DMHIs. To do so, the following information was extracted:\n\n-the population; -the intervention -underpinning principles, delivery mode, level of support, treatment duration; -comparators; -outcomes-clinical and economic outcomes, and the economic endpoint; -study design, analytical approach (within-trial analysis, decision model, statistical model, epidemiological study), and analysis time horizon; -setting (country and analytical perspective); -analytical framework -cost-minimisation (CM), costeffectiveness analysis (CEA), CUA, CCA, or cost-benefit analysis (CBA); and -methods employed to characterise uncertainty. Three reviewers (DJ, PS and LB) independently extracted details from full-text studies. Another reviewer (DM) checked extracted data, and disagreements were resolved by discussion."
    },
    {
      "title": "Critique",
      "text": "The identified studies were critically reviewed to assess whether the existing evidence meets the requirements for decision-making in healthcare  [4]  and to identify challenges in generating cost-effectiveness evidence in this context. In particular, the methods used in applied studies were considered in terms of:\n\n-Does the economic analysis estimate costs and effects, i.e. it is not restricted to a cost-minimisation analysis; -Does the analysis appropriately synthesise all the available evidence; -Are the full range of possible alternative interventions and clinical strategies included; and -Are costs and outcomes considered over an appropriate time horizon?"
    },
    {
      "title": "Results"
    },
    {
      "title": "Summary of Available Economic Evaluations of Digital Mental Health Interventions (DMHIs)",
      "text": "The review identified 63 studies and 67 papers in total, as shown in Fig.  1 . Out of the 10,764 records identified, and after duplicates were removed, a total of 6931 records were screened, of which 6646 were excluded by title and abstract, and 285 were assessed for eligibility by full text. A total of 217 papers were excluded because the primary diagnosis was not a mental health problem (n = 27), or the intervention was not a mental health intervention (n = 13), or the study did not include health economic outcomes (n = 35), or it was not an economic evaluation (n = 7), or it was a review rather than a primary study (n = 2), or it was a conference abstract rather than a peer-reviewed paper (n = 26), or it was a duplicate reference (n = 4), or it was a study protocol rather than a peer-reviewed paper (n = 103). Two papers reported the results of identical analyses  [6, 7] ; all other papers reported unique results (such as a different analytical perspective or length of follow-up), even when multiple papers were based on the same study. The paper by Duarte et al.  [6]  was thus taken out of the analysis to avoid duplicate reporting, and the final number of papers was 66.\n\nThe summary tables and details of individual studies are presented in Online Supplementary Files 2 and 3, respectively, while detailed analysis of evidence on the cost-effectiveness of DMHIs is due to be reported in future publications.\n\nThe majority of the studies (44 (67%) out of 66) evaluated interventions that target anxiety and/or depression. Other conditions included suicidal ideation (n = 1), child disruptive behaviour (n = 1), eating disorders (n = 3), schizophrenia (n = 3), and addiction including drug and alcohol addiction (n = 3 and n = 2, respectively) and smoking cessation (n = 8); see Online Supplementary File 2, Table  S1 .\n\nAll identified interventions were condition-specific, except six interventions that targeted both anxiety and depression. The interventions vary both between and within individual conditions in terms of their underlying principles (e.g. CBT, guided relaxation, self-help, exposure therapy, motivational support for smoking cessation), content (e.g. the number of modules), mode of delivery (e.g. mobile, computer or text based, or completed at home or at a clinic), type of support (online chat, phone, face-to-face), frequency of support (e.g. weekly, ad hoc), person delivering support (e.g. clinician, assistant, lay person) and extent of support (administration support only, additional counselling); see Online Supplementary File 2, Table  3 .\n\nComparators can be broadly categorised as no treatment or waitlist, treatment as usual (TAU), active controls and face-to-face (F2F) psychological therapy. Waitlist comparators may not restrict access to other interventions, and so the difference between waitlist and TAU is not always clear. TAU includes psychological interventions (such as F2F therapy) and pharmacotherapy, although authors often report the lack of clarity over what patients receive in practice. Attention control interventions refer to interventions designed as 'psychological placebos'; they encourage patients to spend the same amount of time on treatment as active interventions, but without the 'active' component, such as CBT or problem-solving therapy. Attention control comparators included websites, printed reading, and online relaxation, among others.\n\nHealth-outcome measures included health-related quality of life (HRQoL), life-years (LY), disease-free days, diseasespecific clinical outcomes, and a range of abstinence measures in addiction and smoking cessation (1-week abstinence, smoke-free years, substance-free urine samples, etc.). Records iden\u019ffied through database searching Quan\u019fta\u019fve: (n = 10,734) Iden\u019ffica\u019fon Addi\u019fonal records iden\u019ffied through other sources (n = 30) Records a\u014cer duplicates removed Quan\u019fta\u019fve: (n = 6931) Screening Records screened (n = 6931) Records excluded (n = 6645) Included Eligibility Full-text ar\u019fcles assessed for eligibility (n = 286) Full-text ar\u019fcles excluded, with reasons (n =219) Primary diagnosis = 27 Interven\u019fon = 13 No HE Outcome = 36 Study Design = 8 Review = 2 Conference Abstract = 26 Duplicate Reference = 4 Protocols = 103\n\nStudies included in qualita\u019fve synthesis (n = 63 studies, 67 papers) Economic endpoints included cost per additional: quality-adjusted life-year (QALY) (n = 43), disability-adjusted life-year (DALY) averted (n = 3), life-year (n = 1), diseasefree day (n = 2), point change in the clinical score (n = 12), responder or clinical improvement (n = 16), cognitive improvement (n = 2), inpatient days avoided (n = 1) or additional day of abstinence in interventions that target addiction (n = 10). Results were presented in terms of incremental cost-effectiveness ratios (ICERs) (n = 40), overall change in the costs and effects (i.e. whether the intervention was dominant or dominated) (n = 2), net benefit (n = 3) and the probability an intervention is cost-effective at a specific cost-effectiveness threshold (n = 4) or at a range of thresholds (n = 33). In studies evaluating interventions that target schizophrenia, child disruptive disorder and suicidal ideation, the outcome measures tend to be disease-specific, and the costs and outcomes compared separately.\n\nMethods for costing interventions varied. The majority of the evaluations (50/66) included the cost of staff time required to deliver the intervention, while a further nine did not report clearly which costs were included. Some studies included variable equipment costs and website maintenance and hosting (23 and 14 studies, respectively), while very few considered the cost of development, capital costs, or patient recruitment (or technology dissemination).\n\nThe vast majority of evaluations (52/66) were within-trial analyses, where one included a temporal extrapolation. A further three studies were evaluations within pilot  [8, 9]  and feasibility trials  [10] , while one study  [11]  used observational data. Nine studies used decision models to evaluate interventions-the summary of these models is provided in Table  1 . Eight out of the nine studies that used modelling to evaluate DMHIs did so due to the absence of head-to-head trial data, and used individual trials or non-comparative data sources to inform the treatment effect of digital interventions. The model for eating disorder used synthesised evidence of the treatment effect to derive the cost of different treatment options.\n\nThe vast majority of the papers (55/66) reported some form of sensitivity analysis. In total, 42 studies used both probabilistic and deterministic sensitivity analysis (PSA and DSA). DSA involved exploring alternative scenarios and assumptions; the most common parameter whose value was varied was the cost of intervention. Other common scenarios included alternative methods for dealing with missing data, and the methods for estimating costs and effects."
    },
    {
      "title": "Key Challenges and Limitations in Economic Evaluation of DMHIs",
      "text": "The critical review of the studies identified a range of challenges arising from the complexity of DMHI interventions, and the heterogeneity of evidence; we describe each in turn below."
    },
    {
      "title": "Estimation of Costs and Outcomes",
      "text": "Section 3.1 highlighted that applied studies use a variety of methods to measure costs and outcomes of DMHIs. In the studies reviewed, benefits were measured in terms of QALYs, DALYs, life-years, disease-free days, disease-specific outcome measures, response or clinical improvement, inpatient days avoided, or day of abstinence in interventions that target addiction. Costs attributed to DMHIs included the cost of staff time required to deliver the intervention, a range of equipment costs, website maintenance and hosting, the cost of development, capital costs, or patient recruitment (or technology dissemination).\n\nThe optimal method for measuring outcomes ultimately depends on the analysis perspective. An employer may be interested in measuring the effect of the intervention on productivity, a mental healthcare provider may include a narrow range of benefits specific to the mental health condition targeted by the intervention and costs that fall on that provider, while a health system may aim to improve overall health, and so requires a broader health measure such as HRQoL to allow comparison across different fields of medicine.\n\nWhile the majority of studies identified in this review reported a range of different costs and outcomes, seven studies evaluated interventions from a healthcare system or payer perspective, but measured outcomes in terms of changes in clinical scores  [15, [22] [23] [24] , clinical improvement/response/ remission  [25, 26] , or disease-free days  [27] . It is not clear how health gains in such disease-specific outcome measures can be used by decision makers to allocate resources across different disease areas.\n\nSimilarly, the appropriate methods for measuring costs depend on the analysis perspective (e.g. whether to include the cost to employer, service provider, broader health system, or society), as well as the role of the intervention. When interventions target undiagnosed patients who would not have sought care otherwise, dissemination (e.g. advertising or public health campaigns) is an integral part of the intervention that is likely to affect its outcomes, and so the cost of dissemination should be included in the cost of the intervention. Conversely, when an intervention targets diagnosed patients, and is prescribed by clinicians, the dissemination costs are likely to be negligible. In this review, 23 studies recruited self-referred patients through advertising, yet only two studies included recruitment costs in their analysis. Furthermore, the costs of DMHIs are highly uncertain. For example, four studies included capital costs (such as computers, staff training or one-off software purchases), and a further 14 included the cost of website maintenance and hosting. (For details of included costs, see Online Supplementary Navershnik  [14]  Cost-effectiveness of an e-health service to support the treatment of patients with depressive disorder, compared to TAU Mapped clinical outcomes and the treatment effect observed in a pilot trial to HRQoL over time, and derived costs from published literature"
    },
    {
      "title": "Depression and anxiety",
      "text": "Lee  [15]  Cost-effectiveness of an online 'wellness' course for depression and anxiety compared to TAU, over 12 months Different data sources (non-comparative) and models were used to model the costs and outcomes for each comparator Solomon  [16]  Cost-effectiveness of iCBT for depression and anxiety, compared to TAU and F2F"
    },
    {
      "title": "CBT, after 6 months",
      "text": "Decision model in the form of a decision tree used to model the probability of response to treatment. Treatment effect was informed by a single RCT Mihalopoulos  [17]  Evaluated the potential of an online intervention for panic disorder to be costeffective if administered to all patients in Australia who seek treatment for depression Used previously published model to derive cost per DALY in patients with panic disorder. Assumed online intervention as effective as F2F CBT GAD Kumar  [18]  Costs and effects of a novel mobile CBT intervention for GAD in comparison to (F2F) CBT and TAU Decision model in the form of a Markov model depicting the patients' change in GAD severity (no, mild, moderate or severe GAD, and co-morbidities). The effect of computerised CBT was derived using pilot program efficacy data for the mobile CBT program. The effect of the intervention was assumed to be fully sustained for the first year, then gradually decrease until the state transition rates were the same as for TAU at the end of the model timeframe Eating disorder Kass  [19]  Modelled the cost of using an online intervention for prevention or treatment of eating disorders Used a decision model in the form of a decision tree to model the probability of response to treatment. Treatment effect informed using a meta-analysis of digital interventions for eating disorders Smoking cessation Guerriero  [20]  Cost-effectiveness of adding text-based support to current practice in smoking cessation Decision model in the form of a Markov model used to model smoking cessation (patients could be smoker, former smoker or dead). In each cycle patients had a risk of developing complications (risk dependent on age, gender and smoking status). Treatment effect was informed by a single RCT Wu  [21]  Cost-effectiveness of computer-tailored self-help intervention compared to a generic self-help intervention in smoking cessation Decision model in the form of a Markov model used to model smoking cessation (patients can be smoker, former smoker or dead). In each cycle patients had a state specific mortality risk. Treatment effect was informed by a single RCT File 3.) The subsequent cost per patient depends on the scale of rollout, where wider delivery (e.g. providing an intervention nationally) is likely to dilute such fixed costs."
    },
    {
      "title": "Use of All Available Evidence",
      "text": "While the volume of economic evaluations of DMHIs is growing, only one of the 66 evaluations  [19]  synthesised evidence from multiple sources to inform the effectiveness of a treatment effect. Evidence synthesis is more complex for DMHIs than for interventions such as medication, as they are multi-layered and subject to external factors, and thus it is difficult to ensure uniform delivery, or to disentangle the impact of each layer on outcomes. There is significant heterogeneity likely between interventions, populations they target, and the settings in which they are delivered -even when interventions target the same condition, they tend to vary in their underlying principles, content, and the type and extent of support (see Sect. 3.1 for details). It is not clear whether each of the characteristics affect the treatment effect, or whether evidence from similar interventions can be reasonably pooled to make an overall recommendation about their cost-effectiveness.\n\nFurthermore, interventions for the same mental health disorder can target different patient populations (e.g. according to disease severity). The population in which an intervention is evaluated can affect its comparability to other trials-i.e. it may not be appropriate to generalise costs and treatment effect observed in one target population to another, or to attempt to synthesise effectiveness of interventions observed in different patient populations.\n\nFinally, digital interventions, as well as comparators that involve behavioural therapy, are likely to vary between settings (clinics and countries) in the referral system, capacity, waiting times and frequency of contact, and so synthesising evidence on resource use may not be appropriate."
    },
    {
      "title": "Specification of Comparators",
      "text": "Comparators included guided and unguided digital interventions, medication, different types of F2F therapy and no treatment. Economic evaluation should include all relevant comparators, yet the majority of studies evaluating DMHIs only included two arms, which may limit their applicability to decision-making.\n\nWaitlist control and TAU were the most common comparators (n = 34); however, their description was often limited and the distinction between them was not always clear. Treatment of mental health conditions tends to vary between health providers, and between different patient populations (e.g. diagnosed vs. undiagnosed); a lack of understanding of a comparator in a trial can limit generalisability of the findings, as well as comparability of results across trials."
    },
    {
      "title": "Time Horizon for Analysis",
      "text": "The majority of the evaluations were conducted alongside a trial or using retrospective data from a single study. Of the 66 papers, 54 (51 RCTs and three pilot and feasibility studies) did not explore the results beyond the trial end point potentially failing to capture long-term costs and effects of DMHIs.\n\nThis is considered to be inadequate for decision-making due to the truncated time horizon. Mental illness is a lifetime condition for many patients, with periods of respite and relapse, during which costs and outcomes can be influenced by any potential treatment received. Limiting the time horizon of an analysis can generate inaccurate estimates of costeffectiveness. The lack of longer-term modelling is likely to be due to, in part, the lack of reliable data about the longterm performance of DMHIs. For many treatments there is no empirical data on how long the treatment effects are likely to be observed for and how these relate to a changing baseline, i.e. how the population without treatment progress in their illness. Furthermore, this is likely to be confounded by co-morbidities and future events, making long-term extrapolation challenging."
    },
    {
      "title": "Discussion",
      "text": "Despite a growing literature on economic evaluation of DMHIs, including several systematic reviews, there is no conclusive evidence regarding their cost-effectiveness. The lack of consensus is often attributed to the heterogeneity in the evaluated interventions, the conditions they target, and the methods used to evaluate them. There may, however, be more fundamental differences between the applied examples, determining how useful these studies are in informing decision-making, including commissioning choices. This paper aimed to assess the appropriateness of the methodology used to determine cost-effectiveness of DMHIs and to highlight the challenges associated with estimating cost-effectiveness."
    },
    {
      "title": "Findings",
      "text": "The review identified 66 papers, and our findings support conclusions from previous reviews that DMHIs are heterogeneous, and the methods used to evaluate them vary  [28] [29] [30] [31] . The review has identified key gaps in DMHIs evidence required for decision-making. It highlighted characteristics of digital interventions that should be considered in future evaluations in order to address these gaps."
    },
    {
      "title": "Evidence Gaps"
    },
    {
      "title": "Evidence to inform an assessment of cost-effectiveness:",
      "text": "Cost-effectiveness analysis typically requires multiple forms and sources of evidence, including clinical effectiveness, adverse events, disease natural progression, cost/ resource use and health-related quality of life. The evidence to inform these often comes from several different data sources, particularly for the treatment effect, providing multiple estimates of the parameter(s).\n\nThis review identified ten studies that used some form of modelling to combine multiple sources of information; however, none of these studies synthesised evidence from multiple studies to inform key parameters, such as the treatment effect. Furthermore, 19 studies evaluated digital interventions for depression, and 17 for various types of anxiety, yet none of these studies estimated the treatment effect from more than one trial.\n\nEvidence on DMHIs is likely to grow further. In order to draw conclusions regarding the cost-effectiveness of digital interventions, evidence review and quantitative synthesis techniques together with decision analytic models represent an ideal vehicle to structure the decision problem, combine all available data, and characterise the various sources of uncertainty associated with the decision problem. For example, network meta-analytic methods may be used to combine multiple sources of evidence to obtain pooled estimates of the treatment effect for all relevant interventions, allowing for the full body of evidence to be reflected and capturing heterogeneity between studies. Choosing a single study to estimate all parameters assumes that all other sources of evidence are not relevant or less relevant for the decision problem.\n\nLong-term trajectory of the treatment effect: The majority of the evaluations were conducted within trials, with limited follow-up. Alas, there is little data to support assumptions regarding the 'stickiness' of DIs in mental health beyond the initial treatment period. The chronic nature of mental health problems requires consideration of the impact of short-term interventions over a longer time horizon, to understand how differences in treatments translate to differences in costs and outcomes over patients' lifetime. This dictates the need for assumptions to be made about a longer-term treatment effect, which must be validated or tested using sensitivity analysis.\n\nTreatment effect in treatment sequencing: For many mental health conditions, it is unlikely that only a single treatment would be offered at a single time point. To appropriately consider the cost-effectiveness of DIs, it is therefore necessary to reflect the possibility that multiple treatments may be given over a patient's lifetime. In modelling sequences of treatments, evidence on effectiveness of treatments at various points in the pathway is required.\n\nNone of the studies identified in this review explored the cost-effectiveness of DMHIs in patients at different stages in the treatment pathway, and many only included treatmentna\u00efve patients. It may not be appropriate to assume that these DIs will have the same effect if given to a patient that has failed to respond to multiple treatment. Modelling treatment sequences can be complex and requires evidence unlikely to be available from randomised trials."
    },
    {
      "title": "Key Considerations When Evaluating DMHIs",
      "text": "Heterogeneity of interventions: DMHIs are complex and multi-layered; as result, there is significant heterogeneity between interventions. Given this complexity, the evaluation of all digital interventions simultaneously would require a taxonomy for DMHIs to be developed, to inform what interventions can reasonably be pooled and compared. Previous reviews have focused on specific types of digital interventions (e.g. internet-delivered CBT  [28] [29] [30] [31]  or guided internet interventions  [32] ) and digital interventions for a specific condition (depression  [28, 32, 33] , anxiety disorders  [34] ), but this review identified additional factors specific to DMHIs that need to be taken into consideration, such as the role of interventions in the treatment pathway.\n\nHeterogeneity in the population they target: The appropriate methods for cost-effectiveness, are, at least in part, driven by the intended role for the analysis. The role of some DMHIs reviewed in this study was unclear-studies recruited patients through self-referral, referral by clinician where patients are identified 'on the job' and recruitment by screening medical records, and proactively inviting patients to participate. Different target populations suggest different aims of interventions-interventions that target self-referred patients have a role in diagnosis and treatment of patients who may not have otherwise sought treatment, whereas targeting diagnosed patients implies that digital interventions are administered in addition to, or alongside, existing treatment. The role of therapy can affect whether evidence from different studies can be pooled, how we measure costs and effects, as well as what the appropriate comparators are.\n\nHeterogeneity in the delivery setting: DMHIs can be selfreferred (and administered) or used on clinicians' referral, either while waiting on or instead of other treatment options. They can also be provided by different providers (e.g. in primary care or by specialists). The delivery setting can affect generalisability of the findings (to other delivery settings), which costs should be included in the analysis, and which comparators are relevant (e.g. TAU in one setting may not be comparable to TAU in another).\n\nFurthermore, the delivery setting can affect the appropriate perspective for the evaluation of DMHIs. Evaluations can be commissioned on a local level (clinics, regional decision-makers), a national level (e.g. NHS), or by employers and individuals themselves. Thus, the costs and outcomes included in the analysis, and the 'decision rule' used to interpret whether an intervention is cost-effective, can also vary. An employer may be interested in measuring the effect of the intervention on productivity, a mental healthcare provider may include a narrow range of benefits specific to the mental health condition targeted by the intervention and costs that fall on that provider, while a health system may aim to improve overall health, and so requires a broader health measure such as HRQoL to allow comparison across different fields of medicine. Furthermore, while NICE has an explicit decision rule (\u00a320,000-\u00a330,000 per QALY), in other perspectives it is not clear how to interpret health gains that result in an additional cost, particularly when health benefits are measured using disease-specific outcomes; e.g. how much should a provider spend on a one-point increase in GAD-7 score?"
    },
    {
      "title": "Considerations for Future Evaluations of DMHIs"
    },
    {
      "title": "Generating New Evidence",
      "text": "Future economic evaluations of DIs need to reflect the body of existing evidence. For example, in designing a particular intervention it is important to see what has worked and not worked previously and how the current evaluation will contribute towards the literature. Data collection should include data required to conduct an economic evaluation, detailed resource use and quality of life. Detailed reporting (e.g. recruitment method, patients' baseline characteristics, comparator details, breakdown of costs) can enable evidence synthesis where heterogeneity of DMHIs is accounted for appropriately (see Sect. 4.2.2)."
    },
    {
      "title": "Evidence Review and its Synthesis",
      "text": "In order to evaluate whether DMHIs represent good value for money, additional research is needed to review and (when appropriate) combine all available evidence, on all relevant comparators, required to inform an economic evaluation. Given the complexity of the interventions, any evidence synthesis needs to take into account the following:\n\n-Taxonomy of DMHIs, informing whether evidence on different interventions must be pooled; -The target patient population, where adjustments may need to be made for potential differences in effect size in different populations; -The decision-making context, reflecting comparators, outcomes and costs specific to that context."
    },
    {
      "title": "Long-Term Outcomes",
      "text": "Trial-based evaluations are often insufficient in follow-up to capture all the relevant differences in costs and outcomes between competing interventions, for example DIs versus non-DIs. The use of modelling, specifically extrapolation modelling, is therefore required in many instances. The use of extrapolation modelling should not, however, negate the need for sufficient follow-up in primary studies. It is important to determine how effective DIs are over the longer term, and valid extrapolation is only possible with longer follow-up."
    },
    {
      "title": "Strengths and Limitations",
      "text": "This paper is the first attempt to understand the appropriateness of methods used to evaluate DMHIs. The review employed a thorough search strategy to identify existing economic evaluations. However, the searches were restricted to publications in English only, and publications before December 2018. Economic evaluations of DMHIs are continuously being conducted and our review has not captured those published since our literature searches have been completed. Given that the primary aim of our review was to critique the methods for conducting economic evaluations of DMHIs based on a large sample of studies identified by our literature searches, our conclusions remain relevant and can be applied to newly published economic evaluations. As a case in point, a recent within-trial economic evaluation  [35]  compared a DMHI against a waiting list control and showed that, for short-term observed outcomes (at 8 weeks), the evaluated DI was unlikely to be cost-effective, whereas for longer term estimated (extrapolated) outcomes (at 12 months), the DMHI could be cost-effective. This emphasises the importance of extrapolation in costeffectiveness analyses of DMHIs, but it should not replace long-term follow-up as it did in this trial."
    },
    {
      "title": "Conclusion",
      "text": "This paper is the first attempt to understand the appropriateness of methods used to evaluate DMHIs. Understanding the limitations of existing research, and methodological challenges specific to DMHIs, motivates a discussion, and helps to work towards a consensus on methodology in future evaluations.\n\nAuthor contributions DJ is a Research Fellow in Health Economics. She contributed to the screening of literature, coordinated the data extraction and methodological discussion, and led the paper submission. LB is a Reader in Health Economics. She supervised and contributed to the searches, data extraction and the methodological discussion. DM is a Research Fellow in Evidence Synthesis. He coordinated the literature searches, screened the retrieved records, and advised on and validated the data extraction. PSG is a Research Fellow in Health Economics. He contributed to the screening of literature, data extraction and methodological discussion. HM is a Research Fellow in Evidence Synthesis. She contributed to the screening of records. SB is a Research Fellow in Mental Health. She contributed to the scoping of the review and the literature searches. RC is a Chair in Evidence Synthesis. She supervised the work of colleagues from the Centre for Reviews and Dissemination and from the Cochrane Common Mental Disorders Group (DM and HM). LiG is a Reader in Mental Health and an Honorary Nurse Consultant. She conceived the programme of work that included this review, obtained the funding, and coordinated and supervised the project, contributed to and checked the literature searches, screening of records, data extractions, analyses and write-up."
    },
    {
      "text": "Fig. 1 Number of studies identified and excluded at each stage of screening"
    },
    {
      "text": "Summary of decision models used in economic evaluation of digital mental health interventions"
    }
  ],
  "references": [
    {
      "title": "Five year forward view",
      "year": 2014,
      "doi": "10.1007/s40274-014-1663-8"
    },
    {
      "title": "Using data and technology to transform outcomes for patients and citizens",
      "authors": [
        "Nhs"
      ],
      "year": 2014,
      "doi": "10.1007/s40274-014-1706-1"
    },
    {
      "title": "Developing and evaluating complex interventions",
      "authors": [
        "P Craig",
        "P Dieppe",
        "S Macintyre",
        "S Michie",
        "I Nazzareth",
        "M Petticrew"
      ],
      "year": 2019,
      "doi": "10.1136/bmj.a1655"
    },
    {
      "title": "Whither trial-based economic evaluation for health care decision making?",
      "authors": [
        "M Sculpher",
        "K Claxton",
        "M Drummond",
        "C Mccabe"
      ],
      "year": 2006,
      "doi": "10.1002/hec.1093"
    },
    {
      "title": "Cognitive-behavioral treatment for impulse control disorders",
      "authors": [
        "D Hodgins",
        "N Peden"
      ],
      "year": 2008,
      "doi": "10.1590/s1516-44462006005000055"
    },
    {
      "title": "Cost-effectiveness of computerized cognitive-behavioural therapy for the treatment of depression in primary care: findings from the Randomised Evaluation of the Effectiveness and Acceptability of Computerised Therapy (REEACT) trial",
      "authors": [
        "A Duarte",
        "S Walker",
        "E Littlewood",
        "S Brabyn",
        "C Hewitt",
        "S Gilbody"
      ],
      "year": 2017
    },
    {
      "title": "A randomised controlled trial of computerised cognitive behaviour therapy for the treatment of depression in primary care: the Randomised Evaluation of the Effectiveness and Acceptability of Computerised Therapy (REEACT) trial",
      "authors": [
        "E Littlewood",
        "A Duarte",
        "C Hewitt",
        "S Knowles",
        "S Palmer",
        "S Walker"
      ],
      "year": 2015,
      "doi": "10.1002/central/CN-01168627/full"
    },
    {
      "title": "Randomised trial of personalised computer based information for patients with schizophrenia",
      "authors": [
        "R Jones",
        "J Atkinson",
        "D Coia",
        "L Paterson",
        "A Morton",
        "K Mckenna"
      ],
      "year": 2001,
      "doi": "10.1136/bmj.322.7290.835"
    },
    {
      "title": "Large multi-centre pilot randomized controlled trial testing a low-cost, tailored, self-help smoking cessation text message intervention for pregnant smokers (MiQuit)",
      "authors": [
        "F Naughton",
        "S Cooper",
        "K Foster",
        "J Emery",
        "J Leonardi-Bee",
        "S Sutton"
      ],
      "year": 2017,
      "doi": "10.1111/add.13802"
    },
    {
      "title": "Computerised cognitive-behavioural therapy for depression in adolescents: feasibility results and 4-month outcomes of a UK randomised controlled trial",
      "authors": [
        "B Wright",
        "L Tindall",
        "E Littlewood",
        "V Allgar",
        "P Abeles",
        "D Trepel"
      ],
      "year": 2017
    },
    {
      "title": "Costs and effects of Internet cognitive behavioral treatment blended with face-to-face treatment: results from a naturalistic study",
      "authors": [
        "Rmf Kenter",
        "P Van De Ven",
        "P Cuijpers",
        "G Koole",
        "S Niamat",
        "R Gerrits"
      ],
      "year": 2015,
      "doi": "10.1016/j.invent.2015.01.001"
    },
    {
      "title": "Economic evaluation of audio based resilience training for depression in primary care",
      "authors": [
        "L Koeser",
        "A Dobbin",
        "S Ross",
        "P Mccrone"
      ],
      "year": 2013,
      "doi": "10.1016/j.jad.2013.01.044"
    },
    {
      "title": "The population cost-effectiveness of delivering universal and indicated school-based interventions to prevent the onset of major depression among youth in Australia",
      "authors": [
        "Y Lee",
        "J Barendregt",
        "E Stockings",
        "A Ferrari",
        "H Whiteford",
        "G Patton"
      ],
      "year": 2017,
      "doi": "10.1017/s2045796016000469"
    },
    {
      "title": "Cost-effectiveness of a novel e-health depression service",
      "authors": [
        "K Naversnik",
        "A Mrhar"
      ],
      "year": 2013,
      "doi": "10.1089/tmj.2012.0081"
    },
    {
      "title": "The costeffectiveness of the online MindSpot Clinic for the treatment of depression and anxiety in Australia",
      "authors": [
        "Y-C Lee",
        "L Gao",
        "B Dear",
        "N Titov",
        "C Mihalopoulos"
      ],
      "year": 2017
    },
    {
      "title": "e-CBT (myCompass), antidepressant medication, and face-to-face psychological treatment for depression in australia: a cost-effectiveness comparison",
      "authors": [
        "D Solomon",
        "J Proudfoot",
        "J Clarke",
        "H Christensen"
      ],
      "year": 2015,
      "doi": "10.2196/jmir.4207"
    },
    {
      "title": "Exploratory economic analyses of two primary care mental health projects: implications for sustainability",
      "authors": [
        "C Mihalopoulos",
        "S Shih",
        "L Kiropoulos",
        "G Blashki",
        "G Meadows",
        "J Gunn"
      ],
      "year": 2005,
      "doi": "10.5694/j.1326-5377.2005.tb07184.x"
    },
    {
      "title": "Mobile and traditional cognitive behavioral therapy programs for generalized anxiety disorder: a cost-effectiveness analysis",
      "authors": [
        "S Kumar",
        "Jones Bell",
        "M Juusola"
      ],
      "year": 2018,
      "doi": "10.1371/journal.pone.0190554"
    },
    {
      "title": "The economic case for digital interventions for eating disorders among United States college students",
      "authors": [
        "A Kass",
        "K Balantekin",
        "E Fitzsimmons-Craft",
        "C Jacobi",
        "D Wilfley",
        "C Taylor"
      ],
      "year": 2017
    },
    {
      "title": "The cost-effectiveness of smoking cessation support delivered by mobile phone text messaging: Txt2stop",
      "authors": [
        "C Guerriero",
        "J Cairns",
        "I Roberts",
        "A Rodgers",
        "R Whittaker",
        "C Free"
      ],
      "year": 2013,
      "doi": "10.1007/s10198-012-0424-5"
    },
    {
      "title": "Cost-effectiveness of computer-tailored smoking cessation advice in primary care: a randomized trial (ESCAPE)",
      "authors": [
        "Q Wu",
        "S Parrott",
        "C Godfrey",
        "H Gilbert",
        "I Nazareth",
        "B Leurent"
      ],
      "year": 2014,
      "doi": "10.1093/ntr/ntt136"
    },
    {
      "title": "Internetbased photoaging within Australian pharmacies to promote smoking cessation: randomized controlled trial",
      "authors": [
        "O Burford",
        "M Jiwa",
        "O Carter",
        "R Parsons",
        "D Hendrie"
      ],
      "year": 2013,
      "doi": "10.2196/jmir.2337"
    },
    {
      "title": "Cost-effectiveness of internet and telephone treatment for smoking cessation: an economic evaluation of The iQUITT Study",
      "authors": [
        "A Graham",
        "Y Chang",
        "Y Fang",
        "N Cobb",
        "D Tinkelman",
        "R Niaura"
      ],
      "year": 2013,
      "doi": "10.1136/tobaccocontrol-2012-050465"
    },
    {
      "title": "Computer-aided self-exposure therapy for phobia/ panic disorder: a pilot economic evaluation",
      "authors": [
        "P Mccrone",
        "I Marks",
        "D Mataix-Cols",
        "M Kenwright",
        "M Mcdonough"
      ],
      "year": 2009
    },
    {
      "title": "Costeffectiveness and long-term follow-up of three forms of minimal contact cognitive behaviour therapy for severe health anxiety: results from a randomised controlled trial",
      "authors": [
        "E Axelsson",
        "E Andersson",
        "B Ljotsson",
        "E Hedman-Lagerlof"
      ],
      "year": 2018,
      "doi": "10.1016/j.brat.2018.06.002"
    },
    {
      "title": "Internet-versus group-administered cognitive behaviour therapy for panic disorder in a psychiatric setting: a randomised trial",
      "authors": [
        "J Bergstr\u00f6m",
        "G Andersson",
        "B Lj\u00f3tsson",
        "C R\u00fcck",
        "S Andr\u00e9ewitch",
        "A Karlsson"
      ],
      "year": 2010
    },
    {
      "title": "Incremental benefits and cost of coordinated anxiety learning and management for anxiety treatment in primary care",
      "authors": [
        "J Joesch",
        "C Sherbourne",
        "G Sullivan",
        "M Stein",
        "M Craske",
        "P Roy-Byrne"
      ],
      "year": 2012,
      "doi": "10.1017/s0033291711002893"
    },
    {
      "title": "Clinical efficacy and economic evaluation of online cognitive behavioral therapy for major depressive disorder: a systematic review and meta-analysis",
      "authors": [
        "E Ahern",
        "S Kinsella",
        "M Semkovska"
      ],
      "year": 2018,
      "doi": "10.1080/14737167.2018.1407245"
    },
    {
      "title": "Cognitive behavior therapy via the Internet: a systematic review of applications, clinical efficacy and cost-effectiveness",
      "authors": [
        "E Hedman",
        "B Lj\u00f3tsson",
        "N Lindefors"
      ],
      "year": 2012,
      "doi": "10.1586/erp.12.67"
    },
    {
      "title": "Computerised cognitive behaviour therapy for depression and anxiety update: a systematic review and economic evaluation",
      "authors": [
        "E Kaltenthaler",
        "J Brazier",
        "De Nigris",
        "E Tumur",
        "I Ferriter",
        "M Beverley",
        "C Parry",
        "G Rooney",
        "G Sutcliffe"
      ],
      "year": 2006,
      "doi": "10.3310/hta10330"
    },
    {
      "title": "Delivery of cognitive behavioural therapy to workers: a systematic review",
      "authors": [
        "V Naidu",
        "E Giblin",
        "K Burke",
        "I Madan"
      ],
      "year": 2016,
      "doi": "10.1093/occmed/kqv141"
    },
    {
      "title": "Cost effectiveness of guided Internet-based interventions for depression in comparison with control conditions: an individual-participant data meta-analysis",
      "authors": [
        "S Kolovos",
        "J Van Dongen",
        "H Riper",
        "C Buntrock",
        "P Cuijpers",
        "D Ebert"
      ],
      "year": 2018,
      "doi": "10.1002/da.22714"
    },
    {
      "title": "Economic evaluations of internet-and mobile-based interventions for the treatment and prevention of depression: a systematic review",
      "authors": [
        "S Paganini",
        "W Teigelk\u00f6tter",
        "C Buntrock",
        "H Baumeister"
      ],
      "year": 2018,
      "doi": "10.1016/j.jad.2017.07.018"
    },
    {
      "title": "Internet-delivered psychological treatments for mood and anxiety disorders: A systematic review of their efficacy, safety, and cost-effectiveness",
      "authors": [
        "F Arnberg",
        "S Linton",
        "M Hultcrantz",
        "E Heintz",
        "U Jonsson"
      ],
      "year": 2014,
      "doi": "10.1371/journal.pone.0098118"
    },
    {
      "title": "A pragmatic randomized waitlist-controlled effectiveness and cost-effectiveness trial of digital interventions for depression and anxiety",
      "authors": [
        "D Richards",
        "Enrique Eilert",
        "N Franklin",
        "M Palacios",
        "J Duffy",
        "D Earley",
        "C Chapman",
        "J Jell",
        "G Sollesse",
        "S Timulak"
      ],
      "year": 2020
    }
  ],
  "num_references": 35
}
