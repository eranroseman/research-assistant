{
  "paper_id": "TZWXE9QS",
  "title": "Revisiting the Psychometric Properties of the Message Fatigue Scale: Evidence for Uni-Dimensionality and Construct Validity",
  "abstract": "Message fatigue is conceptualized as an unpleasant and aversive motivational state that results from excessive and repeated exposure to campaign messages and/or similar information over an extended period of time. There have been substantial increases in research on the role of message fatigue in health communication, the verity of which is contingent upon the robustness and validity of the construct's operationalization. The current study identifies the issues in the extant message fatigue scale validation research and revisits the psychometric properties and factor structure of the  So et al. (2017)  scale. Two-wave panel data from an online survey in the context of COVID-19 and influenza vaccines were used for multilevel confirmatory factor analyses and twolevel modeling for scale validation, which demonstrated strong evidence for the unidimensionality, construct validity, and reliability of the scale.",
  "year": 1987,
  "date": "1987",
  "journal": "Journal of Marketing Research",
  "publication": "Journal of Marketing Research",
  "authors": [
    {
      "forename": "Lijiang",
      "surname": "Shen",
      "name": "Lijiang Shen",
      "orcid": "0000-0003-4870-4878"
    },
    {
      "forename": "Shaochun",
      "surname": "Li",
      "name": "Shaochun Li"
    },
    {
      "affiliation": "Communication Arts & Sciences , The Pennsylvania State University , University Park , United States. \n\t\t\t\t\t\t\t\t Communication Arts & Sciences \n\t\t\t\t\t\t\t\t The Pennsylvania State University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t University Park \n\t\t\t\t\t\t\t\t\t United States"
    },
    {
      "affiliation": "University of Wisconsin-Madison Department of Communication Arts & Sciences , at Pennsylvania State University. Department of Communication Arts & Sciences , at Pennsylvania State University. \n\t\t\t\t\t\t\t\t Department of Communication Arts & Sciences \n\t\t\t\t\t\t\t\t Department of Communication Arts & Sciences \n\t\t\t\t\t\t\t\t University of Wisconsin-Madison \n\t\t\t\t\t\t\t\t at Pennsylvania State University \n\t\t\t\t\t\t\t\t at Pennsylvania State University"
    }
  ],
  "doi": "10.1080/10570314.2025.2468395",
  "keywords": [
    "Bifactor model",
    "Construct validity",
    "Message fatigue",
    "Multilevel confirmatory factor analysis",
    "Multilevel reliability",
    "Two-level modeling",
    "Unidimensionality"
  ],
  "sections": [
    {
      "text": "bombardment of messages are oftentimes by design and intended, probably for good reasons: Repeated and frequent presentation of information typically leads to better memory and learning (e.g.,  Sommer et al., 2021 ; see also  Hassan & Barber, 2021) . And there are potential dose-response effects (see  Arendt, 2015) . Such frequent repetitions of the same or similar messages and information, however, are not without unintended consequences, one of which is message fatigue  (So et al., 2017) .\n\nMessage fatigue can be defined as an unpleasant and aversive motivational state that results from excessive and repeated exposure to campaign messages and/or similar information over an extended period of time  (So et al., 2017) . Campaignrelated information also reaches individuals via secondary channels such as media coverage of the campaign, information spread via social media, and interpersonal discussion on the topic. In this sense, message fatigue can be considered interchangeable with information fatigue (including topic, issue, content, etc.) (see  Gurr, 2022; Gurr & Metag, 2023) . There has been evidence that when message fatigue occurs, individuals tend to be less attentive, less responsive, and more resistant to campaign messages and related information, which renders the campaign less effective (e.g.,  Kim & So, 2018; Reynolds-Tylus et al., 2020) , especially during the COVID-19 pandemic when individuals were already scared and weary (e.g.,  Ball & Wozniak, 2022; Guan et al., 2023; Hwang et al., 2023; ; Sun & Lee, 2023) . This surge of research on the construct and phenomenon of message fatigue has obviously been facilitated by the scale development work by  So et al. (2017) . The variety of results about a psychological construct, however, is determined by the validity (and reliability) of its operationalization  (Flake et al., 2017) . When a key construct does not have a valid measure, the systematic error in its observation always remains an alternative explanation, constituting threats to internal validity. Consequently, the empirical evidence in theory testing would be based on inaccurate or misleading observations, and practices and applications might be misinformed and misguided. Hence, it is imperative that the psychometric properties and construct validity of the message fatigue scale be assessed and validated. Scholars tend to agree that a valid measurement scale requires: 1) conceptual clarification in concept explication and solid conceptual foundations  (Borgstede & Eggert, 2023; Bringmann et al., 2022; Haig & Borsboom, 2008; Markus, 2008) ; 2) a well-established factor structure (i.e., unidimensionality) and psychometric properties; 3) validity (content, construct, and criterion validity) and reliability; and 4) internal and external consistency and parallelism  (Anderson et al., 1987; Flake et al., 2017; Hunter & Gerbing, 1982) .\n\nOur analyses and assessment of  So et al. (2017)  and the replication in  Song and So (2023)  suggest that issues existed in the reported confirmatory factor analyses (CFA); hence, evidence for the scale's factor structure and construct validity is rather inconclusive. The goals of this study were twofold. First, we sought to validate the message fatigue scale developed by  So et al. (2017)  by re-visiting the factor structure and psychometric properties, subsequently assessing its construct validity, and internal and external parallelism. Second, we hoped to assess the scale's measurement invariance. With these goals in mind, the extant scale validation will be assessed and evaluated first. Hypotheses regarding message fatigue and its antecedents and consequences will be derived. Panel data from a two-wave, web-based survey in the context of COVID-19 and influenza vaccines will be presented for confirmatory factor analyses, measurement invariance, and construct validity and reliability assessments."
    },
    {
      "title": "Measuring Message Fatigue",
      "text": "It was proposed that there are four conceptual dimensions in the construct of message fatigue  (So et al., 2017) : perceived overexposure, perceived redundancy, exhaustion, and tedium. The first two dimensions tend to be more cognitive in nature, and the last two are more affective; however, they are supposed to be intertwined as a single construct. So et al. (2017)  developed a scale of 17 items to measure the construct of message fatigue, and established the unidimensionality of the scale with a third-order factor structure, with message environment and audience response as the second-order factors and the originally explicated four first-order factors (overexposure, redundancy, exhaustion, and tedium). Conceptually, the unidimensional structure of the scale makes sense: first, message environment captures the more cognitive dimensions (overexposure and redundancy) and audience response captures the more affective dimensions (tedium and exhaustion); second, the literature on the relationship between cognition and affect (e.g.,  Dillard & Shen, 2005; Rains, 2013)  suggests the cognitive dimensions (overexposure and redundancy) and the affective dimensions (tedium and exhaustion) might be intertwined and cluster into a single construct. On the other hand, there is also literature that suggests cognitive and affective dimensions are distinct and sequential despite the disagreement on their respective primacy (e.g.,  Lazarus, 1999) . The original scale development and the follow-up replication study  (Song & So, 2023) , however, were problematic and warranted further validation and assessment of the scale.\n\nOur review and analysis identified several issues. First, the potential discrepancy between the conceptual definition and factor analyses; it was not clear if the two second-order factors (message environment and audience response) were part of the original conceptual definition. Presumably, they might have been created during confirmatory factor analyses when a second-order single-factor structure did not fit the data. Second, the confirmatory factor analyses were problematic in that a factor (i.e., the third-order factor) with two indicators (i.e., the second-order factors of message environment and audience response) is unidentified unless there are external variables that co-vary with the latent factor (e.g., in the middle of a causal chain) or the two factor loadings are constrained to be equal with the value of the factor loading to be estimated from the data (see  Bollen, 1989; Brown, 2015) . The identification issue was handled by constraining one of the factor loadings to be 1 in both  So et al. (2017)  and  Song and So (2023) , which created a host of problems: 1) the specific factor loading was not estimated from the data but determined by the researcher, which constituted researcher's degree of freedom  (Wicherts et al., 2016) , introduced substantial model uncertainty and factor indeterminacy  (Rigdon & Sarstedt, 2022) , and rendered the factor structure uninterpretable  (Loehlin & Beaujean, 2017) ; 2) there is an arguably worse problem: when the standardized factor loading was constrained to be 1.0 (which is different from assigning a starting value of 1.0 for a parameter), the latent factor became identical with the corresponding indicator-for example, message fatigue would be identical with audience response in  So et al. (2017)  and  Song and So (2023) . When that was the case, the full scale was no longer needed and should be reduced to the eight items that measure audience response; and 3) if this was the case, then it, in turn, caused content validity issues in that the reduced scale no longer captured the full range of meaning of message fatigue explicated in the conceptual definition. Finally, with the issues in CFA and unresolved uncertainty in the factor structure, the construct validity assessment reported in the scale development and validation studies  (So et al., 2017; Song & So, 2023)  became suspect. Fourth, the reported replications focused on model fit across multiple topics and content domains, but the measurement invariance of the scale was not assessed.\n\nFor confirmatory factor analysis and structural equation modeling in general, alternative model specifications should be specified, tested, and compared  (Vandenberg & Grelle, 2009) . Given the conceptualization and extant empirical observations, the testing of and comparison with the first-order single-factor model might have become moot. The second model is the first-order four-factor model (i.e., overexposure, redundancy, exhaustion, and tedium). The third model is the secondorder, two-factor model (i.e., message environment and audience response) based on  So et al. (2017) . Given that message environment is more cognitive and audience response is more affective, per the cognitive appraisal theories (see  Scherer et al., 2001) , the former might be a causal antecedent to the latter rather than a mere covariate. When the unidimensionality of a scale is not established on the first order, there are two alternatives, that is, via a higher-order model or a bifactor model  (Markon, 2019) . The fourth model is the second-order single-factor model. Finally, the bifactor model where the general factor represents the latent factor of message fatigue and four uncorrelated group/nuisance factors represent the unique aspects captured by the items corresponding to the four first-order factors  (Gignac, 2016; Markon, 2019; Morin et al., 2020) . It was asked:\n\nRQ1: What is the factor structure of the seventeen-item message fatigue scale  (So et al., 2017) ?"
    },
    {
      "title": "Validity Assessment",
      "text": "With the knowledge of the factor structure, scale validation also requires validity assessment in a nomological network of external variables consisting of both antecedents and outcomes of the construct. For this study, validation of the  So et al. (2017)  message fatigue scale was performed in the context of COVID-19 and influenza vaccines for the following reasons. First, the pandemic had lasted for an extended period of time (i.e., from December 2019 to April 11, 2023, when the U.S. ended the COVID national emergency). There has been a plethora of information on COVID-19 vaccines since when they were authorized for emergency use authorization in December 2020, from both pro-and anti-vaccine positions, and in all sorts of channels (traditional media, social media, interpersonal and social networks, etc.). There were also debates and political controversies regarding a COVID-19 vaccine mandate. Second, there was also extensive media coverage and discussions on the annual influenza vaccine being strongly recommended (but to a lesser degree relative to COVID-19 vaccines) because it would facilitate COVID-19 diagnoses if medical care professionals could rule out the flu faster and more easily. Third, there were also substantial and clear differences between the type, amount, and potential impact of information on COVID-19 vaccines and on influenza vaccines in that there was a lot more uncertainty and anxiety (i.e., due to the new technology in the development and the short history), misinformation (e.g.,  Skafle et al., 2022) , politicization, and polarization between the pro-and antivaccine groups for the COVID-19 vaccines (e.g.,  Bolsen & Palm, 2022; Zhao et al., 2023)  than for the influenza vaccine. Along these lines of argument, it was predicted that: H1: Message fatigue related to COVID-19 vaccines is significantly higher than that related to influenza vaccine.\n\nAs a form of psychological/mental fatigue, message fatigue was conceptualized as the combination of cognitive overload and mental exhaustion  (So et al., 2017) . One antecedent to such fatigue lies in prolonged cognitive activities or sustained attention to stressful information and/or demanding tasks. This is particularly relevant when the more cognitive dimensions of message fatigue (i.e., overexposure and redundancy) are considered. It has been well-established both conceptually and empirically that message fatigue results from excessive and cumulative exposure to the same class of message/information (i.e., in terms of topic, issue, content, etc.) (e.g.,  So et al., 2017; Song & So, 2023) . Therefore, it was predicted that:\n\nH2: Message fatigue is positively associated with cumulative exposure to vaccinerelated information.\n\nThe experiential dimensions (i.e., exhaustion and tedium) in message fatigue are similar to a state of depletion or overwhelmedness related to emotional experiences and stressors, which suggests there are affective correlates of message fatigue. Above and beyond excessive exposure to similar information, experiential message fatigue can occur due to prolonged experience of negative affective states such as stress, anxiety, or emotional turmoil. On the other hand, experiences of positive affective states should help with coping with and mitigation of fatigue. This is consistent with the literature on motivated information processing, especially in the context of health issues (e.g.,  Good & Abraham, 2007; Johnson et al., 2004; van 't Riet et al., 2013) . Hence, it was predicted that:\n\nH3a: Message fatigue is positively associated with vaccine-related negative affective states. H3b: Message fatigue is negatively associated with vaccine-related positive affective states.\n\nThe direct impact of mental and psychological fatigue lies in decreased motivation, reduced cognitive capacity, and impaired performance (e.g.,  Gavelin et al., 2020) . Potential outcomes of message fatigue consist of desensitization to and avoidance of similar messages/information. The extant literature has demonstrated the robust relationship between message fatigue and unintended effects such as audience becoming less attentive, less responsive to, and having more negative evaluations of campaign messages and related information (e.g.,  Gurr & Metag, 2023; Schumann, 2022) , and ultimately more resistance against campaigns and/or interventions (e.g.,  Guan et al., 2023; Shen & Li, 2022; Kim & So, 2018; So et al., 2017; Reynolds-Tylus et al., 2020) . Based on both theory and available empirical evidence, it was predicted that in the context of COVID-19 and influenza vaccines:\n\nH4: Message fatigue is negatively associated with intention to seek vaccine-related information. H5: Message fatigue is negatively associated with intention to get vaccinated."
    },
    {
      "title": "Method"
    },
    {
      "title": "Participants and Procedures",
      "text": "A two-wave online survey was conducted during the spring of 2023. Participants were sampled from the general U.S. population through a nationwide, opted-in, online panel with Qualtrics. The inclusion criteria were English-speaking and age 18 years and older. The Wave 1 survey took place between March and April 2023. Participants who completed the first survey were invited to participate in Wave 2 of the survey, which took place between May and June 2023. Two mechanisms were in place for data quality control purposes: 1) data from respondents who failed at the attention checkers were automatically dropped; and 2) data from respondents who spent less than 1/3 of the mean participation duration time in the Wave-1 survey soft launch (M = 25 minutes) were also dropped. Of the 601 participants who completed the first-wave survey, 305 (50.83%) also completed the second wave of the survey. Only data from the 305 respondents who completed the survey in both waves were reported here. The demographic and geographic profiles of the sample matched the census data through quota sampling. Table  1  presents the demographic information of the sample.\n\nThe consenting participants were asked to respond to questions on both vaccine topics (each topic was presented in a random order). When relevant, the multiple questions measuring the same construct were presented in a random order. For the survey in Wave 1, participants were asked to report their demographic information and political orientation first. Then, within each topic, participants were asked to report their vaccination status (for COVID-19: without the primary series, the first booster shot, and the updated booster shot; and for influenza: yes or no). They then responded to measures of cumulative exposure to vaccine-related information in the past year, their emotional responses to vaccine-related information, and the seventeen-item message fatigue measure  (So et al., 2017) . Finally, they reported their intention to seek vaccinerelated information and intention to get vaccinated (for COVID-19: when they are/ become eligible for the updated booster shot; for influenza: for the next flu season). The survey design in the second wave remained largely the same, with the following differences: 1) the demographic questions were no longer asked; 2) the participants were asked to update their vaccination status if they got vaccinated since they completed the first-wave survey; and 3) the time frame for the vaccine-related information exposure questions was specified since you completed our survey about a month ago."
    },
    {
      "title": "Measures",
      "text": "Except for the demographic variables and political orientation, the measures for other variables were repeated four times (i.e., across the two topics and two waves).\n\nBecause of this nested design (i.e., individuals nested within measurement occasions), reliabilities at the measurement occasion level are the functional equivalent of Cronbach's alphas taking into consideration the nested structure of observations  (Nezlek, 2017 ; see also  Bonito et al., 2012) ."
    },
    {
      "title": "Message Fatigue",
      "text": "The seventeen-items of the  So et al. (2017)  scale were used to measure message fatigue (1 = strongly disagree, 7 = strongly agree) toward information related to COVID-19 and influenza vaccines in both waves. The seventeen items were used as the input data for analyses to validate the factor structure and psychometric properties of the scale."
    },
    {
      "title": "Political Orientation",
      "text": "Political orientation was a controlled covariate. The literature on vaccine confidence and hesitancy suggests significant associations between political orientation and responses to vaccines-namely, more conservative individuals tend to have more negative reactions to vaccines and higher levels of vaccine hesitancy than more liberal persons (e.g.,  Bolsen & Palm, 2022; Cao et al., 2022) . The construct was measured by two 1-to-7-point semantic differential items. The word pairs were: liberal/conservative and left-wing/right-wing. A composite score was created by taking the average of the two items (r = .82), where higher scores indicate a stronger conservative orientation (M = 3.89, SD = 1.41)."
    },
    {
      "title": "Cumulative Message Exposure",
      "text": "The instrument to measure cumulative message exposure was adapted from Shen & Li (2022). For each of the two topics, within each time frame (\"during the last year\"\n\nfor Wave 1, and \"since the last survey\" for Wave 2), participants reported their cumulative exposure to both pro-and anti-vaccine information from nine sources: medical professionals, traditional media, acquaintances, friends, coworkers, family members, social media, Internet websites, and other sources, on a 7-point scale (1 = never, 2 = once or twice, 3 = 3-5 times, 4 = 6-10 times, 5 = 10-20 times, 6 = 20-30 times, 7 = more than 30 times). The averages of the respective nine items were taken as the scores for pro-and anti-vaccine information exposure, which were then combined into a score for total exposure to vaccine-related information (M = 3.70, SD = 1.69). The items were considered as causal-formative indicators for the exposure construct; hence, alpha reliability was not relevant  (Bollen & Diamantopoulos, 2017) ."
    },
    {
      "title": "Affective Responses to Vaccine-Related Information",
      "text": "On each measurement occasion, participants reported how the vaccine-related information and messages made them feel on a 7-point scale (1 = none of this feeling, 7 = a lot of this feeling) adapted from  Dillard & Shen (2018) . Two negative and two positive affective states were measured. The corresponding items and the multilevel-scale reliabilities were: anger (annoyed, irritated, angry, multilevel \u03b1 = .73, M = 2.65, SD = 1.67), fear (scared, afraid, fearful, multilevel \u03b1 = .78, M = 2.39, SD = 1.55), hope (hopeful, optimistic, upbeat, multilevel \u03b1 = .74, M = 3.13, SD = 1.67), and happiness (happy, glad, joyful, elated, multilevel \u03b1 = .83, M = 2.78, SD = 1.59)."
    },
    {
      "title": "Intention to Seek Vaccine-Related Information",
      "text": "Within each vaccine topic, five items measured participants' intention to seek more information about that topic on a 7-point scale (1 = extremely unlikely, 7 = extremely likely): \"I will try to seek information about [the vaccine],\" \"I intend to find more information about [the vaccine],\" \"I will avoid information about [the vaccine],\" \"When it comes to [the vaccine], I don't want to know more\" (reverse coded), and \"I will tune out information about [the vaccine]\" (reverse coded). A composite score was created by taking the average of the items (multilevel \u03b1 = .80, M = 4.17, SD = 1.52)."
    },
    {
      "title": "Intention to Get Vaccinated",
      "text": "Intention to get vaccinated was measured by a single item for each topic: \"How likely are you going to receive an annual COVID-19 booster shot (if recommended by the CDC)\" and \"How likely are you going to receive the annual flu shot this flu season (or the next flu season if you already received the shot this year). Participants indicated on a slider their likelihood (in percentage) of getting vaccinated (M = 58.2%, SD = 39.8%). The statement for COVID-19 referred to a hypothetical annual revaccination scenario for the following factors: 1) the uncertainty regarding when the booster shot might be updated; 2) the individual differences in terms of their eligibility for the booster shot; 3) the potential of an annual revaccination recommendation for a COVID-19 booster shot (e.g., The Centers for Disease Control and Prevention (CDC), 2023); and 4) to make the intention measure more consistent between the two vaccines."
    },
    {
      "title": "Results"
    },
    {
      "title": "Data Analysis Strategy",
      "text": "Considering the interdependence in the data introduced by the structure of four measurement occasions (two topics by two waves) nested within individuals, the multilevel confirmatory factor analysis was adopted to validate the factor structure and psychometric properties of the  So et al. (2017)  seventeen-item message fatigue scale. The multilevel CFA approach  (Brown, 2015; Kaplan & Elliott, 1997; Mehta & Neale, 2005; Silva et al., 2020)  was more appropriate than and superior to the traditional (multi-group) CFA approach for the data for the following reasons: first, the participants responded to the seventeen scale items four times (running four separate CFA models would be inefficient and create a multiple-testing scenario); second, the multi-group CFA approach could not be an option since the observations at each measurement occasion were not independent; third, potentially the 68 items across the four measurement occasions can be modeled in a single CFA model (i.e., the latent factors and their corresponding items in the four measurement occasions would be listed parallel to each other and associations between items and factors allowed where appropriate), but that would greatly increase the size of the covariance matrix (by four times), artificially create more degrees of freedom in model fitting and testing, and inflate the goodness-of-fit statistics  (Moshagen, 2012) ; and, fourth, issues in measurement invariance assessment  (Putnick & Bornstein, 2016)  due to the nested data structure could not be addressed in the multi-group CFA approach-on the contrary, the multilevel CFA approach estimates the factor structures within measurement occasions (between individuals) and between measurement occasions (within individuals) simultaneously without inflating the covariance matrix size or biasing the goodness-of-fit statistics. It is therefore more efficient, more parsimonious, and more robust. Given that the multilevel factor model is a good fit to the data, the factor structure and loadings are equivalent to the fixed effects parameters in a multilevel modeling analysis; and the potential differences between measurement occasions are considered as random variances.\n\nIn other words, measurement invariance across the measurement occasions would be self-evident in a multilevel CFA, since the parameters (i.e., factor loadings) in the obtained model are based on the input data across the four measurement occasions, the differences between which are due to sampling error, hence, evidence for structural and metric invariance  (Meredith, 1993) . Assessment of construct validity also adopted the multilevel modeling approach to test the hypotheses. Power for the confirmatory factor analyses was estimated following  MacCallum et al. (1996) : With a sample size of N = 305 and degrees of freedom of about 240 (see  Rigdon, 1994  for calculation of d.f. for SEM models), the statistical power to detect a close fit exceeded .99. Statistical power in the two-level models was estimated following the procedure in  Raudenbush & Liu (2000) , with the following parameters: \u03b1 = .05, number of repeated measures = 4, standardized effect size at .30, variability of Level 1 coefficient at 1.0, and variability of Level 1 residual at 0.1, the sample size of N = 305 yielded a statistical power of .74."
    },
    {
      "title": "Multilevel Confirmatory Factor Analyses 1",
      "text": "The seventeen items from  So et al. (2017)  measured across the four measurement occasions were used as the input data to Mplus 8.9 for multilevel CFA analyses, using maximum likelihood estimation and the two-level, random-slope procedure to test various factor structures of the scale, with measurement occasion as the clustering factor. Per the RQ, five models were estimated: the first-order single-factor model where a single factor loaded on all seventeen items (M1); the first-order four-factor model where the factors of overexposure, redundancy, exhaustion, and tedium loaded on their corresponding items, and were allowed to correlate (M2); the second-order two-factor model where message environment loaded overexposure and redundancy and audience response on exhaustion and tedium, and the latter regressed onto the former (M3); the second-order single-factor model where message fatigue loaded onto the four first-order factors (M4); and the bifactor model where the general factor loaded on all seventeen items and the four group/nuisance factors loaded on their corresponding items with no inter-factor correlations allowed (M5).\n\nTo evaluate the overall fit of the models to the data, four fit indices were considered. First, the Goodness-of-Fit Index (GFI) produces values ranging from 0 to 1 with values larger than .90 indicating a good fit. Second, the Comparative Fit Index (CFI) produces values ranging from 0 to 1 with values larger than .95 indicating a good fit  (Hu & Bentler, 1999) . Third,  Bentler and Bonett (1980)  recommended that a Tucker-Lewis index (TLI) larger than .90 indicates an acceptable model fit. Fourth,  Browne and Cudeck (1993)  contend that values of the Root Mean Square Error of Approximation (RMSEA) of .08 or lower indicate reasonable fit, though values of .06 or below should be preferred. Fifth, the Bayesian Information Criterion (BIC) is constructed such that negative values provide evidence of model fit, while positive BIC values suggest problematic model fit  (Raftery, 1995) . For model comparisons, the chi-square significance test and BIC difference were used. Differences in BIC of 2 are thought to provide some evidence; 6 or more, strong evidence; and 10 or more, very strong evidence for the superiority of the model with a more negative BIC value over another  (Raftery, 1995) . Table  2  presents the model fit indices and model comparisons from the multilevel CFA analyses.\n\nThe first-order single-factor model (M1) was not an acceptable fit to the data across the fit statistics. Although the chi-squares were significant, the other four models all yielded good model fit statistics. The first-order fourfactor model (M2) was superior to the other three models, which was expected since the other models had more constraints and were nested with M2. The goodness-of-fit indices were almost identical for the other three models, but model comparison results were in favor of M5. Evidence for the superiority of M5 came from chi-square difference tests: \u0394\u03c7 foot_0  (22) = 47.62, p = .001 against M2; \u0394\u03c7 2 (24) = 137.23, p < .001 against M3; and \u0394\u03c7 2 (26) = 162.34, p < .001 against M4. The BIC differences showed that M5 was superior to M4 (\u0394BIC = 13.61), equivalent to M3 (\u0394BIC = 0.06), but with a worse fit than M2 (\u0394BIC = 75.23). Based on these results, the bifactor model was obtained, which suggested the message fatigue scale was unidimensional. It should be noted that 1) although M4 was not superior or equivalent to M2 or M5, it remained an acceptable model based on the goodness-of-fit indices, which suggested the message fatigue scale was unidimensional; and 2) while M3 can also be a plausible model, a single-factor structure is more parsimonious and more efficient (for the data reduction purpose), and easier to interpret and use in research."
    },
    {
      "title": "Parallelism and Scale Reliability",
      "text": "Figure  1  presents the unstandardized within-measurement-occasion/betweenindividuals factor loadings in the obtained bifactor model. The factor loadings for the general factor of message fatigue were quite similar in magnitude across the seventeen items, demonstrating internal parallelism. Given the uni-dimensionality on the first order, the internal parallelism also means that the scale has external parallelism (i.e., the observed indicators will be associated with external variables in similar magnitudes). The seventeen items of the scale were averaged into a composite score on each measurement occasion for validity assessment (multilevel reliability \u03b1 = .94). Western Journal of Communication 711 (\u03b2 = -0.10, p = .002) and hope (\u03b2 = -0.16, p < .001) reduced fatigue. H3b was supported.\n\nWhen predicting intention to seek information, being more conservative reduced intention (\u03b2 = 0.07, p=.03). Cumulative exposure (\u03b2 = 0.06, p=.003), fear (\u03b2 = 0.10, p < .001), happiness (\u03b2 = .08, p = .01), and hope (\u03b2 = 0.11, p < .001) increased, while anger (\u03b2 = -0.19, p < .001) reduced intention. More importantly, message fatigue had a significant and negative impact on intention (\u03b2 = -0.48, p < .001). H4 was supported.\n\nWhen predicting intention to get vaccinated, education (\u03b2 = 2.89, p=.008) increased, and being conservative (\u03b2 = -3.16, p=.002) reduced vaccination intention. Between the two topics, individuals had a significantly higher intention (\u03b2 = -6.50, p < .001) to receive the influenza vaccine (M = 72.2%, s.e. = 7.6%) than COVID-19 (M = 65.7%, s.e. = 7.5%). Anger (\u03b2 = -3.97, p < .001) reduced, but happiness (\u03b2 = 2.33, p = .005) and hope (\u03b2 = 2.41, p = .002) increased intention. More importantly, message fatigue significantly reduced intention to get vaccinated: \u03b2 = -6.96, p < .001. H5 received support.\n\nAll hypotheses for validity assessment were supported except that results for H3a were mixed. The results related to the impact of fear were opposite to the prediction. It was plausible that the affective experience of fear toward COVID-19 vaccines could not be empirically separated from fear toward the virus and disease of COVID-19. It might be impossible to think about the vaccines without thinking about the corresponding viruses/diseases. The former might even be overridden by the latter. The results for H3a were compatible with the fear appeal literature (e.g.,  Tannenbaum et al., 2015)  and the protection motivation theory (R. W.  Rogers & Prentice-Dunn, 1997)  in particular: Fear should be negatively associated with message fatigue but positively associated with protection motivation (i.e., intention to seek information and to get vaccinated). In conclusion, results from two-level models predicting message fatigue and intentions to seek information and to get vaccinated constituted evidence for the construct validity of the message fatigue scale."
    },
    {
      "title": "Discussion"
    },
    {
      "title": "Further Validation of the Message Fatigue Scale",
      "text": "The credibility and replicability of substantive research findings on a psychological construct are contingent upon the quality of its measurement instrument (i.e., psychometric property, validity, and reliability). Accordingly, evaluation and assessment of the message fatigue scale  (So et al., 2017)  is an increasingly important precursor to building a body of knowledge on message fatigue, its role in campaign/ message effects, and means to mitigate or preempt fatigue, especially given the recent surge of interest in the construct in the context of the pandemic. So et al. (2017)  and the subsequent replication  (Song & So, 2023)  claimed there was evidence for the unidimensionality and construct validity of the scale. The issues in the confirmatory factor analyses reported in  So et al. (2017)  and  Song and So (2023) , however, rendered the results reported suspect at best. This study set out to re-visit the psychometric properties and factor structure of the  So et al. (2017)  message fatigue scale in a two-wave survey design in the context of two vaccine topics (COVID-19 and influenza vaccines).\n\nGiven the repeated measures defined by topic and survey wave, multilevel confirmatory factor analyses were performed to test and compare factor models. Based on a set of goodness-of-fit statistics, chi-square significance tests, and BIC differences, the bifactor model yielded the best fit to the data and was obtained; a general conceptual factor of message fatigue and four group/nuisance factors was a good fit within and between measurement occasions, and adequately represented/produced the two-level variance/covariance structure in the data based on the seventeen items. The multilevel CFA results also suggested metric measurement invariance across measurement occasions in that the potential differences in factor loadings across occasions were random variances (i.e., due to sampling error).\n\nThe factor loadings from the general conceptual factor onto the seventeen items (Figure  1 ) were also similar in magnitude, which constituted parallelism. Multilevel reliability assessment following Nezlek (2017) suggested the scale was reliable. Hypothesis testing in the context of a nomological network of antecedents (vaccine topic, cumulative exposure, and negative and positive affective experiences) and consequences (intention to seek information and to get vaccinated) demonstrated evidence for the scale's construct validity.\n\nThe unidimensionality, validity, and reliability of the So et al. (  2017 ) message fatigue scale reported in this study suggest that health communication and practitioners need not worry about the findings in the extant research on message fatigue. They should be valid and robust. Researchers should continue the practice of using the seventeen items to measure a single construct. Nevertheless, better and stronger evidence should come from future studies across contexts and topics (including health, non-health, political issues, and beyond) that replicate and expand the results reported in the current study (or potential re-analyses of the data from So and associates)."
    },
    {
      "title": "Strengths and Limitations",
      "text": "These findings should be interpreted with the strengths and weaknesses of the current study in mind. The study had a few strengths. First, the confirmatory factor analyses presented in this study addressed the model fitting issues in  So et al. (2017)  and  Song and So (2023) , which reduced model uncertainty and factor indeterminacy. Rigorous model testing and comparisons further added to the robustness of the findings. Second, the multilevel CFA approach also yielded evidence for metric measurement invariance and inherent replications. Third, one potential issue in the majority of extant studies on message fatigue lies in that the temporal dimension and cumulative nature of fatigue have been largely overlooked. The two-wave panel data and the measure of cumulative exposure to vaccine-related information through multiple channels adequately addressed that issue.\n\nThis study also had some limitations. First, with only two waves in the data, the current study was unable to study the longitudinal and dynamic relationship between cumulative exposure to information, message fatigue, and outcomes. Second, a related issue was that the size of clusters in multilevel modeling analyses (n = 4) was not optimal (see  Maas & Hox, 2005; Moerbeek & Teerenstra, 2016; Rabe-Hesketh & Skrondal, 2005 ). An intensive longitudinal design (e.g.,  Brinberg & Lydon-Staley, 2023 ) might be needed for future studies. Third, the same issue applies to the number of topics (n = 2). Replications and evidence from future studies would certainly benefit from designs with more and/or non-vaccine-related topics. Fourth, only the convergent validity of the scale was assessed, but not discriminant validity. More comprehensive assessments of validity and reliability should further strengthen the evidence for the scale."
    },
    {
      "title": "Summary",
      "text": "In conclusion, data from the current study showed strong evidence that the seventeen-item message fatigue scale  (So et al., 2017)  is unidimensional, reliable, and valid. This forms a solid foundation for research findings using the  So et al. (2017)  scale or its short forms (e.g.,  Song & So, 2023, but see; Kogar, 2020) . Although more replications and evidence from future studies might be needed, readers should have confidence in the extant literature, as well as new findings from future studies."
    },
    {
      "title": "Disclosure Statement",
      "text": "No potential conflict of interest was reported by the author(s)."
    },
    {
      "text": "Figure 1 Unstandardized Factor Loadings in the Obtained Bifactor Model"
    },
    {
      "text": "Demographic Characteristics of the Sample (N = 305)"
    },
    {
      "text": "Fit Indices and Model Comparisons from the Multilevel Confirmatory Factor Analyses"
    },
    {
      "text": "Fixed Effects Parameter Estimates from Two-Level Models for Validity Assessment"
    }
  ],
  "references": [
    {
      "title": "On the assessment of unidimensional measurement: Internal and external consistency, and overall consistency criteria",
      "authors": [
        "J Anderson",
        "D Gerbing",
        "J Hunter"
      ],
      "year": 1987,
      "doi": "10.1177/002224378702400412"
    },
    {
      "title": "Toward a dose-response account of media priming",
      "authors": [
        "F Arendt"
      ],
      "year": 2015,
      "doi": "10.1177/0093650213482970"
    },
    {
      "title": "Why do some Americans resist COVID-19 prevention behavior? An analysis of issue importance, message fatigue, and reactance regarding COVID-19 messaging",
      "authors": [
        "H Ball",
        "T Wozniak"
      ],
      "year": 2022,
      "doi": "10.1080/10410236.2021.1920717"
    },
    {
      "title": "Significance tests and goodness of fit in the analysis of covariance structures",
      "authors": [
        "P Bentler",
        "D Bonett"
      ],
      "year": 1980,
      "doi": "10.1037/0033-2909.88.3.588"
    },
    {
      "title": "In defense of causal-formative indicators: A minority report",
      "authors": [
        "K Bollen",
        "& John Wiley",
        "Sons",
        "K Bollen",
        "A Diamantopoulos"
      ],
      "year": 1989,
      "doi": "10.1037/met0000056"
    },
    {
      "title": "Politicization and COVID-19 vaccine resistance in the U",
      "authors": [
        "T Bolsen",
        "R Palm"
      ],
      "year": 2022,
      "doi": "10.1016/bs.pmbts.2021.10.002"
    },
    {
      "title": "Reliability estimates for multilevel designs in group research",
      "authors": [
        "J Bonito",
        "E Ruppel",
        "J Keyton"
      ],
      "year": 2012,
      "doi": "10.1177/1046496412437614"
    },
    {
      "title": "Squaring the circle: From latent variables to theory-based measurement",
      "authors": [
        "M Borgstede",
        "F Eggert"
      ],
      "year": 2023,
      "doi": "10.1177/09593543221127985"
    },
    {
      "title": "Conceptualizing and examining change in communication research",
      "authors": [
        "M Brinberg",
        "D Lydon-Staley"
      ],
      "year": 2023,
      "doi": "10.1080/19312458.2023.2167197"
    },
    {
      "title": "Back to basics: The importance of conceptual clarification in psychological science",
      "authors": [
        "L Bringmann",
        "T Elmer",
        "M Eronen"
      ],
      "year": 2022,
      "doi": "10.1177/09637214221096485"
    },
    {
      "title": "Confirmatory factor analysis for applied research",
      "authors": [
        "T Brown"
      ],
      "year": 2015
    },
    {
      "title": "Alternative ways of assessing model fit",
      "authors": [
        "M Browne",
        "R Cudeck"
      ],
      "year": 1993,
      "doi": "10.1177/0049124192021002005"
    },
    {
      "title": "The politics of vaccine hesitancy in the United States",
      "authors": [
        "J Cao",
        "C Ramirez",
        "R Alvarez"
      ],
      "year": 2022,
      "doi": "10.1111/ssqu.13106"
    },
    {
      "title": "CDC recommends updated COVID-19 vaccine for fall/winter virus season",
      "year": 2023,
      "doi": "10.1001/jama.2024.24258"
    },
    {
      "title": "On the nature of reactance and its role in persuasive health communication",
      "authors": [
        "J Dillard",
        "L Shen"
      ],
      "year": 2005,
      "doi": "10.1080/03637750500111815"
    },
    {
      "title": "Threat appeals as multi-emotion messages: An argument structure Model of fear and disgust",
      "authors": [
        "J Dillard",
        "L Shen"
      ],
      "year": 2018,
      "doi": "10.1093/hcr/hqx002"
    },
    {
      "title": "Construct validation in social and personality research: Current practice and recommendations",
      "authors": [
        "J Flake",
        "J Pek",
        "E Hehman"
      ],
      "year": 2017,
      "doi": "10.1177/1948550617693063"
    },
    {
      "title": "Mental fatigue in stress-related exhaustion disorder: Structural brain correlates, clinical characteristics and relations with cognitive functioning",
      "authors": [
        "H Gavelin",
        "A Neely",
        "T Dun\u00e5s",
        "T Eskilsson",
        "L J\u00e4rvholm",
        "C Boraxbekk"
      ],
      "year": 2020,
      "doi": "10.1016/j.nicl.2020.102337"
    },
    {
      "title": "The higher-order model imposes a proportionality constraint: That is why the bifactor model tends to fit better",
      "authors": [
        "G Gignac"
      ],
      "year": 2016,
      "doi": "10.1016/j.intell.2016.01.006"
    },
    {
      "title": "Measuring defensive responses to threatening messages: A meta-analysis of measures",
      "authors": [
        "A Good",
        "C Abraham"
      ],
      "year": 2007,
      "doi": "10.1080/17437190802280889"
    },
    {
      "title": "COVID-19 message fatigue: How does it predict preventive behavioral intentions and what types of information are people tired of hearing about?",
      "authors": [
        "M Guan",
        "Y Li",
        "J Scoles",
        "Y Zhu"
      ],
      "year": 2023,
      "doi": "10.1080/10410236.2021.2023385"
    },
    {
      "title": "Does fatigue from ongoing news issues harm news media? Assessing reciprocal relationship between audience issue fatigue and news media evaluations",
      "authors": [
        "G Gurr"
      ],
      "year": 2022,
      "doi": "10.1080/1461670x.2022.2049453"
    },
    {
      "title": "What leads to audience issue fatigue? A linkage analysis study on the effects of news coverage on fatigue from ongoing news issues",
      "authors": [
        "G Gurr",
        "J Metag"
      ],
      "year": 2023,
      "doi": "10.1080/1461670x.2022.2049453"
    },
    {
      "title": "On the conceptual foundations of psychological measurement",
      "authors": [
        "B Haig",
        "D Borsboom"
      ],
      "year": 2008,
      "doi": "10.1080/15366360802035471"
    },
    {
      "title": "The effects of repetition frequency on the illusory truth effect",
      "authors": [
        "A Hassan",
        "S Barber"
      ],
      "year": 2021,
      "doi": "10.1186/s41235-021-00301-5"
    },
    {
      "title": "Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives",
      "authors": [
        "L Hu",
        "P Bentler"
      ],
      "year": 1999,
      "doi": "10.1080/10705519909540118"
    },
    {
      "title": "Unidimensional measurement, second order factor analysis, and causal models",
      "authors": [
        "J Hunter",
        "D Gerbing"
      ],
      "year": 1982
    },
    {
      "title": "Does COVID-19 message fatigue lead to misinformation acceptance? An extension of the risk information seeking and processing model",
      "authors": [
        "Y Hwang",
        "J So",
        "S Jeong"
      ],
      "year": 2023,
      "doi": "10.1080/10410236.2022.2111636"
    },
    {
      "title": "Truth or consequences: Overcoming resistance to persuasion with positive thinking",
      "authors": [
        "B Johnson",
        "A Smith Mclallen",
        "L Killeya",
        "K Levin"
      ],
      "year": 2004
    },
    {
      "title": "A didactic example of multilevel structural equation modeling application to the study of organizations",
      "authors": [
        "D Kaplan",
        "P Elliott"
      ],
      "year": 1997,
      "doi": "10.1080/10705519709540056"
    },
    {
      "title": "How message fatigue toward health messages leads to ineffective persuasive outcomes: Examining the mediating roles of reactance and inattention",
      "authors": [
        "S Kim",
        "J So"
      ],
      "year": 2018,
      "doi": "10.1080/10810730.2017.1414900"
    },
    {
      "title": "Development of a short form: Methods, examinations and recommendations",
      "authors": [
        "H Kogar"
      ],
      "year": 2020,
      "doi": "10.21031/epod.739548"
    },
    {
      "title": "The cognition-emotion debate: A bit of history",
      "authors": [
        "R Lazarus"
      ],
      "year": 1999,
      "doi": "10.1002/0470013494.ch1"
    },
    {
      "title": "Latent variable models: An introduction to factor, path, and structural equation analysis",
      "authors": [
        "J Loehlin",
        "A Beaujean"
      ],
      "year": 2017
    },
    {
      "title": "Sufficient sample sizes for multilevel modeling",
      "authors": [
        "C Maas",
        "J Hox"
      ],
      "year": 2005,
      "doi": "10.1027/1614-2241.1.3.86"
    },
    {
      "title": "Power analysis and determination of sample size for covariance structure modeling",
      "authors": [
        "R Maccallum",
        "M Browne",
        "H Sugawara"
      ],
      "year": 1996,
      "doi": "10.1037/1082-989x.1.2.130"
    },
    {
      "title": "Bifactor and hierarchical models: Specification, inference, and interpretation",
      "authors": [
        "K Markon"
      ],
      "year": 2019,
      "doi": "10.1146/annurev-clinpsy-050718-095522"
    },
    {
      "title": "Constructs, concepts and the worlds of possibilities: Connecting the measurement, manipulation, and meaning of variables",
      "authors": [
        "K Markus"
      ],
      "year": 2008,
      "doi": "10.1080/15366360802035513"
    },
    {
      "title": "People are variables too: Multilevel structural equation modeling",
      "authors": [
        "P Mehta",
        "M Neale"
      ],
      "year": 2005,
      "doi": "10.1037/1082-989x.10.3.259"
    },
    {
      "title": "Measurement invariance, factor analysis and factorial invariance",
      "authors": [
        "W Meredith"
      ],
      "year": 1993,
      "doi": "10.1007/bf02294825"
    },
    {
      "title": "Power analysis of trials with multilevel data",
      "authors": [
        "M Moerbeek",
        "S Teerenstra"
      ],
      "year": 2016
    },
    {
      "title": "Modern factor analytic techniques: Bifactor models, exploratory structural equation modeling (ESEM), and bifactor-esem",
      "authors": [
        "A Morin",
        "N Myers",
        "S Lee"
      ],
      "year": 2020,
      "doi": "10.1002/9781119568124.ch51"
    },
    {
      "title": "The model size effect in SEM: Inflated goodness-of-fit statistics are due to the size of the covariance matrix",
      "authors": [
        "M Moshagen"
      ],
      "year": 2012,
      "doi": "10.1080/10705511.2012.634724"
    },
    {
      "title": "A practical guide to understanding reliability in studies of within-person variability",
      "authors": [
        "J Nezlek"
      ],
      "year": 2017,
      "doi": "10.1016/j.jrp.2016.06.020"
    },
    {
      "title": "Measurement invariance conventions and reporting: The state of the art and future directions for psychological research",
      "authors": [
        "D Putnick",
        "M Bornstein"
      ],
      "year": 2016,
      "doi": "10.1016/j.dr.2016.06.004"
    },
    {
      "title": "Multilevel and longitudinal modeling using Stata",
      "authors": [
        "S Rabe-Hesketh",
        "A Skrondal"
      ],
      "year": 2005
    },
    {
      "title": "Bayesian model selection in social research",
      "authors": [
        "A Raftery"
      ],
      "year": 1995,
      "doi": "10.2307/271063"
    },
    {
      "title": "The nature of psychological reactance revisited: A meta-analytic review",
      "authors": [
        "S Rains"
      ],
      "year": 2013,
      "doi": "10.1111/j.1468-2958.2012.01443.x"
    },
    {
      "title": "Statistical power and optimal design for multisite randomized trials",
      "authors": [
        "S Raudenbush",
        "X Liu"
      ],
      "year": 2000,
      "doi": "10.1037/1082-989x.5.2.199"
    },
    {
      "title": "Message fatigue to bystander intervention messages: Examining pathways of resistance among college men",
      "authors": [
        "T Reynolds-Tylus",
        "K Lukacena",
        "O Truban"
      ],
      "year": 2020,
      "doi": "10.1080/10410236.2020.1794551"
    },
    {
      "title": "Calculating degrees of freedom for a structural equation model",
      "authors": [
        "E Rigdon"
      ],
      "year": 1994,
      "doi": "10.1080/10705519409539979"
    },
    {
      "title": "Accounting for uncertainty in the measurement of unobservable marketing phenomena",
      "authors": [
        "E Rigdon",
        "M Sarstedt"
      ],
      "year": 2022,
      "doi": "10.1108/s1548-643520220000019003"
    },
    {
      "title": "Communication campaigns",
      "authors": [
        "E Rogers",
        "J Storey"
      ],
      "year": 1987
    },
    {
      "title": "Protection motivation theory",
      "authors": [
        "R Rogers",
        "S Prentice-Dunn"
      ],
      "year": 1997
    },
    {
      "title": "Appraisal processes in emotion: Theory, methods, research",
      "authors": [
        "K Scherer",
        "A Schorr",
        "T Johnstone"
      ],
      "year": 2001,
      "doi": "10.1093/oso/9780195130072.001.0001"
    },
    {
      "title": "When news topics annoy-Exploring issue fatigue and subsequent information avoidance and extended coping strategies",
      "authors": [
        "C Schumann"
      ],
      "year": 2022,
      "doi": "10.3390/journalmedia3030037"
    },
    {
      "title": "Misinformation about COVID-19 vaccines on social media: Rapid review",
      "authors": [
        "B Silva",
        "C Bosancianu",
        "L Littvay",
        "Sage",
        "I Skafle",
        "A Nordahl-Hansen",
        "D Quintana",
        "R Wynn",
        "E Gabarron"
      ],
      "year": 2020,
      "doi": "10.2196/37367%20"
    },
    {
      "title": "Message fatigue: Conceptual definition, operationalization, and correlates",
      "authors": [
        "J So",
        "S Kim",
        "H Cohen"
      ],
      "year": 2017,
      "doi": "10.1080/03637751.2016.1250429"
    },
    {
      "title": "Memory specificity is linked to repetition effects in event-related potentials across the lifespan",
      "authors": [
        "V Sommer",
        "L Mount",
        "S Weigelt",
        "M Werkle-Bergner",
        "M Sander"
      ],
      "year": 2021,
      "doi": "10.1016/j.dcn.2021.100926"
    },
    {
      "title": "Message fatigue beyond the health message context: A replication and further extension of so et al",
      "authors": [
        "H Song",
        "J So"
      ],
      "year": 2017,
      "doi": "10.1093/hcr/hqad021"
    },
    {
      "title": "Two faces of message repetition: Audience favorability as a determinant of the explanatory capacity of processing fluency and message fatigue",
      "authors": [
        "H Song",
        "J So"
      ],
      "year": 2023,
      "doi": "10.1093/joc/jqad025"
    },
    {
      "title": "No more COVID-19 messages via social media, please\": The mediating role of COVID-19 message fatigue between information overload, message avoidance, and behavioral intention",
      "authors": [
        "J Sun",
        "S Lee"
      ],
      "year": 2023,
      "doi": "10.1007/s12144-023-04726-7"
    },
    {
      "title": "Appealing to fear: A meta-analysis of fear appeal effectiveness and theories",
      "authors": [
        "M Tannenbaum",
        "J Hepler",
        "R Zimmerman",
        "L Saul",
        "S Jacobs",
        "K Wilson",
        "D Albarrac\u00edn"
      ],
      "year": 2015,
      "doi": "10.1037/a0039729"
    },
    {
      "title": "Alternative model specifications in structural equation modeling: Facts, fictions, and truth",
      "authors": [
        "R Vandenberg",
        "D Grelle"
      ],
      "year": 2009,
      "doi": "10.4324/9780203867266-15"
    },
    {
      "title": "Defensive reactions to health-promoting information: An overview and implications for future research",
      "authors": [
        "Van 't Riet",
        "R Ruiter"
      ],
      "year": 2013,
      "doi": "10.1080/17437199.2011.606782"
    },
    {
      "title": "Degrees of freedom in planning, running, analyzing, and reporting psychological studies: A checklist to Avoid p-hacking",
      "authors": [
        "J Wicherts",
        "S Veldkamp",
        "C Augusteijn",
        "H Bakker"
      ],
      "year": 2016,
      "doi": "10.3389/fpsyg.2016.01832"
    },
    {
      "title": "The prevalence, features, influencing factors, and solutions for COVID-19 vaccine misinformation: Systematic review",
      "authors": [
        "S Zhao",
        "S Hu",
        "X Zhou",
        "S Song",
        "Q Wang",
        "H Zheng",
        "Y Zhang",
        "Z Hou"
      ],
      "year": 2023,
      "doi": "10.2196/40201"
    }
  ],
  "num_references": 67
}
