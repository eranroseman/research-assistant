{
  "paper_id": "VJLBMKL5",
  "title": "Markov Models in Medical Decision Making: A Practical Guide",
  "abstract": "Markov models are useful when a decision problem involves risk that is continuous over time, when the timing of events is important, and when important events may happen more than once. Representing such clinical settings with conventional decision trees is difficult an abdominal aortic aneurysm, and the risk of mortality in any person, whether sick or healthy. There are two important consequences of events that have ongoing risk. First, the times at which the events will occur are uncertain. This has important implications because the utility of an outcome often depends on when it occurs. For example, a stroke that occurs im- mediately may have a different impact on the patient than one that occurs ten years later. For economic analyses, both costs and utilities are discounted&dquo;,&dquo; such that later events have less impact than earlier ones. The second consequence is that a given event may occur more than once. As the following example shows, representing events that are repetitive or that occur with uncertain timing is difficult using a simple tree model.",
  "year": 1989,
  "date": "1989",
  "authors": [
    {
      "name": "Frank Sonnenberg"
    },
    {
      "name": "J Beck"
    },
    {
      "affiliation": {
        "organization": "Department of Medicine",
        "department": "Department of Medicine",
        "institution": "UMDNJ Robert Wood Johnson Medical School",
        "address": "New Brunswick, New Jersey"
      }
    },
    {
      "affiliation": {
        "organization": "mation Technology Program",
        "department": "mation Technology Program",
        "institution": "Baylor College of Medicine",
        "address": "Houston"
      }
    },
    {
      "affiliation": {
        "organization": "Division of General Internal Medicine",
        "department": "Division of General Internal Medicine",
        "institution": "UMDNJ Robert Wood John- son Medical School",
        "address": "97 Paterson Street, 08903, New Brunswick, NJ"
      }
    }
  ],
  "doi": "10.1177/0272989x8900900209",
  "md5": "39E5691CFAA658D5483BF8F248D53B1D",
  "publication": {
    "journal": "Med Decis Making",
    "journal_inferred": true
  },
  "funding": [
    "",
    ""
  ],
  "sections": [
    {
      "text": "and may require unrealistic simplifying assumptions. Markov models assume that a patient is always in one of a finite number of discrete health states, called Markov states. All events are represented as transitions from one state to another. A Markov model may be evaluated by matrix algebra, as a cohort simulation, or as a Monte Carlo simulation. A newer repre- sentation of Markov models, the Markov-cycle tree, uses a tree representation of clinical events and may be evaluated either as a cohort simulation or as a Monte Carlo simulation.\n\nThe ability of the Markov model to represent repetitive events and the time dependence of both probabilities and utilities allows for more accurate representation of clinical settings that involve these issues. Key words: Markov models; Markov-cycle decision tree; decision mak- ing. (Med Decis Making 1993;13:322-338) A decision tree models the prognosis of a patient sub- sequent to the choice of a management strategy. For example, a strategy involving surgery may model the events of surgical death, surgical complications, and various outcomes of the surgical treatment itself. For practical reasons, the analysis must be restricted to a finite time frame, often referred to as the time horizon of the analysis. This means that, aside from death, the outcomes chosen to be represented by terminal nodes of the tree may not be final outcomes, but may simply represent convenient stopping points for the scope of the analysis. Thus, every tree contains terminal nodes that represent &dquo;subsequent prognosis&dquo; for a particular combination of patient characteristics and events.\n\nThere are various ways in which a decision analyst can assign values to these terminal nodes of the de- cision tree. In some cases the outcome measure is a crude life expectancy; in others it is a quality-adjusted life expectancy.' One method for estimating life ex- pectancy is the declining exponential approximation of life expectancy (DEALE),2 which calculates a patientspecific mortality rate for a given combination of pa- tient characteristics and comorbid diseases. Life expectancies may also be obtained from Gompertz models of survival' or from standard life tables.' This paper explores another method for estimating life expec- tancy, the Markov model.\n\nIn 1983, Beck and Pauker described the use of Mar- kov models for determining prognosis in medical ap- plications.' Since that introduction, Markov models have been applied with increasing frequency in pub- lished decision analyses.'-9 Microcomputer software has been developed to permit constructing and eval- uating Markov models more easily. For these reasons, a revisit of the Markov model is timely. This paper serves both as a review of the theory behind the Mar- kov model of prognosis and as a practical guide for the construction of Markov models using microcom- puter decision-analytic software.\n\nMarkov models are particularly useful when a de- cision problem involves a risk that is ongoing over time. Some clinical examples are the risk of hemorrhage while on anticoagulant therapy, the risk of rupture of A Specific Example Consider a patient who has a prosthetic heart valve and is receiving anticoagulant therapy. Such a patient may have an embolic or hemorrhagic event at any time. Either kind of event causes morbidity (short-term and/ or chronic) and may result in the patient's death. The decision tree fragment in figure  1  shows one way of representing the prognosis for such a patient. The first chance node, labelled ANTICOAG, has three branches, labelled BLEED, EMBOLUS, and NO EVENT. Both BLEED and EMBOLUS may be either FATAL or NON-FATAL. If NO EVENT occurs, the patient remains  WELL. There are several shortcomings with this model. First, the model does not specify when events occur. Sec- ond, the structure implies that either hemorrhage or embolus may occur only once. In fact, either may oc- cur more than once. Finally, at the terminal nodes labelled POST EMBOLUS, POST BLEED, and WELL, the analyst still is faced with the problem of assigning utilities, a task equivalent to specifying the prognosis for each of these non-fatal outcomes.\n\nThe first problem, specifying when events occur, may be addressed by using the tree structure in figure  1  and making the assumption that either BLEED or EMBOLUS occurs at the average time consistent with the known rate of each complication. For example, if the rate of hemorrhage is a constant 0.05 per person per year, then the average time before the occurrence of a hemorrhage is 1/0.05 or 20 years. Thus, the event of having a fatal hemorrhage will be associated with a utility of 20 years of normal-quality survival. However, the patient's normal life expectancy may be less than  20  years. Thus, the occurrence of a stroke would have the paradoxical effect of improving the patient's life expectancy. Other approaches, such as assuming that the stroke occurs halfway through the patient's nor- mal life expectancy, are arbitrary and may lessen the fidelity of the analysis.\n\nBoth the timing of events and the representation of events that may occur more than once can be ad- dressed by using a recursive decision tree.12 In a re- cursive tree, some nodes have branches that have ap- peared previously in the tree. Each repetition of the tree structure represents a convenient length of time and any event may be considered repeatedly. A re- cursive tree that models the anticoagulation problem is depicted in figure  2 .\n\nHere, the nodes representing the previous terminal nodes POST-BLEED, POST-EMBOLUS, and No EVENT are re- placed by the chance node ANTICOAG, which appeared previously at the root of the tree. Each occurrence of BLEED or EMBOLUS represents a distinct time period, so the recursive model can represent when events occur.\n\nHowever, despite this relatively simple model and car- rying out the recursion for only two time periods, the tree in figure  2  is &dquo;bushy,&dquo; with 17 terminal branches.\n\nIf each level of recursion represents one year, then carrying out this analysis for even five years would result in a tree with hundreds of terminal branches.\n\nThus, a recursive model is tractable only for a very short time horizon."
    },
    {
      "title": "The Markov Model",
      "text": "The Markov model provides a far more convenient way of modelling prognosis for clinical problems with ongoing risk. The model assumes that the patient is always in one of a finite number of states of health referred to as Markov states. All events of interest are modelled as transitions from one state to another. Each state is assigned a utility, and the contribution of this utility to the overall prognosis depends on the length of time spent in the state. In our example of a patient with a prosthetic heart valve, these states are WELL, DISABLED, and DEAD. For the sake of simplicity in this example, we assume that either a bleed or a non-fatal embolus will result in the same state (DISABLED) and that the disability is permanent.\n\nThe time horizon of the analysis is divided into equal increments of time, referred to as Markov cycles. Dur- ing each cycle, the patient may make a transition from one state to another. Figure  3  shows a commonly used representation of Markov processes, called a state- transition diagram, in which each state is represented by a circle. Arrows connecting two different states in- dicate allowed transitions. Arrows leading from a state to itself indicate that the patient may remain in that state in consecutive cycles. Only certain transitions are allowed. For example, a person in the WELL state may make a transition to the DISABLED state, but a transition from DISABLED to WELL is not allowed. A per- son in either the WELL state or the DISABLED state may die and thus make a transition to the DEAD state. How- ever, a person who is in the DEAD state, obviously, cannot make a transition to any other state. Therefore, a single arrow emanates from the DEAD state, leading back to itself. It is assumed that a patient in a given state can make only a single state transition during a cycle. The length of the cycle is chosen to represent a clinically meaningful time interval. For a model that spans the entire life history of a patient and relatively rare events the cycle length can be one year. On the other hand, if the time frame is shorter and models events that may occur much more frequently, the cycle time must be shorter, for example monthly or even weekly. The cycle time also must be shorter if a rate changes rapidly over time. An example is the risk of perioperative myocardial infarction (MI) following previous MI that declines to a stable value over six months.&dquo;\n\nThe rapidity of this change in risk dictates a monthly cycle time. Often the choice of a cycle time will be determined by the available probability data. For ex- ample, if only yearly probabilities are available, there is little advantage to using a monthly cycle length."
    },
    {
      "title": "INCREMENTAL UTILITY",
      "text": "Evaluation of a Markov process yields the average number of cycles (or analogously, the average amount of time) spent in each state. Seen another way, the patient is &dquo;given credit&dquo; for the time spent in each state. If the only attribute of interest is duration of survival, then one need only add together the average times spent in the individual states to arrive at an expected survival for the process. where ts is the time spent in state s.\n\nUsually, however, the quality of survival is consid- ered important. Each state is associated with a quality factor representing the quality of life in that state rel- ative to perfect health. The utility that is associated with spending one cycle in a particular state is referred to as the incremental utility. Consider the Markov process depicted in figure  3 . If the incremental utility of the DISABLED state is 0.7, then spending the cycle in the DISABLED state contributes 0.7 quality-adjusted cycles to the expected utility. Utility accrued for the entire Markov process is the total number of cycles spent in each state, each multiplied by the incremental utility for that state. Let us assume that the DEAD state has an incremental utility of zero,* and that the WELL state has an in- cremental utility of 1.0. This means that for every cycle spent in the WELL state the patient is credited with a quantity of utility equal to the duration of a single Markov cycle. If the patient spends, on average,  2.5  cycles in the WELL state and 1.25 cycles in the DISABLED state before entering the DEAD state, the utility assigned would be (2.5 X 1) + (1.25 X 0.7), or 3.9 quality-adjusted cycles. This number is the quality-adjusted life expectancy of the patient. * For medical examples, the incremental utility of the absorbing DEAD state must be zero, because the patient will spend an infinite amount of time in the DEAD state and if the incremental utility were non-zero, the net utility for the Markov process would be infinite.\n\nWhen performing cost-effectiveness analyses, a separate incremental utility may be specified for each state, representing the financial cost of being in that state for one cycle. The model is evaluated separately for cost and survival. Cost-effectiveness ratios are cal- culated as for a standard decision tree.10,11 TYPES OF MARKOV PROCESSES Markov processes are categorized according to whether the state-transition probabilities are constant over time or not. In the most general type of Markov process, the transition probabilities may change over time. For example, the transition probability for the transition from WELL to DEAD consists of two compo- nents. The first component is the probability of dying from unrelated causes. In general, this probability changes over time because, as the patient gets older, the probability of dying from unrelated causes will increase continuously. The second component is the probability of suffering a fatal hemorrhage or embolus during the cycle. This may or may not be constant over time.\n\nA special type of Markov process in which the tran- sition probabilities are constant over time is called a Markov chain. If it has an absorbing state, its behavior over time can be determined as an exact solution by simple matrix algebra, as discussed below. The DEALE can be used to derive the constant mortality rates needed to implement a Markov chain. However, the availability of specialized software to evaluate Markov processes and the greater accuracy afforded by agespecific mortality rates have resulted in greater reli- ance on Markov processes with time-variant probabilities.\n\nThe net probability of making a transition from one state to another during a single cycle is called a tran- sition probability. The Markov process is completely defined by the probability distribution among the starting states and the probabilities for the individual allowed transitions. For a Markov model of n states, there will be n2 transition probabilities. When these probabilities are constant with respect to time, they can be represented by an n x n matrix, as shown in table 1. Probabilities representing disallowed transi- tions will, of course, be zero. This matrix, called the P matrix, forms the basis for the fundamental matrix solution of Markov chains described in detail by  Beck  and Pauker.' TaMe 1 . P Matrix"
    },
    {
      "title": "THE MARKOV PROPERTY",
      "text": "The model illustrated in figure  3  is compatible with a number of different models collectively referred to as finite stochastic processes. In order for this model to represent a Markov process, one additional restric- tion applies. This restriction, sometimes referred to as the Markovian assumption' or the Markov property) 14 specifies that the behavior of the process subsequent to any cycle depends only on its description in that cycle. That is, the process has no memory for earlier cycles. Thus, in our example, if someone is in the DISABLED state after cycle n, we know the probability that he or she will end up in the DEAD state after cycle n + 1. It does not matter how much time the person spent in the WELL state before becoming DISABLED. Put another way, all patients in the DISABLED state have the same prognosis regardless of their previous histories.\n\nFor this reason, a separate state must be created for each subset of the cohort that has a distinct utility or prognosis. If we want to assign someone disabled from a bleed a different utility or risk of death than someone disabled from an embolus, we must create two dis- abled states. The Markovian assumption is not fol- lowed strictly in medical problems. However, the as- sumption is necessary in order to model prognosis with a finite number of states."
    },
    {
      "title": "MARKOV STATES",
      "text": "In order for a Markov process to terminate, it must have at least one state that the patient cannot leave. Such states are called absorbing states because, after a sufficient number of cycles have passed, the entire cohort will have been absorbed by those states. In medical examples the absorbing states must represent death because it is the only state a patient cannot leave. There is usually no need for more than one DEAD state, because the incremental utility for the DEAD state is zero. However, if one wishes to keep track of the causes of death, then more than one DEAD state may be used.\n\nTemporary states are required whenever there is an event that has only short-term effects. Such states are defined by having transitions only to other states and not to themselves. This guarantees that the patient can spend, at most, one cycle in that state. Figure  4  illustrates a Markov process that is the same as that shown in figure  3  except that a temporary state has been added, labeled STROKE. An arrow leads to STROKE only from the WELL state, and there is no arrow from the STROKE back to itself. This ensures that a patient may spend no more than a single cycle in the STROKE state. Temporary states have two uses. The first use is to apply a utility or cost adjustment specific to the temporary state for a single cycle. The second use is to assign temporarily different transition probabilities. For example, the probability of death may be higher in the STROKE state than in either the WELL state or the DISABLED state.\n\nA special arrangement of temporary states consists of an array of temporary states arranged so that each has a transition only to the next. These states are called tunnel states because they can be visited only in a fixed sequence, analogous to passing through a tunnel. The purpose of an array of tunnel states is to apply to incremental utility or to transition probabilities a tem- porary adjustment that lasts more than one cycle.\n\nAn example of tunnel states is depicted in figure  5 .\n\nThe three tunnel states, shaded and labelled POST Mil through POST M13, represent the first three months fol- lowing an MI. The POST Mil state is associated with the highest risk of perioperative death. POST MI2 and POST M13 are associated with successively lower risks of per- ioperative death. If a patient passes through all three tunnel states without having surgery, he or she enters the POST Mi state, in which the risk of perioperative death is constant.\n\nBecause of the Markovian assumption, it is not pos- sible for the prognosis of a patient in a given state to depend on events prior to arriving in that state. Often, however, patients in a given state, for example WELL, may actually have different prognoses depending on previous events. For example, consider a patient who is WELL but has a history of gallstones. Each cycle, the patient has a certain probability of developing com- plications from the gallstones. Following a cholecystectomy, the patient will again be WELL but no longer has the same probability of developing biliary com- plications. Thus, the state WELL actually contains two distinct populations of people, those with gallstones and those who have had a cholecystectomy. In order for the model to reflect the different prognoses for these two classes of well patients, it must contain two distinct well states, one representing WELL WITH GALL- STONES and the other representing WELL, STATUS-POST FIGURE 5. Tunnel states: the three shaded circles represent tem- porary states that can be visited only in a fixed sequence.\n\nCHOLECYSTECTOMY. In general, if prognosis depends in any way on past history, it requires that there be one distinct state to represent the different histories."
    },
    {
      "title": "USE OF THE MARKOV PROCESS IN"
    },
    {
      "title": "DECISION ANALYSIS",
      "text": "The Markov process models prognosis for a given patient and thus is analogous to a utility in an ordinaiy decision tree. For example, if we are trying to choose between surgeiy and medical therapy, we may con- struct a decision tree like that shown in figure 6A. In this case, events of interest, such as operative death and cure, are modelled by tree structure &dquo;outside&dquo; the Markov process. The Markov process is being used simply to calculate survival for a terminal node of the tree. This structure is inefficient, because it requires that an entire Markov process be run for each terminal node, of which there may be dozens or even hundreds. A far more efficient structure is shown in figure 6B. In this case, the Markov process incorporates all events of interest and the decision analysis is reduced simply to comparing the values of two Markov processes. The use of the cycle tree representation (discussed in detail below) permits representing all relevant events within the Markov process.\n\n1#nufllati'is of Markov Models THE FUNDAMENTAL MATRIX SOLUTION When the Markov process has constant transition probabilities (and constant incremental utilities) for all states, the expected utility may be calculated by matrix algebra to yield the fundamental matrix, which shows, for each starting state, the expected length of time spent in the state. The matrix solution is fast and provides an &dquo;exact&dquo; solution that is not affected by the cycle length. There are three main disadvantages of the matrix formation. The first is the difficulty in performing matrix inversion. However, this is less of a problem than when Beck and Pauker' described the technique, because many commonly available micro- computer spreadsheet programs now perform matrix algebra. The second disadvantage is the restriction to constant transition probabilities. The third disadvan- tage is the need to represent all the possible ways of making a transition from one state to another as a single transition probability. At least for medical ap- plications, the matrix algebra solution has been largely relegated to the history books. For more details of the matrix algebra solution the reader is referred to Beck and Pauker.'    (middle)  shows the distribution partway through the simulation. Panel C (bottom) shows the final distribution, with the entire cohort in the DEAD state."
    },
    {
      "title": "MARKOV COHORT SIMULATION",
      "text": "The Markov cohort simulation is the most intuitive representation of a Markov process. The difference between a cohort simulation and the matrix formulation may be thought of as analogous to the difference between determining the area under a curve by divid- ing it into blocks and summing their areas versus cal- culating the area by solving the integral of the function describing the curve. The simulation considers a hypothetical cohort of patients beginning the process with some distribution among the starting states. Con- sider again the prognosis of a patient who has a pros- thetic heart valve, represented by the Markov-state dia- gram in figure  3 . Figure  7A  illustrates the cohort at the beginning of the simulation. In this example, all pa- tients are in the WELL state. However, it is not necessary to have all patients in the same state at the beginning of the simulation. For example, if the strategy represents surgery, a fraction of the cohort may begin the simulation in the DEAD state as a result of operative mortality.\n\nThe simulation is &dquo;run&dquo; as follows. For each cycle, the fraction of the cohort initially in each state is par- titioned among all states according to the transition probabilities specified by the P matrix. This results in a new distribution of the cohort among the various states for the subsequent cycle. The utility accrued for the cycle is referred to as the cycle sum and is cal- culated by the formula:\n\nwhere n is the number of states, fs is the fraction of the cohort in state s, and U, is the incremental utility of state s. The cycle sum is added to a running total that is referred to as the cumulative utility. Figure  7B  shows the distribution of the cohort after a few cycles.\n\nFifty percent of the cohort remains in the WELL state. Thirty percent of the cohort is in the SICK state and 20% in the DEAD state. The simulation is run for enough cycles so that the entire cohort is in the DEAD state (fig. 7C ).\n\nThe cohort simulation can be represented in tabular form, as shown in table  2 . This method may be im- plemented easily using a microcomputer spreadsheet program. The first row of the table represents the start- ing distribution. A hypothetical cohort of 10,000 pa- tients begins in the WELL state. The second row shows the distribution at the end of the first cycle. In ac- cordance with the transition probabilities specified in the P-matrix (table  1 ), 2,000 patients (20% of the original cohort) have moved to the DISABLED state and another 2,000 patients to the DEAD state. This leaves 6,000  (60%)  remaining in the WELL state. This process is repeated in subsequent cycles. The fifth column in table  2  shows the calculation of the cycle sum, which is the sum of the number of cohort members in each state multiplied by the incremental utility for that state. For ex- ample, because the incremental utility of the DISABLED state is 0.7, the cycle sum during cycle 1 is equal to (6,000 X 1) + (2,000 X 0.7) = 7,400. The DEAD state does not contribute to the cycle sum because its in- Table  2  . Markov Cohort Simulation cremental utility is zero. The sixth column shows the ' cumulative utility following each cycle.\n\nBecause the probabilities of leaving the WELL and DEAD states are finite and the probability of leaving the DEAD sate is zero, more and more of the cohort ends up in the DEAD state. The fraction of the cohort in the DEAD state actually is always less than 100% because, during each cycle, there is a finite probability of a patient's remaining alive. For this reason, the simu- lation is stopped when the cycle sum falls below some arbitrarily small threshold (e.g., 1 person-cycle) or when the fraction of the cohort remaining alive falls below a certain amount. In this case, the cycle sum falls below 1 after 24 cycles. The expected utility for this Markov cohort simulation is equal to the cumulative utility when the cohort has been completely absorbed divided by the original size of the cohort. In this case, the expected utility is 23,752/10,000, or 2.3752 qualityadjusted cycles. The unadjusted life expectancy may be found by summing the entries in the columns for the WELL and DISABLED states and dividing by the cohort size. Notice that the cohort memberships at the start do not contribute to these sums. Thus, the cohort members will spend, on average, 1.5 cycles in the WELL state and 1.25 cycles in the DISABLED state, for a net unadjusted life expectancy of 2.75 cycles."
    },
    {
      "title": "THE HALF-CYCLE CORRECTION",
      "text": "The Markov model assumes that during a single cycle, each patient undergoes no more than one state transition. One way to visualize the Markov process is to imagine that a clock makes one &dquo;tick&dquo; for each cycle length. At each tick, the distribution of states is ad- justed to reflect the transitions made during the preceding cycle. The Markov cohort simulation requires explicit bookkeeping (as illustrated in table 2) during each cycle to give credit according to the fraction of the cohort in each state. In the example illustrated in table 2, the bookkeeping was performed at the end of each cycle.\n\nIn reality, transitions occur not only at the clock ticks, but continuously throughout each cycle. There- fore, counting the membership only at the beginning or at the end of the cycle will lead to errors. The process of carrying out a Markov simulation is anal- ogous to calculating expected survival that is equal to the area under a survival curve. Figure  8  shows a sur- vival curve for members of a state. The smoothness of the curve reflects the continuous nature of state transitions. Each rectangle under the curve represents the accounting of the cohort membership during one cycle when the count is performed at the end of each cycle. The area of the rectangles consistently underestimates the area under the curve. Counting at the beginning of each cycle, as in figure  9 , consistently overestimates survival. To more accurately reflect the continuous nature of the state transitions, we make the assump- FIGURE 8. Counting cohort membership at the end of each cycle. FIGURE 9.  Counting cohort membership at the beginning of each cycle. tion that state transitions occur, on average, hayway through each cycle. There is no way to determine the state membership in the middle of the cycle. However, if we consider the count at the end of each cycle to be in the middle of a cycle that begins halfway through the previous cycle and ends halfway through the sub- sequent cycle, as in figure  10 , then the under-and overestimations will be balanced. This is equivalent to shifting all cycles one half cycle to the right. We must then add a half cycle for the starting membership at the beginning to compensate for this shift to the right. Adding a half cycle for the example in table 2 results in an expected utility of 2.875 quality-adjusted cycles and a life expectancy of  3.25  cycles.\n\nThe shift to the right makes no difference at the end of the simulation if the cohort is completely absorbed because the state membership at that time is infini- tesimal. However, if the simulation is terminated prior to the absorption of the cohort, the shift to the right will result in overestimation of the expected survival.\n\nTherefore, for simulations that terminate prior to ab- sorption, an additional correction must be made by subtracting a half cycle for members of the state who are still alive at the end of the simulation. The importance of the half cycle correction depends on cycle length. If the cycle length is veiy short relative to av- erage survival, the difference between actual survival and simulated survival (as shown in figure  8 ) will be small. If the cycle time is larger relative to suivival, the difference will be more significant. The interested reader should note that the fundamental matrix represen- tation is equivalent to counting state membership at the beginning of each cycle. Therefore) the correction that should be applied to the result of a matrix solution is subtraction of one half cycle from the membership of each starting state."
    },
    {
      "title": "THE MARKOV-CYCLE TREE",
      "text": "In the preceding discussion, transition probabilities were provided as if they were elemental data supplied with a problem. However, for actual clinical settings, transition probabilities may be quite complicated to calculate because transitions from one state to another may happen in a variety of ways. For example, a patient in the WELL state may make a transition to the DEAD state by having a fatal stroke, by having an accident, or by dying of complications of a coexisting disease. Each transition probability must take into account all of these transition paths. Hollenberg15 devised an el- egant representation of Markov processes in which the possible events taking place during each cycle are rep- resented by a probability tree.\n\nThe probability tree corresponding to the WELL state is illustrated in figure  11 . It contains a chance node modeling the occurrence of death from age, sex, and race (ASR)-specific mortality, the branch labelled DIE ASR. If the patient does not die from natural causes, the branch labelled SURVIVE leads to a chance node modelling whether the patient has a BLEED or an EM- BOLUS, either of which may be fatal. If neither BLEED nor EMBOLUS occurs (the branch NO EVENT), the patient remains WELL. Each terminal node in the probability tree is labelled with the name of the state in which a patient reaching that terminal node will begin the next cycle. Thus, a patient reaching any terminal node la- belled DEAD will begin the next cycle in the DEAD state.\n\nA patient surviving either an embolus or a bleed will begin the next cycle in the DISABLED state. The probability tree for patients beginning in the DISABLED state is identical to that for the WELL state, except that patients having NO EVENT will still be DISABLED. The probability tree for patients beginning in the DEAD state consists only of the terminal node labelled with the name of the DEAD state since no event is possible, and a patient in the DEAD state will always remain in that state.\n\nThe subtrees are attached to a special type of node designated a Markov node as depicted in figure  12. There is one branch of the Markov node for each Mar- kov state. Each probability from the Markov node to one of its branches is equal to the probability that the patient will start in the corresponding state. The Mar- kov node together with its attached subtrees is referred to as a Markov-cycle tree15 and, along with the incre- mental utilities and the probabilities of the branches of chance nodes, is a complete representation of a Markov process. Starting at any state branch, the sum of the probabilities of all paths leading to terminal nodes labelled with the name of a particular ending state is equal to the transition probability from the beginning state to the ending state. For example, the highlighted paths in figure  12  show all transitions from WELL to DISABLED."
    },
    {
      "title": "EVALUATING CYCLE TREES",
      "text": "A cycle tree may be evaluated as a Markov cohort simulation. First, the starting composition of the co- hort is determined by partitioning the cohort among the states according to the probabilities leading from the Markov node to the individual branches. Each sub- tree is then traced from its root to its termini (&dquo;folding forward&dquo;), partitioning the subcohort for the corre- sponding state according to the probability tree. The result is a new distribution of the cohort among the states, which reflects how the cohort appears after a single cycle. The fraction of the cohort currently in each state is then credited with the appropriate in- cremental utility to form the cycle sum, which is added to the cumulative utility. The new distribution of the cohort is then used as the starting distribution for the next cycle. The process is repeated until some pre- determined criterion is reached, usually when the quantity of utility accumulating for each state drops below some specified small quantity. This occurs when the fraction of the cohort in the DEAD state approaches one."
    },
    {
      "title": "ADVANTAGES OF THE CYCLE TREE REPRESENTATION",
      "text": "Cycle trees have many of the same advantages that decision trees have for modelling complex clinical sit- uations. They allow the analyst to break up a large problem into smaller, more manageable ones. This clarifies issues for the analyst and for others trying to understand the results. The use of subtrees promotes appropriate symmetiy among the various states, thus enhancing the fidelity of the model. The model pro- vides a great deal of flexibility when changing or re- fining a Markov model. If a single component probability or a detail of a subtree needs to be changed, this can be done without recalculating the aggregate tran- sition probabilities. Finally, the disaggregation of tran- sition probabilities permits sensitivity analysis to be performed on any component probability. Because of its advantages, the cycle tree representation has been used most often in recently published Markov deci- sion analyses.'-'"
    },
    {
      "title": "MONTE CARLO SIMULATION",
      "text": "As an alternative to simulating the prognosis of a hypothetical cohort of patients, the Monte Carlo sim- ulation determines the prognoses of a large number of individual patients. This is illustrated in figure  13. Each patient begins in the starting state (i.e., the WELL state), and at the end of each cycle, a random-number generator is used together with the transition probabilities to determine in which state the patient will begin the next cycle. Just as for the cohort simulation, the patient is given credit for each cycle spent in a FIGURE 12. Complete Markov-cycle tree corresponding to the an- ticoagulation problem.\n\nnon-DEAD state and each state may be adjusted for quality of life. When the patient enters the DEAD state, the simulation is stopped. For the example in figure  13 , the patient spends two cycles in the WELL state and three cycles in the DISABLED state before being &dquo;ab- sorbed,&dquo; resulting in a utility of (2 X 1) + (3 X 0.7) or 4.1 quality-adjusted cycles. The process is repeated a very large number (on the order of 104) of times. Each trial generates a quality-adjusted survival time. After a large number of trials, these constitute a distribution of survival values. The mean value of this distribution will be similar to the expected utility obtained by a cohort simulation. However, in addition to the mean survival, statistical measures such as variance and standard deviation of the expected utility may be de- termined from this distribution. It should be noted that a Markov cycle tree may be evaluated as a Monte Carlo simulation."
    },
    {
      "title": "COMPARING THE DIFFERENT REPRESENTATIONS",
      "text": "Each representation has specific advantages and disadvantages for particular purposes. The simula- tions (Markov cohort, Monte Carlo, and cycle tree) per- mit the analyst to specify transition probabilities and incremental utilities that vary with time. Such variation is necessary to model certain clinical realities, such as the increase in baseline mortality rate with age. A dis- advantage common to all simulations (cohort, cycle tree, and Monte Carlo) is the necessity for repetitive and time-consuming calculations. However, the avail- ability of specialized microcomputer software to perform these simulations has made this much less of an issue. The fundamental matrix solution is very fast because it involves only matrix algebra and provides an &dquo;exact&dquo; solution that is not sensitive to cycle time (as in the cohort simulation) or number of trials (as in the Monte Carlo simulation). The major disadvantages of the matrix formulation are the restriction to problems with constant transition probabilities, the need to express each composite transition probability as a single number, and the difficulty of performing matrix algebra. The matrix manipulations required for a Mar- kov process with a large number of states may require special computational resources. The Monte Carlo method and the matrix solutions provide measures of variability, if these are desired. Such measures are not possible with a cohort simulation. The features of the three representations are summarized in table  3 ."
    },
    {
      "title": "Tpmsiflon Probabilides CONVERSION OF RATES TO PROBABILITIES",
      "text": "The tendency of a patient to make a transition from one state to another is described by the rate of tran- sition. The rate describes the number of occurrences of an event (such as death) for a given number of patients per unit of time and is analogous to an in- stantaneous velocity. Rates range from zero to infinity. A probability, on the other hand, describes the like- lihood that an event will occur in a given length of time. Probabilities range from zero to 1. Rates may be converted to probabilities if their proper relationship is considered.\n\nThe probability of an event that occurs at a constant rate (r) in a specified time (t) is given by the equation:\n\nThis equation can be easily understood by examining the survival curve for a process defined by a constant rate. The equation describing this survival curve is: where f is the fraction surviving at time t and r is the constant transition rate. At any given time, the fraction Table  3 9   that has experienced the event is equal to 1 -f. Thus, the curve describing the probability that the event will occur in time t is simply 1 -f, or 1 -e -rt as shown in equation 1. The probability of transition in time t is always less than the corresponding rate per time t because as the cohort members die, fewer are at risk for the transition later in the time period. When the rate is small or t is short, the rate and probability are very similar. Often, data supplied for an analysis provide rates of complications. For use in a Markov anal- ysis, these rates must be converted to the corresponding transition probabilities by substituting the Markov- cycle length for t in equation 1."
    },
    {
      "title": "PRECAUTIONS IN CHANGING THE CYCLE LENGTH",
      "text": "When changing the Markov-cycle duration from yearly to monthly, one cannot simply divide the calculated transition probabilities by 12 to arrive at the appropriate transition probabilities for the shorter cycle. If the original rate is a yearly rate, then the monthly probability is p = 1 -e -r/12. If one has only the yearly transition probability and not the rate, the transition probability can be converted to a rate by solving equation 2 for r: Then, the calculated rate is used, as above, to recal- culate the transition probability."
    },
    {
      "title": "TIME DEPENDENCE OF PROBABILITIES",
      "text": "In the most general case, the transition probabilities in a Markov model vary with time. An obvious example is the probability of death, which increases as the co- hort ages. If the time horizon for the analysis is a long one, the mortality rate will increase significantly dur- ing later cycles. There are two ways of handling such changing probabilities. One is with a continuous func- tion, such as the Gompertz function.3 For each clock cycle, the appropriate mortality rate is calculated from a formula and converted to a transition probability. Some rates are not easily described as a simple func- tion. One example is the actual mortality rate over a lifetime, which initially is high during early childhood, falls to a minimum during late childhood, and then gradually increases during adulthood. Another ex- ample is the risk of acquiring a disease (such as Hodgkins' disease) that has a bimodal age distribution. In such cases, the necessary rates (or corresponding probabilities) may be stored in a table, indexed by cycle number, and retrieved as the Markov model is eval- uated. Some computer software used for evaluating Markov processes provides facilities for constructing and using such tables. DISCOUNTING: TIME DEPENDENCE OF UTILITIES Incremental utilities, like transition probabilities, may vary with time. One important application of this time dependence is the discounting used in cost-effec- tiveness analyses.'\u00b0 This is based on the fact that costs or benefits occurring immediately are valued more highly than those occurring in the future. The dis- counting formula is:\n\nwhere Ut is the increment utility at time t, Uo is the initial incremental utility, and d is the discount rate.10 Because of the time variance, discounting cannot be used when the fundamental matrix solution is used."
    },
    {
      "title": "A Med Example",
      "text": "The following example is a Markov implementation of a decision analysis that has been published in detail elsewhere as an ordinary decision tree.l6,'; This anal- ysis was performed for an actual patient at the New England Medical Center. The implementation of the model is a Markov-cycle tree as used by two specific decision analysis microcomputer programs Decision Maker1s and SMLTREE.'9\n\nCase history. A 42-year-old man had had a cadaveric kidney transplant  18  months previously and had done well except for an early rejection episode, which had been treated successfully. He had maintained normal kidney function. While he was receiving standard treatment with azathioprine and prednisone, how- ever, two synchronous malignant melanomas ap- peared and required wide resection. Continuation of immunosuppressive therapy increases the chance of another, possibly lethal melanoma. Cessation of this therapy ensures that the patient's kidney will be re- jected and will require his return to dialysis, a ther- apeutic modality he prefers to avoid.\n\nThe key assumptions in the construction of this model are:\n\n1. If therapy is stopped, the patient will reject the kidney immediately.\n\n2. If therapy is continued, the patient still may reject the kidney, but with a lower probability.\n\n3. If the patient rejects the kidney despite contin- uation of therapy, the therapy will be stopped at the time the rejection occurs.\n\n4. A second transplant will not be considered.\n\n5. Quality of life is lower on dialysis than with a functioning transplant. Based on the original util- ity assessment from the patient, the utility of life on dialysis was 0.7 and that of life with a func- tioning transplant 1.0&dquo;6 FIGURE 14. Simple decision tree for the kid- ney transplant, melanoma case.\n\n6. No adjustment is made to quality of life for having recurrent melanoma.\n\n7. The patient's life expectancy is reduced because of having had a renal transplant and a previous melanoma. It will be further reduced if the patient goes on dialysis or if melanoma recurs.\n\nThe simple tree modeling this problem is shown in figure  14 . There are two branches of the decision node, representing CONTINUE and STOP therapy, respectively.\n\nIn the case of CONTINUE) a chance node models the occurrence of REJECT or NO REJECT. The development of a new melanoma is modelled by the chance node with the branches MELANOMA and No MELANOMA. Terminal nodes represent the six possible combinations of therapy, renal status, and occurrence of a new mel- anoma. The two combinations representing sTOY Trrrr~- APY and NO REJECT are assumed not to occur. Probabilities in this model must be assigned to reflect the different risks of developing a new melanoma de- pending on whether or not therapy has been contin- ued. The lowest probability is for patients whose ther- apy is stopped immediately. The highest probability is for those whose therapy is continued indefinitely. Because therapy will be stopped, patients who ex- perience rejection after an initial period of continuing therapy will have an intermediate risk of melanoma recurrence.\n\nBecause it was a simple tree, the original model required several simplifying assumptions. The first was that recurrent melanoma occurred at a fixed time in the future (one year)16 although, in reality, it may occur at any time. The second was that transplant rejection occurred at a fixed time, the midpoint of the patient's life expectancy. Therefore, the utility of continuing therapy, then experiencing transplant rejection was assigned the average of the utilities for transplant and dialysis. If the patient values time on dialysis differ- ently now compared with later, this is an oversimpli- fication. The third assumption was that the probability of melanoma recurrence in this intermediate scenario was the average of the high and low probabilities. Again, this is an oversimplification because the patient ac- tually has a high probability while on the therapy and a low probability while off it. The Markov model can address all of these issues.\n\n'I'he Markov decision model is shown in figure  15  and figure  16 . 'I'he root of the tree in figure  15  is a decision node with two branches representing the two choices CONTINUE and sTOP. The Markov-cycle tree de- picted in figure  16  consists of a Markov node with one branch for each Markov state. If we assume that the utility of a state depends only on whether the patient is on dialysis or not and that the probability of mel- anoma depends only on whether or not the patient is receiving immunosuppressive therapy, then only five states are required to represent the scenario. These are (from top to bottom) TRANSWEL (transplant well), TRANSMEL (transplant with melanoma), DIALWELL (di- alysis, no melanoma), DIALMEL (dialysis and mela- noma), and DEAD. Separate states are not needed based on treatment because it is assumed that patients in the transplant states are on immunosuppressive ther- apy and those in the dialysis states are not."
    },
    {
      "title": "INITIAL PROBABILITIES",
      "text": "The first task is to assign probabilities to the branches of the Markov node. Recall that these probabilities represent the probabilities of starting in the individual states. For the CONTINUE strategy, all patients begin in the TRANSWEL state, so the probability of that state should be 1. Similarly, for the STOP strategy, all patients begin in the oraLwELL state. We can implement these as- sumptions by assigning the probabilities of the TRANSWEL and DIALWELL branches as variables. A bind- ing set between the strategy branch and the Markov node can set the appropriate variable to 1. Thus, the same Markov-cycle tree can be used as a subtree&dquo; to represent the prognosis for both strategies.\n\nSUBSEQUENT PROGNOSIS Each branch of the Markov node is attached to a subtree that models the possible events for each Mar- kov state. The most complex is for the TRANSWEL state, shown at the top of figure  16 . The first event modelled is the chance of dying from all causes (the branch Die). Die leads to a terminal node. In this case the utility is DEAD, because a patient who dies during one cycle will begin the next cycle in the DEAD state. For patients who do not die (the branch Survive), the next chance node models the chance of transplant rejection (the branches Reject and NoReject). Subsequent to each of these branches is a chance node modelling the risk of recurrent melanoma (the branches Recur and NoRecur and Recur2 and NoRecur2). Each of these branches leads to a terminal node. For Recur following Reject, the appropriate state is DIALMEL, for Recur2 fol- lowing NoReject the appropriate sate is TRANSMEL. For NoRecur following Reject and NoRecur2 following NoReject, the appropriate states are DIALWELL and TRANSWEL, respectively. Only the latter branch represents a return to the starting state.\n\nThe event tree for the TRANSMEL state is also shown in figure  16 . It is simpler than that for TRANSWEL be- cause the risk of melanoma recurrence need not be modeled. Assignment of terminal states is similar to that for the TRANSWEL state except that patients may not make a transition to the TRANSWEL or DIALWELL state.\n\nSimilarly, the probability tree for the DIALWELL state models only the risks of death and of melanoma re- currence and that for the DIALMEL state models only the risk of death. The event tree for the DEAD state is simply a terminal node assigned to the state DEAD, since no event is possible and all patients return to the DEAD state in the subsequent cycle."
    },
    {
      "title": "CHOICE OF CYCLE LENGTH",
      "text": "Before the probabilities can be assigned, the analyst must decide on the cycle length. The cycle length should be short enough so that events that change over time can be represented by changes in successive  FIGURE 16 . Markov-cycle tree representing the kidney transplant, melanoma case. cycles. For example, if the risk of allograft rejection were markedly different in month 3 than in month 1, then a monthly cycle should be used. Another con- sideration is that the cohort simulation is an approx- imation and will more closely approximate the &dquo;exact&dquo; & d q u o ; solution when the cycle length is short. In practice, however, it makes little difference whether the cycle length is one year or one month, if the appropriate half-cycle corrections are made.20 A final consideration is evaluation time. A monthly cycle length will result in a 12-fold increase in evaluation time over a yearly cycle length. For this example, since there is no im- portant change during a year, a yearly cycle length is used."
    },
    {
      "title": "ASSIGNMENT OF PROBABILITIES",
      "text": "The next task is to assign probabilities to the events in each event tree. Each state has a chance node representing the occurrence of death during a given cycle."
    },
    {
      "title": "DEFERRED EVALUATION",
      "text": "There are two ways to introduce the expression de- fining the probability of death into the Markov decision model. At first glance, it may seem that the expression above can be placed in a binding proximal to the Mar- kov node, since it is shared by all branches. However, the values of mEXCESS are different for the individual states. Moreover, the value of the expression for pDIE should change for each cycle of the simulation as mASR increases. A simple binding would be evaluated only once and thus would not allow the value of the expres- sion to change. One solution is to place a binding with the above expression on each branch of the Markov node. However, this is cumbersome, because it re- quires entering the expression four times (it isn't needed for the DEAD state), and slows evaluation, because the entire expression must be placed on the binding stack during the evaluation of each state during each cycle.\n\nAn ideal solution is provided by deferring the eval- uation of the expression until the value of pDIE is needed, thus ensuring that the evaluation will use the current value of m.CYCLE and the appropriate local value of mEXCESS. This is accomplished using the PASSBIND function in Decision Maker&dquo; and SMLTREE.19 This function tells the computer program to place the entire expression on the binding stack instead of eval- uating the expression first. Thus, when the value of pDIE is needed at any time, anywhere in the tree, the expression will be evaluated with the prevailing values of m.CYCLE and mEXCESS. The expression thus can be entered in a binding proximal to the Markov node. The required binding expression is: Each branch of the Markov node then needs a binding for the appropriate value of mEXCESS. The values of the probabilities of pReject and pRecur depend on whether the patient is on immunosuppressive therapy and therefore must be specified for each state. The values of mEXCESS, pReject, and pRecur for each state are shown in table 4."
    },
    {
      "title": "ASSIGNING UTILITIES",
      "text": "As described above, utilities in a Markov cohort sim- ulation are associated with a state, rather than with terminal nodes of the tree. Therefore, each state must be assigned an incremental utility that reflects the value of being in that state for one cycle. In Decision Maker18 and SML TREE) 19 this is accomplished by setting the values of three special variables. The variable m.uINCR represents the incremental utility of a state for one cycle. The variable m.uINIT is a one-time ad- justment to the incremental utility that is made at the beginning of the Markov simulation. It is used to im- This probability is based on the mortality rate for each state, which consists of two components, the baseline mortality rate and the excess mortality due to any comorbid diseases. The baseline mortality rate (mASR) depends on the patient's age, sex, and race. We can assign a different mASR for each cycle to reflect the increasing mortality rate as patients get older. The most convenient way to implement this is to use a table of age-specific mortality rates and look up the appropriate value for each cycle. With a yearly cycle length, the patient's age at the end of cycle n is: There are three refinements to the age used to cal- culate the cycle-specific age. First, because we assume that transitions occur, on average, halfway through a cycle, the age should be reduced by 0.5 cycle. Second, published mortality rates for patients of a given age (e.g., 50 years old) are derived from all patients between that age and the next (50 and 51 years). Thus, the published rate for age 50 actually applies to a group with an average age of 50.5 years and the cycle-specific age should be reduced by an additional 0.5 year to retrieve the appropriate rate. Finally, deaths are slightly more likely to occur among the older members of a heterogeneous cohort and toward the end of a year (when all members are older), so that the observed death rate applies to patients who are slightly older than the average. Empirically, reducing the age by an additional 0.1 to 0.2 years corrects for these effects.\n\nThus, the starting age should be corrected according to the formula: where cyclen is the length of the Markov cycle in years.\n\nFor a detailed discussion of these corrections, the in- terested reader is referred to Sonnenberg and Wong.'O\n\nThe mortality rate may be retrieved from the table (MTABLE) by the following expression, where StartAge is corrected as above and m.CYCLE is the Markov-cycle number:\n\nFor this example, the initial value of mASR is 0.0036/ year (for a 43-year-old male). The excess component of mortality due to the patient's coexisting diseases is added to the baseline mortality rate to produce a total compound mortality rate.2 The total mortality rate may then be used to calculate the probability of death dur- ing any cycle: TO* 4 o Mortality Rates and Probabilities plement the half-cycle correction and therefore its value is usually set to 0.5 X m.uINCR. The variable m.uTAIL is used when the Markov cohort simulation is terminated before the entire cohort is in the absorbing state. Its value is added to the incremental utility for a state at the end of the simulation. The tail utility has two uses. One is to represent the prognosis beyond the stopping point in the Markov simulation. For example, if a Markov process is used only to represent the events taking place during the first six months following an operation, then m.uTAIL will represent the life ex- pectancy of the patient beyond the first six months. The second use is to apply the half-cycle correction to a simulation that is stopped prior to absorption of the cohort, even if the subsequent prognosis is of no interest. In this case, the tail utility must be set to -0.5 X m.uINCR.\n\nThe values of these special variables are set with bindings on each branch of the Markov node. For the TRANSWEL and TRANSMEL states the bindings are:\n\nThe value of m.uINCR is 1 because there is no utility decrement for the TRANSPLANT states. m.u.TAIL is 0 be- cause we are planning to run the simulation until the cohort is completely absorbed.\n\nFor the DwLwELL and DIALMEL states, the bindings are:\n\nbecause the DIALYSIS states are associated with a utility of only 0.7 relative to perfect health.16\n\nFor the DEAD state, the bindings are:\n\n., ,.\n\n-.\n\nbecause no utility accrues for membership in the DEAD state. In practice, these bindings may be omitted for the DEAD state because if their values are not specified, they will be assumed to be zero."
    },
    {
      "title": "MARKOV-STATE BINDINGS: A REFINEMENT",
      "text": "Examination of figure  16  reveals that a chance node with branches Reject and NoReject appears in two places in the tree. Similarly, a chance node with branches Recur and NoRecur appears in three places in the tree. We would like to use a common subtree to represent these events in all portions of the tree. The problem is that several of the branches are ter- minal nodes and their utilities apply only to one specific context. The solution to this problem is the use of Markov-state bindings. When Markov-state names are used on the right side of a binding expression, the program substitutes the state on the right side for the variable on the left side wherever it appears. This permits representing the prognoses of all four non-dead states with a single subtree, as in figure  17 . With the state bindings shown, this Markov-cycle tree will be functionally identical to the one in figure  16 ."
    },
    {
      "title": "EVALUATION",
      "text": "When the Markov model is evaluated as a cohort simulation, the expected utilities are: CONTINUE THERAPY 7.4 STOP THERAPY"
    },
    {
      "title": "5.2",
      "text": "Thus, the analysis favors continuing therapy by a large margin, more than two quality-adjusted life years. If the quality adjustment is removed from the analysis (by setting quality of life on dialysis to unity), then the results are:"
    },
    {
      "title": "Conelusion",
      "text": "Markov models consider a patient to be in one of a finite number of discrete states of health. All clinically important events are modelled as transitions from one state to another. Markov processes may be represented by a cohort simulation (one trial, multiple sub- jects), by a Monte Carlo simulation (many trials, a sin- gle subject for each), or by a matrix algebra solution. The matrix algebra solution requires the least com- putation, but can be used only when transition probabilities are constant, a special case of the Markov process called a Markov chain. The Markov-cycle tree is a formalism that combines the modelling power of the Markov process with the clarity and convenience of a decision-tree representation. Specialized com- puter software18,19 has been developed to implement Markov-cycle trees.\n\nThe assignment of quality adjustments to incre- mental utility permits Markov analyses to yield quality- adjusted life expectancy. Discounting may be applied to incremental utilities in cost-effectiveness analyses. The Markov model provides a means of modelling clin- ical problems in which risk is continuous over time, in which events may occur more than once, and when the utility of an outcome depends on when it occurs. FIGURE 17. Markov-cycle tree using subtrees and state bindings.\n\nMost analytic problems involve at least one of these considerations. Modelling such problems with con- ventional decision trees may require unrealistic or un- justified simplifying assumptions and may be com- putationally intractable. Thus, the use of Markov models has the potential to permit the development of deci- sion models that more faithfully represent clinical problems."
    },
    {
      "text": "FIGURE 1. Simple tree fragment modeling complications of antico- agulant therapy."
    },
    {
      "text": "FIGURE 2. Recursive tree modeling complications of antico- agulant therapy."
    },
    {
      "text": "FIGURE 3. Markov-state diagram. Each circle represents a Markov state. Arrows indicate allowed transitions."
    },
    {
      "text": "Expected utility = ~ ts s=l i"
    },
    {
      "text": "Expected utility = ~ ts X Us s=l i"
    },
    {
      "text": "FIGURE 4. Markov-state diagram. The shaded circle labeled &dquo;STROKE&dquo; represents a temporary state."
    },
    {
      "text": "FIGURE 6. Use of Markov processes in a decision model. In panel A (top), the Markov process is used only as a utility. In panel B (bottom), the Markov process is used to represent all events."
    },
    {
      "text": "FIGURE 7. Markov cohort simulation. PanelA (top), shows the initial distribution with all patients in the WELL state. Panel B(middle)"
    },
    {
      "text": "FIGURE 10. Illustration of the half-cycle correction."
    },
    {
      "text": "FIGURE 11. Probability tree corresponding to the WELL state."
    },
    {
      "text": "FIGURE 13. Monte Carlo simulation. The figure shows the state tran- sitions of a single person until death occurs during cycle6."
    },
    {
      "text": "Adapted fromBeck et al.5"
    },
    {
      "text": "FIGURE 15. Root of the tree representing the Markov model of the kidney transplant, melanoma case."
    },
    {
      "text": "Texas (JRB). Supported in part by Grant  LM05266  from the  National Library of Medicine  and Grant  HS06396  from the  Agency for Health Care Policy and Research ."
    }
  ],
  "references": [
    {
      "title": "Quality-adjusted life years, utility theory, and healthy-years equivalents",
      "authors": [
        "A Mehrez",
        "A Gafni"
      ],
      "year": 1989,
      "doi": "10.1177/0272989x8900900209",
      "journal": "Med Decis Making",
      "volume": "9",
      "raw": "Quality-adjusted life years, utility theory, and healthy-years equivalents \n\t\t \n\t\t\t A Mehrez \n\t\t \n\t\t \n\t\t\t A Gafni \n\t\t \n\t\t 10.1177/0272989x8900900209 \n\t \n\t \n\t\t Med Decis Making \n\t\t \n\t\t\t 9 \n\t\t\t \n\t\t\t 1989 \n\t\t \n\t \n\t Mehrez A, Gafni A. Quality-adjusted life years, utility theory, and healthy-years equivalents. Med Decis Making. 1989;9:142-9."
    },
    {
      "title": "A convenient approximation of life expectancy (the \"DEALE\"). I. Validation of the model",
      "authors": [
        "J Beck",
        "J Kassirer",
        "S Pauker"
      ],
      "year": 1982,
      "doi": "10.1016/0002-9343(82)90786-0",
      "journal": "Am J Med",
      "volume": "73",
      "raw": "A convenient approximation of life expectancy (the \"DEALE\"). I. Validation of the model \n\t\t \n\t\t\t J R Beck \n\t\t \n\t\t \n\t\t\t J P Kassirer \n\t\t \n\t\t \n\t\t\t S G Pauker \n\t\t \n\t\t 10.1016/0002-9343(82)90786-0 \n\t \n\t \n\t\t Am J Med \n\t\t \n\t\t\t 73 \n\t\t\t \n\t\t\t 1982 \n\t\t \n\t \n\t Beck JR, Kassirer JP, Pauker SG. A convenient approximation of life expectancy (the \"DEALE\"). I. Validation of the model. Am J Med. 1982;73:883-8."
    },
    {
      "title": "On the nature of the function expressive of the law of human mortality",
      "authors": [
        "B Gompertz"
      ],
      "doi": "10.1098/rstl.1825.0026",
      "journal": "Philos Trans R Soc London",
      "volume": "115",
      "raw": "On the nature of the function expressive of the law of human mortality \n\t\t \n\t\t\t B Gompertz \n\t\t \n\t\t 10.1098/rstl.1825.0026 \n\t \n\t \n\t\t Philos Trans R Soc London \n\t\t \n\t\t\t 115 \n\t\t\t \n\t\t\t 1825 \n\t\t \n\t \n\t Gompertz B. On the nature of the function expressive of the law of human mortality. Philos Trans R Soc London. 1825;115:513- 85."
    },
    {
      "title": "Vital Statistics of the United States",
      "year": 1988,
      "doi": "10.1086/639803",
      "volume": "II",
      "raw": "10.1086/639803 \n\t\t Vital Statistics of the United States \n\t\t \n\t\t\t Washington, Public Health Service \n\t\t\t 1988. 1991 \n\t\t\t II \n\t\t \n\t\t \n\t\t\t National Center for Health Statistics \n\t\t \n\t \n\t Mortality, Part A \n\t National Center for Health Statistics. Vital Statistics of the United States, 1988. Vol II, Mortality, Part A, Section 6. Washington, Public Health Service, 1991."
    },
    {
      "title": "The Markov process in medical prognosis",
      "authors": [
        "J Beck",
        "S Pauker"
      ],
      "year": 1983,
      "doi": "10.1177/0272989x8300300403",
      "journal": "Med Decis Making",
      "volume": "3",
      "raw": "The Markov process in medical prognosis \n\t\t \n\t\t\t J R Beck \n\t\t \n\t\t \n\t\t\t S G Pauker \n\t\t \n\t\t 10.1177/0272989x8300300403 \n\t \n\t \n\t\t Med Decis Making \n\t\t \n\t\t\t 3 \n\t\t\t \n\t\t\t 1983 \n\t\t \n\t \n\t Beck JR, Pauker SG. The Markov process in medical prognosis. Med Decis Making. 1983;3:419-58."
    },
    {
      "title": "Anticoagulation for noncardiac procedures in patients with prosthetic heart valves. Does low risk mean high cost?",
      "authors": [
        "M Eckman",
        "J Beshansky",
        "I Durand-Zaleski",
        "H Levine",
        "S Pauker"
      ],
      "year": 1990,
      "doi": "10.1001/jama.1990.03440110079032",
      "journal": "JAMA",
      "volume": "263",
      "raw": "Anticoagulation for noncardiac procedures in patients with prosthetic heart valves. Does low risk mean high cost? \n\t\t \n\t\t\t M H Eckman \n\t\t \n\t\t \n\t\t\t J R Beshansky \n\t\t \n\t\t \n\t\t\t I Durand-Zaleski \n\t\t \n\t\t \n\t\t\t H J Levine \n\t\t \n\t\t \n\t\t\t S G Pauker \n\t\t \n\t\t 10.1001/jama.1990.03440110079032 \n\t \n\t \n\t\t JAMA \n\t\t \n\t\t\t 263 \n\t\t\t \n\t\t\t 1990 \n\t\t \n\t \n\t Eckman MH, Beshansky JR, Durand-Zaleski I, Levine HJ, Pauker SG. Anticoagulation for noncardiac procedures in patients with prosthetic heart valves. Does low risk mean high cost? JAMA, 1990;263:1513-21."
    },
    {
      "title": "Myocardial revascularization for chronic stable angina: an analysis of the role of percutaneous transluminal coronary angioplasty based on data available in 1989",
      "authors": [
        "J Wong",
        "F Sonnenberg",
        "D Salem",
        "S Pauker"
      ],
      "year": 1990,
      "doi": "10.7326/0003-4819-113-11-852",
      "journal": "Ann Intern Med",
      "volume": "113",
      "raw": "Myocardial revascularization for chronic stable angina: an analysis of the role of percutaneous transluminal coronary angioplasty based on data available in 1989 \n\t\t \n\t\t\t J B Wong \n\t\t \n\t\t \n\t\t\t F A Sonnenberg \n\t\t \n\t\t \n\t\t\t D Salem \n\t\t \n\t\t \n\t\t\t S G Pauker \n\t\t \n\t\t 10.7326/0003-4819-113-11-852 \n\t \n\t \n\t\t Ann Intern Med \n\t\t \n\t\t\t 113 \n\t\t\t \n\t\t\t 1990 \n\t\t \n\t \n\t Wong JB, Sonnenberg FA, Salem D, Pauker SG. Myocardial re- vascularization for chronic stable angina: an analysis of the role of percutaneous transluminal coronary angioplasty based on data available in 1989. Ann Intern Med. 1990;113:852-71."
    },
    {
      "title": "Efficacy and cost-effectiveness of autologous bone marrow transplantation in metastatic breast cancer. Estimates using decision analysis while awaiting clinical trial results",
      "authors": [
        "B Hillner",
        "T Smith",
        "C Desch"
      ],
      "year": 1992,
      "doi": "10.1001/jama.1992.03480150061038",
      "journal": "JAMA",
      "volume": "267",
      "raw": "Efficacy and cost-effectiveness of autologous bone marrow transplantation in metastatic breast cancer. Estimates using decision analysis while awaiting clinical trial results \n\t\t \n\t\t\t B E Hillner \n\t\t \n\t\t \n\t\t\t T J Smith \n\t\t \n\t\t \n\t\t\t C E Desch \n\t\t \n\t\t 10.1001/jama.1992.03480150061038 \n\t \n\t \n\t\t JAMA \n\t\t \n\t\t\t 267 \n\t\t\t \n\t\t\t 1992 \n\t\t \n\t \n\t Hillner BE, Smith TJ, Desch CE. Efficacy and cost-effectiveness of autologous bone marrow transplantation in metastatic breast cancer. Estimates using decision analysis while awaiting clinical trial results. JAMA. 1992;267:2055-61."
    },
    {
      "title": "Should patients with Bjork-Shiley valves undergo prophylactic replacement?",
      "authors": [
        "J Birkmeyer",
        "C Marrin",
        "O' Connor"
      ],
      "year": 1992,
      "doi": "10.1016/0140-6736(92)91717-m",
      "journal": "Lancet",
      "volume": "340",
      "raw": "Should patients with Bjork-Shiley valves undergo prophylactic replacement? \n\t\t \n\t\t\t J D Birkmeyer \n\t\t \n\t\t \n\t\t\t C A Marrin \n\t\t \n\t\t \n\t\t\t O' Connor \n\t\t \n\t\t \n\t\t\t G-T \n\t\t \n\t\t 10.1016/0140-6736(92)91717-m \n\t \n\t \n\t\t Lancet \n\t\t \n\t\t\t 340 \n\t\t\t \n\t\t\t 1992 \n\t\t \n\t \n\t Birkmeyer JD, Marrin CA, O'Connor G-T. Should patients with Bjork-Shiley valves undergo prophylactic replacement? Lancet. 1992;340:520-3."
    },
    {
      "title": "Foundations of cost-effectiveness analysis for health and medical practices",
      "authors": [
        "M Weinstein",
        "W Stason"
      ],
      "year": 1977,
      "doi": "10.1056/nejm197703312961304",
      "journal": "N Engl J Med",
      "volume": "296",
      "raw": "Foundations of cost-effectiveness analysis for health and medical practices \n\t\t \n\t\t\t M C Weinstein \n\t\t \n\t\t \n\t\t\t W B Stason \n\t\t \n\t\t 10.1056/nejm197703312961304 \n\t \n\t \n\t\t N Engl J Med \n\t\t \n\t\t\t 296 \n\t\t\t \n\t\t\t 1977 \n\t\t \n\t \n\t Weinstein MC, Stason WB. Foundations of cost-effectiveness analysis for health and medical practices. N Engl J Med. 1977;296:716-21."
    },
    {
      "title": "A clinician's guide to cost-effectiveness analysis",
      "authors": [
        "A Detsky",
        "I Naglie"
      ],
      "year": 1990,
      "doi": "10.7326/0003-4819-113-2-147",
      "journal": "Ann Intern Med",
      "volume": "113",
      "raw": "A clinician's guide to cost-effectiveness analysis \n\t\t \n\t\t\t A S Detsky \n\t\t \n\t\t \n\t\t\t I G Naglie \n\t\t \n\t\t 10.7326/0003-4819-113-2-147 \n\t \n\t \n\t\t Ann Intern Med \n\t\t \n\t\t\t 113 \n\t\t\t \n\t\t\t 1990 \n\t\t \n\t \n\t Detsky AS, Naglie IG. A clinician's guide to cost-effectiveness analysis. Ann Intern Med. 1990;113:147-54."
    },
    {
      "title": "DECISION MAKER 3.0: improved decision analysis by personal computer",
      "authors": [
        "J Lau",
        "J Kassirer",
        "S Pauker"
      ],
      "year": 1983,
      "doi": "10.1177/0272989x8300300110",
      "journal": "Med Decis Making",
      "volume": "3",
      "raw": "DECISION MAKER 3.0: improved decision analysis by personal computer \n\t\t \n\t\t\t J Lau \n\t\t \n\t\t \n\t\t\t J P Kassirer \n\t\t \n\t\t \n\t\t\t S G Pauker \n\t\t \n\t\t 10.1177/0272989x8300300110 \n\t \n\t \n\t\t Med Decis Making \n\t\t \n\t\t\t 3 \n\t\t\t \n\t\t\t 1983 \n\t\t \n\t \n\t Lau J, Kassirer JP, Pauker SG. DECISION MAKER 3.0: improved de- cision analysis by personal computer. Med Decis Making. 1983;3:39-43."
    },
    {
      "title": "Cardiac risks and complications of noncardiac surgery",
      "authors": [
        "L Goldman"
      ],
      "year": 1983,
      "doi": "10.7326/0003-4819-98-4-504",
      "journal": "Ann Intern Med",
      "volume": "98",
      "raw": "Cardiac risks and complications of noncardiac surgery \n\t\t \n\t\t\t L Goldman \n\t\t \n\t\t 10.7326/0003-4819-98-4-504 \n\t \n\t \n\t\t Ann Intern Med \n\t\t \n\t\t\t 98 \n\t\t\t \n\t\t\t 1983 \n\t\t \n\t \n\t Goldman L. Cardiac risks and complications of noncardiac sur- gery. Ann Intern Med. 1983;98:504-13."
    },
    {
      "title": "Finite Markov Chains",
      "authors": [
        "J Kemeny",
        "J Snell"
      ],
      "year": 1976,
      "doi": "10.1007/978-1-4684-9455-6_4",
      "raw": "Finite Markov Chains \n\t\t \n\t\t\t J B Kemeny \n\t\t \n\t\t \n\t\t\t J L Snell \n\t\t \n\t\t 10.1007/978-1-4684-9455-6_4 \n\t\t \n\t\t\t 1976 \n\t\t\t Springer-Verlag \n\t\t\t New York \n\t\t \n\t \n\t Kemeny JB, Snell JL. Finite Markov Chains. New York: Springer- Verlag, 1976."
    },
    {
      "title": "Markov cycle trees: a new representation for complex Markov processes (abstr)",
      "authors": [
        "J Hollenberg"
      ],
      "year": 1984,
      "journal": "Med Decis Making",
      "volume": "4",
      "pages": "529",
      "raw": "Markov cycle trees: a new representation for complex Markov processes (abstr) \n\t\t \n\t\t\t J P Hollenberg \n\t\t \n\t \n\t \n\t\t Med Decis Making \n\t\t \n\t\t\t 4 \n\t\t\t 529 \n\t\t\t 1984 \n\t\t \n\t \n\t Hollenberg JP. Markov cycle trees: a new representation for com- plex Markov processes (abstr). Med Decis Making. 1984;4:529."
    },
    {
      "title": "Kidney Failure or Cancer: Should Immunosuppression Be Continued in a Transplant Patient with Malignant Melanoma?",
      "authors": [
        "G Cucharal",
        "A Levey",
        "S Pauker"
      ],
      "year": 1984,
      "doi": "10.1177/0272989x8400400113",
      "journal": "Med Decis Making",
      "volume": "4",
      "raw": "Kidney Failure or Cancer: Should Immunosuppression Be Continued in a Transplant Patient with Malignant Melanoma? \n\t\t \n\t\t\t G J Cucharal \n\t\t \n\t\t \n\t\t\t A S Levey \n\t\t \n\t\t \n\t\t\t S G Pauker \n\t\t \n\t\t 10.1177/0272989x8400400113 \n\t \n\t \n\t\t Med Decis Making \n\t\t \n\t\t\t 4 \n\t\t\t \n\t\t\t 1984 \n\t\t \n\t \n\t Cucharal GJ, Levey AS, Pauker SG. Kidney Failure or Cancer: Should Immunosuppression Be Continued in a Transplant Pa- tient with Malignant Melanoma? Med Decis Making. 1984;4:82- 107."
    },
    {
      "title": "Decision analysis",
      "authors": [
        "J Kassirer",
        "F Sonnenberg"
      ],
      "year": 1988,
      "raw": "Decision analysis \n\t\t \n\t\t\t J P Kassirer \n\t\t \n\t\t \n\t\t\t F A Sonnenberg \n\t\t \n\t \n\t \n\t\t Textbook of Internal Medicine \n\t\t \n\t\t\t W N Kelley \n\t\t \n\t\t Philadelphia \n\t\t \n\t\t\t J. B. Lippincott \n\t\t\t 1988. 1991 \n\t\t \n\t \n\t Kassirer JP, Sonnenberg FA. Decision analysis. In Kelley WN, ed. Textbook of Internal Medicine. Philadelphia: J. B. Lippincott, 1988, 1991."
    },
    {
      "title": "Decision Maker: an advanced personal computer tool for clinical decision analysis",
      "authors": [
        "F Sonnenberg",
        "S Pauker"
      ],
      "year": 1987,
      "raw": "Decision Maker: an advanced personal computer tool for clinical decision analysis \n\t\t \n\t\t\t F A Sonnenberg \n\t\t \n\t\t \n\t\t\t S G Pauker \n\t\t \n\t \n\t \n\t\t Proceedings of the Eleventh Annual Symposium on Computer Applications in Medical Care \n\t\t the Eleventh Annual Symposium on Computer Applications in Medical Care Washington, D.C. \n\t\t \n\t\t\t IEEE Computer Society \n\t\t\t 1987 \n\t\t \n\t \n\t Sonnenberg FA, Pauker SG. Decision Maker: an advanced per- sonal computer tool for clinical decision analysis. Proceedings of the Eleventh Annual Symposium on Computer Applications in Medical Care, Washington, D.C.: IEEE Computer Society,1987."
    },
    {
      "title": "The All Purpose Decision Tree Builder",
      "authors": [
        "J Hollenberg"
      ],
      "year": 1985,
      "raw": "J Hollenberg \n\t\t \n\t\t \n\t\t\t Smltree \n\t\t \n\t\t The All Purpose Decision Tree Builder \n\t\t Boston \n\t\t \n\t\t\t Pratt Medical Group \n\t\t\t 1985 \n\t\t \n\t \n\t Hollenberg J. SMLTREE: The All Purpose Decision Tree Builder. Boston: Pratt Medical Group; 1985."
    },
    {
      "title": "Fine-tuning Markov models for lifeexpectancy calculations",
      "authors": [
        "F Sonnenberg",
        "J Wong"
      ],
      "year": 1993,
      "doi": "10.1177/0272989x9301300215",
      "journal": "Med Decis Making",
      "volume": "13",
      "raw": "Fine-tuning Markov models for lifeexpectancy calculations \n\t\t \n\t\t\t F A Sonnenberg \n\t\t \n\t\t \n\t\t\t J B Wong \n\t\t \n\t\t 10.1177/0272989x9301300215 \n\t \n\t \n\t\t Med Decis Making \n\t\t \n\t\t\t 13 \n\t\t\t \n\t\t\t 1993 \n\t\t \n\t \n\t Sonnenberg FA, Wong JB. Fine-tuning Markov models for life- expectancy calculations. Med Decis Making. 1993;13:170-2."
    }
  ],
  "num_references": 20,
  "figures": [
    {
      "caption": "FIGURE 1 .",
      "description": "FIGURE 1. Simple tree fragment modeling complications of antico- agulant therapy."
    },
    {
      "caption": "FIGURE 2 .",
      "description": "FIGURE 2. Recursive tree modeling complications of antico- agulant therapy."
    },
    {
      "caption": "FIGURE 3 .",
      "description": "FIGURE 3. Markov-state diagram. Each circle represents a Markov state. Arrows indicate allowed transitions."
    },
    {
      "caption": "n",
      "description": "Expected utility = ~ ts s=l i"
    },
    {
      "caption": "n",
      "description": "Expected utility = ~ ts X Us s=l i"
    },
    {
      "caption": "FIGURE 4 .",
      "description": "FIGURE 4. Markov-state diagram. The shaded circle labeled &dquo;STROKE&dquo; represents a temporary state."
    },
    {
      "caption": "FIGURE 6 .",
      "description": "FIGURE 6. Use of Markov processes in a decision model. In panel A (top), the Markov process is used only as a utility. In panel B (bottom), the Markov process is used to represent all events."
    },
    {
      "caption": "FIGURE 7 .",
      "description": "FIGURE 7. Markov cohort simulation. PanelA (top), shows the initial distribution with all patients in the WELL state. Panel B(middle)"
    },
    {
      "caption": "FIGURE 10 .",
      "description": "FIGURE 10. Illustration of the half-cycle correction."
    },
    {
      "caption": "FIGURE 11 .",
      "description": "FIGURE 11. Probability tree corresponding to the WELL state."
    },
    {
      "caption": "FIGURE 13 .",
      "description": "FIGURE 13. Monte Carlo simulation. The figure shows the state tran- sitions of a single person until death occurs during cycle6."
    },
    {
      "caption": "*",
      "description": "Adapted fromBeck et al.5"
    },
    {
      "caption": "FIGURE 15 .",
      "description": "FIGURE 15. Root of the tree representing the Markov model of the kidney transplant, melanoma case."
    }
  ],
  "num_figures": 13,
  "num_citations": 24,
  "cited_references": [
    "b16",
    "b15",
    "b2",
    "b14",
    "b19",
    "b17",
    "b11",
    "b10"
  ],
  "notes": [
    "[raw_affiliation] Department of Medicine , UMDNJ Robert Wood Johnson Medical School , New Brunswick , New Jersey",
    "[raw_affiliation] mation Technology Program , Baylor College of Medicine , Houston ,",
    "[raw_affiliation] Division of General Internal Medicine , UMDNJ Robert Wood John- son Medical School , 97 Paterson Street , New Brunswick , NJ 08903 .",
    "[submission] Received February 23, 1993,",
    "[raw_reference] Mehrez A, Gafni A. Quality-adjusted life years, utility theory, and healthy-years equivalents. Med Decis Making. 1989;9:142-9.",
    "[raw_reference] Beck JR, Kassirer JP, Pauker SG. A convenient approximation of life expectancy (the \"DEALE\"). I. Validation of the model. Am J Med. 1982;73:883-8.",
    "[raw_reference] Gompertz B. On the nature of the function expressive of the law of human mortality. Philos Trans R Soc London. 1825;115:513- 85.",
    "Mortality, Part A",
    "[raw_reference] National Center for Health Statistics. Vital Statistics of the United States, 1988. Vol II, Mortality, Part A, Section 6. Washington, Public Health Service, 1991.",
    "[raw_reference] Beck JR, Pauker SG. The Markov process in medical prognosis. Med Decis Making. 1983;3:419-58.",
    "[raw_reference] Eckman MH, Beshansky JR, Durand-Zaleski I, Levine HJ, Pauker SG. Anticoagulation for noncardiac procedures in patients with prosthetic heart valves. Does low risk mean high cost? JAMA, 1990;263:1513-21.",
    "[raw_reference] Wong JB, Sonnenberg FA, Salem D, Pauker SG. Myocardial re- vascularization for chronic stable angina: an analysis of the role of percutaneous transluminal coronary angioplasty based on data available in 1989. Ann Intern Med. 1990;113:852-71.",
    "[raw_reference] Hillner BE, Smith TJ, Desch CE. Efficacy and cost-effectiveness of autologous bone marrow transplantation in metastatic breast cancer. Estimates using decision analysis while awaiting clinical trial results. JAMA. 1992;267:2055-61.",
    "[raw_reference] Birkmeyer JD, Marrin CA, O'Connor G-T. Should patients with Bjork-Shiley valves undergo prophylactic replacement? Lancet. 1992;340:520-3.",
    "[raw_reference] Weinstein MC, Stason WB. Foundations of cost-effectiveness analysis for health and medical practices. N Engl J Med. 1977;296:716-21.",
    "[raw_reference] Detsky AS, Naglie IG. A clinician's guide to cost-effectiveness analysis. Ann Intern Med. 1990;113:147-54.",
    "[raw_reference] Lau J, Kassirer JP, Pauker SG. DECISION MAKER 3.0: improved de- cision analysis by personal computer. Med Decis Making. 1983;3:39-43.",
    "[raw_reference] Goldman L. Cardiac risks and complications of noncardiac sur- gery. Ann Intern Med. 1983;98:504-13.",
    "[raw_reference] Kemeny JB, Snell JL. Finite Markov Chains. New York: Springer- Verlag, 1976.",
    "[raw_reference] Hollenberg JP. Markov cycle trees: a new representation for com- plex Markov processes (abstr). Med Decis Making. 1984;4:529.",
    "[raw_reference] Cucharal GJ, Levey AS, Pauker SG. Kidney Failure or Cancer: Should Immunosuppression Be Continued in a Transplant Pa- tient with Malignant Melanoma? Med Decis Making. 1984;4:82- 107.",
    "[raw_reference] Kassirer JP, Sonnenberg FA. Decision analysis. In Kelley WN, ed. Textbook of Internal Medicine. Philadelphia: J. B. Lippincott, 1988, 1991.",
    "[raw_reference] Sonnenberg FA, Pauker SG. Decision Maker: an advanced per- sonal computer tool for clinical decision analysis. Proceedings of the Eleventh Annual Symposium on Computer Applications in Medical Care, Washington, D.C.: IEEE Computer Society,1987.",
    "[raw_reference] Hollenberg J. SMLTREE: The All Purpose Decision Tree Builder. Boston: Pratt Medical Group; 1985.",
    "[raw_reference] Sonnenberg FA, Wong JB. Fine-tuning Markov models for life- expectancy calculations. Med Decis Making. 1993;13:170-2."
  ],
  "editors": [
    "W N Kelley"
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  }
}
