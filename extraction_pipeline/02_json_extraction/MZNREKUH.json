{
  "paper_id": "MZNREKUH",
  "title": "Using Adaptive Bandit Experiments to Increase and Investigate Engagement in Mental Health",
  "abstract": "Digital mental health (DMH) interventions, such as textmessage-based lessons and activities, offer immense potential for accessible mental health support. While these interventions can be effective, real-world experimental testing can further enhance their design and impact. Adaptive experimentation, utilizing algorithms like Thompson Sampling for (contextual) multi-armed bandit (MAB) problems, can lead to continuous improvement and personalization. However, it remains unclear when these algorithms can simultaneously increase user experience rewards and facilitate appropriate data collection for social-behavioral scientists to analyze with sufficient statistical confidence. Although a growing body of research addresses the practical and statistical aspects of MAB and other adaptive algorithms, further exploration is needed to assess their impact across diverse real-world contexts. This paper presents a software system developed over two years that allows text-messaging intervention components to be adapted using bandit and other algorithms while collecting data for side-by-side comparison with traditional uniform random non-adaptive experiments. We evaluate the system by deploying a text-message-based DMH intervention to 1100 users, recruited through a large mental health nonprofit organization, and share the path forward for deploying this system at scale. This system not only enables applications in mental health but could also serve as a model testbed for adaptive experimentation algorithms in other domains.",
  "year": 2015,
  "date": "2015",
  "journal": "JMIR MHealth UHealth",
  "publication": "JMIR MHealth UHealth",
  "authors": [
    {
      "forename": "Harsh",
      "surname": "Kumar",
      "name": "Harsh Kumar",
      "affiliation": "1  Department of Computer Science , University of Toronto \n\t\t\t\t\t\t\t\t Department of Computer Science \n\t\t\t\t\t\t\t\t University of Toronto"
    },
    {
      "forename": "Tong",
      "surname": "Li",
      "name": "Tong Li",
      "affiliation": "2  Department of Statistics , University of Toronto \n\t\t\t\t\t\t\t\t Department of Statistics \n\t\t\t\t\t\t\t\t University of Toronto"
    },
    {
      "forename": "Jiakai",
      "surname": "Shi",
      "name": "Jiakai Shi",
      "affiliation": "1  Department of Computer Science , University of Toronto \n\t\t\t\t\t\t\t\t Department of Computer Science \n\t\t\t\t\t\t\t\t University of Toronto"
    },
    {
      "forename": "Ilya",
      "surname": "Musabirov",
      "name": "Ilya Musabirov",
      "affiliation": "1  Department of Computer Science , University of Toronto \n\t\t\t\t\t\t\t\t Department of Computer Science \n\t\t\t\t\t\t\t\t University of Toronto"
    },
    {
      "forename": "Rachel",
      "surname": "Kornfield",
      "name": "Rachel Kornfield",
      "affiliation": "3  Center for Behavioral Intervention Technologies , Northwestern University \n\t\t\t\t\t\t\t\t Center for Behavioral Intervention Technologies \n\t\t\t\t\t\t\t\t Northwestern University"
    },
    {
      "forename": "Jonah",
      "surname": "Meyerhoff",
      "name": "Jonah Meyerhoff",
      "affiliation": "3  Center for Behavioral Intervention Technologies , Northwestern University \n\t\t\t\t\t\t\t\t Center for Behavioral Intervention Technologies \n\t\t\t\t\t\t\t\t Northwestern University"
    },
    {
      "forename": "Ananya",
      "surname": "Bhattacharjee",
      "name": "Ananya Bhattacharjee",
      "affiliation": "1  Department of Computer Science , University of Toronto \n\t\t\t\t\t\t\t\t Department of Computer Science \n\t\t\t\t\t\t\t\t University of Toronto"
    },
    {
      "forename": "Chris",
      "surname": "Karr",
      "name": "Chris Karr",
      "affiliation": "4  Audacious Software \n\t\t\t\t\t\t\t\t Software \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Audacious"
    },
    {
      "forename": "Theresa",
      "surname": "Nguyen",
      "name": "Theresa Nguyen",
      "affiliation": "5  Mental Health America \n\t\t\t\t\t\t\t\t Mental Health \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t America"
    },
    {
      "forename": "David",
      "surname": "Mohr",
      "name": "David Mohr",
      "affiliation": "3  Center for Behavioral Intervention Technologies , Northwestern University \n\t\t\t\t\t\t\t\t Center for Behavioral Intervention Technologies \n\t\t\t\t\t\t\t\t Northwestern University"
    },
    {
      "forename": "Anna",
      "surname": "Rafferty",
      "name": "Anna Rafferty",
      "affiliation": "6  Carleton College \n\t\t\t\t\t\t\t\t Carleton College"
    },
    {
      "forename": "Sofia",
      "surname": "Villar",
      "name": "Sofia Villar",
      "affiliation": "7  MRC -Biostatistics Unit , University of Cambridge \n\t\t\t\t\t\t\t\t MRC -Biostatistics Unit \n\t\t\t\t\t\t\t\t University of Cambridge"
    },
    {
      "forename": "Nina",
      "surname": "Deliu",
      "name": "Nina Deliu",
      "affiliation": "7  MRC -Biostatistics Unit , University of Cambridge \n\t\t\t\t\t\t\t\t MRC -Biostatistics Unit \n\t\t\t\t\t\t\t\t University of Cambridge"
    },
    {
      "forename": "Joseph",
      "surname": "Williams",
      "name": "Joseph Williams",
      "affiliation": "1  Department of Computer Science , University of Toronto \n\t\t\t\t\t\t\t\t Department of Computer Science \n\t\t\t\t\t\t\t\t University of Toronto"
    }
  ],
  "doi": "https://doi.org/10.13039/100000025",
  "sections": [
    {
      "title": "Introduction",
      "text": "Enhancing digital mental health interventions can contribute significantly to improved well-being and support in today's society  (Boardman 2011) . The global prevalence of mental health problems increased by an unprecedented 25% in 2020, the first year of the COVID-19 pandemic. This increased prevalence and disruptions to traditional mental health care emphasized preexisting gaps in access to support. Before, during, and after the pandemic, many cannot access adequate mental health support and are increasingly turning to DMH tools  (Torous et al. 2020) . There is an opportunity for AI to help address these challenges and enhance mental health support across various populations  (Kumar et al. 2023; Malgaroli et al. 2023) .\n\nDigital Mental Health (DMH) interventions hold promise in extending the availability of support for individuals as they take steps to manage their mental health. Automated messaging is a central component of many DMH interventions as a modality for delivering support and information. However, messaging interventions typically deliver the same content across users despite the users' varied needs. This in turn reduces the relevance of such messages as well as compromises engagement and effectiveness. This is problematic because while engagement with interventions is not sufficient, it is necessary to benefit users. Moreover, building, optimizing, and evaluating multicomponent interventions is a multi-stage process that is complex and requires data-driven decisions from experts  (Collins, Murphy, and Strecher 2007) .\n\nTo address these challenges, we developed a system for adaptive experimentation to improve people's engagement with text messages providing a mental health intervention, using Multi-Armed Bandit (MAB) algorithms. The system was built in partnership with Mental Health America (MHA) foot_0  , a large non-profit organization dedicated to promoting mental health and preventing mental illness through advocacy, education, research, and services. The system supports an eight-week DMH intervention in which users receive various contents via text messages to help manage their mental health (see Figure  1 ). To continually test out improvements, our software system instruments components of the text messages to function like intelligent agents that test out different actions (arms), by using MAB algorithms to conduct adaptive experiments.\n\nThe purpose of using this system is twofold:\n\n\u2022 First, we are able to run algorithms in a real-world mental health setting to optimize efficacy, as has been done in Figure  1 : Schematic representation of an example sequence of messages a user could receive during days D i , where D i is any random day within the 8-week-long intervention when the user receives a message. 'Mood' and 'Energy' during each day D i represent a subset of contexts describing the user during that particular day, and 'Reward' indicates a response from the user to the question \"How helpful were these messages? Reply with a number 1 (not at all helpful) to 5 (very helpful)\" after receiving the messages during the day. The messages are composed of three modular components in a 2 (Rationale: present vs absent) x 2 (Link: present vs absent) x 4 (Interaction type: 4 options) factorial design.\n\nproduct development.\n\n\u2022 Second, this system allows us to understand how well the results of such algorithms can be analyzed by clinical scientists with statistical rigor.\n\nFor example, consider an Action (experimental) variable that is testing whether providing a rationale for using a particular psychological strategy impacts the Reward (outcome) -a measure of message helpfulness. The impact of the Action variable on the Reward may depend on contextual variables, such as self-reported Mood. Domain scientists, like clinical psychology researchers, may want to analyze such data to understand how the Action variable impacts the Reward, and how that impact is mediated by covariates or contextual variables like Mood.\n\nTraditional experiments with uniform random assignment generate data that can be used to provide answers to these questions. However, traditional experiments do not dynamically provide a better user experience by rapidly using existing data to inform what a user will receive in the future. Using the most fundamental formulation of explorationexploitation tradeoffs, (contextual) MAB algorithms allow for such a dynamic, adaptive experimental design. This can have the benefit of increasing the probability that users are assigned to actions that work best for them, as well as the benefit of decreasing the probability that users receive burdensome or ineffective actions.\n\nHowever, there might be a trade-off between collecting data to answer domain scientist questions and using data to try to optimize for users  (Yao et al. 2021) . For example, research has suggested that there may be biases in estimates of arm means, increased false positive rates, and reduced statistical power. Our system not only enables the use of contextual MAB algorithms to optimize for users, but also provides a testbed for evaluating how different scenarios can impact false positive rates, statistical power, and reward maximization."
    },
    {
      "title": "Related Work Digital Mental Health and Text-Message Based Interventions",
      "text": "Digital mental health (DMH) interventions provide a solution for narrowing the service provision gap, wherein the need for mental health support far outweighs the availability of traditional care  (Gan et al. 2021) . By utilizing tools like computers and smartphones, psychological treatment can become widely accessible. The majority of Americans own smartphones, and DMH interventions using this modality allow users to customize how they wish to receive and engage with mental health support. Previous work has found DMH interventions for depression to be effective across randomized control trials  (Firth et al. 2017) . However, user engagement levels with DMH interventions are low, barring adoption into the real world  (Gan et al. 2021) . Text messaging as a modality has proven to be effective in promoting behavior change. Using automated messaging, short content that is repeatedly delivered throughout the day can lay the foundation for a larger behavior change process  (Abroms et al. 2015) . Further, automated messaging has been successful in promoting and maintaining positive mental health  (Armanasco et al. 2017) ."
    },
    {
      "title": "Adaptive Experiments and Multi-Armed Bandit Algorithms",
      "text": "Contextual MAB algorithms are one solution for adaptive experiments. These algorithms base the probability of assignment on previous data, ensuring that more users are exposed to more effective conditions, and fewer users are exposed to less effective conditions  (Li et al. 2010 ). Bandit algorithms have been extensively applied in real-world settings to tackle the exploration-exploitation dilemma in sequential decision-making  (Fouch\u00e9, Komiyama, and B\u00f6hm 2019; Zhan et al. 2021) . However, there are issues that arise from MAB algorithms that complicate data analysis. Primarily, these algorithms have been shown to produce measurement errors, increases in false positive rates, and decreases in statistical power  (Russo 2020) . These hindrances work directly against the objective of the algorithm by decreasing the chance that effective conditions will be identified and increasing the probability that unhelpful conditions will be deployed  (Rafferty et al. 2019 ). Therefore, it may be helpful to use systems that enable comparisons of different algorithms, such that researchers can make informed decisions about these statistical trade-offs."
    },
    {
      "title": "Design of Intervention",
      "text": "A series of design workshops were conducted with nontreatment seeking participants  (Kornfield et al. 2022; Bhattacharjee et al. 2023)  to generate content which could be tailored according to users' preferences, backgrounds, and contexts. In the next section, we deep dive into a particular component of the intervention to show as an example how contextual multi-armed bandit algorithms are used throughout the numerous experimentation points."
    },
    {
      "title": "Adaptive Components in DMH Intervention",
      "text": "Modular dialogues are brief, self-contained interactions that support a single psychological strategy, and can be delivered at one contact point without the need to reference messages earlier or later in the day. Our software system enables embedded adaptive experiments at a number of intelligent decision points in these modular dialogues. Figure  1  illustrates an example of message sequences a participant may receive during an 8-week intervention to practice self-compassion. The messages contain three modular components (decision points) in a factorial design: Rationale (present vs. absent), Link (present vs. absent), and Interaction type (four options). Our software system enables adaptive experiments at various intelligent decision points in these modular dialogues.\n\nWe use contextual multi-armed bandit algorithms throughout numerous experimentation points to adapt the assignment of arms based on the collected data. The system captures various contextual variables to tailor messages according to users, such as user profiles, preferences, and interactions with the system during the intervention (Table  1 ). The coding of these variables can be adjusted as needed.\n\nRewards in the form of message ratings and link clicks are used to optimize content quickly. For instance, at the end of each message sequence, users rate the helpfulness of the\n\nVariable Type Description Mood & Energy Binary Takes 0 when users report Low or Medium levels, and 1 for High levels K10 Ordinal Based off of the Kessler Psychological Distress Scale. Bounded between 1 and 4. Recent Activity Last 48 hours"
    },
    {
      "title": "Binary",
      "text": "Takes 0 when user is inactive in the last 48 hours of receiving the message, and 1 if user interacts in any way with the system (e.g. types something, clicks on any link, etc).\n\nTable  1 : Some user contexts captured by the system (out of 12 total contextual variables).\n\nmessages on a scale of 1 to 5. The bandit algorithm also considers whether users click the embedded hyperlinks in the messages.\n\nThe bandit algorithm adapts the assignment of action variables based on the collected data. For example, it decides whether to provide a Rationale for introducing a psychological strategy, include a Link to web content, or select one of the four Interaction types. The system is designed to capture rewards of varying natures to enable rapid prototyping and testing of different rewards for different contexts."
    },
    {
      "title": "Algorithms for Adaptive Experimentation",
      "text": "The system supports a range of algorithms for adaptive experimentation, which dynamically update the assignment probability of each intervention based on the observed data. Below we describe the application of one of the algorithms.\n\nProblem Formulation Assuming an experiment over a horizon of size T , the problem is to choose a sequence of T actions {a t } t=1,...,T that maximize the expected cumulative reward over time E[ T t=1 r at (t)], with r at (t) being the reward associated to action a t at time t. One way to formalize the problem of dynamic decision-making about what type of message to deliver to whom is by using a contextual MAB problem  (Li et al. 2010; Agrawal and Goyal 2013) . In contextual MABs, the reward is conceived as a function of users' contexts, in addition to allocated arms, so it allows personalization as well. We formulate each dimension of the messaging protocol (framing, hyperlink, interaction type) as a separate intelligent decision point, so we solve three contextual bandit problems. Here, we illustrate the setup of a popular MAB strategy based on contextual linear TS  (Agrawal and Goyal 2013) .\n\nAlgorithm Suppose that the likelihood of the observed reward r i (t) of arm i at step t, given a context vector b i (t) \u2208 R d and the unknown parameter vector \u00b5 \u2208 R d , is given by a Gaussian model with mean b i (t)\u00b5 and stan- is N (\u03bc(t), v 2 B(t) -1 ), then the posterior at t + 1 is given by N (\u03bc(t + 1), v 2 B(t + 1) -1 ). In practice, at each step t, a sample \u03bc(t) is be generated from N (\u03bc(t), v 2 B(t) -1 ), and the i-th arm which maximizes b i (t) T \u03bc(t) is played."
    },
    {
      "title": "Evaluation of System",
      "text": "After extensive internal testing, we deployed this system with 50 participants (recruited from the MHA website) to undergo the eight-week intervention. The study was approved by the local university ethics board. This helped us design simulation scenarios and make adjustments to ensure data is being appropriately collected, and that the algorithms are adequately adapting the experiments. Based on data from pilot deployments, we illustrate the following simulated scenarios. The code to reproduce the following analysis is made publicly available 2 ."
    },
    {
      "title": "Simulation Settings",
      "text": "We generate each user's context randomly (with all possible values being equally likely). To resemble our realworld scenario, where the users' feedback rating has 5 levels (see Figure  1 ), we simulate reward values from R = {0, 0.25, 0.5, 0.75, 1}. The generating process involves first, generating a raw reward from a Normal distribution, and then rounding it to the closest value in R. We consider 'Rationale' framing (arm i = 1) versus 'No Rationale' framing (arm i = 0) arms, and context.\n\nScenario 1: No arm difference In this case, the rawreward r i (t) follows the same distribution for both arms and does not depend on the context: r i (t) \u223c N 0.5, (1/6) 2 , i = 0, 1.\n\nScenario 2: Substantial arm difference Here, we assume that arm i = 1 works better than the arm i = 0: r i (t) \u223c N 0.5 + 1/8 \u00d7 i, (1/6) 2 , i = 0, 1."
    },
    {
      "title": "Scenario 3: Optimal arm changes based on the context",
      "text": "We assume that the reward for each arm i = 0, 1 changes based on an interaction between arm and context. Denoting the interaction with * , this is given by:\n\n)\n\nwhere m t is the context variable assuming value of 1 if the t-th participant has a high mood, and 0 otherwise. According to our setting, when a participant has a high mood, the arm 'Rationale' has a higher expected raw reward (0.875 with 'Rationale' versus 0.5 with 'No Rationale'), while the opposite is true for participants with a low mood (0 with 'Rationale' versus 0.25 with 'No Rationale')."
    },
    {
      "title": "Simulation Analysis",
      "text": "For statistical analysis, the data collected can be used to run simulations of the algorithm's behavior if an experiment was 2  https://github.com/harsh-kumar9/bandit simulation run thousands of times. We present the Reward, False Positive Rate (FPR; the probability of a statistical test to incorrectly report an arm difference, when one does not exist), and Statistical Power (the probability of a test to correctly report an arm difference, when one exists). The hypothesis tests related to FPR and Power are conducted by sampling from the joint posterior distribution of the parameters of interest and estimating the 95% Confidence Intervals. Compared with traditional uniform random experimentation, these reveal the extent to which an algorithm's adaptive data collection increases, reduces, or has no effect on reliably detecting different kinds of effect -like whether or how much better an arm is or which arm is best based on a contextual variable.\n\nFrom Figure  2 , we see that Contextual TS can adapt to the data and lead to a higher reward than Uniform Random when there is a difference in the expected arm rewards. For people in a high mood, Contextual TS assigns most of them to the 'Rationale' arm, and gets 0.14 more average reward than Uniform Random; for people in a low mood, Contextual TS assigns the arm with 'No Rationale' more frequently.\n\nTable  2  shows the FPR results in our first simulation setting (Scenario 1). The FPR for Contextual TS is almost as good as the Uniform Random algorithm when the sample size is N = 100, and it increased to 0.07 when the sample size increases to N = 1000. This is because we chose a relatively uninformative prior, which forces Contextual TS to explore more and reduces FPR. Increasing the sample size, the effect of the prior is reduced, and an exploitative algorithm like TS may allocate the two arms unevenly, impacting statistical inference ability. However, a value of 0.07 may be regarded as a good trade-off given the higher average reward. This highlights how one could further reduce the FPR by using a wider confidence interval, or choosing a more uninformative prior -making the choice to give up some reward. Table 3: Calculation of Power for Scenario 2 (substantial difference between the arms) and 3 (optimal arm changes based on context).\n\nScenarios 2 and 3. In Scenario 2, when the sample size is small (N = 100), the Contextual TS algorithm has 15% less Power than Uniform Random. However, when the sample size is fairly large, Power is not much of a concern, as both approaches produce Power close to 1. In Scenario 3, where the reward is a more complicated function of 'Rationale' and 'Mood', the Contextual TS algorithm has good discovery rates on detecting effects in terms of 'Rationale' and the interacting effect 'Rationale * Mood'. The only drawback for Contextual TS, in this case, is its low Power on the single effect on 'Mood'. This occurs because Contextual TS assigns most people with a high mood to the arm 'Rationale' and those with a low mood to 'No Rationale' arm, increasing Reward for both groups, whereas UR more accurately evaluates the effect of Mood across both arms.\n\nThe data can also be used to understand the detailed behavior of an algorithm over time, and reveal violations of assumptions and interesting extensions based on the structure of the data, like unforeseen subgroups, non-stationarity, or correlations between observations. These simulations are an important part of the intervention design process. First, they help evaluate the effectiveness of adaptive algorithms for exploration-exploitation, such as MAB-based strategies, in terms of how they balance reward and rigor of statistical analysis. Second, when tuned for the specific intervention design problem, they serve as a foundation for fine-grained intervention design discussion between domain scientists, developers, and machine learning specialists, allowing exploration of multiple alternative adaptive experimentation scenarios in mental health even before data collection."
    },
    {
      "title": "Real-World Deployment",
      "text": "To evaluate the system and the intervention experimentally, we deployed the system with 1100 users recruited through an online ad on the MHA website in multiple batches. Each user consented to enroll in the 8-week program, where they received modular messages (visually represented in Figure  1 ) 2-3 times a week, as part of a larger text-message-based intervention.\n\nWe structure the analysis around two factors of the intervention, Rationale (present vs absent) and Link (present vs absent). Engagement For 8,521 total arm assignments, we received 813 ratings (9.54% engagement rate), contributed by 230 unique users (20.9% of total users). Overall engagement is low, as is characteristic of DMH interventions  (Gan et al. 2021) . To check if the engagement depends on the experimental arms, we analyzed the rate by arms (see Table  4  for the Link arm), observing no large differences."
    },
    {
      "title": "Efficiency of Policies",
      "text": "Table  5  shows the summary of data for the different factors and arms of the experiment. We observe an increase in Mean rewards for both levels of each factor for Contextual TS, compared to Uniform Random assignment.\n\nContextual Effects Checks on potential contextual effects are difficult in the early stages due to higher power requirements for detecting interactions, but they are still important.\n\nHere we present two summary analyses for promising contextual variables. In Figure  3   TS with Mood as a contextual variable was able to achieve a slightly higher average reward compared to Uniform Random. This corresponds to the results of one of the simulation scenarios we developed in the earlier stage of the analysis (Figure  2 ), contributing to the reinforcement of our hypothesis about the role of mood in moderating reactions. Figure  4  shows how Contextual TS adapts the assignments for Link vs No Link decisions based on users' interactions. For the Recent Activity variable, the effect is less pronounced for not recently active participants but observed for those recently active. One design decision to consider based on these results might be to revise the 48h cut-off or make it adaptive."
    },
    {
      "title": "Discussion and Conclusion",
      "text": "A key insight in the design of our system was to build flexibility in how algorithms are applied. First, in open source testbed where algorithms can be directly uploaded and used in production within days foot_2  . Second, in allowing for algorithms to flexibly adjust which reward and contextual variables are being used and how, with rapid redeployment. For example, the current reward for the Rationale bandit problem is the message rating provided by the user. However, other variables could be used as reward to optimize the messages. The system also allows for new arms to be added by the social-behavioural science design team, as the adaptive experiments reveal that some arms are less effective, as we scale to 5000 users.\n\nOur system provides a testbed for optimizing user experience in mental health while also facilitating critical analysis of algorithms, particularly understanding how algorithms balance reward maximization with data collection for statistical analysis. This places more emphasis on support- Each small square is one reward we receive with a fill color representing how helpful the participant found the message. In the Period 1, there was a marginally better response for \"No Link,\" leading to more allocations to this arm in Period 2. However, the algorithm was able to adjust based on responses, consistently allocating more interactions to the \"Link\" arm in periods 3-4.\n\ning domain scientists to answer socio-behavioral research questions and to draw conclusions that can be generalized to many future users, which is increasingly being emphasized in applications of bandit algorithms  (Yao et al. 2021) . There is a growing understanding in the behavioral science and policy communities that behavioral interventions require taking into account the heterogeneity of treatment effects  (Bryan, Tipton, and Yeager 2021) , including adapting to the contexts on the participant or situational level. This is also relevant for vulnerable and underprivileged populations, providing intervention designers with the tools to break the vicious circle of optimizing for the average participant. Future work can look into incorporating fairness metrics to evaluate the fairness of these algorithms when applied in a mental health setting  (Wang et al. 2022; Joseph et al. 2016; Huang et al. 2022) .\n\nWe showed how the algorithms trade-off optimization of reward (by giving the better arm on average or providing a personalized user experience) while collecting data that enables statistical inference. These just begin to scratch the surface of the complex real-world scenarios. Our system opens doors for future investigation of rewards that are dependent on multiple interactions between different action variables, between contextual variables, non-stationarity, when data are missing in different ways, and with repeated observations from the same person. The accompanying appendix to this manuscript is available online.  4"
    },
    {
      "text": "T and with\u03bc(t) = B(t) -1 t-1 \u03c4 b a\u03c4 (\u03c4 )r a\u03c4 (\u03c4 ) , ifthe prior at step tThe Thirty-Eighth AAAI Conference on Artificial Intelligence"
    },
    {
      "text": "Figure 2: Average rewards using Thompson Sampling for Contextual Bandits (Contextual TS) versus Uniform Random in different cases. The first pair of bars compares the reward in the group of participants having low mood, the second pair compares in high mood group, and the last pair takes the average among all participants."
    },
    {
      "text": "Figure3: Average reward (rating of 1 to 5 scaled) using Contextual TS versus Uniform Random for \"Link\" rating for different levels of contextual variables. FigureAshows the distribution for contextual variable Mood (Low vs High). Number of participants (N) from left to right is[322, 316, 83, 87]. FigureBshows the distribution for Activity in last 48 hours (Yes vs No). N from left to right are[67, 75, 338, 329]."
    },
    {
      "text": "Figure 4: Arm allocation dynamics for Contextual Thompson Sampling. Columns represent arms, and grid rows artificially split experiments by approximately one-month periods, allowing to compare arm allocation in different stages of the experiment.Each small square is one reward we receive with a fill color representing how helpful the participant found the message. In the Period 1, there was a marginally better response for \"No Link,\" leading to more allocations to this arm in Period 2. However, the algorithm was able to adjust based on responses, consistently allocating more interactions to the \"Link\" arm in periods 3-4."
    },
    {
      "text": "Table 3 summarizes the results for Power in simulation The Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)False Positive Rate (FPR) in simulation Scenario 1 where there are no differences between the arms."
    },
    {
      "text": "Response rate by arm for the factor \"Link\". We do not observe large differences between arms in terms of response rate"
    },
    {
      "text": "Overall summary of the rewards collected for the Link and Rationale factors."
    }
  ],
  "references": [
    {
      "title": "Developing and pretesting a text messaging program for health behavior change: Recommended steps",
      "authors": [
        "L Abroms",
        "R Whittaker",
        "C Free",
        "Mendel Van Alstyne",
        "J Schindler-Ruwisch"
      ],
      "year": 2015,
      "doi": "10.2196/mhealth.4917"
    },
    {
      "title": "Thompson Sampling for Contextual Bandits with Linear Payoffs",
      "authors": [
        "S Agrawal",
        "N Goyal"
      ],
      "year": 2013
    },
    {
      "title": "Preventive health behavior change text message interventions: a meta-analysis",
      "authors": [
        "A Armanasco",
        "Y Miller",
        "B Fjeldsoe",
        "A Marshall"
      ],
      "year": 2017,
      "doi": "10.1016/j.amepre.2016.10.042"
    },
    {
      "title": "Investigating the Role of Context in the Delivery of Text Messages for Supporting Psychological Wellbeing",
      "authors": [
        "A Bhattacharjee",
        "J Williams",
        "J Meyerhoff",
        "H Kumar",
        "A Mariakakis",
        "R Kornfield"
      ],
      "year": 2023,
      "doi": "10.1145/3544548.3580774"
    },
    {
      "title": "Social exclusion and mental health-how people with mental health problems are disadvantaged: an overview",
      "authors": [
        "J Boardman"
      ],
      "year": 2011,
      "doi": "10.1108/20428301111165690"
    },
    {
      "title": "Behavioural science is unlikely to change the world without a heterogeneity revolution",
      "authors": [
        "C Bryan",
        "E Tipton",
        "D Yeager"
      ],
      "year": 2021,
      "doi": "10.1038/s41562-021-01143-3"
    },
    {
      "title": "The multiphase optimization strategy (MOST) and the sequential multiple assignment randomized trial (SMART): new methods for more potent eHealth interventions",
      "authors": [
        "L Collins",
        "S Murphy",
        "V Strecher"
      ],
      "year": 2007,
      "doi": "10.1016/j.amepre.2007.01.022"
    },
    {
      "title": "The efficacy of smartphone-based mental health interventions for depressive symptoms: a meta-analysis of randomized controlled trials",
      "authors": [
        "J Firth",
        "J Torous",
        "J Nicholas",
        "R Carney",
        "A Pratap",
        "S Rosenbaum",
        "J Sarris"
      ],
      "year": 2017,
      "doi": "10.1002/wps.20472"
    },
    {
      "title": "Scaling multi-armed bandit algorithms",
      "authors": [
        "E Fouch\u00e9",
        "J Komiyama",
        "K B\u00f6hm"
      ],
      "year": 2019,
      "doi": "10.1145/3292500.3330862"
    },
    {
      "title": "Effect of engagement with digital interventions on mental health outcomes: A systematic review and meta-analysis",
      "authors": [
        "D Gan",
        "L Mcgillivray",
        "J Han",
        "H Christensen",
        "M Torok"
      ],
      "year": 2021,
      "doi": "10.3389/fdgth.2021.764079"
    },
    {
      "title": "Achieving user-side fairness in contextual bandits",
      "authors": [
        "W Huang",
        "K Labille",
        "X Wu",
        "D Lee",
        "N Heffernan"
      ],
      "year": 2022,
      "doi": "10.1007/s44230-022-00008-w"
    },
    {
      "title": "Fairness in learning: Classic and contextual bandits",
      "authors": [
        "M Joseph",
        "M Kearns",
        "J Morgenstern",
        "A Roth"
      ],
      "year": 2016,
      "doi": "10.1145/3278721.3278764"
    },
    {
      "title": "Meeting users where they are: User-centered design of an automated text messaging tool to support the mental health of young adults",
      "authors": [
        "R Kornfield",
        "J Meyerhoff",
        "H Studd",
        "A Bhattacharjee",
        "J Williams",
        "M Reddy",
        "D Mohr"
      ],
      "year": 2022,
      "doi": "10.1145/3491102.3502046"
    },
    {
      "title": "Exploring the Use of Large Language Models for Improving the Awareness of Mindfulness",
      "authors": [
        "H Kumar",
        "Y Wang",
        "J Shi",
        "I Musabirov",
        "N Farb",
        "J Williams"
      ],
      "year": 2023,
      "doi": "10.1145/3544549.3585614"
    },
    {
      "title": "A contextual-bandit approach to personalized news article recommendation",
      "authors": [
        "L Li",
        "W Chu",
        "J Langford",
        "R Schapire"
      ],
      "year": 2010,
      "doi": "10.1145/1772690.1772758"
    },
    {
      "title": "Natural language processing for mental health interventions: a systematic review and research framework",
      "authors": [
        "M Malgaroli",
        "T Hull",
        "J Zech",
        "T Althoff"
      ],
      "year": 2023,
      "doi": "10.1038/s41398-023-02592-2"
    },
    {
      "title": "Statistical consequences of using multi-armed bandits to conduct adaptive educational experiments",
      "authors": [
        "A Rafferty",
        "H Ying",
        "J Williams"
      ],
      "year": 2019,
      "doi": "10.1201/b10274-11"
    },
    {
      "title": "Simple bayesian algorithms for best-arm identification",
      "authors": [
        "D Russo"
      ],
      "year": 2020,
      "doi": "10.1287/opre.2019.1911"
    },
    {
      "title": "Digital mental health and COVID-19: using technology today to accelerate the curve on access and quality tomorrow",
      "authors": [
        "J Torous",
        "K Myrick",
        "N Rauseo-Ricupero",
        "J Firth"
      ],
      "year": 2020,
      "doi": "10.2196/18848"
    },
    {
      "title": "A survey on the fairness of recommender systems",
      "authors": [
        "Y Wang",
        "W Ma",
        "* Zhang",
        "M Liu",
        "Y Ma"
      ],
      "year": 2022,
      "doi": "10.1145/3547333"
    },
    {
      "title": "Power Constrained Bandits",
      "authors": [
        "J Yao",
        "E Brunskill",
        "W Pan",
        "S Murphy",
        "F Doshi-Velez"
      ],
      "year": 2021
    },
    {
      "authors": [
        "Pmlr"
      ]
    },
    {
      "title": "Off-policy evaluation via adaptive weighting with data from contextual bandits",
      "authors": [
        "R Zhan",
        "V Hadad",
        "D Hirshberg",
        "S Athey"
      ],
      "year": 2021,
      "doi": "10.1145/3447548.3467456"
    }
  ],
  "num_references": 23
}
