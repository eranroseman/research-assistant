{
  "paper_id": "Z3TWZ3LU",
  "title": "BioREx: Improving Biomedical Relation Extraction by Leveraging Heterogeneous Datasets",
  "abstract": "Objective: Biomedical relation extraction (RE) is the task of automatically identifying and characterizing relations between biomedical concepts from free text. RE is a central task in biomedical natural language processing (NLP) research and plays a critical role in many downstream applications, such as literature-based discovery and knowledge graph construction. State-of-the-art methods were used primarily to train machine learning models on individual RE datasets, such as protein-protein interaction and chemical-induced disease relation. Manual dataset annotation, however, is highly expensive and time-consuming, as it requires domain knowledge. Existing RE datasets are usually domain-specific or small, which limits the development of generalized and high-performing RE models. Methods: In this work, we present a novel framework for systematically addressing the data heterogeneity of individual datasets and combining them into a large dataset. Based on the framework and dataset, we report on BioREx, a data-centric approach for extracting relations. Results and Conclusion: Our evaluation shows that BioREx achieves significantly higher performance than the benchmark system trained on the individual dataset, setting a new SOTA from 74.4% to 79.6% in F-1 measure on the recently released BioRED corpus. We further demonstrate that the combined dataset can improve performance for five different RE tasks. In addition, we show that on average BioREx compares favorably to current best-performing methods such as transfer learning and multi-task learning. Finally, we demonstrate BioREx's robustness and generalizability in two independent RE tasks not previously seen in training data: drug-drug N-ary combination and document-level genedisease RE. The integrated dataset and optimized method have been packaged as a stand-alone tool available at  https://github.com/ncbi/BioREx .",
  "year": 2022,
  "date": "2022",
  "journal": "Briefings in Bioinformatics",
  "publication": "Briefings in Bioinformatics",
  "authors": [
    {
      "forename": "Po-Ting",
      "surname": "Lai",
      "name": "Po-Ting Lai",
      "affiliation": "a  National Center for Biotechnology Information (NCBI) , National Library of Medicine (NLM) , National Institutes of Health (NIH) , MD , 20894 , Bethesda , USA \n\t\t\t\t\t\t\t\t National Center for Biotechnology Information (NCBI) \n\t\t\t\t\t\t\t\t National Library of Medicine (NLM) \n\t\t\t\t\t\t\t\t National Institutes of Health (NIH) \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 20894 \n\t\t\t\t\t\t\t\t\t Bethesda \n\t\t\t\t\t\t\t\t\t MD \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Chih-Hsuan",
      "surname": "Wei",
      "name": "Chih-Hsuan Wei",
      "affiliation": "a  National Center for Biotechnology Information (NCBI) , National Library of Medicine (NLM) , National Institutes of Health (NIH) , MD , 20894 , Bethesda , USA \n\t\t\t\t\t\t\t\t National Center for Biotechnology Information (NCBI) \n\t\t\t\t\t\t\t\t National Library of Medicine (NLM) \n\t\t\t\t\t\t\t\t National Institutes of Health (NIH) \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 20894 \n\t\t\t\t\t\t\t\t\t Bethesda \n\t\t\t\t\t\t\t\t\t MD \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Ling",
      "surname": "Luo",
      "name": "Ling Luo",
      "affiliation": "b  School of Computer Science and Technology , Dalian University of Technology , 116024 , Dalian , China \n\t\t\t\t\t\t\t\t School of Computer Science and Technology \n\t\t\t\t\t\t\t\t Dalian University of Technology \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 116024 \n\t\t\t\t\t\t\t\t\t Dalian \n\t\t\t\t\t\t\t\t\t China"
    },
    {
      "forename": "Qingyu",
      "surname": "Chen",
      "name": "Qingyu Chen",
      "affiliation": "a  National Center for Biotechnology Information (NCBI) , National Library of Medicine (NLM) , National Institutes of Health (NIH) , MD , 20894 , Bethesda , USA \n\t\t\t\t\t\t\t\t National Center for Biotechnology Information (NCBI) \n\t\t\t\t\t\t\t\t National Library of Medicine (NLM) \n\t\t\t\t\t\t\t\t National Institutes of Health (NIH) \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 20894 \n\t\t\t\t\t\t\t\t\t Bethesda \n\t\t\t\t\t\t\t\t\t MD \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Zhiyong",
      "surname": "Lu",
      "name": "Zhiyong Lu",
      "affiliation": "a  National Center for Biotechnology Information (NCBI) , National Library of Medicine (NLM) , National Institutes of Health (NIH) , MD , 20894 , Bethesda , USA \n\t\t\t\t\t\t\t\t National Center for Biotechnology Information (NCBI) \n\t\t\t\t\t\t\t\t National Library of Medicine (NLM) \n\t\t\t\t\t\t\t\t National Institutes of Health (NIH) \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 20894 \n\t\t\t\t\t\t\t\t\t Bethesda \n\t\t\t\t\t\t\t\t\t MD \n\t\t\t\t\t\t\t\t\t USA",
      "email": "zhiyong.lu@nih.gov"
    }
  ],
  "doi": "https://doi.org/10.13039/100000092",
  "keywords": [
    "Biomedical natural language processing",
    "Biomedical dataset",
    "Transformers",
    "Transfer learning",
    "Multi-task learning"
  ],
  "sections": [
    {
      "title": "Introduction",
      "text": "Biomedical literature is the primary knowledge source of novel biomedical research results. The literature contains rigorous statistical results and biological evidence, which are typically simplified to the relations among entities. With the rapid growth of biomedical literature, processing data volume becomes increasingly feasible by using relation extraction (RE) techniques. RE identifies the pairs of entities involved in the relations and assigns granular relation types. It effectively transforms unstructured text into structured knowledge. An example of this process is shown in Figure  1 , which presents a portion of the abstract from PMID:31440061.\n\nIn this example, BRAF is a gene that normally regulates cell growth. However, a specific mutation in BRAF, known as V600E, can lead to uncontrolled cell growth, resulting in a tumor. Treating a tumor caused by the BRAF V600E mutation with a combination of the drugs dabrafenib and trametinib has been shown to inhibit or reduce tumor growth. The text essentially asserts the relations among the entities: BRAF V600E, tumor, trametinib, and dabrafenib. This exemplifies how RE can be utilized for performing literature-based discovery  [3] [4] [5] [6]  and knowledge graph construction  [6] [7] [8] .\n\nVarious RE methods include co-occurrence  [11, 12] , rule-based approaches  [14, 15] , supervised methods  [18, 19]  , and distant supervision  [22, 23] . As the most straightforward method, co-occurrence usually achieves high recall at the expense of precision. The method involves collection of the pairs of entities that co-occur in single sentences or documents. Rule-based approaches, in contrast, can achieve higher precision by delineating predicates within relations. It is very difficult, however, to generate robust rules to handle all cases, which results in lower recall. In the past decade, many manually curated RE datasets  [9, 10, 16, 24, 25]  have been developed for public usage, and machine learning (ML) and deep learning (DL) methods have been widely employed  [18, 19, [26] [27] [28]  to solve RE tasks (e.g., chemical-disease  [16, 29, 30] , chemical-protein  [9, [26] [27] [28] , protein-protein  [2, 13, 31] , drug-drug  [26] [27] [28] 32] , and diseasegene  [22, 29] ).\n\nMost RE datasets, however, contain only a single relation type, and these benchmark datasets are gathered from different annotation scopes. It is challenging and time-consuming to integrate different RE systems. For example, a protein drug in DrugProt  [9]  is categorized as a chemical, whereas AIMed  [2]  categorizes it as a gene product. Most systems were developed and validated on individual datasets, and this severely limited the development of generalized biomedical RE systems. In response, a new RE dataset, BioRED  [33] , was created, consisting of multiple relations (e.g., gene-disease) between some of the most important biomedical concepts (e.g., gene, disease, and chemical). The dataset was successfully used by the recent NIH LitCoin NLP Challenge  1  . Although BioRED is rich in relation types and has a broad annotation scope, it currently contains annotations of only 600 PubMed articles. Its portability and generalization abilities require further studies.\n\nThere has been some research  [34] [35] [36]  on transfer learning (TL) and multi-task learning (MTL) for biomedical RE tasks. TL pretrains the language model on large datasets and fine-tunes the model in downstream task(s). As a result, downstream tasks benefit from the pre-trained language model (PLM), which has learned domain-specific neural networks, and can focus on tuning the task-specific neural parameters. In contrast, MTL involves many related tasks simultaneously and improves overall generalization, and MTL makes no distinction among the different tasks. Using these approaches, TL and MTL aggregate external data and eliminate the sparsity problem of small tasks.\n\nThis work proposes a method to improve the performance of all kinds of relation extraction tasks over state-of-the-art performance. Different from TL and MTL, a data-centric approach is proposed that harmonizes the annotation differences between data sources and integrates them to construct a rich dataset with sufficient quantity. Recognizing the nature of different annotation scopes in the existing datasets, we propose a harmonization framework for effectively improving the consistency of different annotations. The main contributions of our work can be summarized as follows:\n\n(1) We propose a framework that can systematically integrate heterogeneous annotations into one largescale dataset despite a diverse annotation scope and guidelines (e.g., relation annotations with or without entity spans).\n\n(2) Our proposed approach, which is BioREx, results in a large training set for developing generalized RE systems. Using our combined dataset, higher performance is achieved compared with TL, MTL, and that of models trained on the individual datasets.\n\n(3) Our results show that the pre-trained model built on the merged dataset is robust and generalizable through its applications to two new RE tasks that were not previously studied.\n\n(4) Both the merged dataset and trained model are made freely available to the research community."
    },
    {
      "title": "Related works"
    },
    {
      "title": "Multi-task Learning for Relation Extraction",
      "text": "Multi-task learning (MTL) focuses on jointly learning different tasks. This is typically achieved through\n\n(1) a shared representation, which encodes different tasks into the same semantic space and (2) a sum of the losses from individual tasks, where the model's weights are updated using backpropagation against the combined losses obtained from each task in a batch.\n\nIn NLP, for instance, Zhao et al  [37] , Wiatrak et al  [38] , and Zhou et al.  [39]  successfully applied MTL to jointly learned Named Entity Recognition (NER) and entity linking tasks. Some studies have also explored MTL across NER and Relation Extraction (RE) tasks. Eberts et al.  [40]  proposed a transformerbased approach to jointly train NER and RE on the adverse drug effect (ADE) dataset  [41] , reporting promising results. However, it is important to note that even when these MTL studies are applied to different tasks, the annotations used still come from a single corpus.\n\nAlternatively, MTL can be applied to a single NLP task using multiple corpora. Peng et al  [36]  demonstrated the effectiveness of this approach by learning jointly from eight different corpora spanning four different tasks and demonstrating significant improvements in all four tasks. However, they expressed concerns about the application of heterogeneous datasets to the task of relation extraction. As an example, the CDR corpus, which is a document-level chemical-disease relation extraction dataset, may not be suitable for the sentence-level drug-drug interaction  [10] , chemical-protein relation  [42]  tasks."
    },
    {
      "title": "Document-level and N-ary Relation Extraction",
      "text": "Document-level RE identifies and classifies relations between multiple entity pairs within a single document  [16, 22, 33] . In contrast to sentence-level RE  [9, 10] , which identifies and classifies relations for only one entity pair in each sentence, document-level RE requires the model to identify and classify relations for every entity pair in the document. Pairs can be related across multiple sentences. This task challenges the identification of relevant context for each entity pair. It has received attention in both the general and biomedical domains recently. Common approaches for document-level RE, like treating different pairs as individual instances, and applying deep learning models for classification  [30] . To obtain relation labels, some studies aggregate the entity-level and document-level representations and feed them into a classifier  [43] . Adaptive Transfer Learning with Local Context Pooling (ATLOP)  [29]  is an approach that leverages local context pooling to differentiate the same entity embedding across various entity pairs. It improves entity embedding by incorporating additional context relevant to the current entity pair. By transferring attention heads PLM to entities, ATLOP captures each entity's attention. Furthermore, it combines the attentions of both entities to identify the context that holds significance for both. This process enables ATLOP to enhance entity representation by incorporating relevant contextual information. ATLOP is evaluated on both general, DocRED dataset  [44] , and biomedical domains, BC5CDR and RENET  [22]  datasets. RENET is a large-scale distant supervision dataset that uses PubTator's annotations and handannotated disease-gene tuples in DisGeNet  [45] , with approximately 31,000 abstracts of disease-gene associations, and 1,000 manually re-annotated abstracts are used for evaluation.\n\nOn the other hand, Tiktinsky et al.  [46]  developed a drug combination dataset for RE. It is intended to assist in the identification of effective combinations of therapies for diseases such as cancer, tuberculosis, malaria, and HIV. The set contains 1600 manually annotated abstracts mentioning between two and fifteen drugs. In the dataset, 840 abstracts have one or more positive drug combinations ranging from two to eleven drugs. There are 760 abstracts that either mention drugs that are not used in combination or discuss combinations of drugs that do not provide a positive result when used together. As a basis for further research and improvement, a PubMedBERT baseline model is developed to identify effective drug combinations. A co-occurring sentence was used to select drug subsets as instances for prediction, and greedy heuristics and unions were used to determine the final N-ary drug combination."
    },
    {
      "title": "Material and methods"
    },
    {
      "title": "Workflow of BioREx",
      "text": "We propose a harmonization framework for unifying different datasets into one via addressing their heterogeneity. Figure  2  illustrates our workflow, which consists of four steps. The first step is to determine the target relation extraction task. As a case for this study, we chose BioRED, which focuses on the relations between genes (proteins), variants, diseases, and chemicals. As previously defined in BioRED, we continued to explore the eight relation types (positive correlation, negative correlation, association, bind, drug-interaction, co-treatment, comparison, and conversion). Further, entities with interchangeable names are combined (e.g., gene products are grouped together with genes, drugs are grouped with chemicals, phenotypes are grouped with diseases). Moreover, we simplified the BioRED task by merging variants and genes into a single concept and their relationships accordingly, as the mutated genes are much more frequently searched in PubMed as compared to the variants.\n\nThe second step is to collect datasets relevant to user research interests and benchmarking tasks. There are eight relevant datasets selected for the BioRED task in total, including corpora and repositories. Text corpora are collections of texts with manually curated entities and the relations between them. The relations are typically at the mention level. In contrast, a repository contains a list of relations at the document level.\n\nFor example, in the CTD repository  [47] , relation triples, such as <entity1, entity2, PMID>, consist of gene, disease, and chemical entities with PMID, but no mention level annotations are provided. In addition, full text versions can be used to curate relations. In the third step, we systematically adjust the datasets to a uniform format by using our procedure, enabling them to be merged with BioRED. In the fourth step, we formulate the RE task as a classification problem for each relation pair. The fifth step involves training a deep learning classifier using a state-of-the-art BERT-based pre-trained language model (PLM). In the last step, the well-trained model can be applied to the new articles for relation extraction."
    },
    {
      "title": "Data collection",
      "text": "We summarized most of the existing RE datasets in the supplementary material (Table  S1 ). In our observation, it is more difficult for some to be integrated into a large RE dataset due to several issues:\n\n(1) Not fully annotated: As shown in Table  S1 , some datasets were built by the automatically extracted entities and relations. Certain studies refined those automatic results but did not curate the entities or pairs from scratch. Lower annotation consistency or a lack of annotation guidelines could result in negative effects if we integrated these datasets with other datasets.\n\n(2) Specific scope: Some datasets focus on specific subsets of granular entity and relation types and do not annotate all entities and relations. For example, ADE  [41]  annotates the relations among drug, dosage, and adverse effect but only partially matches the scope of chemical, disease, and their relations in BioRED. To avoid the mismatch of scopes that may result in an inter-dataset annotation inconsistency, we do not use certain datasets.\n\n(3) No entity spans: Many repositories and a few datasets do not include relation entity spans. Based on our procedure, the automatic annotation of PubTator  [48]  should be applied to complement the entity spans. PubTator's annotation, however, is not entirely accurate. Specifically, ML and DL models may be confused by a missed or incorrect annotation.\n\nTo enhance the consistency of the integrated dataset, we first chose the datasets (i.e., AIMed  [2] ,\n\nDrugProt  [9] , DDI  [10] , HPRD50  [13] , and BC5CDR  [16] ) that are relatively free from the above issues due to clear guidelines and well-defined entities. Due to lack of a publicly available dataset for the <G, D> relation, we collected EMU  [17]  in the dataset pool and DisGeNet  [45]  repository. In addition, we include PharmGKB  [20]  to support the <G, C> entity pairs that still have room for improvement."
    },
    {
      "title": "Data adjustment procedure",
      "text": "Each dataset is characterized by its annotation scope and guidelines. For example, a relation pair annotated within the same sentence is a common occurrence; however, only a few datasets allow for crosssentence relations. In addition, some datasets map the entities to specific concepts in controlled vocabularies (e.g., MESH  [49] ), while others do not. To integrate datasets into one dataset, we identify the characteristics of the datasets and define five categories of characteristic diversity. Five solutions are provided to adjust the different datasets as shown in Table  1 . The details of the adjustment solution for the eight datasets are illustrated in Table  2 .\n\n(a) With entity span: In some datasets, such as repositories, the spans of entities are not provided.\n\nHowever, these spans are essential for training the RE model. To address the gap, we used both the dictionary match approach and the automatic annotation by PubTator  [48]  to map the corresponding spans of those entities into the dataset entities. As some of the entities cannot be found in the automatic annotations, we retained only those relations with spans found in the text. For example, the annotation from repositories, such as PharmGKB, is curated by reading full text versions. In that case, we retained only the relations with the associated spans in the same abstract sentence accordingly.\n\n(b) Document-or sentence-level: This category distinguishes datasets by the context range of the association evidence. Relation datasets can be roughly divided into two levels, document-and sentence-levels, according to their annotations. (1) Document-level: The relation entities are allowed to appear across sentences, and their spans need to be given in the sentences. (2) Sentence-level:\n\nThis level requires the entity pair and its evidence to co-occur in a single sentence. Typically, such datasets do not map entity spans to concept identifiers. Depending on the context range, which can be at the sentence-level or document-level, we delimit the input text to the corresponding sentence (or the document) as required. Because repository annotations are more reliable due to manual curation, we considered them sentence-level annotations.\n\n(c) Negative or unannotated relations: Some datasets focus on only a specific scope of a relation pair.\n\nFor instance, BC5CDR  [16]  annotates the chemical-induced disease relation but not the treatment.\n\nThese unannotated pairs are not necessarily negative (i.e., they don't definitively lack the relation), they're simply unannotated, and thus it would be incorrect to mark all of them as negatives. To more effectively utilize annotations in this case, we assigned a specific relation type to the pairs that were not curated (e.g., \"None-BC5CDR\" for BC5CDR). Certainly, if the dataset annotates all the relations in the target entity pair, the specific relation type is not required for those unlabeled pairs.\n\nBesides, some datasets do not annotate all the relations in the text, such as the repositories (e.g., PharmGKB). In this case, we do not use those unannotated pairs as negative cases.\n\n(d) Granular relation type defined (Y/N): Some datasets focus on specific concept pairs (e.g., DrugProt focuses on the chemical-gene pair), with multiple granular relation types (e.g., inhibition).\n\nThe adjustment solution to utilizing those annotations is to manually map the granular relation types types cannot be mapped to any type in BioRED, the relations will be considered \"Association.\"\n\n(e) Entity definition of the target dataset: Different datasets may define the same concept differently.\n\nFor example, a protein drug in DrugProt is categorized as a drug, whereas BioRED categorizes it as a gene product. For these chemicals in DrugProt, we assigned a specific entity type (i.e., \"DrugProt-Chem\" instead of \"Chemical\"). A dataset can be merged without changing the types of entities if the entities match the BioRED.\n\nWe adjusted each dataset according to its own annotation characteristics. The selected datasets and the corresponding adjustments are shown in Table  2 . For example, AIMed is a sentence-level dataset of protein-protein interaction (<G,G>). All of the text spans of the mentioned proteins in the sentence are annotated even though some are not asserted in a relation. Further, no granular type was annotated in AIMed. Based on these characteristics, we modified the AIMed accordingly: (a1) AIMed provides entities involved in relations; thus, no automatic entity annotation is needed. (b2) AIMed is a sentence-level dataset.\n\nHence, we use the sentence with the co-occurring relation entities as the input. (c1) We generated a specific relation type, \"None-AIMed,\" for those pairs that were not annotated in AIMed. (d2) Because no granular type was annotated to the relations in AIMed, we simply set all the relation pairs as \"Association.\" (e2) The concept definition of the AIMed is the same as the \"Gene\" concept in BioRED, which we use consistently."
    },
    {
      "title": "Deep learning model for relation extraction",
      "text": "In this section, we first introduce how we formulate the RE problem. We then present our deep learning method. 0.6 \u2026 [CLS] and [SEP] \u2026 <D>anxiety</D> <G>beta-adrenergic receptors</G> Binding Conversion Comparison Association Positive_correlation Negative_correlation Drug_interaction Co-treatmnet No relation 0.0 0.2 0.0 0.0 0.0 0.2 0.0 0.0 Confid. anxiety beta-adrenergic receptors Association Type \u2026 \u2026 \u2026 \u2026 Pre-trained Language Model\n\n[CLS] What is the relation in BioRED between <D>anxiety</D> and <G> betaadrenergic receptors </G> ? [SEP] These results indicate that noradrenergic signaling via <G>beta-adrenergic receptors</G> is required for cocaine-induced <D>anxiety</D> in mice . The confidence scores of the classification output depend on the state of the PLM's [CLS] token. In order to obtain the confidence scores for each class, the fixed-length representation of the [CLS] token is fed into a linear layer followed by a softmax activation. A prediction for the text sequence is based on the class with the highest probability. For our implementation, we chose PubMedBERT [28] as our default PLM. The output of the model provides the confidence of the correlation types (or no relation). The type with the highest confidence becomes the predicted output."
    },
    {
      "title": "Approaches for comparison",
      "text": "To evaluate BioREx's effectiveness, we compare BioREx with two other deep learning configurations.\n\n(1) Transfer learning (TL): We trained the BERT model on the external datasets and then fine-tuned it on the training set of the evaluated task. (2) Multi-task learning (MTL): We consider different RE datasets as individual tasks using the multi-task learning approach  [36]  as depicted in Figure  4 . In MTL, the distinguishing of different tasks does not rely on prompts. Instead, all datasets are combined and instances are randomly arranged. In this approach, the [CLS] tag is used as the representation fed into all tasks. In this approach, the [CLS] tag is used as the representation fed into all tasks. The [CLS] tag serves as a shared representation across the different tasks where each task has its own task-specific output layers. This enables the model to capture and leverage the underlying information from each task without task-specific prompts. By using this uniform representation, MTL addresses multiple tasks simultaneously. Furthermore, we evaluated the portability of our model, which was trained on BioRED along with all eight external datasets (BioRED+8 datasets). As shown in Figure 5, we fine-tuned the BERT model on the adjusted BioREx training set using the architecture described in section 3.4. Subsequently, the fine-tuned BERT model was adapted to Tikinsky et al.'s and ATLOP's source code implementations for drug combination Nary and RENET tasks, respectively. This experiment is crucial to validate the BioREx's adaptability to different RE system architectures."
    },
    {
      "title": "Results",
      "text": "To demonstrate the advantage of our data-centric method for improving RE tasks, we design three which was trained on BioRED plus all external datasets (BioRED+8 datasets). The experiment evaluates the robustness and generalizability of the BioREx model by using two different tasks not previously seen in training data: N-ary  [46]  and RENET  [22] ."
    },
    {
      "title": "Performance on the BioRED task",
      "text": "In this experiment, we evaluate how external datasets improve BioRED performance. As seen in Table  3 , the PubMedBERT model trained on the BioRED training set is set as the baseline (Original). We evaluated the performance on the BioRED test set by leveraging external datasets via the three configurations (i.e., TL, MTL, and BioREx).\n\nTo evaluate the effects of external datasets, we developed the models using the BioRED training set and the external datasets individually. The three datasets (i.e., DisGeNet, PharmGKB, and EMU) cannot be integrated into the TL and MTL training sets due to the lack of entity spans. We conduct a pairwise t-test to determine whether there is a significant difference in the mean F-score of the two models. As we expected, TL, MTL, and BioREx outperform the baseline with p-values of 0.029, 0.002, and 0.001, respectively. In addition, the model trained on the adjusted datasets (BioREx) performed better than did TL and MTL for most of the relation pairs, except for MTL, which is slightly higher than BioREx in BioRED+DDI and BioRED+AIMed.\n\nWe analyzed Table  3  results, and carefully examined some cases where MTL produced true positives Additionally, we also examined the instances where BioREx generated TP but MTL produced FN/FP within the BioRED+HPRD50 and BioRED+DrugProt datasets. We found that the majority of these instances were low-frequency pairs, where at least one entity appears only once in the abstract. BioREx identified these pairs correctly, while MTL did not. Consequently, we evaluated the identification of lowfrequency pairs across the entire BioRED test set. The results revealed that Original, TL, MTL, and BioREx PharmGKB is a repository with manual annotation from full text, which means some of the annotations exist in the full text but not in the abstract. In addition, not all the relations in an article are recorded in PharmGKB.\n\nFinally, we trained the models using the training set of BioRED plus all external datasets (BioRED+8 datasets) in the three configurations. BioREx achieved the highest performance (79.6% in F-score), which is above 2-3% of other methods. Compared to TL and MTL, BioREx is higher than theirs by F-scores of 2.0% and 1.6%, respectively. Further statistical results, however, show that improvement did not pass the significant statistical test with p-values (TL vs. BioREx: 0.4; MTL vs. BioREx: 0.89). By our observations, the harmonization procedure reduced the heterogeneity between datasets and is able to integrate those into a large dataset.\n\nWe have conducted an analysis of the errors made by the TL models trained on the BioRED+DDI and BioRED+AIMed datasets. These errors specifically pertain to relation pairs that were correctly recognized by the original model. Upon reviewing the missed relation pairs, we observed that the entities involved in these pairs often co-occur within the same sentence. However, the evidence statements supporting these relationships are not explicitly stated. As we observed, corpora have different curation criteria, such as the DDI dataset not annotating co-treatment relations between drugs. Without using the harmonization procedure to reconcile the discrepancy of the annotations, the transfer learning process may not yield a reasonable result. We are actively working to address these issues and improve the performance of our models."
    },
    {
      "title": "Performance on individual datasets by leveraging BioRED dataset",
      "text": "In the previous experiment, we demonstrate that the proposed procedure leverages external datasets to improve performance on the BioRED task. We are interested in determining whether BioREx can be applied to other tasks. Here, we focus on the five benchmark datasets that provide the entity spans in the texts. We used BioRED as an external dataset to support individual tasks. For each task, a model was first trained and evaluated on the target dataset (e.g., DDI). Based on the three configurations, we developed three models and tested them on the test sets for each dataset. In addition, we compared the models with SOTA approaches  [29, 33, 50] . Our configurations are compared to the BioRED benchmark result. In BC5CDR, we compare the configurations with ATLOP  [29] , which does not use any additional postprocessing. As a result of our procedure, DrugProt and DDI relation types were combined into BioRED relation types, which makes us unable to compare our configurations with SOTA  [9, 51]  directly. Further, AIMed and HPRD50 do not have formal partitions for training and testing. Therefore, we follow most studies by using 10-fold cross-validation to evaluate different configurations (Target dataset, TL, MTL, and BioREx). Note that some of the datasets (e.g., PharmGKB) do not annotate all the relations in the articles, which means that we were not able to locate those entity pairs that are not in the relations. Therefore, we omitted those datasets in this experiment.\n\nAs an example of the evaluation of the AIMed dataset, the model training on its training set obtained an F-score of 82.4%. Once the two datasets are merged with adjustments, the model presents a reliable performance on both test sets, which are both higher than the baselines (82.4% to 84.9 % in AIMed test set   4 ) and 78.1% to 81.5% in BioRED (Table  3 )). The three other models do not achieve better than BioREx. Despite all models' having improvements over the baseline, statistical significance is not achieved;\n\nthe p-values are 0.37, 0.15, and 0.06 for TL, MTL, and BioREx, respectively. Both MTL and BioREx outperform the baseline with p-values of 0.045 and 0.044, respectively.\n\nAs we expected, the performances of TL and MTL are both improved; but they are still 1.3% and 0.8% lower in F-scores on average compared to our approach. Table  4  shows how important consistency between datasets is to performing multiple tasks."
    },
    {
      "title": "Evaluating the robustness and generalizability of pre-trained language models",
      "text": "To demonstrate the robustness and generalizability of our pre-trained models, we chose two RE tasks, N-ary  [52]  and RENET  [22] , that have not been studied in BioRED or the other eight datasets. To demonstrate the portability of our PLMs, we used Tiktinsky et al.'s  [52]  and ATLOP  [29]  state-of-the-art implementations for the N-ary and RENET datasets, respectively.\n\nDrug combination relations in the N-ary dataset: We followed the experiment in the N-ary study  [52] ,  As shown in Table  5 , the state-of-the-art (SOTA) result was achieved by the proposed method in  [52] , using\n\nPubMedBERT as the PLM. Therefore, we retrained the model, using their open-source implementation  [52]  and replaced PLM with BioRED and BioREx pre-trained models. As can be seen, the BioREx model outperforms the baseline (PubMedBERT) by 1% and 5% in the Positive and Any Combinations, respectively.\n\nGene-disease association in the RENET dataset: Other than the relations and no-relations of the diseasegene pairs in the RENET dataset, RENET dataset categorized the semantically ambiguous pairs into ambiguous relations. We applied the proposed method, which uses ATLOP  [29]  with the default PLM of SciBERT  [53] . We further applied ATLOP, using our pre-trained models (BioRED and BioREx PLMs). As shown in Table  6 , the configuration of ATLOP trained on the BioREx PLM presents the highest performance."
    },
    {
      "title": "Discussion",
      "text": "To demonstrate the effectiveness of our method on smaller datasets, we conducted an evaluation on the models trained using varying sizes of BioRED dataset, which is included in the supplementary materials (Experiment A). Our findings indicate that our approach has the capability to leverage the external datasets to build dependable training data with minimal annotation requirements.\n\nWhile BioREx has exhibited encouraging results for relation extraction, its performance is far from perfect. To gain a deeper understanding of remaining challenges, we examined the results of the BioRED test set, with particular emphasis on the findings of the most effective model (BioREx). Through a random selection process, we analyzed 40 instances of errors and have subsequently presented the distinguishing features of these cases. It is worth noting that some errors may demonstrate more than one attribute.\n\nThe primary category of error (83%) is associated with low-frequency entities featured in the abstract.\n\nMost of these errors involve at least one entity that has been mentioned only once in the abstract. For instance, in the abstract of PMID:15485686, it states, \"These findings suggest that the Na(v)1.5/V1763M channel dysfunction and possible neighboring mutants contribute to a persistent inward current due to altered inactivation kinetics and clinically congenital LQTS with perinatal onset of arrhythmias that responded to lidocaine and mexiletine.\" Here, there is a gene-disease association <Na(v)1.5, arrhythmias, Association> in the last sentence of the abstract. However, the association description is not explicit in the context, and \"arrhythmias\" appears only once in the abstract. As a result, BioREx fails to identify this pair, leading to a false negative. Among the errors, 63% have been classified as false negatives, while 20% are identified as false positives. These error cases frequently do not pertain to the key relations elaborated in the abstract, Consequently, BioREx is unable to extract the necessary information to accurately classify these pairs, leading to their classification as no relation instances.\n\nThe second type of error (30%) pertains to the absence of sentences where entities co-occur. In BioRED, there are approximately 15% of relations that lack co-occurring sentences, rendering them more challenging to extract. Due to the lack of supporting co-occurrence evidence, BioREx is inclined to predict these cases as no relational instances. Aomng these errors, 22.5% are classified as false negatives, while 7.5% are predicted as false positives. For example, in PMID:18503483, it states, \"MRI demonstrated hyperintense T2 signals in the cervical cord and right brachial plexus roots indicative of both myelitis and right brachial plexitis. Symptoms persisted for three months despite TAC dose reduction, administration of IVIG and four doses of methylprednisolone pulse therapy.\" In this case, the disease \"brachial plexitis\" and the chemical \"methylprednisolone\" do not have any co-occurring sentence in the abstract. Based on the context, BioREx predicts an \"Association\" between them, but since the relation is not annotated in BioRED, it leads to a false positive case.\n\nThe last category of errors (13%) encompasses a set of challenging error types that defy simple categorization. These errors involve co-occurring entities that are mentioned multiple times in the text. For example, PMID:18457324 entitled \"Genetic polymorphisms in the carbonyl reductase 3 (CBR3) and the NAD(P)H:quinone oxidoreductase 1 (NQO1) genes in patients who developed anthracycline-related congestive heart failure after childhood cancer,\" the paper primarily discusses the gene expression of congestive heart failure (CHF) patients who had childhood cancer. Although the term \"cancer\" occurs multiple times in the abstract, there is no association between \"cancer\" and those genes related to CHF.\n\nHowever, BioREx incorrectly predicts them as positive instances. Consequently, 7.5% of these errors are erroneously classified as positive instances, while 5.5% are inaccurately classified as negative instances.\n\nWe further observed the errors of the results and realized that most remaining errors are due to two main challenges. First, a significant p-value or genomic evidence may be required to demonstrate the relation.\n\nThus, the genetic and statistical evidence of the relation frequently comes from multiple sentences, which causes the largest portion of errors. Second, a difficulty arises when some of the relation statements (e.g., previous studies) can be overturned by following sentences (e.g., the authors present an interesting finding that conflicts with the initial assumption of the related study)."
    },
    {
      "title": "Conclusions",
      "text": "Using BioREx to integrate diverse datasets within different relation topics (e.g., gene-gene and chemical-disease relations) and criteria (e.g., sentence-and document-levels), the new model performs better than do the models trained on the individual dataset. Many available bioconcept relation resources have emerged during the past decade. This study proposed a procedure to improve the consistencies of the heterogeneous datasets and further optimize the performance. As in the case study on the N-ary and RENET datasets, we obtained a promising result, which demonstrated the possible usage to other RE tasks. To support other tasks, we have released the adjusted union dataset and the well-trained model for stand-alone usage. In the future, we will use BioREx on other repositories (e.g., CTD  [47] ) and further apply it to largescale data, such as entire PubMed abstracts and PMC full-text versions."
    },
    {
      "title": "Supplementary Material Experiment A: The performance of BioREx using partial BioRED data",
      "text": "Because it is time-consuming and costly to create a multi-relation dataset, such as BioRED, the results of the previous experiments suggest that using our approach may effectively decrease the need for manual data annotation.\n\nWe conducted an experiment using different BioRED subsets to determine whether leveraging external datasets can achieve a similar (or better) performance compared to the original data. 59.1% 64.1% 72.0% 74.0% 74.4% 68.4% 72.4% 75.8% 77.8% 79.6% 50% 55% 60% 65% 70% 75% 80% 85% 100 200 300 400 500 F1-score # of used docs in BioRED BioRED BioRED + 8\n\nWe further compared the performance and efficiency of different PLM models. We chose five well-known pre-trained models for the comparison, including PubMedBERT  [1] , BioELECTRA  [2] , Bioformer  [3] , BioBert  [4]  and Roberta  [5] . As shown in Table  1 , we evaluated the final performance using the merged training set of BioRED with the eight corpora. PubMedBERT achieved the best performance, but Bioformer presents much more efficiency than do other models with close performance, as it is about two times faster on training and processing steps. Even though PubMedBERT achieved slightly higher performance than did Bioformer, Bioformer is more efficient than is PubMedBERT, which is an impressive advantage for processing large-scale data (e.g., entire PubMed abstracts, PMC full-text versions). Table S1. Existing relation corpora and the available relations. The event detection corpora (e.g., BioNLP share task) are not listed below. G: Gene/Protein/Variant, C: Chemical/Drug, and D: Disease/Phenotype. Dataset # Doc./Sent. SEN/DOC Relation Not fully annotated (\u00a5) Specific scope ( \u2020) Span is not provided ( \u2021) Not available (\u00d7) <G,G> <G,C> <C,C> <G,D> <C,D> BioRED [6] 600 abstracts Document \u2022 \u2022 \u2022 \u2022 \u2022 AIMed  [7]  230 abstracts Sentence \u2022 HPRD50  [8]  50 abstracts Sentence \u2022 DrugProt  [9]  & ChemProt  [10]  5,000 abstracts Sentence \u2022 DDI  [11]  905 abstracts Sentence \u2022 RENET2  [12]  500 full texts Document \u2022 \u00a5 Not fully annotated RENET  [13]  30,192 abstracts Document \u2022 \u00a5 Not fully annotated EU-ADR  [14]  300 abstracts Sentence \u2022 \u2022 \u2022 \u00a5 Not fully annotated N-ary dataset  [15]  1,634 abstracts Sentence \u2022 \u2020 Drug combination ADE  [16]  2,972 abstracts Sentence \u2022 \u2020 Dose relation BRONCO  [17]  108 full texts Document \u2022 \u2020 Genetic relation BC5CDR  [18]  1,500 abstracts Document \u2022 \u2020 Induce relation BioCreative VI PM  [19]  5,509 abstracts Document \u2022 \u2020 Genetic relation PGxCorpus  [20]  945 sentences Sentence\n\n\u2022 \u2022 \u2022 \u2020 Phenotype relation EMU [21] 110 abstracts Document \u2022 \u2020 Variant relation \u2021 Entity spans are not provided PharmGKB [22] --\u2022 \u2021 Repository DisGeNet [23] --\u2022 \u2021 Repository CTD [24] --\u2022 \u2022 \u2022 \u2021 Repository GWAS [25] --\u2022 \u2021 Repository BindingDB [26] --\u2022 \u2021 Repository BioInfer[27] 1,100 sentences Sentence \u2022 \u00d7 LLL[28] 167 sentences Sentence \u2022 \u00d7 IEPA[29] 300 abstracts Document \u2022 \u00d7 BioCreative II PPI IPS [30] 1,098 full texts Document \u2022 \u00d7 BioCreative II.5 IPT [31] 122 full texts Document \u2022 \u00d7 n2c2 2018 ADE[32] 505 summaries -\u2022 \u00d7"
    },
    {
      "text": "Figure 1. Example of the relations (middle) in the text (left) and the extracted knowledge (right)."
    },
    {
      "text": "Figure 2. Workflow of our approach."
    },
    {
      "text": "We defined a relation candidate instance that contains a pair of biomedical entities and their context of co-occurrence. A few datasets, such as BioRED and BC5CDR, annotate relations at the document level. Such datasets annotate all spans of the same entity, which may appear multiple times. In addition, if an entity span contains two or more entities (e.g., \"breast or ovarian cancer\" contains both MESH:D001943 and MESH:D010051), the relation with this span must be expanded to two (or more) instances. Each instance requires that two entities belong to unique IDs individually. We treat RE as text classification, which aims to classify the instance into a pre-defined RE relation type or no relation (\"None\").Deep learning model:The architecture of the model of BioREx is illustrated in Figure3. For each instance, two boundary tags are inserted at the beginning and the end of the entities (e.g., <D> and </D> for diseases). We also added those tags to the vocabulary of the PLM to ensure that the tags are not separated into multiple tokens. In addition, we further constructed a prompt question to provide contextual guidance to the model for its corresponding pair and the RE task. The prompt question, likes \"[CLS] What is the relation in [Corpus] between <entity1> and <entity2>?\", is appended at the beginning of the input text to emphasize the two entities in a pair (<entity1> and <entity2>) and the RE task ([Corpus]). [Corpus] is the specific task name for various tasks, such as \"DrugProt.\" \"BioRED\" is the default of the [Corpus], and we used it for the BioRED task."
    },
    {
      "text": "Figure 3. Architecture of the BioREx model on a relation extraction task."
    },
    {
      "text": "Figure 4. An example of multi-task learning (MTL) approach."
    },
    {
      "text": "To demonstrate that BioREx can be used to improve the performance on a BioRED task, we train the model by using different training set combinations and evaluate the model on the BioRED test set. (2) To show the generalizability of BioREx on other datasets, we use BioRED as an external dataset for five different RE tasks. (3) To enhance the portability of our work, we release the language model (LM),"
    },
    {
      "text": "Figure 5. Evaluate the BioREx model using other tasks and open source systems."
    },
    {
      "text": "TP) but BioREx generated either false negatives (FN) or false positives (FP) within the BioRED+DDI and BioRED+AIMed datasets. Further, we observed that out of the randomly selected 15 cases, 11 had more than one coinciding sentence in the abstract. However, their relational statements were not explicitly defined. For instance, in PMID:23069675, \"Our results indicate a regulatory role of NP1 in Bad/Baxdependent mitochondrial release of Cyt C and caspase-3 activation.\" The relation between the gene-gene relation pairs <Bad, Cyt C, Association>, <Bad, caspase-3, Association>, <Bax, Cyt C, Association>, and <Bax, caspase-3, Association><Bad, caspase-3, Association> are not clearly stated. Similarly, the chemical pair <tacrolimus, everolimus, Conversion> from PMID:18503483 \"Recovery of tacrolimus-associated brachial neuritis after conversion to everolimus in a pediatric renal transplant recipient--case report and review of the literature\" is only implicitly connected since the conversion mechanism is not explicitly explained. It appears that MTL has a slight edge over BioREx in identifying these implicit relations."
    },
    {
      "text": "differentiated the relations into three categories: Positive Combination (POS_COMB), Non-positive Combination (OTHER_COMB), and Not a Combination (NO_COMB). Using the Positive Combination evaluation metric, the OTHER_COMB is grouped with NO_COMB. Using the Any Combination evaluation metric, the OTHER_COMB is grouped with POS_COMB. The drug combination relations may contain two or more drugs. The exact match requires all relation pairs to be extracted. Other than the exact match, the performance of the partial match determined only a subset of relation pairs in the combination."
    },
    {
      "text": "Specifically, we randomly sampled four subsets of the BioRED training data of different sizes for model development and evaluation on the independent BioRED test set. The detailed results are shown in Figure 1. With the eight external datasets, the performance of the models trained on five incremental sizes (100, 200, 300, 400, and 500 abstracts) of training data is improved significantly.In particular, the performance of the model trained on 60% of the training set (300 abstracts) achieved a better result (75.8%) than did the model trained on the entire training set of the original BioRED (74.4%). These results demonstrate that our approach can take advantage of external datasets to build reliable training data with fewer annotation efforts."
    },
    {
      "text": "Figure 1. Performance of BioREx using partial BioRED with additional eight datasets."
    },
    {
      "text": "Characteristic diversity and adjustment solutions."
    },
    {
      "text": "Corpora collected for training and evaluation.SEN: sentence level.DOC: document-level.No span: not entity span is provided. D = Disease, G = Gene/Protein, and C = Chemical/Drug."
    },
    {
      "text": "Performance on the BioRED task using external datasets.All numbers are F-scores.*p< 0.05 (pairwise t-test in mean F-score compared with baseline).hadF-scores of 46.0%, 55.7%, 56.2%, and 61.5%, respectively.Since BioREx utilizes the entire model for various tasks, including sentence-level tasks that tag an entity only once per instance, it significantly outperforms the other methods.Document-level annotations (e.g., BC5CDR) and sentence-level annotations (e.g., DDI) serve distinct goals and offer different advantages.Sentence-level annotations provide precise context, including the locations of entity pairs and supporting evidence.On the other hand, document-level annotations do not offer explicit relation sentences between pairs but provide rich contextual information.By merging datasets from both document-and sentence-level annotations, our model becomes capable of handling different types of contexts, making it more versatile.Ours has improved the DDI performance by 2.7% compared with the baseline, but with a p-value of 0.11, which is not statistically significant.The performance of BioREx on chemical-disease <C,D> relations increased from 76.5% to 79.3% after we merged the BC5CDR dataset with BioRED, which also shows better performance than the models trained by TL (77.6%) and MTL (78.0%). The performance of the gene-chemical <G,C> relation also was improved when we merged the adjusted datasets of DrugProt or PharmGKB within BioRED. Further,"
    },
    {
      "text": "Performance of the RE model on the test set of individual datasets. All numbers are performance (F-score) of the test set in individual datasets. *p < 0.05 (pairwise t-test in mean F-score compared with baseline)."
    },
    {
      "text": "Evaluation of N-ary based on different PLMs. PubMedBERT is the default PLM model. Stateof-the-art (SOTA) performance has been reported in the N-ary study."
    },
    {
      "text": "Evaluation on RENET based on different PLMs. SciBERT presents the SOTA performance reported in the RENET study."
    },
    {
      "text": "Comparison of the PLM models"
    }
  ],
  "references": [
    {
      "title": "BioRED: A Rich Biomedical Relation Extraction Dataset",
      "authors": [
        "L Luo",
        "P-T Lai",
        "C-H Wei",
        "C Arighi",
        "Z Lu"
      ],
      "year": 2022
    },
    {
      "title": "Comparative experiments on learning information extractors for proteins and their interactions",
      "authors": [
        "R Bunescu",
        "R Ge",
        "R Kate",
        "E Marcotte",
        "R Mooney",
        "A Ramani"
      ],
      "year": 2005,
      "doi": "10.1016/j.artmed.2004.07.016"
    },
    {
      "title": "A survey on literature based discovery approaches in biomedical domain",
      "authors": [
        "V Gopalakrishnan",
        "K Jha",
        "Jin Zhang"
      ],
      "year": 2019
    },
    {
      "title": "LION LBD: a literature-based discovery system for cancer biology",
      "authors": [
        "S Pyysalo",
        "S Baker",
        "I Ali",
        "S Haselwimmer",
        "T Shah",
        "A Young"
      ],
      "year": 2018,
      "doi": "10.1093/bioinformatics/bty845"
    },
    {
      "title": "PheneBank: a literature-based database of phenotypes",
      "authors": [
        "M Pilehvar",
        "A Bernard",
        "D Smedley",
        "N Collier"
      ],
      "year": 2021,
      "doi": "10.1093/bioinformatics/btab740"
    },
    {
      "title": "Discovering novel drugsupplement interactions using SuppKG generated from the biomedical literature",
      "authors": [
        "D Schutte",
        "J Vasilakes",
        "A Bompelli",
        "Y Zhou",
        "M Fiszman",
        "H Xu"
      ],
      "year": 2022,
      "doi": "10.1016/j.jbi.2022.104120"
    },
    {
      "title": "EpiGraphDB: a database and data mining platform for health data science",
      "authors": [
        "Y Liu",
        "B Elsworth",
        "P Erola",
        "V Haberland",
        "G Hemani",
        "M Lyon"
      ],
      "year": 2021,
      "doi": "10.1101/2020.08.01.230193"
    },
    {
      "title": "Using computable knowledge mined from the literature to elucidate confounders for EHR-based pharmacovigilance",
      "authors": [
        "S Malec",
        "P Wei",
        "E Bernstam",
        "R Boyce",
        "T Cohen"
      ],
      "year": 2021
    },
    {
      "title": "Overview of DrugProt BioCreative VII track: quality evaluation and large scale text mining of drug-gene/protein relations",
      "authors": [
        "A Miranda",
        "F Mehryary",
        "J Luoma",
        "S Pyysalo",
        "A Valencia",
        "M Krallinger"
      ],
      "year": 2021
    },
    {
      "title": "The DDI corpus: An annotated corpus with pharmacological substances and drug-drug interactions",
      "authors": [
        "M Herrero-Zazo",
        "I Segura-Bedmar",
        "P Mart\u00ednez",
        "T Declerck"
      ],
      "year": 2013
    },
    {
      "title": "Biobibliometrics: information retrieval and visualization from co-occurrences of gene names in Medline abstracts",
      "authors": [
        "B Stapley",
        "G Benoit"
      ],
      "year": 1999,
      "doi": "10.1142/9789814447331_0050"
    },
    {
      "title": "A literature network of human genes for highthroughput analysis of gene expression",
      "authors": [
        "T-K Jenssen",
        "A Laegreid",
        "J Komorowski",
        "E Hovig"
      ],
      "year": 2001
    },
    {
      "title": "RelEx-Relation extraction using dependency parse trees",
      "authors": [
        "K Fundel",
        "R K\u00fcffner",
        "R Zimmer"
      ],
      "year": 2007,
      "doi": "10.1093/bioinformatics/btl616"
    },
    {
      "title": "Pattern discovery for wide-window open information extraction in biomedical literature",
      "authors": [
        "Q Li",
        "X Wang",
        "Y Zhang",
        "F Ling",
        "C Wu",
        "J Han"
      ],
      "year": 2018,
      "doi": "10.1109/bibm.2018.8621375"
    },
    {
      "title": "Discovering patterns to extract protein-protein interactions from full texts",
      "authors": [
        "M Huang",
        "X Zhu",
        "Y Hao",
        "D Payan",
        "K Qu",
        "M Li"
      ],
      "year": 2004
    },
    {
      "title": "Assessing the state of the art in biomedical relation extraction: overview of the BioCreative V chemical-disease relation (CDR) task",
      "authors": [
        "C-H Wei",
        "Y Peng",
        "R Leaman",
        "A Davis",
        "C Mattingly",
        "J Li"
      ],
      "year": 2016,
      "doi": "10.1093/database/baw032"
    },
    {
      "title": "Toward an automatic method for extracting cancer-and other disease-related point mutations from the biomedical literature",
      "authors": [
        "E Doughty",
        "A Kertesz-Farkas",
        "O Bodenreider",
        "G Thompson",
        "A Adadey",
        "T Peterson"
      ],
      "year": 2010
    },
    {
      "title": "Extracting chemical-protein relations with ensembles of SVM and deep learning models",
      "authors": [
        "Y Peng",
        "A Rios",
        "R Kavuluru",
        "Z Lu"
      ],
      "year": 2018
    },
    {
      "title": "Humboldt@ DrugProt: Chemical-Protein Relation Extraction with Pretrained Transformers and Entity Descriptions",
      "authors": [
        "L Weber",
        "M S\u00e4nger",
        "S Garda",
        "F Barth",
        "C Alt",
        "U Leser"
      ],
      "year": 2021,
      "doi": "10.1093/database/baac098"
    },
    {
      "title": "PharmGKB: the pharmacogenomics knowledge base",
      "authors": [
        "C Thorn",
        "T Klein",
        "R Altman"
      ],
      "year": 2013
    },
    {
      "title": "The DisGeNET knowledge platform for disease genomics: 2019 update",
      "authors": [
        "J Pi\u00f1ero",
        "J Ram\u00edrez-Anguita",
        "J Sa\u00fcch-Pitarch",
        "F Ronzano",
        "E Centeno",
        "F Sanz"
      ],
      "year": 2020
    },
    {
      "title": "A deep learning approach for extracting genedisease associations from literature",
      "authors": [
        "Y Wu",
        "R Luo",
        "H Leung",
        "H-F Ting",
        "T-W Lam",
        "Renet"
      ],
      "year": 2019
    },
    {
      "title": "Extracting microRNA-gene relations from biomedical literature using distant supervision",
      "authors": [
        "A Lamurias",
        "L Clarke",
        "F Couto"
      ],
      "year": 2017
    },
    {
      "title": "Automatic construction of a large-scale and accurate drug-side-effect association knowledge base from biomedical literature",
      "authors": [
        "R Xu",
        "Q Wang"
      ],
      "year": 2014,
      "doi": "10.1016/j.jbi.2014.05.013"
    },
    {
      "title": "Overview of the BioCreative VI Precision Medicine Track: mining protein interactions and mutations for precision medicine",
      "authors": [
        "R Islamaj Do\u011fan",
        "S Kim",
        "A Chatr-Aryamontri",
        "C-H Wei",
        "D Comeau",
        "R Antunes"
      ],
      "year": 2019
    },
    {
      "title": "BioELECTRA: pretrained biomedical text encoder using discriminators",
      "authors": [
        "Raj Kanakarajan",
        "K Kundumani",
        "B Sankarasubbu"
      ],
      "year": 2021
    },
    {
      "title": "BioM-transformers: building large biomedical language models with BERT, ALBERT and ELECTRA",
      "authors": [
        "S Alrowili",
        "Vijay Shanker"
      ],
      "year": 2021
    },
    {
      "title": "Domain-specific language model pretraining for biomedical natural language processing",
      "authors": [
        "Y Gu",
        "R Tinn",
        "H Cheng",
        "M Lucas",
        "N Usuyama",
        "X Liu"
      ],
      "year": 2021
    },
    {
      "title": "Document-level relation extraction with adaptive thresholding and localized context pooling",
      "authors": [
        "W Zhou",
        "K Huang",
        "T Ma",
        "J Huang"
      ],
      "year": 2021,
      "doi": "10.1609/aaai.v35i16.17717"
    },
    {
      "title": "Document-level biomedical relation extraction using graph convolutional network and multihead attention: algorithm development and validation",
      "authors": [
        "J Wang",
        "X Chen",
        "Y Zhang",
        "Y Zhang",
        "J Wen",
        "H Lin"
      ],
      "year": 2020
    },
    {
      "title": "All-paths graph kernel for proteinprotein interaction extraction with evaluation of cross-corpus learning",
      "authors": [
        "A Airola",
        "S Pyysalo",
        "J Bj\u00f6rne",
        "T Pahikkala",
        "F Ginter",
        "T Salakoski"
      ],
      "year": 2008
    },
    {
      "title": "Deep learning for drug-drug interaction extraction from the literature: a review",
      "authors": [
        "T Zhang",
        "J Leng",
        "Y Liu"
      ],
      "year": 2019
    },
    {
      "title": "BioRED: A Rich Biomedical Relation Extraction Dataset",
      "authors": [
        "L Luo",
        "P-T Lai",
        "C-H Wei",
        "C Arighi",
        "Z Lu"
      ],
      "year": 2022,
      "doi": "10.1093/bib/bbac282"
    },
    {
      "title": "A BERT-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction",
      "authors": [
        "C Lin",
        "T Miller",
        "D Dligach",
        "F Sadeque",
        "S Bethard",
        "G Savova"
      ],
      "year": 2020
    },
    {
      "title": "Relation extraction from biomedical and clinical text: Unified multitask learning framework",
      "authors": [
        "S Yadav",
        "S Ramesh",
        "S Saha",
        "A Ekbal"
      ],
      "year": 2020
    },
    {
      "title": "An empirical study of multi-task learning on BERT for biomedical text mining",
      "authors": [
        "Y Peng",
        "Q Chen",
        "Z Lu"
      ],
      "year": 2020,
      "doi": "10.18653/v1/2020.bionlp-1.22"
    },
    {
      "title": "A neural multi-task learning framework to jointly model medical named entity recognition and normalization",
      "authors": [
        "S Zhao",
        "T Liu",
        "S Zhao",
        "F Wang"
      ],
      "year": 2019,
      "doi": "10.1609/aaai.v33i01.3301817"
    },
    {
      "title": "Simple hierarchical multi-task neural end-to-end entity linking for biomedical text",
      "authors": [
        "M Wiatrak",
        "J Iso-Sipila"
      ],
      "year": 2020
    },
    {
      "title": "An end-to-end progressive multi-task learning framework for medical named entity recognition and normalization",
      "authors": [
        "B Zhou",
        "X Cai",
        "Y Zhang",
        "X Yuan"
      ],
      "year": 2021
    },
    {
      "title": "Span-based joint entity and relation extraction with transformer pre-training",
      "authors": [
        "M Eberts",
        "Ulges Ajapa"
      ],
      "year": 2019
    },
    {
      "title": "Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports",
      "authors": [
        "H Gurulingappa",
        "A Rajput",
        "A Roberts",
        "J Fluck",
        "M Hofmann-Apitius",
        "L Toldo"
      ],
      "year": 2012
    },
    {
      "title": "Overview of the BioCreative VI chemical-protein interaction Track",
      "authors": [
        "M Krallinger",
        "O Rabal",
        "S Akhondi",
        "M P\u00e9rez",
        "J Santamar\u00eda",
        "G Rodr\u00edguez"
      ],
      "year": 2017
    },
    {
      "title": "Hin: Hierarchical inference network for document-level relation extraction",
      "authors": [
        "H Tang",
        "Y Cao",
        "Z Zhang",
        "J Cao",
        "F Fang",
        "S Wang"
      ],
      "year": 2020,
      "doi": "10.1007/978-3-030-47426-3_16"
    },
    {
      "title": "DocRED: A Large-Scale Document-Level Relation Extraction Dataset",
      "authors": [
        "Y Yao",
        "D Ye",
        "P Li",
        "X Han",
        "Y Lin",
        "Z Liu"
      ],
      "year": 2019
    },
    {
      "title": "The DisGeNET knowledge platform for disease genomics: 2019 update",
      "authors": [
        "J Pi\u00f1ero",
        "J Ram\u00edrez-Anguita",
        "J Sa\u00fcch-Pitarch",
        "F Ronzano",
        "E Centeno",
        "F Sanz"
      ],
      "year": 2020,
      "doi": "10.1093/nar/gkz1021"
    },
    {
      "title": "A Dataset for N-ary Relation Extraction of Drug Combinations",
      "authors": [
        "A Tiktinsky",
        "V Viswanathan",
        "D Niezni",
        "D Azagury",
        "Y Shamay",
        "H Taub-Tabib"
      ],
      "year": 2022,
      "doi": "10.18653/v1/2022.naacl-main.233"
    },
    {
      "title": "Comparative toxicogenomics database (CTD): update 2021",
      "authors": [
        "A Davis",
        "C Grondin",
        "R Johnson",
        "D Sciaky",
        "J Wiegers",
        "T Wiegers"
      ],
      "year": 2021
    },
    {
      "title": "PubTator central: automated concept annotation for biomedical full text articles",
      "authors": [
        "C-H Wei",
        "A Allot",
        "R Leaman",
        "Z Lu"
      ],
      "year": 2019
    },
    {
      "title": "Medical subject headings (MeSH)",
      "authors": [
        "C Lipscomb"
      ],
      "year": 2000
    },
    {
      "title": "Protein-protein interaction relation extraction based on multigranularity semantic fusion",
      "authors": [
        "Y Li",
        "Y Chen",
        "Y Qin",
        "Y Hu",
        "R Huang",
        "Q Zheng"
      ],
      "year": 2021,
      "doi": "10.1016/j.jbi.2021.103931"
    },
    {
      "title": "Integrating heterogeneous knowledge graphs into drug-drug interaction extraction from the literature",
      "authors": [
        "M Asada",
        "M Miwa",
        "Y Sasaki"
      ],
      "year": 2023,
      "doi": "10.1093/bioinformatics/btac754"
    },
    {
      "title": "A Dataset for N-ary Relation Extraction of Drug Combinations",
      "authors": [
        "A Tiktinsky",
        "V Viswanathan",
        "D Niezni",
        "D Azagury",
        "Y Shamay",
        "H Taub-Tabib"
      ],
      "year": 2022,
      "doi": "10.18653/v1/2022.naacl-main.233"
    },
    {
      "title": "SciBERT: A Pretrained Language Model for Scientific Text",
      "authors": [
        "I Beltagy",
        "K Lo",
        "A Cohan"
      ],
      "year": 2019
    },
    {
      "title": "Domain-specific language model pretraining for biomedical natural language processing",
      "authors": [
        "Y Gu"
      ],
      "year": 2021
    },
    {
      "title": "BioELECTRA: pretrained biomedical text encoder using discriminators",
      "authors": [
        "K Raj Kanakarajan",
        "B Kundumani",
        "M Sankarasubbu"
      ],
      "year": 2021,
      "doi": "10.18653/v1/2021.bionlp-1.16"
    },
    {
      "title": "Team Bioformer at BioCreative VII LitCovid Track: Multic-label topic classification for COVID-19 literature with a compact BERT model",
      "authors": [
        "L Fang",
        "K Wang"
      ],
      "year": 2021
    },
    {
      "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
      "authors": [
        "J Lee"
      ],
      "year": 2020,
      "doi": "10.1093/bioinformatics/btz682"
    },
    {
      "title": "Pretrained language models for biomedical and clinical tasks: Understanding and extending the state-of-the-art",
      "authors": [
        "P Lewis"
      ],
      "year": 2020,
      "doi": "10.18653/v1/2020.clinicalnlp-1.17"
    },
    {
      "title": "BioRED: A Rich Biomedical Relation Extraction Dataset",
      "authors": [
        "L Luo"
      ],
      "year": 2022
    },
    {
      "title": "Comparative experiments on learning information extractors for proteins and their interactions",
      "authors": [
        "R Bunescu"
      ],
      "year": 2005,
      "doi": "10.1016/j.artmed.2004.07.016"
    },
    {
      "title": "RelEx-Relation extraction using dependency parse trees",
      "authors": [
        "K Fundel",
        "R K\u00fcffner",
        "R Zimmer"
      ],
      "year": 2007,
      "doi": "10.1093/bioinformatics/btl616"
    },
    {
      "title": "Overview of DrugProt BioCreative VII track: quality evaluation and large scale text mining of drug-gene/protein relations",
      "authors": [
        "A Miranda"
      ],
      "year": 2021
    },
    {
      "title": "Overview of the BioCreative VI chemical-protein interaction Track",
      "authors": [
        "M Krallinger"
      ],
      "year": 2017
    },
    {
      "title": "The DDI corpus: An annotated corpus with pharmacological substances and drug-drug interactions",
      "authors": [
        "M Herrero-Zazo"
      ],
      "year": 2013
    },
    {
      "title": "RENET2: high-performance full-text gene-disease relation extraction with iterative training data expansion",
      "authors": [
        "J Su"
      ],
      "year": 2021
    },
    {
      "title": "A deep learning approach for extracting gene-disease associations from literature",
      "authors": [
        "Y Wu"
      ],
      "year": 2019
    },
    {
      "title": "The EU-ADR corpus: annotated drugs, diseases, targets, and their relationships",
      "authors": [
        "E Van Mulligen"
      ],
      "year": 2012
    },
    {
      "title": "Cross-sentence n-ary relation extraction with graph lstms",
      "authors": [
        "N Peng"
      ],
      "year": 2017
    },
    {
      "title": "Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports",
      "authors": [
        "H Gurulingappa"
      ],
      "year": 2012
    },
    {
      "title": "BRONCO: Biomedical entity Relation ONcology COrpus for extracting genevariant-disease-drug relations",
      "authors": [
        "K Lee"
      ],
      "year": 2016
    },
    {
      "title": "Assessing the state of the art in biomedical relation extraction: overview of the BioCreative V chemical-disease relation (CDR) task",
      "authors": [
        "C.-H Wei"
      ],
      "year": 2016
    },
    {
      "title": "Overview of the BioCreative VI Precision Medicine Track: mining protein interactions and mutations for precision medicine",
      "authors": [
        "R Islamaj Do\u011fan"
      ],
      "year": 2019
    },
    {
      "title": "PGxCorpus, a manually annotated corpus for pharmacogenomics",
      "authors": [
        "J Legrand"
      ],
      "year": 2020
    },
    {
      "title": "Toward an automatic method for extracting cancer-and other disease-related point mutations from the biomedical literature",
      "authors": [
        "E Doughty"
      ],
      "year": 2010
    },
    {
      "title": "PharmGKB: the pharmacogenomics knowledge base",
      "authors": [
        "C Thorn",
        "T Klein",
        "R Altman"
      ],
      "year": 2013
    },
    {
      "title": "The DisGeNET knowledge platform for disease genomics: 2019 update",
      "authors": [
        "J Pi\u00f1ero"
      ],
      "year": 2020
    },
    {
      "title": "Comparative toxicogenomics database (CTD): update 2021",
      "authors": [
        "A Davis"
      ],
      "year": 2021
    },
    {
      "title": "An Open Access Database of Genome-wide Association Results",
      "authors": [
        "A Johnson",
        "C O'donnell"
      ],
      "year": 2009
    },
    {
      "title": "BindingDB in 2015: a public database for medicinal chemistry, computational chemistry and systems pharmacology",
      "authors": [
        "M Gilson"
      ],
      "year": 2016
    },
    {
      "title": "BioInfer: a corpus for information extraction in the biomedical domain",
      "authors": [
        "S Pyysalo"
      ],
      "year": 2007
    },
    {
      "title": "Learning language in logic-genic interaction extraction challenge",
      "authors": [
        "C N\u00e9dellec"
      ],
      "year": 2005
    },
    {
      "title": "Mining MEDLINE: abstracts, sentences, or phrases?",
      "authors": [
        "J Ding"
      ],
      "year": 2001
    },
    {
      "title": "Overview of the protein-protein interaction annotation extraction task of BioCreative II",
      "authors": [
        "M Krallinger"
      ],
      "year": 2008,
      "doi": "10.1186/gb-2008-9-s2-s4"
    },
    {
      "title": "An Overview of BioCreative II.5",
      "authors": [
        "F Leitner"
      ],
      "year": 2010,
      "doi": "10.1109/tcbb.2010.61"
    },
    {
      "title": "n2c2 shared task on adverse drug events and medication extraction in electronic health records",
      "authors": [
        "S Henry"
      ],
      "year": 2018,
      "doi": "10.1093/jamia/ocz166"
    }
  ],
  "num_references": 85
}
