{
  "paper_id": "DX5MMCQF",
  "title": "Application of substitution box of present cipher for automated detection of snoring sounds",
  "abstract": "Background and purpose: Snoring is one of the sleep disorders, and snoring sounds have been used to diagnose many sleep-related diseases. However, the snoring sound classification is done manually which is timeconsuming and prone to human errors. An automated snoring sound classification model is proposed to overcome these problems. Material and method: This work proposes an automated snoring sound classification method using three new methods. These methods are maximum absolute pooling (MAP), the nonlinear present pattern, and two-layered neighborhood component analysis, and iterative neighborhood component analysis (NCAINCA) selector. Using these methods, a new snoring sound classification (SSC) model is presented. The MAP decomposition model is applied to snoring sounds to extract both low and high-level features. The presented model aims to attain high performance for SSC problem. The developed present pattern (Present-Pat) uses substitution box (SBox) and statistical feature generator. By deploying these feature generators, both textural and statistical features are generated. NCAINCA chooses the most informative/valuable features, and these selected features are fed to knearest neighbor (kNN) classifier with leave-one-out cross-validation (LOOCV). The Present-Pat based SSC system is developed using Munich-Passau Snore Sound Corpus (MPSSC) dataset comprising of four categories. Results: Our model reached an accuracy and unweighted average recall (UAR) of 97.10 % and 97.60 %, respectively, using LOOCV. Moreover, a nocturnal sound dataset is used to show the universal success of the presented model. Our model attained an accuracy of 98.14 % using the used nocturnal sound dataset. Conclusions: Our developed classification model is ready to be tested with more data and can be used by sleep specialists to diagnose the sleep disorders based on snoring sounds.",
  "year": 2021,
  "date": "2021-05-06",
  "authors": [
    {
      "name": "Sengul Dogan",
      "email": "sdogan@firat.edu.tr",
      "affiliation": {
        "organization": "Department of Digital Forensics Engineering",
        "department": "Department of Digital Forensics Engineering",
        "institution": "Firat University",
        "address": "Elazig, Turkey"
      }
    },
    {
      "name": "Erhan Akbal",
      "affiliation": {
        "organization": "Department of Digital Forensics Engineering",
        "department": "Department of Digital Forensics Engineering",
        "institution": "Firat University",
        "address": "Elazig, Turkey"
      }
    },
    {
      "name": "Turker Tuncer",
      "affiliation": {
        "organization": "Department of Digital Forensics Engineering",
        "department": "Department of Digital Forensics Engineering",
        "institution": "Firat University",
        "address": "Elazig, Turkey"
      }
    },
    {
      "name": "U Rajendra Acharya",
      "affiliation": {
        "organization": "Department of Electronics and Computer Engineering",
        "department": "Department of Electronics and Computer Engineering",
        "institution": "Ngee Ann Polytechnic",
        "address": "599489, Singapore"
      }
    }
  ],
  "doi": "10.1016/j.artmed.2021.102085",
  "md5": "2D0D7C93996BA97DEFF73D42DEB66240",
  "publication": {
    "journal": "INTERSPEECH",
    "journal_inferred": true
  },
  "sections": [
    {
      "title": "1.. Introduction",
      "text": "Snoring is a sleep disorder affecting 45 % of people worldwide  [1]  and the studies show that 45 % of people have snoring problems  [2, 3] . This problem is more common in men and the elderly  [4] . Sleep problems cause many ailments such as daytime fatigue, drowsiness, sleepiness, social activity disorders, problems between spouses, problems in the family, problems in business life, and health problems  [1] . A few studies have shown a positive association between high snoring and risk of stroke or even death  [2, 3] . It is important for people to have good quality sleep without snoring problems.\n\nSnoring is the problem with airflow in the airways during sleep. Soft-tissue structures in the upper airways (UA) are stimulated by inspiratory airflow and vibrate. Thus, the person cannot perform healthy breathing during sleep and hence snores. This problem may trigger different diseases such as obstructive sleep apnea (OSA), brain and heart disease  [2] . The source of the problem must be diagnosed to treat the snoring. Different methods are used to diagnose snoring, such as detailed clinical history and examination, polysomnography (PSG)  [3] , drug-induced sleep endoscopy (DISE)  [4] , camera  [5] , and voice recording  [6] . The purpose of all methods is to diagnose the reason for snoring and suggest appropriate treatment  [7, 8] .\n\nThe PSG is a reliable diagnostic method used to diagnose the type and severity of sleep-related breathing disorder  [9] . However, it has limited use in identifying the underlying mechanisms. Drug-induced sleep endoscopy (DISE) is a method developed to determine obstruction in the palate or tongue area during sleep and problems in the airway structures  [4] . During DISE, the patient is examined intranasal using a nasopharyngoscope (an endoscope for visually examining the nasal passages and pharynx) while the patient is unconscious during sleep  [4] . During the test, video, audio recordings, and documentation are made, and then the expert evaluation is made. However, it is not possible to do it at home or during natural sleep because the patient takes medication, the process takes a long time, and the endoscope is attached to the patient. Sound-based snoring diagnosis studies have become popular in recent years because of their easier and more convenient application  [2, 10, 11] . Many studies have shown that the snoring sound occurs during the air passage through the respiratory system and has different acoustic properties in different locations  [6] . Therefore, it is possible to classify snoring sounds by using characteristic acoustic properties. The sounds collected during sleep can be detected using artificial intelligence-based computer-aided diagnostic systems. There are many sound-based studies done using artificial intelligence in the literature. Several automated snoring sound detection methods have been presented  [6, [12] [13] [14] [15] . Studies generally focused on distinguishing snoring from OSA or snoring / not snoring  [2, [16] [17] [18] . There are also many sound-based studies linking sleep sounds to sleep stages  [19, 20] . Also, fewer studies are presented to determine the location of sound in the respiratory system  [21] . In their study, an automated system is proposed to classify the snoring sound's location in the respiratory system using the Munich-Passau Snore Sound Corpus (MPSSC) dataset.\n\nNowadays, many studies have been conducted on vibration source classification using snoring sound. Some of them are discussed below. Albornoz et al.  [22]  proposed a model using spectral properties of a sound signal, Mel frequency cepstral coefficients (MFCCs)  [23] , and support vector machine (SVM)  [24, 25] . Their model has shown an unweighted average recall (UAR) of 49.38 %. Amiriparian et al.  [10]  showed a method using the convolutional neural network (CNN)  [26]  and Alexnet  [26]  to classify the snoring sounds. They have reported the performance of 67.0 % using CNN and Alexnet with deep spectrum features. Demir et al.  [27]  presented an image processing-based SSC model. They extract spectrogram images of the snoring sound and used a local binary pattern (LBP)  [28]  and a histogram of oriented gradients (HOG)  [29]  extractors-based classification model. MPSSC dataset was used for testing, and they reached a UAR of 72.60 %. Tuncer et al.  [6]  proposed a method using iterative hybrid feature selector and local dual octal pattern (LDOP). They presented a multileveled feature generation model using LDOP local extractor, and a two-layered feature selector picked the most valuable features. They attained UAR of 94.65 % and accuracy of 95.53 % using leave-one-out cross-validation (LOOCV)  [30]  training and testing strategy. Vesperini et al.  [31]  used a scattering spectrum transformation with a deep neural network, using MPSSC dataset and reported UAR of 74.19 %. Wang et al.  [32]  presented a model to detect obstructive sleep apnea (OSA) by analyzing acoustic snoring sounds. They obtained 91.14 % recognition rate using SVM classifier. Lim et al.  [13]  showed that snoring sounds can be classified using recurrent neural network (RNN)  [33] . For this purpose, a dataset is created consisting of different environmental sounds and snoring sounds. Their method is able to detect the snoring sound with an accuracy of 98.9 %. Cavusoglu et al.  [2]  proposed a method to determine the relationship between sleep sounds and snoring. They have shown that collected sounds during the polysomnography test are classified with an accuracy of 97.3 % using spectral features and robust linear regression classifier."
    },
    {
      "title": "1.1.. Main contributions novelties",
      "text": "The novelties and key contributions of this work are given below. The novelties of this work are:\n\n\u2022 A novel nonlinear and multi-kernel feature generation function is presented by using SBox  [34] [35] [36] [37]  of the present lightweight cipher. \u2022 Novel MAP decomposer is presented.\n\n\u2022 Combination of NCA  [38]  and INCA named as NCAINCA is proposed to select the discriminative features easily.\n\nThe main contributions of this paper are given below:\n\n\u2022 Handcrafted feature generation methods have used linear patterns and binary feature extractors  [38] . In this work, we have proposed an efficient and simple feature generation function called Present-Pat to extract the hidden subtle changes in the signal. This pattern (feature generation function) uses both a nonlinear function to create pattern and multiple binary feature generation functions. A new MAP decomposer is used to create features at various levels and statistical features are also generated. The presented multileveled feature generation method generates both low-level and high-level features.\n\n\u2022 Feature selection is one of the critical phases of a machine learning method. A two-layered NCAINCA features selection method is used to select the most discriminative features. Also, a highly accurate SSC method is presented by using the presented feature generation method (Present-Pat and MAP-based method) and NCAINCA selector."
    },
    {
      "title": "2.. Material",
      "text": "In this work, we have used Munich-Passau Snore Sound Corpus (MPSSC) dataset, which was presented at the INTERSPEECH 2017 Computational Paralinguistic Challenge  [39] . The dataset was collected from the endoscopy records of patients who had previously undergone polysomnography (PSG) and were diagnosed with OSA during DISE examinations. It was collected from 3 health centers: Munich Technical University, Alfried Krupp Hospital Essen, and University Hospital Halle.\n\nA total of 2174 raw records collected from 3 centers were used to create this dataset. Records were taken from 38 subjects from Munich Technical University from 2013 to 2014, 2090 subjects from Alfried Krupp Hospital Essen between 2006 and 2015, 46 subjects from University Hospital Halle from 2012 to 2015. 331 suitable snoring subjects were selected from raw DISE records  [39] . Subsequently, 219 subjects suitable for VOTE classification were selected manually by the experts. The sound samples are labeled in four classes: V, O, T, and E  [40] . The 'V' is the vibration level in the velum, 'O' is the oropharyngeal vibration level in the tonsils, 'T' indicates the vibration of the tongue base and the posterior pharyngeal wall, and 'E' denotes the vibration of the epiglottis represents. Finally, the dataset containing sound samples of 828 snoring events from 219 subjects is created. There are a total of 828 sound samples (484 V, 216 O, 39 T and 89 E) of 16 bits and sampled at 16 kHz frequency. The average sample time is 1.46 s (range 0.73\u2026 2.75 s). The average age of subjects is 49.8 years (range 24\u2026 78), with 93.6 % of total subjects are male subjects."
    },
    {
      "title": "3.. The presented SSC model",
      "text": "Detection of various sleep orders using snoring sounds is complex and time-consuming. Hence, automated systems have been proposed for this work. We have used the MPSSC dataset containing 828 snoring sounds with four categories to develop the automated model. Most of the prior methods have used the conventional feature generation methods and used widely known sound descriptors. In this work, we have presented an automated SSC method using nonlinear feature generation functions to obtain the highest classification performance. Our proposed method consists of three phases: multiple kernelled Present-Pat (the prime feature generation function), MAP decomposer, and NCAINCA selector. The proposed multiple kernelled Present-Pat generates nonlinear features using both signum and ternary binary feature extraction functions. It efficiently extracts the hidden nonlinear features from the sound signals. The multileveled extraction method can obtain both low-level and high-level features with more detailed hidden changes. The maximum pooling (MAP) method routes only peak values and minimum pooling routes only minimum values. The main idea behind the MAP is to obtain an efficient and simple decomposition/ routing function. The neighborhood component analysis (NCA) is presented to select clinically significant features. The main problem in NCA is its inability to choose the optimal feature vector automatically. Hence, iterative neighborhood component analysis (INCA)  [41]  is used to overcome this problem. However, the computational complexity of INCA is high. Hence the proposed new selector (NCAINCA) overcomes this problem. Hence, we have developed our SSC model using these three functions coupled with a kNN classifier  [42] . The general flow diagram of our proposed automated SSC model is shown in Fig.  1 .\n\nThe presented SSC model has three main sections: multileveled nonlinear multiple kernel feature extraction, NCAINCA based feature selection, and classification. The details of these sections are given in the following sections."
    },
    {
      "title": "3.1.. Overview of the proposed model",
      "text": "This work presents a novel multileveled nonlinear features-based SSC model. Fig.  2  presents the snapshot of the proposed multiple kernels Present-Pat, MAP feature generation, and NCAINCA selector-based SSC method.\n\nIn Fig.  2 , L is used to define the length of signals. The proposed feature generation method has six levels. We achieved the highest performance using six leveled feature generation structure. Hence, we have developed the model with six levels. The presented multiple kernel Present-Pat and statistical generator generated 1561 features at each level, and the generated features are merged, and finally, 9366 features are obtained. The NCAINCA selector applied on the generated features to select the most valuable features. Then these selected features are fed to the kNN classifier for automated classification. The pseudocode of the SSC method is shown in Algorithm 1."
    },
    {
      "title": "Algorithm 1. Pseudocode of proposed SSC method.",
      "text": "Algorithm 1 demonstrates the steps involved in the presented SSC method. Lines 1-8 define the recommended multiple kernels Present-Pat, MAP decomposer-based feature generation, feature selection, and classification phases are indicated in lines 09-11."
    },
    {
      "title": "3.2.. Feature extraction",
      "text": "As stated in Algorithm 1, the recommended feature generation process used two prime functions: Present-Pat and MAP decomposer. The feature generator extracted 9366 features from a one-dimensional signal, and the used prime functions are explained in the following subsections."
    },
    {
      "title": "3.2.1.. Multiple kernelled present pattern",
      "text": "The used prime feature generation function in this work is the multiple kernelled present pattern. This function aims to generate nonlinear features by using nonlinear pattern (SBox of the Present cipher) and two binary features extraction functions. The used kernels (binary feature generation functions) are signum and ternary. 16 sized overlapping blocks (windows) are used to generate local features as the used SBox of the present cipher is a 4-bits SBox and its length is 2 4 = 16. Steps of the recommended Present-Pat are;\n\nStep 1: Divide sound signal into 16 sized overlapping blocks. Herein, L -15 overlapping blocks are created using the signal of length = L.\n\nStep 2: Use SBox of the lightweight present cipher for constructing nonlinear pattern. The used SBox is given in Table  1  and it shows indices of the generated pattern.\n\nThis SBox (see Table  1 ) is used as the pattern of proposed feature generation function. Therefore, this function is named present pattern (Table  2 ).\n\nStep 3: Generate 48 bits using signum and ternary functions\n\n) bit(t + 16) = { 0, blck(S(t) )blck(t) \u2265thr 1, blck(S(t) )blck(t) <thr (2) bit(t + 32) = { 0, blck(S(t) )blck(t) \u2264 thr 1, blck(S(t) )blck(t) > thr (3)\n\nwhere blck represents an overlapping block with a size of 16 and thr is a threshold value. We selected the threshold value as half of the standard deviation of the snore sound (SS). As seen from Eqs. (  1 ) to (4), the binary feature generation process is defined mathematically. Eq. (  1 ) shows the signum function, and first 16 bits are generated to deploy the signum function. The Eqs. (  2 ) and (  3 ) indicate the ternary function. Eq. (  2 ) shows the lower bit generation using the ternary function, and Eq. (  3 ) denotes the upper bit generation.\n\nStep 4: Create six map values by calculating the generated 48 bits. We have used binary to decimal conversion in this step.\n\nAs stated in Eq. (  5 ), the generated 48 bits are divided into six groups with 8-bits length as local binary pattern use 8-bits for coding. By employing Eq. (  5 ), six map signals are calculated for feature generation.\n\nStep 5: Compute histograms from the generated map signals (six map signals). The developed Present-Pat is a histogram-based feature generator, and hence histograms are generated in this step.\n\nwhere histo k defines k th histogram value.\n\nStep 6: Merge the generated six histograms and obtain the feature vector."
    },
    {
      "title": "fvec((k",
      "text": "where fvec is a feature vector with a length of 1536. These six steps define the recommended multiple kernel Present-Pat and is defined as Present -Pat(.) in Algorithm 1."
    },
    {
      "title": "3.2.2.. Statistical feature generation",
      "text": "The mostly preferred handcrafted feature extraction functions are divided into two primary groups: textural feature extractors and statistical feature generators. The Present-Pat is a textural feature generator. Therefore, a statistical feature generation function is also implemented to generate 25 statistical moments and these moments are mean, standard deviation, variance, median, maximum, minimum, range, root mean square error, energy, mean of the absolute of the signal, standard deviation of the absolute of the signal, variance of the absolute of the signal, median of the absolute of the signal, Shannon entropy, sure entropy, log energy entropy, Shannon entropy of the absolute signal, sure entropy of the absolute signal, log energy entropy of the absolute signal, kurtosis, skewness, kurtosis of the absolute of the signal, skewness of the absolute signal, mean absolute deviation and mean absolute deviation absolute signal  [43] . By applying these moments, 25 features are generated from the signal."
    },
    {
      "title": "3.2.3.. Maximum absolute pooling",
      "text": "We have used a novel and simple maximum absolute pooling (MAP) decomposition method in this work. As stated in the capsule network, the weakest atomic structure of the convolutional neural networks (CNNs) is pooling  [26] . This is because the maximum pooling method routes only the peak values. By presenting the MAP, both minimum and peak values can be routed. It is a very basic decomposition function, and Eq. (  9 ) defines it."
    },
    {
      "title": "MAP(x, y)",
      "text": "where x, y are input parameters of the MAP(., .) function. In this work, 2 sized non-overlapping blocks are used for decomposition. A graphical example of MAP is shown in Fig.  3 ."
    },
    {
      "title": "3.3.. Feature selection",
      "text": "The generated feature vector is fed to NCAINCA, which uses both NCA  [44]  and INCA  [41]  to solve the time complexity problem of INCA. The NCA is a weighted feature selector. In the first layer, NCA is employed to generate 9366 weighted vectors. A threshold value of 1 \u00d7 10 -5 is chosen to eliminate the redundant ones. Then, INCA feature selector is applied on the selected features. The steps of recommended NCAINCA are given below. NCA(., .) function is used to define the NCA feature selector.\n\nStep 1: Calculate weights (w) of each feature.\n\nw = NCA(X, y)  (10)  Step 2: Remove the redundant ones using the defined threshold value and calculated weights. where first defines the selected feature vector.\n\nStep 3: Apply INCA the first. The subroutine of INCA is given in Algorithm 2  [41] ."
    },
    {
      "title": "Algorithm 2. Pseudo code of INCA subroutine.",
      "text": "In this work, 850 features are selected from the generated 9366 features in the first phase, and INCA selected 283 most discriminative features from 850 features."
    },
    {
      "title": "3.4.. Classification",
      "text": "The last phase of the presented Present-Pat and NCAINCA based SSC method is classification using kNN  [45]  classifier with leave-one-out (LOOCV) strategy  [46] . The selected 283 features are fed as input to k-nearest neighbor (kNN) classifier. k value is chosen as 1 to obtain the optimum performance, and spearman distance is used."
    },
    {
      "title": "4.. Results",
      "text": "We have implemented the proposed model in MATLAB (2020a) environment and coded all six (main, Present-Pat, statistical-generator, MAP, NCAINCA, and classification) functions. The pseudocode of the main function is shown in Algorithm 1. The main function calls the other functions to implement the SSC model. In order to evaluate the performance of the model, geometric mean (GM), accuracy, F1-score, unweighted average recall (UAR), unweighted average precision (UAP), Cohen's kappa, and Matthews correlation coefficient (MCC) are used  [47] [48] [49] [50] . The computed results and confusion matrix are presented below.\n\nThe obtained confusion matrix of the proposed SSC model is presented in Table  3 .   model generates 9366 features from a sound signal. Our model used six leveled feature generation structure as the best performance is obtained with six levels. The plot of accuracies versus the number of levels obtained using our proposed method with LOOCV strategy is given in Fig.  4 ."
    },
    {
      "title": "5.. Discussion",
      "text": "The NCAINCA method is used to select the most discriminative 283 features. The graph of loss value versus the number of features obtained during the feature selection process with NCAINCA selector is shown in Fig.  5 .\n\nThe selected 283 features are fed to the kNN classifier, which yielded an accuracy of 97.10 % and UAR of 97.60 %. The box plots of generated 283 features for (a) V, (b) O, (c) T, and (d) E are shown in Fig.  6 .\n\nThe boxplot analysis is used to discriminate the generated and selected features graphically. It denotes the statistical attributes of features per class. It shows the differences of quartile 3 and quartile 1 using blue boxes, red pluses indicating the abnormal attributes. Moreover, minimum, maximum, and mean values of each feature is shown in the box plots. Fig.  5  shows unique features for each class which has yielded the highest classification accuracy. Fig. 6. Range of 283 features obtained for categories: (a) V, (b) O, (c) T, and (d) E. In the classification phase, LOOCV is considered to obtain the generalized results. Also, the results of hold-out validation (75:25 and 50:50), three-fold cross-validation, and ten-fold cross-validation techniques are used, and their results are shown in Table  4 .\n\nThe confusion matrices obtained using four validation techniques are shown in Fig.  7 .\n\nThe summary of comparison with other similar works developed using the same database is shown in Table  5 .\n\nIn Table  5 , UAR, AP, and Acc. indicate unweighted average recall, average precision, and accuracy, respectively. It can be noted from the presented model that our proposed model reached the highest results as compared to the other state-of-the-techniques using a heterogeneous dataset. Therefore, the UAR metric is used to evaluate the performance of the models. Tuncer et al.  [6]  have used LOOCV to develop their model in their work. Hence, we have also used the LOOCV strategy to validate our results. We have obtained UAR of 2.95 % more than Tuncer et al.'s model  [6] . Also, they have used a linear local feature generator to obtain the results and generated eight leveled feature generation structure. In this work, we have used six leveled feature generation structure and used nonlinear Present-Pat pattern. This nonlinear pattern successfully extracted subtle changes in the sound signal and yielded clinically  49.58 UAR Janott et al.  [39]  55.8 UAR Wang et al.  [52]  63.8 UAR Demir et al.  [27]  72.6 UAR Amiriparian et al.  [10]  67.0 UAR Zhang et al.  [53]  67.4 UAR Qian et al.  [15]  69.4 UAR Vesperini et al.  [31]  74.19 UAR Freitag et al.  [54]  72.6 UAR  Furthermore, we have also applied our proposed to a nocturnal sounds dataset  [55]  to validate the robustness of our model. This dataset is available at:  http://web.firat.edu.tr/turkertuncer/nocturnal.rar  with seven classes. The presented model has reached an accuracy of 97.49 % using this dataset. The work by  [55]  has attained an accuracy of 97.22 % with the same database. This confirms the success of the presented model. Accuracy (%) obtained using our method with nocturnal sound dataset is shown in Table  6 .\n\nIt can be noted from Table  6  that the presented model achieved the highest accuracy (%) using a decision tree, Quadratic SVM, Cubic SVM, and kNN classifiers as compared to other models  [55] .\n\nOur developed automated snoring classification system can be employed in medical centers and homes to detect the type of snoring which can be used to detect the type of sleep disorder. The snapshot of such a cloud-based system is shown in Fig.  8 .\n\nIt can be noted from Table  6  that the highest performance is obtained using our present pattern-based model. Our proposed nonlinear Present pattern is able to pick clearly the subtle changes from the features and yielded the highest classification performance. Other nonlinear methods like instance quantum transformations, chaos theorem, chaotic maps, entropies, and fractals can also be used. Also, new deep learning architectures can be used for the automated classification of snoring sounds.\n\nIt can be noted from Table  5  that, the presented SSC model yielded 2.95 % higher UAR than the reported best methods. The advantages and disadvantages of the proposed method are given below.\n\nThe advantages of our model are as follows:\n\n\u2022 Proposed a nonlinear textural feature generation function, a cryptographic structure (SBox of the lightweight Present cipher) based pattern is presented. The proposed method is able to extract subtle changes from the sound signal and yielded the highest classification performance.\n\n\u2022 A new decomposition method (MAP) is presented to perform the effective decomposition. It routes both peak and minimum values depending on the situation. \u2022 Given model has low computational complexity and hence it is fast. \u2022 NCAINCA selector solved the time complexity problem of NCA.\n\n\u2022 Developed model has yielded the highest performance, better than the state-of-art-technique models. \u2022 Proposed method is robust as it is generated using five various validation techniques.\n\nThe limitations of this work are given below:\n\n\u2022 The sound signals are fed to MAP to obtain both negative and positive values. \u2022 NCAINCA is an effective feature selector only if the appropriate threshold value is selected. So, the performance depends on the selection of threshold values."
    },
    {
      "title": "6.. Conclusion",
      "text": "Manual snoring sound detection is tedious, time-consuming, and prone to human errors. Hence, computer-assisted systems are proposed to aid clinicians in their diagnosis. This paper presents a novel SSC system using three new functions: (i) multiple kernelled Present-Pat, ii) MAP decomposer and (iii) NCAINCA feature selector. Our developed model has yielded an accuracy of 97.1 % and UAR of 97.6 % using kNN classifier with LOOCV strategy. This SSC model performed better than the state-of-the-art techniques and can be used in medical centers to diagnose sleep-related diseases accurately by detecting the type of snoring sound (see Fig.  8 ).\n\nWe have obtained the highest detection performance using MPSSC and nocturnal datasets. In future, we intend to explore the possibility of using our developed model to detect various arrhythmias and neurological disorders using electrocardiogram (ECG) and electroencephalogram (EEG) signals, respectively. Also, our developed system can be tested with big SSC and nocturnal datasets to classify sleep sound automatically. Our developed SSC model can be used in sleep centers to assist the sleep specialists in making accurate diagnosis."
    },
    {
      "text": "Fig. 1. General flow diagram of automated SSC model."
    },
    {
      "text": "Fig. 2. Snapshot of proposed multiple kernel Present-Pat, MAP feature generation, and NCAINCA selector based SSC method."
    },
    {
      "text": "Fig. 3. Illustration of MAP decomposition."
    },
    {
      "text": "This work employed three novel functions: Present-Pat feature generation function, MAP decomposer, and NCAINCA selector to develop an accurate SSC model. The Present-Pat based snoring sound classification"
    },
    {
      "text": "Fig. 4. Plot of accuracies versus the number of levels obtained using our proposed method."
    },
    {
      "text": "Fig. 5. Graph of loss value versus the number of features obtained during feature selection process using NCAINCA selector."
    },
    {
      "text": "Fig. 7. Confusion matrices obtained using four validation techniques with our proposed method: (a) hold-out (75 %-25 %), (b) hold-out (50 %-50 %), (c) 3-fold, and (d) 10-fold."
    },
    {
      "text": "significant features. Freitag et al. [54]  have used a deep model to classify the snoring sound signals. They used a spectrogram image of sound signals and a pre-trained deep feature generator. A metaheuristic optimization-based feature selector is utilized to select the features and these selected features are classified using SVM classifier. Their model used deep learning and metaheuristic optimization-based feature selectors, which is computationally expensive (high computational complexity). Our presented model reached higher performance than Freitag et al. [54]  model with lower time burden. Furthermore, Vesperini et al.'s [31]  used a deep model to classify these snoring sound signals and obtained an accuracy of 74.19 %. But our model has yielded the highest accuracy of 97.58 % and lower computational complexity."
    },
    {
      "text": "Fig. 8. Snapshot of the planned web-based real-time snoring sound classification and monitoring application."
    },
    {
      "text": "SBox of the present cipher."
    },
    {
      "text": "Results obtained using the proposed method."
    },
    {
      "text": "Confusion matrix obtained using the proposed model."
    },
    {
      "text": "Results (%) obtained using various validation techniques."
    },
    {
      "text": "Summary of comparison with other similar works developed using the same database."
    },
    {
      "text": "Accuracy (%) obtained using our method with the nocturnal sound dataset."
    },
    {
      "title": "Declaration of Competing Interest",
      "text": "The authors report no declarations of interest."
    }
  ],
  "references": [
    {
      "title": "Ambient air pollutants aggravate association of snoring with prevalent hypertension: results from the Henan Rural Cohort",
      "authors": [
        "H Zhang",
        "S Li",
        "G Chen",
        "T Abdulai",
        "X Liu",
        "Y Wang"
      ],
      "journal": "Chemosphere",
      "volume": "2020",
      "pages": "127108",
      "raw": "Ambient air pollutants aggravate association of snoring with prevalent hypertension: results from the Henan Rural Cohort \n\t\t \n\t\t\t H Zhang \n\t\t \n\t\t \n\t\t\t S Li \n\t\t \n\t\t \n\t\t\t G Chen \n\t\t \n\t\t \n\t\t\t T Abdulai \n\t\t \n\t\t \n\t\t\t X Liu \n\t\t \n\t\t \n\t\t\t Y Wang \n\t\t \n\t \n\t \n\t\t Chemosphere \n\t\t \n\t\t\t 2020 \n\t\t\t 127108 \n\t\t \n\t \n\t Zhang H, Li S, Chen G, Abdulai T, Liu X, Wang Y, et al. Ambient air pollutants aggravate association of snoring with prevalent hypertension: results from the Henan Rural Cohort. Chemosphere 2020:127108."
    },
    {
      "title": "An efficient method for snore/nonsnore classification of sleep sounds",
      "authors": [
        "M Cavusoglu",
        "M Kamasak",
        "O Erogul",
        "T Ciloglu",
        "Y Serinagaoglu",
        "T Akcam"
      ],
      "year": 2007,
      "doi": "10.1088/0967-3334/28/8/007",
      "journal": "Physiol Meas",
      "volume": "28",
      "pages": "841",
      "raw": "An efficient method for snore/nonsnore classification of sleep sounds \n\t\t \n\t\t\t M Cavusoglu \n\t\t \n\t\t \n\t\t\t M Kamasak \n\t\t \n\t\t \n\t\t\t O Erogul \n\t\t \n\t\t \n\t\t\t T Ciloglu \n\t\t \n\t\t \n\t\t\t Y Serinagaoglu \n\t\t \n\t\t \n\t\t\t T Akcam \n\t\t \n\t\t 10.1088/0967-3334/28/8/007 \n\t \n\t \n\t\t Physiol Meas \n\t\t \n\t\t\t 28 \n\t\t\t 841 \n\t\t\t 2007 \n\t\t \n\t \n\t Cavusoglu M, Kamasak M, Erogul O, Ciloglu T, Serinagaoglu Y, Akcam T. An efficient method for snore/nonsnore classification of sleep sounds. Physiol Meas 2007;28:841."
    },
    {
      "title": "Snoring patterns during home polysomnography. A proposal for a new classification",
      "authors": [
        "J Cambi",
        "Z Chiri",
        "S Boccuzzi"
      ],
      "year": 2020,
      "journal": "Am J Otolaryngol",
      "pages": "102589",
      "raw": "Snoring patterns during home polysomnography. A proposal for a new classification \n\t\t \n\t\t\t J Cambi \n\t\t \n\t\t \n\t\t\t Z M Chiri \n\t\t \n\t\t \n\t\t\t S Boccuzzi \n\t\t \n\t \n\t \n\t\t Am J Otolaryngol \n\t\t \n\t\t\t 102589 \n\t\t\t 2020 \n\t\t \n\t \n\t Cambi J, Chiri ZM, Boccuzzi S. Snoring patterns during home polysomnography. A proposal for a new classification. Am J Otolaryngol 2020:102589."
    },
    {
      "title": "Drug-induced sleep endoscopy: the VOTE classification",
      "authors": [
        "E Kezirian",
        "W Hohenhorst",
        "N De Vries"
      ],
      "year": 2011,
      "doi": "10.1007/s00405-011-1633-8",
      "journal": "Eur Arch Oto-Rhino-laryngol",
      "volume": "268",
      "raw": "Drug-induced sleep endoscopy: the VOTE classification \n\t\t \n\t\t\t E J Kezirian \n\t\t \n\t\t \n\t\t\t W Hohenhorst \n\t\t \n\t\t \n\t\t\t N De Vries \n\t\t \n\t\t 10.1007/s00405-011-1633-8 \n\t \n\t \n\t\t Eur Arch Oto-Rhino-laryngol \n\t\t \n\t\t\t 268 \n\t\t\t \n\t\t\t 2011 \n\t\t \n\t \n\t Kezirian EJ, Hohenhorst W, de Vries N. Drug-induced sleep endoscopy: the VOTE classification. Eur Arch Oto-Rhino-laryngol 2011;268:1233-6."
    },
    {
      "title": "Video sleep nasendoscopy: the Hong Kong experience",
      "authors": [
        "V Abdullah",
        "Y Wing",
        "Van Hasselt"
      ],
      "year": 2003,
      "doi": "10.1016/s0030-6665(02)00176-7",
      "journal": "Otolaryngol Clin North Am",
      "volume": "36",
      "raw": "Video sleep nasendoscopy: the Hong Kong experience \n\t\t \n\t\t\t V Abdullah \n\t\t \n\t\t \n\t\t\t Y Wing \n\t\t \n\t\t \n\t\t\t Van Hasselt \n\t\t \n\t\t \n\t\t\t C \n\t\t \n\t\t 10.1016/s0030-6665(02)00176-7 \n\t \n\t \n\t\t Otolaryngol Clin North Am \n\t\t \n\t\t\t 36 \n\t\t\t \n\t\t\t 2003 \n\t\t \n\t \n\t Abdullah V, Wing Y, Van Hasselt C. Video sleep nasendoscopy: the Hong Kong experience. Otolaryngol Clin North Am 2003;36:461-71."
    },
    {
      "title": "An automated snoring sound classification method based on local dual octal pattern and iterative hybrid feature selector",
      "authors": [
        "T Tuncer",
        "E Akbal",
        "S Dogan"
      ],
      "year": 2020,
      "doi": "10.1016/j.bspc.2020.102173",
      "journal": "Biomed Signal Process Control",
      "volume": "63",
      "pages": "102173",
      "raw": "An automated snoring sound classification method based on local dual octal pattern and iterative hybrid feature selector \n\t\t \n\t\t\t T Tuncer \n\t\t \n\t\t \n\t\t\t E Akbal \n\t\t \n\t\t \n\t\t\t S Dogan \n\t\t \n\t\t 10.1016/j.bspc.2020.102173 \n\t \n\t \n\t\t Biomed Signal Process Control \n\t\t \n\t\t\t 63 \n\t\t\t 102173 \n\t\t\t 2020 \n\t\t \n\t \n\t Tuncer T, Akbal E, Dogan S. An automated snoring sound classification method based on local dual octal pattern and iterative hybrid feature selector. Biomed Signal Process Control 2020;63:102173."
    },
    {
      "title": "Overview and implications of obstructive sleep apnoea",
      "authors": [
        "H Sharma",
        "S Sharma"
      ],
      "year": 2008,
      "doi": "10.53347/rid-72580",
      "journal": "Indian J Chest Dis Allied Sci",
      "volume": "50",
      "pages": "137",
      "raw": "Overview and implications of obstructive sleep apnoea \n\t\t \n\t\t\t H Sharma \n\t\t \n\t\t \n\t\t\t S Sharma \n\t\t \n\t\t 10.53347/rid-72580 \n\t \n\t \n\t\t Indian J Chest Dis Allied Sci \n\t\t \n\t\t\t 50 \n\t\t\t 137 \n\t\t\t 2008 \n\t\t \n\t \n\t Sharma H, Sharma S. Overview and implications of obstructive sleep apnoea. Indian J Chest Dis Allied Sci 2008;50:137."
    },
    {
      "title": "Palatal procedures for obstructive sleep apnea",
      "authors": [
        "K Yaremchuk"
      ],
      "year": 2016,
      "journal": "Otolaryngol Clin North Am",
      "volume": "49",
      "raw": "Palatal procedures for obstructive sleep apnea \n\t\t \n\t\t\t K Yaremchuk \n\t\t \n\t \n\t \n\t\t Otolaryngol Clin North Am \n\t\t \n\t\t\t 49 \n\t\t\t \n\t\t\t 2016 \n\t\t \n\t \n\t Yaremchuk K. Palatal procedures for obstructive sleep apnea. Otolaryngol Clin North Am 2016;49:1383-97."
    },
    {
      "title": "Clinical value of polysomnography",
      "authors": [
        "N Douglas",
        "S Thomas"
      ],
      "year": 1992,
      "doi": "10.1016/0140-6736(92)91660-z",
      "journal": "Lancet",
      "volume": "339",
      "raw": "Clinical value of polysomnography \n\t\t \n\t\t\t N J Douglas \n\t\t \n\t\t \n\t\t\t S Thomas \n\t\t \n\t\t \n\t\t\t Jan Ma \n\t\t \n\t\t 10.1016/0140-6736(92)91660-z \n\t \n\t \n\t\t Lancet \n\t\t \n\t\t\t 339 \n\t\t\t \n\t\t\t 1992 \n\t\t \n\t \n\t Douglas NJ, Thomas S, Jan MA. Clinical value of polysomnography. Lancet 1992; 339:347-50."
    },
    {
      "title": "Snore sound classification using image-based deep spectrum features",
      "authors": [
        "S Amiriparian",
        "M Gerczuk",
        "S Ottl",
        "N Cummins",
        "M Freitag",
        "S Pugachevskiy"
      ],
      "doi": "10.21437/interspeech.2017-434",
      "journal": "INTERSPEECH",
      "volume": "2017",
      "raw": "Snore sound classification using image-based deep spectrum features \n\t\t \n\t\t\t S Amiriparian \n\t\t \n\t\t \n\t\t\t M Gerczuk \n\t\t \n\t\t \n\t\t\t S Ottl \n\t\t \n\t\t \n\t\t\t N Cummins \n\t\t \n\t\t \n\t\t\t M Freitag \n\t\t \n\t\t \n\t\t\t S Pugachevskiy \n\t\t \n\t\t 10.21437/interspeech.2017-434 \n\t \n\t \n\t\t INTERSPEECH \n\t\t \n\t\t\t 2017 \n\t\t\t \n\t\t \n\t \n\t Amiriparian S, Gerczuk M, Ottl S, Cummins N, Freitag M, Pugachevskiy S, et al. Snore sound classification using image-based deep spectrum features. INTERSPEECH 2017:3512-6."
    },
    {
      "title": "Automatic breath and snore sounds classification from tracheal and ambient sounds recordings",
      "authors": [
        "A Yadollahi",
        "Z Moussavi"
      ],
      "year": 2010,
      "doi": "10.1016/j.medengphy.2010.06.013",
      "journal": "Med Eng Phys",
      "volume": "32",
      "raw": "Automatic breath and snore sounds classification from tracheal and ambient sounds recordings \n\t\t \n\t\t\t A Yadollahi \n\t\t \n\t\t \n\t\t\t Z Moussavi \n\t\t \n\t\t 10.1016/j.medengphy.2010.06.013 \n\t \n\t \n\t\t Med Eng Phys \n\t\t \n\t\t\t 32 \n\t\t\t \n\t\t\t 2010 \n\t\t \n\t \n\t Yadollahi A, Moussavi Z. Automatic breath and snore sounds classification from tracheal and ambient sounds recordings. Med Eng Phys 2010;32:985-90."
    },
    {
      "title": "A deep learning model for snoring detection and vibration notification using a smart wearable gadget",
      "authors": [
        "T Khan"
      ],
      "year": 2019,
      "journal": "Electronics",
      "volume": "8",
      "pages": "987",
      "raw": "A deep learning model for snoring detection and vibration notification using a smart wearable gadget \n\t\t \n\t\t\t T Khan \n\t\t \n\t \n\t \n\t\t Electronics \n\t\t \n\t\t\t 8 \n\t\t\t 987 \n\t\t\t 2019 \n\t\t \n\t \n\t Khan T. A deep learning model for snoring detection and vibration notification using a smart wearable gadget. Electronics 2019;8:987."
    },
    {
      "title": "Classification of snoring sound based on a recurrent neural network",
      "authors": [
        "S Lim",
        "S Jang",
        "J Lim",
        "J Ko"
      ],
      "year": 2019,
      "doi": "10.1016/j.eswa.2019.01.020",
      "journal": "Expert Syst Appl",
      "volume": "123",
      "raw": "Classification of snoring sound based on a recurrent neural network \n\t\t \n\t\t\t S J Lim \n\t\t \n\t\t \n\t\t\t S J Jang \n\t\t \n\t\t \n\t\t\t J Y Lim \n\t\t \n\t\t \n\t\t\t J H Ko \n\t\t \n\t\t 10.1016/j.eswa.2019.01.020 \n\t \n\t \n\t\t Expert Syst Appl \n\t\t \n\t\t\t 123 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Lim SJ, Jang SJ, Lim JY, Ko JH. Classification of snoring sound based on a recurrent neural network. Expert Syst Appl 2019;123:237-45."
    },
    {
      "title": "Automatic snore sound extraction from sleep sound recordings via auditory image modeling",
      "authors": [
        "R Nonaka",
        "T Emoto",
        "U Abeyratne",
        "O Jinnouchi",
        "I Kawata",
        "H Ohnishi"
      ],
      "year": 2016,
      "journal": "Biomed Signal Process Control",
      "volume": "27",
      "raw": "Automatic snore sound extraction from sleep sound recordings via auditory image modeling \n\t\t \n\t\t\t R Nonaka \n\t\t \n\t\t \n\t\t\t T Emoto \n\t\t \n\t\t \n\t\t\t U R Abeyratne \n\t\t \n\t\t \n\t\t\t O Jinnouchi \n\t\t \n\t\t \n\t\t\t I Kawata \n\t\t \n\t\t \n\t\t\t H Ohnishi \n\t\t \n\t \n\t \n\t\t Biomed Signal Process Control \n\t\t \n\t\t\t 27 \n\t\t\t \n\t\t\t 2016 \n\t\t \n\t \n\t Nonaka R, Emoto T, Abeyratne UR, Jinnouchi O, Kawata I, Ohnishi H, et al. Automatic snore sound extraction from sleep sound recordings via auditory image modeling. Biomed Signal Process Control 2016;27:7-14."
    },
    {
      "title": "A bag of wavelet features for snore sound classification",
      "authors": [
        "K Qian",
        "M Schmitt",
        "C Janott",
        "Z Zhang",
        "C Heiser",
        "W Hohenhorst"
      ],
      "year": 2019,
      "journal": "Ann Biomed Eng",
      "volume": "47",
      "raw": "A bag of wavelet features for snore sound classification \n\t\t \n\t\t\t K Qian \n\t\t \n\t\t \n\t\t\t M Schmitt \n\t\t \n\t\t \n\t\t\t C Janott \n\t\t \n\t\t \n\t\t\t Z Zhang \n\t\t \n\t\t \n\t\t\t C Heiser \n\t\t \n\t\t \n\t\t\t W Hohenhorst \n\t\t \n\t \n\t \n\t\t Ann Biomed Eng \n\t\t \n\t\t\t 47 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Qian K, Schmitt M, Janott C, Zhang Z, Heiser C, Hohenhorst W, et al. A bag of wavelet features for snore sound classification. Ann Biomed Eng 2019;47:1000-11."
    },
    {
      "title": "Acoustic information in snoring noises",
      "authors": [
        "C Janott",
        "B Schuller",
        "C Heiser"
      ],
      "year": 2017,
      "journal": "HNO",
      "volume": "65",
      "raw": "Acoustic information in snoring noises \n\t\t \n\t\t\t C Janott \n\t\t \n\t\t \n\t\t\t B Schuller \n\t\t \n\t\t \n\t\t\t C Heiser \n\t\t \n\t \n\t \n\t\t HNO \n\t\t \n\t\t\t 65 \n\t\t\t \n\t\t\t 2017 \n\t\t \n\t \n\t Janott C, Schuller B, Heiser C. Acoustic information in snoring noises. HNO 2017; 65:107-16."
    },
    {
      "title": "Prediction of obstructive sleep apnea based on respiratory sounds recorded between sleep onset and sleep offset",
      "authors": [
        "J-W Kim",
        "J-W Kim",
        "J Shin",
        "G Choe",
        "H Lim",
        "C-S Rhee"
      ],
      "year": 2019,
      "doi": "10.21053/ceo.2018.00388",
      "journal": "Clin Exp Otorhinolaryngol",
      "volume": "12",
      "pages": "72",
      "raw": "Prediction of obstructive sleep apnea based on respiratory sounds recorded between sleep onset and sleep offset \n\t\t \n\t\t\t J-W Kim \n\t\t \n\t\t \n\t\t\t J-W Kim \n\t\t \n\t\t \n\t\t\t J Shin \n\t\t \n\t\t \n\t\t\t G Choe \n\t\t \n\t\t \n\t\t\t H J Lim \n\t\t \n\t\t \n\t\t\t C-S Rhee \n\t\t \n\t\t 10.21053/ceo.2018.00388 \n\t \n\t \n\t\t Clin Exp Otorhinolaryngol \n\t\t \n\t\t\t 12 \n\t\t\t 72 \n\t\t\t 2019 \n\t\t \n\t \n\t Kim J-W, Kim J-W, Shin J, Choe G, Lim HJ, Rhee C-S, et al. Prediction of obstructive sleep apnea based on respiratory sounds recorded between sleep onset and sleep offset. Clin Exp Otorhinolaryngol 2019;12:72."
    },
    {
      "title": "Automatic snoring sounds detection from sleep sounds based on deep learning",
      "authors": [
        "Y Jiang",
        "J Peng",
        "X Zhang"
      ],
      "year": 2020,
      "doi": "10.1007/s13246-020-00876-1",
      "journal": "Phys Eng. Sci Med",
      "raw": "Automatic snoring sounds detection from sleep sounds based on deep learning \n\t\t \n\t\t\t Y Jiang \n\t\t \n\t\t \n\t\t\t J Peng \n\t\t \n\t\t \n\t\t\t X Zhang \n\t\t \n\t\t 10.1007/s13246-020-00876-1 \n\t \n\t \n\t\t Phys Eng. Sci Med \n\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Jiang Y, Peng J, Zhang X. Automatic snoring sounds detection from sleep sounds based on deep learning. Phys Eng. Sci Med 2020."
    },
    {
      "title": "Non-contact sleep stage detection using canonical correlation analysis of respiratory sound",
      "authors": [
        "B Xue",
        "B Deng",
        "H Hong",
        "Z Wang",
        "X Zhu",
        "D Feng"
      ],
      "year": 2019,
      "journal": "IEEE J Biomed Health Inform",
      "volume": "24",
      "raw": "Non-contact sleep stage detection using canonical correlation analysis of respiratory sound \n\t\t \n\t\t\t B Xue \n\t\t \n\t\t \n\t\t\t B Deng \n\t\t \n\t\t \n\t\t\t H Hong \n\t\t \n\t\t \n\t\t\t Z Wang \n\t\t \n\t\t \n\t\t\t X Zhu \n\t\t \n\t\t \n\t\t\t D D Feng \n\t\t \n\t \n\t \n\t\t IEEE J Biomed Health Inform \n\t\t \n\t\t\t 24 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Xue B, Deng B, Hong H, Wang Z, Zhu X, Feng DD. Non-contact sleep stage detection using canonical correlation analysis of respiratory sound. IEEE J Biomed Health Inform 2019;24:614-25."
    },
    {
      "title": "Sleep staging using nocturnal sound analysis",
      "authors": [
        "E Dafna",
        "A Tarasiuk",
        "Y Zigel"
      ],
      "year": 2018,
      "doi": "10.1038/s41598-018-31748-0",
      "journal": "Sci Rep",
      "volume": "8",
      "raw": "Sleep staging using nocturnal sound analysis \n\t\t \n\t\t\t E Dafna \n\t\t \n\t\t \n\t\t\t A Tarasiuk \n\t\t \n\t\t \n\t\t\t Y Zigel \n\t\t \n\t\t 10.1038/s41598-018-31748-0 \n\t \n\t \n\t\t Sci Rep \n\t\t \n\t\t\t 8 \n\t\t\t \n\t\t\t 2018 \n\t\t \n\t \n\t Dafna E, Tarasiuk A, Zigel Y. Sleep staging using nocturnal sound analysis. Sci Rep 2018;8:1-14."
    },
    {
      "title": "Classification of the excitation location of snore sounds in the upper airway by acoustic multifeature analysis",
      "authors": [
        "K Qian",
        "C Janott",
        "V Pandit",
        "Z Zhang",
        "C Heiser",
        "W Hohenhorst"
      ],
      "year": 2016,
      "journal": "IEEE Trans Biomed Eng",
      "volume": "64",
      "raw": "Classification of the excitation location of snore sounds in the upper airway by acoustic multifeature analysis \n\t\t \n\t\t\t K Qian \n\t\t \n\t\t \n\t\t\t C Janott \n\t\t \n\t\t \n\t\t\t V Pandit \n\t\t \n\t\t \n\t\t\t Z Zhang \n\t\t \n\t\t \n\t\t\t C Heiser \n\t\t \n\t\t \n\t\t\t W Hohenhorst \n\t\t \n\t \n\t \n\t\t IEEE Trans Biomed Eng \n\t\t \n\t\t\t 64 \n\t\t\t \n\t\t\t 2016 \n\t\t \n\t \n\t Qian K, Janott C, Pandit V, Zhang Z, Heiser C, Hohenhorst W, et al. Classification of the excitation location of snore sounds in the upper airway by acoustic multifeature analysis. IEEE Trans Biomed Eng 2016;64:1731-41."
    },
    {
      "title": "Snore recognition using a reduced set of spectral features",
      "authors": [
        "E Albornoz",
        "L Bugnon",
        "C Mart\u00ednez"
      ],
      "year": 2017,
      "doi": "10.23919/rpic.2017.8214357",
      "raw": "Snore recognition using a reduced set of spectral features \n\t\t \n\t\t\t E M Albornoz \n\t\t \n\t\t \n\t\t\t L A Bugnon \n\t\t \n\t\t \n\t\t\t C E Mart\u00ednez \n\t\t \n\t\t 10.23919/rpic.2017.8214357 \n\t \n\t \n\t\t 2017 XVII Workshop on Information Processing and Control (RPIC) \n\t\t \n\t\t\t 2017 \n\t\t\t \n\t\t \n\t \n\t Albornoz EM, Bugnon LA, Mart\u00ednez CE. Snore recognition using a reduced set of spectral features. In: 2017 XVII Workshop on Information Processing and Control (RPIC); 2017. p. 1-5."
    },
    {
      "title": "A discriminative filter bank model for speech recognition",
      "authors": [
        "A Biem",
        "E Mcdermott",
        "S Katagiri"
      ],
      "year": 1995,
      "doi": "10.21437/eurospeech.1995-140",
      "raw": "A discriminative filter bank model for speech recognition \n\t\t \n\t\t\t A Biem \n\t\t \n\t\t \n\t\t\t E Mcdermott \n\t\t \n\t\t \n\t\t\t S Katagiri \n\t\t \n\t\t 10.21437/eurospeech.1995-140 \n\t \n\t \n\t\t Fourth European Conference on Speech Communication and Technology \n\t\t \n\t\t\t 1995 \n\t\t \n\t \n\t Biem A, McDermott E, Katagiri S. A discriminative filter bank model for speech recognition. Fourth European Conference on Speech Communication and Technology 1995."
    },
    {
      "title": "The support vector method of function estimation",
      "authors": [
        "V Vapnik"
      ],
      "year": 1998,
      "journal": "Nonlinear Modeling",
      "raw": "The support vector method of function estimation \n\t\t \n\t\t\t V Vapnik \n\t\t \n\t \n\t \n\t\t Nonlinear Modeling \n\t\t \n\t\t\t \n\t\t\t 1998 \n\t\t\t Springer \n\t\t \n\t \n\t Vapnik V. The support vector method of function estimation. Nonlinear Modeling: Springer; 1998. p. 55-85."
    },
    {
      "title": "The nature of statistical learning theory",
      "authors": [
        "V Vapnik"
      ],
      "year": 2013,
      "doi": "10.1007/978-1-4757-3264-1_8",
      "raw": "The nature of statistical learning theory \n\t\t \n\t\t\t V Vapnik \n\t\t \n\t\t 10.1007/978-1-4757-3264-1_8 \n\t\t \n\t\t\t 2013 \n\t\t\t Springer science & business media \n\t\t \n\t \n\t Vapnik V. The nature of statistical learning theory. Springer science & business media; 2013."
    },
    {
      "title": "Imagenet classification with deep convolutional neural networks",
      "authors": [
        "A Krizhevsky",
        "I Sutskever",
        "G Hinton"
      ],
      "year": 2017,
      "journal": "Commun ACM",
      "volume": "60",
      "raw": "Imagenet classification with deep convolutional neural networks \n\t\t \n\t\t\t A Krizhevsky \n\t\t \n\t\t \n\t\t\t I Sutskever \n\t\t \n\t\t \n\t\t\t G E Hinton \n\t\t \n\t \n\t \n\t\t Commun ACM \n\t\t \n\t\t\t 60 \n\t\t\t \n\t\t\t 2017 \n\t\t \n\t \n\t Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional neural networks. Commun ACM 2017;60:84-90."
    },
    {
      "title": "Low level texture features for snore sound discrimination",
      "authors": [
        "F Demir",
        "A Sengur",
        "N Cummins",
        "S Amiriparian",
        "B Schuller"
      ],
      "year": 2018,
      "doi": "10.1109/embc.2018.8512459",
      "raw": "Low level texture features for snore sound discrimination \n\t\t \n\t\t\t F Demir \n\t\t \n\t\t \n\t\t\t A Sengur \n\t\t \n\t\t \n\t\t\t N Cummins \n\t\t \n\t\t \n\t\t\t S Amiriparian \n\t\t \n\t\t \n\t\t\t B Schuller \n\t\t \n\t\t 10.1109/embc.2018.8512459 \n\t \n\t \n\t\t 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) \n\t\t \n\t\t\t 2018 \n\t\t\t \n\t\t \n\t \n\t Demir F, Sengur A, Cummins N, Amiriparian S, Schuller B. Low level texture features for snore sound discrimination. In: 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC); 2018. p. 413-6."
    },
    {
      "title": "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns",
      "authors": [
        "T Ojala",
        "M Pietikainen",
        "T Maenpaa"
      ],
      "year": 2002,
      "journal": "IEEE Trans Pattern Anal Mach Intell",
      "volume": "24",
      "raw": "Multiresolution gray-scale and rotation invariant texture classification with local binary patterns \n\t\t \n\t\t\t T Ojala \n\t\t \n\t\t \n\t\t\t M Pietikainen \n\t\t \n\t\t \n\t\t\t T Maenpaa \n\t\t \n\t \n\t \n\t\t IEEE Trans Pattern Anal Mach Intell \n\t\t \n\t\t\t 24 \n\t\t\t \n\t\t\t 2002 \n\t\t \n\t \n\t Ojala T, Pietikainen M, Maenpaa T. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. IEEE Trans Pattern Anal Mach Intell 2002;24:971-87."
    },
    {
      "title": "Histograms of oriented gradients for human detection",
      "authors": [
        "N Dalal",
        "B Triggs"
      ],
      "year": 2005,
      "doi": "10.1109/cvpr.2005.177",
      "raw": "Histograms of oriented gradients for human detection \n\t\t \n\t\t\t N Dalal \n\t\t \n\t\t \n\t\t\t B Triggs \n\t\t \n\t\t 10.1109/cvpr.2005.177 \n\t \n\t \n\t\t IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) \n\t\t \n\t\t\t 2005. 2005 \n\t\t\t \n\t\t \n\t \n\t Dalal N, Triggs B. Histograms of oriented gradients for human detection. In: 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05); 2005. p. 886-93."
    },
    {
      "title": "Model determination using predictive distributions with implementation via sampling-based methods",
      "authors": [
        "A Gelfand",
        "D Dey",
        "H Chang"
      ],
      "year": 1992,
      "doi": "10.1093/oso/9780198522669.003.0009",
      "raw": "Model determination using predictive distributions with implementation via sampling-based methods \n\t\t \n\t\t\t A E Gelfand \n\t\t \n\t\t \n\t\t\t D K Dey \n\t\t \n\t\t \n\t\t\t H Chang \n\t\t \n\t\t 10.1093/oso/9780198522669.003.0009 \n\t\t \n\t\t\t 1992 \n\t\t \n\t\t \n\t\t\t Stanford Univ CA Dept of Statistics \n\t\t \n\t \n\t Gelfand AE, Dey DK, Chang H. Model determination using predictive distributions with implementation via sampling-based methods. Stanford Univ CA Dept of Statistics; 1992."
    },
    {
      "title": "Snore sounds excitation localization by using scattering transform and deep neural networks",
      "authors": [
        "F Vesperini",
        "A Galli",
        "L Gabrielli",
        "E Principi",
        "S Squartini"
      ],
      "year": 2018,
      "doi": "10.1109/ijcnn.2018.8489576",
      "raw": "Snore sounds excitation localization by using scattering transform and deep neural networks \n\t\t \n\t\t\t F Vesperini \n\t\t \n\t\t \n\t\t\t A Galli \n\t\t \n\t\t \n\t\t\t L Gabrielli \n\t\t \n\t\t \n\t\t\t E Principi \n\t\t \n\t\t \n\t\t\t S Squartini \n\t\t \n\t\t 10.1109/ijcnn.2018.8489576 \n\t \n\t \n\t\t 2018 International Joint Conference on Neural Networks (IJCNN) \n\t\t \n\t\t\t 2018 \n\t\t\t \n\t\t \n\t \n\t Vesperini F, Galli A, Gabrielli L, Principi E, Squartini S. Snore sounds excitation localization by using scattering transform and deep neural networks. In: 2018 International Joint Conference on Neural Networks (IJCNN); 2018. p. 1-8."
    },
    {
      "title": "A classification method related to respiratory disorder events based on acoustical analysis of snoring",
      "authors": [
        "C Wang",
        "J Peng",
        "X Zhang"
      ],
      "year": 2020,
      "journal": "Arch Acoust",
      "volume": "45",
      "raw": "A classification method related to respiratory disorder events based on acoustical analysis of snoring \n\t\t \n\t\t\t C Wang \n\t\t \n\t\t \n\t\t\t J Peng \n\t\t \n\t\t \n\t\t\t X Zhang \n\t\t \n\t \n\t \n\t\t Arch Acoust \n\t\t \n\t\t\t 45 \n\t\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Wang C, Peng J, Zhang X. A classification method related to respiratory disorder events based on acoustical analysis of snoring. Arch Acoust 2020;45:141-51."
    },
    {
      "title": "Learning representations by backpropagating errors",
      "authors": [
        "D Rumelhart",
        "G Hinton",
        "R Williams"
      ],
      "year": 1986,
      "doi": "10.1038/323533a0",
      "journal": "Nature",
      "volume": "323",
      "raw": "Learning representations by backpropagating errors \n\t\t \n\t\t\t D E Rumelhart \n\t\t \n\t\t \n\t\t\t G E Hinton \n\t\t \n\t\t \n\t\t\t R J Williams \n\t\t \n\t\t 10.1038/323533a0 \n\t \n\t \n\t\t Nature \n\t\t \n\t\t\t 323 \n\t\t\t \n\t\t\t 1986 \n\t\t \n\t \n\t Rumelhart DE, Hinton GE, Williams RJ. Learning representations by back- propagating errors. Nature 1986;323:533-6."
    },
    {
      "title": "Report of the workshop on cryptography in support of computer security",
      "authors": [
        "D Branstad",
        "J Gait",
        "S Katzke"
      ],
      "year": 1977,
      "doi": "10.6028/nbs.ir.77-1291",
      "raw": "Report of the workshop on cryptography in support of computer security \n\t\t \n\t\t\t D Branstad \n\t\t \n\t\t \n\t\t\t J Gait \n\t\t \n\t\t \n\t\t\t S Katzke \n\t\t \n\t\t 10.6028/nbs.ir.77-1291 \n\t\t \n\t\t\t 1977 \n\t\t\t National Institute of Standards and Technology \n\t\t \n\t \n\t Branstad D, Gait J, Katzke S. Report of the workshop on cryptography in support of computer security. National Institute of Standards and Technology; 1977."
    },
    {
      "title": "Essential algebraic structure within the AES",
      "authors": [
        "S Murphy",
        "M Robshaw"
      ],
      "year": 2002,
      "doi": "10.1007/3-540-45708-9_1",
      "raw": "Essential algebraic structure within the AES \n\t\t \n\t\t\t S Murphy \n\t\t \n\t\t \n\t\t\t M J Robshaw \n\t\t \n\t\t 10.1007/3-540-45708-9_1 \n\t \n\t \n\t\t Annual International Cryptology Conference \n\t\t \n\t\t\t 2002 \n\t\t\t \n\t\t \n\t \n\t Murphy S, Robshaw MJ. Essential algebraic structure within the AES. In: Annual International Cryptology Conference; 2002. p. 1-16."
    },
    {
      "title": "A simple algebraic representation of rijndael",
      "authors": [
        "N Ferguson",
        "R Schroeppel",
        "D Whiting"
      ],
      "year": 2001,
      "doi": "10.1007/3-540-45537-x_8",
      "raw": "A simple algebraic representation of rijndael \n\t\t \n\t\t\t N Ferguson \n\t\t \n\t\t \n\t\t\t R Schroeppel \n\t\t \n\t\t \n\t\t\t D Whiting \n\t\t \n\t\t 10.1007/3-540-45537-x_8 \n\t \n\t \n\t\t International Workshop on Selected Areas in Cryptography \n\t\t \n\t\t\t 2001 \n\t\t\t \n\t\t \n\t \n\t Ferguson N, Schroeppel R, Whiting D. A simple algebraic representation of rijndael. In: International Workshop on Selected Areas in Cryptography; 2001. p. 103-11."
    },
    {
      "title": "In: A Systematic Evaluation of Compact Hardware Implementations for the Rijndael S-Box",
      "authors": [
        "N Mentens",
        "L Batina",
        "B Preneel",
        "I Verbauwhede"
      ],
      "year": 2005,
      "raw": "In: A Systematic Evaluation of Compact Hardware Implementations for the Rijndael S-Box \n\t\t \n\t\t\t N Mentens \n\t\t \n\t\t \n\t\t\t L Batina \n\t\t \n\t\t \n\t\t\t B Preneel \n\t\t \n\t\t \n\t\t\t I Verbauwhede \n\t\t \n\t \n\t \n\t\t Cryptographers' Track at the RSA Conference \n\t\t \n\t\t\t 2005 \n\t\t\t \n\t\t \n\t \n\t Mentens N, Batina L, Preneel B, Verbauwhede I. In: A Systematic Evaluation of Compact Hardware Implementations for the Rijndael S-Box. Cryptographers' Track at the RSA Conference; 2005. p. 323-33."
    },
    {
      "title": "Integration of deep feature representations and handcrafted features to improve the prediction of N6methyladenosine sites",
      "authors": [
        "L Wei",
        "R Su",
        "B Wang",
        "X Li",
        "Q Zou",
        "X Gao"
      ],
      "year": 2019,
      "doi": "10.1016/j.neucom.2018.04.082",
      "journal": "Neurocomputing",
      "volume": "324",
      "raw": "Integration of deep feature representations and handcrafted features to improve the prediction of N6methyladenosine sites \n\t\t \n\t\t\t L Wei \n\t\t \n\t\t \n\t\t\t R Su \n\t\t \n\t\t \n\t\t\t B Wang \n\t\t \n\t\t \n\t\t\t X Li \n\t\t \n\t\t \n\t\t\t Q Zou \n\t\t \n\t\t \n\t\t\t X Gao \n\t\t \n\t\t 10.1016/j.neucom.2018.04.082 \n\t \n\t \n\t\t Neurocomputing \n\t\t \n\t\t\t 324 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Wei L, Su R, Wang B, Li X, Zou Q, Gao X. Integration of deep feature representations and handcrafted features to improve the prediction of N6- methyladenosine sites. Neurocomputing 2019;324:3-9."
    },
    {
      "title": "Snoring classified: the Munich-Passau snore sound corpus",
      "authors": [
        "C Janott",
        "M Schmitt",
        "Y Zhang",
        "K Qian",
        "V Pandit",
        "Z Zhang"
      ],
      "year": 2018,
      "doi": "10.1016/j.compbiomed.2018.01.007",
      "journal": "Comput Biol Med",
      "volume": "94",
      "raw": "Snoring classified: the Munich-Passau snore sound corpus \n\t\t \n\t\t\t C Janott \n\t\t \n\t\t \n\t\t\t M Schmitt \n\t\t \n\t\t \n\t\t\t Y Zhang \n\t\t \n\t\t \n\t\t\t K Qian \n\t\t \n\t\t \n\t\t\t V Pandit \n\t\t \n\t\t \n\t\t\t Z Zhang \n\t\t \n\t\t 10.1016/j.compbiomed.2018.01.007 \n\t \n\t \n\t\t Comput Biol Med \n\t\t \n\t\t\t 94 \n\t\t\t \n\t\t\t 2018 \n\t\t \n\t \n\t Janott C, Schmitt M, Zhang Y, Qian K, Pandit V, Zhang Z, et al. Snoring classified: the Munich-Passau snore sound corpus. Comput Biol Med 2018;94:106-18."
    },
    {
      "title": "VOTE versus ACLTE: comparison of two snoring noise classifications using machine learning methods",
      "authors": [
        "C Janott",
        "M Schmitt",
        "C Heiser",
        "W Hohenhorst",
        "M Herzog",
        "M Carrasco"
      ],
      "year": 2019,
      "journal": "HNO",
      "volume": "67",
      "raw": "VOTE versus ACLTE: comparison of two snoring noise classifications using machine learning methods \n\t\t \n\t\t\t C Janott \n\t\t \n\t\t \n\t\t\t M Schmitt \n\t\t \n\t\t \n\t\t\t C Heiser \n\t\t \n\t\t \n\t\t\t W Hohenhorst \n\t\t \n\t\t \n\t\t\t M Herzog \n\t\t \n\t\t \n\t\t\t M L Carrasco \n\t\t \n\t \n\t \n\t\t HNO \n\t\t \n\t\t\t 67 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Janott C, Schmitt M, Heiser C, Hohenhorst W, Herzog M, Carrasco ML, et al. VOTE versus ACLTE: comparison of two snoring noise classifications using machine learning methods. HNO 2019;67:670-8."
    },
    {
      "title": "Novel multi center and threshold ternary pattern based method for disease detection method using voice",
      "authors": [
        "T Tuncer",
        "S Dogan",
        "F \u00d6zyurt",
        "S Belhaouari",
        "H Bensmail"
      ],
      "year": 2020,
      "journal": "IEEE Access",
      "volume": "8",
      "raw": "Novel multi center and threshold ternary pattern based method for disease detection method using voice \n\t\t \n\t\t\t T Tuncer \n\t\t \n\t\t \n\t\t\t S Dogan \n\t\t \n\t\t \n\t\t\t F \u00d6zyurt \n\t\t \n\t\t \n\t\t\t S B Belhaouari \n\t\t \n\t\t \n\t\t\t H Bensmail \n\t\t \n\t \n\t \n\t\t IEEE Access \n\t\t \n\t\t\t 8 \n\t\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Tuncer T, Dogan S, \u00d6zyurt F, Belhaouari SB, Bensmail H. Novel multi center and threshold ternary pattern based method for disease detection method using voice. IEEE Access 2020;8:84532-40."
    },
    {
      "title": "Ns-k-nn: Neutrosophic set-based knearest neighbors classifier",
      "authors": [
        "Y Akbulut",
        "A Sengur",
        "Y Guo",
        "F Smarandache"
      ],
      "year": 2017,
      "journal": "Symmetry",
      "volume": "9",
      "pages": "179",
      "raw": "Ns-k-nn: Neutrosophic set-based knearest neighbors classifier \n\t\t \n\t\t\t Y Akbulut \n\t\t \n\t\t \n\t\t\t A Sengur \n\t\t \n\t\t \n\t\t\t Y Guo \n\t\t \n\t\t \n\t\t\t F Smarandache \n\t\t \n\t \n\t \n\t\t Symmetry \n\t\t \n\t\t\t 9 \n\t\t\t 179 \n\t\t\t 2017 \n\t\t \n\t \n\t Akbulut Y, Sengur A, Guo Y, Smarandache F. Ns-k-nn: Neutrosophic set-based k- nearest neighbors classifier. Symmetry 2017;9:179."
    },
    {
      "title": "Sens\u00f6r is \u00b8aretlerinden cinsiyet tan\u0131ma i\u00e7in yerel ikili \u00f6r\u00fcnt\u00fcler tabanl\u0131 yeni yaklas \u00b8\u0131mlar",
      "authors": [
        "F Kuncan",
        "Y Kaya",
        "M Kuncan"
      ],
      "year": 2019,
      "journal": "J Faculty Eng Arch Gazi Univ",
      "pages": "34",
      "raw": "Sens\u00f6r is \u00b8aretlerinden cinsiyet tan\u0131ma i\u00e7in yerel ikili \u00f6r\u00fcnt\u00fcler tabanl\u0131 yeni yaklas \u00b8\u0131mlar \n\t\t \n\t\t\t F Kuncan \n\t\t \n\t\t \n\t\t\t Y Kaya \n\t\t \n\t\t \n\t\t\t M Kuncan \n\t\t \n\t \n\t \n\t\t J Faculty Eng Arch Gazi Univ \n\t\t \n\t\t\t 34 \n\t\t\t 2019 \n\t\t \n\t \n\t Kuncan F, Kaya Y, Kuncan M. Sens\u00f6r is \u00b8aretlerinden cinsiyet tan\u0131ma i\u00e7in yerel ikili \u00f6r\u00fcnt\u00fcler tabanl\u0131 yeni yaklas \u00b8\u0131mlar. J Faculty Eng Arch Gazi Univ 2019:34."
    },
    {
      "title": "Classification of focal and non-focal EEG signals using neighborhood component analysis and machine learning algorithms",
      "authors": [
        "S Raghu",
        "N Sriraam"
      ],
      "year": 2018,
      "journal": "Expert Syst Appl",
      "volume": "113",
      "raw": "Classification of focal and non-focal EEG signals using neighborhood component analysis and machine learning algorithms \n\t\t \n\t\t\t S Raghu \n\t\t \n\t\t \n\t\t\t N Sriraam \n\t\t \n\t \n\t \n\t\t Expert Syst Appl \n\t\t \n\t\t\t 113 \n\t\t\t \n\t\t\t 2018 \n\t\t \n\t \n\t Raghu S, Sriraam N. Classification of focal and non-focal EEG signals using neighborhood component analysis and machine learning algorithms. Expert Syst Appl 2018;113:18-32."
    },
    {
      "title": "kNN-IS: an iterative spark-based design of the k-nearest neighbors classifier for big data",
      "authors": [
        "J Maillo",
        "S Ram\u00edrez",
        "I Triguero",
        "F Herrera"
      ],
      "year": 2017,
      "journal": "Knowledge Based Syst",
      "volume": "117",
      "raw": "kNN-IS: an iterative spark-based design of the k-nearest neighbors classifier for big data \n\t\t \n\t\t\t J Maillo \n\t\t \n\t\t \n\t\t\t S Ram\u00edrez \n\t\t \n\t\t \n\t\t\t I Triguero \n\t\t \n\t\t \n\t\t\t F Herrera \n\t\t \n\t \n\t \n\t\t Knowledge Based Syst \n\t\t \n\t\t\t 117 \n\t\t\t \n\t\t\t 2017 \n\t\t \n\t \n\t Maillo J, Ram\u00edrez S, Triguero I, Herrera F. kNN-IS: an iterative spark-based design of the k-nearest neighbors classifier for big data. Knowledge Based Syst 2017;117: 3-15."
    },
    {
      "title": "Practical Bayesian model evaluation using leaveone-out cross-validation and WAIC",
      "authors": [
        "A Vehtari",
        "A Gelman",
        "J Gabry"
      ],
      "year": 2017,
      "journal": "Stat Comput",
      "volume": "27",
      "raw": "Practical Bayesian model evaluation using leaveone-out cross-validation and WAIC \n\t\t \n\t\t\t A Vehtari \n\t\t \n\t\t \n\t\t\t A Gelman \n\t\t \n\t\t \n\t\t\t J Gabry \n\t\t \n\t \n\t \n\t\t Stat Comput \n\t\t \n\t\t\t 27 \n\t\t\t \n\t\t\t 2017 \n\t\t \n\t \n\t Vehtari A, Gelman A, Gabry J. Practical Bayesian model evaluation using leave- one-out cross-validation and WAIC. Stat Comput 2017;27:1413-32."
    },
    {
      "title": "Automated arrhythmia detection using novel hexadecimal local pattern and multilevel wavelet transform with ECG signals",
      "authors": [
        "T Tuncer",
        "S Dogan",
        "P P\u0142awiak",
        "U Acharya"
      ],
      "year": 2019,
      "journal": "Knowledge Based Syst",
      "volume": "186",
      "pages": "104923",
      "raw": "Automated arrhythmia detection using novel hexadecimal local pattern and multilevel wavelet transform with ECG signals \n\t\t \n\t\t\t T Tuncer \n\t\t \n\t\t \n\t\t\t S Dogan \n\t\t \n\t\t \n\t\t\t P P\u0142awiak \n\t\t \n\t\t \n\t\t\t U R Acharya \n\t\t \n\t \n\t \n\t\t Knowledge Based Syst \n\t\t \n\t\t\t 186 \n\t\t\t 104923 \n\t\t\t 2019 \n\t\t \n\t \n\t Tuncer T, Dogan S, P\u0142awiak P, Acharya UR. Automated arrhythmia detection using novel hexadecimal local pattern and multilevel wavelet transform with ECG signals. Knowledge Based Syst 2019;186:104923."
    },
    {
      "title": "The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation",
      "authors": [
        "D Chicco",
        "G Jurman"
      ],
      "year": 2020,
      "doi": "10.1186/s12864-019-6413-7",
      "journal": "BMC Genomics",
      "volume": "21",
      "pages": "6",
      "raw": "The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation \n\t\t \n\t\t\t D Chicco \n\t\t \n\t\t \n\t\t\t G Jurman \n\t\t \n\t\t 10.1186/s12864-019-6413-7 \n\t \n\t \n\t\t BMC Genomics \n\t\t \n\t\t\t 21 \n\t\t\t 6 \n\t\t\t 2020 \n\t\t \n\t \n\t Chicco D, Jurman G. The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. BMC Genomics 2020;21:6."
    },
    {
      "title": "On the equivalence of Cohen's kappa and the Hubert-Arabie adjusted Rand index",
      "authors": [
        "M Warrens"
      ],
      "year": 2008,
      "journal": "J Classif",
      "volume": "25",
      "raw": "On the equivalence of Cohen's kappa and the Hubert-Arabie adjusted Rand index \n\t\t \n\t\t\t M J Warrens \n\t\t \n\t \n\t \n\t\t J Classif \n\t\t \n\t\t\t 25 \n\t\t\t \n\t\t\t 2008 \n\t\t \n\t \n\t Warrens MJ. On the equivalence of Cohen's kappa and the Hubert-Arabie adjusted Rand index. J Classif 2008;25:177-83."
    },
    {
      "title": "Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation",
      "authors": [
        "D Powers"
      ],
      "raw": "D M Powers \n\t\t \n\t\t arXiv 2020:201016061 \n\t\t Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation \n\t\t \n\t \n\t arXiv preprint \n\t Powers DM. Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation. arXiv preprint arXiv 2020:201016061."
    },
    {
      "title": "A dual source-filter model of snore audio for snorer group classification",
      "authors": [
        "M Rao",
        "S Yadav",
        "P Ghosh"
      ],
      "journal": "INTERSPEECH",
      "volume": "2017",
      "raw": "A dual source-filter model of snore audio for snorer group classification \n\t\t \n\t\t\t M A Rao \n\t\t \n\t\t \n\t\t\t S Yadav \n\t\t \n\t\t \n\t\t\t P K Ghosh \n\t\t \n\t \n\t \n\t\t INTERSPEECH \n\t\t \n\t\t\t 2017 \n\t\t\t \n\t\t \n\t \n\t Rao MA, Yadav S, Ghosh PK. A dual source-filter model of snore audio for snorer group classification. INTERSPEECH 2017:3502-6."
    },
    {
      "title": "A CNN-GRU approach to capture timefrequency pattern interdependence for snore sound classification",
      "authors": [
        "J Wang",
        "H Str\u00f6mfeli",
        "B Schuller"
      ],
      "year": 2018,
      "raw": "A CNN-GRU approach to capture timefrequency pattern interdependence for snore sound classification \n\t\t \n\t\t\t J Wang \n\t\t \n\t\t \n\t\t\t H Str\u00f6mfeli \n\t\t \n\t\t \n\t\t\t B W Schuller \n\t\t \n\t \n\t \n\t\t 2018 26th European Signal Processing Conference (EUSIPCO) \n\t\t \n\t\t\t 2018 \n\t\t\t \n\t\t \n\t \n\t Wang J, Str\u00f6mfeli H, Schuller BW. A CNN-GRU approach to capture time- frequency pattern interdependence for snore sound classification. In: 2018 26th European Signal Processing Conference (EUSIPCO); 2018. p. 997-1001."
    },
    {
      "title": "Snore-GANs: Improving automatic snore sound classification with synthesized data",
      "authors": [
        "Z Zhang",
        "J Han",
        "K Qian",
        "C Janott",
        "Y Guo",
        "B Schuller"
      ],
      "year": 2019,
      "journal": "IEEE J Biomed Health Inform",
      "volume": "24",
      "raw": "Snore-GANs: Improving automatic snore sound classification with synthesized data \n\t\t \n\t\t\t Z Zhang \n\t\t \n\t\t \n\t\t\t J Han \n\t\t \n\t\t \n\t\t\t K Qian \n\t\t \n\t\t \n\t\t\t C Janott \n\t\t \n\t\t \n\t\t\t Y Guo \n\t\t \n\t\t \n\t\t\t B Schuller \n\t\t \n\t \n\t \n\t\t IEEE J Biomed Health Inform \n\t\t \n\t\t\t 24 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Zhang Z, Han J, Qian K, Janott C, Guo Y, Schuller B. Snore-GANs: Improving automatic snore sound classification with synthesized data. IEEE J Biomed Health Inform 2019;24:300-10."
    },
    {
      "title": "An'end-toevolution'hybrid approach for snore sound classification",
      "authors": [
        "M Freitag",
        "S Amiriparian",
        "N Cummins",
        "M Gerczuk",
        "B Schuller"
      ],
      "doi": "10.21437/interspeech.2017-173",
      "journal": "INTERSPEECH",
      "volume": "2017",
      "raw": "An'end-toevolution'hybrid approach for snore sound classification \n\t\t \n\t\t\t M Freitag \n\t\t \n\t\t \n\t\t\t S Amiriparian \n\t\t \n\t\t \n\t\t\t N Cummins \n\t\t \n\t\t \n\t\t\t M Gerczuk \n\t\t \n\t\t \n\t\t\t B W Schuller \n\t\t \n\t\t 10.21437/interspeech.2017-173 \n\t \n\t \n\t\t INTERSPEECH \n\t\t \n\t\t\t 2017 \n\t\t\t \n\t\t \n\t \n\t Freitag M, Amiriparian S, Cummins N, Gerczuk M, Schuller BW. An'end-to- evolution'hybrid approach for snore sound classification. INTERSPEECH 2017: 3507-11."
    },
    {
      "title": "FusedTSNet: an automated nocturnal sleep sound classification method based on a fused textural and statistical feature generation network",
      "authors": [
        "E Akbal",
        "T Tuncer"
      ],
      "year": 2021,
      "doi": "10.1016/j.apacoust.2020.107559",
      "journal": "Appl Acoust",
      "volume": "171",
      "pages": "107559",
      "raw": "FusedTSNet: an automated nocturnal sleep sound classification method based on a fused textural and statistical feature generation network \n\t\t \n\t\t\t E Akbal \n\t\t \n\t\t \n\t\t\t T Tuncer \n\t\t \n\t\t 10.1016/j.apacoust.2020.107559 \n\t \n\t \n\t\t Appl Acoust \n\t\t \n\t\t\t 171 \n\t\t\t 107559 \n\t\t\t 2021 \n\t\t \n\t \n\t Akbal E, Tuncer T. FusedTSNet: an automated nocturnal sleep sound classification method based on a fused textural and statistical feature generation network. Appl Acoust 2021;171:107559."
    }
  ],
  "num_references": 55,
  "figures": [
    {
      "caption": "Fig. 1 .",
      "description": "Fig. 1. General flow diagram of automated SSC model."
    },
    {
      "caption": "Fig. 2 .",
      "description": "Fig. 2. Snapshot of proposed multiple kernel Present-Pat, MAP feature generation, and NCAINCA selector based SSC method."
    },
    {
      "caption": "Fig. 3 .",
      "description": "Fig. 3. Illustration of MAP decomposition."
    },
    {
      "description": "This work employed three novel functions: Present-Pat feature generation function, MAP decomposer, and NCAINCA selector to develop an accurate SSC model. The Present-Pat based snoring sound classification"
    },
    {
      "caption": "Fig. 4 .",
      "description": "Fig. 4. Plot of accuracies versus the number of levels obtained using our proposed method."
    },
    {
      "caption": "Fig. 5 .Fig. 6 .",
      "description": "Fig. 5. Graph of loss value versus the number of features obtained during feature selection process using NCAINCA selector."
    },
    {
      "caption": "Fig. 7 .",
      "description": "Fig. 7. Confusion matrices obtained using four validation techniques with our proposed method: (a) hold-out (75 %-25 %), (b) hold-out (50 %-50 %), (c) 3-fold, and (d) 10-fold."
    },
    {
      "description": "significant features. Freitag et al. [54]  have used a deep model to classify the snoring sound signals. They used a spectrogram image of sound signals and a pre-trained deep feature generator. A metaheuristic optimization-based feature selector is utilized to select the features and these selected features are classified using SVM classifier. Their model used deep learning and metaheuristic optimization-based feature selectors, which is computationally expensive (high computational complexity). Our presented model reached higher performance than Freitag et al. [54]  model with lower time burden. Furthermore, Vesperini et al.'s [31]  used a deep model to classify these snoring sound signals and obtained an accuracy of 74.19 %. But our model has yielded the highest accuracy of 97.58 % and lower computational complexity."
    },
    {
      "caption": "Fig. 8 .",
      "description": "Fig. 8. Snapshot of the planned web-based real-time snoring sound classification and monitoring application."
    },
    {
      "type": "table",
      "caption": "Table 1",
      "description": "SBox of the present cipher."
    },
    {
      "type": "table",
      "caption": "Table 2",
      "description": "Results obtained using the proposed method."
    },
    {
      "type": "table",
      "caption": "Table 3",
      "description": "Confusion matrix obtained using the proposed model."
    },
    {
      "type": "table",
      "caption": "Table 4",
      "description": "Results (%) obtained using various validation techniques."
    },
    {
      "type": "table",
      "caption": "Table 5",
      "description": "Summary of comparison with other similar works developed using the same database."
    },
    {
      "type": "table",
      "caption": "Table 6",
      "description": "Accuracy (%) obtained using our method with the nocturnal sound dataset."
    }
  ],
  "num_figures": 15,
  "tables": [
    {
      "content": "t 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 S(t) 6 1 2 5 8 13 4 9 14 7 10 3 16 11 12 15"
    },
    {
      "content": "Measurement metric Result (%) Accuracy 97.10 GM 97.58 F1-score 97.55 UAR 97.60 AP 97.50 Cohen's kappa 94.97 MCC 96.22"
    },
    {
      "content": "Real/actual category Predicted category V O T E Recall (%) V 473 9 0 2 97.73 O 10 205 0 1 94.91 T 0 0 39 0 100.0 E 2 0 0 87 97.75 Precision (%) 97.53 95.79 100.0 96.67 97.10"
    },
    {
      "content": "Measurement Hold-out Hold-out 3-fold 10-fold metric (75:25) (50:50) CV CV Accuracy(%) 97.58 93.96 94.44 95.77 GM(%) 97.60 93.80 93.18 95.82 F1-score(%) 98.28 94.96 94.18 95.70 UAR(%) 97.69 93.97 93.27 95.86 AP(%) 99.02 96.11 95.14 95.61 Cohen's kappa(%) 95.71 89.29 90.27 92.63 MCC(%) 97.21 92.22 91.64 93.79"
    },
    {
      "content": "Work Result (%) Performance metric Albornoz et al. [22] 49.38 UAR Rao et al. [51]"
    },
    {
      "content": "94.65 UAR Tuncer et al. [6] 95.53 Acc. 95.84 AP 97.10 Acc. Our method (LOOCV) 97.60 UAR 97.50 AP 97.58 Acc. Our method hold-out (75:25) 97.69 UAR 99.02 AP 93.96 Acc. Our method hold-out (50:50) 93.97 UAR 96.11 AP 94.44 Acc. Our method 3-fold CV 93.27 UAR 95.14 AP Classifier used Accuracy(%) using our model Accuracy(%) using [55] Our method 10-fold CV 95.77 95.86 95.61 Acc. UAR AP Decision tree Linear discriminant Quadratic SVM 88.43 93.86 97.14 86.71 94.29 96.71 Cubic SVM 97.85 97.43 kNN 98.14 98.0"
    }
  ],
  "num_tables": 6,
  "license": "\u00a9 2021 Elsevier B.V. All rights reserved.",
  "license_type": "unknown",
  "formulas": [
    {
      "text": "bit(t) = { 0, blck(S(t) ) -blck(t) < 0 1, blck(S(t) ) -blck(t) \u2265 0 , t = {1, 2, \u2026, 16} (1"
    },
    {
      "text": "thr = 1 2 \u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305\u0305 \u0305 \u2211 L i=1 ( SS(i) -1 L \u2211 L i=1 SS(i) ) L \u221a \u221a \u221a \u221a \u221a \u221a (4)"
    },
    {
      "text": "map k (i) = \u2211 8 l=1 bit((k -1) * 8 + l ) * 2 8-l , i = {1, 2, \u2026, L -15}, k = {1, 2, \u2026, 6} (5)"
    },
    {
      "text": "histo k (j) = 0, j = {1, 2, \u2026, 2 8 } (6) histo k ( map k (i) + 1 ) = histo k ( map k (i) + 1 ) + 1 (7)"
    },
    {
      "text": "-1) * 256 + j ) = histo k (j), j = {1, 2, \u2026, 256} (8)"
    },
    {
      "text": "= { x, |x| \u2265 |y| y, |y| > |x| (9)"
    },
    {
      "text": "first(i, cnt) = X(i, j), if w(j) > 0.00001 and cnt = cnt + 1, i = {1, 2, \u2026, D} (11)"
    }
  ],
  "num_formulas": 7,
  "num_citations": 89,
  "cited_references": [
    "b3",
    "b13",
    "b39",
    "b41",
    "b18",
    "b44",
    "b49",
    "b2",
    "b14",
    "b17",
    "b36",
    "b25",
    "b9",
    "b1",
    "b35",
    "b20",
    "b43",
    "b21",
    "b51",
    "b47",
    "b40",
    "b12",
    "b42",
    "b30",
    "b31",
    "b54",
    "b52",
    "b29",
    "b16",
    "b37",
    "b46",
    "b15",
    "b23",
    "b32",
    "b5",
    "b19",
    "b28",
    "b45",
    "b10",
    "b38",
    "b27",
    "b24",
    "b4",
    "b33",
    "b7",
    "b48",
    "b11",
    "b8",
    "b53",
    "b22",
    "b34",
    "b6",
    "b0",
    "b26"
  ],
  "notes": [
    "[raw_affiliation] a  Department of Digital Forensics Engineering , College of Technology , Firat University , Elazig , Turkey",
    "[raw_affiliation] a  Department of Digital Forensics Engineering , College of Technology , Firat University , Elazig , Turkey",
    "[raw_affiliation] a  Department of Digital Forensics Engineering , College of Technology , Firat University , Elazig , Turkey",
    "[raw_affiliation] b  Ngee Ann Polytechnic , Department of Electronics and Computer Engineering , 599489 , Singapore",
    "[raw_affiliation] c  Department of Biomedical Engineering , School of Science and Technology , SUSS University , Singapore",
    "[raw_affiliation] d  Department of Biomedical Informatics and Medical Engineering , Asia University , Taichung , Taiwan",
    "[submission] Received 26 November 2020; Received in revised form 30 April 2021; Accepted 3 May 2021",
    "[raw_reference] Zhang H, Li S, Chen G, Abdulai T, Liu X, Wang Y, et al. Ambient air pollutants aggravate association of snoring with prevalent hypertension: results from the Henan Rural Cohort. Chemosphere 2020:127108.",
    "[raw_reference] Cavusoglu M, Kamasak M, Erogul O, Ciloglu T, Serinagaoglu Y, Akcam T. An efficient method for snore/nonsnore classification of sleep sounds. Physiol Meas 2007;28:841.",
    "[raw_reference] Cambi J, Chiri ZM, Boccuzzi S. Snoring patterns during home polysomnography. A proposal for a new classification. Am J Otolaryngol 2020:102589.",
    "[raw_reference] Kezirian EJ, Hohenhorst W, de Vries N. Drug-induced sleep endoscopy: the VOTE classification. Eur Arch Oto-Rhino-laryngol 2011;268:1233-6.",
    "[raw_reference] Abdullah V, Wing Y, Van Hasselt C. Video sleep nasendoscopy: the Hong Kong experience. Otolaryngol Clin North Am 2003;36:461-71.",
    "[raw_reference] Tuncer T, Akbal E, Dogan S. An automated snoring sound classification method based on local dual octal pattern and iterative hybrid feature selector. Biomed Signal Process Control 2020;63:102173.",
    "[raw_reference] Sharma H, Sharma S. Overview and implications of obstructive sleep apnoea. Indian J Chest Dis Allied Sci 2008;50:137.",
    "[raw_reference] Yaremchuk K. Palatal procedures for obstructive sleep apnea. Otolaryngol Clin North Am 2016;49:1383-97.",
    "[raw_reference] Douglas NJ, Thomas S, Jan MA. Clinical value of polysomnography. Lancet 1992; 339:347-50.",
    "[raw_reference] Amiriparian S, Gerczuk M, Ottl S, Cummins N, Freitag M, Pugachevskiy S, et al. Snore sound classification using image-based deep spectrum features. INTERSPEECH 2017:3512-6.",
    "[raw_reference] Yadollahi A, Moussavi Z. Automatic breath and snore sounds classification from tracheal and ambient sounds recordings. Med Eng Phys 2010;32:985-90.",
    "[raw_reference] Khan T. A deep learning model for snoring detection and vibration notification using a smart wearable gadget. Electronics 2019;8:987.",
    "[raw_reference] Lim SJ, Jang SJ, Lim JY, Ko JH. Classification of snoring sound based on a recurrent neural network. Expert Syst Appl 2019;123:237-45.",
    "[raw_reference] Nonaka R, Emoto T, Abeyratne UR, Jinnouchi O, Kawata I, Ohnishi H, et al. Automatic snore sound extraction from sleep sound recordings via auditory image modeling. Biomed Signal Process Control 2016;27:7-14.",
    "[raw_reference] Qian K, Schmitt M, Janott C, Zhang Z, Heiser C, Hohenhorst W, et al. A bag of wavelet features for snore sound classification. Ann Biomed Eng 2019;47:1000-11.",
    "[raw_reference] Janott C, Schuller B, Heiser C. Acoustic information in snoring noises. HNO 2017; 65:107-16.",
    "[raw_reference] Kim J-W, Kim J-W, Shin J, Choe G, Lim HJ, Rhee C-S, et al. Prediction of obstructive sleep apnea based on respiratory sounds recorded between sleep onset and sleep offset. Clin Exp Otorhinolaryngol 2019;12:72.",
    "[raw_reference] Jiang Y, Peng J, Zhang X. Automatic snoring sounds detection from sleep sounds based on deep learning. Phys Eng. Sci Med 2020.",
    "[raw_reference] Xue B, Deng B, Hong H, Wang Z, Zhu X, Feng DD. Non-contact sleep stage detection using canonical correlation analysis of respiratory sound. IEEE J Biomed Health Inform 2019;24:614-25.",
    "[raw_reference] Dafna E, Tarasiuk A, Zigel Y. Sleep staging using nocturnal sound analysis. Sci Rep 2018;8:1-14.",
    "[raw_reference] Qian K, Janott C, Pandit V, Zhang Z, Heiser C, Hohenhorst W, et al. Classification of the excitation location of snore sounds in the upper airway by acoustic multifeature analysis. IEEE Trans Biomed Eng 2016;64:1731-41.",
    "[raw_reference] Albornoz EM, Bugnon LA, Mart\u00ednez CE. Snore recognition using a reduced set of spectral features. In: 2017 XVII Workshop on Information Processing and Control (RPIC); 2017. p. 1-5.",
    "[raw_reference] Biem A, McDermott E, Katagiri S. A discriminative filter bank model for speech recognition. Fourth European Conference on Speech Communication and Technology 1995.",
    "[raw_reference] Vapnik V. The support vector method of function estimation. Nonlinear Modeling: Springer; 1998. p. 55-85.",
    "[raw_reference] Vapnik V. The nature of statistical learning theory. Springer science & business media; 2013.",
    "[raw_reference] Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional neural networks. Commun ACM 2017;60:84-90.",
    "[raw_reference] Demir F, Sengur A, Cummins N, Amiriparian S, Schuller B. Low level texture features for snore sound discrimination. In: 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC); 2018. p. 413-6.",
    "[raw_reference] Ojala T, Pietikainen M, Maenpaa T. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. IEEE Trans Pattern Anal Mach Intell 2002;24:971-87.",
    "[raw_reference] Dalal N, Triggs B. Histograms of oriented gradients for human detection. In: 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05); 2005. p. 886-93.",
    "[raw_reference] Gelfand AE, Dey DK, Chang H. Model determination using predictive distributions with implementation via sampling-based methods. Stanford Univ CA Dept of Statistics; 1992.",
    "[raw_reference] Vesperini F, Galli A, Gabrielli L, Principi E, Squartini S. Snore sounds excitation localization by using scattering transform and deep neural networks. In: 2018 International Joint Conference on Neural Networks (IJCNN); 2018. p. 1-8.",
    "[raw_reference] Wang C, Peng J, Zhang X. A classification method related to respiratory disorder events based on acoustical analysis of snoring. Arch Acoust 2020;45:141-51.",
    "[raw_reference] Rumelhart DE, Hinton GE, Williams RJ. Learning representations by back- propagating errors. Nature 1986;323:533-6.",
    "[raw_reference] Branstad D, Gait J, Katzke S. Report of the workshop on cryptography in support of computer security. National Institute of Standards and Technology; 1977.",
    "[raw_reference] Murphy S, Robshaw MJ. Essential algebraic structure within the AES. In: Annual International Cryptology Conference; 2002. p. 1-16.",
    "[raw_reference] Ferguson N, Schroeppel R, Whiting D. A simple algebraic representation of rijndael. In: International Workshop on Selected Areas in Cryptography; 2001. p. 103-11.",
    "[raw_reference] Mentens N, Batina L, Preneel B, Verbauwhede I. In: A Systematic Evaluation of Compact Hardware Implementations for the Rijndael S-Box. Cryptographers' Track at the RSA Conference; 2005. p. 323-33.",
    "[raw_reference] Wei L, Su R, Wang B, Li X, Zou Q, Gao X. Integration of deep feature representations and handcrafted features to improve the prediction of N6- methyladenosine sites. Neurocomputing 2019;324:3-9.",
    "[raw_reference] Janott C, Schmitt M, Zhang Y, Qian K, Pandit V, Zhang Z, et al. Snoring classified: the Munich-Passau snore sound corpus. Comput Biol Med 2018;94:106-18.",
    "[raw_reference] Janott C, Schmitt M, Heiser C, Hohenhorst W, Herzog M, Carrasco ML, et al. VOTE versus ACLTE: comparison of two snoring noise classifications using machine learning methods. HNO 2019;67:670-8.",
    "[raw_reference] Tuncer T, Dogan S, \u00d6zyurt F, Belhaouari SB, Bensmail H. Novel multi center and threshold ternary pattern based method for disease detection method using voice. IEEE Access 2020;8:84532-40.",
    "[raw_reference] Akbulut Y, Sengur A, Guo Y, Smarandache F. Ns-k-nn: Neutrosophic set-based k- nearest neighbors classifier. Symmetry 2017;9:179.",
    "[raw_reference] Kuncan F, Kaya Y, Kuncan M. Sens\u00f6r is \u00b8aretlerinden cinsiyet tan\u0131ma i\u00e7in yerel ikili \u00f6r\u00fcnt\u00fcler tabanl\u0131 yeni yaklas \u00b8\u0131mlar. J Faculty Eng Arch Gazi Univ 2019:34.",
    "[raw_reference] Raghu S, Sriraam N. Classification of focal and non-focal EEG signals using neighborhood component analysis and machine learning algorithms. Expert Syst Appl 2018;113:18-32.",
    "[raw_reference] Maillo J, Ram\u00edrez S, Triguero I, Herrera F. kNN-IS: an iterative spark-based design of the k-nearest neighbors classifier for big data. Knowledge Based Syst 2017;117: 3-15.",
    "[raw_reference] Vehtari A, Gelman A, Gabry J. Practical Bayesian model evaluation using leave- one-out cross-validation and WAIC. Stat Comput 2017;27:1413-32.",
    "[raw_reference] Tuncer T, Dogan S, P\u0142awiak P, Acharya UR. Automated arrhythmia detection using novel hexadecimal local pattern and multilevel wavelet transform with ECG signals. Knowledge Based Syst 2019;186:104923.",
    "[raw_reference] Chicco D, Jurman G. The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. BMC Genomics 2020;21:6.",
    "[raw_reference] Warrens MJ. On the equivalence of Cohen's kappa and the Hubert-Arabie adjusted Rand index. J Classif 2008;25:177-83.",
    "[report_type] arXiv preprint",
    "[raw_reference] Powers DM. Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation. arXiv preprint arXiv 2020:201016061.",
    "[raw_reference] Rao MA, Yadav S, Ghosh PK. A dual source-filter model of snore audio for snorer group classification. INTERSPEECH 2017:3502-6.",
    "[raw_reference] Wang J, Str\u00f6mfeli H, Schuller BW. A CNN-GRU approach to capture time- frequency pattern interdependence for snore sound classification. In: 2018 26th European Signal Processing Conference (EUSIPCO); 2018. p. 997-1001.",
    "[raw_reference] Zhang Z, Han J, Qian K, Janott C, Guo Y, Schuller B. Snore-GANs: Improving automatic snore sound classification with synthesized data. IEEE J Biomed Health Inform 2019;24:300-10.",
    "[raw_reference] Freitag M, Amiriparian S, Cummins N, Gerczuk M, Schuller BW. An'end-to- evolution'hybrid approach for snore sound classification. INTERSPEECH 2017: 3507-11.",
    "[raw_reference] Akbal E, Tuncer T. FusedTSNet: an automated nocturnal sleep sound classification method based on a fused textural and statistical feature generation network. Appl Acoust 2021;171:107559."
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  }
}
