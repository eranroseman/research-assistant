{
  "paper_id": "4JJNUGTM",
  "title": "Dynamic Treatment Regimes",
  "abstract": "A dynamic treatment regime consists of a sequence of decision rules, one per stage of intervention, that dictate how to individualize treatments to patients based on evolving treatment and covariate history. These regimes are particularly useful for managing chronic disorders, and fit well into the larger paradigm of personalized medicine. They provide one way to operationalize a clinical decision support system. Statistics plays a key role in the construction of evidence-based dynamic treatment regimes -informing best study design as well as efficient estimation and valid inference. Due to the many novel methodological challenges it offers, this area has been growing in popularity among statisticians in recent years. In this article, we review the key developments in this exciting field of research. In particular, we discuss the sequential multiple assignment randomized trial designs, estimation techniques like Q-learning and marginal structural models, and several inference techniques designed to address the associated non-standard asymptotics. We reference software, whenever available. We also outline some important future directions.",
  "year": 2014,
  "date": "2014-11-14",
  "journal": "Mathematical Modelling",
  "publication": "Mathematical Modelling",
  "authors": [
    {
      "forename": "Bibhas",
      "surname": "Chakraborty",
      "name": "Bibhas Chakraborty",
      "affiliation": "1  Department of Biostatistics , Columbia University , New York , USA , 10032 \n\t\t\t\t\t\t\t\t Department of Biostatistics \n\t\t\t\t\t\t\t\t Columbia University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 10032 \n\t\t\t\t\t\t\t\t\t New York \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Susan",
      "surname": "Murphy",
      "name": "Susan Murphy",
      "affiliation": "2  Department of Statistics and Institute for Social Research , University of Michigan , Ann Arbor , USA , 48109 \n\t\t\t\t\t\t\t\t Department of Statistics and Institute for Social Research \n\t\t\t\t\t\t\t\t University of Michigan \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 48109 \n\t\t\t\t\t\t\t\t\t Ann Arbor \n\t\t\t\t\t\t\t\t\t USA"
    }
  ],
  "doi": "https://doi.org/10.13039/100000002",
  "arxiv": "arXiv:1006.5831v2[stat.ME].2011",
  "pmid": "10790677",
  "keywords": [
    "dynamic treatment regime",
    "reinforcement learning",
    "sequential randomization",
    "non-regularity",
    "Qlearning"
  ],
  "sections": [
    {
      "title": "Introduction",
      "text": "Personalized medicine is an increasingly popular theme in today's health care. Operationally, personalized treatments are decision rules that dictate what treatment to provide given a patient state (consisting of demographics, results of diagnostic tests, genetic information, etc.). Dynamic treatment regimes (DTRs)  [1, 2, 3, 4, 5, 6]  generalize personalized medicine to time-varying treatment settings in which treatment is repeatedly tailored to a patient's time-varying -or dynamic -state. DTRs are alternatively known as adaptive treatment strategies  [7, 8, 9, 10, 11]  or treatment policies  [12, 13, 14] . These decision rules offer an effective vehicle for personalized management of chronic conditions, e.g. alcohol and drug abuse, cancer, diabetes, HIV infection, and mental illnesses, where a patient typically has to be treated at multiple stages, adapting the treatment (type, dosage, timing) at each stage to the evolving treatment and covariate history. DTRs underpin clinical decision support systems -described as a key element of the chronic care model  [15] .\n\nA simple example of a DTR arising in the treatment of alcohol dependence is: After the patient completes an intensive outpatient program, provide the medication naltrexone along with face-to-face medical management. If within the following two months the patients experiences 2 or more heavy drinking days, then immediately augment the naltrexone with a cognitive behavioral therapy. Otherwise at the end of the two months, provide telephone disease management in addition to the naltrexone. A second example given in Rosth\u00f8j et al.  [16]  is a DTR for use in guiding warfarin dosing to control the risk of both clotting and excessive bleeding. Here the decision rules input summaries of the trajectory of International Normalized Ratio (a measure of clotting tendency of blood) over the recent past and output recommendations concerning how much to change the dose of warfarin (if any). The third example, provided by Robins et al.  [17]  concerns a DTR with decision rules that input summaries of the trajectories of plasma HIV RNA and CD4 counts over the recent past and output when to start an asymptomatic HIV-infected subject on highly active antiretroviral therapy. In Section 3 different statistical methods for constructing the decision rules in a DTR are reviewed."
    },
    {
      "title": "Decision Problems",
      "text": "Traditionally personalized medicine concerns single stage decision making. In a single-stage (non-dynamic) decision problem one observes a random vector, the first observation, O 1 , then one selects an action (here a treatment action), a 1 , from a set of actions and then depending on which action was selected, observes a second observation, O 2 (a 1 ). To avoid technical details and for simplicity, here and below, we assume sufficient regularity for all statements. A decision rule, say d 1 , is a mapping from the range of O 1 into . The quality of a treatment for a particular value of O 1 is evaluated in terms of its utility, say r(O 1 , a 1 , O 2 (a 1 )), for r a known function. The utility may be a summary of one outcome, such as percent days abstinent in an alcohol dependence study or a composite outcome; for example, in Wang et al.  [18]  the utility is a compound score numerically combining information on treatment efficacy, toxicity, and the risk of disease progression. The optimal decision rule outputs the treatment (action) that maximizes the expected utility, ; this is personalized decision making since the choice of optimal treatment depends on o 1 . Equivalently the optimal decision rule is given by arg max d1\n\n, where the maximum is taken over all functions on the range of O 1 . is called the Value of the decision rule d 1 .\n\nConstructing DTRs involves solving, or estimating quantities relevant in, a multi-stage decision problem. In multi-stage decision problems, observations are interweaved with action selection; denote such a sequence by where and denotes the observation made at stage j + 1 subsequent to the selection of the action sequence . A DTR is a sequence of decision rules, ; the decision rule d j is a mapping from the range of into the jth action space,\n\n. When K = 2 and the treatment actions are discrete, the Value of the DTR (d 1 , d 2 ) can be written on one line as  (1)  (the generalization to more than two stages is straightforward). Using this formula we might compare two or more DTRs in terms of their Value or equivalently their expected utility.\n\nThe optimal DTR is the set of decision rules, , that maximize the Value.\n\nConstructing the optimal decision rules in multi-stage decision problems is challenging due to the time-varying or dynamic nature of this problem. Historically, an early method for solving (e.g. construct the optimal decision rules) multi-stage decision problems is dynamic programming (DP), which dates at least back to Bellman  [19] . The primary reason why classical DP algorithms have seen little use in DTR research is due to the fact that these algorithms require complete knowledge of, or a full model for, the multivariate distribution of the data for any set of actions; this is impractical in many application areas (curse of modeling)  [20] . Secondly, DP methods are computationally very expensive, and they become hard to manage in moderately high-dimensional problems; in other words, they suffer from the curse of dimensionality  [21] . But DP provides an important theoretical and conceptual foundation for research in multi-stage decision problems; in fact, as will be seen, many present day estimation methods build on classical DP algorithms, while relaxing its stringent requirements."
    },
    {
      "title": "Data Sources for Constructing DTRs",
      "text": "Most statistical research in the arena of DTRs concerns: (a) the comparison of two or more preconceived DTRs in terms of their Value; and (b) the estimation of the optimal DTR, i.e. to estimate the sequence of decision rules, one per stage, that result in the highest Value, within a class of DTRs. In each case the data used in comparing or constructing DTRs are usually from: (i) sequentially randomized studies, or (ii) longitudinal observational studies, or (iii) dynamical system models. Research based on the first source of data, that from sequentially randomized studies, is experiencing a period of rapid growth, due to the increasing number of clinical trials in which many of the patients are randomized multiple times, in a sequential manner. However, by far, the majority of statistical research, led by Robins' pioneering work  [1, 2, 3, 4]  concerns the use of data from longitudinal, observational studies. The third data source, based on simulating from or otherwise using existing dynamical system models has seen much less use in DTR development. In this section we briefly review the first two types of data sources, their advantages and drawbacks, and the assumptions required to perform valid analyses in each, along with some examples. Dynamical system models will be discussed in Section 3."
    },
    {
      "title": "Sequentially Randomized Trials (SMART)",
      "text": "Initially, beginning with Robins' work  [1, 2, 3, 4] , sequentially randomized trials were used as a conceptual tool to precisely state the inferential goals in DTR research. More recently trial designs, known as Sequential Multiple Assignment Randomized Trial (SMART) designs  [7, 22, 11] , have been implemented in practice. SMART designs involve an initial randomization of patients to available treatment actions, followed by re-randomizations at each subsequent stage of some or all of the patients to treatment actions available at that stage. The re-randomizations and set of treatment actions at each subsequent stage may depend on information collected in prior stages such as how well the patient responded to the previous treatment.\n\nRecent SMARTs include: a smoking cessation study  [23] ; a study involving treatment of autism among children  [24, 25] ; a study involving interventions for children with attention deficit hyperactivity disorder  [26, 27] ; a study involving treatment for pregnant drug abusers  [28, 25] ; and a study involving alcohol-dependent individuals  [25] . For a list of some further SMARTs see the website  http://methodology.psu.edu/ra/adap-treat-strat/projects .\n\nTo make the discussion more concrete, see Figure  1  for a hypothetical SMART design based on the addiction management example introduced earlier. In this trial, each participant is randomly assigned to one of two possible initial treatments: cognitive behavioral therapy (CBT) or naltrexone (NTX). A participant is classified as a non-responder or responder to the initial treatment according to whether s/he does or does not experience more than two heavy drinking days during the next two months. A non-responder to NTX is re-randomized to one of the two subsequent treatment options: either a switch to CBT, or an augmentation of NTX with CBT (CBT+NTX). Similarly, a non-responder to CBT is re-randomized to either a switch to NTX, or an augmentation (CBT+NTX). Responders to the initial treatment receive telephone monitoring (TM) for an additional period of six months. One goal of the study might be to construct a DTR leading to a maximal mean number of non-heavy drinking days over 12 months. Denote the observable data trajectory for a participant in a two-stage SMART by (O 1 , A 1 , O 2 , A 2 , O 3 ), where O 1 , O 2 and O 3 are the pretreatment information, intermediate outcomes and final outcomes, respectively. The randomized treatment actions are A 1 and A 2 and the primary outcome is Y = r(O 1 , A 1 , O 2 , A 2 , O 3 ) for r a known function. For example, in the addiction management study above, O 1 may include addiction severity and co-morbid conditions, O 2 may include the participant's binary response status, side effects and adherence to the initial treatment, and Y may be the number of non-heavy drinking days over the 12-month study period.\n\nTo connect the distribution of the data collected in the above SMART to the distributions considered in the multistage decision problem in Section (1.1), we make a short digression into the field of causal inference. Recall that in the case of two stages, in Section (1.1), we denoted the sequence of random observations by (O 1 , a 1 , O 2 (a 1 ), a 2 , O 3 (a 1 , a 2 )) for the selected actions (a 1 , a 2 ). These observations are potential outcomes  [29, 1] . Potential outcomes or counterfactual outcomes are defined as a person's outcome had s/he followed a particular treatment (sequence), possibly different from the treatment (sequence) s/he was actually observed to follow. Consider, for example, a single-stage randomized trial in which participants can receive either a or a'. Accordingly, any participant in this study is conceptualized to have two potential second observations, O 2 (a) and O 2 (a'). However, only one of these -the one corresponding to the treatment a participant is randomized to -will be observed. Clearly, it is not possible to observe the O 2 under both treatments a and a' without further data and assumptions (e.g. in a crossover trial with no carryover effect). Now suppose that participants are treated over two stages, and can receive at each stage either a or . In this case there are four sequences of potential observations, (O 2 (a), O 3 (a, a)), (O 2 (a), O 3 (a, a')), (O 2 (a'), O 3 (a', a)), (O 2 (a'), O 3 (a', a')); only one of these sequences will be observed on any given participant.\n\nTo connect the potential observations to the observations made during the conduct of a SMART, we make two assumptions  [4] :\n\n1. Consistency: The potential outcome under the observed treatment and the observed outcome agree."
    },
    {
      "title": "2.",
      "text": "No unmeasured confounders: For any treatment sequence , treatment A j is independent of future (potential) outcomes, , conditional on the history . That is, for any possible treatment sequence ,\n\nThe consistency assumption subsumes Rubin's  [30]  more explanatory Stable Unit Treatment Value Assumption (SUTVA), which is: each participant's potential outcome is not influenced by the treatment applied to other participants. In clinical trials SUTVA is most often violated when the treatment is not well defined. For example the treatment as defined may not specify that some aspects of the treatment are provided in a group setting containing multiple participants from the trial. In this case the response of one participant to treatment may influence the response of another participant if they are in the same group.\n\nUnder the consistency assumption, the potential outcomes in a two stage SMART are connected to the observable data by\n\n. The \"no unmeasured confounders\" assumption holds in a SMART design if the randomization probabilities depend at most on the past observations; more precisely, the randomization probabilities for A 1 and A 2 may depend on O 1 and (O 1 , A 1 , O 2 ), respectively. Under this assumption,\n\n, and\n\n. This implies that the Value for a DTR can be written as a function of the multivariate distribution of the observable data obtained from a SMART; in the case of two stages (1) can be written as\n\n). A similar result holds for settings with more than two stages. Thus the validity of the two assumptions ensures that data from SMARTs can be effectively used to evaluate pre-specified DTRs or to estimate the optimal DTR within a certain class."
    },
    {
      "title": "Some Practical Considerations in Designing a SMART-A variety of",
      "text": "authors recommend that the design of a SMART be no more complicated than necessary. Indeed the class of treatment options at each stage should not be unnecessarily restricted  [22, 11] . For example it is better to use a low dimensional summary criterion (e.g. responder/ non-responder status, as used in the example addiction management SMART) instead of all intermediate outcomes (e.g. improvement of symptom severity, side-effects, adherence etc.) to restrict the class of possible treatments. Furthermore a SMART is best viewed as one trial among a series of randomized trials intended to develop and/or refine a DTR. It should eventually be followed by a confirmatory randomized trial that compares the developed regime and an appropriate control  [11] . That is, the construction of DTRs is a developmental endeavor as opposed to confirmatory. In this sense a scientist employing a SMART design has a similar goal to Box's  [31]  goal of developing multicomponent treatments. Indeed the SMART can be viewed as an extension of the factorial design to the setting in which time and sequencing of treatments play a crucial role  [32] . As a result often the primary hypothesis, that is, the hypothesis used to determine the sample size for the trial, concerns a main effect. However due to the multiple randomizations, a variety of interesting secondary research questions can be addressed with randomized data. Note that the SMART may or may not be powered to address these secondary hypothesis questions.\n\nMost often the primary hypothesis concerns the main effect of the first stage treatment. For example, in the addiction management study an interesting primary research question would be: \"marginalizing over secondary treatments, what is the best initial treatment on average?\". In other words, here the researcher wants to compare the mean primary outcome of the group of patients receiving NTX as the initial treatment with the mean primary outcome of those receiving CBT. Another interesting primary question could concern the main effect of a second stage treatment: \"on average what is the best secondary treatment, a 'switch' or an 'augmentation', for non-responders to initial treatment?\". Here the researcher might compare the mean primary outcome of non-responders assigned to switch with the mean primary outcome of non-responders assigned to augmentation. In all of these cases sample size formulae are standard or easily derived.\n\nAlternatively the primary research question may concern the comparison of two of the embedded DTRs. In the example addiction management SMART there are 4 embedded DTRs, corresponding to 2 options for the first stage treatment and 2 options for the second stage treatment for nonresponders (note that there is only one option for the responders). For example, one embedded regime in this SMART is: 'treat the patient with NTX at stage 1; give TM at stage 2 if the patient is a responder, and give CBT at stage 2 if the patient is a non-responder'; other embedded regimes can be described similarly. Determining appropriate sample sizes to compare two embedded DTRs in terms of a continuous outcome was considered by Murphy  [11] , Oetting et al.  [33] , and Dawson and Lavori  [34, 35] . A web application that calculates the required sample size for a SMART design for a continuous endpoint can be found at  http://methodologymedia.psu.edu/smart/samplesize . Much work has concerned survival endpoints  [12, 13, 14, 36] . Relevant sample size formulae can be found in Feng and Wahed  [37]  and Li and Murphy  [38] . A web application for sample size calculation in this case can be found at  http://methodologymedia.psu.edu/logranktest/  samplesize ."
    },
    {
      "title": "SMART versus",
      "text": "Other Designs-The SMART design discussed above involves stages of treatment and/or experimentation. In this regard, it bears superficial similarity with adaptive designs  [39] . The term, \"adaptive design\" is an umbrella term used to denote a variety of trial designs that allow certain trial features to change based on accumulating data while maintaining statistical, scientific, and ethical integrity of the trial  [39] . In a SMART design, each participant moves through multiple stages of treatment, while in adaptive designs each stage involves different participants. The goal of a SMART is to develop a good DTR that could benefit future patients. Many adaptive designs try to provide the most efficacious treatment to each patient in the trial based on the current knowledge available at the time that a participant is randomized. In a SMART, unlike in an adaptive design, the design elements such as the final sample size, randomization probabilities and treatment options are pre-specified. SMART designs involve within-participant adaptation of treatment, while adaptive designs involve between-participant adaptation. While in some settings it is possible to incorporate some adaptive elements into a SMART design  [10, 40] , how to optimally do this is an open question that warrants further research.\n\nSMART designs have some operational similarity with classical crossover trial designs; however they differ greatly in the scientific goal. In particular a crossover design is typically used to contrast the effects of stand-alone treatments whereas the SMART is used to develop a DTR, that is, a sequence of treatments. Note that treatment allocation at any stage after the initial stage of a SMART typically depends on a participant's intermediate outcome (response/non-response). However, in a crossover trial, participants receive all the candidate treatments irrespective of their intermediate outcomes. And most importantly, it is crucial in a crossover trial to attempt to wash out the carryover effects, whereas the process of constructing a DTR involves harnessing carryover effects so as to lead to improved outcomes. That is, carryover effects such as synergistic interactions between treatments at different stages may lead to a better DTR as compared to a DTR in which there are no carryover effects."
    },
    {
      "title": "Observational Studies",
      "text": "In observational studies the treatments are not randomized; in particular, the reasons why different individuals receive differing treatments or the reasons why one individual receives different treatments at different times are not known with certainty. Certainly data in which the treatments are (sequentially) randomized, when available, is preferable for making inferences concerning DTRs. However observational studies are the most common source of data for constructing DTRs and indeed most research in statistics has concentrated on how best to use observational data.\n\nIn observational data associations observed in the data (e.g., between treatment and outcome) may be partially due to the unobserved or unknown reasons why individuals receive differing treatments as opposed to the effects of the treatments. Thus to conduct inference, assumptions are required. Assumptions such as the consistency assumption and the no unmeasured confounders assumption discussed earlier can be used to justify estimation and inference based on observational data; the plausibility of these assumptions is generally best justified by scientific, expert knowledge. A variety of studies aimed at constructing DTRs from observational data have been undertaken. Data sources include hospital databases  [16, 17, 41, 42] , randomized encouragement trials  [43] , and cohort studies  [44] .\n\nThe assumption of no unmeasured confounders must be given careful consideration and thought in the observational data setting. Recall the no unmeasured confounders is the assumption that conditional on the past history, treatment received at stage j is independent of future potential observations and outcome:\n\n. This assumption allows us to effectively view the observational data as coming from a sequentially randomized trial, albeit with unknown as opposed to known randomization probabilities at stage j. The assumption may be (approximately) true in observational settings where all relevant common causes of outcomes and treatment have been observed.\n\nIn addition to careful consideration of causal inference issues, using observational data to construct DTRs requires careful thought concerning how the data may restrict the set of DTRs that can be assessed absent further assumptions. This set is called the feasible  [45]  or viable  [18]  DTRs. Feasibility of a DTR requires a positive probability that some participants in the study will have followed ."
    },
    {
      "title": "Data Analysis",
      "text": "As mentioned in Section 2, two common goals are: (a) the estimation/comparison of a small number of DTRs in terms of their Value; and (b) to estimate the optimal DTR within a certain class. In the following, we review the analysis strategies for both. Throughout we assume that both the no-unmeasured confounding and consistency assumptions hold and that all DTRs considered are feasible.\n\nWeighting is often used to address both (a) and (b). Weights or inverse probability of treatment weights (IPTW) were originally developed to estimate the Value of non-dynamic regimes  [46, 47] , but later adapted to the problem of estimating the Value of DTRs. IPTWs were used to estimate the Values of a small number of DTRs in Murphy et al.  [48]  and Wang et al.  [18] . To see why weights might be used, consider a SMART as in Figure  1 , with only one option for responding participants (e.g. telephone monitoring). Suppose that the treatment assignment probabilities at stage 1 and also for the non-responders are uniform (randomization probability is 0.5). Suppose further that we want to estimate the Value of the embedded DTR, \"treat the patient with NTX at stage 1; give TM at stage 2 if the patient is a responder, and give CBT at stage 2 if the patient is a non-responder.\" To estimate the Value we utilize the outcome of all participants with treatment patterns consistent with this DTR. However within this group of participants there is an over-representation of responders compared to non-responders because the non-responders were subdivided in the trial but the responders were not. The IPTWs are used to adjust for over-representation of participants across the treatment patterns consistent with a given DTR. In this example, data from responders would have a weight of as responders have been randomized only in stage 1 (with a probability of 0.5) whereas data from non-responders would have a weight of as they have been randomized twice (each with a probability of 0.5). See Wang et al.  [18]  and Nahum-Shani et al.  [26]  for detailed explanations of how IPTWs can be used to account for this over/under representation in SMARTs. Lunceford et al.  [12] , Wahed and Tsiatis  [13, 14] , and Miyahara and Wahed  [49]  use ITPW weights in estimating the Value of DTRs in the survival analysis setting. Improved versions of IPTW estimator are available in papers by Robins and colleagues  [48, 17, 41, 50]  and Zhang et al.  [51] ."
    },
    {
      "title": "Direct Methods for Estimating an Optimal DTR",
      "text": "For notational simplicity, let d denote the DTR, , in the following. Recall from Section 1 that the Value of a DTR is the mean of the utility, marginalized over all observations that might be impacted by the treatment. In direct methods one specifies a class of DTRs (see below for an example), estimates the Value for each candidate DTR , say and then selects the DTR in with maximal estimated Value.\n\nThe use of IPTWs for estimating an optimal DTR was pioneered by Robins and colleagues  [17, 41] . For a simple example consider DTRs that use a risk score to indicate when to initiate treatment. At the clinic visit at which the risk score is greater than or equal to x, treatment is initiated. The Value varies by DTR, that is, by x. In Robins et al.  [17]  the Value is parameterized as a polynomial function in x and pretreatment variables; for example, V(x; \u03b2) = \u03b2 0 + \u03b2 1 x + \u03b2 2 x 2 . The optimal DTR is to initiate treatment when the risk score is greater than or equal to x 0 where x 0 = arg max x V(x, \u03b2). To estimate the optimal DTR, we need estimators of the \u03b2's. In the simplest setting the \u03b2's are estimated by solving an IPTW weighted estimating equation. To improve efficiency in the estimation of the \u03b2's, Robins et al.  [17]  take advantage of the fact that some individuals' treatment sequence will be consistent with more than one DTR. For example if the individual initiates treatment with a risk score of 12 and at the prior office visits the individual's risk score was always lower than 10, then this individual has a treatment sequence consistent with x = 10, 11 and 12. To improve efficiency this individual's data is used to estimate the Value V (x; \u03b2) for x = 10, 11, 12. Operationally, the estimating equation uses three replicates of this individual's data. In the above example the individual is replicated twice to produce three replicates and the replicated outcome Y is relabeled as Y 10 , Y 11 , Y 12 (Y 10 = Y 11 = Y 12 ). In general the number of replicates of an individual's data is equal to the number of DTRs with which their observed treatment is consistent. The \u03b2's can be estimated by solving the weighted estimating equation where the is an average over the augmented data set (containing the replicates). Nahum-Shani et al.  [26] , in the context of SMART, provides an intuitive discussion of why replication of participants can be used to account for the fact that a participant's observed treatment is consistent with more than one DTR. The observational data setting can be more complicated; see Robins et al.  [17]  and Shortreed and Moodie  [52]  for detailed expositions. Related work that compares a range of candidate DTRs by incorporating a treatmenttailoring threshold can be found in Hern\u00e1n et al.  [53] , Petersen et al.  [54] , van der Laan and Petersen  [55] , and Cotton and Heagerty  [42] .\n\nDirect methods for a one-stage decision making setting (e.g. K = 1) has seen a great deal of research; here the single decision rule is often called an individualized decision rule. As highlighted by Qian and Murphy  [56] , the one stage decision making problem has a close connection with classification. Subsequently, methods based on classification  [57, 58]  have been proposed for estimating the decision rule. Other work in the one-stage decision setting include Cai et al.  [59]  and Imai and Ratkovicz  [60] ."
    },
    {
      "title": "Indirect Methods for Estimating an Optimal DTR",
      "text": "Indirect approaches to estimating the optimal DTR are commonly employed when scientists wish to consider decision rules that may depend on multiple covariates or depend on covariates in a complex manner. In the indirect approach the stage-specific conditional mean outcomes (called Q-functions) or contrasts thereof are modeled first, and then the optimal decision rules are found via maximization of these estimated conditional means or contrasts. These methods were originally developed in the reinforcement learning literature within computer science, but later adapted to statistics. One such procedure that has become particularly popular in the DTR literature is Q-learning  [21] . Q-learning is an approximate dynamic programming method -approximate because the Q-functions are approximated by the use of data and models. In its simplest incarnation, Q-learning uses linear models for the Q-functions, and can be viewed as an extension of least squares regression to multi-stage decision problems  [61] . However, one can use more flexible models for the Q-functions, e.g. regression trees  [62]  or kernels  [63] . The version of Q-learning considered in the DTR literature is most similar to the fitted Q-iteration algorithm  [62]  in the reinforcement learning literature."
    },
    {
      "title": "Q-learning with",
      "text": "Linear Models-For clarity, here we will define Q-functions and describe Q-learning for studies with two stages only; generalization to K (\u2265 2) stages is straightforward  [61] . For simplicity, assume that the data come from a SMART with two possible treatments at each stage, A j \u2208 {-1, 1) and that the treatment is randomized with known randomization probabilities. The data from a SMART involving n subjects will consist of n data trajectories of the form (O 1 , A 1 , O 2 , A 2 , O 3 ); as before the histories are defined as The optimal Q-functions for the two stages are defined as:  [21]  can be used to prove that the optimal treatment at a particular stage is given by the value of the action that maximizes the associated Q-function. In particular, if these two Q-functions were known, the optimal DTR (d 1 , d 2 ) would be d j (h j ) = arg max aj Q j (h j , a j ), j = 1, 2. In practice, the true Q-functions are not known and hence must be estimated. Since Q-functions are conditional expectations, a natural approach to model them is via regression models. A dynamic programming (moving backwards through the stages) approach is used to estimate the parameters. Consider linear regression models for the Q-functions. Let the stage j (j = 1, 2) Q-function be modeled as\n\n, where H j0 and H j1 are two (possibly different) features of the history H j .\n\nThere are many versions of the Q-learning algorithm depending on whether there are parameters that are common across the stages and depending on the form of the dependent variable used in the stage 1 regression. One form for the Q-learning algorithm consists of the following steps:"
    },
    {
      "title": "1.",
      "text": "Stage 2 regression: ."
    },
    {
      "title": "2.",
      "text": "Stage 1 dependent variable: ."
    },
    {
      "title": "Stage 1 regression:",
      "text": ". Note that in step 2. above, the quantity is a predictor of the unobserved random variable Y 1i + max a2 Q 2 (H 2i , a 2 ), i = 1, \u2026 , n. The estimated optimal DTR using Q-learning is given by , where the stage j optimal rule is specified as .\n\nQ-learning (with K = 2) has been implemented in the R package qLearn, freely available from:  http://cran.r-project.org/web/packages/qLearn/index.html , and in the SAS procedure QLEARN:  http://methodology.psu.edu/downloads/procqlearn . Q-learning can be extended for application to observational data by incorporating appropriate adjustments to account for confounding; more precisely, this can be done either by including all the measured confounders -or simply the propensity score as a proxy for all measured confounders -in the models for Q-functions, or instead weighting the stage-specific regressions by the inverse of the propensity scores  [64] . Q-learning is a version of Robins' optimal structural nested mean model  [6]  developed in the causal inference literature; see Chakraborty et al.  [23]  for a detailed discussion and derivation.\n\nQ-learning has been generalized in a variety of ways. Lizotte et al.  [65, 66]  generalize Qlearning for use when different patients may make different tradeoffs between multiple outcomes and thus a data analysis of one composite outcome is insufficient. Q-learning has also been generalized to settings in which Y is a, possibly censored, survival time  [67, 68] ; both these papers provide a Q-learning method with the aim of maximizing a truncated survival time."
    },
    {
      "title": "Approaches based on Dynamical Systems",
      "text": "Models-An alternate indirect approach to estimating an optimal DTR is to use dynamical systems models. By dynamical systems models we mean a time-ordered sequence of nested conditional models (each model conditions on past data) for the multivariate distribution of the data. In this approach one first develops a dynamical systems model; this model may be constructed using expert opinion or may be estimated using observational or sequentially randomized data sets. Indeed these types of models are quite attractive when there are strong biological, behavioral or social theories that can be employed to guide the formation of the nested conditional models. Once the dynamical systems model is in hand, algorithms from control theory, such as dynamic programming or constrained optimization algorithms are used to estimate the optimal DTR  [69] . This is a common approach in applications in engineering, economics and business. In the clinical field there has been much less development. Bayesian methods have been employed in simple, low dimensional problems; one example is Thall et al.  [70] .\n\nRosenberg et al.  [71] , and Banks et al.  [72]  discussed how a variety of data sources with models based on ordinary differential equations can be used to build a dynamical systems model for use in estimating an optimal DTR in AIDS treatment. In this setting the treatment is a continuous dose of antiviral therapy, and the optimal DTR is chosen to bring the dynamical system to its \"steady state\". Rivera and colleagues, in a series of presentations available at  http://csel.asu.edu/node/13  and papers  [69, 73] , discussed how common dynamical systems models might be used to describe behaviorial dynamics and thus form the basis for DTRs involving behavioral treatments in obesity and addiction treatment. Gaweda et al.  [74, 75]  discussed the use of control theoretic approaches to anemia management in patients with end-stage renal disease. Bennett and Hauser  [76]  discussed a framework for simulating clinical decision making from electronic medical records data. In summary, while the dynamical systems approaches to develop DTRs are emerging, from a statistical perspective they still lag behind the other approaches presented earlier; hence this area is ripe for further development."
    },
    {
      "title": "Confidence Sets",
      "text": "High quality measures of confidence are needed in the development of DTRs both for (i) the parameters indexing the optimal DTR; and (ii) the Value of a DTR -either a pre-specified DTR, or an estimated DTR. Inference for the Values of pre-specified regimes has been addressed by numerous authors  [12, 13, 14, 9, 10] ; however there is little work on inference for the Value of an estimated regime. We return to this problem after discussing the construction of confidence intervals (CIs) for the parameters indexing the optimal regime. Measures of confidence for these parameters are important for the following reasons. First, if the CIs for some of these parameters contain zero, then the corresponding patient variables need not be collected in future, thus lowering the data collection burden. Second, CIs for the coefficient of the treatment variable can be used to indicate if there is insufficient support in the data to recommend one uniquely best treatment over another, thereby suggesting considerations other than the treatment effect be used to decide on treatment, e.g. cost, patient/clinician familiarity, preference etc.\n\nOrellana et al.  [41]  discussed construction of confidence sets for parameters indexing the optimal DTR when direct methods of estimation using IPTW are employed. These confidence sets are based on standard Taylor series arguments, and are asymptotically valid under a set of smoothness assumptions. Robins  [6]  pointed out that non-regularity arises in the indirect estimation of DTRs. By non-regularity, we mean that the asymptotic distribution of the estimator of the treatment effect parameter does not converge uniformly over the parameter space; see below for further details. Indeed the treatment effect parameters at any stage prior to the last can be non-regular. This phenomenon has practical consequences, including bias in estimation and poor frequentist properties of Wald-type or other standard CIs in small samples. Any inference technique that aims to provide good frequentist properties such as nominal Type I error and/or nominal coverage of CIs in small samples has to address this problem of non-regularity. The problem can be better understood with a simple but instructive example discussed by Robins  [6] ; here we present a slightly modified version as presented by Chakraborty et al.  [23] . Consider the problem of estimating |\u03bc| based on n i.i.d. observations X 1 , \u2026 , X n from . Note that is the maximum likelihood estimator of |\u03bc|, where is the sample average. The asymptotic distribution of for any \u03bc \u2260 0 is a standard normal, whereas for \u03bc = 0 it is nonnormal; that is, the change in the distribution as a function of \u03bc is abrupt. Thus is a non-regular estimator of |\u03bc|; an exact proof of non-regularity of this estimator uses local alternatives as in Leeb and P\u00f6tscher  [77] . Also, for . This asymptotic bias  [6]  is one symptom of the underlying non-regularity.\n\nNext we review the problem of non-regularity in the context of Q-learning. Suppose we want to construct CIs for the parameters \u03c8 j 's appearing in the model for Q-functions. In a two-stage set-up, the inference for the stage 2 parameters \u03c8 2 is straightforward since this falls in the standard linear regression framework. In contrast, inference for \u03c8 1 is complicated. Note that the stage 1 dependent variable in Q-learning for the i-th participant is , which is a non-differentiable function of (due to the presence of the absolute value function). Since is a function of , it is in turn a non-smooth function of . As a consequence, the distribution of does not converge uniformly over the parameter space  [6] . More specifically, the asymptotic distribution of is normal if \u03c6 2 is such that , but is non-normal if p > 0, and this change in the distribution happens abruptly. Below we present several different approaches to address the problem."
    },
    {
      "title": "Adjusted Projection Confidence Intervals",
      "text": "As discussed in Robins  [6] , a joint CI for all of the parameters (in our two stage example both the first and second stage regression coefficients) can be formed by inverting hypothesis tests. That is, if the parameters are \u03c6 = (\u03c6 1 , \u03c6 2 ) and a hypothesis test of \u03c6 = \u03c6 0 for each value of \u03c6 0 is well behaved, then a joint (1 -\u03b1)% CI, for \u03c6 can be constructed. This is the case in Q-learning since it is easy to construct a well-behaved hypothesis test statistic when all of the regression coefficients are set to fixed values (the test statistic is based on a quadratic form involving the estimating functions evaluated at values).\n\nNext a projected CI for \u03c6 1 is given by . Unfortunately this interval is very conservative. As a result, Robins  [6]  using ideas as advanced by Berger and Boos  [78]  adjusts the usual projection CI. We discuss this idea in the context of the two stage Qlearning method presented above.\n\nRecall that we are interested in a CI for \u03c6 1 . In this context, \u03c6 2 is a nuisance parameter. If the true value of \u03c6 2 were known, then the asymptotic distribution of would be regular (in fact, normal), and standard procedures could be used to construct an asymptotically valid CI. Let denote a (1 -\u03b1)% asymptotic CI for \u03c6 1 if \u03c6 2 were known. Let be a (1 -\u220a)% asymptotic CI for \u03c6 2 . Then, it follows that is a (1 -\u03b1 -\u220a)% CI for \u03c6 1 . To see this, note that . Thus, this CI is the union of the CIs over all values , and is an asymptotically valid (1 -\u03b1 -\u220a)% CI for \u03c6 1 . The main downside of this approach is that it appears to be computationally di cult to implement; to our knowledge this CI has not yet been implemented."
    },
    {
      "title": "Adaptive Confidence Intervals",
      "text": "Laber et al.  [79]  developed an adaptive bootstrap procedure to construct CIs for linear combinations\n\n, where c is a known vector. In this procedure, they decomposed the asymptotic expansion of as , where the first term is smooth and asymptotically normally distributed, while the distribution of the second term depends on the underlying data-generating process \"non-smoothly\". The adaptive confidence intervals (ACIs) are formed by first constructing smooth data-dependent upper and lower bounds on , and thereby on . The data-dependent upper/lower bounds use a pretest  [80]  that partitions the data into two sets: (i) patients for which there appears to be a treatment effect, and (ii) patients where it appears there is no treatment effect. The pretests are performed using a critical value \u03bb n , which is a tuning parameter of the procedure and can be varied; Laber et al.  [79]  used \u03bb n = log log n in their analysis. percentiles of respectively is the m-out-of-n bootstrap analog of . This bootstrap procedure is consistent, and\n\n, where the probability statement is with respect to the bootstrap distribution. Furthermore, if p = 0, then the procedure possesses the adaptive property in that the above inequality is an equality. The method has been implemented in the R package qLearn on  http://cran.r-project.org/web/  packages/qLearn/index.html .\n\nSee the online Supplemental Materials for a simulation study that illustrates the performance of the above approaches to forming a CI."
    },
    {
      "title": "Confidence Intervals for the Value of an Estimated DTR",
      "text": "The topic of constructing CIs for the Value of an estimated DTR has not been adequately addressed in the literature yet, but some insight can be gained by exploiting its connection with classification. As highlighted by Qian and Murphy and Zhao et al.  [58] , the Value of a DTR can be expressed in a similar form as the misclassification error rate in a weighted classification problem. Thus constructing a CI for the Value of an estimated DTR is equivalent to constructing a CI for the test error of an estimated weighted classifier. Unfortunately even in an unweighted classification problem, constructing a CI for the test error is di cult due to the inherent non-smoothness; standard methods like normal approximation or usual bootstrap fail. Laber and Murphy  [83]  developed a method for constructing such CIs using smooth data-dependent upper and lower bounds on the test error; this method is similar to the ACI method described in Section 4.2. While intuitively one can expect that this method could be successfully adapted for the Value of an estimated DTR, more targeted research is needed to extend and fine-tune the procedure to the current setting."
    },
    {
      "title": "Discussion and The Future",
      "text": "Dynamic treatment regimes comprise an increasingly active area of current statistical research with much interest from the clinical science community. SMART studies are increasing in number indicating that for some time the design of, and data analysis for, these trials will provide a steady source of new statistical problems. For example, many interventions are administered in group settings; in case of DTRs this requires the design and analysis of cluster-randomized SMARTs. At the design level, cluster randomization would imply increased sample size requirements due to intra-class correlation. At the analysis level, it would open up questions as to how best to incorporate random effects models or generalized estimating equations into the existing framework of estimation, how the intra-class correlation would impact the non-regularity in inference, and so on. Furthermore the development of statistical methods that can be used in the analysis of longitudinal observational data sets will likely continue to be necessary in this area. In either case methods for variable selection and model checking in the context of constructing data-driven DTRs, both of which pose slightly different issues than similar topics in the prediction literature are under-developed, and warrant further research.\n\nInference in the domain of DTRs is a particularly challenging problem due to non-regularity of the estimators under certain underlying longitudinal data distributions. This challenge occurs both when the targets of inference are the parameters indexing the optimal DTR and when the target is the Value of an estimated DTR. Optimality principles and statistical methods aiming to achieve optimal CIs in these non-regular problems is an open area of research. There is growing interest in confidence intervals for other parameters. One example is data-dependent parameters such as the first stage regression coefficients that would result in a future study in which the estimated second stage decision rule is used to assign treatment. Confidence intervals for this type of parameter is as yet undeveloped.\n\nIn today's health care, there is an increasing use of sophisticated mobile devices (e.g. smart phones, actigraph units containing accelerometers, etc.) to remotely monitor patients' chronic conditions and to intervene, when needed. This is an instance in which methods from online reinforcement learning in the infinite horizon setting may be useful. Development of sound estimation and inference techniques for such a setting is an important future research direction.\n\nThe field of DTRs is in its infancy and is quickly evolving. These methods and trial designs hold much promise for informing sequential decision making in health care. To achieve this promise many of the problems discussed above require further efforts on the part of the statistical community. In addition, dissemination of the newly developed methods into the medical domains and collaboration with clinical scientists will be crucial. Hypothetical SMART design schematic for the addiction management example (an \"R\" within a circle denotes randomization at a critical decision point)."
    },
    {
      "text": "The study can have either a single terminal utility (primary outcome) Y observed at the end of stage 2, or two stage-specific utilities Y 1 and Y 2 adding up to the primary outcome Y = Y 1 + Y 2 (in general Y can be any known function of the data). The interest lies in estimating a two-stage DTR (d 1 , d 2 ), with d j (H j ) \u2208 {-1, 1}."
    },
    {
      "text": "Figure 1."
    }
  ],
  "references": [
    {
      "title": "A new approach to causal inference in mortality studies with sustained exposure periods -application to control of the healthy worker survivor effect",
      "authors": [
        "J Robins"
      ],
      "year": 1986
    },
    {
      "title": "Health Service Research Methodology: A Focus on AIDS",
      "authors": [
        "J Robins"
      ],
      "year": 1989
    },
    {
      "title": "Information recovery and bias adjustment in proportional hazards regression analysis of randomized trials using surrogate markers",
      "authors": [
        "J Robins"
      ],
      "year": 1993,
      "doi": "10.1007/978-1-4757-1229-2_14"
    },
    {
      "title": "Latent Variable Modeling and Applications to Causality: Lecture Notes in Statistics",
      "authors": [
        "J Robins"
      ],
      "doi": "10.1007/978-1-4612-1842-5_4"
    },
    {
      "authors": [
        "M Berkane"
      ],
      "year": 1997
    },
    {
      "title": "Optimal dynamic treatment regimes (with discussions)",
      "authors": [
        "S Murphy"
      ],
      "year": 2003,
      "doi": "10.1111/1467-9868.00389"
    },
    {
      "title": "Proceedings of the Second Seattle Symposium on Biostatistics",
      "authors": [
        "J Robins"
      ],
      "year": 2004
    },
    {
      "title": "A design for testing clinical strategies: Biased adaptive within-subject randomization",
      "authors": [
        "P Lavori",
        "R Dawson"
      ],
      "year": 2000,
      "doi": "10.1111/1467-985x.00154"
    },
    {
      "title": "Adaptive treatment strategies in chronic disease",
      "authors": [
        "P Lavori",
        "R Dawson"
      ],
      "year": 2008,
      "doi": "10.1146/annurev.med.59.062606.122232"
    },
    {
      "title": "Evaluating multiple treatment courses in clinical trials",
      "authors": [
        "P Thall",
        "R Millikan",
        "H Sung"
      ],
      "year": 2000
    },
    {
      "title": "Selecting therapeutic strategies based on efficacy and death in multicourse clinical trials",
      "authors": [
        "P Thall",
        "H Sung",
        "E Estey"
      ],
      "year": 2002
    },
    {
      "title": "An experimental design for the development of adaptive treatment strategies",
      "authors": [
        "S Murphy"
      ],
      "year": 2005,
      "doi": "10.1002/sim.2022"
    },
    {
      "title": "Estimation of survival distributions of treatment policies in two-stage randomization designs in clinical trials",
      "authors": [
        "J Lunceford",
        "M Davidian",
        "A Tsiatis"
      ],
      "year": 2002
    },
    {
      "title": "Optimal estimator for the survival distribution and related quantities for treatment policies in two-stage randomized designs in clinical trials",
      "authors": [
        "A Wahed",
        "A Tsiatis"
      ],
      "year": 2004,
      "doi": "10.1111/j.0006-341x.2004.00160.x"
    },
    {
      "title": "Semiparametric efficient estimation of survival distributions in two-stage randomisation designs in clinical trials with censored data",
      "authors": [
        "A Wahed",
        "A Tsiatis"
      ],
      "year": 2006
    },
    {
      "title": "Improving chronic illness care: Translating evidence into action",
      "authors": [
        "E Wagner",
        "B Austin",
        "C Davis",
        "M Hindmarsh",
        "J Schaefer",
        "A Bonomi"
      ],
      "year": 2001,
      "doi": "10.1377/hlthaff.20.6.64"
    },
    {
      "title": "Estimation of optimal dynamic anticoagulation regimes from observational data: A regret-based approach",
      "authors": [
        "S Rosth\u00f8j",
        "C Fullwood",
        "R Henderson",
        "S Stewart"
      ],
      "year": 2006,
      "doi": "10.1002/sim.2694"
    },
    {
      "title": "Estimation and extrapolation of optimal treatment and testing strategies",
      "authors": [
        "J Robins",
        "L Orellana",
        "A Rotnitzky"
      ],
      "year": 2008,
      "doi": "10.1002/sim.3301"
    },
    {
      "title": "Evaluation of viable dynamic treatment regimes in a sequentially randomized trial of advanced prostate cancer",
      "authors": [
        "L Wang",
        "A Rotnitzky",
        "X Lin",
        "R Millikan",
        "P Thall"
      ],
      "year": 2012,
      "doi": "10.1080/01621459.2011.641416"
    },
    {
      "title": "Dynamic programming",
      "authors": [
        "R Bellman"
      ],
      "year": 1957
    },
    {
      "title": "Semi-markov adaptive critic heuristics with application to airline revenue management",
      "authors": [
        "K Kulkarni",
        "A Gosavi",
        "S Murray",
        "K Grantham"
      ],
      "year": 2011,
      "doi": "10.1007/s11768-011-0161-9"
    },
    {
      "title": "Reinforcement learning: An introduction",
      "authors": [
        "R Sutton",
        "A Barto"
      ],
      "year": 1998
    },
    {
      "title": "Dynamic treatment regimes: Practical design considerations",
      "authors": [
        "P Lavori",
        "R Dawson"
      ],
      "year": 2004
    },
    {
      "title": "Inference for non-regular parameters in optimal dynamic treatment regimes",
      "authors": [
        "B Chakraborty",
        "S Murphy",
        "V Strecher"
      ],
      "year": 2010,
      "doi": "10.1177/0962280209105013"
    },
    {
      "title": "Developmental and augmented intervention for facilitating expressive language (ccnia)",
      "authors": [
        "C Kasari"
      ],
      "year": 2009,
      "doi": "10.5152/tud.2019.19133"
    },
    {
      "title": "A SMART design for building individualized treatment sequences",
      "authors": [
        "H Lei",
        "Nahum Shani",
        "I Lynch",
        "K Oslin",
        "D Murphy"
      ],
      "year": 2011
    },
    {
      "title": "Experimental design and primary data analysis methods for comparing adaptive interventions",
      "authors": [
        "Nahum-Shani I Qian",
        "M Almiral",
        "D Pelham",
        "W Gnagy"
      ],
      "year": 2012
    },
    {
      "title": "Q-learning: A data analysis method for constructing adaptive interventions",
      "authors": [
        "Nahum-Shani I Qian",
        "M Almiral",
        "D Pelham",
        "W Gnagy"
      ],
      "year": 2012
    },
    {
      "title": "Reinforcement-based treatment for pregnant drug abusers (HOME II)",
      "authors": [
        "H Jones"
      ],
      "year": 2010
    },
    {
      "title": "Estimating causal effects of treatments in randomized and nonrandomized studies",
      "authors": [
        "D Rubin"
      ],
      "year": 1974,
      "doi": "10.1037/h0037350"
    },
    {
      "title": "Discussion of \"Randomized analysis of experimental data: The Fisher randomization test\" by D. Basu",
      "authors": [
        "D Rubin"
      ],
      "year": 1980
    },
    {
      "title": "Statistics for experimenters: An introduction to design, data analysis, and model building",
      "authors": [
        "G Box",
        "W Hunter",
        "J Hunter"
      ],
      "year": 1978
    },
    {
      "title": "Screening experiments for developing dynamic treatment regimes",
      "authors": [
        "S Murphy",
        "D Bingham"
      ],
      "year": 2009
    },
    {
      "title": "Causality and Psychopathology: Finding the Deter minants of Disorders and their Cures",
      "authors": [
        "A Oetting",
        "J Levy",
        "R Weiss",
        "S Murphy"
      ],
      "year": 2011
    },
    {
      "title": "Sample size calculations for evaluating treatment policies in multi-stage designs",
      "authors": [
        "R Dawson",
        "P Lavori"
      ],
      "year": 2010,
      "doi": "10.1177/1740774510376418"
    },
    {
      "title": "E cient design and inference for multistage randomized trials of individualized treatment policies",
      "authors": [
        "R Dawson",
        "P Lavori"
      ],
      "year": 2012
    },
    {
      "title": "Supremum weighted log-rank test and sample size for comparing two-stage adaptive treatment strategies",
      "authors": [
        "W Feng",
        "A Wahed"
      ],
      "year": 2008
    },
    {
      "title": "Sample size for two-stage studies with maintenance therapy",
      "authors": [
        "W Feng",
        "A Wahed"
      ],
      "year": 2009,
      "doi": "10.1002/sim.3593"
    },
    {
      "title": "Sampe size formulae for two-stage randomized trials with survival outcomes",
      "authors": [
        "Z Li",
        "S Murphy"
      ],
      "year": 2011,
      "doi": "10.1093/biomet/asr019"
    },
    {
      "title": "Overview, hurdles, and future work in adaptive designs: Perspectives from an nih-funded workshop",
      "authors": [
        "C Coffey",
        "B Levin",
        "C Clark",
        "C Timmerman",
        "J Wittes"
      ],
      "year": 2012
    },
    {
      "title": "Covariate-adjusted adaptive randomization in a sarcoma trial with multi-stage treatments",
      "authors": [
        "P Thall",
        "J Wathen"
      ],
      "year": 2005,
      "doi": "10.1002/sim.2077"
    },
    {
      "title": "Dynamic regime marginal structural mean models for estimation of optimal dynamic treatment regimes, part I: Main content",
      "authors": [
        "L Orellana",
        "A Rotnitzky",
        "J Robins"
      ],
      "year": 2010,
      "doi": "10.2202/1557-4679.1200"
    },
    {
      "title": "A data augmentation method for estimating the causal effect of adherence to treatment regimens targeting control of an intermediate measure",
      "authors": [
        "C Cotton",
        "P Heagerty"
      ],
      "year": 2011
    },
    {
      "title": "Estimating response-maximized decision rules with applications to breastfeeding",
      "authors": [
        "E Moodie",
        "R Platt",
        "M Kramer"
      ],
      "year": 2009,
      "doi": "10.1198/jasa.2009.0011"
    },
    {
      "title": "Statistical learning of origin-specific statically optimal individualized treatment rules",
      "authors": [
        "M Van Der Laan",
        "M Petersen"
      ],
      "year": 2007,
      "doi": "10.2202/1557-4679.1040"
    },
    {
      "title": "Correcting for non-compliance in randomized trials using structural nested mean models",
      "authors": [
        "J Robins"
      ],
      "year": 1994,
      "doi": "10.1080/03610929408831393"
    },
    {
      "title": "Statistical Models in Epidemiology, the Environment, and Clinical Trials",
      "authors": [
        "J Robins"
      ],
      "year": 1999
    },
    {
      "title": "Marginal structural models and causal inference in epidemiology",
      "authors": [
        "J Robins",
        "M Hern\u00e1n",
        "B Brumback"
      ],
      "year": 2000,
      "doi": "10.1097/00001648-200009000-00011"
    },
    {
      "title": "Marginal mean models for dynamic regimes",
      "authors": [
        "S Murphy",
        "M Der Laan",
        "J Robins",
        "Cpprg"
      ],
      "year": 2001
    },
    {
      "title": "Weighted kaplanmeier estimators for two-stage treatment regimes",
      "authors": [
        "S Miyahara",
        "A Wahed"
      ],
      "year": 2010,
      "doi": "10.1002/sim.4020"
    },
    {
      "title": "Dynamic regime marginal structural mean models for estimation of optimal dynamic treatment regimes, part II: Proofs and additional results",
      "authors": [
        "L Orellana",
        "A Rotnitzky",
        "J Robins"
      ],
      "year": 2010,
      "doi": "10.2202/1557-4679.1242"
    },
    {
      "title": "A robust method for estimating optimal treatment regimes",
      "authors": [
        "B Zhang",
        "A Tsiatis",
        "E Laber",
        "M Davidian"
      ],
      "year": 2012
    },
    {
      "title": "Estimating the optimal dynamic antipsychotic treatment regime: Evidence from the sequential-multiple assignment randomized CATIE Schizophrenia Study",
      "authors": [
        "S Shortreed",
        "E Moodie"
      ],
      "year": 2012
    },
    {
      "title": "Comparison of dynamic treatment regimes via inverse probability weighting",
      "authors": [
        "M Hern\u00e1n",
        "E Lanoy",
        "D Costagliola",
        "J Robins"
      ],
      "year": 2006
    },
    {
      "title": "Individualized treatment rules: Generating candidate clinical trials",
      "authors": [
        "M Petersen",
        "S Deeks",
        "M Van Der Laan"
      ],
      "year": 2007
    },
    {
      "title": "Causal effect models for realistic individualized treatment and intention to treat rules",
      "authors": [
        "M Van Der Laan",
        "M Petersen"
      ],
      "year": 2007
    },
    {
      "title": "Performance guarantees for individualized treatment rules",
      "authors": [
        "M Qian",
        "S Murphy"
      ],
      "year": 2011
    },
    {
      "title": "Estimating optimal treatment regimes from a classification perspective",
      "authors": [
        "B Zhang",
        "A Tsiatis",
        "M Davidian",
        "M Zhang",
        "E Laber"
      ],
      "year": 2012
    },
    {
      "title": "Estimating individual treatment rules using outcome weighted learning",
      "authors": [
        "Y Zhao",
        "D Zeng",
        "A Rush",
        "M Kosorok"
      ],
      "year": 2012
    },
    {
      "title": "Analysis of randomized comparative clinical trial data for personalized treatment selections",
      "authors": [
        "T Cai",
        "L Tian",
        "P Wong",
        "L Wei"
      ],
      "year": 2011
    },
    {
      "title": "Estimating treatment effect heterogeneity in randomized program evaluation",
      "authors": [
        "K Imai",
        "M Ratkovicz"
      ],
      "year": 2013
    },
    {
      "title": "A generalization error for Q-learning",
      "authors": [
        "S Murphy"
      ],
      "year": 2005
    },
    {
      "title": "Tree-based batch mode reinforcement learning",
      "authors": [
        "D Ernst",
        "P Geurts",
        "L Wehenkel"
      ],
      "year": 2005
    },
    {
      "title": "Kernel-based reinforcement learning",
      "authors": [
        "D Ormoneit",
        "S Sen"
      ],
      "year": 2002
    },
    {
      "title": "Q-learning for estimating optimal dynamic treatment rules from observational data",
      "authors": [
        "E Moodie",
        "B Chakraborty",
        "M Kramer"
      ],
      "year": 2012
    },
    {
      "title": "Twenty-Seventh International Conference on Machine Learning (ICML)",
      "authors": [
        "D Lizotte",
        "M Bowling",
        "S Murphy"
      ],
      "year": 2010
    },
    {
      "title": "Linear fitted-Q iteration with multiple reward functions",
      "authors": [
        "D Lizotte",
        "M Bowling",
        "S Murphy"
      ],
      "year": 2012
    },
    {
      "title": "Reinforcement learning strategies for clinical trials in nonsmall cell lung cancer",
      "authors": [
        "Y Zhao",
        "D Zeng",
        "M Socinski",
        "M Kosorok"
      ],
      "year": 2011
    },
    {
      "title": "Q-learning with censored data",
      "authors": [
        "Y Goldberg",
        "M Kosorok"
      ],
      "year": 2012
    },
    {
      "title": "Using engineering control principles to inform the design of adaptive interventions: A conceptual introduction",
      "authors": [
        "D Rivera",
        "M Pew",
        "L Collins"
      ],
      "year": 2007
    },
    {
      "title": "Adaptive therapy for androgenindependent prostate cancer: A randomized selection trial of four regimens",
      "authors": [
        "P Thall",
        "C Logothetis",
        "L Pagliaro",
        "S Wen",
        "M Brown"
      ],
      "year": 2007
    },
    {
      "title": "Using mathematical modeling and control to develop structured treatment interruption strategies for hiv infection",
      "authors": [
        "E Rosenberg",
        "M Davidian",
        "H Banks"
      ],
      "year": 2007
    },
    {
      "title": "Feedback control of hiv antiviral therapy with long measurement time",
      "authors": [
        "H Banks",
        "T Jang",
        "H Kwon"
      ],
      "year": 2011
    },
    {
      "title": "A dynamical model for describing behavioural interventions for weight loss and body composition change",
      "authors": [
        "J Navarro-Barrientos",
        "D Rivera",
        "L Collins"
      ],
      "year": 2011
    },
    {
      "title": "Individualization of pharmacological anemia management using reinforcement learning",
      "authors": [
        "A Gaweda",
        "M Muezzinoglu",
        "G Arono",
        "A Jacobs",
        "J Zurada",
        "M Brier"
      ],
      "year": 2005
    },
    {
      "title": "Model predictive control of erythropoietin administrateion in the anemia of esrd",
      "authors": [
        "A Gaweda",
        "A Jacobs",
        "G Arono",
        "M Brier"
      ],
      "year": 2008
    },
    {
      "title": "Artificial intelligence framework for simulating clinical decision-making: A markov decision process approach",
      "authors": [
        "C Bennett",
        "K Hauser"
      ],
      "year": 2012
    },
    {
      "title": "The finite-sample distribution of post-model-selection estimators and uniform versus nonuniform approximations",
      "authors": [
        "H Leeb",
        "B P\u00f6tscher"
      ],
      "year": 2003
    },
    {
      "title": "P values maximized over a confidence set for the nuisance parameter",
      "authors": [
        "R Berger",
        "D Boos"
      ],
      "year": 1994
    },
    {
      "title": "Statistical inference in dynamic treatment regimes",
      "authors": [
        "E Laber",
        "M Qian",
        "D Lizotte",
        "S Murphy"
      ]
    },
    {
      "title": "The conditional level of the f-test",
      "authors": [
        "R Olshen"
      ],
      "year": 1973
    },
    {
      "title": "Bootstrap sample size in nonregular cases",
      "authors": [
        "J Shao"
      ],
      "year": 1994,
      "doi": "10.1090/s0002-9939-1994-1227529-8"
    },
    {
      "title": "Inference for optimal dynamic treatment regimes using an adaptive m-out-of-n bootstrap scheme",
      "authors": [
        "B Chakraborty",
        "E Laber",
        "Y Zhao"
      ],
      "year": 2013
    },
    {
      "title": "Adaptive confidence intervals for the test error in classification",
      "authors": [
        "E Laber",
        "S Murphy"
      ],
      "year": 2011
    }
  ],
  "num_references": 84
}
