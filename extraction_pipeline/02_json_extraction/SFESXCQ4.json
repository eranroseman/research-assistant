{
  "paper_id": "SFESXCQ4",
  "title": "Preference-Based Assessments Computing PROPr Utility Scores for PROMIS \u00ae Profile Instruments",
  "abstract": "Objectives: The Patient-Reported Outcomes Measurement Information System \u00ae (PROMIS) Profile instruments measure health status on 8 PROMIS domains. The PROMIS-Preference (PROPr) score provides a preference-based summary score for health states defined by 7 PROMIS domains. The Profile and PROPr share 6 domains; PROPr has 1 unique domain (Cognitive Function-Abilities), and the Profile has 2 unique domains (Anxiety and Pain Intensity). We produce an equation for calculating PROPr utility scores with Profile data. Methods: We used data from 3982 members of US online survey panels who have scores on all 9 PROMIS domains. We used a 70%/30% split for model fit/validation. Using root-mean-square error and mean error on the utility scale, we compared models for predicting the missing Cognitive Function score via (A) the population average; (B) a score representing excellent cognitive function; (C) a score representing poor cognitive function; (D) a score predicted from linear regression of the 8 profile domains; and (E) a score predicted from a Bayesian neural network of the 8 profile domains. Results: The mean errors in the validation sample on the PROPr scale (which ranges from -0.022 to 1.00) for the models were: (A) 0.025, (B) 0.067, (C) -0.23, (D) 0.018, and (E) 0.018. The root-mean-square errors were: (A) 0.097, (B) 0.12, (C) 0.29, (D) 0.095, and (E) 0.094. \n Conclusion: Although the Bayesian neural network had the best root-mean-square error for producing PROPr utility scores from Profile instruments, linear regression performs almost as well and is easier to use. We recommend the linear model for producing PROPr utility scores for PROMIS Profiles.",
  "year": 2007,
  "date": "2007",
  "journal": "Med Care",
  "publication": "Med Care",
  "authors": [
    {
      "forename": "Barry",
      "surname": "Dewitt",
      "name": "Barry Dewitt",
      "affiliation": "1  Department of Engineering & Public Policy , Carnegie Mellon University , Pittsburgh , PA , USA; \n\t\t\t\t\t\t\t\t Department of Engineering & Public Policy \n\t\t\t\t\t\t\t\t Carnegie Mellon University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Pittsburgh \n\t\t\t\t\t\t\t\t\t PA \n\t\t\t\t\t\t\t\t\t USA;",
      "email": "barrydewitt@cmu.edu"
    },
    {
      "forename": "Hawre",
      "surname": "Jalal",
      "name": "Hawre Jalal",
      "affiliation": "2  Department of Health Policy and Management , Graduate School of Public Health , University of Pittsburgh , Pittsburgh , PA , USA; \n\t\t\t\t\t\t\t\t Department of Health Policy and Management \n\t\t\t\t\t\t\t\t Graduate School of Public Health \n\t\t\t\t\t\t\t\t University of Pittsburgh \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Pittsburgh \n\t\t\t\t\t\t\t\t\t PA \n\t\t\t\t\t\t\t\t\t USA;"
    },
    {
      "forename": "Janel",
      "surname": "Hanmer",
      "name": "Janel Hanmer",
      "affiliation": "3  Division of General Internal Medicine , University of Pittsburgh , Pittsburgh , PA , USA. \n\t\t\t\t\t\t\t\t Division of General Internal Medicine \n\t\t\t\t\t\t\t\t University of Pittsburgh \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Pittsburgh \n\t\t\t\t\t\t\t\t\t PA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "affiliation": "Department of Engineering & Public Policy , Carnegie Mellon University , 5000 Forbes Avenue , Pittsburgh , PA , 15217 , USA \n\t\t\t\t\t\t\t\t Department of Engineering & Public Policy \n\t\t\t\t\t\t\t\t Carnegie Mellon University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 5000 Forbes Avenue \n\t\t\t\t\t\t\t\t\t 15217 \n\t\t\t\t\t\t\t\t\t Pittsburgh \n\t\t\t\t\t\t\t\t\t PA \n\t\t\t\t\t\t\t\t\t USA"
    }
  ],
  "doi": "https://doi.org/10.13039/100000002",
  "keywords": [
    "health utility",
    "patient-reported outcomes",
    "PROMIS",
    "PROPr"
  ],
  "sections": [
    {
      "title": "Introduction",
      "text": "Health-related quality of life (HRQL) measurements usually follow one of two approaches. The psychometric approach describes health states using psychometric testing theories. The econometric approach combines a rudimentary descriptive system for health states with a scoring function to attach utilities to those states. Although both are used for population health studies and clinical trials, only the econometric approach can be used for costutility analyses.\n\nThe Patient-Reported Outcomes Measurement Information System \u00ae (PROMIS) is an initiative supported by the National Institutes of Health (NIH) that produces scales for various domains of HRQL, such as cognitive function, depression, and physical function, using psychometric methodology from item response theory (IRT).  1, 2 PROMIS measures are freely available and used widely.  [3] [4] [5] [6]  The PROMIS-Preference (PROPr) scoring system is based on multi-attribute utility theory, taking health states described by PROMIS and attaching utilities to them so that they can be easily compared.  7 By using PROMIS as its descriptive system for health states, PROPr combines the advantages of psychometric systems-increased reliability and validity of health state measurements-with the usefulness of a value-based econometric system.\n\nThe PROPr scoring system is a societal preference-based measure of HRQL based on 7 PROMIS domains: Cognitive Function-Abilities, Depression, Fatigue, Pain Interference, Physical Function, Sleep Disturbance, and Ability to Participate in Social Roles and Activities. PROPr allows for the calculation of preference-based summary scores for any study that collects measurements on its 7 PROMIS domains. The PROPr scoring system connects the psychometrically advanced measurement system represented by PROMIS with best practices in utility-based scoring system construction. PROPr allows PROMIS data to be used to produce health utilities, be incorporated in economic and decision analyses, and be used to construct quality-adjusted lifeyears (QALYs). PROPr was developed as a generic societalpreference based HRQL instrument. Its development, including the choice of its PROMIS domains, are described elsewhere.  [7] [8] [9] [10] [11] [12]  Briefly, it was produced using preference elicitations of a US sample representative of the general population (n = 983) via the standard gamble technique. Its minimum score is -0.022, dead has a score of 0, and the maximum score is 1.\n\nPROMIS Profile instruments are widely used standardized short-form questionnaires.  6 Our own scoping review of the literature found that over 20 000 PROMIS Profile survey administrations have been reported. All PROMIS Profile instruments produce measurements on 8 PROMIS domains, 6 of which are used in PROPr and 2 of which are not included in PROPr (Anxiety and Pain Intensity) (see Figure  1 ). Studies that use PROMIS Profile instruments cannot calculate a PROPr summary score with their data unless they have a way to predict the missing Cognitive Function score. Here, we compare various methods for predicting a Cognitive Function score from PROMIS Profile data, with the goal of producing a summary PROPr score for those data. Our goal is to find a model that allows those with PROMIS Profile data to produce a PROPr score with a high level of confidence while also presenting the user with a model that is straightforward to implement, lest it be misapplied or misunderstood."
    },
    {
      "title": "Methods",
      "text": "We begin with a detailed overview of the measures used in the study, and the data we used to select a model for calculating PROPr scores for PROMIS Profile data. We then describe the candidate models."
    },
    {
      "title": "PROMIS measures",
      "text": "PROMIS is an NIH-funded initiative for producing psychometrically advanced patient-reported outcomes that are free to use and available for dozens of health domains.  1, 13 Every PROMIS domain produces a measurement on a latent unidimensional scale called \"theta.\" For example, responses to any set of items (questions) from the PROMIS Depression domain would produce a depression score. The underlying IRT calibration is on theta with a population mean of 0 and a standard deviation of 1. PROMIS scores are usually reported on the T-score metric, which is a transformation so that the population mean is 50 with a standard deviation of 10.\n\nOne advantage of IRT-based measures is that scores produced by different sets of items from a domain are commensurable.  14 This feature makes PROMIS suitable for a variety of data-collecting contexts, ranging from population surveys to clinical encounters, as the set of questions can be tailored to the scenario at hand. PROMIS can be administered with computer adaptive testing, which presents an individual with the most informative set of questions available and can use stopping rules to produce a theta estimate with a given level of uncertainty. Standardized short-forms are also commonly used, which give the same set of questions to all participants. Because PROMIS is based on IRT, a score from a computer adaptive test and a score from a short form on the same PROMIS domain can be compared.\n\nPROMIS Profile instruments are widely used standardized sets of short forms, intended to provide a general HRQL measure. There are a variety in use, such as the PROMIS-29, the PROMIS-43, and the PROMIS-57 (see  http://www.healthmeasures.net/ ). They all measure 8 PROMIS domains: Anxiety, Depression, Fatigue, Pain Intensity, Pain Interference, Physical Function, Sleep Disturbance, and Ability to Participate in Social Roles and Activities."
    },
    {
      "title": "The PROMIS-Preference (PROPr) Scoring System",
      "text": "The PROMIS-Preference (PROPr) scoring system allows preference-based scores to be estimated from health states described by 7 PROMIS domains. The 7 domains are used to generate single-attribute utility scores-one for each domain-using 7 single-attribute utility functions. These are then combined using multi-attribute utility theory to produce a summary score. Cognitive Function-Abilities Depression Fatigue Pain Interference Physical Function Sleep Disturbance Social Roles Anxiety Pain Intensity PROMIS Profile PROPr PROMIS indicates Patient-Reported Outcomes Measurement Information System; PROPr, PROMIS-Preference scoring system."
    },
    {
      "title": "Data Source",
      "text": "We used data from 3982 members of US online survey panels who responded to items from 9 PROMIS domains: the 8 included in the PROMIS Profile instruments plus Cognitive Function-Abilities. The data came from 2 sources. Of the 3982 participants, 983 came from the PROPr estimation survey, which was used to produce the PROPr summary scoring function.  7, 9 he other 2999 came from the Profiles-Health Utility Index (HUI) survey.  15 Both surveys have been described in detail elsewhere.  7, 15 cores for each PROMIS domain were calculated using the scoring service from the HealthMeasures Assessment Center ( https://www.assessmentcenter.net/ac_scoringservice ), with the default adult calibration sample consistent with the Profile v2.0 scoring. PROPr scores were calculated using a freely available scoring algorithm ( https://github.com/janelhanmer/PROPr )."
    },
    {
      "title": "Modeling"
    },
    {
      "title": "Model descriptions",
      "text": "The Model D uses forward and backward stepwise regression without interactions to choose a candidate model, where the smallest model is the intercept-only model and the largest is expressed in Equation  1 :\n\nEquation 1: Predicting Cognitive Function scores in a linear regression model, with the PROMIS Profile domains as independent variables.\n\nHere, q domain is the theta score on the given domain, S pain is the pain intensity score (q pain is the pain interference score), and \u03b5 is an error term. The qs are unbounded, and the pain intensity score (S pain ) is on a 0-10 scale with unit intervals.\n\nModel E implements a machine learning procedure called a multi-layer perceptron neural network. The neural network is particularly suited to discovering nonlinear relationships between the independent variables (8 PROMIS domain scores) and the dependent variable (the Cognitive Function scores). It is a Bayesian neural network because it uses a Bayesian regularization backpropagation process to choose the hyperparameters of the model.  16, 17 All analyses were run in R (version 3.4.4). The Bayesian neural network was estimated using the keras package (version 2.2.4), using the TensorFlow backend and rstan (version 2.18.2). We varied the number of layers in the neural network (from 2 to 100) and the number of nodes in each layer (from 5 to 100)."
    },
    {
      "title": "Model comparison procedure",
      "text": "The data set described earlier includes the required information to calculate a PROPr score for all participants. Therefore we used the data set to predict Cognitive Function thetas using the models from the previous section, using those predicted thetas to produce PROPr scores and comparing the predicted PROPr scores with true PROPr scores. We evaluated model fit using mean-error (ME) and root-mean-square error (rMSE). We split the data randomly into a 70%/30% training/validation set for cross-validation, fitting the models on the training set and calculating MEs and rMSEs on the validation set (n training \u00bc 2786 and n training \u00bc 1196). That split was chosen because the machine-learning method is data dependent in a way that usual parametric regression is not. Although the parameter estimates of the latter are obviously data-dependent, the actual functional form of the machine-learning model depends on the data set as well-not just its (hyper)parameters values. In addition, to compare model performance among the competing models, one needs to have a common group for out-ofsample validation. The rMSEs calculated on the validation set provided an unbiased estimate of generalization error.\n\nWe As a robustness check, we repeated the above procedure stratifying the validation set by the number of chronic conditions reported by the participants,  7, 15  and by binning the Cognitive Function theta scores, based on the quartiles of those scores across the whole data set. These procedures were intended to stress each model's performance by adjusting the health of the validation sample. We also computed correlations between observed and predicted scores and prediction bias, as well as the means and standard deviations of observed and predicted scores by age and gender, all on the validation set."
    },
    {
      "title": "Results",
      "text": "Table  1  shows the demographic characteristics of the sample, including the number of chronic conditions reported by the participants.\n\nThe results of both stepwise regression procedures selected the largest model (Equation  1 ) as the candidate linear model. We observed suppression effects on Fatigue and Pain Interference (ie, negative zero-order correlations of around -0.3 for each with the dependent variable, but positive coefficients in the model). We re-estimated the model, removing those two domains. That yielded a model with no suppression effects and similar model fit (the difference in variance-explained occurred at the thousandths decimal place). Because worse fatigue or worse pain should not predict better utilities-by predicting better cognitive function-we continued our analyses with the model that omits Pain Interference and Fatigue.\n\nThe neural network's performance plateaued quickly with the increase in the number of hidden layers and hidden nodes. We relied on using the validation data set to avoid overfitting the neural network. The model's performance started to plateau when we used 10 hidden nodes and 2 layers. As expected, larger models had better fitting scores to the training data set but lower scores for the validation data set.\n\nTable  2  shows the results of calculating rMSE and ME on the PROPr scale (columns 1 and 2), and the rMSE and ME on the Cognitive Function theta scale (columns 3 and 4). The PROPr scale ranges from -0.022 to 1 and the Cognitive Function theta scale is unbounded, although the observed range of cognitive function in these data is -2.70 to 1.67.\n\nIn terms of rMSE on both the PROPr scale and the Cognitive Function scale, the Bayesian neural network performed best, followed by the linear model, the zero model, the ceiling model, and the floor model.\n\nExcept for the low score constant model (the floor model), the other models tended to overpredict the Cognitive Function score (and hence the PROPr score).\n\nFigure  2  shows the rMSE on the PROPr scale when the validation set is split into those who reported 0, 1, 2, 3, 4, and 51 chronic conditions (see Table  1 ). The Bayesian neural network performed best, followed by the linear model, the zero model, the ceiling model, and the floor model. Figure  3  shows model performance when the validation set is divided by the sample quantiles of Cognitive Function scores. Here, the linear model, neural network, and zero model performed best in the middle two quartiles, with the floor and ceiling unsurprisingly producing the best predictions for the lowest and highest cognitive function scores, respectively.\n\nPrediction bias and correlations between observed and predicted scores are in Table  3 , showing high correlations and a tendency for overprediction (except for the floor model, as one would expect). Table  4  shows the mean actual and predicted scores by age and gender for each of the models."
    },
    {
      "title": "Discussion",
      "text": "We compared 5 models for producing PROPr preference scores using PROMIS Profile data. PROMIS Profile instruments are widely used standardized questionnaires for measuring HRQL and provide PROMIS scores for 8 domains: Anxiety, Depression, Fatigue, Pain Intensity, Pain Interference, Physical Function, Sleep Disturbance, and Ability to Participate in Social Roles and Activities. To generate PROPr scores, measurements on 7 PROMIS domains are required, which include 6 of the PROMIS Profile domains (all except Anxiety and Pain Intensity) and a measurement on the Cognitive Function-Abilities domain. Thus, without true Cognitive Function scores, it is necessary to predict them for PROMIS Profile datasets so that those data can be used to inform economic, decision, and public-health analyses via utility values generated from PROPr. Our analyses have produced models with generalization error less than 10% of the PROPr scale, allowing the generation of a PROPr score for datasets with only PROMIS Profile data.\n\nWe found that a linear model is nearly as good at predicting Cognitive Function scores as a Bayesian neural network. Our results, we believe, are largely driven by the way that the PROMIS domains in PROPr were chosen. They were selected to be structurally independent, meaning that, given a pair of domains, any combination of theta values could conceivably occur.  11 Structural and statistical independence are related, but neither one is necessary nor sufficient for the other. The fact that a linear model with no interactions or transformations performs almost as well as the Bayesian neural network can be seen as an additional empirical validation of the domain selection method. That is, the PROMIS domains in PROPr contain only so much information about each other, and about Cognitive Function in particular; including more complicated terms in the model-the Bayesian neural network excels at discovering nonlinear relationships-only improves prediction by a small amount. The good performance overall of the zero model further demonstrates the difficulty of the prediction task. Thus, although we believe the out-of-sample performance demonstrates that one can estimate a PROPr score with the PROMIS Profile, we do not endorse the use of Table  2 . Root-mean-square error and mean error of the five models, calculated on the validation data set. The second and third columns show the results on the PROPr utility scale, and the fourth and fifth columns show the results on the Cognitive Function-Abilities scale."
    },
    {
      "title": "Model",
      "text": "RMSE (PROPr) ME (PROPr) RMSE (cog) ME (cog) (A) Zero 0.0966 0.0251 1.0867 0.2435 (B) Ceiling 0.1178 0.0673 1.7296 1.3675 (C) Floor 0.2860 -0.2308 2.0958 -1.8085 (D) Linear model 0.0946 0.0175 0.954 0.0399 (E) Bayesian neural network 0.0938 0.0175 0.9357 0.0300 Cog indicates Cognitive Function-Abilities scale; ME, mean error; PROPr, PROMIS-preference; RMSE, root-mean-squared error.\n\nthese models for the prediction of Cognitive Function scores for other purposes. In addition, we recommend that any researcher designing a new data collection with PROMIS measures who also wants to compute health utility scores include the 7 domains from PROPr so that their data set has complete measurements. In the case where a researcher is considering a PROMIS Profile, that can be accomplished by adding only two additional Cognitive Function-Abilities items (e.g., see the \"PROMIS-29 1 2\" at  http://www.healthmeasures.net ). Thus our analyses suggest that the linear model is sufficient for the task at hand, performing almost as well as a neural network with many more parameters. The linear model is easy to implement as it requires knowing only the 6 coefficients and the intercept value. It is also a method that should be familiar to policy analysts and researchers across public health, health, pharmaco-economics, and decision analysis. Table  5  shows the regression coefficients of the linear model estimated from the entire data set. The entries in Table  5  can be used to predict the missing Cognitive Function score, and then the complete vector of 7 PROMIS scores can be used as input to the PROPr summary scoring function to obtain a PROPr score. An appendix (see Supplemental Materials Section) provides example code showing an implementation of the model in Table  5  and the computation of a confidence interval for an estimate of a conditional mean Cognitive Function score.\n\nDuring the course of the study, we also investigated the candidate models under linear equating, a common practice in health-utility mapping studies, where predicted scores are linearly transformed to have the same mean and standard deviation as the observed scores, to counteract regression to the mean.  15, 18, 19 Nevertheless, unlike mapping studies, the dependent variable in our models was a health domain, not a utility, which would then be used as input together with other health domain measurements to estimate a health utility score. As such, we are attempting to best predict cognitive function in order to produce PROPr scores and thus should be minimizing rMSE, rather than scale-aligning, as in the mapping literature.\n\nBecause PROPr was estimated using a sample whose demographics match the general population, it is not surprising that the unconditional population mean is worse in terms of rMSE than the nonconstant models, and that it would not perform as well in samples with Cognitive Function scores very different from the mean (eg, in those with excellent health or with conditions affecting cognition). As with other generic societal preference-based scores, PROPr is relevant in analyses using patient data when a societal perspective is required. Nevertheless, in a PROMIS Profile data set with vastly different participant characteristics than the data we used in our study, our recommended model might not perform as well as it would for data sets from other community samples. Care should be taken in such instances to consider whether, and if so, how, relationships among the PROMIS domains could differ in those contexts, and whether the results of our study are still appropriate.\n\nThe Profiles-HUI sample had more unhealthy participants than would be expected from a probability sample of the US general population. Depending on the true relationships among the PROMIS domains, it could be the case that the model selection procedure is sensitive to the health of the sample. Operationalizing health by the number of chronic conditions (Figure  2 ), the models perform in the same order and with Both the PROPr survey data and Profiles-HUI survey data are publicly available.  20, 21 Our goal was to produce a method that could work for anyone who collected PROMIS Profile data. The two surveys we used both share variables beyond the 8 PROMIS domains used in our models, such as age and sex and common chronic conditions. A researcher whose data shares these variables could use our approach to build a better model. Furthermore, a researcher with a sample of the general population that is missing the Cognitive Function score for other reasons (ie, who truly has missing data in the sense of Little and Rubin's seminal work) could combine their data with the PROPr and Profiles-HUI surveys and use multiple imputation to complete their analyses.  22, 23 e aimed to produce a recommendation that could be used with individual-level data coming from any PROMIS Profile instrument, and thus we restricted our set of independent variables to the PROMIS domains used in the PROMIS Profile. As PROPr's summary scoring function is multiplicative, and thus"
    },
    {
      "title": "Conclusion",
      "text": "With the model presented in Table  5 , any researcher or analyst with a data set that administered a PROMIS Profile instrument can now use that data to produce utility-based summary scores using the PROPr scoring system. Many more data sets can now be used for health valuation, and thus be incorporated in analyses that require those numbers, such as cost-effectiveness analyses. The linear model we recommend is easily implementable in any statistical programming language (see the Appendix in the Supplemental Materials section), and the PROPr scoring system is free to use, with freely available code in R and SAS, which can be translated to other programming languages."
    },
    {
      "text": "Six of the PROPr domains are shared with the PROMIS Profile instruments: Depression, Fatigue, Pain Interference, Physical Function, Sleep Disturbance, and Ability to Participate in Social Roles and Activities. The seventh is Cognitive Function-Abilities. Without a Cognitive Function score, those with PROMIS Profile data cannot produce a single-attribute Cognitive Function utility score and thus a PROPr summary score."
    },
    {
      "text": "Figure 1. Venn diagram showing the PROMIS domains included in the PROMIS Profile instruments and those required to generate a PROPr utility score."
    },
    {
      "text": "range of Cognitive Function theta scores captured by PROPr is -2.052 to 1.124. We chose to compare 5 models for producing PROPr scores when Cognitive Function scores are missing: A. The zero model, which uses the population average Cognitive Function score (q cognition \u00bc 0). B. The ceiling model, which uses a score representing excellent cognitive function, q cognition \u00bc 1:124, the lowest Cognitive Function score to produce a utility of 1 in the single-attribute Cognitive Function utility scale. C. The floor model, which uses a score representing poor cognitive function, q cognition \u00bc 2 2:052, which is the highest Cognitive Function score to produce a utility of 0 in the single-attribute Cognitive Function utility scale. D. A linear regression model, which predicts the Cognitive Function score as a function of the 8 PROMIS Profile domains. The selection of a functional form is described below. E. A Bayesian neural network, which predicts the Cognitive Function score and where the feature data are the 8 PROMIS Profile domain scores. These models predict the missing Cognitive Function score, which is then used to produce a single-attribute Cognitive Function utility that is combined with the other 6 single-attribute utilities to produce the PROPr summary score. Models A to C are constant models-predicting the same PROMIS Cognitive Function theta score for every participant. The population average theta value (zero model [A]) is 0 by construction and receives a utility value of 0.858 on the single-attribute Cognitive Function utility scale. A value of 1.124 was used as a score representing excellent cognitive function (ceiling model [B]), as it is the lowest theta value receiving a utility of 1 in the PROPr Cognitive Function utility scale, which is the highest possible utility. Similarly, a value of -2.052 was used as a score representing poor cognitive function (floor model [C]) because it is the highest theta value receiving a utility of 0 in the PROPr Cognitive Function utility scale, which is the lowest possible utility of the scale. These 3 constant models were chosen to represent na\u00efve approaches to adding a Cognitive Function score to PROMIS Profile data."
    },
    {
      "text": "calculated ME and rMSE on the Cognitive Function theta scores and the resulting PROPr scores. The former refers to comparing predicted Cognitive Function theta scores with the true Cognitive Function theta scores. The latter refers to using the predicted Cognitive Function theta score along with the 6 other (true) PROMIS domain scores included in the PROPr scoring system to generate a predicted PROPr score and comparing it with the true PROPr score."
    },
    {
      "text": "Figure 2. Root-mean-square error on the PROPr scale, dividing the validation set by self-reported chronic conditions."
    },
    {
      "text": "Figure 3. Root-mean-square error on the PROPr scale, dividing the validation set by sample quartile on Cognitive Function-Abilities.The \"1\" indicates the group whose cognitive function score fell within the minimum to the first quartile; \"2,\" the group whose score fell within the first quartile to the median; \"3,\" the group whose score fell within the median to the third quartile, and \"4,\" the group whose score fell within the third quartile to the maximum."
    },
    {
      "text": "Demographic information of the study sample, which is composed of two surveys, the PROPr and Profiles-HUI survey. The last column compares the makeup of those surveys with the 2010 US Census for the demographic variables and the National Health Interview Survey 2016 for the health-related variables."
    },
    {
      "text": "Prediction bias (mean of predictions minus mean of observed scores) and Pearson correlation between predictions and observed scores for each model on the validation set, all on the PROPr scale."
    },
    {
      "text": "Mean and standard deviations of observed scores and predicted scores of the validation set, by age and gender.* indicates female; LM, linear model; M, male; NM, neural network. *Two participants were removed from these calculations: one, who reported an impossible age, and another who was the only person in the PROPr survey data set to respond \"other\" when asked to self-report their gender."
    },
    {
      "text": "Regression table for the recommended linear model, estimated on the entire data set."
    }
  ],
  "references": [
    {
      "title": "The patient-reported outcomes measurement information system (PROMIS): progress of an NIH roadmap cooperative group during its first two years",
      "authors": [
        "D Cella",
        "S Yount",
        "N Rothrock"
      ],
      "year": 2007,
      "doi": "10.1097/01.mlr.0000258615.42478.55"
    },
    {
      "title": "NIH's transformative opportunities for the behavioral and social sciences",
      "authors": [
        "F Collins",
        "W Riley"
      ],
      "year": 2016,
      "doi": "10.1126/scitranslmed.aai9374"
    },
    {
      "title": "PROMIS \u00ae adult health profiles: efficient short-form measures of seven health domains",
      "authors": [
        "D Cella",
        "S Choi",
        "D Condon"
      ],
      "year": 2019,
      "doi": "10.1016/j.jval.2019.02.004"
    },
    {
      "title": "PROMIS\u00ae: standardizing the patient voice in health psychology research and practice",
      "authors": [
        "S Yount",
        "D Cella",
        "S Blozis"
      ],
      "year": 2019,
      "doi": "10.1037/hea0000741"
    },
    {
      "authors": [
        "Healthmeasures",
        "Promis"
      ],
      "year": 2019,
      "doi": "10.1186/s41687-020-0176-4"
    },
    {
      "title": "The use of PROMIS and assessment center to deliver patient-reported outcome measures in clinical research",
      "authors": [
        "R Gershon",
        "N Rothrock",
        "R Hanrahan",
        "M Bass",
        "D Cella"
      ],
      "year": 2010
    },
    {
      "title": "Estimation of a preference-based summary score for the patient-reported outcomes measurement information system: The PROMIS\u00ae-preference (PROPr) scoring system",
      "authors": [
        "B Dewitt",
        "D Feeny",
        "B Fischhoff"
      ],
      "year": 2018,
      "doi": "10.1177/0272989x18776637"
    },
    {
      "title": "Evaluation of options for presenting healthstates from PROMIS\u00ae item banks for valuation exercises",
      "authors": [
        "J Hanmer",
        "D Cella",
        "D Feeny"
      ],
      "year": 2018,
      "doi": "10.1007/s11136-018-1852-1"
    },
    {
      "title": "Cross-sectional validation of the PROMIS-Preference scoring system",
      "authors": [
        "J Hanmer",
        "B Dewitt",
        "L Yu"
      ],
      "year": 2018,
      "doi": "10.1371/journal.pone.0201093"
    },
    {
      "title": "PROMIS-Preference (PROPr) Score Construction-A",
      "authors": [
        "J Hanmer",
        "B Dewitt"
      ],
      "year": 2017
    },
    {
      "title": "Selection of key health domains from PROMIS\u00ae for a generic preference-based scoring system",
      "authors": [
        "J Hanmer",
        "D Cella",
        "D Feeny"
      ],
      "year": 2017,
      "doi": "10.1007/s11136-017-1686-2"
    },
    {
      "title": "The PROMIS of QALYs",
      "authors": [
        "J Hanmer",
        "D Feeny",
        "B Fischhoff"
      ],
      "year": 2015,
      "doi": "10.1186/s12955-015-0321-6"
    },
    {
      "title": "The future of outcomes measurement: item banking, tailored short-forms, and computerized adaptive assessment",
      "authors": [
        "D Cella",
        "Gershon Lai",
        "J Choi"
      ],
      "year": 2007,
      "doi": "10.1007/s11136-007-9204-6"
    },
    {
      "title": "Item Response Theory for Psychologists",
      "authors": [
        "S Embretson",
        "S Reise"
      ],
      "year": 2000
    },
    {
      "title": "Using linear equating to map PROMIS\u00ae global health items and the PROMIS-29 V2",
      "authors": [
        "R Hays",
        "D Revicki",
        "D Feeny",
        "P Fayers",
        "K Spritzer",
        "D Cella"
      ],
      "doi": "10.1007/s40273-016-0408-x"
    },
    {
      "title": "0 profile measure to the health utilities index mark 3",
      "year": 2016,
      "doi": "10.1007/s40273-016-0408-x"
    },
    {
      "title": "Bayesian interpolation",
      "authors": [
        "Djc Mackay"
      ],
      "year": 1992,
      "doi": "10.1162/neco.1992.4.3.415"
    },
    {
      "title": "Gauss-Newton approximation to Bayesian learning",
      "authors": [
        "F Foresee",
        "M Hagan"
      ],
      "year": 1997
    },
    {
      "title": "Mapping PROMIS global health items to EuroQol (EQ-5D) utility scores using linear and equipercentile equating",
      "authors": [
        "N Thompson",
        "B Lapin",
        "I Katzan"
      ],
      "year": 2017,
      "doi": "10.1007/s40273-017-0541-1"
    },
    {
      "title": "Should linking replace regression when mapping from profile-based measures to preference-based measures?",
      "authors": [
        "P Fayers",
        "R Hays"
      ],
      "year": 2014,
      "doi": "10.1016/j.jval.2013.12.002"
    },
    {
      "title": "PROMIS Profiles-HUI data",
      "authors": [
        "D Cella"
      ],
      "year": 2017
    },
    {
      "title": "Creating the PROMIS-Preference (PROPr) Score",
      "authors": [
        "B Dewitt",
        "J Hanmer"
      ],
      "year": 2016,
      "doi": "10.1016/j.jval.2019.09.2752"
    },
    {
      "title": "Multiple imputation to deal with missing EQ-5D-3L data: Should we impute individual domains or the actual index?",
      "authors": [
        "C Simons",
        "O Rivero-Arias",
        "L Yu",
        "J Simon"
      ],
      "year": 2015,
      "doi": "10.1007/s11136-014-0837-y"
    },
    {
      "title": "Tutorial in biostatistics multiple imputation using chained equations : issues and guidance for practice",
      "authors": [
        "I White",
        "A Wood"
      ],
      "year": 2011,
      "doi": "10.1002/sim.4067"
    }
  ],
  "num_references": 24
}
