{
  "paper_id": "9U8RG6UJ",
  "title": "Do We Trust ChatGPT as much as Google Search and Wikipedia?",
  "abstract": "Although studies, audits, and anecdotal observations have shown that information generated by ChatGPT is not always accurate, many users tend to show unwarranted trust in this new source. Do they consider ChatGPT to be like any other online information source such as Google and Wikipedia, without realizing that generative AI technology creates content that is not necessarily based on facts? Why do they trust information from ChatGPT? Understanding how users perceive content from generative AI tools is crucial because it can help reduce unwarranted trust in inaccurate information and mitigate the spread of misinformation. A focus group and interview study (N=14) revealed that thankfully not all users trust ChatGPT-generated information as much as Google Search and Wikipedia. It also shed light on the primary psychological considerations when trusting an online information source, namely perceived gatekeeping, and perceived information completeness. In addition, technological afordances such as interactivity and crowdsourcing were also found to be important for trust formation. We discuss theoretical and practical implications for design of generative AI interfaces.",
  "year": 2023,
  "date": "2023",
  "journal": "The New York Times",
  "publication": "The New York Times",
  "authors": [
    {
      "forename": "Jung",
      "surname": "Yongnam",
      "name": "Jung Yongnam",
      "affiliation": "Media Efects Research Laboratory Elon University Pennsylvania State University Doimukh , NC , USA University Park , PA , USA Media Efects Research Laboratory Media Efects Research Laboratory \n\t\t\t\t\t\t\t\t Media Efects Research Laboratory \n\t\t\t\t\t\t\t\t Media Efects Research Laboratory Media Efects Research Laboratory \n\t\t\t\t\t\t\t\t Elon University Pennsylvania State University Doimukh \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t University Park \n\t\t\t\t\t\t\t\t\t NC PA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "surname": "Chen",
      "name": "Chen",
      "affiliation": "Media Efects Research Laboratory Elon University Pennsylvania State University Doimukh , NC , USA University Park , PA , USA Media Efects Research Laboratory Media Efects Research Laboratory \n\t\t\t\t\t\t\t\t Media Efects Research Laboratory \n\t\t\t\t\t\t\t\t Media Efects Research Laboratory Media Efects Research Laboratory \n\t\t\t\t\t\t\t\t Elon University Pennsylvania State University Doimukh \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t University Park \n\t\t\t\t\t\t\t\t\t NC PA \n\t\t\t\t\t\t\t\t\t USA",
      "email": "cchen8@elon.edu"
    },
    {
      "forename": "Eunchae",
      "surname": "Jang",
      "name": "Eunchae Jang",
      "affiliation": "Pennsylvania State University Pennsylvania State University University Park , PA , USA University Park , PA , USA \n\t\t\t\t\t\t\t\t Pennsylvania State University Pennsylvania State University University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Park University Park \n\t\t\t\t\t\t\t\t\t PA PA \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "S",
      "surname": "Shyam Sundar",
      "name": "S Shyam Sundar",
      "affiliation": "Pennsylvania State University Pennsylvania State University University Park , PA , USA University Park , PA , USA \n\t\t\t\t\t\t\t\t Pennsylvania State University Pennsylvania State University University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Park University Park \n\t\t\t\t\t\t\t\t\t PA PA \n\t\t\t\t\t\t\t\t\t USA"
    }
  ],
  "doi": "10.1145/3613905.3650862",
  "keywords": [
    "Trust",
    "ChatGPT",
    "Google",
    "Wikipedia"
  ],
  "sections": [
    {
      "title": "INTRODUCTION",
      "text": "In January 2023, two New York lawyers were sanctioned for citing fctitious cases in their legal briefs  [1] . The lawyers had used ChatGPT, which fabricated judicial opinions and legal citations.\n\nThey believed that the information they had obtained from Chat-GPT was factual. This incident shows that laypersons, including professionals, tend to trust ChatGPT-generated information. They seem to equate it to a research tool such as Google Search and Wikipedia, without recognizing it as a product of Generative AI that generates text without regard for factual accuracy. Our project investigates whether this is indeed the case, and where ChatGPT stacks up on information credibility compared to more established online sources. Understanding user psychology pertaining to the reception of content from generative AI tools is important for designing alerts, warnings, and other guardrails to scafold users as they peruse and share such content online. It can help reduce unwarranted trust in wrong information and thereby help temper the spread of misinformation."
    },
    {
      "title": "TRUST",
      "text": "Researchers have long studied the diferential trust in information from diferent sources. Whenever a new communication technology is adopted widely in society, scholars tend to be concerned about the credibility of the information from it. This is because most users most of the time do not have the bandwidth to carefully examine the veracity of the information themselves; they rely on the credibility of the source instead to decide whether or not they should believe in the information provided by that source. When Wikipedia was introduced, many individuals had concerns about the credibility of its information because of the open-source nature of Wikipedia articles whose sources are unknown  [16] , and the absence of a centralized editorial review  [7] . Similarly, scholars examined why individuals trust information from Google search results soon after its launch and what features contribute to their decisions. An eyetracking study revealed that individuals have a positive bias toward information ranked higher on the results page even if it is less relevant than information which appears lower  [18] . ChatGPT as a communication source difers from Wikipedia and Google Search because it is neither a crowdsourcing platform nor a search engine, but its output may be seen as credible as these sources, especially given the authoritative manner in which it responds to questions and the fact that it is trained on a vast corpus of human-written text. Given that Google Search Engine and Wikipedia are now commonly used as credible sources for information gathering, we treat them as reference groups and ask: do individuals trust ChatGPT as much as Google Search and Wikipedia?"
    },
    {
      "title": "TYPOLOGY OF SOURCES",
      "text": "The literature in the feld of communication studies not only emphasizes the importance of source credibility, but also suggests that there are several diferent types of sources. Communication receivers often fail to make a clear distinction between the originator of the message (source) and the interface conveying a message (channel)  [3] . This murkiness became more complicated with the arrival of new communication technologies in the internet era, leading Sundar and Nass to create a typology of online communication sources: visible sources (i.e., experts or professionals, like journalists, who curate information for consumption by the masses), technological sources (i.e., technological interfaces perceived by recipients as the origin of information), and receiver sources (i.e., peers and other users of the same service or platform who approve, forward, and otherwise curate information for their networks)  [24] . User responses to content can vary based on the type of source that is identifed as the originator of content. The three sources of interest to this project could be roughly aligned with these three categories of sources identifed by the typology, in that Google Search is a visible source known to prioritize expert and relevant outputs, ChatGPT is a technological source that autonomously generates content without ostensible human intervention, and Wikipedia is a receiver source based on collective eforts of several peers. Such distinctions between the sources is important because they highlight the diferences (sometimes real, sometimes presumed) in their role as sources, triggering diferent cognitive heuristics (or mental shortcuts) that may shape user evaluations of credibility and consequently their decisions pertaining to the degree to which they trust the information coming from a given source  [21] . For example, a visual cue on the interface suggesting a visible source may cue the authority heuristic (experts can be trusted), or one signaling a technological source may cue the machine heuristic (machines provide more objective and precise information than humans), or one attributing a receiver source may cue the bandwagon heuristic (if many others think this information is good, then it is credible). In this way, sources can convey diferent meanings to users."
    },
    {
      "title": "WHAT MEDIATES INFORMATION SOURCES AND TRUST",
      "text": "Depending upon how the sources in the typology are operationalized and advertised on the interface, users will draw specifc meanings about the nature of the sources as well as the veracity of the information provided by them. One study used Sundar and Nass's (2001) source typology in the online health information context and further categorized the visible source into collective level and individual level  [12] . Their study revealed that individuals are more likely to take action based on the information from collective-level sources (a website) than individual-level sources (a personal home page and blog), and this efect was mediated by the perceived level of gatekeeping and perceived information completeness. These are two potential mediators for source efects, and we describe each of them in the sections that follow."
    },
    {
      "title": "Perceived gatekeeping",
      "text": "Gatekeeping is the journalistic process by which an extensive range of potential news messages are refned into a few new messages that the news media broadcasts  [19] . Scholars posit that the important role of selecting sources is to perform gatekeeping, and information chosen collectively stands a greater chance of being consumed by the mass audience compared to information selected individually  [12] . Traditionally, professional gatekeepers could flter a signifcant portion of available information, and they are incentivized to maintain credibility standards  [17] . However, as communication technologies such as the Web lowered the cost of information production and dissemination, the vast amount of digital information do not undergo the same degree of fltering through professional gatekeepers, making readers susceptible to information that is of questionable credibility. Thus, in the current online environment, gatekeeping is not only related to the experts' editorial capability (because laypersons can upload diverse information online) but also its collective nature. Information chosen collectively stands a greater chance of being consumed by a mass audience compared to information selected individually  [12] . Wikipedia's principle is that as the community collaboratively contributes to content, the reliability of the content improves over time  [4] . These all posit that the role of gatekeeping in information evaluation is also related to the collective nature of the source. Studies have observed that the gatekeeping function on the internet has changed the responsibility for assessing content and ensuring the accuracy of information from editors to other online users  [10] ."
    },
    {
      "title": "Perceived information completeness",
      "text": "Perceived information completeness pertains to how users perceive the comprehensiveness and inclusiveness of information  [5] . Previous studies indicate that source characteristics can impact the perception of information completeness  [12] . If the source provides diverse perspectives, the information is considered complete  [2] . Some scholars consider information completeness under the umbrella of information quality, with design, readability, accuracy, comprehensiveness, coverage, and scope as contributing components  [8] . Therefore, perceived information completeness can be infuenced not only by how the source generated the information but also by the quality and format of the information. Perceived gatekeeping and perceived information completeness are but two examples of a plethora of mediators that could explain the efects of sources on users' trust in the information provided by the sources. To explore them, we conducted a focus group as an exploratory step toward building a comprehensive model for understanding relative diferences in user trust across diferent online sources. The role played by these mediators can be useful for designing and deploying interfaces for online sources that promote trust in a warranted manner."
    },
    {
      "title": "FOCUS GROUP",
      "text": "We conducted fve focus groups and one interview with a total of 14 participants from September to November 2023 via Zoom. Based on the availability of participants, two to three participants were assigned to each focus group. Participants were recruited via   1 ). We developed a focus group protocol based on our research question and the information credibility literature. We asked participants about their experience with ChatGPT, their level of trust toward three sources (Google, Wikipedia, and ChatGPT), and the attributes and technological features that contribute to the perceived trustworthy of the information on each platform. After the focus groups/interview, we transcribed the data and analyzed them using the open-ended technique, a process of \"breaking down, examining, comparing, conceptualizing, and categorizing data\"  [20] . Two authors coded the data independently, following which they discussed similarities and discrepancies in their respective fndings. The focus groups were centered around fve major probes:\n\n\u2022 Let's say you are looking for information about a certain topic. What is the frst source that you turn to? Do you go online or ask your smart speaker or do something else to fnd the information? If you said you go online, where do you normally go and why? \u2022 You mentioned that you have used ChatGPT before. Please share your experience with ChatGPT. Why did you use it? What did you do with it? How do you feel about ChatGPT based on your overall user experience? \u2022 How credible would you say that ChatGPT is? For example, do you think ChatGPT gives you the correct answer? \u2022 I would like to know how much you trust three diferent sources (Google, Wikipedia, ChatGPT). Could you tell us how much trust you place in these sources? For example, would you feel comfortable using the information provided by these sources in your day-to-day decisions? If possible, please share the rank order and explain why. \u2022 What attributes or features of each platform (Google, Wikipedia, and ChatGPT) make you believe that the information is trustworthy?"
    },
    {
      "title": "RESULTS",
      "text": "In this late-breaking work, we report responses to the following two questions: (a) why do users trust each information source? and (b) among Google, Wikipedia, and ChatGPT, which source do users trust more?\n\n6.1 Trust toward diferent information sources is based on diferent reasons.\n\nA variety of reasons underlie a user's decision to trust a given source. We elaborate on the reasons provided for each of the three sources below.\n\n6.1.1 Google. Users trusted information from Google mainly because of its credible gatekeeping practice (see Table  2 ). P8 commented:\"If the information that comes from the website has a high reputation in credibility, then I will think this information is more credible, for example, maybe the government information, or maybe like a credible journal. They will provide more credible information on Google.\" They understand the gatekeeping role of Google and evaluate the information based on each source presented by Google. Participants answered that Google provides a huge amount of information from various sources, and they believed information on Google is more ofcial and representative. As P12 commented: \"If I just google search something, then there are tons of diferent links that will come up and then I can kind of debate which ones I want to take the information from, or which ones I think are most reliable.\" Furthermore, participants mentioned that adding advertisement marks to information up front increases the perceived transparency, which afects their trust in Google further. \"I like how Google adds advertisement marks in the advertisement. I usually skip it, so the mark helps me screen out the information I do not want to see. This feature makes me trust Google\" as noted by P1. While labeling advertisements represents the gatekeeping role of Google and helps users identify the most valuable information, others argue that having advertisements in the search output lowers the perceived information credibility because they do not want to see information sponsored by advertisers. An example quote came from P4, \"Sometimes it has a lot of ads in your search results. So, it might take away some credibility.\" Finally, respondents value the recency of the information from Google because it quickly updates new information. P2 commented: \"It has been around and constantly updated.\"\n\nIn sum, users trusted information from Google mainly because of its credible gatekeeping practice, the large volume of search results, and perceived transparency derived from disclosure of information provided by advertisers.\n\n6.1.2 Wikipedia. Some people trust Wikipedia because of its crowdsourcing feature, but others disagree. The collaborative editing affordance of crowdsourcing sites provides conficting perceptions about the information credibility of Wikipedia (see Table  3 ). On the one hand, the involvement of others often indicates the objectivity, reliability, and accountability of the source [4]  [13] . Also, the fact that the contributors actively correct errors and update the information may prompt users to think that biased opinions cannot dominate the site  [13] . Research also suggests that \"the wisdom of crowds\" i.e., the work of a collection of individuals will likely be superior to that of any one individual  [25] . This aspect is represented in P5's comment, \"Wikipedia would probably be the most accurate because people can actually edit the articles. So, you could always have somebody that knew something about what it was make that edit.\" However, the editing afordance of crowdsourcing sites encourages broad involvement from laypersons, making the accuracy of the resulting content uncertain  [16] [13] . P12 commented: \"Wikipedia, I don't prefer just because I mean, we've always been told it isn't good because people can edit Wikipedia.\" Indeed, the editable nature of Wikipedia is a factor positively infuencing trust among some participants, while others express distrust in Wikipedia because of its susceptibility to edits by uninformed or partisan laypersons. Due to these concerns, participants value the pedigree of information for ascertaining credibility. The level of trust individuals place in a medium relies on the number of source layers  [15] . Source layering means there are multiple layers of communication sources (e.g., computer, website, and web agent)  [24][15] . At least one participant mentioned that Wikipedia is trustworthy because he/she lands on Wikipedia through Google as elaborated by P9 \"Whenever I want to fnd the defnition of a concept or the history or background, I Google it. But the frst resource I look for is Wikipedia. So, I think I have more trust in Wikipedia, because I think the information comes from a lot of resources as well.\" This reveals the participant's perception of source layering. Other participants emphasized that the feature indicating where this information originally comes from makes them trust Wikipedia. An example quote from P9 is \"We can know where the information is from. And we can see how many users have viewed the information or given thumbs up, or we can know they're the provider behind it.\" In sum, participants valued the editability and built-in corrective mechanism of Wikipedia as also its detailed referencing of sources and the consequent presentation of source layering on the interface.\n\n6.1.3 ChatGPT. Interface features that aford conversationality appeared to contribute to trust in ChatGPT because it makes the source seems more social (see Table  4 ). For technologies to evoke social responses from users, they must be interactive, use natural language, and fulfll roles that were traditionally performed by humans  [23] . ChatGPT's unique characteristics such as chat functionality and human-like natural language seem to make it more interactive, leading users to respond to it socially. Focus group comments echoed this sentiment. It was clear that participants valued the contingency and conversationality of ChatGPT. For instance, P11 commented: \"ChatGPT already knows what I'm talking about and connects my two questions. \" P2 mentioned: \"I wanted to use it as kind of a language buddy.\" Participants also appreciated the speed and directness of ChatGPT's responses. As P12 noted, \"I really turn to ChatGPT when I need somebody who just gets straight to the point and just fgures out what the exact answer I'm looking for is.\" This sentiment was echoed by P6 who said, \"When I use GPT, it goes straight to the answer, which is something that I really like\" Also, the participants mentioned that the organized format of the information or the level of detail makes them trust ChatGPT. An example quote from P3 is \"The answer was quite well organized. The information provided by ChatGPT is sometimes too general, but it is very organized\" In sum, participant's trust in information generated by ChatGPT comes from its high speed in generating outputs, directness of responses, contingency of interaction, and human-like conversation.\n\n6.2 Google is the default information source, but it varies depending on the information they search for.\n\nA majority of participants (93%) answered that they frst turn to Google Search Engine when they look for information. Google is considered a default information source because users are familiar with using it or it is set as the default search engine on their web browsers (see Table  5 ). However, depending on the type of information they search for, they occasionally turn to ChatGPT for novel ideas and writing improvement, Wikipedia for defnitions of the terms, and YouTube for infotainment. P1 commented: \"It depends on what kind of information I'm looking for, but mostly go to Google frst.\" Interestingly, Google is considered the frst basic source they rely on regardless of the type of information. Among three sources, participants tend to have specifc use cases for Chat-GPT as commented by P10 \"I think usually I just Google it online frst. But depending on what kind of information I'm trying to fnd, like, if it's for an essay type of thing, I've defnitely turned to Chat-GPT or something like that recently, as well,\" leading us to further investigate what motivates ChatGPT usage."
    },
    {
      "title": "What then motivates",
      "text": "ChatGPT usage? Among the three sources, ChatGPT has unique features that draw users to it (see Table  6 ). First, ChatGPT provides a template for routinized communications that can beneft from a boilerplate approach, such as cover letters and recommendation letters. As P3 notes: \"For cover letters, I would use it to start a little template for me.\" Also, ChatGPT is used for ideation to create certain outputs. Example quote from P2: \"ChatGPT is for brainstorming ideas. My internship experience with social media inspired me to use it. It is not perfect, but helpful for ideation.\" Finally, increasing writing efciency is another important motivation for using ChatGPT. P8 commented: \"I don't use ChatGPT for any research use, like academic research use, but I use it for just writing English sentences, like for the casual conversation and composing emails.\""
    },
    {
      "title": "Sourcing is key to greater trust in Google and Wikipedia",
      "text": "Among all three information sources, Google was the most trusted platform, favored by 57% of our participants, followed by Wikipedia, which was liked by 29% of our participants (see Table  7 ). Four participants expressed that ChatGPT is less credible than Google because it does not disclose the original source of the information. P9 commented:\"Because for Google and Wikipedia, we can know where the information is from. But for the information provided by ChatGPT, we do not know where the resources are from.\" Two participants mentioned that Google is trustworthy because it presents external sources, as commented by P14 \"I think Google's probably the most reliable for me just because it has external sources that you can look at, to clarify what the initial search gives you.\" P7 argued that Google and Wikipedia are much more user-driven/validated and much less algorithmically driven than ChatGPT, so it is difcult to compare these three sources directly. \"So, I have no idea how to compare user-generated and user-validated to AI algorithm generated. I'd say those two are equal in my eyes.\""
    },
    {
      "title": "DISCUSSION",
      "text": "This exploratory study found that users do not trust ChatGPT as much as Google and Wikipedia. The most mentioned reason for the lack of trust is the absence of information referencing. While entirely reasonable, this also betrays users' mistaken understanding of generative AI technology. Although ChatGPT is developed to generate creative content, users seem to view it as an information provider, expecting it to curate and present information obtained from various other sources. And since references are absent, they hesitate to trust its content. Another reason that emerged for their relatively lower trust of ChatGPT is that they perceived it to be more algorithm-driven whereas they see Google and Wikipedia as being more user-driven. This fnding indicates that users' validation of information sourced to humans is critical when forming trust in online information. Both reasons call for greater emphasis on explainability in design and deployment of the next generation of generative AI tools. Users tend to trust an AI system more when it includes an understandable explanation of the algorithm, compared to when no explanation is provided  [6][11] . This pattern is also observed when users form trust in the information generated by AI. For example, providing references could work as an explainability cue, indicating not only the provenance of the information but also shedding light on the relative weight used by the algorithm for sources of diferential credibility.\n\nThe study found that users perceived ChatGPT as a communication source or social buddy because of its chat interface, interactivity, and contingency. Users are able to have more active communication with ChatGPT than the other two sources by asking multiple questions and connecting two diferent questions in the same interaction. An increase in interactivity and a sense of control changes how users assess the credibility of both the source and content on the crowdsourcing platform because of ego defensiveness and self-enhancement bias  [14]   [13] . Interactivity afordance can activate a cognitive bias termed \"control heuristic. \"  [22]  When users have the chance to initiate actions and make choices on the interface, their perception of these interactive features instills a sense of control and they tend to view themselves as sources. Consequently, this positive perception infuences their evaluation of both the source and content on the interface. Control heuristics evoked by users' active interaction can give a sense of control, leading to a better evaluation of the information.\n\nHowever, the credibility of the information generated by Chat-GPT is not evaluated solely by its communication features but also by the presentation of the information. Some participants mentioned that they liked the organized format of the ChatGPTgenerated information or suggested template. Readability and comprehensiveness of the information contribute to information quality, leading to perceived information completeness  [8] . In sum, perceived information completeness triggered by the presented information format could also infuences trust in information. Finally, many participants argued that they turn to Google frst because they are accustomed to doing so, or they use the Google search engine as the default setting. Usage of or reliance on media and perception of its credibility has a positive relationship  [9] . Previous studies have found that the convenience of using the Web increases online credibility by increasing users' reliance on it. This could be one reason why users trust Google more than ChatGPT, and why they turn to Google frst. As generative AI technology get embedded in more and more applications, they may appear as defaults, leading potentially to blind trust in a technology that does not deserve it, given that its mandate is to generate, rather than curate, content."
    },
    {
      "title": "IMPLICATIONS AND FUTURE DIRECTIONS",
      "text": "The study's fndings ofer noteworthy implications for generative AI interface designers. To instill greater trust in information generated by AI, it is important to include reference source information in the output. While this addition may slightly impede the naturalness of the conversation with ChatGPT as a communication source, it has the potential to enhance veracity (and consequently trust, if warranted) in the provided information. Considering ChatGPT's appeal as a communication source, provision of information in an interactive manner is benefcial for trust. A key design element to consider in this context is building a chat interface that can provide dialogue and imbue in users a higher sense of contingency. In addition, interface designers need to carefully think about how the interface can promote perceived information completeness, which appears to be important for enhancing user trust. Finally, we found that convenience and reliance on media itself increase trust in the information coming from it. Interface designers need to consider how the rapid integration of LLM technology to routinely used apps and sites can potentially promote unwarranted trust and thereby mislead users. Based on our focus groups and literature review, we have identifed perceived gatekeeping, crowdsourcing, source layering, information source (reference), conversationality, and perceived information completeness as potential mediators between information source and trust. These mediators will be added to our developing model of source-driven trust in online information. The resulting model will be empirically tested in order to identify and test the viability of key new afordances for generative AI technologies that are important for assessing credibility of the information provided by them."
    },
    {
      "title": "Participant"
    },
    {
      "title": "P7 P12",
      "text": "Google is a collection of resources. If I just google search something, then there are tons of diferent links that will come up, and then I can kind of combat which ones I want to take the information from, or which ones I think are most reliable.\n\nBecause like Google, you can get other sources that are more reliable. First, I will take the name of the source, like, what's your website? The information that comes from the website has a high reputation in credibility, then I will think this information is more credible, for example, maybe the government information, or maybe like a credible journal. They will provide more credible information on Google. Google has the websites they provide. Some of them are sponsored by advertisements. So I'm not 100% sure if it's commercial action or if it really wants to provide useful information resources. So, I will question this perspective. So, every time I see it's sponsored, I probably will not click the link frst. I think that's a question about Google. I like how Google adds advertisement marks in the advertisement. I usually skip it, so the mark helps me screen out the information I do not want to see. This feature makes me trust Google. Sometimes it has a lot of ads in your search results. So, it might take away some credibility. It has been around and constantly updated. And most people will use it to fnd the defnition, and they can revise it. So, I think the content provided is a result of thousands of users generated so that it can be trusted. If it's wrong, someone will revise it later. So, it can be updated very frequently. Wikipedia provides extremely good and precise information. It had details about up-to-date information.\n\nWhenever I want to fnd the defnition of a concept or the history of background, I Google it. But the frst resource I look for is Wikipedia. So, I think I have more trust in Wikipedia, because I think the information comes from a lot of resources as well.\n\nBecause for Google and Wikipedia, we can know where the information is from. And we can see how many, sometimes we can see how many users have viewed the information or thumbs up, or we can know they're the provider that behind it. So we can go to look for information about the background and test them if they can be credible. I think Wikipedia and their sources, the references, and the further reading part gives you that sensibility that yeah, this information came from something that wasn't just somebody making it up."
    },
    {
      "title": "Participant",
      "text": "P9 P6 P12 P11 P5 P7 P3 P6 P3 Participant P1 P4 P5 P10 P12 P14\n\nTable 4: Why we trust ChatGPT\n\nQuotation They can generate some paragraphs or content related to my prompts. So, and it's very fast, like in a timely fashion, they already write an essay, or gonna write the title body and the conclusion parts. So, it's amazing. When I use GPT, it goes straight to the answer, which is something that I really like, also, like you it's like talking to not like talking to someone, but I feel like I can. Like I can put things I want like let's say I want to enter about a question, but I don't want the explanation. So I just put like, just answer the question. And it will just answer the question with no explanation. So I like those features about ChatGPT. So, it's almost kind of I wanted to use it as kind of a language buddy, chat person can see and see the viability of that. If you do, like easy functions, basic math calculations, they'll work so easily, and I'll just, I'll just fully trust it. I won't even Google it. Whenever I asked for some information on material science engineering, their answer was quite well organized. The information provided by ChatGPT is sometimes too general, but it is very organized. Well, I started using it for the novelty of it. When it frst became available. I basically asked general questions like biographical questions about composers and things like that, or how do you create a fve-year plan? So, I'm surprised at how it gives a synopsis, but I'm surprised at how much depth it does also give. Even though it is still limited, it is an excellent machine for classifcation with good quality format with a huge amount of data. Table 6: Motivation to Use ChatGPT\n\nQuotation I said, for cover letters, I would use it to start a little template for me, I would like to say the company, because obviously, it would have a little bit of knowledge like, especially if it's a bigger company, about the background and maybe its values. Another big thing I use it for is if I wrote something already, I would copy and paste it into there. And I'll say like, fx the readability on this, like, make sure that it like sounds right. ChatGPT for brainstorming ideas. My internship experience with social media inspired me to use it. It is not perfect, but helpful for ideation. It helps me come up with new ideas to how to explain and answer the questions. It's very helpful for brainstorming. So I didn't use ChatGPT for any research use, like academic research use, but I use I just writing English sentences, like for the casual conversation and composing emails. I feel like it's a really good tool for me to organize the sentences in a more native speaker way. After attempting various questions, such as asking ChatGPT to compose an email to my professor for a recommendation letter and requesting a diversity statement, the answers provided by GPT were really impressive. I feel like he is smarter than me. The machine writes better than me! When I need to write an email or ask some academic questions. I will go to ChatGPT and see what answers will be provided by the ChatGPT. And every time I think I'm impressed, and the answers are like the opinion leader and the gatekeeper, you know, the flter the information from Google and provide me a more organized and more related information. So I feel like it's a very efective and helpful & useful tool. Quotation Google is a collection of resources. So, I would put that at the top. And Google, they what Google scrapes some internet content, and then have like an informational panel on this side for like summarization, and sometimes it's sourced directly from Wikipedia. Or they list like other sources right then in there. In that regard, Google will be the highest for me. I think I have more trust in Wikipedia because I think the information that is provided comes from a lot of resources as well. And most people will use it to fnd the defnition, and they can revise it. So, I think the content that's provided, for me in front of me is a result of thousands of users generating (content), so it can be trusted. If it's wrong, someone will revise it later. So it can be updated very frequently. Because for Google and Wikipedia, we can know where the information is from. And we can see how many, sometimes we can see how many users have viewed the information or thumbs up, or we can know they're the provider behind it. So we can go to look for information about the background and test them if they can be credible. But for the information provided by ChatGPT, we do not know the resources where the resources are from. If I just Google search something, then there's tons of diferent links that will come up and then I can kind of combat which ones I want to take the information from, or which ones I think are most reliable. I think Google's probably the most reliable for me Just because it has, like external sources that you can look at, to clarify what, like the initial search gives you. And then second, I would probably say, chat GPT, just because it pulls from a lot of diferent sources."
    },
    {
      "text": "I really turned to ChatGPT. When I need somebody who just gets straight to the point and just fgures out what the exact answer I'm looking for is. When I want to know a lot of information about a topic, I just ask the question and then I just go like I'm following up with what, um, as my like my frst question. So that's what I really like. ChatGPT already knows what I'm talking about and connects my two questions."
    },
    {
      "text": "Primary Source for Information Quotation It depends on what kind of information I'm looking for, but mostly go to Google frst. I mostly go to Google search, sometimes to ChatGPT. If I want to use something new, I go to ChatGPT, and it's pretty good. I also use Facebook Search for regular topics. I guess I'm kind of old school, I just Google it. And it seems like in all the browsers now you can just type in information on the address bar, and it goes to a default search engine. I think usually I just Google it online frst. But depending on what kind of information I'm trying to fnd, like, if it's for an essay type of thing, I've defnitely turned to ChatGPT or something like that recently, as well. I'll do a quick Google search or something. But also, depending on the kind of information, I might just ask, like a friend or my parents, if they might already know the information about the topic I'm looking for. I usually just Google things. If it's for a class or something I need more in-depth information about, I might use Google Scholar."
    },
    {
      "text": "Demographics of participants"
    },
    {
      "text": "Why we trust Wikipedia"
    },
    {
      "text": "Why we trust GoogleFaculty did not recommend it because everyone can edit it. It is least trustful. Wikipedia would probably be the most accurate because people can actually edit the articles. So, you could always have somebody that knew something about what it was make that edit. Wikipedia, I don't prefer just because I mean, we've always been told that like, it isn't good because people can edit Wikipedia."
    },
    {
      "text": "Why users trust Google and Wikipedia more than ChatGPT"
    }
  ],
  "references": [
    {
      "title": "Netherlands 'will pay the price' for blocking Turkish visit -Erdo\u011fan",
      "authors": [
        "Weiser Benjamin",
        "Schweber Nate"
      ],
      "year": 2023,
      "doi": "10.33965/ciaca_ciawi2023_202308l013"
    },
    {
      "title": "Communication technology an society: Audience adoption and uses",
      "authors": [
        "Lin Carolyn",
        "Atkin David"
      ],
      "year": 2002
    },
    {
      "title": "Mass media and interpersonal channels: Competitive, convergent, or complementary",
      "authors": [
        "Steven H Chafee"
      ],
      "year": 1982
    },
    {
      "title": "On measuring the quality of Wikipedia articles",
      "authors": [
        "Gabriel De",
        "La Calzada",
        "Alex Dekhtyar"
      ],
      "year": 2010
    },
    {
      "title": "Health communication on the web: The roles of web use motivation and information completeness",
      "authors": [
        "J Mohan",
        "Dutta-Bergman"
      ],
      "year": 2003
    },
    {
      "title": "Expanding explainability: Towards social transparency in ai systems",
      "authors": [
        "Q Upol Ehsan",
        "Michael Vera Liao",
        "Mark Muller",
        "Justin Riedl",
        "Weisz"
      ],
      "year": 2021
    },
    {
      "title": "Why People Trust Wikipedia Articles: Credibility Assessment Strategies Used by Readers",
      "authors": [
        "Houda Elmimouni",
        "Andrea Forte",
        "Jonathan Morgan"
      ],
      "year": 2022,
      "doi": "10.1145/3555051.3555052"
    },
    {
      "title": "Empirical studies assessing the quality of health information for consumers on the world wide web: a systematic review",
      "authors": [
        "Gunther Eysenbach",
        "John Powell",
        "Oliver Kuss",
        "Eun-Ryoung Sa"
      ],
      "year": 2002,
      "doi": "10.1001/jama.287.20.2691"
    },
    {
      "title": "Perceptions of Internet information credibility",
      "authors": [
        "J Andrew",
        "Miriam Flanagin",
        "Metzger"
      ],
      "year": 2000
    },
    {
      "title": "E-credibility: Building common ground in web environments",
      "authors": [
        "Christina Haas",
        "Stanley T Wearden"
      ],
      "year": 2003,
      "doi": "10.1023/a:1024557422109"
    },
    {
      "title": "Interpreting black-box models: a review on explainable artifcial intelligence",
      "authors": [
        "Vikas Hassija",
        "Vinay Chamola",
        "Atmesh Mahapatra",
        "Abhinandan Singal",
        "Divyansh Goel",
        "Kaizhu Huang",
        "Simone Scardapane",
        "Indro Spinelli",
        "Mahmud Mufti",
        "Amir Hussain"
      ],
      "year": 2023,
      "doi": "10.1007/s12559-023-10179-8"
    },
    {
      "title": "Efects of online health sources on credibility and behavioral intentions",
      "authors": [
        "Yifeng Hu",
        "S Shyam Sundar"
      ],
      "year": 2010,
      "doi": "10.1177/0093650209351512"
    },
    {
      "title": "Do we trust the crowd? Efects of crowdsourcing on perceived credibility of online health information",
      "authors": [
        "Yan Huang",
        "S Shyam Sundar"
      ],
      "year": 2022,
      "doi": "10.1080/10410236.2020.1824662"
    },
    {
      "title": "Accuracy and bias in self-perception: individual diferences in self-enhancement and the role of narcissism",
      "authors": [
        "P Oliver",
        "Richard John",
        "Robins"
      ],
      "year": 1994
    },
    {
      "title": "Heuristic versus systematic processing of specialist versus generalist sources in online media",
      "authors": [
        "Jeon Yoon",
        "S Shyam Koh",
        "Sundar"
      ],
      "year": 2010
    },
    {
      "title": "Trust in wikipedia: how users trust information from an unknown source",
      "authors": [
        "Teun Lucassen",
        "Jan Maarten Schraagen"
      ],
      "year": 2010,
      "doi": "10.1145/1772938.1772944"
    },
    {
      "title": "Credibility and trust of information in online environments: The use of cognitive heuristics",
      "authors": [
        "J Miriam",
        "Andrew Metzger",
        "Flanagin"
      ],
      "year": 2013
    },
    {
      "title": "In Google we trust: Users' decisions on rank, position, and relevance",
      "authors": [
        "Bing Pan",
        "Helene Hembrooke",
        "Thorsten Joachims",
        "Lori Lorigo",
        "Geri Gay",
        "Laura Granka"
      ],
      "year": 2007,
      "doi": "10.1111/j.1083-6101.2007.00351.x"
    },
    {
      "title": "Individual and routine forces in gatekeeping",
      "authors": [
        "Pamela Shoemaker",
        "Martin Eichholz",
        "Eunyi Kim",
        "Brenda Wrigley"
      ],
      "year": 2001,
      "doi": "10.1177/107769900107800202"
    },
    {
      "title": "Basics of qualitative research techniques",
      "authors": [
        "Anselm Strauss",
        "Juliet Corbin"
      ],
      "year": 1998
    },
    {
      "title": "Self as source: Agency and customization in interactive media",
      "authors": [
        "Sundar Shyam"
      ],
      "year": 2008,
      "doi": "10.4324/9780203926864-12"
    },
    {
      "title": "Toward a theory of interactive media efects (TIME) four models for explaining how interface features afect user psychology",
      "authors": [
        "Haiyan Shyam Sundar",
        "Franklin Jia",
        "Yan Waddell",
        "Huang"
      ],
      "year": 2015
    },
    {
      "title": "Source orientation in human-computer interaction: Programmer, networker, or independent social actor",
      "authors": [
        "Shyam Sundar",
        "Cliford Nass"
      ],
      "year": 2000,
      "doi": "10.1177/009365000027006001"
    },
    {
      "title": "Conceptualizing sources in online news",
      "authors": [
        "Shyam Sundar",
        "Cliford Nass"
      ],
      "year": 2001,
      "doi": "10.1111/j.1460-2466.2001.tb02872.x"
    },
    {
      "title": "The wisdom of crowds",
      "authors": [
        "James Surowiecki"
      ],
      "year": 2005,
      "doi": "10.3138/jspr.37.3.351"
    }
  ],
  "num_references": 25
}
