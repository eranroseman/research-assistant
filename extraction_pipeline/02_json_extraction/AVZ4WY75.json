{
  "paper_id": "AVZ4WY75",
  "title": "Persuading Voters",
  "abstract": "An omniscient information designer can attain decision rule \u03c3 if and only if it is a BCE, i.e., if it satisfies obedience.",
  "year": 2016,
  "date": "2016",
  "journal": "American Economic Review",
  "publication": "American Economic Review",
  "authors": [
    {
      "forename": "Ben",
      "surname": "Brooks",
      "name": "Ben Brooks",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Laura",
      "surname": "Doval",
      "name": "Laura Doval",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Jeff",
      "surname": "Ely",
      "name": "Jeff Ely",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Francoise",
      "surname": "Forges",
      "name": "Francoise Forges",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Drew",
      "surname": "Fudenberg",
      "name": "Drew Fudenberg",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Olivier",
      "surname": "Gossner",
      "name": "Olivier Gossner",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Tibor",
      "surname": "Heumann",
      "name": "Tibor Heumann",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Atsushi",
      "surname": "Kajii",
      "name": "Atsushi Kajii",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Rohit",
      "surname": "Lamba",
      "name": "Rohit Lamba",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Laurent",
      "surname": "Mathevet",
      "name": "Laurent Mathevet",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Roger",
      "surname": "Myerson",
      "name": "Roger Myerson",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Tymofiy",
      "surname": "Mylanov",
      "name": "Tymofiy Mylanov",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Alessandro",
      "surname": "Pavan",
      "name": "Alessandro Pavan",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Eran",
      "surname": "Shmaya",
      "name": "Eran Shmaya",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Jonathan",
      "surname": "Weinstein",
      "name": "Jonathan Weinstein",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Juan",
      "surname": "Xandri",
      "name": "Juan Xandri",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Ian",
      "surname": "Ball",
      "name": "Ian Ball",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Leon",
      "surname": "Musolff",
      "name": "Leon Musolff",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    },
    {
      "forename": "Denis",
      "surname": "Shishkin",
      "name": "Denis Shishkin",
      "affiliation": "Department of Economics , Yale Univer- sity. Morris : Department of Economics , Princeton Univer- sity. \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Department of Economics \n\t\t\t\t\t\t\t\t Yale Univer- sity. Morris \n\t\t\t\t\t\t\t\t Princeton Univer- sity"
    }
  ],
  "doi": "10.1257/jel.20181489",
  "sections": [
    {
      "text": "1. Introduction P layers' payoffs in a game depend on their actions and also on the realization of a payoff-relevant state. An \"information designer\" can commit how to provide information about the states to the players. \"Information design\" studies how the information designer, through the choice of the information provided, can influence the individually optimal behavior of the players to achieve her objective. She can achieve this objective even though she has no ability to change outcomes or force the Information Design: A Unified Perspective \u2020"
    },
    {
      "title": "Dirk Bergemann and Stephen Morris *",
      "text": "Given a game with uncertain payoffs, information design analyzes the extent to which the provision of information alone can influence the behavior of the players. Information design has a literal interpretation, under which there is a real information designer who can commit to the choice of the best information structure (from her perspective) for a set of participants in a game. We emphasize a metaphorical interpretation, under which the information design problem is used by the analyst to characterize play in the game under many different information structures. We provide an introduction to the basic issues and insights of a rapidly growing literature in information design. We show how the literal and metaphorical interpretations of information design unify a large body of existing work, including that on communication in games  (Myerson 1991) , Bayesian persuasion  (Kamenica and Gentzkow 2011) , and some of our own recent work on robust predictions in games of incomplete information. ( JEL C70, D82, D83)\n\nBergemann and Morris: Information Design: A Unified Perspective players to choose particular actions that determine outcomes.  1 he past decade has seen a rapidly growing body of literature in information design. An influential paper by  Kamenica and Gentzkow (2011)  phrased the optimal design of information as a \"Bayesian persuasion\" problem between a sender and single receiver. A large body of work fits this rubric, including important contributions of  Brocas and Carrillo (2007)  and  Rayo and Segal (2010) . The economic applications of information design have been investigated in areas as far apart as grade disclosure and matching markets  (Ostrovsky and Schwarz 2010) , voter mobilization  (Alonso and C\u00e2mara 2016) , traffic routing  (Das, Kamenica, and Mirka 2017) , rating systems  (Duffie, Dworczak, and Zhu 2017) , and transparency regulation  (Asquith, Covert, and Pathak 2013)  in financial markets, price discrimination  (Bergemann, Brooks, and Morris 2015) , and stress tests in banking regulation  (Inostroza and Pavan 2017) .\n\nOne purpose of the paper is to provide an overview of information design that unifies this recent work with a number of literatures sometimes treated as distinct. If we assume that there are many players, but the information designer (or \"mediator\") has no informational advantage over the players, this problem reduces to the analysis of communication in games  (Myerson 1991 , section 6.3) and, more generally, the literature on correlated equilibrium in incomplete information games  (Forges 1993 ). If there is only one player (or \"receiver\") but the information designer (or \"sender\") has an informational advantage over the player, the problem reduces to the \"Bayesian persuasion\" problem of  Kamenica and Gentzkow (2011) . Information design concerns the general case where there are both many players and the information designer has an informational advantage over the players. This case has been the focus of some our own work  (Bergemann and Morris 2013b, 2016a) , where we show that the set of outcomes that can arise in this setting corresponds to a version of incomplete information equilibrium (Bayes-correlated equilibrium, or BCE) that allows outcomes to be conditioned on states that the players do not know.\n\nA second purpose of the paper is to highlight a distinction between literal information design and metaphorical information design. The information design problem has a literal interpretation (given above): there really is an information designer (or mediator, or sender) who can commit to provide extra information to players to serve her own interests. While the commitment assumption may be problematic in many settings, it provides a useful benchmark. But the information design formulation might also be a metaphor that the analyst uses as a tool. For example, we might be interested in finding an upper bound (across information structures) on the aggregate variance of output in a given economy with idiosyncratic and common shocks to agents' productivity  (Bergemann, Heumann, and Morris 2015) . We can understand this as an information design problem, where the information designer is interested in choosing an information structure to maximize aggregate variance in output. But in this case, we do not have in mind that there is an actual information designer maximizing aggregate variance. We will discuss this application, and other applications where information design is metaphorical, below.\n\nThis survey reviews the pure information design problem where a designer can commit to a certain information structure for the players but has no control over outcomes. This problem is a special case of the more general mechanism design problem where a mechanism designer can control outcomes but may also be able to manipulate information in the course of doing so. 2 We study the case where all information structures are available to the designer. It is thus possible to appeal to the revelation principle from the general mechanism design problem, and without loss of generality restrict attention to information structures where the signals that the information designer sends to a player can be identified with action recommendations. This revelation principle/mechanism design approach to information design thus contrasts with work where there is no commitment to the information structure or attention is restricted to a parameterized class of information structures.\n\nWe use a family of two-player, two-action, and two-state examples to survey the literature, and to provide some graphical illustrations. We start with the leading example of Bayesian persuasion (with a single player/ receiver with no prior information) from the work of  Kamenica and Gentzkow (2011) . We can use extensions of this example-with many players and prior information-to illustrate many of the key ideas in the survey. Three key substantive general insights are illustrated in these examples.\n\nFirst, it is often optimal for the information designer to selectively obfuscate information. This insight is familiar from the case of one player without prior information.\n\nSecond, the information designer has less ability to manipulate outcomes in his favor if players have more prior information: if the players are endowed with their own information, the designer has less influence over the information structure that they end up with. This insight can already be illustrated in the 2   Myerson (1982 Myerson ( , 1991) )  describes the problem of \"communication in games\" where the designer cannot control outcomes but can elicit information from players and pass it to other players. Thus, what we are defining as the \"information design\" problem can be viewed as Myerson's \"communication in games\" problem with the important new feature that the designer may have access to information that is not available to the players. one-player case. But we will also describe a general partial order on information structures-generalizing the Blackwell order for the one-player case-which characterizes the right definition of \"more information\" in this context  (Bergemann and Morris 2016a) .\n\nThird, we can ask whether the information designer prefers to give the information to players in a public or in a private message. Of course, this last question only arises once we have multiple players. Public information is optimal if the information designer wants perfect correlation between players' actions; otherwise private information will be optimal. While the information designer may have intrinsic preferences over whether players' actions are correlated (or not), the designer may care about correlation for purely instrumental reasons: if there are strategic complementarities between the players' actions, she may want to correlate players' actions to relax the obedience constraints on her ability to attain specific outcomes. The converse holds for strategic substitutability. We will illustrate the case when there are only instrumental preferences over correlation.\n\nThe examples also illustrate a methodological point. The information design problem can be solved in two steps. First, we can identify the set of outcomes that could be induced by the information designer. Second, we can identify which of these outcomes would be preferred by the information designer. This, too, parallels the mechanism design literature: we can first identify which outcomes are implementable and then identify the one most preferred by the designer. As noted above, in the information design problem, the set of implementable outcomes corresponds to the set of Bayes-correlated equilibria. This approach reduces the problem to a linear program.\n\nThe information designer is assumed to be able to commit to an information structure that maps payoff-relevant states of the world and prior information of the agents (types) into possibly stochastic signals to the players. 3 As the mapping essentially recommends actions to the players, we refer to it as a decision rule. We initially focus on what we sometimes call the omniscient case: here, the information designer faces no constraints on her ability to condition the signals on the payoff-relevant states of the world and all the players' prior information (i.e., their types). But we also consider information design constrained by private information, where the prior information of the players is not accessible to the information designer, even though she can condition on the payoff-relevant states. There are two cases to consider here: an information designer may be able to condition on the reported realizations of the players' signals even if she does not observe them (information design with elicitation) or she may be unable to do so (information design without elicitation). If the information designer cannot condition on the payoff state at all, and has to rely entirely on the private information of the players, then these three scenarios (omniscient, private information with elicitation, and private information without elicitation) correspond to versions of incomplete information correlated equilibrium: in the terminology of  Forges (1993) , the Bayesian solution, communication equilibrium, and strategic form correlated equilibrium, respectively.\n\nOnce the information designer has picked the information structure, the players decide how to play the resulting game of incomplete 3 Whether or not the information designer will observe the payoff relevant state is irrelevant-what is important is whether she can condition the signals she sends on the realization of the state and the players' prior signals. For example, a prosecutor might never know whether the defendant is guilty or innocent, but can nevertheless set up an investigation process that would provide different evidence depending on the actual guilt or innocence of the subject and the information of the judge. We thank an anonymous referee who stressed the distinction between conditioning on a state, and actually knowing the realization of the state.\n\ninformation. There may be multiple Bayes-Nash equilibria of the resulting game. In our treatment of the information design problem, we have been implicitly assuming that the designer can pick which equilibrium is played. Under this maintained assumption, we can appeal to the revelation principle and focus attention on information structures where the signal space is set equal to the action space, and the signals have the interpretation that they are action recommendations. In the single-player case, this maintained equilibrium selection assumption is without loss of generality. But just as the revelation principle breaks down in mechanism design if the designer does not get to pick the best equilibrium (as in  Maskin 1999) , it similarly breaks down for information design.  4 We follow  Mathevet, Perego, and Taneva (2017)  in formally describing a notion of maxmin information design, where an information designer gets to pick an information structure but the selected equilibrium is the worst one for the designer. We note how some existing work can be seen as an application of maxmin information design, in particular, an extensive literature on \"robustness to incomplete information\"  (Kajii and Morris 1997) .\n\nOther assumptions underlying the revelation principle-and maintained throughout this paper-are that (i) all information structures are feasible, (ii) there is zero (marginal) cost of using information, (iii) there is a single information designer, and (iv) the setting is static. Of course, there are many (static) settings where the impact of different information structures has been studied, without allowing all information structures. Two classic examples would be information sharing in oligopoly (a literature beginning with  Novshek and Sonnenschein 1982)  and the revenue comparison across different auction formats in auction theory  (Milgrom and Weber 1982) . In the former, there is a restriction to normally distributed signals, and in the latter there is the restriction to affiliated signals.\n\nOptimal information design in dynamic settings has been studied recently in  Ely, Frankel, and Kamenica (2015) ;  Passadore and Xandri (2014) ;  Doval and Ely (2016) ;  Ely (2017) ;  Ely and Szydlowski (2017) ;  Ball (2018) ; and  Makris and Renou (2018) . A new aspect to information design that appears in these dynamic settings is that information can be used as an incentive device to reward behavior over time. Horner and Skrzypacz (2016)  survey work on information design in dynamic settings. Gentzkow and Kamenica (2014)  consider the case of costly information and  Gentzkow and Kamenica (2017)  allow for multiple information designers.\n\nThis paper provides a conceptual synthesized guide to the literature; we discuss applications when they are relevant for this purpose, but make no attempt to provide a comprehensive survey of the many applications of information design. A recent survey by Kamenica (forthcoming) reviews the literature of Bayesian persuasion and discusses some leading economic applications.\n\nWe describe the basic information design problem in section 2. We illustrate the main notions and ideas with an investment example in section 3. We discuss key ideas from information design in the investment example in section 4. Here, we discuss private versus public signals, intrinsic versus instrumental preferences over correlation, the two-step procedure for solving information design problems, ordering information, and the use of concavification in information design (instead of pure linear programming methods). Section 5 describes, in more detail, two applications of information design with a microeconomic and macroeconomic perspective, respectively: limits of price discrimination, and the link between information and volatility. These two applications emphasize the relevance of the metaphorical interpretation of information design. In section 6, we describe what happens when players' prior information is not known by the information designer; this discussion allows us to locate the information design problem within mechanism design and within a larger literature on incomplete information correlated equilibrium reviewed by  Forges (1993) . In section 7, we discuss the role of equilibrium selection.\n\nGiven the synthetic treatment of the literature, there is much terminology that has been introduced and used in different contexts (including by us in prior work), and which is at times inconsistent or redundant. To give one example, what we are calling an \"information designer\" has in previous work been called a sender, mediator, principal, or mechanism designer. We are attempting throughout to use a unified and consistent language, but compromising at times between the use of a consistent terminology and precedents set by earlier work."
    },
    {
      "title": "The Information Design Problem",
      "text": "We begin by describing the general setting and notation that we maintain throughout the paper. We will fix a finite set of players and a finite set of payoff states of the world. There are I players, 1, 2, \u2026, I , and we write i for a typical player. We write \u0398 for the set of payoff states of the world and \u03b8 for a typical element of set \u0398 .\n\nA \"basic game\" G consists of (1) for each player i , a finite set of actions A i , and an ( ex post) utility function\n\nwhere we write A = A 1 \u00d7 \u22ef \u00d7 A I , and a = ( a 1 , \u2026, a I ) for a typical element of A ; and (2) a full support prior \u03c8 \u2208 \u0394 ( \u0398 ) that is shared by all players and the information designer. Thus G = ( ( A i , u i ) i=1 I , \u0398, \u03c8 ) . We define the ex post objective of the information designer by:\n\nAn \"information structure\" S consists of (i) for each player i , a finite set of types t i \u2208 T i ; and (ii) a type distribution \u03c0 : \u0398 \u2192 \u0394 ( T ) , where we write\n\nTogether, the \"payoff environment\" or \"basic game\" G and the \"belief environment\" or \"information structure\" S define a standard \"incomplete information game\" (G, S) .\n\nWhile we use different notation, this division of an incomplete information game into the \"basic game\" and the \"information structure\" is a common one in the literature, see, for example,  Gossner (2000) .\n\nWe are interested in the problem of an information designer who has the ability to commit to provide the players with additional information, in order to induce them to make particular action choices. In this section, we will consider the leading case where the designer can condition on the state and on all the players' types-their prior information-if they have any. We will sometimes refer to this setting as omniscient information design. In section 6, we will consider the case where prior information of the players is truly private to them, and hence the information designer cannot condition on their prior information unless she is able to induce them to reveal it.  5 f viewed as an extensive form game between the information designer and the players, the timing is as follows:\n\n(i) the information designer picks and commits to a rule for providing the players with extra messages;\n\n(ii) the true state \u03b8 is realized;\n\n(iii) each agent's type t i is privately realized;\n\n(iv) the players receive extra messages according to the information designer's rule;\n\n(v) the players pick their actions based on their prior information and the messages provided by the information designer;\n\n(vi) payoffs are realized.\n\nWe emphasize that the information designer commits to a decision rule before the realization of the state and type profile. This structure in the timing sets the information design problem apart from informed principal, cheap talk, or signaling environments where the informed party chooses a message only after the state has been revealed.\n\nIn general, the information designer could follow any rule for generating messages. However, a \"revelation principle\" argument implies that it is without loss of generality to assume that the information designer sends only \"action recommendations\" that are obeyed. The argument is that any message will give rise to an action in equilibrium and we might as well label messages by the actions to which they give rise. We discuss the revelation principle in more detail below. Given this restriction, the information designer is choosing among decision rules\n\n(1)\n\nThe information designer can condition the recommended action profile on the true state \u03b8 \u2208 \u0398 and the type vector t \u2208 T . We stress that the designer does not need to know the true realization of the state or the type profile-it is sufficient that the decision rule can condition on these. For example, in a medical test, the information designer, the doctor, may not know the true condition of the patient, but can choose a diagnostic test that reveals the condition of the patient with the desired precision and accuracy.\n\nThe decision rule encodes the information that the players receive about the realized state of the world, the types and actions of the other players. The conditional dependence of the recommended action a on state of the world \u03b8 and type profile t represents the information conveyed to the players.\n\nThe key restriction on the decision rule is a notion of obedience that we now define. Obedience is the requirement that the information privately communicated to player i in the form of an action recommendation a i according to \u03c3 is such that each player i would want to follow his recommended action a i rather than choose any other available action a i \u2032 .\n\nDEFINITION 1 (Obedience): Decision rule \u03c3 : T \u00d7 \u0398 \u2192 \u0394(A) is obedient for ( G, S) if, for each i , t i \u2208 T i and a i \u2208 A i , we have\n\nfor all a i \u2032 \u2208 A i .\n\nFor notational compactness, we only list the elements, but not the sets, over which we sum under the summation operator, thus, e.g., \u2211 a rather than \u2211 a\u2208A . The obedience inequality requires that each player i , after receiving his recommendation a i , finds that no other action a i \u2032 could yield him a strictly higher utility. We emphasize that each player, when computing his expected utility, is indeed using the information contained in the action recommendation a i , and thus the above inequality is written from an interim perspective (conditioning on t i and a i ). We can state the above inequality explicitly in terms of the interim beliefs that agent i holds, given his type t i and his action recommendation a i , thus using Bayes's rule:\n\nWe observe that the belief of agent i updates independently of whether he is following the recommendation a i or deviating from it to a i \u2032 . Moreover, the denominator in Bayes's rule sums up over all possible profiles a -i \u2032\u2032 \u2208 A -i , t -i \u2032\u2032 \u2208 T -i , \u03b8 \u2033 \u2208 \u0398 , and hence is constant across all possible realizations of a -i \u2208 A -i , t -i \u2208 T -i , \u03b8 \u2208 \u0398 . Hence, we can multiply through to obtain the earlier inequality (2), provided that the denominator is strictly positive.\n\nBergemann and Morris (2016a) define a Bayes-correlated equilibrium (BCE) to be any decision rule \u03c3 satisfying obedience. An important aspect of this solution concept is that the decision rule \u03c3 enters the obedience constraints, as stated above in (2), in a linear manner as a probability. Thus, an obedient decision rule can be computed as the solution to a linear program. communication rule that gives rise to this decision rule in Bayes-Nash equilibrium. 6  We refer to the resulting (ex ante) joint distribution of payoff state \u03b8 and action profile a as the outcome of the information design, thus integrating out the prior information t :\n\nIn this (and later) propositions, we omit formal statements and proofs that correspond to revelation principle arguments. Bergemann and Morris (2016a)  give a formal statement 7 and proof of this proposition as theorem 1. The argument is a straightforward adaptation of standard characterizations of complete and incomplete information correlated equilibrium.\n\nIf there is no payoff uncertainty-the set \u0398 is a singleton-then the notion of BCE exactly coincides with the complete information correlated equilibrium as introduced in the seminal contributions of  Aumann (1974 Aumann ( , 1987)) . In the absence of payoff uncertainty, we can simply suppress the dependence of the payoff function on the state of the world \u03b8 . Thus, the decision rule \u03c3 does not vary with \u03b8, nor is there any private information t about the state of the world \u03b8 . A decision rule \u03c3 is then simply a joint distribution over actions, or \u03c3 \u2208 \u0394(A) . Now, a distribution \u03c3 \u2208 \u0394(A) is defined to be a correlated equilibrium if for each i and a i \u2208 A i , we have:\n\n6 We do not discuss information design under solution concepts other than Bayes-Nash equilibrium in this paper. Mathevet, Perego, and Taneva (2017)  study information design under bounded level rationalizability and Inostroza and Pavan (2017) under full rationalizability.\n\n7 A formal statement also appears in section 7.\n\nThe obedience condition (2) thus collapses to the best response property (3) in the absence of payoff uncertainty. Aumann (1987)  argued that correlated equilibrium captured the implications of common knowledge of rationality in a complete information game (under the common prior assumption). An alternative interpretation is that the set of correlated equilibria is the set of outcomes attainable by an information designer in the absence of payoff uncertainty. We discuss these interpretational issues and the literature on incomplete information correlated equilibrium more broadly in section 6.4.\n\nThe proof of proposition 1 in Bergemann and Morris (2016a), like the proof of  Aumann (1987) , is a \"revelation principle\" argument, establishing that it is without loss of generality to focus on a set of signals that equals the set of actions to be taken by the agents-so that there is \"direct communication\"-and to recommend actions in such way that they will be obeyed-so that \"incentive compatibility\" gives rise to \"obedience\" conditions. In the case of complete information, Myerson (1991, section 6.2) describes this as the \"revelation principle for strategic form games.\" Note that while the expression \"revelation principle\" is sometimes limited to the case where agents are sending messages rather than receiving them (e.g.,  Fudenberg and Tirole 1991 and Mas-Collel, Whinston, and Green 1995) , we follow Myerson in using the broader meaning throughout the paper. In the basic information design described in this section, the only incentive constraints are obedience conditions, but we discuss the extension to the case where the information designer must elicit players' private information in section 6, where truth-telling incentive constraints also arise. We postpone a discussion of how to place information design in the broader context of the mechanism design literature until then.\n\nProposition 1 characterizes the set of outcomes that an information designer could attain, i.e., a feasible set. To complete the description of the basic information design problem, we need an objective. Given the information designer's ex post utility v (a, \u03b8) , her ex ante utility from the decision rule \u03c3 for a given game of incomplete information ( G, S ) is:\n\nThe (omniscient) information design problem is then to pick a BCE \u03c3 to maximize V ( \u03c3 ) . When there is a single player with no prior information, the information design problem reduces to the benchmark Bayesian persuasion problem described by  Kamenica and Gentzkow (2011) . In this case, the single player is called the \"receiver\" and the information designer is called the \"sender.\""
    },
    {
      "title": "An Investment Example",
      "text": "We now apply this framework to an investment game and discuss the main themes of information design through the lens of this example.\n\nWe first consider the following benchmark setting. There is a bad state ( B ) and a good state ( G ) . The two states are equally likely:\n\nThere is one player (the \"firm\"). The firm can decide to invest or not invest. The payoff from not investing is normalized to 0 . The payoff to investing is -1 in the bad state and x in the good state, with 0 < x < 1 . These payoffs, u ( a, \u03b8 ) , are summarized in the fol- lowing matrix:\n\n(5)\n\nu(a, \u03b8) bad state B good state G invest -1 x\n\n. not invest 0 0"
    },
    {
      "title": "Single Player without Prior Information",
      "text": "We begin the analysis when the firm has no prior information about the state (beyond the uniform prior). Together with the above assumptions about the payoff matrix, the firm would therefore choose to not invest if it had no additional information.\n\nWe will assume that an information designer (the \"government\") is interested in maximizing the probability of investment independent of the state, or\n\nThis example is (modulo some changes in labelling) the leading example in  Kamenica and Gentzkow (2011) . We will describe this example first, but then use variations to illustrate more general points. The decision rule is now simply:\n\nwhere we can omit the type space T due to the absence of prior information. In this binary decision environment, the decision rule \u03c3 ( \u03b8 ) specifies the probability of invest- ment, denoted by p \u03b8 , conditional on the true state \u03b8 \u2208 { B, G } . Thus, a decision rule is a pair ( p B , p G ) of investment probabilities. We can think of a decision rule as a (stochastic) action recommendation from the government. If the recommendations are obeyed, the outcome-the ex ante distribution over states and actions-is given by:\n\nIf the firm receives a recommendation to invest, it will update its beliefs about the state by Bayes's rule. The firm's interim expected utility from following the recommendation represents the left-hand side of the inequality below. If the firm were to disobey the recommendation and chose not to invest, then its payoff would be zero. This gives rise to the following obedience constraint:\n\nAs we discussed following definition 1, we can simplify the inequality by multiplying through with the conditioning probability 1 _ 2 p B + 1 _ 2 p G , and thus write the obedience condition equivalently in terms of the interim probabilities:\n\nThere is an analogous obedience constraint corresponding to the recommendation not to invest, namely:\n\nBecause the firm would not invest absent information from the designer-by our maintained assumption that x < 1 -the binding obedience constraint will be the one corresponding to investment, i.e., inequality (7). We see that the highest probability of investment corresponds to the decision rule with p G = 1 and p B = x .\n\nWe illustrate the set of BCE decision rules for the case where x = 55/100 in figure  1 . Any decision rule ( p B , p G ) in the blue shaded area can arise as some BCE. We observe that the feasible set of BCE does not depend on the government's preference v ( a, \u03b8 ) . Now every BCE decision rule corresponds to optimal behavior under some information structure S . By the revelation principle for the BCE, it suffices to give the firm a binary information structure S to implement any BCE decision rule in the binary action environment. For the outcome that maximizes the probability of investment, it suffices to generate a no-investment recommendation with probability 1x if the state is bad, and otherwise give the firm an investment recommendation. The resulting outcome-the ex ante distribution over states and actionsis given by: (  8 )\n\nThus, a government trying to encourage investment will obfuscate the states of the world in order to maximize investment. By pooling realizations of the bad and good states in the recommendation to invest, the firm is made exactly indifferent between investing or not when recommended to invest. The bad state is completely isolated in the recommendation not to invest. Finally, we observe that under complete information the firm would always invest in the good state and never invest in the bad state. We thus have described three different information structures-zero information, partial information, and complete information-that support the three vertices of the above investment triangle. Thus, the set of all investment probabilities that satisfy the obedience constraints can be described by a set of linear inequalities that jointly form a polyhedron of implementable outcomes."
    },
    {
      "title": "Single Player with Prior Information",
      "text": "We remain with the investment example where there is still only one firm, but now the firm has some prior information about the true state that it receives independently of the government. 8 In particular, the firm has a type (or receives a signal) that is \"correct\" with probability q > 1 / 2 . Formally, the firm observes its type t \u2208 { b, g } with probability q conditional on the true state being B or G, respectively:\n\ngood signal g 1q q\n\n8 Some detailed calculations for this example appear in the appendix.\n\nHere, signals refer to the prior information that firms are endowed with. Conditional on the type of the firm, the analysis of the obedience constraints reduces immediately to the analysis of the previous section, but where the firm has an updated belief, q or 1q , depending on the type. We nonetheless analyze this problem because we want to trace the ex ante implications of a player's prior information for information design. A decision rule \u03c3 now specifies the probability of investment p \u03b8t conditional on the true state \u03b8 \u2208 { B, G } and the type t \u2208 { b, g } . Thus a decision rule is now a quadruple: (9) p = ( p Bb , p Bg , p Gb , p Gg ) . 1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1 0 p B p We can solve the problem-conditional on state and type-as before. For example, the obedience constraint for the recommendation to invest after receiving a good type g now becomes:\n\n(10) ( 1 -q ) p Bg ( -1 ) + q p Gg x \u2265 0.\n\nHowever, we are interested in what we can say about the joint distribution of states and actions ex ante, integrating out the types, say\n\nOne can show that there is a lower bound on investment in the good state given by:\n\nwhich approaches 1 as q approaches 1 . As before, the bound for p G depends on p B and the lowest bound is obtained by taking p B = 0 in that expression.\n\nThe set of BCE is illustrated in figure 2. More prior information shrinks the set of BCE, since the obedience constraints become tighter. Once q reaches 1 , the firm knows the state and the information designer has no ability to influence the outcome. The firm is simply pursuing the complete information optimal decision, which is to invest in the good state, p G = 1 , and not to invest in the bad state, p B = 0 .\n\nThe set of BCE across different q has two notable features. First, we notice that the set of BCE happens to be constant across some information structures near precision q = 0.5 , for example at q = 0.5 and q = 0.6 . With low precision in the signals, such as q = 0.6 , the firm would pursue the same action for either type realization, absent any additional recommendation by the government. Thus, the weak prior information by the agent does not constrain the government in its recommendation policy. In consequence, prior information of the player only affects the set of BCE if the prior information by itself already generates a differential response by the player. Second, the slope of the boundary is constant across different levels of precision q . This occurs because the rate at which the optimal decision of the player can be reversed by additional information of the designer (and hence indifference is attained) is constant across q by Bayes's law."
    },
    {
      "title": "Many Players without Prior Information",
      "text": "We can now generalize the analysis to two firms and return to the assumption that the firms have no prior information. foot_4 We assume, for now, that the government wants to maximize the sum over each individual firm's probability of investment. If there is no strategic interaction between firms, the previous analysis can be carried out firm by firm and will thus be unchanged.\n\nBut we now perturb the problem to make it strategic, assuming that each firm gets an extra payoff \u03b5 if both invest, where \u03b5 may be positive or negative. If \u03b5 is positive, we have a game of strategic complementarities; if \u03b5 < 0 , we have a game of strategic substitutes. We can write firm 1 's state dependent payoffs for the game as follows (and symmetrically for firm 2 ):\n\nWe can focus on symmetric decision rules, given the symmetry of the basic game, for any symmetric objective of the information designer. To see why, note that if we found an asymmetric maximizing decision rule, the decision rule changing the names of the firms would also be optimal, and so would the (symmetric) average of the two decision rules. Therefore, we will continue to write p \u03b8 for the probability that each firm will invest in state \u03b8 \u2208 { G, B } ; but we will now write r \u03b8 for the probability that both invest. Thus a decision rule is a vector To ensure that all probabilities are nonnegative, we require that for all\n\nThe firm has an incentive to invest when told to do so if\n\nand an incentive to not invest when told to not do so if  14 ) is always the binding constraint and-for | \u03b5 | sufficiently close to 0 -we can rewrite it by the same reasoning as in section 3.1 as\n\nNow maximizing the sum of the probabilities of each firm investing corresponds to maximizing p B , (or p B + p G , but we will have p G = 1 always) subject to (15). For fixed\n\nx < 1 and | \u03b5 | \u2248 0 , it is clearly optimal to have firms always invest when the state is good (so p G = 1 and r G = 1 ) and it is not possible to get both firms to always invest when the signal is bad. If \u03b5 > 0 , (15) implies that it is optimal to choose r B as large as possible given p B . Thus we will set r B = p B . Substituting these variables into expression (15), we have\n\nand so it is optimal to set\n\nand we can summarize the optimal decision rule in the following table:\n\nThis decision rule entails a public signal: there is common certainty among the firms that they always observe the same signal.\n\nIf \u03b5 < 0 , it remains optimal to have both firms always invest when the state is good ( p G = r G = 1 ). But now we want to minimize r B given ( p B , p G , r G ) . To reduce cases, let us assume that x > 1/2 and restrict attention to | \u03b5 | \u2264 x -1/2 . In this case, it will be optimal to set r B = 0 . Substituting these expressions into (15), we have\n\nThus we will now have p B = x + \u03b5, and we can summarize the optimal decision rule in the following table:\n\nUnder this decision rule, firms told to invest know neither whether the state is good or bad, nor if the other firm is investing or not. Thus, signals are private to each firm. Given that, in the bad state, each firm will invest with (roughly) probability x and will not with (roughly) probability 1x , the above information structure minimizes the unconditional correlation of the signals across firms (or equivalently minimizes the negative correlation conditional on the bad state.) Strategic complementarities increase the private return from investing if the other player invests as well. Below, we display the set of investment probabilities that can be attained by the government while varying the size of the strategic effect \u03b5 . As the strategic effect \u03b5 increases, the boundaries of the investment probabilities attainable by the government shift outwards as illustrated in figure  3 . As the strategic complementarity increases (or strategic substitutability decreases), the government can support a larger probability of investment in both states. The intermediate case of \u03b5 = 0 reduces to the case of a single player, and hence reduces to the area depicted earlier in figure 1."
    },
    {
      "title": "Many Players with Prior Information",
      "text": "We analyzed the case of two players and prior information in  Bergemann and Morris (2016a) . Here, we illustrate this case without formally describing it. As in the single-player case, an increase in players' prior information limits the ability of the designer to influence the players' choices. Consequently, the impact of prior information on the set of attainable investment probabilities with many players is similar to the one-player case.\n\nIn figure  4  we illustrate the set of attainable investment probabilities under increasing prior information with strategic complementarities. The strategic complementarities give rise to a kink in the set of attainable probabilities ( p B , p G ) , unlike in the single-player case depicted earlier in figure 2."
    },
    {
      "title": "Issues in Information Design Illustrated by the Examples",
      "text": "Let us draw out the significance of these examples. One basic point that has been extensively highlighted (e.g., by Kamenica and Gentzkow 2011 and the following Bayesian persuasion literature) is that when there is a conflict between the designer and the player(s), it will, in general, be optimal for the designer to obfuscate, that is, hide information from the player(s) in order to induce him to make choices that are in the designer's interests. And conditional on obfuscation being optimal, it may not be optimal to hide all information, but will, in general, be optimal to partially reveal information. This issue already arises in the case of one player with no prior information.\n\nIn this section, we draw out a number of additional insights about information design that emerged from the examples. First, we observe that information will be supplied to players publicly or privately depending on whether the designer would like to induce positive or negative correlation in players' actions; we also discuss designers' possible intrinsic or instrumental reasons for wanting positive or negative correlation. Second, we note that in the case of one player with prior information, more prior information constrains the ability of the designer to control outcomes; we discuss the manyplayer generalization of this observation. Third, we discuss the elegant \"concavification\" approach as an alternative to the linear programming representation used above to characterize and provide insights into the information designer's problem. We also discuss an extension of the concavification approach to the many-player case but note limitations of the concavification approach, both in the one-player case and (even more) in the many-player case."
    },
    {
      "title": "Public versus Private Signals and Instrumental versus Intrinsic Motivation for Preferences over Correlation",
      "text": "An information designer will often have preferences over whether players' actions are correlated with each other or not. The case of many players without prior information illustrates the point that if the designer wants players' actions to be correlated, it will be optimal to give them public signals, and if he wants players' actions to be uncorrelated he will give them private signals. However, there are different reasons why the designer might want to induce positive or negative correlation in actions.\n\nIn our analysis of the case of two players without prior information, we made the assumption that the information designer wanted to maximize the sum of the probabilities that each player invests. Thus, we assumed that the information designer did not care whether players' actions were correlated or not. Put differently, we assumed that the information designer had no intrinsic preferences over correlation. Yet, despite this assumption, we observed that the information designer wants-for instrumental reasons-to induce correlated behavior when players' actions are strategic complements, and to induce negative correlation when there were strategic substitutes among the players. This in turn gen-\n\n1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1 0 erated the insight that the designer would like to generate public signals when there are strategic complementarities and private signals when there are strategic substitutes.\n\nThe reason for this instrumental objective is that under strategic complements, the designer can slacken obedience constraints by correlating play, with the opposite mechanism holding under strategic substitutes. We now describe three environments where there will be only instrumental concerns about correlation. First,  Mathevet, Perego, and Taneva (2017)  consider an environment with one-sided strategic complementarities. The designer cares about the action of a first player who cares about the action of a second player who has no strategic concerns, i.e., does not care about the first player's action. In this case, the information designer does not have intrinsic preferences over correlation (because she only cares about the first player's action), but has an instrumental incentive to correlate actions because she can use information design to influence the action of the second player and correlate behavior in order to slacken the first player's obedience constraint. In the formulation of  Mathevet, Perego, and Taneva (2017) , the information designer is a manager, the first player is a worker, and the second player is a supervisor.\n\n1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1 0 p B\n\np G q = 0.5 q = 0.6 q = 0.7 q = 0.8 q = 0.9 Second, Bergemann and Morris (2016a) consider an environment with two-sided strategic complementarities but where a nonstrategic payoff externality removes intrinsic preferences over correlation. To illustrate this, suppose that we take our many player with no prior information example from section 3.3, but now suppose that-in addition to the existing payoffs-each firm would like the other firm to invest, and thus there are spillovers. In the following payoff table, we are assuming that each firm gets an extra payoff of z > 0 if the other firm invests:\n\nObserve that this change in payoffs has no impact on the firms' best responses: neither firm can influence whether the other firm invests. But now suppose that the government is interested in maximizing the sum of the firms' payoffs. Consider the case that z is very large. As z becomes larger and larger, the government's objective will approach maximizing the sum of the probabilities that each firm invests. In this sense, the government's instrumental preference for correlation is micro-founded in the benevolent government's desire to make each firm invest in the interests of the other firm. This example illustrates a distinctive point about strategic information design. Recall that in the one-player case where the designer and the player have common interests, it is always optimal for the designer to fully reveal all information in order to allow the player to take an action that is optimal given their shared preferences. In the many-player case, however, the players themselves may not act in their joint interest for the usual ( noncooperative strategic) reasons. In this case-as in the above example-a benevolent information designer might want to obfuscate information. For a last case with only instrumental concerns over correlation,  Bergemann and Morris (2013b)  considered quantity (Cournot) competition in a market, where the information designer wants to maximize the sum of the firms' payoffs, i.e., the industry profits. foot_5 A continuum of firms choose output where there is uncertainty about the intercept of the demand curve, i.e., the level of demand. In this case, the information designer would like the firms' total output to be correlated with the level of demand, but total profits do not depend on the correlation of firms' output conditional on the level of aggregate output. However, firms would like their actions to be negatively correlated (because the game is one of strategic substitutes); but they would also like output to be correlated with the state. The information designer can induce players to make total output choices that are closer to the optimal level, but allow them to negatively correlate their output. In the optimal outcome (for some parameters), firms observe conditionally independent private signals about the state of demand, trading off these two objectives.  11 aving considered the case where the information designer cares about correlation for instrumental but not intrinsic reasons, we can also consider the opposite case where the information designer cares about correlation for intrinsic but not instrumental reasons. We can illustrate this case with the example of section 3.3, also. Suppose that the payoffs remain the same, but now the government would like to maximize the probability that at least one firm invests, so that the government has intrinsic preferences over correlation. But in this case-under our maintained assumption that x > 1/2 -it is possible to ensure that one firm always invests. Consider the following decision rule:\n\nIf \u03b5 were equal to 0 , this decision rule would be obedient, with all constraints holding strictly: a firm told to not invest would have a strict incentive to obey, since it would know that the state was bad; a firm told to invest would have a strict incentive to obey, since its expected payoff will be 2\n\nBecause the obedience constraints hold strictly, this decision rule will continue to be obedient, for positive or negative \u03b5 , as long as | \u03b5 | is sufficiently small. Note that the government's objective of maximizing the probability that at least one firm invests necessitates private signals.\n\nIn a dynamic setting,  Ely (2017)  shows how an information designer with intrinsic preferences for negative correlation will optimally use private signals to induce it (he also shows that this is consistent with players' strategic objectives). Arieli and Babichenko (2016)  and  Meyer (2017)  provide a general analysis of optimal information design when players have binary actions and the information designer has an intrinsic motive for correlation, but there is no strategic interaction-and thus no instrumental motive for caring about correlation. With supermodular payoffs, public signals are optimal, whereas with submodular payoffs, private signals are optimal and it is optimal to minimize correlation.  12"
    },
    {
      "title": "Tightening Obedience Constraints and BCE Outcomes",
      "text": "There is never any reason for an information and/or mechanism designer to provide players with more information than they will use in making their choices. Giving more information will impose more incentive constraints on players' choices, and thus reduce the ability of an information designer to attain outcomes that are desirable for him. In dynamic mechanism design, giving players information about others' past reports will tighten truth-telling constraints. Myerson (1986)  emphasizes that a similar observation is true in dynamic problems of communication in games; in these games the extra information imposes more obedience constraints as well. Recall that in our language, communication in games corresponds to information design when the information designer has no information of her own.\n\nOur examples have illustrated this general observation: giving players more information will impose more obedience constraints and thus reduce the set of (BCE) outcomes that can occur. However, the examples illustrate a more subtle point that is the focus of Bergemann and Morris (2016a): it is not only true that sending additional signals reduces the set of outcomes that can occur; it is also possible to construct a partial order on arbitrary information structures that exactly characterizes the notion of \"more informative,\" and one that corresponds exactly to adding more obedience constraints.\n\nThis was illustrated in our one-player example with prior information. In that example, the set of implementable BCE outcomes shrunk in size as the accuracy q of the prior information increased (as illustrated in figure  2 ). As q increases, we are intuitively giving the player more information. The additional information is given to the player not in the form of more signals, but rather more precise signals.\n\nWe will now informally describe how this observation can be generalized in many directions. In the one-player case, an information structure reduces to an experiment in the sense of  Blackwell (1951 Blackwell ( , 1953)) . He defines the \"more informative\" ordering in terms of a feasibility ordering. An experiment is said to be more informative than another experiment if the set of outcomes (joint distributions over actions and states) that can be induced by decision rules mapping signals into actions is larger-in any decision problem-under the first experiment. 13  Blackwell  (1951, 1953)  offered an alternative, entirely statistical ordering on experiments, without reference to actions or payoffs: one experiment is sufficient for another if the latter can be attained by adding noise to the former.\n\nWe have described an incentive ordering on experiments: one experiment is more 13 Blackwell (1951, 1953) defines \"more informative\" in terms of \"risk vectors\" rather than joint distributions between states and action. These two feasibility conditions are equivalent. Blackwell defines as risk vector the vector of expected payoffs that can be sustained by a decision rule measurable with respect to the information structure alone. The resulting payoff vector is, however, computed conditional (on the vector) of the true state. It then follows easily that a larger set of risk vectors is sustained if and only if a larger set of joint distribution of actions and states is sustained.\n\nincentive constrained than another if the set of BCE outcomes under the former experiment is smaller (reflecting the tighter obedience constraints) in every decision problem (or one-player basic game).\n\nTaken together, there is now an elegant set of connections between Blackwell's theorem and the information design problem. One can show that there is a three-way equivalence between (i) the \"more informative\" ordering; (ii) the \"sufficiency\" ordering; and (iii) the \"incentive-constrained\" ordering. Blackwell's theorem shows an equivalence between (i) and (ii). Thus, if an experiment is \"more informative\" in the sense of Blackwell, then-in any decision problem-the set of BCE outcomes for a given experiment is smaller under the more informative experiment. There is naturally also a converse. If an experiment is not more informative than another, then one can find a decision problem and an outcome that is a BCE for the first experiment but not for the second.\n\nThis equivalence result holds in the oneplayer case for general games, i.e., decision problems with finitely many states and actions. This result is the one-player special case of the main result (for many-player information structures) from  Bergemann and Morris (2016a) .\n\nThe definition of the incentive ordering, as well as the definition of the feasibility ordering, generalizes naturally to the many-player case. Bergemann and Morris (2016a)  offer a new statistical ordering, termed individual sufficiency, for many players, and show that is equivalent to the incentive ordering in the many-player case. Individual sufficiency is defined as follows. Fix two information structures. A combined information structure is one where players observe a pair of signals, corresponding to the two information structures, with the marginal on signal profiles of each information structure corresponding to the original information structures. Thus, there are many combinations of any two information structures corresponding to different ways of correlating signals across the two information structures. One information structure is now individually sufficient for another if there is a combined information structure such that each player's signal in the former information structure is a sufficient statistic for his beliefs about the state of the world and others' signals in the latter information structure. A subtle feature of this ordering is that one information structure being individually sufficient for another neither implies nor is implied by the property that players' joint information in the former case is sufficient (in the statistical sense) for their joint information in the latter case. We should add that in the special case of a single player individual sufficiency and sufficiency naturally coincide. The ordering of individual sufficiency has a number of natural properties. Two information structures are individually sufficient for each other if and only if they correspond to the same beliefs and higher-order beliefs about states, and differ only in the redundancies of the type identified in  Mertens and Zamir (1985) . One information structure is individually sufficient for another only if we can get from the latter to the former by providing additional information and removing redundancies.\n\nIn the one-player setting, there is an alternative but equivalent ordering to the feasibility ordering. It is phrased in terms of optimality and appears more frequently in the economics, rather than statistic, literature. For example,  Laffont (1989)  defines one experiment to be \"more valuable\" than another if it leads to (weakly) higher maximal expected utility for every decision problem. In a single-player problem, a larger set of feasible joint distributions clearly implies a larger maximal expected utility. Less obvious perhaps, the converse also holds, as the ranking has to hold across all decision problems.\n\nA common observation is that in strategic situations, there is no many-player analogue to the \"more valuable\" ordering: see, for example,  Hirshleifer (1971) ; Neyman (1991);  Gossner (2000) ; and  Bassan et al. (2003) .\n\nThe above discussion provides a novel perspective. Intuitively, there are two effects of giving players more information in a strategic setting. First, it allows players to condition on more informative signals, and thus-in the absence of incentive constraints-attain more outcomes. Second, more information can reduce the set of attainable outcomes by imposing more incentive constraints on players' behavior. The value of information in strategic situations is ambiguous in general because both effects are at work. Following  Lehrer, Rosenberg, and Shmaya (2010) , we can abstract from the second (incentive) effect by focusing on common-interest games. Here, more information in the sense of individual sufficiency translates into more attainable outcomes. But looking at BCE abstracts from the first (feasibility) effect by allowing the information designer to supply any information to the players. Now, more information in the sense of individual sufficiency translates into less attainable outcomes."
    },
    {
      "title": "BCE Outcomes and Information Design without Concavification",
      "text": "We have described a \"two-step\" approach to solving information design problems. First, provide a linear algebraic characterization of implementable outcomes, meaning the set of joint distributions over actions and states that can be induced by some information structure that the information designer might choose to give the players. The set of implementable outcomes is exactly the set of BCE. Second, we select among the BCE the one that is optimal for the information designer. This second step implicitly identifies the optimal information structure. The first problem is solved by finding the set of outcomes that satisfy a set of linear (obedience) constraints. The second problem corresponds to maximizing a linear objective subject to linear constraints. Both steps of this problem are well behaved. There is a separate reason why we might pursue this two-step procedure: for many questions of interest, it is critical to first understand the set of BCE outcomes. The next two subsections describe two contexts where the structure of the BCE outcomes is the focus of the analysis.\n\nHowever, there is a different approach to information design: concavification. The \"concavification\" approach is based on a geometric analysis of the function mapping receiver posterior beliefs to sender payoffs. Concavification focuses more on the \"experiments\" or the distribution of posteriors that are induced for the receivers, rather than on the joint distribution between actions and states. In the one-person problem, we can identify the payoff that the information designer receives for any given probability distribution over states, subject to the fact that the player will make an optimal choice. But the information designer has the ability to split the player's beliefs about the state, i.e., supply the player with information that will induce any distribution over posteriors with the constraint that the prior equals the expected posterior. This implies that the set of attainable payoffs for the information designer, as a function of prior distributions of states, is the concavification of the set of payoffs of the designer in the absence of information design. This concavification argument (building on Aumann and Maschler 1995) is the focus of both  Kamenica and Gentzkow (2011)  and the large and important literature inspired by their work. The many-players case is significantly harder than the single-player case, as it is no longer the set of probability distributions over states that matters, but rather the set of (common prior) subsets of the universal type space of  Mertens and Zamir (1985)  that are relevant for strategic analysis. Mathevet, Perego, and Taneva (2017)  describe this generalization of concavification for the many-player case.\n\nConcavification and its many-player analogue are important for two reasons. First, they offer structural insights into the information design problem. Second, they provide a method for solving information design problems. As a solution method, the concavification approach and its generalization do not always help without some special structure. Our own work  (Bergemann, Brooks, and Morris 2015)  on (one player) price discrimination, discussed in the next section, relies heavily on linear programming; but while the solution must correspond to the concavification of an objective function, it is very difficult to visualize the concavification or provide a proof using it. However, linear programming methods do not always help, either: in our work on (many player) auctions  (Bergemann, Brooks, and Morris 2017a) , neither generalized concavification nor linear programming methods are used in stating or proving our results (although linear programming played an important role in supplying conjectures for the results)."
    },
    {
      "title": "Metaphorical Information Design and Applications",
      "text": "Mechanism design sometimes has a literal interpretation. For example-in some settings-a seller may be able to commit to an auction for selling an object. In other settings, the mechanism design problem is studied even though there does not exist a mechanism designer able to commit. For example, suppose that we are interested in a buyer and seller bargaining over an object. There may be no rules for how the players bargain and no one who could enforce such rules. Nonetheless,  Myerson and Satterthwaite (1983)  studied what would be the optimal mechanism for realizing gains from trade because it bounds what could happen under any bargaining protocol that ends up being used. In this sense, there is not a literal mechanism designer, but we are rather using the language of mechanism design for another purpose.\n\nSimilarly for information design, the most literal interpretation of the information design problem is that there is an actual information designer who can commit to choosing the players' information structure in order to achieve a particular objective. In many contexts, this commitment assumption may not be plausible.  14 Yet, the information design perspective can be used to address many important questions even where there is not a literal information designer. In particular, understanding the set of outcomes that an information designer can induce corresponds to identifying the set of all outcomes that could arise from some information structure.\n\nIn our own applications of information design, we have mostly been interested in metaphorical interpretations. The set of BCE is precisely the set of outcomes that can arise with additional information for a given basic game and prior information structure. If there are properties that hold for all BCE, we have identified predictions that are robust to the exact information structure. Identifying the best or worst outcome that can arise under some information structure according to some objective function as criterion is the same as solving an information design problem where the designer is maximizing or minimizing that criterion. In this section, we will review two such economic applications of information design. We will highlight the implications of this approach in the context of third-degree price discrimination  (Bergemann, Brooks, and Morris 2015)  and a linear interaction game with a focus on aggregate variance, and macroeconomic implications  (Bergemann, Heumann, and Morris 2015) . Caplin and Martin (2015)  adopt a similar, metaphorical, approach to the recovery of preference orderings and utility from choice data. They allow for the possibility that the decision maker has imperfect information while satisfying Bayes's law and iterated expectation. They ask what they can learn from the observed choice data about the underlying preference profile without making strong assumptions on the information available to the decision maker at the moment of choice. In related work,  Caplin and Dean (2015)  develop a revealed preference test giving conditions under which apparent choice \"mistakes\" can be explained in terms of optimal costly information acquisition by the player in the presence of imperfect information."
    },
    {
      "title": "The Limits of Price Discrimination",
      "text": "A classic issue in the economic analysis of monopoly is the impact of discriminatory pricing on consumer and producer surplus. A monopolist engages in third-degree price discrimination if he uses additional information about consumer characteristics to offer different prices to different segments of the aggregate market. Bergemann, Brooks, and Morris (2015)  characterize what could happen to consumer and producer surplus for all possible segmentations of the market.\n\nOne can provide some elementary bounds on consumer and producer surplus in any market segmentation. First, consumer surplus must be nonnegative as a consequence of the participation constraint: a consumer will not buy the good at a price above his valuation. Second, the producer must get at least the surplus that he could get if there was no segmentation and he had no additional information beyond the prior distribution. In this case, an optimal policy is Bergemann and Morris: Information Design: A Unified Perspective always to offer the product with probability one at a given price to all buyers. We therefore refer to it as the uniform monopoly price, and correspondingly, uniform monopoly profit. Third, the sum of consumer and producer surplus cannot exceed the total social value that is generated by the good, which is willingness-to-pay minus unit cost of production. The shaded right-angled triangle in figure  5  illustrates these three bounds.\n\nThe main result in Bergemann, Brooks, and  Morris (2015)  is that every welfare outcome satisfying these constraints is attainable by some market segmentation. This is the entire shaded triangle in figure  5 . If the monopolist has no information beyond the prior distribution of valuations, there will be no segmentation. The producer charges the optimal monopoly price and gets the associated monopoly profit, and consumers receive a positive surplus; this is marked by point A in figure  5 . If the monopolist has complete information, then he can charge each buyer his true valuation, i.e., engage in perfect or first-degree price discrimination; this is marked by point B. The point marked C is where consumer surplus is maximized; the outcome is efficient and the consumer gets all the surplus gains over the uniform monopoly profit. At the point marked D, social surplus is minimized by holding producer surplus down to uniform monopoly profits and holding consumer surplus down to zero.\n\nThe main result states that we can make only very weak predictions about producer and consumer surplus. It can be understood as the outcome of a set of metaphorical information design problems. If an information designer wanted to maximize consumer surplus, she would choose point C. If she wanted to minimize consumer surplus, or producer surplus, or any weighted combination of the two, she could choose point D. Any other point on the boundary of the triangle is the solution to some maximization problem of the information designer defined by some preferences over producer and consumer surplus.\n\nThe information design problem has a very clear literal interpretation in the case where the monopolist knows the consumer's valuation. She can then achieve perfect price discrimination at point B. However, giving a literal information design interpretation of point C is more subtle. We would need to identify an information designer who knew consumers' valuations and committed to give partial information to the monopolist in order to maximize the sum of consumers' welfare. Importantly, even though the disclosure rule is optimal for consumers as a group, individual consumers would not have an incentive to truthfully report their valuations to the information designer, given the designer's disclosure rule, since they would want to report themselves to have low values.\n\nAs discussed in the previous section, it seems hard to explain the main result using concavification, but there is an elementary geometric argument. One can show that any point where the monopolist is held down to his uniform monopoly profits with no information beyond the prior distribution-including outcomes A, C, and D in figure  5 -can be achieved with the same segmentation. In this segmentation, consumer surplus varies because the monopolist is indifferent between charging different prices.\n\nWe can use a simple example to illustrate these results. There are three valuations, v \u2208 V = { 1, 2, 3 } , which arise in equal proportions, and there is zero marginal cost of production. The feasible social surplus is\n\nThe uniform monopoly price is v * = 2 . Under the uniform monopoly price, profit is \u03c0 * = (2/3) \u00d7 2 = 4/3 and consumer surplus\n\nA segment x is a vector of probabilities of each valuation, thus x = ( x 1 , x 2 , x 3 ) , and by \u03c3 ( x ) we denote the total mass of a segment x . A segmentation of the market is therefore a collection of segments x \u2208 X and and a probability distribution \u03c3 ( \u22c5 ) over the seg- ments. We give an example of a segmentation below. In the example, there are three segments and each segment is identified by its support on the valuations indicated by the set { \u2022 } in the superscript. The frequency of each segment x is given by \u03c3 ( x ) :\n\nThe particular segmentation has a number of interesting properties. First, in each segment, the seller is indifferent between charging as price any valuation that is in the support of the segment. Second, the uniform monopoly price, p * = 2 , is in the support of every segment. Thus, this particular segmentation preserves the uniform monopoly profit. If the monopolist charges the uniform monopoly price on each segment, we get point A. If he charges the lowest value in the support of each segment (which is also an optimal price, by construction), we get point C; and if he charges the highest value in the support, we get point D.\n\nRoesler and Szentes (2017) consider a related information design problem in which a single buyer can design her own information about her value before she is facing a monopolist seller. While the analysis of the third-degree price discrimination proceeds as a one-player application, the arguments extend to many-player settings. Bergemann, Brooks, and Morris (2017a) pursue the question of how private information may impact the pricing behavior in a many-buyer environment. There, we derive results about equilibrium behavior in the first-price auction that hold across all common-prior information structures. The results that we obtain can be used for a variety of applications, e.g., to partially identify the value distribution in settings where the information structure is unknown and to make informationally robust comparisons of mechanisms."
    },
    {
      "title": "Information and Volatility",
      "text": "Bergemann, Heumann, and Morris (2015) revisit a classic issue in macroeconomics. Consider an economy of interacting agents-each of whom picks an actionwhere the agents are subject to idiosyncratic and aggregate shocks. A fundamental economic question in this environment is to ask how aggregate and idiosyncratic shocks map into \"aggregate volatility\"-the variance of the average action. Versions of this question arise in many different economic contexts.\n\nIn particular, a central question in macro-economics is how aggregate and individual productivity shocks translate into variation in GDP. Another classical question is when and how asymmetric information can influence this mapping, and in particular exacerbate aggregate volatility.\n\nThese questions are studied in a setting with a continuum of agents whose best responses are linear in the (expectation of the) average action of others and in the idiosyncratic as well as aggregate shocks. Shocks, actions, and signals are symmetrically normally distributed across agents, maintaining symmetry and normality of the information structure. The maximal aggregate volatility is attained in an information structure in which the agents confound idiosyncratic and aggregate shocks, and display excess response to the aggregate shocks, as in  Lucas (1972)  and more recently in  Hellwig and Venkateswaran (2009) ,  Venkateswaran (2013) , and Angeletos and La'O (2013). Our contribution is to highlight that, in this setting with idiosyncratic and aggregate shocks, a class of noise-free confounding information structures are extremal and provide global bounds on how much volatility can arise. In particular, for any given variance of aggregate shocks, the upper bound on aggregate volatility is linearly increasing in the variance of the idiosyncratic shocks.\n\nIn this application, we do not think there is any economic agent who is able to or wants to maximize aggregate volatility. But because we are interested in bounds on aggregate volatility across equilibria of different information structures, the problem is naturally represented as an information design problem.\n\nThe basic setting is that the payoff shock \u03b8 i of individual i is given by the sum of an aggregate shock \u03b8 and an idiosyncratic shock \u03b5 i :\n\nThe aggregate shock \u03b8 is common to all agents and the idiosyncratic shock \u03b5 i is independent and identically distributed across agents, as well as independent of the aggregate shock. Each component of the payoff shock \u03b8 i is normally distributed:\n\n. The variance of the individual payoff shock \u03b8 i can be expressed in terms of the variance of the sum of the idiosyncratic and the aggregate shock: \u03c3 \u03b8 2 + \u03c3 \u03b5"
    },
    {
      "title": "2",
      "text": ". The correlation (coefficient) \u03c1 \u03b8 between the payoff shocks \u03b8 i and \u03b8 j of any two agents i and j is:\n\nThe best response of agent i is given by a linear function\n\nwhere A is the average action. Now, the results described above regarding the structure of the extremal information structure hold independently of whether the weight on the average action, r , is negative (the strategic substitutes case), zero (the purely decision theoretic case), or positive (the strategic complements case). A striking property is that the set of feasible correlations between individual and average actions and individual and aggregate shocks is independent of r and determined only by statistical constraints. Here we will thus convey the flavor of the result in a setting where the decision of the agent is independent of any strategic considerations, thus the decision-theoretic case.\n\nIt suffices to consider the following one-dimensional class of signals:\n\nwhere the linear composition of the signal s i is determined by the parameter \u03bb \u2208 [ 0, 1 ] .\n\nThe information structure \u03bb is noise free in the sense that every signal s i is a linear combination of the idiosyncratic and the aggregate shock, \u03b5 i and \u03b8 , and no extraneous noise or error term enters the signal of each agent. Nonetheless, since the signal s i combines the idiosyncratic and the aggregate shock with weights \u03bb and 1 -\u03bb , each signal s i leaves agent i with residual uncertainty about his true individual payoff shock \u03b8 i , unless \u03bb = 1 -\u03bb = 1/2 . In the decision-theoretic case, r = 0 , the best response of each agent simply reflects a statistical prediction problem, namely to predict the payoff shock \u03b8 i given the signal s i :\n\n(20\n\nThe individual prediction problem is more responsive to the signal s i , that is, assigns a larger weight to s i if and only if the signal contains more information about the individual payoff shock \u03b8 i . The noise-free information structure \u03bb = 1/ 2 allows each agent to perfectly infer the individual payoff shock \u03b8 i . It follows that the responsiveness, and hence the variance of the individual action \u03c3 a"
    },
    {
      "title": "2",
      "text": ", is maximized at \u03bb = 1 / 2 :\n\nNow, to the extent that the individual payoff shocks, \u03b8 i and \u03b8 j , are correlated, we find that even though each agent i only solves an individual prediction problem, his actions are correlated by means of the underlying correlation of the individual payoff shocks, and the resulting aggregate volatility is:\n\nWe can ask whether the aggregate volatility can reach higher levels under information structures different from \u03bb = 1 / 2 . As the information structure departs from \u03bb = 1 / 2 , we necessarily introduce a bias in the signal\n\nBergemann and Morris: Information Design: A Unified Perspective s i toward one of the two components of the payoff shock \u03b8 i . Clearly, the signal s i is losing its informational quality with respect to the individual payoff shock \u03b8 i as \u03bb moves away from 1 / 2 in either direction. Thus, the individual prediction problem (  20 ) is becoming noisier and in consequence, the response of the individual agent to the signal s i is attenuated. But a larger weight, 1 -\u03bb , on the aggregate shock \u03b8 , may support correlation in the actions across agents, and thus support larger aggregate volatility. As the response of the agent is likely to be attenuated, a trade-off appears between bias and loss of information. We show that the maximal aggregate volatility:\n\nis achieved by the information structure \u03bb * :\n\nwhich biases the signal toward the aggregate shock. We can express the information structure that maximizes the aggregate volatility in terms of the correlation coefficient \u03c1 \u03b8 :\n\nand the maximal volatility can be expressed as:\n\nSurprisingly, as we approach an environment with purely idiosyncratic shocks, the maximal aggregate volatility does not converge to zero; rather, it is bounded away from zero , and given by \u03c3 \u03b5 2 /4 . Thus, the economy can maintain a large aggregate volatility even in the presence of vanishing aggregate payoff shocks by confounding the payoff-relevant information about the idiosyncratic shock with the (in the limit) payoff-irrelevant information about the aggregate shock."
    },
    {
      "title": "Information Design with Private Information",
      "text": "We have thus far considered the scenario where the designer knows not only the true state \u03b8 , but also the players' prior information about the state. We now consider what happens when the information designer does not have access to players' prior information (but still can condition on the state). Here, we consider two alternative assumptions about the designer's ability to condition recommendations on players' prior information. If the designer can elicit the private information, then we have information design with elicitation. If the designer cannot elicit the private information, we have information design without elicitation. We present a self-contained discussion of these extensions and then discuss how-with these extensions-information design fits into the mechanism design and incomplete-information-correlated equilibrium literatures more broadly in sections 6.3 and 6.4."
    },
    {
      "title": "Players' Prior Information is not Known to the Designer",
      "text": "When the information designer cannot observe the players' prior information, she may or may not be able to ask the players about it. In the case of information design with elicitation, she will be able to condition her recommendations on the reported types. In the case of information design without elicitation, she can only send a list of recommendations, namely one recommendation for each possible type of the player.\n\nIn the case of information design with elicitation, the revelation principle still implies that we can restrict attention to the case where the information sent by the information designer consists of action recommendations. However, we will now require an incentive compatibility condition that entails truth telling as well as obedience, so that the information designer can only condition on a player's signal if the player can be given an incentive to report it truthfully. Following  Myerson (1991, section 6 .3), we can think of the information designer choosing a decision rule \u03c3 : T \u00d7 \u0398 \u2192 \u0394(A) , but each type of each player can choose a deviation \u03b4 i : A i \u2192 A i with the interpretation that \u03b4 i ( a i ) is the action chosen by player i if the information designer recommended action a i . The decision rule \u03c3 is incentive compatible if each player does not have an incentive to deviate."
    },
    {
      "title": "DEFINITION 2 (Incentive Compatible): A decision rule",
      "text": "for all t i \u2032 \u2208 T i and \u03b4 i :\n\nThe displayed inequality will be referred to as player i 's type-t i incentive constraint. It ensures that player i , after observing signal t i , finds it optimal to report his signal truthfully and then, after observing and updating on the information contained in the resulting action recommendation a i , finds it optimal to follow this recommendation. Thus it builds in both truth telling and obedience. In addition, the notion of incentive compatibility requires that the decision rule is immune to \"double deviations\" in which the player misreports his type to be t i \u2032 (rather than t i ) and disobeys the recommendation of the designer by choosing \u03b4 i ( a i ) rather than a i . Thus, incentive compatibility implies, but is not implied by, separately requiring truth telling and obedience.\n\nPROPOSITION 2: An information designer with elicitation can attain a decision rule if and only if it is incentive compatible.\n\nIn the case of information design without elicitation, the designer cannot condition the action recommendation on the reported type, but has to offer a contingent recommendation, a vector of action recommendations, where each individual entry is an action recommendation for a specific type of the player, hence contingent on the realized type. The set of feasible recommendations to player i is therefore given by B i = A i T i . The set of player i 's contingent recommendations therefore has a typical element\n\nWe are now interested in contingent action recommendations \u03d5 : \u0398 \u2192 \u0394(B) rather than action recommendations."
    },
    {
      "title": "DEFINITION 3 (Public Feasibility): A decision rule \u03c3 : T \u00d7 \u0398 \u2192 \u0394(A) is publicly feasible if there exists a contingent recommendation",
      "text": "In this case, we say that \u03c3 is induced by \u03d5.\n\nPublic feasibility is the restriction that a given player's contingent recommendation cannot depend on the type of the player himself nor on the types of the other players. We refer to the above requirement as public feasibility, since the recommendation vector cannot be tailored to the private information of the players and it has to be feasible in the sense that it induces the decision rule \u03c3 . We emphasize that each contingent recommendation b i is still communicated to each agent i separately and privately, and thus is not public in the sense of a public announcement to all players.\n\nWhen I = 1 , public feasibility is a vacuous restriction. Every decision rule \u03c3 is induced by the contingent recommendation \u03d5 given by\n\nUnder this choice of \u03d5, the components of the contingent recommendation vector b(t) are drawn independently. When I > 1 , however, public feasibility is a substantive restriction. By recommending to a particular player a strategy rather than an action, the designer can condition that player's action on his type. By judiciously choosing a distribution over B , the designer can even correlate the players' strategies. But she cannot correlate one player's strategy on another player's type.\n\nWe are not interested in all contingent recommendations, but rather those that are obedient in the sense defined earlier, in definition 1. Below, we adapt the definition to account for the larger space of contingent recommendations, b , rather than action recommendations, a . DEFINITION 4 (Publicly Feasible Obedience): A decision rule \u03c3 : T \u00d7 \u0398 \u2192 \u0394(A) is publicly feasible obedient if there exists a contingent recommendation \u03d5 : \u0398 \u2192 \u0394(B) such that ( i ) \u03d5 induces \u03c3 , and ( ii ) \u03d5 satisfies obedience in the sense that for each i , t i \u2208 T i , and b i \u2208 B i ,\n\nfor all a i \u2032 \u2208 A i .\n\nThe displayed inequality will be referred to as player i 's ( t i , b i ) -publicly feasible obedience constraint. It ensures that player i , after observing signal t i and receiving and updating on the recommendation b i , finds it optimal to take the action b i ( t i ) prescribed by the vector b i for his type t i . Note that in so far as a contingent recommendation b i reveals more information about the state \u03b8 and thus possibly and indirectly about the type profile t -i than just an action recommendation, publicly feasible obedience will be a more demanding concept than mere obedience as it allows the agents to contemplate deviations based on more accurate information. After all, type t i is able to observe the recommendation tailored toward him as well as the recommendation offered to all other types t i \u2032 \u2260 t i . To the extent that the recommendation across types is not perfectly correlated, it then follows that the type t i will receive additional information through the contingent recommendation rather than the action recommendation."
    },
    {
      "title": "PROPOSITION 3: An information designer without elicitation can attain a decision rule if and only if it is publicly feasible obedient."
    },
    {
      "title": "The Investment Example Revisited",
      "text": "We now illustrate information design with private information using the investment example introduced earlier in section 3. The issues that arise in the one-player case with private information are already interesting and subtle. Here we do not present any examples of elicitation with many players. We thus do not consider any additional issues of public feasibility that only arise in the many-player case.\n\nWe therefore now allow the information of the firm to be private. The government does not know the realization of the signal that the firm observes but can or cannot elicit it."
    },
    {
      "title": "Information Design with Elicitation",
      "text": "In the case of elicitation, we have a screening problem where the designer offers a recommendation that induces a probability of investing as a function of the reported signal and the true state. As noted above, we have three sets of constraints that need to be satisfied. First, each type has to truthfully report his signal; second, each type has to be willing to follow the recommendation, the obedience constraints; and third, double deviations, by means of misreporting and disobeying at the same time, must not be profitable. Kolotilin et al. (2017)  refer to this informational environment as \"private persuasion.\" 15   Kolotilin (2018)  pursues a linear programming approach to identify the optimal information disclosure policy under a single-crossing assumption.\n\nA decision rule now specifies the probability of investment p \u03b8t conditional on the true state \u03b8 \u2208 { B, G } and the reported type t \u2208 { b, g } . Thus, as before in section 3.2, a decision rule is now a vector p = ( p Bb , p Bg , p Gb , p Gg ) . The information designer offers a recommendation (stochastically) as a function of the true state and the reported type. The obedience conditions are as in section 3.2, where information was not private. A truthful reporting constraint is 15 Bergemann, Bonatti, and Smolin (2018) consider a model of private persuasion with quasilinear utility. Their main objective is to analyze the revenue maximizing solution to the information design problem subject to the elicitation constraints. Daskalakis, Papadimitriou, and Tzamos (2016)  also consider an information design with quasilinear utility. The novel aspect of their analysis is that the object for sale has many attributes, and the seller chooses optimally how much to disclose about each individual attribute. Their analysis reveals a close relationship to the classic bundling problem of a multi-item monopolist.\n\ndescribed below for a good type t = g . The truth-telling constraint for the good type t = g is:\n\nand correspondingly for the bad type t = b:\n\nBy misreporting and then following the resulting recommendation afterwards, each type can change the probability of investing. We can write the above two truth-telling constraints in terms of a bracketing inequality:\n\nThese inequalities highlight how the differential between type t = b and t = g in the recommendation p Bt in the bad state are bounded, below and above, by the differential in the recommendation p Gt in the good state. Notice also that since\n\nthe above bracketing inequality requires that p Ggp Gb \u2265 0, p Bgp Bb \u2265 0, thus, the conditional probability of investing has to be larger for the good type than the bad type in either state. An implication specific to the binary action, binary state environment is the fact that double deviations do not impose any additional restriction on the behavior of the player. We state and prove this result formally in the appendix as proposition 6. In particular, this means that the obedience and truth-telling constraints discussed above imply the incentive compatibility condition of definition 2.\n\nWith these additional constraints, the set of outcomes that can arise in equilibrium under information design with elicitation is weakly, and typically strictly, smaller than under an omniscient designer, i.e., the case in the previous section where the designer can condition his recommendation directly on the players' prior information. The truth-telling constraints impose restrictions on how the differences in the conditional probabilities across types can vary across states. These impose additional restrictions on the ability of the government to attain either very low or very high investment probabilities in both states, as highlighted by equation (  25 ).\n\nFigure  6  illustrates the case where x = 0.9 and q = 0.7 ; the dark red region corresponds to the outcomes that can arise under information design with elicitation; adding in the pink region, we get back to the triangle that corresponds to omniscient information design where the designer knows players' prior information."
    },
    {
      "title": "Information Design without Elicitation",
      "text": "We could also consider a government, who does not know the signal of the firm and cannot even elicit it. Kolotilin et al. (2017)  call this scenario \"public persuasion.\" Such information design without elicitation has been the focus of the recent literature.\n\nClearly, the designer can replicate any decision rule without elicitation with a decision rule with elicitation. This inclusion holds without any restrictions on the state space, the number of players, or the players' actions. In the specific investment example above, with a single player, two states, and two actions, the converse happens to be true as well. That is, any decision rule attainable with elicitation can also be attained without elicitation. In other words, in the binary setting and with a single player, there is no need for elicitation. The designer can induce any incentive-compatible decision rule by recommendations alone. We state and prove these two results in the appendix as propositions 5 and 6. 16  The equivalence breaks down immediately if either of the binary assumptions regarding action and state are relaxed or we consider more than one player. We illustrate this failure of the equivalence result with a minor generalization of the investment example. In particular, in a single-player environment, we allow the player to either consider a small or a large investment. For completeness, we present, in the appendix, examples where one of the other two hypotheses fails. This modified example allows us to find a strict nesting of the set of outcomes without prior information, with prior information and an omniscient designer, with elicitation, and finally without elicitation. For the purpose of this example, it will be sufficient to focus on the case of a single player."
    },
    {
      "title": "Beyond the Binary Setting",
      "text": "Consider the basic investment example with I = 1 , \u0398 = {B, G} , uniform prior, and symmetric types that are correct with probability q > 1/2 . We now add an additional investment decision, to invest small, to the 16   Kolotilin et al. (2017)  showed such an equivalence under a different set of assumptions. In their model, the designer and the player are privately informed about distinct payoff states rather than having distinct information about the same state as in the present setting. set of feasible actions of the player. The decision to invest small comes with a higher rate of return but smaller total return than the (regular) investment decision. The payoff from a small investment is -1/2 in the bad state and y \u2208 (x/2, x) in the good state:\n\nFor simplicity we restrict attention to decision rules that put zero probability on the small investment in equilibrium. We note that the small investment decision still plays a role in the characterization of incentive compatible decision rules as it is a feasible action to the player. It will hence generate additional obedience constraints that the designer has to respect as the player has now two possible deviations from the recommended action, one of which is to invest at a small scale. The decision rules-restricted to invest and not invest-can still be represented by a vector p = ( p Bb , p Bg , p Gb , p Gg ) that records the probability of investing. As a benchmark, first suppose the player has no prior information. Then a decision rule that never recommends the small investment can be represented as a pair ( p B , p G ) \u2208 [0, 1] 2 that specifies the probability of the large investment in each state. When the firm has no prior information, there are two binding obedience constraints, one for the big investment against the small investment:\n\nand one for no investment against the small investment:\n\nThe equilibrium regions are depicted in figure 7. If the firm has no prior information, the government faces only the above two constraints. The set of attainable decision rules is described by the light red area. In contrast to the setting with two investment levels analyzed earlier, there is now a kink in the area of attainable decision rules that reflects a change in the binding obedience constraint, from zero investment to small investment.\n\nIf we consider the case in which the firm has prior information, then we have three different communication protocols for the government. An omniscient designer faces the obedience constraints that we analyzed earlier in section 3.2. By contrast, if the firm holds private information, then the information designer is no longer omniscient. Now the firm has two possible ways to disobey. If the government does not observe the signal but can elicit the information from the firm, then we have truth-telling constraints as described by (  23 ) and (  24 ) in addition to the obedience constraints. Importantly, in this setting with more than two actions, the possibility of double deviations-misreporting and disobeying-generates additional constraints on the incentive compatible decision rules. Finally, a designer without elicitation faces additional obedience constraints that rule out deviations on a particular vector recommendation. The corresponding areas in figure  7  illustrate that the sequence of additional constraints from omniscient to elicitation to no elicitation impose increasingly more restrictions on the government and hence generate a sequence of strictly nested sets.\n\nWe already discussed how these three regimes offer an increasing number of constraints. It remains to discuss the specific impact of being able to elicit (or not) the private information. With elicitation, the player only learns the designer's recommendation for one type, namely the type that he reports. But a designer who cannot elicit must reveal her action recommendations for all types, hence the contingent recommendation. This enables a player to contemplate additional contingencies and hence deviations. With three possible actions, as in this example, there are two additional deviations that take advantage of this finer information. In particular, the high type can disobey the recommendation to invest by deviating to invest small only when the designer also recommends not to invest to the low type. Likewise, the low type can disobey the recommendation not to invest by deviating to invest small only when the designer also recommends investing to the high type. The additional options for the player induce further constraints on the information designer. Naturally, these additional deviations were not available in the binary action environment. And in fact, the absence of this large set of deviations accounts for the equivalence between elicitation and no elicitation in the binary action and state environment. 18  We conclude with a few observations about the comparative statics with respect to the information structure. As the precision of the information q decreases toward 1/2 , the inner three regions expand outward and converge to the no-prior-information equilibrium set. By contrast, as the precision q increases towards 1 , the three inner regions contract and converge to the single coordinate vector (0, 1) ."
    },
    {
      "title": "Information Design within Mechanism Design",
      "text": "In the information design problem, the \"information designer\" can commit to providing information to the players to serve his ends, but has no ability to choose outcomes (or force the players to take particular actions). The set of available actions and a mapping from action profiles to outcomes and thus payoffs is fixed. How does this relate to \"mechanism design\"? Myerson (1982)  describes a class of Bayes incentive problems, which constitutes a leading definition of mechanism design (see also  Myerson 1987 Myerson , 1994)) . In this setting, players may have control over some actions affecting outcomes but the mechanism designer may be able to commit to pick other outcomes as a function of the players' reports. For example, in many classical mechanism design problems with individual rationality constraints, players do have control over some actions: participation versus nonparticipation. And even if the mechanism designer may not have any information that is unavailable to the players, he canvia the mechanism-implicitly control the 18 We mentioned earlier that double deviations were not relevant in the binary environment in the sense that they do not add additional restrictions. This changes in the richer environment here, where the communicating designer indeed faces additional restrictions coming from the possibility of double deviations. information that players have about each other. Myerson (1991)  then labels the case where the mechanism designer has no direct control over outcomes \"Bayesian games with communication\" (section 6.3) and the setting where the designer has complete control over outcomes \"Bayesian collective choice problems\" (section 6.4). Thus, what we are calling information design corresponds to Myerson's Bayesian games with communication with the proviso that the mediator brings his own information to the table, rather than merely redistributing others' information.\n\nThere is also an important literature on an informed player (referred to as informed principal) who can commit to choose outcomes as a function of messages (see  Myerson 1983) . But in this setting, the information designer (principal) is typically assumed to be able to commit to a mechanism only after receiving his private information and the principal is not choosing action herself; see  Mylovanov and Troeger (2012, 2014)  and  Perez-Richet (2014)  for recent contributions. By contrast, in the information design setting there is a principal who cannot pick a contract/mechanism but can commit to a disclosure rule prior to observing her information."
    },
    {
      "title": "Correlated Equilibrium and Incomplete Information",
      "text": "Aumann  (1974, 1987)  introduced correlated equilibrium as a solution concept for games with complete information (about the payoff matrix). He showed that the set of correlated equilibria equals the set of distributions over actions that could arise in a Bayes-Nash equilibrium if players observed some additional payoff-irrelevant signals (consistent with the common prior). Equivalently, the set of correlated equilibria corresponds to the set of outcomes that could be induced by an (uninformed) information designer. What we are calling \"information design\" thus corresponds to an incomplete information elaboration of this original rationale for thinking about correlated equilibrium when the information designer has information of her own. 19 In this section, we review the existing literature on incomplete information correlated equilibrium to relate it to the version of incomplete information correlated equilibrium-BCE-that is relevant for information design.\n\nWhile  Aumann (1987)  provides an information design foundation for complete information correlated equilibrium, he offers a broader interpretation of the characterization, arguing that correlated equilibrium captures the implications of common knowledge of rationality in a complete information game, under the common prior assumption. 20 A large literature on the epistemic foundations of game theory has developed since then  (Dekel and Siniscalchi 2015) , elaborating on the formal language and questions suggested by Aumann's work, although focused on the case of complete information without the common prior assumption. Formal treatment of the implications of common knowledge of rationality and the common prior assumption under incomplete information ties in with many of the issues discussed in this survey; we will discuss one issue that arises in this case in the next subsection.\n\nTo understand the literature on incomplete information correlated equilibrium, it is useful to identify two kinds of constraints in the literature on incomplete information correlated equilibrium: feasibility conditions 19 Bergemann and Morris (2017) consider foundations for other solution concepts based on informational robustness and information design considerations, when the common prior assumption is not maintained. 20 Hillas, Kohlberg, and Pratt (2007) propose a related alternative foundation for correlated equilibrium. Consider an external observer who observes an infinite sequence of plays of a complete information game, has exchangeable beliefs about them, but does not believe he can offer beneficial advice to players on how to improve their payoffs. This observer must believe that play corresponds to a correlated equilibrium.\n\n(constraints on what kind of information decision rules can condition on) and incentive compatibility conditions (what decision rules are consistent with optimal behavior). In this paper so far, we have introduced one feasibility condition-public feasibility (definition 3)-and three incentive constraints-obedience (definition 1), incentive compatibility (definition 2) and publicly feasible obedience (definition 4). Recall that BCE-our characterization of outcomes that can be induced by an omniscient information designer-imposed only obedience. We will discuss two further feasibility conditions to provide an overview of correlated equilibrium with incomplete information."
    },
    {
      "title": "Belief Invariance",
      "text": "Consider the requirement that the information designer can correlate players' actions, but without changing players' beliefs and higher-order beliefs about the state of the world. This is formalized as follows.\n\nDEFINITION 5 (Belief Invariant): Decision rule \u03c3 : T \u00d7 \u0398 \u2192 \u0394(A) is belief invariant for ( G, S ) if \u03c3 i ( a i | ( t i , t -i ), \u03b8 ) is independent of t -i for each i, a i , t i , and \u03b8, where\n\nWe then say that a decision rule is a belief-invariant BCE if it satisfies belief invariance and obedience. It is not obvious how this feasibility condition arises under an information design interpretation: if the designer can condition his information on \u03b8 , why not allow him to change beliefs and higher-order beliefs?\n\nThere are two conceptual reasons why one might nonetheless be interested in belief-invariant BCE. First,  Dekel, Fudenberg, and Morris (2007)  introduced the solution concept of interim correlated rationalizability. They show that it characterizes the implica-tions of common certainty of rationality and players' beliefs and higher-order beliefs. The solution concept by construction imposes belief invariance. Liu (2015)  observes that the set of interim correlated rationalizable actions corresponds to the set of actions that can be played in a correlated equilibrium with incomplete information and subjective priors. If, then, the common prior assumption is imposed, this corresponds to the set of belief-invariant Bayes-correlated equilibria. Thus, the solution concept of belief-invariant BCE is the \"right\" one for understanding the implications of common knowledge assumptions under the common prior assumption.\n\nSecond, Mathevet, Perego, and Taneva (2017) consider a situation where the information designer can convey information only about beliefs and higher-order beliefs, but is not able to send additional information about correlation. Now the set of belief-invariant BCE, once some higher-order belief information has been sent, is equal to the set of BCE. Bergemann and Morris (2016a)  describe how an arbitrary information structure can be decomposed into information about beliefs and higher-order beliefs, and additional belief-invariant signals."
    },
    {
      "title": "Join Feasibility",
      "text": "Twenty five years ago,  Forges (1993)  (see also  Forges 2006)  gave an overview of incomplete information correlated equilibrium. A maintained assumption in that literature was that the information designer (or \"mediator\") did not bring any information of her own to the table, but simply rearranged information, telling players privately about others' information. This can be formalized as follows.\n\nDEFINITION 6 (Join Feasibility): Decision rule \u03c3 : T \u00d7 \u0398 \u2192 A is join feasible for ( G, S ) if \u03c3(a | t, \u03b8 ) is independent of \u03b8 , i.e. , \u03c3(a | t, \u03b8) = \u03c3(a | t, \u03b8\u2032) for each t \u2208 T , a \u2208 A , and \u03b8, \u03b8 \u2032 \u2208 \u0398 .\n\nThus, join feasibility allows the designer to use the join of the private information of all the players, the information contained in the entire type profile t . At the same time, it requires that the information designer can send information only about the type profile of the players and thus can only condition on the type profile, not on the state of the world \u03b8 or \u03b8 \u2032 . Join feasibility is imposed implicitly in some work on incomplete information correlated equilibrium-  Forges (1993)  integrates out uncertainty other than the players' types-but explicitly in others, e.g.,  Lehrer, Rosenberg, and Shmaya (2010) .\n\nAs noted in the introduction, information design adds to the old incomplete information correlated literature the twist that the designer brings information of her own to the table. In turn, this allows the designer to choose the optimal design and provision of the information to the players.\n\nForges's 1993 paper was titled \"Five Legitimate Definitions of Correlated Equilibrium in Games with Incomplete Information.\" The feasibility and incentive conditions described so far allow us to completely describe the five solution concepts she discusses: (i) A Bayesian solution is a decision rule satisfying join feasibility and obedience.\n\n(ii) A belief invariant Bayesian solution is a decision rule satisfying join feasibility, belief invariance, and obedience.\n\n(iii) An agent normal form correlated equilibrium is a decision rule satisfying join feasibility, public feasibility, (which implies belief invariance) and obedience.\n\n(iv) A communication equilibrium is a decision rule satisfying join feasibility and incentive compatibility (which implies obedience).\n\n(v) A strategic form correlated equilibrium is a decision rule satisfying join feasibility and publicly feasible obedience (which implies belief invariance, public feasibility, obedience, and incentive compatibility).\n\nThus, the Bayesian solution, communication equilibrium, and strategic form correlated equilibrium correspond to omniscient information design, information design with elicitation, and information design without elicitation, respectively. The belief invariant Bayesian solution and the agent normal form correlated equilibrium do not have natural information design interpretations. Forges (1993)  noted inclusions implied by these definitions. In particular, if we write (n) for the set of incomplete information cor- related equilibria of type n above, we have (5) \u2286 (3) \u2286 (2) \u2286 (1) and (  5 ) \u2286 (4) \u2286 (1) . Forges (1993)  reports examples showing that these inclusions are the only ones that can be shown, i.e., there exist decision rules that (i) are Bayesian solutions but not belief invariant BCE or communication equilibria; (ii) are belief invariant Bayes solutions but not communication equilibria or agent normal form correlated equilibria; (iii) are communication equilibria but not belief invariant Bayesian solutions; (iv) are belief invariant Bayesian solutions and communication equilibria but not agent normal form equilibria; (v) are agent normal form correlated equilibria but not communication equilibria; (vi) are agent normal form correlated equilibria and communication equilibria. Forges (1993)  discusses one more solution concept: the universal Bayesian solution. The universal Bayesian solution corresponds-in our language-to the set of Bayes-correlated equilibria that would arise under join feasibility if players had no information."
    },
    {
      "title": "Information Design with Adversarial Equilibrium and Mechanism Selection",
      "text": "We have so far examined settings where the revelation principle holds: we can, without loss of generality, assume that the set of signals, or types, is equal to the set of actions. We now consider two natural extensions of information design where the revelation principle breaks down."
    },
    {
      "title": "Adversarial Equilibrium Selection",
      "text": "In section 2, it was implicitly assumed that the information designer could, having designed the information structure, also select the equilibrium to be played. With one player, the equilibrium selection problem reduces to breaking ties and is not of substantive interest. However,  Carroll (2016)  and  Mathevet, Perego, and Taneva (2017)  highlighted that this issue is of first-order importance in the many-player case, and that the revelation principle argument breaks down and alternative arguments must be used;  Mathevet, Perego, and Taneva (2017)  formalize and analyze the case where players with no prior information will choose the worst equilibrium for the designer.\n\nFor our representation, we define a \"communication rule\" for the information designer. Players have the prior information encoded in the information structure S = ( ( T i ) i=1 I , \u03c0 ) . The information designer sends each player i an extra message\n\nWe will write E ( C ) for the set of Bayes-Nash equilibria of the game with communication rule C . We can now give a more formal statement of proposition 1.\n\nPROPOSITION 4: Decision rule \u03c3 is a BCE of ( G, S ) if and only if there exists a communication rule C and a Bayes-Nash equilibrium b \u2208 E(C) that induce \u03c3 . This is a revelation principle argument that was formally stated as theorem 1 in  Bergemann and Morris (2016a) .\n\nRecall that in section 2, we defined the information designer's utility from BCE \u03c3 :\n\nWe can also define the information designer's utility from communication rule C and strategy profile b :\n\nLet us consider the problem of an information designer who can pick both the communication rule and the equilibrium and is thus solving the problem max\n\nBut one could also consider the problem of an information designer who can pick the communication rule, but wants to maximize his utility in the worst equilibrium, and is thus solving the problem max\n\nWe now discuss three applications where maxmin information design problems have been motivated and studied; in each application, players have prior information. First,  Carroll (2016)  considers the problem of bilateral trade where he wants to know the worst possible gains from trade for a given distribution over the known private values of a buyer and a seller. If we picked the worst equilibrium, we could always support no trade with probability one, so instead he considers the best equilibrium. This is equivalent to having an information designer pick an information structure to minimize the efficiency of trade anticipating that the buyer and seller will play an equilibrium that maximizes efficiency (i.e., maximizes the gains from trade).\n\nSecond, Inostroza and Pavan (2017) consider global game models of regime change and the problem of an information designer trying to minimize the probability of regime change (they are motivated by the design of stress tests to minimize the probability of a run on a bank). What information should the information designer send-as a function of the state and players' initial information-to minimize the probability of a run? They call this scenario \"discriminatory\" because the information designer can condition on players' prior information. As in Carroll's bilateral trade problem, the problem is not interesting if the designer is able to pick the equilibrium as well as the information structure: in this case, he can prevent the possibility 22 Of course, the minmax problem min of inefficient outcomes by creating common knowledge of payoffs and picking the good equilibrium. To make the problem interesting, they then study the maxmin problem.\n\nFinally, a literature on robustness to incomplete information  (Kajii and Morris 1997)  can be understood as an information design problem with adversarial equilibrium selection. We will give an example to illustrate this connection. 23 We will consider a slightly adapted version of the incomplete information investment game discussed earlier with payoffs:\n\n, not invest 0, -1 0, 0 for some 0 < x < 1 , and the probability of state G is \u03b5 , and \u03b5 is small. Assume that the prior information is that player 1 knows the state and player 2 knows nothing. Thus, player 1 has a dominant strategy to invest in state G , while there are multiple equilibria in the complete information game corresponding to state B . In this setting, we can study the standard information design (with prior information) described above. Suppose that the information designer wants to maximize the probability that at least one player invests. Maintaining the assumption that the designer can pick the equilibrium, the answer is trivial: the information designer can simply give the players no additional information and there will be an equilibrium where players always invest. But what if the information designer anticipated that the worst equilibrium would be played? This is information design with adversarial equilibrium selection. What information structure would the information designer choose and what would be the induced probability that at least one player invests? It is convenient and more transparent to the describe information structures using the language of partitions .\n\nConsider the information structure defined by a set \u03a9 = { 1, 2, \u2026 , \u221e } where player 1 observes an element of the partition:\n\nand player 2 observes an element of the partition:\n\nThus, an element of the partition now constitutes a signal realization. Let payoffs be given as defined by the payoff state \u03b8 = G if 1 \u2208 \u03c3 is realized and by the payoff state \u03b8 = B everywhere else. For some q \u2208 ( 1 _ 2 , 1 ) , let the probability of state \u03c9 \u2260 \u221e be \u03b5 ( 1q ____ q ) \u03c9 and so the probability of state\n\nThis information structure could arise from the prior information described above (only player 1 can distinguish between states B and G ) and communicating additional information. Now suppose that q > 1 ____ 1 + x ; this condition implies that a player assigning probability q to the other player investing will always have a strict incentive to invest. Following the induction argument of  Rubinstein (1989) , invest is the unique rationalizable action for both players at all states \u03c9 \u2260 \u221e . To see this, observe that at state 1 , player 1 has a dominant strategy to invest. Now player 2 , with information set {1, 2} , must have a best response to invest, since he attaches probability q to player 1 investing. Now suppose that we have established that both players are investing at information sets of the form { \u03c9, \u03c9 + 1 } if \u03c9 \u2264 k . Now consider the player with information set { k + 1, k + 2 } . He attaches probability q to the other player being at information set { k, k + 1 } and therefore investing. So the player with information set { k + 1, k + 2 } will invest. This argument establishes that it is possible to ensure thatif \u03b5 is sufficiently small-both players invest with probability q _____ 2q -1 \u03b5 . Since this is true for any q > 1 ____ 1 + x , it implies that it is possible to get both players to invest with probability arbitrarily close to\n\nThe information structure we used to get arbitrarily close to this bound was (countably) infinite, but we can also get arbitrarily close using finite information structures as shown in  Kajii and Morris (1997) . Now, arguments from  Kajii and Morris (1997)  imply that this information structure is (arbitrarily close to) optimal for the information designer in this problem. To get a flavor of the argument, say that a player p -believes an event if he attaches probability at least p to the event occurring, and that there is common p -belief of that event if each player p -believes it, each player p -believes that both p -believe it, and so on. One can show that not invest is rationalizable only if there is common x ____ 1 + x -belief that payoffs correspond to state B . But since x < 1 , it follows that x ____ 1 + x > 1 _ 2 and one can show that if the event that payoffs are given by state B has probability at least 1 -\u03b5 , then-for sufficiently small \u03b5 -the ex ante probability that there is common x ____ 1 + x -belief that the state is B is Bergemann and Morris: Information Design: A Unified Perspective at least 1 -1 ____ 1x \u03b5 . This establishes that the bound is tight. If x > 1 , similar arguments can be used to show that the information designer can ensure that both players invest with probability 1 .\n\nArguments from  Kajii and Morris (1997)  and the follow-up literature  (Ui 2001 and Morris and Ui 2005 ) can be used to analyze maxmin payoffs more generally when-as in the above example-the incomplete information game has each player either knowing that payoffs are given by a fixed complete information game or having a dominant strategy.\n\nIt is worth emphasizing that the above definition of the maxmin problem, and all three applications, correspond to the omniscient case where the information designer can condition on players' prior information as well as on the state. An alternative case that has been studied is when the information designer can only send public signals and only condition on the state (and not players' prior information). Goldstein and Huang (2016)  and  Inostroza and Pavan (2017)  have studied this problem in global game models of regime change. (Inostroza and Pavan 2017 call this the nondiscriminatory case, to contrast with the discriminatory case described previously.) This case can be illustrated by our example above. An information designer interested in maximizing the probability of both investing would send a public signal to invest always if the state was good and with probability \u03b5 ____ 1 -\u03b5 x if the state was bad. This would make player 2 indifferent between investing and not investing if he got the \"invest\" signal."
    },
    {
      "title": "Adversarial Mechanism Selection",
      "text": "We considered an information designer who was choosing additional information for the players, holding fixed the basic game and players' prior information. But what if the information designer had to pick the information structure not knowing what the basic game, or mechanism, was going to be? In particular, suppose that the choice of mechanism was adversarial. Again, we will lose the revelation principle. Once the information designer has picked the information structure (and thus the set of signals), the adversarial mechanism designer could pick a mechanism with a different set of messages. Bergemann, Brooks, and Morris (2016)  consider the problem of an information designer picking an information structure for a set of players with a common value of an object to minimize revenue, anticipating that an adversarial mechanism designer will then pick a mechanism to maximize revenue (a minmax problem). This gives an upper bound on the revenue of the seller of a single object who is picking a mechanism anticipating that the worst information structure will be chosen (a maxmin problem). Du (2018)  constructs elegant bounds for the latter problem and shows that these bounds are sharp in the limit as the number of bidders increases. The former establishes the equivalence between minmax and maxmin exactly when there are two bidders and when the support of the value is binary, and the latter solves the auction design problem in the limit when the number of bidders goes to infinity. In a recent paper,  Brooks and Du (2018)  provide a general solution to the common value auction problem with a general common prior and a finite number of bidders. Both problems are studied without the common prior assumption by  Chung and Ely (2007) ."
    },
    {
      "title": "Conclusion",
      "text": "We have provided a unified perspective for a rapidly expanding literature on Bayesian persuasion and information design. In contrast with the recent literature on Bayesian persuasion that is concerned with a single player (receiver), we emphasized the implications of information design for many-player strategic environments. We presented a two-step approach to information design: first identify the set of outcomes that are attainable under some information structure, then identify the optimal information structure. We have described the close connection between the information design problem and the earlier literature on correlated equilibrium with incomplete information; but whereas players are receiving real payoff-relevant information in the information design problem, in the older correlated equilibrium literature, the designer (mediator) was merely providing correlating devices.\n\nWe have focused on a pure version of the static information design problem where the designer has no ability to control outcomes. But-as argued in  Myerson (1982)  and  Myerson (1987)  and discussed in section 6.3there are settings where a designer can control some outcomes (as a function of players' messages), but cannot control others and then can only use information to influence the outcomes outside her control. In other settings, the principal may be able to jointly choose the mechanism and the information structures. For example,  Bergemann and Pesendorfer (2007)  consider the optimal design of information structure and auction format in an independent private value environment. More recently,  Daskalakis, Papadimitriou, and Tzamos (2016)  solve for the optimal auction and information structure when the seller and the bidders each have some private information about the valuation of the object. Their analysis is motivated by online advertising auctions, where the two-way information asymmetry among seller and bidder is a central feature of the environment.\n\nAs one moves into dynamic settings, an overlap between the tools of information design and mechanism design more generally become more central. A specific setting where the tools of mechanism design and information design have recently been studied in conjunction is the area of markets with resale. Here, the information that is disclosed in the first stage fundamentally affects the interaction in the resale market, see for example  Calzolari and Pavan (2006) ;  Dworczak (2017) ;  Carroll and Segal (forthcoming); and Bergemann, Brooks, and Morris (2017b) .\n\nThe information design problemwhether literal or metaphorical-identifies a mapping from the economic environment to possible outcomes, allowing for different choices of information structures. There is a second, reverse use of information design for robust identification, identifying a mapping from outcomes to possible parameters of the economic environment, allowing that different information structures might have generated the data.  24 For example, in an auction setting, one might consider a sample of bids from a sequence (or cross-section) of independent auctions. We can then ask what we can infer about the underlying distribution of valuations under weak assumptions on the information structure, that is without assuming a specific information structure. Syrgkanis, Tamer, and Ziani (2017)  pursue such an approach for inference and identification in an auction setting. Magnolfi and Roncoroni (2017)  adopt a similar perspective in the analysis of discrete games, in particular entry and exit games.\n\nMany interesting avenues remain open in information design. There are many open methodological questions. The concavification approach has been very influential in the single-player (receiver) setting, so it is natural to ask if it can be as useful in the many-player setting. In both the linear programming and the concavification approach, the optimal information structure is identified by a global optimization problem. It might be insightful to find a more local approach that could identify the direction of valuable information provision. We briefly mentioned a number of applications of information design in the introduction. Digital information is becoming widely used in the allocation and distribution of services and commodities, as in traffic navigation apps such as Waze or Google Maps, recommender systems used by Netflix and Appendix Additional Computation for Section 3.2\n\nWe observed in section 3.1 that, absent any additional information beyond the common prior, the firm does not invest. For any additional private information of the firm to change the \"default\" behavior, it has to be that the firm is investing after receiving the good signal, or that (28)\n\nIn other words, the information has to be sufficiently precise-thus q sufficiently large-to induce a change in the behavior. Conditional on being type g, the firm will have an incentive to invest (when told to invest) under p = ( p Bb , p Bg , p Gb , p Gg ) if\n\nand an incentive to not invest (when told to not invest) if\n\nA similar pair of incentive constraints apply to the recommendations conditional on being type b .\n\nAs long as the private information of the firm is sufficiently noisy, or q \u2264 1/ ( 1 + x ) , the binding constraint is (29) as in the uninformed case; otherwise it is the inequality (30) that determines the conditional probabilities. The obedience conditions for the firm observing a bad type b are derived in an analogous manner. The obedience conditions are defined type by type, and we compute the restrictions on the conditional probabilities averaged across types. Now the decision rule ( p Bb , p Bg , p Gb , p Gg ) will induce behavior ( p B , p G ) integrating over types t \u2208 { b, g } .\n\nAmazon, or service platforms such as Uber or OpenTable. This suggests that information design will naturally be part of the solution of a large class of allocation problems. To the extent that the relevant information is arriving sequentially and improving over time, the resulting models will likely incorporate and address dynamic aspects.\n\nTherefore, we assume u(1, G )u(0, G) and u(1, B )u(0, B) are each nonzero and have opposite signs. Then without loss, we may assume the payoffs take the form u(0, G) = u(0, B) = 0 , u(1, B) = -1 , and u(1, G) = x > 0 . foot_11 Action 1 can be interpreted as investment. We will represent a decision rule \u03c3 by a vector p = ( p \u03b8t ) (\u03b8, t)\u2208\u0398\u00d7T , where p \u03b8t = \u03c3(1 | \u03b8, t) . For each signal t \u2208 T , let\n\nwhere \u03c0(t ) = \u03c8(G ) \u03c0(t | G ) + \u03c8(B ) \u03c0(t | B ) > 0 by assumption. Let p = ( p \u03b8t ) \u2208 E(G, S) . To show that p \u2208 NE (G, S) , we will explicitly construct an obedient contingent recommendation \u03d5 that induces p . Let t, t \u2032 \u2208 T and set q = q(t) and q \u2032 = q( t \u2032 ) . Since p satisfies the truth-telling constraint,\n\nTaking (1q \u2032 , 1q) and ( q \u2032 , q) linear combinations of these two inequalities respectively yields (qq \u2032 ) ( p Gtp G t \u2032 ) x \u2265 0 and (qq \u2032 ) ( p Btp B t \u2032 ) \u2265 0. So q(t ) < q( t \u2032 ) implies p \u03b8t \u2264 p \u03b8 t \u2032 for \u03b8 \u2208 {G, B} . In the case q = q \u2032 , both inequalities must hold with equality so q( p Gtp G t \u2032 )x = (1q ) ( p Btp B t \u2032 ), and hence p Gt \u2265 p G t \u2032 if and only if p Bt \u2265 p B t \u2032 . Therefore, we can label the signals t 1 , \u2026, t n so that (31) q( t 1 ) \u2264 \u22ef \u2264 q( t n ) and p \u03b8 t 1 \u2264 \u22ef \u2264 p \u03b8 t n for \u03b8 = B, G.\n\nTo simplify notation, define q l = q( t l ) for each l = 1, \u2026, n ; set p \u03b8 t 0 = 0 and p \u03b8 t n+1 = 1 for all \u03b8 . By (31), p \u03b8 t kp \u03b8 t k-1 \u2265 0 , so \u03d5( \u22c5 |\u03b8) is a probability distribution for each \u03b8 \u2208 {G, B} . It is easy to check that \u03d5 induces the decision rule p .\n\nTo complete the proof, we verify that \u03d5 is obedient. For each l = 1, \u2026, n and k = 1, \u2026, n + 1 , type t l 's expected utility from investing if and only if being recommended b k is:\n\nSince both expressions in parentheses are nonnegative, U l|k is weakly increasing in l . Therefore, for types t l with l \u2265 k , U l|k \u2265 U k|k = ( q k p G t k x -(1 -q k ) p B t k ) -( q k p G t k-1 x -(1 -q k ) p B t k-1 ) \u2265 0, where the last inequality holds by truth telling for k > 1 and obedience for k = 1 . Similarly, for types t l with l < k , U l|k \u2264 U k-1|k = ( q k-1 p G t k x -(1 -q k-1 ) p B t k ) -( q k-1 p G t k-1 x -(1 -q k-1 ) p B t k-1 ) \u2264 0.\n\nThe last two inequalities establish the obedience of \u03d5 , so the proof is complete. \u220e Now we return to the main problem of finding ( p Bb , p Bg , p Gb , p Gg ) . To compare these decision rules to the benchmark, we will ultimately integrate over the signals to compute the probability of investment in each state. Formally, ( p Bb , p Bg , p Gb , p Gg ) \u2192 ( (1 -q) p Bg + q p Bb , q p Gg + (1 -q) p Gb ) .\n\nWith an informed receiver, the omniscient designer faces four obedience constraints: (32a)\n\n\u0394 g 1 \u225c q p Gg x -(1q) p Bg -( q p Gg y - 1q _ 2 p Bg ) \u2265 0, (32b) \u0394 b 1 \u225c (1q) p Gb xq p Bb -( (1 -q) p Gb y - q _ 2 p Bb ) \u2265 0, (32c)\n\n(1p Bb ) \u2264 0."
    },
    {
      "text": "Figure 1. Investment Probability with Uninformed Player: x = 55/100"
    },
    {
      "text": "Figure 2. Investment Probability with Informed Player: x = 55/100"
    },
    {
      "text": "Figure 3. Investment Probability with Negative or Positive Strategic Term \u03b5"
    },
    {
      "text": "Figure 4. Investment Probability with Two Players with Prior Information, with Strategic Term \u03b5 = 3 /10"
    },
    {
      "text": "Figure 5. The Bounds on Profits and Consumer Surplus in Third-Degree Price Discrimination"
    },
    {
      "text": "b i : T i \u2192 A i . We define B = \u220f i=1 I B i and let a generic element be given by b = ( b 1 , \u2026, b I ) \u2208 B , and so b"
    },
    {
      "text": "Figure 6. Investment Probability with Private Information"
    },
    {
      "text": "Figure 7. Investment Probability under Different Information Design Scenarios"
    },
    {
      "text": "the basic game G , the prior information structure S , and the communication rule C describe a Bayesian game ( G, S, C ) . 21 A 21 Bergemann and Morris (2016a) call the pair ( S, C ) an \"expanded information structure.\" strategy for player i in this game is a mapping"
    },
    {
      "text": "b"
    },
    {
      "text": "C max b\u2208E (C) V * (C, b) is a reinterpretation of a maxmin problem where the objective is replaced by -V * (C, b) . The minmin problem is sim- ilarly a reinterpretation of the maxmax problem."
    },
    {
      "text": "For each k = 1, \u2026, n + 1 , define the cutoff strategy b k by b k ( t l ) = { 1 if l \u2265 k 0 otherwise.In particular, b 1 is unconditional investment and b n+1 is unconditional non-investment. Define the stochastic contingent recommendation \u03d5 : \u0398 \u2192 \u0394(B) by\u03d5(b | \u03b8 ) = { p \u03b8 t kp \u03b8 t k-1 if b = b k for some k = 1, \u2026, n + 1 0 otherwise."
    }
  ],
  "references": [
    {
      "title": "Persuading Voters",
      "authors": [
        "Ricardo Alonso",
        "Odilon C\u00e2mara"
      ],
      "year": 2016
    },
    {
      "title": "Sentiments",
      "authors": [
        "George-Marios Angeletos",
        "Jennifer La"
      ],
      "year": 2013,
      "doi": "10.3982/ecta10008"
    },
    {
      "title": "Private Bayesian Persuasion",
      "authors": [
        "Itai Arieli",
        "Yakov Babichenko"
      ],
      "year": 2018
    },
    {
      "title": "The Effects of Mandatory Transparency in Financial Market Design: Evidence from the Corporate Bond Market",
      "authors": [
        "Asquith",
        "Thomas Paul",
        "Parag Covert",
        "Pathak"
      ],
      "year": 2013
    },
    {
      "title": "Subjectivity and Correlation in Randomized Strategies",
      "authors": [
        "Robert Aumann"
      ],
      "year": 1974
    },
    {
      "title": "Correlated Equilibrium as an Expression of Bayesian Rationality",
      "authors": [
        "Robert Aumann"
      ],
      "year": 1987,
      "doi": "10.2307/1911154"
    },
    {
      "title": "Repeated Games with Incomplete Information",
      "authors": [
        "Robert Aumann",
        "Michael Maschler"
      ],
      "year": 1995
    },
    {
      "title": "Dynamic Information Provision: Rewarding the Past and Guiding the Future",
      "authors": [
        "Ian Ball"
      ],
      "year": 2018,
      "doi": "10.3982/ecta17345"
    },
    {
      "title": "Positive Value of Information in Games",
      "authors": [
        "Bruno Bassan",
        "Olivier Gossner",
        "Marco Scarsini",
        "Shmuel Zamir"
      ],
      "year": 2003
    },
    {
      "title": "The Design and Price of Information",
      "authors": [
        "Dirk Bergemann",
        "Alessandro Bonatti",
        "Alex Smolin"
      ],
      "year": 2018,
      "doi": "10.1257/aer.20161079"
    },
    {
      "title": "The Limits of Price Discrimination",
      "authors": [
        "Dirk Bergemann",
        "Benjamin Brooks",
        "Stephen Morris"
      ],
      "year": 2015
    },
    {
      "title": "Informationally Robust Optimal Auction Design",
      "authors": [
        "Dirk Bergemann",
        "Benjamin Brooks",
        "Stephen Morris"
      ],
      "year": 2016
    },
    {
      "title": "First-Price Auctions with General Information Structures: Implications for Bidding and Revenue",
      "authors": [
        "Dirk Bergemann",
        "Benjamin Brooks",
        "Stephen Morris"
      ],
      "year": 2017,
      "doi": "10.3982/ecta13958"
    },
    {
      "title": "Selling to Intermediaries: Optimal Auction Design in a Common Value Model",
      "authors": [
        "Dirk Bergemann",
        "Benjamin Brooks",
        "Stephen Morris"
      ],
      "year": 2017,
      "doi": "10.2139/ssrn.3018883"
    },
    {
      "title": "Information and Volatility",
      "authors": [
        "Dirk Bergemann",
        "Tibor Heumann",
        "Stephen Morris"
      ],
      "year": 2015,
      "doi": "10.1016/j.jet.2014.12.002"
    },
    {
      "title": "Bayes Correlated Equilibrium and the Comparison of Information Structures",
      "authors": [
        "Dirk Bergemann",
        "Stephen Morris"
      ],
      "year": 2013,
      "doi": "10.3982/te1808"
    },
    {
      "title": "Robust Predictions in Games with Incomplete Information",
      "authors": [
        "Dirk Bergemann",
        "Stephen Morris"
      ],
      "year": 2013
    },
    {
      "title": "Bayes Correlated Equilibrium and the Comparison of Information Structures in Games",
      "authors": [
        "Dirk Bergemann",
        "Stephen Morris"
      ],
      "year": 2016,
      "doi": "10.3982/te1808"
    },
    {
      "title": "Information Design, Bayesian Persuasion, and Bayes Correlated Equilibrium",
      "authors": [
        "Dirk Bergemann",
        "Stephen Morris"
      ],
      "year": 2016,
      "doi": "10.1257/aer.p20161046"
    },
    {
      "title": "Belief-Free Rationalizability and Informational Robustness",
      "authors": [
        "Dirk Bergemann",
        "Stephen Morris"
      ],
      "year": 2017
    },
    {
      "title": "Information Structures in Optimal Auctions",
      "authors": [
        "Dirk Bergemann",
        "Martin Pesendorfer"
      ],
      "year": 2007,
      "doi": "10.1016/j.jet.2007.02.001"
    },
    {
      "title": "Comparison of Experiments",
      "authors": [
        "David Blackwell"
      ],
      "year": 1951
    },
    {
      "title": "Equivalent Comparisons of Experiments",
      "authors": [
        "David Blackwell"
      ],
      "year": 1953,
      "doi": "10.1214/aoms/1177729032"
    },
    {
      "title": "Influence through Ignorance",
      "authors": [
        "Isabelle Brocas",
        "Juan Carrillo"
      ],
      "year": 2007
    },
    {
      "title": "Optimal Auction Design with Common Values: An Informationally-Robust Approach",
      "authors": [
        "Benjamin Brooks",
        "Songzi Du"
      ],
      "year": 2018
    },
    {
      "title": "Monopoly with Resale",
      "authors": [
        "Giacomo Calzolari",
        "Alessandro Pavan"
      ],
      "year": 2006
    },
    {
      "title": "Revealed Preference, Rational Inattention, and Costly Information Acquisition",
      "authors": [
        "Andrew Caplin",
        "Mark Dean"
      ],
      "year": 2015
    },
    {
      "title": "A Testable Theory of Imperfect Perception",
      "authors": [
        "Andrew Caplin",
        "Daniel Martin"
      ],
      "year": 2015
    },
    {
      "title": "Informationally Robust Trade and Limits to Contagion",
      "authors": [
        "Gabriel Carroll"
      ],
      "year": 2016,
      "doi": "10.1016/j.jet.2016.09.003"
    },
    {
      "title": "Robustly Optimal Auctions with Unknown Resale Opportunities",
      "authors": [
        "Gabriel Carroll",
        "Ilya Segal"
      ]
    },
    {
      "title": "Foundations of Dominant-Strategy Mechanisms",
      "authors": [
        "Kim-Sau Chung",
        "J Ely"
      ],
      "year": 2007,
      "doi": "10.1111/j.1467-937x.2007.00427.x"
    },
    {
      "title": "Reducing Congestion through Information Design",
      "authors": [
        "Sammy Das",
        "Emir Kamenica",
        "Renee Mirka"
      ],
      "year": 2017
    },
    {
      "title": "Does Information Revelation Improve Revenue?",
      "authors": [
        "Constantinos Daskalakis",
        "Christos Papadimitriou",
        "Christos Tzamos"
      ],
      "year": 2016
    },
    {
      "title": "Interim Correlated Rationalizability",
      "authors": [
        "Eddie Dekel",
        "Drew Fudenberg",
        "Stephen Morris"
      ],
      "year": 2007
    },
    {
      "title": "Epistemic Game Theory",
      "authors": [
        "Eddie Dekel",
        "Marciano Siniscalchi"
      ],
      "year": 2015,
      "doi": "10.1016/b978-0-444-53766-9.00012-4"
    },
    {
      "title": "Sequential Information Design",
      "authors": [
        "Laura Doval",
        "Jeffrey Ely"
      ],
      "year": 2016
    },
    {
      "title": "Robust Mechanisms under Common Valuation",
      "authors": [
        "Songzi Du"
      ],
      "year": 2018
    },
    {
      "title": "Benchmarks in Search Markets",
      "authors": [
        "Darrell Duffie",
        "Piotr Dworczak",
        "Haoxiang Zhu"
      ],
      "year": 2017
    },
    {
      "title": "Algorithmic Information Structure Design: A Survey",
      "authors": [
        "Shaddin Dughmi"
      ],
      "year": 2017
    },
    {
      "title": "Mechanism Design with Aftermarkets: Cutoff Mechanisms",
      "authors": [
        "Piotr Dworczak"
      ],
      "year": 2017
    },
    {
      "title": "Beeps",
      "authors": [
        "Jeffrey Ely"
      ],
      "year": 2017,
      "doi": "10.1257/aer.20150218"
    },
    {
      "title": "Suspense and Surprise",
      "authors": [
        "Jeffrey Ely",
        "Alexander Frankel",
        "Emir Kamenica"
      ],
      "year": 2015
    },
    {
      "title": "Moving the Goalposts",
      "authors": [
        "Jeffrey Ely",
        "Martin Szydlowski"
      ],
      "year": 2017,
      "doi": "10.1086/704387"
    },
    {
      "title": "Five Legitimate Definitions of Correlated Equilibrium in Games with Incomplete Information",
      "authors": [
        "Fran\u00e7oise Forges"
      ],
      "year": 1993
    },
    {
      "title": "Correlated Equilibrium in Games with Incomplete Information Revisited",
      "authors": [
        "Fran\u00e7oise Forges"
      ],
      "year": 2006,
      "doi": "10.1007/s11238-006-9005-3"
    },
    {
      "title": "Communication Equilibria with Partially Verifiable Types",
      "authors": [
        "Fran\u00e7oise Forges",
        "Fr\u00e9d\u00e9ric Koessler"
      ],
      "year": 2005,
      "doi": "10.1016/j.jmateco.2003.12.006"
    },
    {
      "title": "Game Theory",
      "authors": [
        "Drew Fudenberg",
        "Jean Tirole"
      ],
      "year": 1991
    },
    {
      "title": "Costly Persuasion",
      "authors": [
        "Matthew Gentzkow",
        "Emir Kamenica"
      ],
      "year": 2014,
      "doi": "10.1257/aer.104.5.457"
    },
    {
      "title": "Competition in Persuasion",
      "authors": [
        "Matthew Gentzkow",
        "Emir Kamenica"
      ],
      "year": 2017,
      "doi": "10.1093/restud/rdw052"
    },
    {
      "title": "Bayesian Persuasion in Coordination Games",
      "authors": [
        "Itay Goldstein",
        "Chong Huang"
      ],
      "year": 2016,
      "doi": "10.1257/aer.p20161047"
    },
    {
      "title": "Comparison of Information Structures",
      "authors": [
        "Olivier Gossner"
      ],
      "year": 2000,
      "doi": "10.1006/game.1998.0706"
    },
    {
      "title": "Setting the Right Prices for the Wrong Reasons",
      "authors": [
        "Christian Hellwig",
        "Venky Venkateswaran"
      ],
      "year": 2009,
      "doi": "10.1016/j.jmoneco.2009.06.013"
    },
    {
      "title": "Correlated Equilibrium and Nash Observer's Assessment of the Game",
      "authors": [
        "John Hillas",
        "Elon Kohlberg",
        "John Pratt"
      ],
      "year": 2007,
      "doi": "10.1093/ww/9780199540884.013.31684"
    },
    {
      "title": "The Private and Social Value of Information and the Reward to Inventive Activity",
      "authors": [
        "Jack Hirshleifer"
      ],
      "year": 1971
    },
    {
      "title": "Learning, Experimentation and Information Design",
      "authors": [
        "Johannes Horner",
        "Andrzej Skrzypacz"
      ],
      "year": 2016,
      "doi": "10.1017/9781108227162.002"
    },
    {
      "title": "Multi-agent Persuasion: Leveraging Strategic Uncertainty",
      "authors": [
        "T Hoshino"
      ],
      "year": 2017
    },
    {
      "title": "Persuasion in Global Games with Application to Stress Testing",
      "authors": [
        "Nicolas Inostroza",
        "Alessandro Pavan"
      ],
      "year": 2017,
      "doi": "10.2139/ssrn.4894998"
    },
    {
      "title": "The Robustness of Equilibria to Incomplete Information",
      "authors": [
        "Atsushi Kajii",
        "Stephen Morris"
      ],
      "year": 1997
    },
    {
      "title": "Bayesian Persuasion and Information Design",
      "authors": [
        "Emir Kamenica",
        "Forthcoming"
      ]
    },
    {
      "title": "Bayesian Persuasion",
      "authors": [
        "Emir Kamenica",
        "Matthew Gentzkow"
      ],
      "year": 2011
    },
    {
      "title": "Optimal Information Disclosure: A Linear Programming Approach",
      "authors": [
        "Anton Kolotilin"
      ],
      "year": 2018,
      "doi": "10.3982/te1805"
    },
    {
      "title": "Persuasion of a Privately Informed Receiver",
      "authors": [
        "Anton Kolotilin",
        "Tymofiy Mylovanov",
        "Andriy Zapecheinyuk",
        "Ming Li"
      ],
      "year": 2017,
      "doi": "10.3982/ecta13251"
    },
    {
      "title": "The Economics of Uncertainty and Information",
      "authors": [
        "Jean-Jacques Laffont"
      ],
      "year": 1989
    },
    {
      "title": "Signaling and Mediation in Games with Common Interests",
      "authors": [
        "Ehud Lehrer",
        "Dinah Rosenberg",
        "Eran Shmaya"
      ],
      "year": 2010,
      "doi": "10.1016/j.geb.2009.08.007"
    },
    {
      "title": "Correlation and Common Priors in Games with Incomplete Information",
      "authors": [
        "Qingmin Liu"
      ],
      "year": 2015
    },
    {
      "title": "Expectations and the Neutrality of Money",
      "authors": [
        "Robert Lucas",
        "Jr"
      ],
      "year": 1972
    },
    {
      "title": "Estimation of Discrete Games with Weak Assumptions on Information",
      "authors": [
        "Lorenzo Magnolfi",
        "Camilla Roncoroni"
      ],
      "year": 2017
    },
    {
      "title": "Information Design in Multi-stage Games",
      "authors": [
        "Miltiadis Makris",
        "Ludovic Renou"
      ],
      "year": 2018
    },
    {
      "title": "Microeconomic Theory",
      "authors": [
        "Mas-Colell",
        "Michael Andreu",
        "Jerry Whinston",
        "Green"
      ],
      "year": 1995
    },
    {
      "title": "Nash Equilibrium and Welfare Optimality",
      "authors": [
        "Eric Maskin"
      ],
      "year": 1999
    },
    {
      "title": "On Information Design in Games",
      "authors": [
        "Laurent Mathevet",
        "Jacopo Perego",
        "Ina Taneva"
      ],
      "year": 2017
    },
    {
      "title": "Formulation of Bayesian Analysis for Games with Incomplete Information",
      "authors": [
        "Jean-Fran\u00e7ois Mertens",
        "Shmuel Zamir"
      ],
      "year": 1985
    },
    {
      "title": "Information Design: Insights from Orderings of Dependence and Heterogeneity",
      "authors": [
        "Margaret Meyer"
      ],
      "year": 2017
    },
    {
      "title": "A Theory of Auctions and Competitive Bidding",
      "authors": [
        "Paul Milgrom",
        "Robert Weber"
      ],
      "year": 1982,
      "doi": "10.2307/1911865"
    },
    {
      "title": "Generalized Potentials and Robust Sets of Equilibria",
      "authors": [
        "Stephen Morris",
        "Takashi Ui"
      ],
      "year": 2005
    },
    {
      "title": "Optimal Coordination Mechanisms in Generalized Principal-Agent Problems",
      "authors": [
        "Roger Myerson"
      ],
      "year": 1982
    },
    {
      "title": "Mechanism Design By an Informed Principal",
      "authors": [
        "Roger Myerson"
      ],
      "year": 1983
    },
    {
      "title": "Multistage Games with Communication",
      "authors": [
        "Roger Myerson"
      ],
      "year": 1986
    },
    {
      "title": "Bayesian Equilibrium and Incentive-Compatibility: An Introduction",
      "authors": [
        "Roger Myerson"
      ],
      "year": 1987
    },
    {
      "title": "Game Theory: Analysis of Conflict",
      "authors": [
        "Roger Myerson"
      ],
      "year": 1991
    },
    {
      "title": "Communication, Correlated Equilibria and Incentive Compatibility",
      "authors": [
        "Roger Myerson"
      ],
      "year": 1994
    },
    {
      "title": "Efficient Mechanisms for Bilateral Trading",
      "authors": [
        "Roger Myerson",
        "Mark Satterthwaite"
      ],
      "year": 1983
    },
    {
      "title": "Informed-Principal Problems in Environments with Generalized Private Values",
      "authors": [
        "Tymofiy Mylovanov",
        "Thomas Tr\u00f6ger"
      ],
      "year": 2012
    },
    {
      "title": "Mechanism Design By an Informed Principal: Private Values with Transferable Utility",
      "authors": [
        "Morris Bergemann",
        "Thomas Tymofiy",
        "Tr\u00f6ger"
      ],
      "year": 2014
    },
    {
      "title": "The Positive Value of Information",
      "authors": [
        "Abraham Newyman"
      ],
      "year": 1991
    },
    {
      "title": "Fulfilled Expectations Cournot Duopoly with Information Acquisition and Release",
      "authors": [
        "William Novshek",
        "Hugo Sonnenschein"
      ],
      "year": 1982
    },
    {
      "title": "Information Disclosure and Unraveling in Matching Markets",
      "authors": [
        "Michael Ostrovsky",
        "Michael Schwarz"
      ],
      "year": 2010
    },
    {
      "title": "Robust Conditional Predictions in Dynamic Games: An Application to Sovereign Debt",
      "authors": [
        "Juan Passadore",
        "Juan Pablo"
      ],
      "year": 2014
    },
    {
      "title": "Interim Bayesian Persuasion: First Steps",
      "authors": [
        "Eduardo Perez-Richet"
      ],
      "year": 2014
    },
    {
      "title": "Optimal Information Disclosure",
      "authors": [
        "Luis Rayo",
        "Ilya Segal"
      ],
      "year": 2010
    },
    {
      "title": "Buyer-Optimal Learning and Monopoly Pricing",
      "authors": [
        "Anne Roesler",
        "Bal\u00e1zs Katrin",
        "Szentes"
      ],
      "year": 2017
    },
    {
      "title": "The Electronic Mail Game: Strategic Behavior under 'Almost Common Knowledge",
      "authors": [
        "Ariel Rubinstein"
      ],
      "year": 1989
    },
    {
      "title": "Inference on Auctions with Weak Assumptions on Information",
      "authors": [
        "Vasilis Syrgkanis",
        "Elie Tamer",
        "Juba Ziani"
      ],
      "year": 2017
    },
    {
      "title": "Information Design",
      "authors": [
        "Ina Taneva"
      ],
      "year": 2015
    },
    {
      "title": "Robust Equilibria of Potential Games",
      "authors": [
        "Takashi Ui"
      ],
      "year": 2001,
      "doi": "10.1111/1468-0262.00246"
    },
    {
      "title": "Heterogeneous Information and Labor Market Fluctuations",
      "authors": [
        "Venky Venkateswaran"
      ],
      "year": 2013
    }
  ],
  "num_references": 96
}
