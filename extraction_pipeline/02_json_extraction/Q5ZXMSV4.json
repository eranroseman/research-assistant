{
  "paper_id": "Q5ZXMSV4",
  "title": "Offline Contextual Multi-armed Bandits for Mobile Health Interventions: A Case Study on Emotion Regulation",
  "abstract": "Delivering treatment recommendations via pervasive electronic devices such as mobile phones has the potential to be a viable and scalable treatment medium for long-term health behavior management. But active experimentation of treatment options can be time-consuming, expensive and altogether unethical in some cases. There is a growing interest in methodological approaches that allow an experimenter to learn and evaluate the usefulness of a new treatment strategy before deployment. We present the first development of a treatment recommender system for emotion regulation using real-world historical mobile digital data from n = 114 high socially anxious participants to test the usefulness of new emotion regulation strategies. We explore a number of offline contextual bandits estimators for learning and propose a general framework for learning algorithms. Our experimentation shows that the proposed doubly robust offline learning algorithms performed significantly better than baseline approaches, suggesting that this type of recommender algorithm could improve emotion regulation. Given that emotion regulation is impaired across many mental illnesses and such a recommender algorithm could be scaled up easily, this approach holds potential to increase access to treatment for many people. We also share some insights that allow us",
  "year": 2020,
  "date": "2020-08-21",
  "journal": "Perspectives on Psychological Science",
  "publication": "Perspectives on Psychological Science",
  "authors": [
    {
      "forename": "Mawulolo",
      "surname": "Ameko",
      "name": "Mawulolo Ameko",
      "affiliation": "University of Virginia Charlottesville , USA \n\t\t\t\t\t\t\t\t University of Virginia \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Charlottesville \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Miranda",
      "surname": "Beltzer",
      "name": "Miranda Beltzer",
      "affiliation": "University of Virginia Charlottesville , USA \n\t\t\t\t\t\t\t\t University of Virginia \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Charlottesville \n\t\t\t\t\t\t\t\t\t USA",
      "email": "beltzer@virginia.edu"
    },
    {
      "forename": "Lihua",
      "surname": "Cai",
      "name": "Lihua Cai",
      "affiliation": "University of Virginia Charlottesville , USA \n\t\t\t\t\t\t\t\t University of Virginia \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Charlottesville \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Mehdi",
      "surname": "Boukhechba",
      "name": "Mehdi Boukhechba",
      "affiliation": "University of Virginia Charlottesville , USA \n\t\t\t\t\t\t\t\t University of Virginia \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Charlottesville \n\t\t\t\t\t\t\t\t\t USA"
    },
    {
      "forename": "Bethany",
      "surname": "Teachman",
      "name": "Bethany Teachman",
      "affiliation": "University of Virginia Charlottesville , USA \n\t\t\t\t\t\t\t\t University of Virginia \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Charlottesville \n\t\t\t\t\t\t\t\t\t USA",
      "email": "bteachman@virginia.edu"
    },
    {
      "forename": "Laura",
      "surname": "Barnes",
      "name": "Laura Barnes",
      "affiliation": "University of Virginia Charlottesville , USA \n\t\t\t\t\t\t\t\t University of Virginia \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t Charlottesville \n\t\t\t\t\t\t\t\t\t USA"
    }
  ],
  "doi": "https://doi.org/10.13039/100008457",
  "arxiv": "arXiv:2008.09472v1[cs.IR]",
  "keywords": [
    "CCS CONCEPTS",
    "Applied computing \u2192 Consumer health",
    "\u2022 Mathematics of computing \u2192 Causal networks",
    "\u2022 Human-centered computing \u2192 Ubiquitous computing Offline contextual bandits, User modeling, Emotion regulation, Mobile health, Health recommender systems"
  ],
  "sections": [
    {
      "title": "INTRODUCTION",
      "text": "Mental illnesses such as depression and social anxiety, if left untreated, can interfere with healthy life functioning, leading to lower disability-adjusted life years  [30]  and higher suicide rates  [8] . It is estimated that more than 25% of Americans suffer from a diagnosable mental illness each year  [23] , yet half of them do not receive any treatment  [4]  due to the scarce health care resources and limited access to traditional in-person care  [26] . New mobile technologies and increasing smartphone ownership give rise to mobile health, a digital health care paradigm that creates opportunities to scale up health interventions to the underserved patient population  [20] , especially those with chronic conditions.\n\nOne viable target for a digital health intervention that could benefit a significant portion of the population is emotion dysregulation, or difficulty selecting and effectively applying appropriate strategies to modulate the intensity or duration of emotional states  [18] . Emotion dysregulation is observed broadly across many mental illnesses, and improvements in emotion regulation (ER) often accompany decreases in symptom severity  [16, 42] . The ability to effectively manage negative emotions in our daily lives is of utmost importance. For example, days before a job interview, you may not be confident in your preparation, and feel anxious about it. You may find it difficult to focus on anything else, and cannot stop worrying about it or sleep. To manage your negative emotions, you might try a variety of strategies, including suppressing your thoughts about the upcoming interview, talking to a friend about it, conducting a mock interview for practice, distracting yourself with video games, or taking the advice from your therapist to identify and re-evaluate your catastrophic thoughts.\n\nIdeally, one would conduct a randomized control trial (RCT) to evaluate the effect of different ER strategies in different contexts, but this can quickly become unfeasible if the intent is to evaluate more than a dozen strategies across different contexts. We address this challenge in part by using an offline contextual bandits to learn and evaluate a novel treatment recommender algorithm using an observational dataset collected from a population of socially anxious individuals.\n\nWhile an observational design necessarily limits what causal inferences are possible, our contributions in this work include the following: 1) to the best of our knowledge, this is the first study to apply Contextual multi-armed bandit (CMAB) on ER, a domain that is central to treatment for many mental illnesses; 2) we apply CMAB in an offline setting that learns an interpretable initial policy using observational data; 3) we leverage both passively (e.g., Accelerometer) and actively (e.g., how appropriate was timing of survey) sensed contexts with a designed reward signal using self-reported effectiveness to evaluate the CMAB performance using several different importance sampling based estimators, and compare them with both a random policy and the observed policy. Our results show significantly better performance in the proposed CMAB approaches in terms of the average reward of a policy, which we denote as usefulness."
    },
    {
      "title": "RELATED WORK",
      "text": "Emotion regulation (ER) has been studied in psychology for decades due to its importance in understanding how people manage their emotions  [18] , and its implications for both mental and physical health, and interpersonal relations  [3] . People respond to stressful events using different ER strategies in different social and physical contexts, and according to different situational demands  [12, 41] . While ER strategies have long been considered as either adaptive or maladaptive, several researchers have argued that their effectiveness is context dependent  [2, 7] .\n\nNotably, demographic characteristics such as age and gender  [32] , which may be considered internal contexts, significantly influence people's choice of ER strategies. In addition, numerous recent studies have focused on external contexts in people's daily lives, and investigated their impact on ER strategy choice  [1, 45, 49] . An ecological momentary assessment study by Heiy et al. revealed that many of the most frequently used ER strategies were not the most effective for decreasing negative emotions  [19] , suggesting room for improvement in ER even among healthy individuals. To date, the capability of recommending the most effective ER strategies to people based on different contexts is urgently desired but remains a far-off goal  [13] . In this work, we make an effort towards this goal to learn a personalized and adaptive approach for ER strategy recommendation across various contexts.\n\nMany existing works propose various recommender systems targeting different health outcomes. For example, my-Behavior, a mobile app that tracks user's physical and dietary habits, recommends personalized suggestions for a healthier lifestyle  [35] . Cheung et al.  [10]  created a mobile app called IntelliCare, which consists of a suite of 12 individual apps as 'treatments' that will be recommended for managing depression and anxiety. Yang et al.  [51]  created a mobile health recommender system that integrates depression prediction and personalized therapy solutions to patients with emotional distress. In their system, personalization is realized using 9 external factors related to depression, including family life, external competition, interpersonal relationship, selfpromotion burden, economic burden, work pressure, individual personality, coping style, and social support, which are assessed using mobile questionnaires. These mobile health efforts are consistent with a mobile intervention framework called Just-in-time adaptive intervention (JITAI)  [31] .\n\nTwo aspects regarding the intervention decisions made in a JITAI framework are the timing of intervention delivery and choosing the best intervention strategy to deliver. Most existing works focus on optimizing for the best timing to deliver an intervention (e.g., predicting stressful moments linked to emotional eating  [36] ). By contrast, our work focuses on identifying the most effective ER strategies based on a person's context. Reinforcement learning with Markov decision processes (MDPs) are typically used to operationalize the key objectives of a JITAI. Example applications include personalizing sepsis treatment strategies  [33] , encouraging physical activity for diabetes patients  [52] , and managing stress  [21] . Interestingly, although reinforcement learning is not directly applied to recommend ER strategies for emotion management, it has been applied to understand the psychological and cognitive process of ER  [27, 37] .\n\nIn this work, we propose to leverage contextual multiarmed bandits, a reinforcement learning algorithm that treats each learning sample as independent from the same underlying data generating the distribution, but ignores the long term impacts on the distal outcome  [15] . CMAB has been mainly applied in domains such as web contents and advertisement placement  [24, 48] . In recent years, it has also been applied in numerous mobile health applications, such as hospital and doctor referral for medical diagnosis  [47] , personalized feedback for healthier lifestyle  [34] , and physical activity recommendation  [25] . Unlike these studies, which were conducted in an online setting or with simulations, our work focuses on the off-policy setting, in which a historical dataset on ER from a mobile health study is used to train an initial warm-start recommendation policy on ER. We design the various reinforcement learning components in the context of recommending ER strategies, and applied various importance sampling based techniques in learning and evaluation."
    },
    {
      "title": "CONTEXTUAL MULTI-ARMED BANDIT FOR EMOTION REGULATION",
      "text": "Contextual multi-armed bandit (CMAB) is an reinforcement learning algorithm that leverages contextual information to learn a policy that triggers actions based on the context to achieve optimal expected rewards. Typically, CMAB consists of an agent that interacts with an environment over a finite number of trials i = 1, 2, . . . ,T such that: 1) it observes a context x from an input space X; 2) chooses an action from a set A = {a 1 , a 2 , . . . , a k-1 , a k }, which contains all the strategies that each corresponds to an arm of a k MAB; and 3) receives a reward signal r i . The goal of the agent is to learn a policy to guide action decisions. Unlike a full-blown reinforcement learning algorithm typically modeled using MDPs, where an action decision impacts future states and action selections, CMAB assumes that {(x i , a i , r i )} T i=1 are independently and identically distributed following an unknown generative distribution D.\n\nWe formulate ER recommendation as a CMAB using mobile sensing technologies as shown in Figure  1 . Smartphones and wearables are applied to track the users both passively with sensor embedded devices and actively with mobile ecological momentary assessments (EMAs). These mobile sensing data streams will be processed into the contexts, the recommended ER strategies, and the associated rewards for our CMAB framework.\n\nIn the offline learning, logged observational data generated under a different policy will be used to learn and evaluate an initial policy. This data-generating policy is called the behavior policy and can be denoted as \u03c0 b . Similarly, the initial policy is called the target policy denoted as \u03c0 e .\n\nWe seek to achieve two objectives: 1) Learn an initial policy \u03c0 * e given an observational dataset, called the learning problem which is formulated as\n\nWhere V represents the value of a policy and \u03a0, the function class of possible policies. 2) Evaluate the performance of the initial policy using expected rewards from the testing samples. We call this the evaluation problem and this is formulated as\n\nIn the next section, we present the technical details on both the learning and evaluation problem to learn and evaluate the initial policy."
    },
    {
      "title": "LEARNING AND EVALUATION IN CONTEXTUAL MULTI-ARMED BANDIT",
      "text": "We consider learning in a linear policy class, of which the candidate policies are efficient for learning and easy to interpret. We apply importance sampling techniques that use a certain form of weighting scheme denoted as \u03c0 e (a i |x i ) \u03c0b (a i |x i ) in context x i to correct for the distributional shift between the target and behavior policy in order to have an unbiased estimate of the target policy value  [14] .\n\nThere are three main value estimators that lie at the core of offline policy learning and evaluation within the contextual bandit framework; namely, the direct method (DM), Inverse Propensity Weighting (IPW), and Doubly-Robust (DR)  [5] .\n\nNone of these approaches are guaranteed to perform optimally in every application scenario. Thus, we apply all of them in learning the optimal policy, and report their results. Below, we provide more details on the benefits and drawbacks of each approach.\n\nThe Direct Method (DM). The direct method, sometimes called the response surface modeling or covariate adjustment, is the family of approaches that consist of learning a predictive model which maps context and actions to the rewards in a regression model. Specifically, the direct method (DM) consists of estimating a reward approximator for r (x, a), where r : X \u00d7 A \u2192 R. This will result in a value function:\n\nwhere, \u03c0 e is the target policy. While this approach is simple to implement and can be used with most regression models, it relies heavily on model specification and overlap in the distributions of the behavior and evaluation policies. This gets even more complex in application domains where the physical process of the underlying environment is not well understood. In effect, most of the direct methods approaches suffer from high bias in the estimates, albeit with low variance for a sufficiently well-specified model. Some popular examples of algorithms using this approach for learning counterfactual predictions are the Bayesian Additive Regression Trees (BART)  [11]  and the Causal Forest  [50] .\n\nThe Inverse Propensity Weighting Method (IPW). The inverse propensity weighting approach seeks to correct for the distributional shift caused by the behavior policy by using the behavior policy \u03c0 b if known or an estimate \u03c0b (also known as propensity scores  [9] ) otherwise. The correction in distribution shifts is achieved using importance sampling in the estimator to evaluate the target policy. Mathematically, a generalized IPW estimator called the trimmed IPW (tIPW) is as follows:\n\nWhere \u03c4 is a lower bound on the propensity scores to reduce the effect of large weights on variance of the estimator. When \u03c4 = 0 this reduces to a classic IPW estimator. When \u03c4 = 0 this approach gives an unbiased estimate of the value of the target policy, however it suffers from high variance due to extreme values of propensity scores (e.g., a propensity score close to zero will give rise to approximately infinite weights). Some examples of algorithms using this approach are the Policy Optimizer for Exponential Models (POEM)  [46]  and the Offset tree  [6] .\n\nThe Doubly Robust Estimator (DR). The doubly robust approach combines the DM and IPW methods to achieve a balanced trade-off between bias and variance. This avoids extremely high bias and variance in the estimator. The DR estimator has been formalized by Dud\u00edk et al  [14]  as follows:\n\nThe DR estimator combines the DM (typically a maximum likelihood estimator) with the importance sampling of the residual from the DM approximator. This is described as doubly robust because if the DM model is correct, then the expected residual from the model E Y [ \u03b5] = 0, leaving the second term equal to zero for any arbitrary behavior policy \u03c0b ; similarly, if the \u03c0b is correctly estimated, then the second term is a consistent estimator of the error bias from the DM approximator. Though more robust, DR is error prone when both the DM and the behavior policy approximators are misspecified  [22] ."
    },
    {
      "title": "Algorithm 1 Generalized Algorithm for Policy Learning",
      "text": "Input: X, A, R.\n\nOutput: \u03c0 * (x).\n\n1: // Propensity Score Estimation 2: Fit Generalized Boosted Model f : X \u2192 A on S N = (X , A) to balance covariate distribution. 3: Obtain propensity score matrix P = f (x). 4: // Reward Imputation 5: fit a one-time logistic regression r : X \u00d7 A \u2192 R for each strategy 6: for r i j \u2208 R (a matrix of rewards). do 7:\n\nif DM method then 8:\n\nif DR method then 14:\n\nend if 16: end for 17: Set R = { rij } i=1:T , j=1:k the weighted reward matrix 18: // Policy Optimization 19: Fit logistic regression \u0125 : x \u2192 R on new training set (X , R). 20: // For policy \u03c0 * (x) 21: \u03c0 * (x) = argmax a \u2208A \u0125(r a |x) 22: return \u03c0 * (x).\n\nPropensity Score Estimation. As noted above, the behavior policy that generated the data is unknown and needs to be estimated from the data. This is achieved by estimating propensity scores, which represent the likelihood of choosing strategies in different contexts. Propensity scores also serve to reduce multivariate contextual data  [40]  into onedimensional scores such that treatment group distributions are matched. The goal of the propensity scores is to create a pseudo-population where the effect of selection bias due to unobserved confounders, as evidenced by distributional mismatch across strategies, is minimized.\n\nEnsuring overlap in the strategies with respect to the propensity scores reduces the possibility of extreme values in the IPW and DR estimation, given these approaches depend on the estimated score denoted \u03c0b (a|x) or Pij in the algorithm 1. Estimation methods such as logistic regression have typically been used but they are limited due to their linearity assumption  [29] . Recently, there are non-parametric machine learning models developed to add more flexibility in order to model more complex data, such as what we usually expect in human data. An example of a non-parametric model is Generalized Boosted Models (GBM). GBM estimation uses an iterative process with multiple regression trees to capture nonlinear relationships between strategies and context variables without over-fitting the data. We implemented GBM propensity score estimation in our analysis using the R package twang  [38] . We used the absolute standardized mean difference  [44]  as the stopping criteria over 5000 iterations.\n\nThe Learning Algorithms. In our experiments we used a multivariate logistic regression as the value function approximator that maps contexts to rewards for each ER strategy within the direct method and doubly robust estimators. We used logistic regression with \u2113 2 regularization for the ease of interpretation and replication in other studies. We will call the learner using direct method (DM) and the one using doubly-robust estimation as (DR) in our experimentation. The offset tree, denoted OT, is different in that it learns several binary regression trees for propensity weighted reward in each offset tree. More details can be found in Beygelzimer et al.  [6] . We compare the performance of these three approaches, and benchmark them against a random policy (i.e., randomly choosing one strategy from the 10 ER strategies) and the observed policy (i.e., what people reported using in the data).\n\nThe Evaluation of Learned Policies. Given the selection bias in the test data, we evaluate the performance of the different recommender algorithms using two variants of importance sampling approaches; namely, the inverse propensity weighting (IPW)(e.i.\u03c4 = 0) and the trimmed inverse propensity weighting (tIPW)(e.i. \u03c4 0) (see equation 4) by varying the parameter \u03c4 .\n\nWe consider both approaches because while the IPW provides an unbiased estimate of the mean policy reward with possibly high variance, the tIPW reduces the variance at the cost of more bias in the estimator. \u03c4 is a nuisance parameter and can be determined heuristically if \u03c4 < 1/k, where k is the number of strategies according to lemma 3.1 of Strehl et. al,  [43] . We compare the performance of each algorithm on the average reward on the test set."
    },
    {
      "title": "Design of ER Recommender System",
      "text": "Our contextual variables capture the user's state around the time to use a strategy. They are summarized in Table  1 . A combination of these variables allows us to provide contextual recommendation for ER strategies. For example, given that a user is at home in the evening with a trait social anxiety level of 30, we would recommend tackling issues head on if our algorithm predicts it to be the most effective strategy. The actions in our formulation are the top 10 most frequently used adaptive strategies, which are shown in the CMAB in Figure  1 . Admittedly, there are multiple ways to reduce dimensionality of the ER feature space and we explored additional approaches in other analyses. However, we chose to focus on this subset of strategies as they are mostly considered healthy strategies (i.e., they tend to be associated with positive health consequences, unlike a strategy such as using alcohol or drugs to change one's feelings) and were most frequently reported in our learning data.\n\nThe reward signal needs to reflect the effectiveness of the chosen strategy in the given context at helping to manage the participant's emotion. In our data, participants reported the perceived effectiveness of their ER attempt on a scale of 0-10. We binarized this outcome measure to define a reward signal for the agent. Our threshold was defined as the average of effectiveness scores across all users, or the grand mean. Let O(x i , a i ) denote the immediate effectiveness of the chosen ER strategy at time i in context x i , we have the grand mean as\n\n. The reward signal for each context x and action a is thus defined as:\n\nwhere 1 is an indicator function that returns 1 when the condition is satisfied, and 0 otherwise.\n\nTable 1: Contexts for the proposed contextual multi-armed bandit algorithm."
    },
    {
      "title": "Context Description",
      "text": "Social partners self-reported social relationship with people in the context (e.g., being with classmates, friends, strangers/acquaintances, romantic partner and family).\n\nSocial interaction self-reported social context (e.g., being alone, no interactions with others or being around them, and interaction with others).\n\nSocial preference self-reported social preference (e.g., more people, less people)."
    },
    {
      "title": "Motivation to change",
      "text": "self-reported motivation to change feelings on a 0-10 scale."
    },
    {
      "title": "Device OS",
      "text": "device platform (e.g., Android and iOS).\n\nSocial anxiety score self-reported social anxiety score using SIAS scale with 0-80 range."
    },
    {
      "title": "Time of day",
      "text": "this is a manual binning of periods of time in the day, (e.g., morning, midday, afternoon, and night)."
    },
    {
      "title": "Semnatic Location",
      "text": "Self-reported locations (e.g., the gym, home, in transition between locations, other homes, other locations, religious places, restaurant, school, shopping center or workplace).\n\nAccelerometer passively sensed measure of user movement (e.g., mean, energy and standard deviation).\n\nActivity Type passively recognized human activity types (e.g., cycling, stationary, walking and automotive)."
    },
    {
      "title": "Appropriateness of Timing",
      "text": "self-reported measure of how appropriate the timing was for sending an survey prompt on a scale of 0-10."
    },
    {
      "title": "EXPERIMENTS Study Design",
      "text": "After getting approval from the university's Institutional Review Board (IRB), N = 114 participants aged 18 years and older were recruited in a US college department and community to enroll in the present study. Participants were eligible to enroll if they scored at least 29 on the Social Interaction Anxiety Scale (SIAS) developed by Mattick & Clarke [28]. This cutoff was selected to recruit a sample experiencing moderate to severe social anxiety symptoms (scale range is 0-80). Four participants were excluded in the analysis due to missing data; specifically, 1 participant did not report any EMA data and 3 participants did not have any reports of effectiveness of an ER strategy, leaving 110 participants with the following demographics: 81 female, 29 male (no participants reported a non-binary gender identity); 86 undergraduates, 11 graduates or professional students, and 13 others; aged 18-34 with mean 20.41 and SD 2.98; 82 reported their race/ethnicity as White, 21 Asian, 7 African American, 3 Middle Eastern, 3 Native Hawaiian/Pacific Islander (numbers add up to more than 110 because some participants identified as multiple races). Their SIAS scores ranged from 29 to 73 (M = 46.68, SD = 10.39\n\n). Although the full SIAS was used for recruitment (for comparison to the reference group from prior published work), the sum of the straightforwardly-worded items was used for analyses, because the straightforwardly-worded items have been shown to have preferable psychometric properties to the full scale  [39] . A mobile app called MetricWire was installed on all par-ticipants\u00e2\u0102\u0179 personal smartphones to collect random time survey data for five weeks. Six identical surveys were sent randomly within each two hour window from 9am to 9pm daily. Participants were instructed to complete the surveys as promptly as possible upon receiving the notifications. If participants had not completed the survey within 30 minutes of the initial notification, the app sent a reminder notification. If not completed after 45 minutes, the survey disappeared. Participants were instructed to answer the survey with reference to when they received the initial survey notification. This instruction might introduce a small degree of recall bias into survey responses, but was included to enhance ecological validity by sampling a wide variety of situations in daily life, including situations in which it would be difficult to respond to a survey immediately (e.g., when a participant is taking an exam or in the middle of a conversation). Sensor data were also passively collected from participants' smartphones to capture their activity levels and GPS location. Table  1  summarizes the contextual features extracted from both survey and passive data."
    },
    {
      "title": "Data Processing",
      "text": "We used both the random time survey data and the sensor data from the study to obtain the contexts surrounding the reported ER strategy use and its effectiveness. All contextual variables are aligned with random time prompts using two hour windows. For example, accelerometer data within two hours prior to each survey starting time were aggregated to capture the level of activity for each reported ER strategy use. We transformed the x, y, z dimensions of the accelerometer using the formula 1  3 x 2 + y 2 + z 2 to obtain an orientation invariant measure for acceleration. Activity type data consisted of the activities recognized by MetricWire. These activities include stationary, walking, running, automotive, and cycling. The feature associated with each activity type is the sum total of its occurrence in the two hour window. Semantic locations such as home, transition, religious place, restaurant, school, shopping, someone else's house, work etc., provided by participants in the surveys were included in the context variables. Temporal features were created using four time windows: morning (9-12PM), mid-day(12 -3PM), late-afternoon (3-6PM), and night (6-9PM). Finally, we included other survey responses, such as rating the convenience of responding to the prompt when fired, and others summarized in Table  1  as context variables.\n\nThe original EMA data consists of 12742 learning samples from all participants. We excluded samples where participants did not report an effectiveness score for using ER strategies, either because they reported that they did not try to change their feelings (which is one option in the menu provided; 7617 samples were excluded for this reason) or because they used a strategy but skipped the survey prompt about effectiveness (239 samples were excluded for this reason). This leaves 4886 learning samples. 259 samples where important survey responses were missing (specifically, any missingness on reported convenience of responding to the prompt when fired, semantic location, or motivation to change feelings) were further excluded, leaving 4627 samples for analysis. We avoided imputing the 259 samples as these are self-reported ground truth data. On the other hand, we used multiple chained imputation to impute data on the passively sensed accelerometer and activity type data, which have missing rates of 65% and 68%, respectively. The MICE R package with classification and regression trees method was used for the imputation.\n\nThe remaining 4627 learning samples consisted of instances where participants reported choosing not only one strategy but also combinations of strategies in a menu of 20 strategies available to them in the survey. Our algorithm, however, considers the effect of a single strategy at a time. To accommodate this constraint, we split the samples in which more than one strategy was reported to have been used into multiple independent samples. For example, if a participant used a combination of eating food and distracting themselves in a given context, we treated this case as two separate samples in which a single strategy was used, and assigned the same effectiveness score to both. This allows us to retain all the data in which effectiveness was reported, increasing power, and not cut the common occurrence in which people report using more than one ER strategy, increasing generalizability. While we recognize this may reduce accuracy in parameter estimation as more bias is being introduced with this data augmentation approach because it is possible that the self-reported effectiveness score does not apply to all applied strategies equally, we felt the benefits for data retention and external validity were worth the trade-off. By augmenting the data this way, we obtain 6259 learning samples, including instances where any of the top 10 most adaptive strategies have been used. By contrast, restricting the data sample to instances where only one strategy was reported being used by the participants, we ended up with 2496 samples, which is about 1/3 of the data generated by the augmentation approach (contact the first author to see results for the CMAB analyses using this smaller dataset).\n\nWe used a total of 40 contextual variables summarized in Table  3 , consisting of binary variables (e.g., semantic locations, social partner(s) vs. alone, etc.) and continuous variables, including convenience of responding to the prompt when fired, motivation to change, SIAS score (SIASsf), activity types, and accelerometer features. The continuous variables were scaled to a range between [0, 1] to avoid biasing coefficient estimations toward the continuous variables."
    },
    {
      "title": "RESULTS",
      "text": "Our results as summarized in Table  2  show the mean reward across the different recommender algorithms and baselines. We report the mean reward with standard errors on a 5fold cross validation (due to relatively small data), and test for level of significance using an independent samples ttest at \u03b1 = 0.05. The parameter \u03c4 regulates the effect of extremely large weights due to low propensity scores by capping all scores below the chosen value of \u03c4 . Note also that \u03c4 uses the same value in both learning and evaluation for each policy. The algorithm learned with doubly robust estimator (DR) outperforms all its competitors, including the Offset Tree (OT) and the DM learner. This can be seen from its absolute mean reward and the tight confidence bounds for all values of \u03c4 . This implies that the doubly robust method achieves the right trade-off between high variance and high bias, at least relative to the other approaches tested, making it a more more reliable statistical estimator of off-policy performance in our data. We also see that the gap between the Offset tree and the DR get closer as the value of \u03c4 is increased. This is as expected as the classic OT algorithm is heavily dependent on the inverse propensity weighting and thus more affected by high variance. Notice that the parameter values of \u03c4 are set below 0.1 to match with the theoretical constraint developed in Lemma 3.1 of  [43] . Also note that the DM, Random, and Observed policies are affected by the parameter \u03c4 only in the evaluation stage, but they still benefit from less variance in the mean reward estimation on the test set. To probe deeper into a qualitative evaluation of the DR algorithm, we examine the effect sizes of several contextual variables in the learning stage in terms of how they predict individual strategies. These effect sizes are summarized in Table  3 . Contextual variables with a positive effect size can be interpreted as increasing the odds of positive rewards if that strategy is chosen within that context and vice versa for negative effect sizes. For example, the chances are high the strategy will be perceived as effective if the user is recommended to seek advice or comfort from others when they have recently been stationary because the effect size is 1.07. Note that the effect sizes in bold are statistically significant at \u03b1 = 0.05.\n\nWhile there are many significant effects, pointing to the importance of many contextual factors in ER, a few context variables are notable for their large effect sizes. Overall, the contextual predictors that tended to have the largest absolute effect sizes (indicating that they are the most important in determining effectiveness) are the convenience of responding to the prompt when fired, motivation to change thoughts/feelings, trait social anxiety symptoms, accelerometer features, and certain activity types (see Figure  2  for a ranking of contextual features from most to least important, as defined by the absolute value of their effect sizes). This suggests that a person's movement helps to determine what ER strategies are most likely to help them feel they have effectively regulated their emotions. The predicted effectiveness of strategies increased when it was a convenient time to be interrupted with a survey prompt, pointing to the importance of timing in interventions (and suggesting that JITAIs may be a step in the right direction). Notably, effect sizes for time of day were smaller than effect sizes for convenient time for interruption, suggesting personalized timing for ER strategy implementation may be particularly helpful. Strategies were predicted to be less effective for more (vs. less) socially anxious participants, even among this sample where all participants were elevated in social anxiety symptoms at baseline), providing further evidence of emotion dysregulation in this population. Higher motivation to change thoughts/feelings predicted higher effectiveness ratings tied to the ER strategy 'doing something fun with others,' but lower effectiveness ratings tied to the ER strategy distraction, demonstrating that contexts can change the effectiveness of different strategies in opposing directions."
    },
    {
      "title": "DISCUSSION",
      "text": "This study provides evidence that a contextual bandits recommender algorithm may be used to improve ER, based on the current finding that the best performing algorithm, the learner with doubly robust estimation (DR), outperforms the observed ER of socially anxious participants. Further, contexts matter for effective ER, based on our finding that the DR algorithm also outperforms the random algorithm.\n\nThe results from this paper have broad implications for the design and analysis of future recommender systems algorithms. By leveraging the abundance of available observational data from previous studies or interactive systems, a researcher might be able to estimate the usefulness of a novel recommender algorithm before deployment. Recent theoretical studies  [53]  suggest that combining offline policy learning together with online approaches leads to data efficient exploration and adaptations in the online setting. This could potentially reduce the user attrition or disengagement problem that plagues most interactive systems and ecological momentary assessment studies  [48] . In addition, a researcher could use this method to determine the most critical features that affect the effectiveness of ER strategies in order to collect the most salient data for a new study when resources are limited. Some of the strategies included in this recommender algorithm are cognitive, meaning that they involve a change in thinking (e.g., accepting thoughts/feelings), whereas others are behavioral, meaning that they involve a change in actions (e.g., eating food). Notably, contexts do not seem to have the same effect on strategies of the same cognitive/behavioral type. For example, our findings indicate that walking makes it more likely that thinking about things that went/are going well will be an effective strategy, and less likely that thinking of the situation differently will be effective. The distinction between these two specific strategies is subtle; for one, you are trying to think of positive things that may or may not be related to the situation at hand, and for the other, you are focused on the situation at hand but trying to notice other aspects of it or conceptualize it in a different way.\n\nRegarding the social strategies in this recommender algorithm (those that use other people to change emotions; e.g., seeking advice/comfort from others), some surprising patterns emerged with social context variables, though with small effect sizes. For example, seeking advice/comfort from others was more likely to help when a user was around strangers and less likely to help when a user was around classmates. While it might be expected that this would be a more helpful strategy when a user was around friends, a romantic partner, or family, none of these contexts had significant effects on this strategy, suggesting that it would be interesting to see whether these patterns would persist if these recommendations were deployed to users. One interesting question that cannot be answered with the current study is how people sought social support; it is possible that people texted or called a friend when they were around strangers, so they may have still used friends to regulate even when those people were not immediately available in their physical environment. Strategies were generally predicted to be more effective when users were interacting with others than when they were alone or around others but not interacting with them, suggesting that the involvement of others might help users regulate effectively.\n\nThe effect sizes in Table  3  have some implications for the design of future studies. In order to minimize participant burden and to maximize the usefulness of the data collected,\n\nAfternoon Mid-Day Android iOS Night Morning Around Home Alone School Interacting Transit Classmates Romantic Other Places Other Home Slightly Fewer A Bit More A Lot Fewer Family Acquaintances Work Restaurant Friend Shopping Same More People Gym Religious Place Cycling Running Motiv2Change SIASsf Stationary Mean Acc Walking Automotive Std Acc Energy Acc Appropriate 0 2 4 6 Sum of Absolute Effect Sizes a researcher might focus more on collecting the most important features (i.e., those that have the largest effect sizes in predicting the 10 strategies considered in this paper). The most important features were appropriateness of the time to be interrupted; energy, standard deviation, and mean of acceleration; whether participants had recently been in a car, walking, or stationary, their social anxiety symptom severity, and their motivation to change their thoughts/feelings. These important contextual features are all either continuous or discrete variables with many possible values; the less important contextual features are binary. This suggests that future researchers may aim to maximize the predictive value of their contextual variables by considering contextual variables with more variability in their values, as opposed to binary variables. Many of these more important contextual features also reflected movement, so future researchers may wish to preferentially include sensors that capture information about motion. The current algorithms work to maximize short-term perceived effectiveness of regulating emotions, given the ER strategy attempt and effectiveness rating are reported close in time. However, psychologists have noted that both shortterm and long-term regulation are important, with strategies differing in their effectiveness at different timescales  [17] . For example, if you are anxious about an assignment due in a few days, watching TV might make you feel better for 30 minutes but leave you feeling anxious the next day, whereas tackling the issue and starting the assignment might feel worse for the next 30 minutes but make you feel better the next day. While CMAB optimizes for short-term ER effectiveness, evaluating the algorithms for longer-term effectiveness, examining a wider range of ER effectiveness indicators, and examining the algorithms in more diverse samples may all be beneficial directions for future work. Another limitation of this work is that when this policy is deployed, a user will initially need to request an intervention before the most contextually effective strategy is suggested; ultimately, the goal is to be able to passively determine future emotional states and send interventions without the user's initiation."
    },
    {
      "title": "CONCLUSION",
      "text": "In this work, we present a novel application for contextual bandits to learn contextually effective strategies for ER. Our approach is distinct from most existing work in health recommender systems in that we learn an initial policy that might have a positive impact on user engagement when finally deployed, as well as on sample efficiency in the online setting. Our results demonstrate that an experimenter can use available observational data to learn the usefulness of a new intervention policy; this may provide an efficient way to generate hypotheses that can later be tested in (resource intensive) randomized clinical trials. Given that ER is impaired across many mental illnesses, this work has the potential to enhance the availability of scalable interventions that can be used in daily life for many people."
    },
    {
      "text": "Figure 1: Learning initial policy for emotion regulation (ER) using offline learning in contextual multi-armed bandit."
    },
    {
      "text": "Figure 2: Ranking of contextual variables showing most critical features in determining the effectiveness of strategies. The ranking is based on the sum of absolute values of effect sizes."
    },
    {
      "text": "Mean reward by policy (mean \u00b1 std). Superscripts \u2020 and * respectively represent statistical significant at \u03b1 = 0.05 over random and behavior policy baselines."
    },
    {
      "text": "Coefficients(rounded to 2 decimal places) of Contextual Predictors of Strategies (Strats). The strategies are mapped as follows; Seeking advice/comfort from others(S1), Eating food(S2), Doing something fun with others(S3), Distracting myself (S4), TV/internet/gaming(S5), Thinking about things that went/are going well(S6), Thinking of the situation differently(S7), Coming up with ideas/plans for action(S8), Accepting them(S9) and Tackling the issue head on(S10)"
    }
  ],
  "references": [
    {
      "title": "The Future of Emotion Regulation Research: Capturing Context",
      "authors": [
        "Amelia Aldao"
      ],
      "year": 2013,
      "doi": "10.1177/1745691612459518"
    },
    {
      "title": "One versus many: Capturing the use of multiple emotion regulation strategies in response to an emotion-eliciting stimulus",
      "authors": [
        "Amelia Aldao",
        "Susan Nolen-Hoeksema"
      ],
      "year": 2013,
      "doi": "10.1080/02699931.2012.739998"
    },
    {
      "title": "Emotion-regulation strategies across psychopathology: A metaanalytic review",
      "authors": [
        "Amelia Aldao",
        "Susan Nolen-Hoeksema",
        "Susanne Schweizer"
      ],
      "year": 2010,
      "doi": "10.1016/j.cpr.2009.11.004"
    },
    {
      "title": "Mental Health In America -Access To Care Data",
      "doi": "10.4324/9781315189857-4"
    },
    {
      "title": "Deeptreat: Learning optimal personalized treatments from observational data using neural networks",
      "authors": [
        "James Onur Atan",
        "Mihaela Jordon",
        "Van Der Schaar"
      ],
      "year": 2018
    },
    {
      "title": "The offset tree for learning with partial labels",
      "authors": [
        "Alina Beygelzimer",
        "John Langford"
      ],
      "year": 2009,
      "doi": "10.1145/1557019.1557040"
    },
    {
      "title": "Regulatory Flexibility: An Individual Differences Perspective on Coping and Emotion Regulation",
      "authors": [
        "George Bonanno",
        "Charles Burton"
      ],
      "year": 2013,
      "doi": "10.1177/1745691613504116"
    },
    {
      "title": "Affective disorders and suicide risk: A reexamination",
      "authors": [
        "J Bostwick",
        "V Pankratz"
      ],
      "year": 2000,
      "doi": "10.1176/appi.ajp.157.12.1925"
    },
    {
      "title": "Statistical methods for dynamic treatment regimes",
      "authors": [
        "Bibhas Chakraborty"
      ]
    },
    {
      "title": "Evaluation of a recommender app for apps for the treatment of depression and anxiety: an analysis of longitudinal user engagement",
      "authors": [
        "Ken Cheung",
        "Wodan Ling",
        "Chris Karr",
        "Kenneth Weingardt",
        "Stephen Schueller",
        "David Mohr"
      ],
      "year": 2018,
      "doi": "10.1093/jamia/ocy023"
    },
    {
      "title": "BART: Bayesian additive regression trees",
      "authors": [
        "Edward Hugh A Chipman",
        "Robert George",
        "Mcculloch"
      ],
      "year": 2010
    },
    {
      "title": "Emotion regulation in context: Examining the spontaneous use of strategies across emotional intensity and type of emotion",
      "authors": [
        "Katherine Dixon-Gordon",
        "Amelia Aldao",
        "Andres De",
        "Los Reyes"
      ],
      "year": 2015,
      "doi": "10.1016/j.paid.2015.06.011"
    },
    {
      "title": "Toward a Personalized Science of Emotion Regulation",
      "authors": [
        "Bruce Dor\u00e9",
        "Jennifer Silvers",
        "Kevin Ochsner"
      ],
      "year": 2016,
      "doi": "10.1111/spc3.12240"
    },
    {
      "title": "Doubly robust policy evaluation and optimization",
      "authors": [
        "Miroslav Dud\u00edk",
        "Dumitru Erhan",
        "John Langford",
        "Lihong Li"
      ],
      "year": 2014
    },
    {
      "title": "Efficient optimal learning for contextual bandits",
      "authors": [
        "Miroslav Dudik",
        "Daniel Hsu",
        "Satyen Kale",
        "Nikos Karampatziakis",
        "John Langford",
        "Lev Reyzin",
        "Tong Zhang"
      ],
      "year": 2011
    },
    {
      "title": "Emotion Regulation: A Transdiagnostic Perspective on a New RDoC Domain",
      "authors": [
        "Katya Fernandez",
        "Hooria Jazaieri",
        "James Gross"
      ],
      "year": 2016,
      "doi": "10.1007/s10608-016-9772-2"
    },
    {
      "title": "Regulating emotion in the short and long term",
      "authors": [
        "Antonio Freitas",
        "Peter Salovey"
      ],
      "year": 2000
    },
    {
      "title": "The emerging field of emotion regulation: An integrative review",
      "authors": [
        "J James",
        "Gross"
      ],
      "year": 1998
    },
    {
      "title": "Back to Basics: A Naturalistic Assessment of the Experience and Regulation of Emotion",
      "authors": [
        "Jane Heiy",
        "Jennifer Cheavens"
      ],
      "year": 2014,
      "doi": "10.1037/a0037231"
    },
    {
      "title": "The effectiveness of telemental health: A 2013 review",
      "authors": [
        "Donald Hilty",
        "Daphne Ferrer",
        "Michelle Parish",
        "Barb Johnston",
        "Edward Callahan",
        "Peter Yellowlees"
      ],
      "year": 2013,
      "doi": "10.1089/tmj.2013.0075"
    },
    {
      "title": "A stress-free life: just-in-time interventions for stress via real-time forecasting and intervention adaptation",
      "authors": [
        "Martin Luis G Jaimes",
        "Andrew Llofriu",
        "Raij"
      ],
      "year": 2014
    },
    {
      "title": "Demystifying double robustness: A comparison of alternative strategies for estimating a population mean from incomplete data",
      "authors": [
        "Joseph Joseph Dy Kang",
        "Schafer"
      ],
      "year": 2007
    },
    {
      "title": "Lifetime Prevalence and Age-of-Onset Distributions of DSM-IV Disorders in the National Comorbidity Survey Replication",
      "authors": [
        "Patricia Ronald C Kessler",
        "Olga Berglund",
        "Robert Demler",
        "Kathleen Jin",
        "Ellen Merikangas",
        "Walters"
      ],
      "year": 2005,
      "doi": "10.1001/archpsyc.62.6.593"
    },
    {
      "title": "A contextual-bandit approach to personalized news article recommendation",
      "authors": [
        "Lihong Li",
        "Wei Chu",
        "John Langford",
        "Robert Schapire"
      ],
      "year": 2010,
      "doi": "10.1145/1772690.1772758"
    },
    {
      "title": "Personalized heartsteps: A reinforcement learning algorithm for optimizing physical activity",
      "authors": [
        "Peng Liao",
        "Kristjan Greenewald",
        "Predrag Klasnja",
        "Susan Murphy"
      ],
      "year": 2020,
      "doi": "10.1145/3381007"
    },
    {
      "title": "Demographics of the U.S. Psychology Workforce: Findings from the 2007-16 American Community Survey",
      "authors": [
        "Luona Lin",
        "Karen Stamm",
        "Peggy Christidis"
      ],
      "year": 2018
    },
    {
      "title": "Emotion-Driven Reinforcement Learning",
      "authors": [
        "Robert Marinier",
        "John Laird",
        "Robert P Marinier Iii"
      ],
      "year": 2008,
      "doi": "10.1016/j.cogsys.2008.03.004"
    },
    {
      "title": "Development and validation of measures of social phobia scrutiny fear and social interaction anxiety",
      "authors": [
        "P Richard",
        "J Mattick",
        "Clarke Christopher"
      ],
      "year": 1998
    },
    {
      "title": "A tutorial on propensity score estimation for multiple treatments using generalized boosted models",
      "authors": [
        "Beth Daniel F Mccaffrey",
        "Ann Griffin",
        "Daniel Almirall",
        "Mary Slaughter",
        "Rajeev Ramchand",
        "Lane Burgette"
      ],
      "year": 2013
    },
    {
      "title": "The state of US health, 1990-2010: burden of diseases, injuries, and risk factors",
      "authors": [
        "J Christopher",
        "Jerry Murray",
        "Mohammed Abraham",
        "Miriam Ali",
        "Charles Alvarado",
        "Larry Atkinson",
        "David Baddour",
        "Emelia Bartels",
        "Kavi Benjamin",
        "Gretchen Bhalla",
        "Birbeck"
      ],
      "year": 2013
    },
    {
      "title": "Just-intime adaptive interventions (JITAIs) in mobile health: key components and design principles for ongoing health behavior support",
      "authors": [
        "Inbal Nahum-Shani",
        "Shawna Smith",
        "Bonnie Spring",
        "Linda Collins",
        "Katie Witkiewitz",
        "Ambuj Tewari",
        "Susan Murphy"
      ],
      "year": 2017
    },
    {
      "title": "Gender and age differences in emotion regulation strategies and their relationship to depressive symptoms",
      "authors": [
        "Susan Nolen-Hoeksema",
        "Amelia Aldao"
      ],
      "year": 2011,
      "doi": "10.1016/j.paid.2011.06.012"
    },
    {
      "title": "Improving sepsis treatment strategies by combining deep and kernel-based reinforcement learning",
      "authors": [
        "Xuefeng Peng",
        "Yi Ding",
        "David Wihl",
        "Omer Gottesman",
        "Matthieu Komorowski",
        "Li-Wei H Lehman",
        "Andrew Ross",
        "Aldo Faisal",
        "Finale Doshi-Velez"
      ],
      "year": 2018
    },
    {
      "title": "Towards health recommendation systems: an approach for providing automated personalized health feedback from mobile data",
      "authors": [
        "Mashfiqui Rabbi",
        "Min Hane Aung",
        "Tanzeem Choudhury"
      ],
      "year": 2017
    },
    {
      "title": "MyBehavior: automatic personalized health feedback from user behaviors and preferences using smartphones",
      "authors": [
        "Mashfiqui Rabbi",
        "Min Aung",
        "Mi Zhang",
        "Tanzeem Choudhury"
      ],
      "year": 2015
    },
    {
      "title": "Predicting about-to-eat moments for just-in-time eating intervention",
      "authors": [
        "Tauhidur Rahman",
        "Mary Czerwinski",
        "Ran Gilad-Bachrach",
        "Paul Johns"
      ],
      "year": 2016,
      "doi": "10.1145/2896338.2896359"
    },
    {
      "title": "Classifying emotion regulation strategies",
      "authors": [
        "Candace Raio",
        "Elizabeth Goldfarb",
        "Karolina Lempert",
        "Peter Sokol-Hessner"
      ],
      "year": 2016,
      "doi": "10.1038/nrn.2016.78"
    },
    {
      "title": "Toolkit for Weighting and Analysis of Nonequivalent A tutorial for the twang package",
      "authors": [
        "Greg Ridgeway",
        "Dan Mccaffrey",
        "Andrew Morral",
        "Lane Burgette",
        "Beth Griffin"
      ],
      "doi": "10.32614/cran.package.twang"
    },
    {
      "title": "The reverse of social anxiety is not always the opposite: The reversescored items of the Social Interaction Anxiety Scale do not belong",
      "authors": [
        "Carol Thomas L Rodebaugh",
        "Richard Woods",
        "Heimberg"
      ],
      "year": 2007
    },
    {
      "title": "The central role of the propensity score in observational studies for causal effects",
      "authors": [
        "R Paul",
        "Donald Rosenbaum",
        "Rubin"
      ],
      "year": 1983
    },
    {
      "title": "Emotion regulation choice: A conceptual framework and supporting evidence",
      "authors": [
        "Gal Sheppes",
        "Susanne Scheibe",
        "Gaurav Suri",
        "Peter Radu",
        "Jens Blechert",
        "James Gross"
      ],
      "year": 2014,
      "doi": "10.1037/a0030831"
    },
    {
      "title": "Emotion regulation as a transdiagnostic treatment construct across anxiety, depression, substance, eating and borderline personality disorders: A systematic review",
      "authors": [
        "Elise Sloan",
        "Kate Hall",
        "Richard Moulding",
        "Shayden Bryce",
        "Helen Mildred",
        "Petra Staiger"
      ],
      "year": 2016,
      "doi": "10.1016/j.cpr.2017.09.002"
    },
    {
      "title": "Learning from logged implicit exploration data",
      "authors": [
        "Alex Strehl",
        "John Langford",
        "Lihong Li",
        "M Sham",
        "Kakade"
      ],
      "year": 2010
    },
    {
      "title": "Prognostic score-based balance measures can be a useful diagnostic for propensity score methods in comparative effectiveness research",
      "authors": [
        "Elizabeth Stuart",
        "Brian Lee",
        "Finbarr Leacy"
      ],
      "year": 2013,
      "doi": "10.1016/j.jclinepi.2013.01.013"
    },
    {
      "title": "Emotion regulation choice: the role of environmental affordances",
      "authors": [
        "Gaurav Suri",
        "Gal Sheppes",
        "Gerald Young",
        "Damon Abraham",
        "Kateri Mcrae",
        "James Gross"
      ],
      "year": 2018,
      "doi": "10.1080/02699931.2017.1371003"
    },
    {
      "title": "Batch learning from logged bandit feedback through counterfactual risk minimization",
      "authors": [
        "Adith Swaminathan",
        "Thorsten Joachims"
      ],
      "year": 2015
    },
    {
      "title": "Discover the expert: Context-adaptive expert selection for medical diagnosis",
      "authors": [
        "Cem Tekin",
        "Onur Atan",
        "Mihaela Van",
        "Der Schaar"
      ],
      "year": 2014,
      "doi": "10.1109/tetc.2014.2386133"
    },
    {
      "title": "From ads to interventions: Contextual bandits in mobile health",
      "authors": [
        "Ambuj Tewari",
        "Susan Murphy"
      ],
      "year": 2017
    },
    {
      "title": "A Person-by-Situation Approach to Emotion Regulation: Cognitive Reappraisal Can Either Help or Hurt, Depending on the Context",
      "authors": [
        "Allison Troy",
        "Amanda Shallcross",
        "Iris Mauss"
      ],
      "year": 2013,
      "doi": "10.1177/0956797613496434"
    },
    {
      "title": "Estimation and inference of heterogeneous treatment effects using random forests",
      "authors": [
        "Stefan Wager",
        "Susan Athey"
      ],
      "year": 2018,
      "doi": "10.1080/01621459.2017.1319839"
    },
    {
      "title": "emHealth: towards emotion health through depression prediction and intelligent health recommender system",
      "authors": [
        "Shiqi Yang",
        "Ping Zhou",
        "Kui Duan",
        "M Shamim Hossain",
        "Mohammed Alhamid"
      ],
      "year": 2018,
      "doi": "10.1007/s11036-017-0929-3"
    },
    {
      "title": "Encouraging physical activity in patients with diabetes: intervention using a reinforcement learning system",
      "authors": [
        "Elad Yom-Tov",
        "Guy Feraru",
        "Mark Kozdoba",
        "Shie Mannor",
        "Moshe Tennenholtz",
        "Irit Hochberg"
      ],
      "year": 2017,
      "doi": "10.2196/jmir.7994"
    },
    {
      "title": "Transfer learning in multiarmed bandit: a causal approach",
      "authors": [
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "year": 2017
    }
  ],
  "num_references": 53
}
