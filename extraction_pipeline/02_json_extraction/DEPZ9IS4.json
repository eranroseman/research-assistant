{
  "paper_id": "DEPZ9IS4",
  "title": "Ethical Considerations in Artificial Intelligence Interventions for Mental Health and Well-Being: Ensuring Responsible Implementation and Impact",
  "abstract": "AI has the potential to revolutionize mental health services by providing personalized support and improving accessibility. However, it is crucial to address ethical concerns to ensure responsible and beneficial outcomes for individuals. This systematic review examines the ethical considerations surrounding the implementation and impact of artificial intelligence (AI) interventions in the field of mental health and well-being. To ensure a comprehensive analysis, we employed a structured search strategy across top academic databases, including PubMed, PsycINFO, Web of Science, and Scopus. The search scope encompassed articles published from 2014 to 2024, resulting in a review of 51 relevant articles. The review identifies 18 key ethical considerations, including 6 ethical considerations associated with using AI interventions in mental health and wellbeing (privacy and confidentiality, informed consent, bias and fairness, transparency and accountability, autonomy and human agency, and safety and efficacy); 5 ethical principles associated with the development and implementation of AI technologies in mental health settings to ensure responsible practice and positive outcomes (ethical framework, stakeholder engagement, ethical review, bias mitigation, and continuous evaluation and improvement); and 7 practices, guidelines, and recommendations for promoting the ethical use of AI in mental health interventions (adhere to ethical guidelines, ensure transparency, prioritize data privacy and security, mitigate bias and ensure fairness, involve stakeholders, conduct regular ethical reviews, and monitor and evaluate outcomes). This systematic review highlights the importance of ethical considerations in the responsible implementation and impact of AI interventions for mental health and well-being. By addressing privacy, bias, consent, transparency, human oversight, and continuous evaluation, we can ensure that AI interventions like chatbots and AI-enabled medical devices are developed and deployed in an ethically sound manner, respecting individual rights, promoting fairness, and maximizing benefits while minimizing potential harm.",
  "year": 2024,
  "date": "2024-07-22",
  "journal": "Risk Management and Healthcare Policy",
  "publication": "Risk Management and Healthcare Policy",
  "authors": [
    {
      "forename": "Hamid",
      "surname": "Saeidnia",
      "name": "Hamid Saeidnia",
      "affiliation": "1  Department of Knowledge and Information Science , Tarbiat Modares University , Tehran 14115-111 , Iran; \n\t\t\t\t\t\t\t\t Department of Knowledge and Information Science \n\t\t\t\t\t\t\t\t Tarbiat Modares University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 14115-111 \n\t\t\t\t\t\t\t\t\t Tehran \n\t\t\t\t\t\t\t\t\t Iran;",
      "email": "hamidrezasaednia@modares.ac.ir"
    },
    {
      "forename": "Seyed",
      "surname": "Ghasem",
      "name": "Seyed Ghasem"
    },
    {
      "forename": "Hashemi",
      "surname": "Fotami",
      "name": "Hashemi Fotami",
      "affiliation": "2  Department of Computer Science , Tarbiat Modares University , Tehran 14115-111 , Iran; \n\t\t\t\t\t\t\t\t Department of Computer Science \n\t\t\t\t\t\t\t\t Tarbiat Modares University \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 14115-111 \n\t\t\t\t\t\t\t\t\t Tehran \n\t\t\t\t\t\t\t\t\t Iran;"
    },
    {
      "forename": "Brady",
      "surname": "Lund",
      "name": "Brady Lund",
      "affiliation": "3  Department of Information Science , University of North Texas , Denton , TX 76203 , USA; \n\t\t\t\t\t\t\t\t Department of Information Science \n\t\t\t\t\t\t\t\t University of North Texas \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 76203 \n\t\t\t\t\t\t\t\t\t Denton \n\t\t\t\t\t\t\t\t\t TX \n\t\t\t\t\t\t\t\t\t USA;",
      "email": "brady.lund@unt.edu"
    },
    {
      "forename": "Nasrin",
      "surname": "Ghiasi",
      "name": "Nasrin Ghiasi",
      "affiliation": "4  Department of Public Health , School of Health , Ilam University of Medical Sciences , Ilam 69391-77143 , Iran \n\t\t\t\t\t\t\t\t Department of Public Health \n\t\t\t\t\t\t\t\t School of Health \n\t\t\t\t\t\t\t\t Ilam University of Medical Sciences \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t 69391-77143 \n\t\t\t\t\t\t\t\t\t Ilam \n\t\t\t\t\t\t\t\t\t Iran",
      "email": "ghiasi-n@medilam.ac.ir"
    }
  ],
  "doi": "10.3390/socsci13070381",
  "arxiv": "arXivarXiv:2104.06910",
  "keywords": [
    "artificial intelligence",
    "mental health",
    "ethics",
    "well-being",
    "interventions"
  ],
  "sections": [
    {
      "title": "Introduction",
      "text": "Artificial intelligence (AI) is a rapidly advancing technology that involves the development of systems capable of performing tasks that typically require human intelligence, such as learning, problem solving, and decision making  (Chalyi 2024; Saeidnia 2023 ). In the field of health, AI has emerged as a powerful tool with the potential to transform various aspects of healthcare delivery, diagnosis, treatment, and patient care  (Reddy et al. 2019) . By leveraging data analytics, machine learning algorithms, and predictive modeling, AI has the capacity to revolutionize the way healthcare services are delivered and improve patient outcomes  (Alowais et al. 2023; Yelne et al. 2023) .\n\nIn recent years, AI has also made significant inroads into the field of mental health and well-being  (Yelne et al. 2023) . Mental health disorders such as depression, anxiety, and PTSD represent a growing global health burden, with millions of individuals in need of support and treatment  (Wainberg et al. 2017; Charlson et al. 2019 ). AI technologies have been utilized to develop innovative interventions aimed at addressing these challenges by improving access to care, enhancing treatment outcomes, and providing personalized support to individuals in need  (Mennella et al. 2024) . From chatbots and virtual therapists (referring to digital, remote mental health support and treatment, whether delivered by AI systems, human therapists, or a combination of both) to predictive analytics for early intervention, AI interventions in mental health hold great promise for improving the quality and effectiveness of mental healthcare services  (Balcombe 2023) .\n\nThe potential benefits of artificial intelligence in mental health are multifaceted  (Baskin et al. 2021; Carr 2020) . AI-based interventions have the capacity to provide timely and personalized support to individuals experiencing mental health challenges, thereby improving their overall well-being (S. Graham et al. 2019; Shah 2022) . By analyzing vast amounts of data, AI systems can identify patterns and trends that may not be apparent to human clinicians, leading to more accurate diagnoses and treatment recommendations  (Alowais et al. 2023; Faezi and Alinezhad 2024) . AI tools can also help bridge the gap in mental health services by reaching underserved populations, reducing barriers to access, and increasing the efficiency of healthcare delivery (V. Singh et al. 2024) .\n\nAlongside the potential benefits of AI in mental health, however, there are also significant ethical consequences that must be carefully considered  (Jeyaraman et al. 2023) . The use of AI in health care, particularly in sensitive areas such as mental health, raises complex ethical dilemmas related to privacy, consent, transparency, accountability, bias, and the potential for unintended harm  (Farhud and Zokaei 2021; Thakkar et al. 2024 ). Issues such as data security, algorithmic bias, and the impact of automation on the patient-provider relationship are critical considerations that must be addressed to ensure the responsible and ethical implementation of AI interventions in mental health settings  (Alowais et al. 2023; B\u00e9lisle-Pipon et al. 2022; Davahli et al. 2021; Gaonkar et al. 2023; Sarah Graham et al. 2019; Jeyaraman et al. 2023; Khanna and Srivastava 2020) .\n\nAgainst this backdrop, this systematic review study aims to critically examine the ethical considerations surrounding the use of artificial intelligence in mental health interventions. By synthesizing existing literature and research findings, our goal is to shed light on the key ethical challenges and opportunities associated with the integration of AI technologies in mental health care. We seek to identify best practices, guidelines, and recommendations for promoting responsible implementation and ensuring the positive impact of AI interventions on individuals' mental health and overall well-being. Through this review, we aim to contribute to a better understanding of how ethical principles can be upheld in the development and deployment of AI solutions in mental health, ultimately enhancing the quality and accessibility of mental healthcare services while safeguarding the rights and dignity of individuals receiving care."
    },
    {
      "title": "Methods and Materials",
      "text": "In this study, we critically analyze the ethical considerations related to the utilization of artificial intelligence in mental health interventions. Throughout the process of manuscript preparation, we followed the guidelines outlined by  (Smith et al. 2011) , with a specific focus on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines  (Page et al. 2021) ."
    },
    {
      "title": "Research Questions",
      "text": "1. What are the key ethical considerations associated with the use of artificial intelligence interventions in mental health and well-being? 2. How can ethical principles be integrated into the development and implementation of AI technologies in mental health settings to ensure responsible practice and positive outcomes?\n\n3. What are the best practices, guidelines, and recommendations for promoting ethical use of AI in mental health interventions?"
    },
    {
      "title": "Inclusion and Exclusion Criteria",
      "text": "This systematic review applied the following inclusion and exclusion criteria."
    },
    {
      "title": "Inclusion Criteria",
      "text": "The inclusion criteria for this review study encompass studies that focus on the ethical considerations surrounding the use of artificial intelligence interventions in mental health and well-being. Including studies that address ethical considerations ensures a comprehensive understanding of the potential implications of AI in mental health interventions. Additionally, studies investigating the impact of AI on mental health outcomes are crucial for evaluating the effectiveness and potential risks associated with these technologies. All types of articles, including reviews, original research, short communications, and letters to the editor, are considered for inclusion to provide a diverse range of perspectives and insights on the topic. This approach allows for a thorough examination of the current literature on AI in mental health, regardless of the format in which the information is presented. Finally, limiting the inclusions to publications in the English language ensures consistency in data interpretation and accessibility for the review process."
    },
    {
      "title": "Exclusion Criteria",
      "text": "The exclusion criteria for this review study involve excluding studies that do not specifically address the ethical implications of AI interventions in mental health, as the primary focus of this review is on the ethical considerations associated with AI technologies in mental health and well-being. Additionally, studies that primarily emphasize the technical aspects of AI algorithms without integrating discussions on ethical considerations are excluded, as the ethical dimension is a key aspect of interest in this review. Publications in languages other than English are also excluded to maintain consistency in data interpretation and ensure accessibility for the research process. By applying these exclusion criteria, this review aims to focus on studies that provide comprehensive insights into the ethical implications of AI interventions in mental health."
    },
    {
      "title": "Databases and Search Method",
      "text": "We conducted a comprehensive literature search across the following databases: 1.\n\nPubMed; 2.\n\nPsycINFO; 3.\n\nScopus; 4.\n\nWeb of Science; 5.\n\nGoogle Scholar.\n\nSearch terms included combinations of keywords related to artificial intelligence, mental health, ethics, well-being, and interventions. Boolean operators (AND, OR) were used to refine search queries and identify relevant studies. The search scope spanned a decade between 2014 and 2024. We conducted a manual search of Google Scholar to enhance the scope of our search and identify additional relevant articles. This method enabled us to expand our search beyond the initial database search and uncover a broader range of scholarly articles related to our research topic.\n\nThe search strategy was designed to capture a broad range of articles addressing the ethical implications of AI interventions in mental health. While there were slight variations in the specific search terms and strings used across databases, they maintained a consistent structure. Additional information can be found in Supplementary File S1."
    },
    {
      "title": "Study Selection",
      "text": "Our study selection process involved a meticulous review of article titles and abstracts by each researcher to assess relevance to our inclusion criteria, focusing on the ethical considerations of artificial intelligence interventions in mental health. Conflicting articles were promptly excluded, and input from other scholars was sought when doubts arose, ensuring a consensus-based final selection by the research team. This rigorous approach aimed to maintain consistency and rigor in the selection process, address uncertainties collaboratively, and enhance the reliability of the studies included in our systematic review.\n\nIn cases where a researcher had a potential conflict of interest due to prior involvement with a study, such as being a co-author, that researcher recused themselves from evaluating that particular study to maintain objectivity. For example, if a researcher had collaborated on a study examining the ethical implications of a specific AI-powered mental health chatbot, they would not have been involved in assessing the inclusion of that study in our review to avoid any bias. By following this protocol, we ensured that the selection process remained impartial and free from conflicts of interest."
    },
    {
      "title": "Quality Assessment",
      "text": "The quality of included studies was assessed using The Critical Appraisal Skills Programme (CASP) Systematic Review tool, which is a widely recognized tool for evaluating the methodological rigor and validity of research studies. The CASP tool provides a structured framework for critically appraising the key components of a study, including study design, methodology, data collection, analysis, and interpretation of findings (Supplementary File S2)."
    },
    {
      "title": "Data Extraction and Synthesis",
      "text": "Data extraction involved systematically collecting relevant information from each included study, such as author(s), publication year, study design, key findings related to ethical considerations in AI interventions for mental health, and recommendations for ethical practice. Data synthesis involved analyzing and summarizing the extracted information to identify common themes, trends, and gaps in the literature. Findings were synthesized to provide a comprehensive overview of the ethical challenges and opportunities associated with the use of AI in mental health interventions, as well as recommendations for promoting responsible and ethical practice in this evolving field (Supplementary File S3)."
    },
    {
      "title": "Results"
    },
    {
      "title": "Article Selection",
      "text": "Based on the database search strategy (PubMed, PsycINFO, Scopus, Web of Science, and Google Scholar), we identified 5974 articles, out of which 1412 articles were relevant to  PubMed, 1951  articles were relevant to PsycINFO, 1351 articles were relevant to Scopus, and 1100 articles were relevant to Web of Science. Furthermore, our manual search of Google Scholar identified 160 articles. After removing 3236 duplicate articles, the remaining 2738 articles were screened. Of these, 2036 articles were excluded, as they were not relevant to the study objectives; 1969 were from other academic disciplines; and 340 were in languages other than English. This left 702 potentially eligible articles. Upon further review of the titles and abstracts, an additional 443 articles were excluded, as they did not meet the study design criteria (i.e., they focused on other content or subjects). The full texts of the remaining 259 articles were then assessed for inclusion. After this detailed evaluation, 216 articles were excluded, leaving a final set of 43 articles that were included in the systematic review. We found an additional 8 relevant articles through a citation-chaining search. Consequently, in the final summary, we obtained 51 articles (Figure  1 ). texts of the remaining 259 articles were then assessed for inclusion. After this detailed evaluation, 216 articles were excluded, leaving a final set of 43 articles that were included in the systematic review. We found an additional 8 relevant articles through a citationchaining search. Consequently, in the final summary, we obtained 51 articles (Figure  1 )."
    },
    {
      "title": "Quality Assessment Results",
      "text": "The assessment of study quality using the CASP tool yielded insightful results. None of the studies achieved a perfect score of 10. Notably, nine studies stood out with a commendable score of 9, reflecting the high quality of research in those cases, which accounted for 17.64% of the reviewed articles. Additionally, a significant portion of the studies, totaling twenty-three, achieved a score of 8, comprising 45.09% of the total. Twelve studies received a score of 7, demonstrating a satisfactory level of quality, representing 23.52% of the reviewed articles. Moreover, seven studies garnered a score of 6, indicating room for enhancement yet still contributing valuable insights, making up 13.75% of the total. Overall, these findings highlight the qualitative strengths prevalent in the majority of the reviewed studies. For a detailed examination of the study selection process, readers are encouraged to consult Supplementary File S4."
    },
    {
      "title": "Ethical Considerations of Artificial Intelligence Interventions in Mental Health and Well-Being",
      "text": "According to the literature review, there are several key ethical considerations associated with the use of artificial intelligence interventions in mental health and well-being. Some of the main considerations include privacy and confidentiality, informed consent,"
    },
    {
      "title": "Quality Assessment Results",
      "text": "The assessment of study quality using the CASP tool yielded insightful results. None of the studies achieved a perfect score of 10. Notably, nine studies stood out with a commendable score of 9, reflecting the high quality of research in those cases, which accounted for 17.64% of the reviewed articles. Additionally, a significant portion of the studies, totaling twenty-three, achieved a score of 8, comprising 45.09% of the total. Twelve studies received a score of 7, demonstrating a satisfactory level of quality, representing 23.52% of the reviewed articles. Moreover, seven studies garnered a score of 6, indicating room for enhancement yet still contributing valuable insights, making up 13.75% of the total. Overall, these findings highlight the qualitative strengths prevalent in the majority of the reviewed studies. For a detailed examination of the study selection process, readers are encouraged to consult Supplementary File S4."
    },
    {
      "title": "Ethical Considerations of Artificial Intelligence Interventions in Mental Health and Well-Being",
      "text": "According to the literature review, there are several key ethical considerations associated with the use of artificial intelligence interventions in mental health and well-being. Some of the main considerations include privacy and confidentiality, informed consent, bias and fairness, transparency, explainability, accountability, and autonomy and human agency (Table  1 ). Through a comprehensive review of the collected articles, we identified several considerations for incorporating ethical principles into the AI design process, namely an ethical framework, stakeholder engagement, ethical review, bias mitigation, and continuous evaluation and improvement (Table  2 )."
    },
    {
      "title": "Practices for Ethical Use of AI in Mental Health Interventions",
      "text": "According to our comprehensive review of the articles, some key practices to promote the ethical use of AI in mental health interventions are adhering to ethical guidelines, ensuring transparency, prioritizing data privacy and security, mitigating bias and ensuring fairness, involving stakeholders, conducting regular ethical reviews, and monitoring and evaluating outcomes (Table  3 )."
    },
    {
      "title": "Monitor and evaluate outcomes",
      "text": "The impact of AI technologies on mental health outcomes and ethical considerations should be continuously monitored and evaluated. This includes assessing the effectiveness of the technology, soliciting feedback from stakeholders, and making improvements to enhance ethical use and positive outcomes. (Carr 2020; Sarah Graham et al. 2019; Habli et al. 2020; Khanna and Srivastava 2020; Kiseleva et al. 2022; Aditya Singhal et al. 2024; Vollmer et al. 2020)"
    },
    {
      "title": "Discussion",
      "text": "Artificial Intelligence (AI) holds immense potential to revolutionize mental health services by providing personalized support and improving accessibility. However, the responsible implementation of AI interventions in mental health settings requires careful consideration of ethical concerns to ensure positive outcomes for individuals. This study contributes to a theoretical understanding of ethical considerations for AI in mental health interventions by identifying the themes of privacy, informed consent, bias and fairness, transparency, accountability, autonomy, and safety within the literature. In order to adequately integrate these principles, it is critical to engage stakeholders who will be impacted by the technology and continuously evaluate as the technology evolves. Ultimately, these technologies must support people, not overlook them in an effort to automate.\n\nSeveral studies emphasize the importance of safeguarding patient privacy and ensuring confidentiality in AI-driven mental health interventions (Y. Chen and Esmaeilzadeh 2024; Chintala 2022; Murdoch 2021; Sivan and Zukarnain 2021) . One of the foremost ethical considerations in AI-driven mental health interventions is privacy and confidentiality  (Ghadiri 2022; Shimada 2023) . Protecting patient data and ensuring confidentiality are paramount to building trust between users and AI systems. Researchers emphasize the importance of implementing robust data security measures and adhering to privacy regulations  (Murdoch 2021; Sivan and Zukarnain 2021) . By safeguarding patient privacy, AI interventions can uphold ethical principles while delivering personalized support to individuals seeking mental health assistance (Y. Chen and Esmaeilzadeh 2024; Murdoch 2021; Sivan and Zukarnain 2021) .\n\nResearchers stress the need for transparent communication, explainability of AI models, and the need to obtain informed consent from users before deploying AI interventions  (Cohen 2019; Pickering 2021; Ursin et al. 2021) . This includes providing clear information about the purpose, risks, and benefits of the technology  (Cohen 2019; Pickering 2021; Ursin et al. 2021) . Transparent communication fosters trust and empowers individuals to make informed decisions about their mental health care. By prioritizing informed consent, AI interventions can respect individuals' autonomy and promote collaborative decision-making between users and providers  (Cohen 2019; Ursin et al. 2021) .\n\nSeveral researchers have identified the risk of bias in AI algorithms, particularly in mental health diagnostics and treatment recommendations  (Gaonkar et al. 2023; Kerasidou 2021; Martin et al. 2022; Aditya Singhal et al. 2024; Tatineni 2019) . Addressing bias requires diverse and representative datasets, as well as algorithmic fairness assessments to mitigate disparities  (Gaonkar et al. 2023; Kerasidou 2021; Aditya Singhal et al. 2024; Tatineni 2019) . Bias in AI algorithms poses significant ethical challenges in mental health diagnostics and treatment recommendations. Studies have highlighted the importance of addressing bias through the use of diverse and representative datasets, algorithmic fairness assessments, and bias mitigation strategies  (Gaonkar et al. 2023; Kerasidou 2021; Martin et al. 2022; Aditya Singhal et al. 2024; Tatineni 2019) . Fairness in AI-driven mental health interventions ensures equitable access to care and minimizes disparities among diverse patient populations  (Ferrara 2023) . By promoting fairness, AI technologies can enhance the quality and effectiveness of mental health services while reducing the risk of harm  (Ferrara 2023; Aditya Singhal et al. 2024) .\n\nThere is a call for transparency in AI systems, including disclosure of how algorithms make decisions and accountability for their outcomes; this transparency fosters trust between users and AI systems  (Habli et al. 2020; Khanna and Srivastava 2020; Kiseleva et al. 2022; Aditya Singhal et al. 2024; Vollmer et al. 2020) . Transparency in AI systems is crucial for promoting accountability and trustworthiness  (Kiseleva et al. 2022) . Users should have insight into how algorithms make decisions and understand the limitations of AI technology  (de Bruijn et al. 2022; Lee 2018) . Ethical AI-driven mental health interventions prioritize transparency through clear explanations of algorithms' functionality and decision-making processes  (Koutsouleris et al. 2022; Aditya Singhal et al. 2024) . Accountability mechanisms hold developers and providers accountable for the outcomes of AI interventions, fostering responsible practice and ensuring positive outcomes for individuals  (Habli et al. 2020; Kiseleva et al. 2022; Aditya Singhal et al. 2024; Vollmer et al. 2020) .\n\nEthical AI in mental health respects individual autonomy and empowers users to make informed decisions about their treatment options  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Human oversight is essential to ensure that AI interventions complement rather than replace human judgment and agency  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Respecting individual autonomy and human agency is fundamental in ethical AI-driven mental health interventions  (Alowais et al. 2023) . While AI technologies can augment decision-making processes, human oversight is essential to ensure that interventions align with users' preferences and values  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Empowering individuals to actively participate in their mental health care promotes autonomy and self-determination  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Human-centered design approaches prioritize user autonomy and agency, emphasizing collaboration and shared decision making between users and AI systems  (Margetis et al. 2021; Usmani et al. 2023) .\n\nEnsuring the safety and efficacy of AI-driven mental health interventions is paramount; this involves rigorous testing, validation, and ongoing monitoring to detect and mitigate potential adverse effects  (Davahli et al. 2021; Ellahham et al. 2020; Habli et al. 2020; Morley et al. 2021; Tiwari and Dileep 2023) . Ensuring the safety and efficacy of AI-driven mental health interventions is paramount to protecting individuals from harm. Rigorous testing, validation, and ongoing monitoring are essential to detect and mitigate potential adverse effects  (Balcombe and De Leo 2021; Joerin et al. 2020; Tatineni 2019) . Ethical AI practices prioritize safety and efficacy, prioritizing the well-being of users and minimizing the risk of unintended consequences (J. P.  Singh 2021) . By upholding safety standards, AI interventions can enhance the quality and accessibility of mental health care while promoting positive outcomes for individuals (S. Graham et al. 2019; Habli et al. 2020; Mensah 2023; Reddy et al. 2019) .\n\nEthical frameworks and guidelines specific to promoting ethical AI in mental health are advocated for by the authors of many studies  (Jeyaraman et al. 2023; Siala and Wang 2022) . These frameworks provide a structured approach for addressing ethical challenges and promoting responsible practice  (Siala and Wang 2022; Zhang et al. 2023) . Developing and adopting ethical frameworks and guidelines specific to AI-driven mental health inter-ventions provide a structured approach for addressing ethical challenges  (Carr 2020) . These frameworks offer guidance on ethical decision making, risk assessment, and responsible practice  (Carr 2020; Molala and Makhubele 2021) . Stakeholder engagement throughout the development and implementation process ensures that ethical considerations are adequately addressed, promoting transparency and accountability in AI-driven mental health interventions  (B\u00e9lisle-Pipon et al. 2022; Couture et al. 2023; A. Singhal et al. 2024) .\n\nPractical strategies for mitigating bias in AI algorithms include diverse data collection, algorithmic audits, and ongoing evaluation to detect and correct biases that may arise during deployment (F. Chen et al. 2024; Ferrara 2023; Mensah 2023; Mittermaier et al. 2023) . Mitigating bias in AI algorithms is essential to ensure equitable and fair outcomes in mental health interventions  (Timmons et al. 2023) . Diverse data collection, algorithmic audits, and bias mitigation strategies are critical components of ethical AI practice (F. Chen et al. 2024; Ferrara 2023; Mensah 2023; Mittermaier et al. 2023) . Continuous evaluation and improvement efforts aim to detect and correct biases that may arise during deployment, promoting fairness and inclusivity in AI-driven mental health interventions (F. Chen et al. 2024; Mensah 2023; Mittermaier et al. 2023) .\n\nEthical AI practices require continuous evaluation and improvement to adapt to evolving ethical standards, technological advancements, and user needs (WHO Guidance 2021;  Magrabi et al. 2019; McGreevey et al. 2020; Morley et al. 2020) . Continuous evaluation and improvement are integral to ethical AI practice in mental health settings  (WHO Guidance 2021; McGreevey et al. 2020) . Monitoring and evaluating outcomes enable developers and providers to identify areas for improvement and adapt to evolving ethical standards and user needs (WHO Guidance 2021;  Magrabi et al. 2019; McGreevey et al. 2020; Morley et al. 2020) . Regular ethical reviews and stakeholder feedback contribute to ongoing refinement and optimization of AI-driven mental health interventions, ensuring that they remain ethically sound and beneficial to individuals seeking care  (Farhud and Zokaei 2021; WHO Guidance 2021; Leimanis and Palkova 2021; Nasir et al. 2024) .\n\nSeveral recent review studies, including that by  Li et al. (2023) , have critically examined the ethical implications of employing artificial intelligence (AI) in mental health interventions. Li, Han et al. synthesized evidence on the effectiveness of AI-driven conversational agents in enhancing mental health and well-being. Their findings offer valuable insights into the current evidence base for the use of conversational AI in mental health interventions, highlighting both its potential and limitations. Ethical concerns such as informed consent, privacy, transparency, and algorithmic bias were identified as significant challenges  (Li et al. 2023) . Another narrative review by A. M.  Alhuwaydi (2024)  explored the evolving role of AI in mental health care, addressing key challenges, limitations, and prospects. It underscored the potential of AI, particularly predictive analytics, in refining treatment strategies by predicting individual responses to interventions, thus aligning with the shift towards personalized mental health care. The review also scrutinized major ethical dimensions in AI-driven mental health, including algorithmic bias, data privacy, transparency, responsibility, and the doctor-patient relationship  (Alhuwaydi 2024) .\n\nAdditionally, Thakkar et al. (  2024 ) contributed a narrative review discussing AI's applications in managing psychiatric disorders such as neurodegenerative disorders, intellectual disabilities, and seizures. The paper explored AI's role in enhancing awareness, diagnosis, and intervention for mental health conditions. While highlighting AI's potential benefits, the review acknowledged significant challenges, emphasizing the necessity of culturally sensitive and flexible algorithms to mitigate potential biases. It provided a comprehensive overview of AI's current landscape and future prospects in mental health, alongside critical considerations and limitations that warrant attention for its responsible and effective integration into mental health care  (Thakkar et al. 2024) .\n\nTogether, these studies underscore the pressing ethical issues that must be addressed to ensure the safe and ethical use of AI in supporting mental health care. They emphasize the importance of informed consent, data privacy, algorithmic transparency, and maintaining human-centric approaches in AI-powered mental health interventions.\n\nNotably, regulating bodies such as the Federal Drug Administration (FDA) in the United States may play a role in ensuring that AI interventions are developed and deployed in an ethical manner. The AI interventions discussed in this paper could take many forms, such as specific algorithms, chatbots, or complete AI-enabled devices. AI-enabled medical devices may be subject to FDA approval, as noted in recent publications on the agency's website. While this can be a promising development for the protection of consumers, it will be critical that the FDA retain experts who are able to properly assess the ethical design and development of the AI components of these devices. Research like that discussed in this paper can offer an important source of information to inform the development of responsible regulation of AI devices."
    },
    {
      "title": "Limitations of This Study",
      "text": "There are a few limitations to note for this study. This systematic review has a limited scope and mainly focuses on articles published in a specific time period  (2014) (2015) (2016) (2017) (2018) (2019) (2020) (2021) (2022) (2023) (2024)  in a limited set of databases  (PubMed, PsycINFO, Web of Science, and Scopus) . This narrow scope ignores studies or perspectives from other time periods or sources and limits the generalizability of the findings. The review's reliance on published articles may introduce publication bias, as studies with significant findings are more likely to be published than studies with negative results. This bias can distort the overall interpretation of ethical considerations in AI-based mental health interventions. Limiting the search to articles published in specific databases may lead to language bias, as relevant studies published in other languages or regions may be overlooked. This limitation can affect the comprehensiveness of the review findings. This review may not provide an accurate assessment of the quality of included studies, potentially overlooking methodological flaws or biases in the literature. Without robust quality assessment criteria, the reliability and validity of pooled findings may be compromised. Despite efforts to conduct a systematic review, biases inherent in the processes of study selection, data extraction, and synthesis may affect the interpretation of the findings. Future research should aim to overcome these limitations to provide a more comprehensive understanding of ethical considerations in AI-based mental health interventions and to inform responsible practice and policy development."
    },
    {
      "title": "Conclusions",
      "text": "Ethical considerations play a central role in the responsible implementation and impact of AI-driven mental health interventions. By addressing privacy, informed consent, bias, transparency, autonomy, safety, and efficacy, ethical AI practice promotes responsible practice and positive outcomes for individuals. Ethical frameworks, stakeholder engagement, bias mitigation strategies, and continuous evaluation efforts contribute to the ethical development and deployment of AI interventions, fostering trust, fairness, and effectiveness in mental healthcare delivery. As AI technology continues to evolve, prioritizing ethical considerations remains essential to maximizing benefits while minimizing potential harms in mental health interventions. These findings collectively underscore the importance of prioritizing ethical considerations in the development and deployment of AI interventions in mental health. By addressing these concerns, researchers and practitioners can ensure that AI technologies contribute positively to mental health care while minimizing potential risks and harms."
    },
    {
      "title": "Supplementary Materials:",
      "text": "The following supporting information can be downloaded at:  https:  //www.mdpi.com/article/10.3390/socsci13070381/s1 ."
    },
    {
      "text": "Figure 1. Flow diagram showing the study selection/screening process."
    },
    {
      "text": "Figure 1. Flow diagram showing the study selection/screening process."
    },
    {
      "text": "Contributions: Conceptualization, H.R.S. and N.G.; methodology, S.G.H.F. and B.L.; validation, B.L.; formal analysis, H.R.S.; investigation, N.G.; resources, S.G.H.F.; data curation, H.R.S., N.G., B.L. and S.G.H.F.; writing-original draft preparation, H.R.S. and B.L.; writing-review and editing, B.L.; visualization, H.R.S.; supervision, N.G.; project administration, N.G. All authors have read and agreed to the published version of the manuscript. Funding: This research received no external funding."
    },
    {
      "text": "Ethical considerations of artificial intelligence interventions in mental health and well-being."
    },
    {
      "text": "Considerations for integrating ethical principles for responsible practice and positive outcomes in ai technologies for mental health settings."
    },
    {
      "text": "Cont."
    },
    {
      "text": "Best Practices for ethical use of ai in mental health interventions: guidelines and recommendations."
    },
    {
      "text": "Cont."
    }
  ],
  "references": [
    {
      "title": "Exploring the Role of Artificial Intelligence in Mental Healthcare: Current Trends and Future Directions-A Narrative Review for a Comprehensive Insight",
      "authors": [
        "Ahmed Alhuwaydi"
      ],
      "year": 2024,
      "doi": "10.2147/rmhp.s461562"
    },
    {
      "doi": "10.2147/RMHP.S461562"
    },
    {
      "title": "Revolutionizing healthcare: The role of artificial intelligence in clinical practice",
      "authors": [
        "Shuroug Alowais",
        "S Sahar",
        "Nada Alghamdi",
        "Tariq Alsuhebany",
        "Abdulrahman Alqahtani",
        "Alshaya",
        "N Sumaya",
        "Atheer Almohareb",
        "Mohammed Aldairem",
        "Alrashed",
        "Bin Khalid",
        "Hisham Saleh",
        "Badreldin"
      ],
      "year": 2023,
      "doi": "10.1186/s12909-023-04698-z"
    },
    {
      "title": "AI Chatbots in Digital Mental Health",
      "authors": [
        "Luke Balcombe"
      ],
      "year": 2023,
      "doi": "10.3390/informatics10040082"
    },
    {
      "doi": "10.3390/informatics10040082"
    },
    {
      "title": "Digital mental health challenges and the horizon ahead for solutions",
      "authors": [
        "Luke Balcombe",
        "Diego Leo"
      ],
      "year": 2021
    },
    {
      "doi": "10.2196/26811"
    },
    {
      "title": "A health systems ethical framework for de-implementation in health care",
      "authors": [
        "Alison Baskin",
        "Ton Wang",
        "Jacquelyn Miller",
        "Reshma Jagsi",
        "Eve Kerr",
        "Lesly Dossett"
      ],
      "year": 2021
    },
    {
      "doi": "10.1016/j.jss.2021.05.006"
    },
    {
      "title": "Artificial intelligence ethics has a black box problem",
      "authors": [
        "B\u00e9lisle-Pipon",
        "Erica Jean-Christophe",
        "Marie-Christine Monteferrante",
        "Vincent Roy",
        "Couture"
      ],
      "year": 2022,
      "doi": "10.1007/s00146-021-01380-0"
    },
    {
      "doi": "10.1007/s00146-021-01380-0"
    },
    {
      "title": "AI gone mental': Engagement and ethics in data-driven technology for mental health",
      "authors": [
        "Sarah Carr"
      ],
      "year": 2020
    },
    {
      "doi": "10.1080/09638237.2020.1714011"
    },
    {
      "title": "An Evaluation of General-Purpose AI Chatbots: A Comprehensive Comparative Analysis",
      "authors": [
        "Oleksii Chalyi"
      ],
      "year": 2024
    },
    {
      "doi": "10.61186/ist.202401.01.07"
    },
    {
      "title": "New WHO prevalence estimates of mental disorders in conflict settings: A systematic review and meta-analysis",
      "authors": [
        "Fiona Charlson",
        "Abraham Van Mark Ommeren",
        "Joseph Flaxman",
        "Harvey Cornett",
        "Shekhar Whiteford",
        "Saxena"
      ],
      "year": 2019,
      "doi": "10.1016/s0140-6736(19)30934-1"
    },
    {
      "title": "Unmasking bias in artificial intelligence: A systematic review of bias detection and mitigation strategies in electronic health record-based models",
      "authors": [
        "Feng Chen",
        "Liqin Wang",
        "Julie Hong",
        "Jiaqi Jiang",
        "Li Zhou"
      ],
      "year": 2024
    },
    {
      "doi": "10.1093/jamia/ocae060"
    },
    {
      "title": "Generative AI in medical practice: In-depth exploration of privacy and security challenges",
      "authors": [
        "Yan Chen",
        "Pouyan Esmaeilzadeh"
      ],
      "year": 2024
    },
    {
      "doi": "10.2196/53008"
    },
    {
      "title": "Data Privacy and Security Challenges in AI-Driven Healthcare Systems in India",
      "authors": [
        "Sathish Chintala",
        "Kumar"
      ],
      "year": 2022
    },
    {
      "title": "Informed consent and medical artificial intelligence: What to tell the patient?",
      "authors": [
        "I Cohen",
        "Glenn"
      ],
      "year": 2019
    },
    {
      "doi": "10.2139/ssrn.3529576"
    },
    {
      "title": "Ethical implications of artificial intelligence in population health and the public's role in its governance: Perspectives from a citizen and expert panel",
      "authors": [
        "Vincent Couture",
        "Marie-Christine Roy",
        "Emma Dez",
        "Samuel Laperle",
        "Jean-Christophe B\u00e9lisle-Pipon"
      ],
      "year": 2023,
      "doi": "10.2196/44357"
    },
    {
      "doi": "10.2196/44357"
    },
    {
      "title": "Controlling safety of artificial intelligence-based systems in healthcare",
      "authors": [
        "Mohammad Davahli",
        "Waldemar Reza",
        "Krzysztof Karwowski",
        "Thomas Fiok",
        "Hamid Wan",
        "Parsaei"
      ],
      "year": 2021
    },
    {
      "doi": "10.3390/sym13010102"
    },
    {
      "title": "The perils and pitfalls of explainable AI: Strategies for explaining algorithmic decision-making",
      "authors": [
        "De Bruijn",
        "Martijn Hans",
        "Marijn Warnier",
        "Janssen"
      ],
      "year": 2022,
      "doi": "10.1016/j.giq.2021.101666"
    },
    {
      "doi": "10.1016/j.giq.2021.101666"
    },
    {
      "title": "Application of artificial intelligence in the health care safety context: Opportunities and challenges",
      "authors": [
        "Samer Ellahham",
        "Nour Ellahham",
        "Mecit Can",
        "Emre Simsekler"
      ],
      "year": 2020
    },
    {
      "doi": "10.1177/1062860619878515"
    },
    {
      "title": "AI-Enhanced Health Tools for Revolutionizing Hypertension Management and Blood Pressure Control",
      "authors": [
        "Aysan Faezi",
        "Bahman Alinezhad"
      ],
      "year": 2024,
      "doi": "10.61186/ist.202401.01.08"
    },
    {
      "doi": "10.61186/ist.202401.01.08"
    },
    {
      "title": "Enhancing human agency through redress in Artificial Intelligence Systems",
      "authors": [
        "Rosanna Fanni",
        "Giulia Zampedri",
        "Valerie Steinkogler",
        "Jo Pierson"
      ],
      "year": 2023,
      "doi": "10.1007/s00146-022-01454-7"
    },
    {
      "title": "Ethical Issues of Artificial Intelligence in Medicine and Healthcare",
      "authors": [
        "Dariush Farhud",
        "Shaghayegh Zokaei"
      ],
      "year": 2021,
      "doi": "10.18502/ijph.v50i11.7600"
    },
    {
      "title": "Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies",
      "authors": [
        "Emilio Ferrara"
      ],
      "year": 2023,
      "doi": "10.3390/sci6010003"
    },
    {
      "doi": "10.3390/sci6010003"
    },
    {
      "title": "Ethical Issues Arising Due to Bias in Training A.I. Algorithms in Healthcare and Data Sharing as a Potential Solution",
      "authors": [
        "Bilwaj Gaonkar",
        "Kirstin Cook",
        "Luke Macyszyn"
      ],
      "year": 2023,
      "doi": "10.47289/aiej20200916"
    },
    {
      "doi": "10.47289/aiej20200916"
    },
    {
      "title": "Artificial Intelligence Interventions in the Mental Healthcare of Adolescents",
      "authors": [
        "Pooria Ghadiri"
      ],
      "year": 2022,
      "doi": "10.2196/preprints.55686"
    },
    {
      "title": "Ethics and law in research on algorithmic and data-driven technology in mental health care: Scoping review",
      "authors": [
        "Piers Gooding",
        "Timothy Kariotis"
      ],
      "year": 2021,
      "doi": "10.2196/24668"
    },
    {
      "doi": "10.2196/24668"
    },
    {
      "title": "Artificial intelligence for mental health and mental illnesses: An Overview",
      "authors": [
        "Sarah Graham",
        "Colin Depp",
        "Ellen Lee",
        "Camille Nebeker",
        "Xin Tu",
        "Ho-Cheol Kim",
        "Dilip Jeste"
      ],
      "year": 2019,
      "doi": "10.1007/s11920-019-1094-0"
    },
    {
      "doi": "10.1007/s11920-019-1094-0"
    },
    {
      "title": "Artificial intelligence in health care: Accountability and safety",
      "authors": [
        "Ibrahim Habli",
        "Tom Lawton",
        "Zoe Porter"
      ],
      "year": 2020,
      "doi": "10.2471/BLT.19.237487"
    },
    {
      "title": "Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare",
      "authors": [
        "Madhan Jeyaraman",
        "Sangeetha Balaji",
        "Naveen Jeyaraman",
        "Sankalp Yadav"
      ],
      "year": 2023,
      "doi": "10.7759/cureus.43262"
    },
    {
      "doi": "10.7759/cureus.43262"
    },
    {
      "title": "Ethical Artificial Intelligence for Digital Health Organizations",
      "authors": [
        "Angela Joerin",
        "Michiel Rauws",
        "Russell Fulmer",
        "Valerie Black"
      ],
      "year": 2020,
      "doi": "10.7759/cureus.7202"
    },
    {
      "doi": "10.7759/cureus.7202"
    },
    {
      "title": "Ethical Considerations in the Adoption of Artificial Intelligence for Mental Health Diagnosis",
      "authors": [
        "Balaram Kasula",
        "Yadav"
      ],
      "year": 2023
    },
    {
      "title": "Ethics of artificial intelligence in global health: Explainability, algorithmic bias and trust",
      "authors": [
        "Angeliki Kerasidou"
      ],
      "year": 2021,
      "doi": "10.1016/j.jobcr.2021.09.004"
    },
    {
      "doi": "10.1016/j.jobcr.2021.09.004"
    },
    {
      "title": "Patient-centric ethical frameworks for privacy, transparency, and bias awareness in deep learning-based medical systems",
      "authors": [
        "Shivansh Khanna",
        "Shraddha Srivastava"
      ],
      "year": 2020,
      "doi": "10.33140/amlai.05.03.03"
    },
    {
      "title": "Transparency of AI in healthcare as a multilayered system of accountabilities: Between legal requirements and technical limitations",
      "authors": [
        "Anastasiya Kiseleva",
        "Dimitris Kotzinos",
        "Paul Hert"
      ],
      "year": 2022,
      "doi": "10.3389/frai.2022.879603"
    },
    {
      "title": "From promise to practice: Towards the realisation of AI-informed mental health care",
      "authors": [
        "Nikolaos Koutsouleris",
        "Tobias Hauser",
        "Vasilisa Skvortsova",
        "Munmun Choudhury"
      ],
      "year": 2022,
      "doi": "10.1016/s2589-7500(22)00153-4"
    },
    {
      "title": "Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management",
      "authors": [
        "Min Lee",
        "Kyung"
      ],
      "year": 2018
    },
    {
      "doi": "10.1177/2053951718756684"
    },
    {
      "title": "Ethical guidelines for artificial intelligence in healthcare from the sustainable development perspective",
      "authors": [
        "Anr\u012b Leimanis",
        "Karina Palkova"
      ],
      "year": 2021,
      "doi": "10.14207/ejsd.2021.v10n1p90"
    },
    {
      "doi": "10.14207/ejsd.2021.v10n1p90"
    },
    {
      "title": "Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being",
      "authors": [
        "Han Li",
        "Renwen Zhang",
        "Yi-Chieh Lee",
        "Robert Kraut",
        "David Mohr"
      ],
      "year": 2023,
      "doi": "10.1038/s41746-023-00979-5"
    },
    {
      "title": "Just the Facts Ma'am\": Moral and Ethical Considerations for Artificial Intelligence in Medicine and its Potential to Impact Patient Autonomy and Hope",
      "authors": [
        "Charles Love"
      ],
      "year": 2023,
      "doi": "10.1177/00243639231162431"
    },
    {
      "title": "Artificial intelligence in psychological practice: Current and future applications and implications",
      "authors": [
        "David Luxton"
      ],
      "year": 2014
    },
    {
      "doi": "10.1037/a0034559"
    },
    {
      "title": "Artificial intelligence in clinical decision support: Challenges for evaluating AI and practical implications",
      "authors": [
        "Farah Magrabi",
        "Elske Ammenwerth",
        "Jytte Brender Mcnair",
        "Nicolet Keizer",
        "Hannele Hypp\u00f6nen",
        "Pirkko Nyk\u00e4nen",
        "Michael Rigby",
        "Philip Scott",
        "Tuulikki Vehko",
        "Zoie Shui-Yee",
        "Wong"
      ],
      "year": 2019,
      "doi": "10.1055/s-0039-1677903"
    },
    {
      "title": "Human-centered design of artificial intelligence",
      "authors": [
        "George Margetis",
        "Stavroula Ntoa",
        "Margherita Antona",
        "Constantine Stephanidis"
      ],
      "year": 2021
    },
    {
      "doi": "10.1002/9781119636113.ch42"
    },
    {
      "title": "The ethical considerations including inclusion and biases, data protection, and proper implementation among AI in radiology and potential implications",
      "authors": [
        "Clarissa Martin",
        "Kyle Destefano",
        "Harry Haran",
        "Sydney Zink",
        "Jennifer Dai",
        "Danial Ahmed",
        "Abrahim Razzak",
        "Keldon Lin",
        "Ann Kogler",
        "Joseph Waller"
      ],
      "year": 2022
    },
    {
      "doi": "10.1016/j.ibmed.2022.100073"
    },
    {
      "title": "Clinical, legal, and ethical aspects of artificial intelligence-assisted conversational agents in health care",
      "authors": [
        "John Mcgreevey",
        "C Hanson",
        "Ross Koppel"
      ],
      "year": 2020
    },
    {
      "doi": "10.1001/jama.2020.2724"
    },
    {
      "title": "Artificial intelligence and medical research databases: Ethical review by data access committees",
      "authors": [
        "Francis Mckay",
        "Bethany Williams",
        "Graham Prestwich",
        "Daljeet Bansal",
        "Darren Treanor",
        "Nina Hallowell"
      ],
      "year": 2023
    },
    {
      "doi": "10.1186/s12910-023-00927-8"
    },
    {
      "title": "Ethical and regulatory challenges of AI technologies in healthcare: A narrative review",
      "authors": [
        "Ciro Mennella",
        "Umberto Maniscalco",
        "Giuseppe Pietro",
        "Massimo Esposito"
      ],
      "year": 2024,
      "doi": "10.1016/j.heliyon.2024.e26297"
    },
    {
      "title": "Artificial Intelligence and Ethics: A Comprehensive Review of Bias Mitigation, Transparency, and Accountability in AI Systems",
      "authors": [
        "George Mensah",
        "Benneh"
      ],
      "year": 2023
    },
    {
      "title": "Bias in AI-based models for medical applications: Challenges and mitigation strategies",
      "authors": [
        "Mittermaier",
        "Marium Mirja",
        "Joseph Raza",
        "Kvedar"
      ],
      "year": 2023
    },
    {
      "title": "A conceptual framework for the ethical deployment of Artificial Intelligence in addressing mental health challenges: Guidelines for Social Workers",
      "authors": [
        "Thomas Molala",
        "Jabulani Makhubele"
      ],
      "year": 2021
    },
    {
      "title": "The ethics of AI in health care: A mapping review",
      "authors": [
        "Jessica Morley",
        "C Caio",
        "Christopher Machado",
        "Josh Burr",
        "Indra Cowls",
        "Mariarosaria Joshi",
        "Luciano Taddeo",
        "Floridi"
      ],
      "year": 2020
    },
    {
      "doi": "10.1016/j.socscimed.2020.113172"
    },
    {
      "title": "Towards a framework for evaluating the safety, acceptability and efficacy of AI systems for health: An initial synthesis",
      "authors": [
        "Jessica Morley",
        "Kassandra Karpathakis",
        "Caroline Morton",
        "Mariarosaria Taddeo",
        "Luciano Floridi"
      ],
      "year": 2021
    },
    {
      "title": "Canada protocol: An ethical checklist for the use of artificial Intelligence in suicide prevention and mental health",
      "authors": [
        "Carl-Maria M\u00f6rch",
        "Abhishek Gupta",
        "Brian Mishara"
      ],
      "year": 2020,
      "doi": "10.1016/j.artmed.2020.101934"
    },
    {
      "title": "Privacy and artificial intelligence: Challenges for protecting health information in a new era",
      "authors": [
        "Blake Murdoch"
      ],
      "year": 2021
    },
    {
      "doi": "10.1186/s12910-021-00687-3"
    },
    {
      "title": "Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond",
      "authors": [
        "Sidra Nasir",
        "Rizwan Ahmed Khan",
        "Samita Bai"
      ],
      "year": 2024
    },
    {
      "doi": "10.1109/access.2024.3369912"
    },
    {
      "title": "Enhancing mental health with Artificial Intelligence: Current trends and future prospects",
      "authors": [
        "David Olawade",
        "Odetayo Aderonke",
        "Z Ojima",
        "Fiyinfoluwa Wada",
        "Aanuoluwapo Asaolu",
        "Judith Clement David-Olawade",
        "Eberhardt"
      ],
      "year": 2024
    },
    {
      "doi": "10.1016/j.glmedi.2024.100099"
    },
    {
      "title": "Ethical considerations in AI-enhanced medical decision support systems: A review",
      "authors": [
        "Tolulope Olorunsogo",
        "Adekunle Oyeyemi Adenyi",
        "Chioma Anthonia Okolo",
        "Oloruntoba Babawarun"
      ],
      "year": 2024
    },
    {
      "doi": "10.30574/wjaets.2024.11.1.0061"
    },
    {
      "title": "The PRISMA 2020 statement: An updated guideline for reporting systematic reviews",
      "authors": [
        "Matthew Page",
        "M Patrick",
        "Joanne Bossuyt",
        "Tammy Mckenzie",
        "Isabelle Hoffmann",
        "Larissa Boutron",
        "Cynthia Shamseer",
        "Elie Mulrow",
        "Jennifer Akl",
        "Sue Tetzlaff",
        "Brennan"
      ],
      "year": 2021
    },
    {
      "doi": "10.1136/bmj.n71"
    },
    {
      "title": "Trust, but verify: Informed consent, AI technologies, and public health emergencies",
      "authors": [
        "Brian Pickering"
      ],
      "year": 2021
    },
    {
      "title": "Ethical framework of digital technology, artificial intelligence, and health equity",
      "authors": [
        "Piyanat Prathomwong",
        "Pagorn Singsuriya"
      ],
      "year": 2022
    },
    {
      "doi": "10.48048/asi.2022.252136"
    },
    {
      "title": "Artificial intelligence-enabled healthcare delivery",
      "authors": [
        "Sandeep Reddy",
        "John Fox",
        "Maulik Purohit"
      ],
      "year": 2019
    },
    {
      "doi": "10.1177/0141076818815510"
    },
    {
      "title": "iHealth: The ethics of artificial intelligence and big data in mental healthcare",
      "authors": [
        "Giovanni Rubeis"
      ],
      "year": 2022,
      "doi": "10.1016/j.invent.2022.100518"
    },
    {
      "title": "Ethical artificial intelligence (AI): Confronting bias and discrimination in the library and information industry",
      "authors": [
        "Hamid Saeidnia",
        "Reza"
      ],
      "year": 2023
    },
    {
      "doi": "10.1108/lhtn-10-2023-0182"
    },
    {
      "title": "AI in Mental Health: Predictive Analytics and Intervention Strategies",
      "authors": [
        "Varun Shah"
      ],
      "year": 2022
    },
    {
      "title": "Emerging paradigms for ethical review of research using artificial intelligence",
      "authors": [
        "James Shaw"
      ],
      "year": 2022
    },
    {
      "doi": "10.1080/15265161.2022.2055206"
    },
    {
      "title": "The role of artificial intelligence in mental health: A review",
      "authors": [
        "Koki Shimada"
      ],
      "year": 2023
    },
    {
      "doi": "10.15354/si.23.re820"
    },
    {
      "title": "SHIFTing artificial intelligence to be responsible in healthcare: A systematic review",
      "authors": [
        "Haytham Siala",
        "Yichuan Wang"
      ],
      "year": 2022
    },
    {
      "doi": "10.1016/j.socscimed.2022.114782"
    },
    {
      "title": "AI Ethics and Societal Perspectives: A Comparative Study of Ethical Principle Prioritization Among Diverse Demographic Clusters",
      "authors": [
        "Jatin Singh",
        "Pal"
      ],
      "year": 2021
    },
    {
      "title": "Clinical Practice Guidelines on using artificial intelligence and gadgets for mental health and well-being",
      "authors": [
        "Vipul Singh",
        "Sharmila Sarkar",
        "Vikas Gaur",
        "Sandeep Grover",
        "Om Singh"
      ],
      "year": 2024,
      "doi": "10.4103/indianjpsychiatry.indianjpsychiatry_926_23"
    },
    {
      "title": "Toward Fairness, Accountability, Transparency, and Ethics in AI for Social Media and Health Care: Scoping Review",
      "authors": [
        "Aditya Singhal",
        "Nikita Neveditsin",
        "Hasnaat Tanveer",
        "Vijay Mago"
      ],
      "year": 2024,
      "doi": "10.2196/50048"
    },
    {
      "title": "Security and privacy in cloud-based e-health system",
      "authors": [
        "Remya Sivan",
        "Zuriati Ahmad Zukarnain"
      ],
      "year": 2021
    },
    {
      "doi": "10.3390/sym13050742"
    },
    {
      "title": "Persons or data points? Ethics, artificial intelligence, and the participatory turn in mental health research",
      "authors": [
        "Joshua Skorburg",
        "August",
        "O' Kieran",
        "Phoebe Doherty",
        "Friesen"
      ],
      "year": 2024,
      "doi": "10.1037/amp0001168"
    },
    {
      "title": "Methodology in conducting a systematic review of systematic reviews of healthcare interventions",
      "authors": [
        "Valerie Smith",
        "Declan Devane",
        "Cecily Begley",
        "Mike Clarke"
      ],
      "year": 2011,
      "doi": "10.1186/1471-2288-11-15"
    },
    {
      "title": "Humanizing AI in medical training: Ethical framework for responsible design",
      "authors": [
        "Mohammed Sqalli",
        "Begali Tahri",
        "Mukhammadjon Aslonov",
        "Shokhrukhbek Gafurov",
        "Nurmatov"
      ],
      "year": 2023,
      "doi": "10.3389/frai.2023.1189914"
    },
    {
      "title": "Ethical Considerations in AI and Data Science: Bias, Fairness, and Accountability",
      "authors": [
        "Sumanth Tatineni"
      ],
      "year": 2019,
      "doi": "10.48047/resmil.v10i1.22"
    },
    {
      "title": "Artificial intelligence in positive mental health: A narrative review",
      "authors": [
        "Anoushka Thakkar",
        "Ankita Gupta",
        "Avinash Sousa"
      ],
      "year": 2024
    },
    {
      "doi": "10.3389/fdgth.2024.1280235"
    },
    {
      "title": "A call to action on assessing and mitigating bias in artificial intelligence applications for mental health",
      "authors": [
        "Adela Timmons",
        "B Jacqueline",
        "Natalia Duong",
        "Theodore Fiallo",
        "Huong Lee",
        "Quynh Phuc",
        "Matthew Vo",
        "Jonathan Ahle",
        "Laprincess Comer",
        "Stacy Brewer",
        "Theodora Frazier",
        "Chaspari"
      ],
      "year": 2023
    },
    {
      "doi": "10.1177/17456916221134490"
    },
    {
      "title": "The AI ethics principle of autonomy in health recommender systems",
      "authors": [
        "Simona Tiribelli"
      ],
      "year": 2023
    },
    {
      "title": "An Efficacy of Artificial Intelligence Applications in Healthcare Systems-A Bird View",
      "authors": [
        "Vikash Tiwari",
        "M Kumar",
        "Dileep"
      ],
      "year": 2023
    },
    {
      "title": "Diagnosing diabetic retinopathy with artificial intelligence: What information should be included to ensure ethical informed consent",
      "authors": [
        "Frank Ursin",
        "Marcin Orzechowski Cristian Timmermann",
        "Florian Steger"
      ],
      "year": 2021,
      "doi": "10.3389/fmed.2021.695217"
    },
    {
      "title": "Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations",
      "authors": [
        "Usman Usmani",
        "Ari Ahmad",
        "Junzo Happonen",
        "Watada"
      ],
      "year": 2023
    },
    {
      "doi": "10.1109/hora58378.2023.10156761"
    },
    {
      "title": "Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness",
      "authors": [
        "Sebastian Vollmer",
        "Bilal Mateen",
        "Gergo Bohner",
        "Franz Kir\u00e1ly",
        "Rayid Ghani",
        "Pall Jonsson",
        "Sarah Cumbers",
        "Adrian Jonas",
        "Katherine Mcallister",
        "Puja Myles"
      ],
      "year": 2020,
      "doi": "10.1136/bmj.l6927"
    },
    {
      "title": "Challenges and Opportunities in Global Mental Health: A Research-to-Practice Perspective",
      "authors": [
        "Milton Wainberg",
        "Pamela Scorza",
        "James Shultz",
        "Liat Helpman",
        "Jennifer Mootz",
        "Karen Johnson",
        "Yuval Neria",
        "E Jean-Marie",
        "Maria Bradford",
        "Melissa Oquendo",
        "Arbuckle"
      ],
      "year": 2017
    },
    {
      "doi": "10.1007/s11920-017-0780-z"
    },
    {
      "title": "Ethics and Governance of Artificial Intelligence for Health",
      "year": 2021
    },
    {
      "title": "Harnessing the Power of AI: A Comprehensive Review of Its Impact and Challenges in Nursing Science and Healthcare",
      "authors": [
        "Seema Yelne",
        "Minakshi Chaudhary",
        "Karishma Dod",
        "Akhtaribano Sayyad",
        "Ranjana Sharma"
      ],
      "year": 2023
    },
    {
      "doi": "10.7759/cureus.49252"
    },
    {
      "title": "The Adoption of AI in Mental Health Care-Perspectives From Mental Health Professionals: Qualitative Descriptive Study",
      "authors": [
        "Melody Zhang",
        "Jillian Scandiffio",
        "Sarah Younus",
        "Tharshini Jeyakumar",
        "Inaara Karsan",
        "Rebecca Charow",
        "Mohammad Salhia",
        "David Wiljer"
      ],
      "year": 2023,
      "doi": "10.2196/47847"
    },
    {
      "title": "The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of"
    }
  ],
  "num_references": 131
}
