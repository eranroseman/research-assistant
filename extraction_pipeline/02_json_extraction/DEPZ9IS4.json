{
  "paper_id": "DEPZ9IS4",
  "title": "Ethical Considerations in Artificial Intelligence Interventions for Mental Health and Well-Being: Ensuring Responsible Implementation and Impact",
  "abstract": "AI has the potential to revolutionize mental health services by providing personalized support and improving accessibility. However, it is crucial to address ethical concerns to ensure responsible and beneficial outcomes for individuals. This systematic review examines the ethical considerations surrounding the implementation and impact of artificial intelligence (AI) interventions in the field of mental health and well-being. To ensure a comprehensive analysis, we employed a structured search strategy across top academic databases, including PubMed, PsycINFO, Web of Science, and Scopus. The search scope encompassed articles published from 2014 to 2024, resulting in a review of 51 relevant articles. The review identifies 18 key ethical considerations, including 6 ethical considerations associated with using AI interventions in mental health and wellbeing (privacy and confidentiality, informed consent, bias and fairness, transparency and accountability, autonomy and human agency, and safety and efficacy); 5 ethical principles associated with the development and implementation of AI technologies in mental health settings to ensure responsible practice and positive outcomes (ethical framework, stakeholder engagement, ethical review, bias mitigation, and continuous evaluation and improvement); and 7 practices, guidelines, and recommendations for promoting the ethical use of AI in mental health interventions (adhere to ethical guidelines, ensure transparency, prioritize data privacy and security, mitigate bias and ensure fairness, involve stakeholders, conduct regular ethical reviews, and monitor and evaluate outcomes). This systematic review highlights the importance of ethical considerations in the responsible implementation and impact of AI interventions for mental health and well-being. By addressing privacy, bias, consent, transparency, human oversight, and continuous evaluation, we can ensure that AI interventions like chatbots and AI-enabled medical devices are developed and deployed in an ethically sound manner, respecting individual rights, promoting fairness, and maximizing benefits while minimizing potential harm.",
  "year": 2024,
  "date": "2024-07-22",
  "authors": [
    {
      "name": "Hamid Saeidnia",
      "email": "hamidrezasaednia@modares.ac.ir",
      "affiliation": {
        "organization": "Department of Knowledge and Information Science",
        "department": "Department of Knowledge and Information Science",
        "institution": "Tarbiat Modares University",
        "address": "14115-111, Tehran, Iran;"
      }
    },
    {
      "name": "Seyed Ghasem"
    },
    {
      "name": "Hashemi Fotami",
      "affiliation": {
        "organization": "Department of Computer Science",
        "department": "Department of Computer Science",
        "institution": "Tarbiat Modares University",
        "address": "14115-111, Tehran, Iran;"
      }
    },
    {
      "name": "Brady Lund",
      "email": "brady.lund@unt.edu",
      "affiliation": {
        "organization": "Department of Information Science",
        "department": "Department of Information Science",
        "institution": "University of North Texas",
        "address": "76203, Denton, TX, USA;"
      }
    },
    {
      "name": "Nasrin Ghiasi",
      "email": "ghiasi-n@medilam.ac.ir",
      "affiliation": {
        "organization": "Department of Public Health",
        "department": "Department of Public Health",
        "institution": "Ilam University of Medical Sciences",
        "address": "69391-77143, Ilam, Iran"
      }
    }
  ],
  "doi": "10.3390/socsci13070381",
  "md5": "7F6035C342A782DA926B63FD15734DD4",
  "publication": {
    "journal": "Cureus",
    "journal_inferred": true
  },
  "keywords": [
    "artificial intelligence",
    "mental health",
    "ethics",
    "well-being",
    "interventions"
  ],
  "sections": [
    {
      "title": "1.. Introduction",
      "text": "Artificial intelligence (AI) is a rapidly advancing technology that involves the development of systems capable of performing tasks that typically require human intelligence, such as learning, problem solving, and decision making  (Chalyi 2024; Saeidnia 2023 ). In the field of health, AI has emerged as a powerful tool with the potential to transform various aspects of healthcare delivery, diagnosis, treatment, and patient care  (Reddy et al. 2019) . By leveraging data analytics, machine learning algorithms, and predictive modeling, AI has the capacity to revolutionize the way healthcare services are delivered and improve patient outcomes  (Alowais et al. 2023; Yelne et al. 2023) .\n\nIn recent years, AI has also made significant inroads into the field of mental health and well-being  (Yelne et al. 2023) . Mental health disorders such as depression, anxiety, and PTSD represent a growing global health burden, with millions of individuals in need of support and treatment  (Wainberg et al. 2017; Charlson et al. 2019 ). AI technologies have been utilized to develop innovative interventions aimed at addressing these challenges by improving access to care, enhancing treatment outcomes, and providing personalized support to individuals in need  (Mennella et al. 2024) . From chatbots and virtual therapists (referring to digital, remote mental health support and treatment, whether delivered by AI systems, human therapists, or a combination of both) to predictive analytics for early intervention, AI interventions in mental health hold great promise for improving the quality and effectiveness of mental healthcare services  (Balcombe 2023) .\n\nThe potential benefits of artificial intelligence in mental health are multifaceted  (Baskin et al. 2021; Carr 2020) . AI-based interventions have the capacity to provide timely and personalized support to individuals experiencing mental health challenges, thereby improving their overall well-being (S. Graham et al. 2019; Shah 2022) . By analyzing vast amounts of data, AI systems can identify patterns and trends that may not be apparent to human clinicians, leading to more accurate diagnoses and treatment recommendations  (Alowais et al. 2023; Faezi and Alinezhad 2024) . AI tools can also help bridge the gap in mental health services by reaching underserved populations, reducing barriers to access, and increasing the efficiency of healthcare delivery (V. Singh et al. 2024) .\n\nAlongside the potential benefits of AI in mental health, however, there are also significant ethical consequences that must be carefully considered  (Jeyaraman et al. 2023) . The use of AI in health care, particularly in sensitive areas such as mental health, raises complex ethical dilemmas related to privacy, consent, transparency, accountability, bias, and the potential for unintended harm  (Farhud and Zokaei 2021; Thakkar et al. 2024 ). Issues such as data security, algorithmic bias, and the impact of automation on the patient-provider relationship are critical considerations that must be addressed to ensure the responsible and ethical implementation of AI interventions in mental health settings  (Alowais et al. 2023; B\u00e9lisle-Pipon et al. 2022; Davahli et al. 2021; Gaonkar et al. 2023; Sarah Graham et al. 2019; Jeyaraman et al. 2023; Khanna and Srivastava 2020) .\n\nAgainst this backdrop, this systematic review study aims to critically examine the ethical considerations surrounding the use of artificial intelligence in mental health interventions. By synthesizing existing literature and research findings, our goal is to shed light on the key ethical challenges and opportunities associated with the integration of AI technologies in mental health care. We seek to identify best practices, guidelines, and recommendations for promoting responsible implementation and ensuring the positive impact of AI interventions on individuals' mental health and overall well-being. Through this review, we aim to contribute to a better understanding of how ethical principles can be upheld in the development and deployment of AI solutions in mental health, ultimately enhancing the quality and accessibility of mental healthcare services while safeguarding the rights and dignity of individuals receiving care."
    },
    {
      "title": "2.. Methods and Materials",
      "text": "In this study, we critically analyze the ethical considerations related to the utilization of artificial intelligence in mental health interventions. Throughout the process of manuscript preparation, we followed the guidelines outlined by  (Smith et al. 2011) , with a specific focus on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines  (Page et al. 2021) ."
    },
    {
      "title": "2.1.. Research Questions",
      "text": "1. What are the key ethical considerations associated with the use of artificial intelligence interventions in mental health and well-being? 2. How can ethical principles be integrated into the development and implementation of AI technologies in mental health settings to ensure responsible practice and positive outcomes?\n\n3. What are the best practices, guidelines, and recommendations for promoting ethical use of AI in mental health interventions?"
    },
    {
      "title": "2.2.. Inclusion and Exclusion Criteria",
      "text": "This systematic review applied the following inclusion and exclusion criteria."
    },
    {
      "title": "2.2.1.. Inclusion Criteria",
      "text": "The inclusion criteria for this review study encompass studies that focus on the ethical considerations surrounding the use of artificial intelligence interventions in mental health and well-being. Including studies that address ethical considerations ensures a comprehensive understanding of the potential implications of AI in mental health interventions. Additionally, studies investigating the impact of AI on mental health outcomes are crucial for evaluating the effectiveness and potential risks associated with these technologies. All types of articles, including reviews, original research, short communications, and letters to the editor, are considered for inclusion to provide a diverse range of perspectives and insights on the topic. This approach allows for a thorough examination of the current literature on AI in mental health, regardless of the format in which the information is presented. Finally, limiting the inclusions to publications in the English language ensures consistency in data interpretation and accessibility for the review process."
    },
    {
      "title": "2.2.2.. Exclusion Criteria",
      "text": "The exclusion criteria for this review study involve excluding studies that do not specifically address the ethical implications of AI interventions in mental health, as the primary focus of this review is on the ethical considerations associated with AI technologies in mental health and well-being. Additionally, studies that primarily emphasize the technical aspects of AI algorithms without integrating discussions on ethical considerations are excluded, as the ethical dimension is a key aspect of interest in this review. Publications in languages other than English are also excluded to maintain consistency in data interpretation and ensure accessibility for the research process. By applying these exclusion criteria, this review aims to focus on studies that provide comprehensive insights into the ethical implications of AI interventions in mental health."
    },
    {
      "title": "2.3.. Databases and Search Method",
      "text": "We conducted a comprehensive literature search across the following databases: 1.\n\nPubMed; 2.\n\nPsycINFO; 3.\n\nScopus; 4.\n\nWeb of Science; 5.\n\nGoogle Scholar.\n\nSearch terms included combinations of keywords related to artificial intelligence, mental health, ethics, well-being, and interventions. Boolean operators (AND, OR) were used to refine search queries and identify relevant studies. The search scope spanned a decade between 2014 and 2024. We conducted a manual search of Google Scholar to enhance the scope of our search and identify additional relevant articles. This method enabled us to expand our search beyond the initial database search and uncover a broader range of scholarly articles related to our research topic.\n\nThe search strategy was designed to capture a broad range of articles addressing the ethical implications of AI interventions in mental health. While there were slight variations in the specific search terms and strings used across databases, they maintained a consistent structure. Additional information can be found in Supplementary File S1."
    },
    {
      "title": "2.4.. Study Selection",
      "text": "Our study selection process involved a meticulous review of article titles and abstracts by each researcher to assess relevance to our inclusion criteria, focusing on the ethical considerations of artificial intelligence interventions in mental health. Conflicting articles were promptly excluded, and input from other scholars was sought when doubts arose, ensuring a consensus-based final selection by the research team. This rigorous approach aimed to maintain consistency and rigor in the selection process, address uncertainties collaboratively, and enhance the reliability of the studies included in our systematic review.\n\nIn cases where a researcher had a potential conflict of interest due to prior involvement with a study, such as being a co-author, that researcher recused themselves from evaluating that particular study to maintain objectivity. For example, if a researcher had collaborated on a study examining the ethical implications of a specific AI-powered mental health chatbot, they would not have been involved in assessing the inclusion of that study in our review to avoid any bias. By following this protocol, we ensured that the selection process remained impartial and free from conflicts of interest."
    },
    {
      "title": "2.5.. Quality Assessment",
      "text": "The quality of included studies was assessed using The Critical Appraisal Skills Programme (CASP) Systematic Review tool, which is a widely recognized tool for evaluating the methodological rigor and validity of research studies. The CASP tool provides a structured framework for critically appraising the key components of a study, including study design, methodology, data collection, analysis, and interpretation of findings (Supplementary File S2)."
    },
    {
      "title": "2.6.. Data Extraction and Synthesis",
      "text": "Data extraction involved systematically collecting relevant information from each included study, such as author(s), publication year, study design, key findings related to ethical considerations in AI interventions for mental health, and recommendations for ethical practice. Data synthesis involved analyzing and summarizing the extracted information to identify common themes, trends, and gaps in the literature. Findings were synthesized to provide a comprehensive overview of the ethical challenges and opportunities associated with the use of AI in mental health interventions, as well as recommendations for promoting responsible and ethical practice in this evolving field (Supplementary File S3)."
    },
    {
      "title": "3.. Results"
    },
    {
      "title": "3.1.. Article Selection",
      "text": "Based on the database search strategy (PubMed, PsycINFO, Scopus, Web of Science, and Google Scholar), we identified 5974 articles, out of which 1412 articles were relevant to  PubMed, 1951  articles were relevant to PsycINFO, 1351 articles were relevant to Scopus, and 1100 articles were relevant to Web of Science. Furthermore, our manual search of Google Scholar identified 160 articles. After removing 3236 duplicate articles, the remaining 2738 articles were screened. Of these, 2036 articles were excluded, as they were not relevant to the study objectives; 1969 were from other academic disciplines; and 340 were in languages other than English. This left 702 potentially eligible articles. Upon further review of the titles and abstracts, an additional 443 articles were excluded, as they did not meet the study design criteria (i.e., they focused on other content or subjects). The full texts of the remaining 259 articles were then assessed for inclusion. After this detailed evaluation, 216 articles were excluded, leaving a final set of 43 articles that were included in the systematic review. We found an additional 8 relevant articles through a citation-chaining search. Consequently, in the final summary, we obtained 51 articles (Figure  1 ). texts of the remaining 259 articles were then assessed for inclusion. After this detailed evaluation, 216 articles were excluded, leaving a final set of 43 articles that were included in the systematic review. We found an additional 8 relevant articles through a citationchaining search. Consequently, in the final summary, we obtained 51 articles (Figure  1 )."
    },
    {
      "title": "3.2.. Quality Assessment Results",
      "text": "The assessment of study quality using the CASP tool yielded insightful results. None of the studies achieved a perfect score of 10. Notably, nine studies stood out with a commendable score of 9, reflecting the high quality of research in those cases, which accounted for 17.64% of the reviewed articles. Additionally, a significant portion of the studies, totaling twenty-three, achieved a score of 8, comprising 45.09% of the total. Twelve studies received a score of 7, demonstrating a satisfactory level of quality, representing 23.52% of the reviewed articles. Moreover, seven studies garnered a score of 6, indicating room for enhancement yet still contributing valuable insights, making up 13.75% of the total. Overall, these findings highlight the qualitative strengths prevalent in the majority of the reviewed studies. For a detailed examination of the study selection process, readers are encouraged to consult Supplementary File S4."
    },
    {
      "title": "3.3.. Ethical Considerations of Artificial Intelligence Interventions in Mental Health and Well-Being",
      "text": "According to the literature review, there are several key ethical considerations associated with the use of artificial intelligence interventions in mental health and well-being. Some of the main considerations include privacy and confidentiality, informed consent,"
    },
    {
      "title": "3.2.. Quality Assessment Results",
      "text": "The assessment of study quality using the CASP tool yielded insightful results. None of the studies achieved a perfect score of 10. Notably, nine studies stood out with a commendable score of 9, reflecting the high quality of research in those cases, which accounted for 17.64% of the reviewed articles. Additionally, a significant portion of the studies, totaling twenty-three, achieved a score of 8, comprising 45.09% of the total. Twelve studies received a score of 7, demonstrating a satisfactory level of quality, representing 23.52% of the reviewed articles. Moreover, seven studies garnered a score of 6, indicating room for enhancement yet still contributing valuable insights, making up 13.75% of the total. Overall, these findings highlight the qualitative strengths prevalent in the majority of the reviewed studies. For a detailed examination of the study selection process, readers are encouraged to consult Supplementary File S4."
    },
    {
      "title": "3.3.. Ethical Considerations of Artificial Intelligence Interventions in Mental Health and Well-Being",
      "text": "According to the literature review, there are several key ethical considerations associated with the use of artificial intelligence interventions in mental health and well-being. Some of the main considerations include privacy and confidentiality, informed consent, bias and fairness, transparency, explainability, accountability, and autonomy and human agency (Table  1 ). Through a comprehensive review of the collected articles, we identified several considerations for incorporating ethical principles into the AI design process, namely an ethical framework, stakeholder engagement, ethical review, bias mitigation, and continuous evaluation and improvement (Table  2 )."
    },
    {
      "title": "3.5.. Practices for Ethical Use of AI in Mental Health Interventions",
      "text": "According to our comprehensive review of the articles, some key practices to promote the ethical use of AI in mental health interventions are adhering to ethical guidelines, ensuring transparency, prioritizing data privacy and security, mitigating bias and ensuring fairness, involving stakeholders, conducting regular ethical reviews, and monitoring and evaluating outcomes (Table  3 )."
    },
    {
      "title": "Monitor and evaluate outcomes",
      "text": "The impact of AI technologies on mental health outcomes and ethical considerations should be continuously monitored and evaluated. This includes assessing the effectiveness of the technology, soliciting feedback from stakeholders, and making improvements to enhance ethical use and positive outcomes. (Carr 2020; Sarah Graham et al. 2019; Habli et al. 2020; Khanna and Srivastava 2020; Kiseleva et al. 2022; Aditya Singhal et al. 2024; Vollmer et al. 2020)"
    },
    {
      "title": "4.. Discussion",
      "text": "Artificial Intelligence (AI) holds immense potential to revolutionize mental health services by providing personalized support and improving accessibility. However, the responsible implementation of AI interventions in mental health settings requires careful consideration of ethical concerns to ensure positive outcomes for individuals. This study contributes to a theoretical understanding of ethical considerations for AI in mental health interventions by identifying the themes of privacy, informed consent, bias and fairness, transparency, accountability, autonomy, and safety within the literature. In order to adequately integrate these principles, it is critical to engage stakeholders who will be impacted by the technology and continuously evaluate as the technology evolves. Ultimately, these technologies must support people, not overlook them in an effort to automate.\n\nSeveral studies emphasize the importance of safeguarding patient privacy and ensuring confidentiality in AI-driven mental health interventions (Y. Chen and Esmaeilzadeh 2024; Chintala 2022; Murdoch 2021; Sivan and Zukarnain 2021) . One of the foremost ethical considerations in AI-driven mental health interventions is privacy and confidentiality  (Ghadiri 2022; Shimada 2023) . Protecting patient data and ensuring confidentiality are paramount to building trust between users and AI systems. Researchers emphasize the importance of implementing robust data security measures and adhering to privacy regulations  (Murdoch 2021; Sivan and Zukarnain 2021) . By safeguarding patient privacy, AI interventions can uphold ethical principles while delivering personalized support to individuals seeking mental health assistance (Y. Chen and Esmaeilzadeh 2024; Murdoch 2021; Sivan and Zukarnain 2021) .\n\nResearchers stress the need for transparent communication, explainability of AI models, and the need to obtain informed consent from users before deploying AI interventions  (Cohen 2019; Pickering 2021; Ursin et al. 2021) . This includes providing clear information about the purpose, risks, and benefits of the technology  (Cohen 2019; Pickering 2021; Ursin et al. 2021) . Transparent communication fosters trust and empowers individuals to make informed decisions about their mental health care. By prioritizing informed consent, AI interventions can respect individuals' autonomy and promote collaborative decision-making between users and providers  (Cohen 2019; Ursin et al. 2021) .\n\nSeveral researchers have identified the risk of bias in AI algorithms, particularly in mental health diagnostics and treatment recommendations  (Gaonkar et al. 2023; Kerasidou 2021; Martin et al. 2022; Aditya Singhal et al. 2024; Tatineni 2019) . Addressing bias requires diverse and representative datasets, as well as algorithmic fairness assessments to mitigate disparities  (Gaonkar et al. 2023; Kerasidou 2021; Aditya Singhal et al. 2024; Tatineni 2019) . Bias in AI algorithms poses significant ethical challenges in mental health diagnostics and treatment recommendations. Studies have highlighted the importance of addressing bias through the use of diverse and representative datasets, algorithmic fairness assessments, and bias mitigation strategies  (Gaonkar et al. 2023; Kerasidou 2021; Martin et al. 2022; Aditya Singhal et al. 2024; Tatineni 2019) . Fairness in AI-driven mental health interventions ensures equitable access to care and minimizes disparities among diverse patient populations  (Ferrara 2023) . By promoting fairness, AI technologies can enhance the quality and effectiveness of mental health services while reducing the risk of harm  (Ferrara 2023; Aditya Singhal et al. 2024) .\n\nThere is a call for transparency in AI systems, including disclosure of how algorithms make decisions and accountability for their outcomes; this transparency fosters trust between users and AI systems  (Habli et al. 2020; Khanna and Srivastava 2020; Kiseleva et al. 2022; Aditya Singhal et al. 2024; Vollmer et al. 2020) . Transparency in AI systems is crucial for promoting accountability and trustworthiness  (Kiseleva et al. 2022) . Users should have insight into how algorithms make decisions and understand the limitations of AI technology  (de Bruijn et al. 2022; Lee 2018) . Ethical AI-driven mental health interventions prioritize transparency through clear explanations of algorithms' functionality and decision-making processes  (Koutsouleris et al. 2022; Aditya Singhal et al. 2024) . Accountability mechanisms hold developers and providers accountable for the outcomes of AI interventions, fostering responsible practice and ensuring positive outcomes for individuals  (Habli et al. 2020; Kiseleva et al. 2022; Aditya Singhal et al. 2024; Vollmer et al. 2020) .\n\nEthical AI in mental health respects individual autonomy and empowers users to make informed decisions about their treatment options  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Human oversight is essential to ensure that AI interventions complement rather than replace human judgment and agency  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Respecting individual autonomy and human agency is fundamental in ethical AI-driven mental health interventions  (Alowais et al. 2023) . While AI technologies can augment decision-making processes, human oversight is essential to ensure that interventions align with users' preferences and values  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Empowering individuals to actively participate in their mental health care promotes autonomy and self-determination  (Fanni et al. 2023; Love 2023; Tiribelli 2023) . Human-centered design approaches prioritize user autonomy and agency, emphasizing collaboration and shared decision making between users and AI systems  (Margetis et al. 2021; Usmani et al. 2023) .\n\nEnsuring the safety and efficacy of AI-driven mental health interventions is paramount; this involves rigorous testing, validation, and ongoing monitoring to detect and mitigate potential adverse effects  (Davahli et al. 2021; Ellahham et al. 2020; Habli et al. 2020; Morley et al. 2021; Tiwari and Dileep 2023) . Ensuring the safety and efficacy of AI-driven mental health interventions is paramount to protecting individuals from harm. Rigorous testing, validation, and ongoing monitoring are essential to detect and mitigate potential adverse effects  (Balcombe and De Leo 2021; Joerin et al. 2020; Tatineni 2019) . Ethical AI practices prioritize safety and efficacy, prioritizing the well-being of users and minimizing the risk of unintended consequences (J. P.  Singh 2021) . By upholding safety standards, AI interventions can enhance the quality and accessibility of mental health care while promoting positive outcomes for individuals (S. Graham et al. 2019; Habli et al. 2020; Mensah 2023; Reddy et al. 2019) .\n\nEthical frameworks and guidelines specific to promoting ethical AI in mental health are advocated for by the authors of many studies  (Jeyaraman et al. 2023; Siala and Wang 2022) . These frameworks provide a structured approach for addressing ethical challenges and promoting responsible practice  (Siala and Wang 2022; Zhang et al. 2023) . Developing and adopting ethical frameworks and guidelines specific to AI-driven mental health inter-ventions provide a structured approach for addressing ethical challenges  (Carr 2020) . These frameworks offer guidance on ethical decision making, risk assessment, and responsible practice  (Carr 2020; Molala and Makhubele 2021) . Stakeholder engagement throughout the development and implementation process ensures that ethical considerations are adequately addressed, promoting transparency and accountability in AI-driven mental health interventions  (B\u00e9lisle-Pipon et al. 2022; Couture et al. 2023; A. Singhal et al. 2024) .\n\nPractical strategies for mitigating bias in AI algorithms include diverse data collection, algorithmic audits, and ongoing evaluation to detect and correct biases that may arise during deployment (F. Chen et al. 2024; Ferrara 2023; Mensah 2023; Mittermaier et al. 2023) . Mitigating bias in AI algorithms is essential to ensure equitable and fair outcomes in mental health interventions  (Timmons et al. 2023) . Diverse data collection, algorithmic audits, and bias mitigation strategies are critical components of ethical AI practice (F. Chen et al. 2024; Ferrara 2023; Mensah 2023; Mittermaier et al. 2023) . Continuous evaluation and improvement efforts aim to detect and correct biases that may arise during deployment, promoting fairness and inclusivity in AI-driven mental health interventions (F. Chen et al. 2024; Mensah 2023; Mittermaier et al. 2023) .\n\nEthical AI practices require continuous evaluation and improvement to adapt to evolving ethical standards, technological advancements, and user needs (WHO Guidance 2021;  Magrabi et al. 2019; McGreevey et al. 2020; Morley et al. 2020) . Continuous evaluation and improvement are integral to ethical AI practice in mental health settings  (WHO Guidance 2021; McGreevey et al. 2020) . Monitoring and evaluating outcomes enable developers and providers to identify areas for improvement and adapt to evolving ethical standards and user needs (WHO Guidance 2021;  Magrabi et al. 2019; McGreevey et al. 2020; Morley et al. 2020) . Regular ethical reviews and stakeholder feedback contribute to ongoing refinement and optimization of AI-driven mental health interventions, ensuring that they remain ethically sound and beneficial to individuals seeking care  (Farhud and Zokaei 2021; WHO Guidance 2021; Leimanis and Palkova 2021; Nasir et al. 2024) .\n\nSeveral recent review studies, including that by  Li et al. (2023) , have critically examined the ethical implications of employing artificial intelligence (AI) in mental health interventions. Li, Han et al. synthesized evidence on the effectiveness of AI-driven conversational agents in enhancing mental health and well-being. Their findings offer valuable insights into the current evidence base for the use of conversational AI in mental health interventions, highlighting both its potential and limitations. Ethical concerns such as informed consent, privacy, transparency, and algorithmic bias were identified as significant challenges  (Li et al. 2023) . Another narrative review by A. M.  Alhuwaydi (2024)  explored the evolving role of AI in mental health care, addressing key challenges, limitations, and prospects. It underscored the potential of AI, particularly predictive analytics, in refining treatment strategies by predicting individual responses to interventions, thus aligning with the shift towards personalized mental health care. The review also scrutinized major ethical dimensions in AI-driven mental health, including algorithmic bias, data privacy, transparency, responsibility, and the doctor-patient relationship  (Alhuwaydi 2024) .\n\nAdditionally, Thakkar et al. (  2024 ) contributed a narrative review discussing AI's applications in managing psychiatric disorders such as neurodegenerative disorders, intellectual disabilities, and seizures. The paper explored AI's role in enhancing awareness, diagnosis, and intervention for mental health conditions. While highlighting AI's potential benefits, the review acknowledged significant challenges, emphasizing the necessity of culturally sensitive and flexible algorithms to mitigate potential biases. It provided a comprehensive overview of AI's current landscape and future prospects in mental health, alongside critical considerations and limitations that warrant attention for its responsible and effective integration into mental health care  (Thakkar et al. 2024) .\n\nTogether, these studies underscore the pressing ethical issues that must be addressed to ensure the safe and ethical use of AI in supporting mental health care. They emphasize the importance of informed consent, data privacy, algorithmic transparency, and maintaining human-centric approaches in AI-powered mental health interventions.\n\nNotably, regulating bodies such as the Federal Drug Administration (FDA) in the United States may play a role in ensuring that AI interventions are developed and deployed in an ethical manner. The AI interventions discussed in this paper could take many forms, such as specific algorithms, chatbots, or complete AI-enabled devices. AI-enabled medical devices may be subject to FDA approval, as noted in recent publications on the agency's website. While this can be a promising development for the protection of consumers, it will be critical that the FDA retain experts who are able to properly assess the ethical design and development of the AI components of these devices. Research like that discussed in this paper can offer an important source of information to inform the development of responsible regulation of AI devices."
    },
    {
      "title": "5.. Limitations of This Study",
      "text": "There are a few limitations to note for this study. This systematic review has a limited scope and mainly focuses on articles published in a specific time period  (2014) (2015) (2016) (2017) (2018) (2019) (2020) (2021) (2022) (2023) (2024)  in a limited set of databases  (PubMed, PsycINFO, Web of Science, and Scopus) . This narrow scope ignores studies or perspectives from other time periods or sources and limits the generalizability of the findings. The review's reliance on published articles may introduce publication bias, as studies with significant findings are more likely to be published than studies with negative results. This bias can distort the overall interpretation of ethical considerations in AI-based mental health interventions. Limiting the search to articles published in specific databases may lead to language bias, as relevant studies published in other languages or regions may be overlooked. This limitation can affect the comprehensiveness of the review findings. This review may not provide an accurate assessment of the quality of included studies, potentially overlooking methodological flaws or biases in the literature. Without robust quality assessment criteria, the reliability and validity of pooled findings may be compromised. Despite efforts to conduct a systematic review, biases inherent in the processes of study selection, data extraction, and synthesis may affect the interpretation of the findings. Future research should aim to overcome these limitations to provide a more comprehensive understanding of ethical considerations in AI-based mental health interventions and to inform responsible practice and policy development."
    },
    {
      "title": "6.. Conclusions",
      "text": "Ethical considerations play a central role in the responsible implementation and impact of AI-driven mental health interventions. By addressing privacy, informed consent, bias, transparency, autonomy, safety, and efficacy, ethical AI practice promotes responsible practice and positive outcomes for individuals. Ethical frameworks, stakeholder engagement, bias mitigation strategies, and continuous evaluation efforts contribute to the ethical development and deployment of AI interventions, fostering trust, fairness, and effectiveness in mental healthcare delivery. As AI technology continues to evolve, prioritizing ethical considerations remains essential to maximizing benefits while minimizing potential harms in mental health interventions. These findings collectively underscore the importance of prioritizing ethical considerations in the development and deployment of AI interventions in mental health. By addressing these concerns, researchers and practitioners can ensure that AI technologies contribute positively to mental health care while minimizing potential risks and harms."
    },
    {
      "title": "Supplementary Materials:",
      "text": "The following supporting information can be downloaded at:  https:  //www.mdpi.com/article/10.3390/socsci13070381/s1 ."
    },
    {
      "text": "Figure 1. Flow diagram showing the study selection/screening process."
    },
    {
      "text": "Figure 1. Flow diagram showing the study selection/screening process."
    },
    {
      "text": "Contributions: Conceptualization, H.R.S. and N.G.; methodology, S.G.H.F. and B.L.; validation, B.L.; formal analysis, H.R.S.; investigation, N.G.; resources, S.G.H.F.; data curation, H.R.S., N.G., B.L. and S.G.H.F.; writing-original draft preparation, H.R.S. and B.L.; writing-review and editing, B.L.; visualization, H.R.S.; supervision, N.G.; project administration, N.G. All authors have read and agreed to the published version of the manuscript. Funding: This research received no external funding."
    },
    {
      "text": "Ethical considerations of artificial intelligence interventions in mental health and well-being."
    },
    {
      "text": "Considerations for integrating ethical principles for responsible practice and positive outcomes in ai technologies for mental health settings."
    },
    {
      "text": "Cont."
    },
    {
      "text": "Best Practices for ethical use of ai in mental health interventions: guidelines and recommendations."
    },
    {
      "text": "Cont."
    },
    {
      "text": "Data Availability Statement: Data is contained within the article or Supplementary Materials."
    },
    {
      "text": "Institutional Review Board Statement: Not applicable.\n\nInformed Consent Statement: Not applicable."
    },
    {
      "title": "Conflicts of Interest:",
      "text": "The authors declare no conflict of interest."
    }
  ],
  "references": [
    {
      "title": "Exploring the Role of Artificial Intelligence in Mental Healthcare: Current Trends and Future Directions-A Narrative Review for a Comprehensive Insight",
      "authors": [
        "Ahmed Alhuwaydi"
      ],
      "year": 2024,
      "doi": "10.2147/rmhp.s461562",
      "journal": "Risk Management and Healthcare Policy",
      "volume": "17",
      "raw": "Exploring the Role of Artificial Intelligence in Mental Healthcare: Current Trends and Future Directions-A Narrative Review for a Comprehensive Insight \n\t\t \n\t\t\t Ahmed M Alhuwaydi \n\t\t \n\t\t 10.2147/rmhp.s461562 \n\t \n\t \n\t\t Risk Management and Healthcare Policy \n\t\t \n\t\t\t 17 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Alhuwaydi, Ahmed M. 2024. Exploring the Role of Artificial Intelligence in Mental Healthcare: Current Trends and Future Directions- A Narrative Review for a Comprehensive Insight. Risk Management and Healthcare Policy 17: 1339-48."
    },
    {
      "doi": "10.2147/RMHP.S461562",
      "raw": "10.2147/RMHP.S461562 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Revolutionizing healthcare: The role of artificial intelligence in clinical practice",
      "authors": [
        "Shuroug Alowais",
        "S Sahar",
        "Nada Alghamdi",
        "Tariq Alsuhebany",
        "Abdulrahman Alqahtani",
        "N Sumaya",
        "Atheer Almohareb",
        "Mohammed Aldairem",
        "Bin Khalid",
        "Hisham Saleh"
      ],
      "year": 2023,
      "doi": "10.1186/s12909-023-04698-z",
      "journal": "BMC Medical Education",
      "volume": "23",
      "pages": "689",
      "raw": "Revolutionizing healthcare: The role of artificial intelligence in clinical practice \n\t\t \n\t\t\t Shuroug A Alowais \n\t\t \n\t\t \n\t\t\t S Sahar \n\t\t \n\t\t \n\t\t\t Nada Alghamdi \n\t\t \n\t\t \n\t\t\t Tariq Alsuhebany \n\t\t \n\t\t \n\t\t\t Abdulrahman I Alqahtani \n\t\t \n\t\t \n\t\t\t Alshaya \n\t\t \n\t\t \n\t\t\t N Sumaya \n\t\t \n\t\t \n\t\t\t Atheer Almohareb \n\t\t \n\t\t \n\t\t\t Mohammed Aldairem \n\t\t \n\t\t \n\t\t\t Alrashed \n\t\t \n\t\t \n\t\t\t Bin Khalid \n\t\t \n\t\t \n\t\t\t Hisham A Saleh \n\t\t \n\t\t \n\t\t\t Badreldin \n\t\t \n\t\t 10.1186/s12909-023-04698-z \n\t \n\t \n\t\t BMC Medical Education \n\t\t \n\t\t\t 23 \n\t\t\t 689 \n\t\t\t 2023 \n\t\t \n\t \n\t Alowais, Shuroug A., Sahar S. Alghamdi, Nada Alsuhebany, Tariq Alqahtani, Abdulrahman I. Alshaya, Sumaya N. Almohareb, Atheer Aldairem, Mohammed Alrashed, Khalid Bin Saleh, Hisham A. Badreldin, and et al. 2023. Revolutionizing healthcare: The role of artificial intelligence in clinical practice. BMC Medical Education 23: 689. [CrossRef"
    },
    {
      "title": "AI Chatbots in Digital Mental Health",
      "authors": [
        "Luke Balcombe"
      ],
      "year": 2023,
      "doi": "10.3390/informatics10040082",
      "journal": "Informatics",
      "volume": "10",
      "pages": "82",
      "raw": "AI Chatbots in Digital Mental Health \n\t\t \n\t\t\t Luke Balcombe \n\t\t \n\t\t 10.3390/informatics10040082 \n\t \n\t \n\t\t Informatics \n\t\t \n\t\t\t 10 \n\t\t\t 82 \n\t\t\t 2023 \n\t\t \n\t \n\t Balcombe, Luke. 2023. AI Chatbots in Digital Mental Health. Informatics 10: 82."
    },
    {
      "doi": "10.3390/informatics10040082",
      "raw": "10.3390/informatics10040082 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Digital mental health challenges and the horizon ahead for solutions",
      "authors": [
        "Luke Balcombe",
        "Diego Leo"
      ],
      "year": 2021,
      "journal": "JMIR Mental Health",
      "volume": "8",
      "pages": "26811",
      "raw": "Digital mental health challenges and the horizon ahead for solutions \n\t\t \n\t\t\t Luke Balcombe \n\t\t \n\t\t \n\t\t\t Diego De Leo \n\t\t \n\t \n\t \n\t\t JMIR Mental Health \n\t\t \n\t\t\t 8 \n\t\t\t 26811 \n\t\t\t 2021 \n\t\t \n\t \n\t Balcombe, Luke, and Diego De Leo. 2021. Digital mental health challenges and the horizon ahead for solutions. JMIR Mental Health 8: e26811."
    },
    {
      "doi": "10.2196/26811",
      "raw": "10.2196/26811 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "A health systems ethical framework for de-implementation in health care",
      "authors": [
        "Alison Baskin",
        "Ton Wang",
        "Jacquelyn Miller",
        "Reshma Jagsi",
        "Eve Kerr",
        "Lesly Dossett"
      ],
      "year": 2021,
      "journal": "Journal of Surgical Research",
      "volume": "267",
      "raw": "A health systems ethical framework for de-implementation in health care \n\t\t \n\t\t\t Alison S Baskin \n\t\t \n\t\t \n\t\t\t Ton Wang \n\t\t \n\t\t \n\t\t\t Jacquelyn Miller \n\t\t \n\t\t \n\t\t\t Reshma Jagsi \n\t\t \n\t\t \n\t\t\t Eve A Kerr \n\t\t \n\t\t \n\t\t\t Lesly A Dossett \n\t\t \n\t \n\t \n\t\t Journal of Surgical Research \n\t\t \n\t\t\t 267 \n\t\t\t \n\t\t\t 2021 \n\t\t \n\t \n\t Baskin, Alison S., Ton Wang, Jacquelyn Miller, Reshma Jagsi, Eve A. Kerr, and Lesly A. Dossett. 2021. A health systems ethical framework for de-implementation in health care. Journal of Surgical Research 267: 151-58."
    },
    {
      "doi": "10.1016/j.jss.2021.05.006",
      "raw": "10.1016/j.jss.2021.05.006 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Artificial intelligence ethics has a black box problem",
      "authors": [
        "Erica Jean-Christophe",
        "Marie-Christine Monteferrante",
        "Vincent Roy"
      ],
      "year": 2022,
      "doi": "10.1007/s00146-021-01380-0",
      "journal": "AI & Socety",
      "volume": "38",
      "raw": "Artificial intelligence ethics has a black box problem \n\t\t \n\t\t\t B\u00e9lisle-Pipon \n\t\t \n\t\t \n\t\t\t Erica Jean-Christophe \n\t\t \n\t\t \n\t\t\t Marie-Christine Monteferrante \n\t\t \n\t\t \n\t\t\t Vincent Roy \n\t\t \n\t\t \n\t\t\t Couture \n\t\t \n\t\t 10.1007/s00146-021-01380-0 \n\t \n\t \n\t\t AI & Socety \n\t\t \n\t\t\t 38 \n\t\t\t \n\t\t\t 2022 \n\t\t \n\t \n\t B\u00e9lisle-Pipon, Jean-Christophe, Erica Monteferrante, Marie-Christine Roy, and Vincent Couture. 2022. Artificial intelligence ethics has a black box problem. AI & Socety 38: 1507-22."
    },
    {
      "doi": "10.1007/s00146-021-01380-0",
      "raw": "10.1007/s00146-021-01380-0 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "AI gone mental': Engagement and ethics in data-driven technology for mental health",
      "authors": [
        "Sarah Carr"
      ],
      "year": 2020,
      "journal": "Journal of Mental Health",
      "volume": "29",
      "raw": "AI gone mental': Engagement and ethics in data-driven technology for mental health \n\t\t \n\t\t\t Sarah Carr \n\t\t \n\t \n\t \n\t\t Journal of Mental Health \n\t\t \n\t\t\t 29 \n\t\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Carr, Sarah. 2020. 'AI gone mental': Engagement and ethics in data-driven technology for mental health. Journal of Mental Health 29: 125-30."
    },
    {
      "doi": "10.1080/09638237.2020.1714011",
      "raw": "10.1080/09638237.2020.1714011 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "An Evaluation of General-Purpose AI Chatbots: A Comprehensive Comparative Analysis",
      "authors": [
        "Oleksii Chalyi"
      ],
      "year": 2024,
      "journal": "InfoScience Trends",
      "volume": "1",
      "raw": "An Evaluation of General-Purpose AI Chatbots: A Comprehensive Comparative Analysis \n\t\t \n\t\t\t Oleksii Chalyi \n\t\t \n\t \n\t \n\t\t InfoScience Trends \n\t\t \n\t\t\t 1 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Chalyi, Oleksii. 2024. An Evaluation of General-Purpose AI Chatbots: A Comprehensive Comparative Analysis. InfoScience Trends 1: 52-66."
    },
    {
      "doi": "10.61186/ist.202401.01.07",
      "raw": "10.61186/ist.202401.01.07 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "New WHO prevalence estimates of mental disorders in conflict settings: A systematic review and meta-analysis",
      "authors": [
        "Fiona Charlson",
        "Abraham Van Mark Ommeren",
        "Joseph Flaxman",
        "Harvey Cornett",
        "Shekhar Whiteford"
      ],
      "year": 2019,
      "doi": "10.1016/s0140-6736(19)30934-1",
      "journal": "The Lancet",
      "volume": "394",
      "raw": "New WHO prevalence estimates of mental disorders in conflict settings: A systematic review and meta-analysis \n\t\t \n\t\t\t Fiona Charlson \n\t\t \n\t\t \n\t\t\t Abraham Van Mark Ommeren \n\t\t \n\t\t \n\t\t\t Joseph Flaxman \n\t\t \n\t\t \n\t\t\t Harvey Cornett \n\t\t \n\t\t \n\t\t\t Shekhar Whiteford \n\t\t \n\t\t \n\t\t\t Saxena \n\t\t \n\t\t 10.1016/s0140-6736(19)30934-1 \n\t \n\t \n\t\t The Lancet \n\t\t \n\t\t\t 394 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Charlson, Fiona, van Mark Ommeren, Abraham Flaxman, Joseph Cornett, Harvey Whiteford, and Shekhar Saxena. 2019. New WHO prevalence estimates of mental disorders in conflict settings: A systematic review and meta-analysis. The Lancet 394: 240-48."
    },
    {
      "title": "Unmasking bias in artificial intelligence: A systematic review of bias detection and mitigation strategies in electronic health record-based models",
      "authors": [
        "Feng Chen",
        "Liqin Wang",
        "Julie Hong",
        "Jiaqi Jiang",
        "Li Zhou"
      ],
      "year": 2024,
      "journal": "Journal of the American Medical Informatics Association",
      "volume": "31",
      "raw": "Unmasking bias in artificial intelligence: A systematic review of bias detection and mitigation strategies in electronic health record-based models \n\t\t \n\t\t\t Feng Chen \n\t\t \n\t\t \n\t\t\t Liqin Wang \n\t\t \n\t\t \n\t\t\t Julie Hong \n\t\t \n\t\t \n\t\t\t Jiaqi Jiang \n\t\t \n\t\t \n\t\t\t Li Zhou \n\t\t \n\t \n\t \n\t\t Journal of the American Medical Informatics Association \n\t\t \n\t\t\t 31 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Chen, Feng, Liqin Wang, Julie Hong, Jiaqi Jiang, and Li Zhou. 2024. Unmasking bias in artificial intelligence: A systematic review of bias detection and mitigation strategies in electronic health record-based models. Journal of the American Medical Informatics Association 31: 1172-83."
    },
    {
      "doi": "10.1093/jamia/ocae060",
      "raw": "10.1093/jamia/ocae060 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Generative AI in medical practice: In-depth exploration of privacy and security challenges",
      "authors": [
        "Yan Chen",
        "Pouyan Esmaeilzadeh"
      ],
      "year": 2024,
      "journal": "Journal of Medical Internet Research",
      "volume": "26",
      "pages": "53008",
      "raw": "Generative AI in medical practice: In-depth exploration of privacy and security challenges \n\t\t \n\t\t\t Yan Chen \n\t\t \n\t\t \n\t\t\t Pouyan Esmaeilzadeh \n\t\t \n\t \n\t \n\t\t Journal of Medical Internet Research \n\t\t \n\t\t\t 26 \n\t\t\t 53008 \n\t\t\t 2024 \n\t\t \n\t \n\t Chen, Yan, and Pouyan Esmaeilzadeh. 2024. Generative AI in medical practice: In-depth exploration of privacy and security challenges. Journal of Medical Internet Research 26: e53008."
    },
    {
      "doi": "10.2196/53008",
      "raw": "10.2196/53008 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Data Privacy and Security Challenges in AI-Driven Healthcare Systems in India",
      "authors": [
        "Sathish Chintala"
      ],
      "year": 2022,
      "journal": "Journal of Data Acquisition and Processing",
      "volume": "37",
      "raw": "Data Privacy and Security Challenges in AI-Driven Healthcare Systems in India \n\t\t \n\t\t\t Sathish Chintala \n\t\t \n\t\t \n\t\t\t Kumar \n\t\t \n\t \n\t \n\t\t Journal of Data Acquisition and Processing \n\t\t \n\t\t\t 37 \n\t\t\t \n\t\t\t 2022 \n\t\t \n\t \n\t Chintala, Sathish Kumar. 2022. Data Privacy and Security Challenges in AI-Driven Healthcare Systems in India. Journal of Data Acquisition and Processing 37: 2769-78."
    },
    {
      "title": "Informed consent and medical artificial intelligence: What to tell the patient?",
      "authors": [
        "I Cohen"
      ],
      "year": 2019,
      "journal": "The Georgetown Law Journal",
      "volume": "108",
      "pages": "1425",
      "raw": "Informed consent and medical artificial intelligence: What to tell the patient? \n\t\t \n\t\t\t I Cohen \n\t\t \n\t\t \n\t\t\t Glenn \n\t\t \n\t \n\t \n\t\t The Georgetown Law Journal \n\t\t \n\t\t\t 108 \n\t\t\t 1425 \n\t\t\t 2019 \n\t\t \n\t \n\t Cohen, I. Glenn. 2019. Informed consent and medical artificial intelligence: What to tell the patient? The Georgetown Law Journal 108: 1425."
    },
    {
      "doi": "10.2139/ssrn.3529576",
      "raw": "10.2139/ssrn.3529576 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical implications of artificial intelligence in population health and the public's role in its governance: Perspectives from a citizen and expert panel",
      "authors": [
        "Vincent Couture",
        "Marie-Christine Roy",
        "Emma Dez",
        "Samuel Laperle",
        "Jean-Christophe B\u00e9lisle-Pipon"
      ],
      "year": 2023,
      "doi": "10.2196/44357",
      "journal": "Journal of Medical Internet Research",
      "volume": "25",
      "pages": "44357",
      "raw": "Ethical implications of artificial intelligence in population health and the public's role in its governance: Perspectives from a citizen and expert panel \n\t\t \n\t\t\t Vincent Couture \n\t\t \n\t\t \n\t\t\t Marie-Christine Roy \n\t\t \n\t\t \n\t\t\t Emma Dez \n\t\t \n\t\t \n\t\t\t Samuel Laperle \n\t\t \n\t\t \n\t\t\t Jean-Christophe B\u00e9lisle-Pipon \n\t\t \n\t\t 10.2196/44357 \n\t \n\t \n\t\t Journal of Medical Internet Research \n\t\t \n\t\t\t 25 \n\t\t\t 44357 \n\t\t\t 2023 \n\t\t \n\t \n\t Couture, Vincent, Marie-Christine Roy, Emma Dez, Samuel Laperle, and Jean-Christophe B\u00e9lisle-Pipon. 2023. Ethical implications of artificial intelligence in population health and the public's role in its governance: Perspectives from a citizen and expert panel. Journal of Medical Internet Research 25: e44357."
    },
    {
      "doi": "10.2196/44357",
      "raw": "10.2196/44357 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Controlling safety of artificial intelligence-based systems in healthcare",
      "authors": [
        "Mohammad Davahli",
        "Waldemar Reza",
        "Krzysztof Karwowski",
        "Thomas Fiok",
        "Hamid Wan"
      ],
      "year": 2021,
      "journal": "Symmetry",
      "volume": "13",
      "pages": "102",
      "raw": "Controlling safety of artificial intelligence-based systems in healthcare \n\t\t \n\t\t\t Mohammad Davahli \n\t\t \n\t\t \n\t\t\t Waldemar Reza \n\t\t \n\t\t \n\t\t\t Krzysztof Karwowski \n\t\t \n\t\t \n\t\t\t Thomas Fiok \n\t\t \n\t\t \n\t\t\t Hamid R Wan \n\t\t \n\t\t \n\t\t\t Parsaei \n\t\t \n\t \n\t \n\t\t Symmetry \n\t\t \n\t\t\t 13 \n\t\t\t 102 \n\t\t\t 2021 \n\t\t \n\t \n\t Davahli, Mohammad Reza, Waldemar Karwowski, Krzysztof Fiok, Thomas Wan, and Hamid R. Parsaei. 2021. Controlling safety of artificial intelligence-based systems in healthcare. Symmetry 13: 102."
    },
    {
      "doi": "10.3390/sym13010102",
      "raw": "10.3390/sym13010102 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "The perils and pitfalls of explainable AI: Strategies for explaining algorithmic decision-making",
      "authors": [
        "Martijn Hans",
        "Marijn Warnier"
      ],
      "year": 2022,
      "doi": "10.1016/j.giq.2021.101666",
      "journal": "Government Information Quarterly",
      "volume": "39",
      "pages": "101666",
      "raw": "The perils and pitfalls of explainable AI: Strategies for explaining algorithmic decision-making \n\t\t \n\t\t\t De Bruijn \n\t\t \n\t\t \n\t\t\t Martijn Hans \n\t\t \n\t\t \n\t\t\t Marijn Warnier \n\t\t \n\t\t \n\t\t\t Janssen \n\t\t \n\t\t 10.1016/j.giq.2021.101666 \n\t \n\t \n\t\t Government Information Quarterly \n\t\t \n\t\t\t 39 \n\t\t\t 101666 \n\t\t\t 2022 \n\t\t \n\t \n\t de Bruijn, Hans, Martijn Warnier, and Marijn Janssen. 2022. The perils and pitfalls of explainable AI: Strategies for explaining algorithmic decision-making. Government Information Quarterly 39: 101666."
    },
    {
      "doi": "10.1016/j.giq.2021.101666",
      "raw": "10.1016/j.giq.2021.101666 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Application of artificial intelligence in the health care safety context: Opportunities and challenges",
      "authors": [
        "Samer Ellahham",
        "Nour Ellahham",
        "Mecit Can",
        "Emre Simsekler"
      ],
      "year": 2020,
      "journal": "American Journal of Medical Quality",
      "volume": "35",
      "raw": "Application of artificial intelligence in the health care safety context: Opportunities and challenges \n\t\t \n\t\t\t Samer Ellahham \n\t\t \n\t\t \n\t\t\t Nour Ellahham \n\t\t \n\t\t \n\t\t\t Mecit Can \n\t\t \n\t\t \n\t\t\t Emre Simsekler \n\t\t \n\t \n\t \n\t\t American Journal of Medical Quality \n\t\t \n\t\t\t 35 \n\t\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Ellahham, Samer, Nour Ellahham, and Mecit Can Emre Simsekler. 2020. Application of artificial intelligence in the health care safety context: Opportunities and challenges. American Journal of Medical Quality 35: 341-48."
    },
    {
      "doi": "10.1177/1062860619878515",
      "raw": "10.1177/1062860619878515 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "AI-Enhanced Health Tools for Revolutionizing Hypertension Management and Blood Pressure Control",
      "authors": [
        "Aysan Faezi",
        "Bahman Alinezhad"
      ],
      "year": 2024,
      "doi": "10.61186/ist.202401.01.08",
      "journal": "InfoScience Trends",
      "volume": "1",
      "raw": "AI-Enhanced Health Tools for Revolutionizing Hypertension Management and Blood Pressure Control \n\t\t \n\t\t\t Aysan Faezi \n\t\t \n\t\t \n\t\t\t Bahman Alinezhad \n\t\t \n\t\t 10.61186/ist.202401.01.08 \n\t \n\t \n\t\t InfoScience Trends \n\t\t \n\t\t\t 1 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Faezi, Aysan, and Bahman Alinezhad. 2024. AI-Enhanced Health Tools for Revolutionizing Hypertension Management and Blood Pressure Control. InfoScience Trends 1: 67-72."
    },
    {
      "doi": "10.61186/ist.202401.01.08",
      "raw": "10.61186/ist.202401.01.08 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Enhancing human agency through redress in Artificial Intelligence Systems",
      "authors": [
        "Rosanna Fanni",
        "Giulia Zampedri",
        "Valerie Steinkogler",
        "Jo Pierson"
      ],
      "year": 2023,
      "doi": "10.1007/s00146-022-01454-7",
      "journal": "AI & Society",
      "volume": "38",
      "raw": "Enhancing human agency through redress in Artificial Intelligence Systems \n\t\t \n\t\t\t Rosanna Fanni \n\t\t \n\t\t \n\t\t\t Giulia Zampedri \n\t\t \n\t\t \n\t\t\t Valerie Eveline Steinkogler \n\t\t \n\t\t \n\t\t\t Jo Pierson \n\t\t \n\t\t 10.1007/s00146-022-01454-7 \n\t \n\t \n\t\t AI & Society \n\t\t \n\t\t\t 38 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Fanni, Rosanna, Giulia Zampedri Valerie Eveline Steinkogler, and Jo Pierson. 2023. Enhancing human agency through redress in Artificial Intelligence Systems. AI & Society 38: 537-47."
    },
    {
      "title": "Ethical Issues of Artificial Intelligence in Medicine and Healthcare",
      "authors": [
        "Dariush Farhud",
        "Shaghayegh Zokaei"
      ],
      "year": 2021,
      "doi": "10.18502/ijph.v50i11.7600",
      "journal": "Iranian Journal of Public Health",
      "volume": "50",
      "raw": "Ethical Issues of Artificial Intelligence in Medicine and Healthcare \n\t\t \n\t\t\t Dariush D Farhud \n\t\t \n\t\t \n\t\t\t Shaghayegh Zokaei \n\t\t \n\t\t 10.18502/ijph.v50i11.7600 \n\t \n\t \n\t\t Iranian Journal of Public Health \n\t\t \n\t\t\t 50 \n\t\t\t \n\t\t\t 2021 \n\t\t \n\t \n\t Farhud, Dariush D., and Shaghayegh Zokaei. 2021. Ethical Issues of Artificial Intelligence in Medicine and Healthcare. Iranian Journal of Public Health 50: I-V. [CrossRef]"
    },
    {
      "title": "Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies",
      "authors": [
        "Emilio Ferrara"
      ],
      "year": 2023,
      "doi": "10.3390/sci6010003",
      "journal": "Sci",
      "volume": "6",
      "issue": "3",
      "raw": "Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies \n\t\t \n\t\t\t Emilio Ferrara \n\t\t \n\t\t 10.3390/sci6010003 \n\t \n\t \n\t\t Sci \n\t\t \n\t\t\t 6 \n\t\t\t 3 \n\t\t\t 2023 \n\t\t \n\t \n\t Ferrara, Emilio. 2023. Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies. Sci 6: 3."
    },
    {
      "doi": "10.3390/sci6010003",
      "raw": "10.3390/sci6010003 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical Issues Arising Due to Bias in Training A.I. Algorithms in Healthcare and Data Sharing as a Potential Solution",
      "authors": [
        "Bilwaj Gaonkar",
        "Kirstin Cook",
        "Luke Macyszyn"
      ],
      "year": 2023,
      "doi": "10.47289/aiej20200916",
      "journal": "The AI Ethics Journal",
      "volume": "1",
      "raw": "Ethical Issues Arising Due to Bias in Training A.I. Algorithms in Healthcare and Data Sharing as a Potential Solution \n\t\t \n\t\t\t Bilwaj Gaonkar \n\t\t \n\t\t \n\t\t\t Kirstin Cook \n\t\t \n\t\t \n\t\t\t Luke Macyszyn \n\t\t \n\t\t 10.47289/aiej20200916 \n\t \n\t \n\t\t The AI Ethics Journal \n\t\t \n\t\t\t 1 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Gaonkar, Bilwaj, Kirstin Cook, and Luke Macyszyn. 2023. Ethical Issues Arising Due to Bias in Training A.I. Algorithms in Healthcare and Data Sharing as a Potential Solution. The AI Ethics Journal 1: 1-14."
    },
    {
      "doi": "10.47289/aiej20200916",
      "raw": "10.47289/aiej20200916 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Artificial Intelligence Interventions in the Mental Healthcare of Adolescents",
      "authors": [
        "Pooria Ghadiri"
      ],
      "year": 2022,
      "doi": "10.2196/preprints.55686",
      "raw": "Pooria Ghadiri \n\t\t \n\t\t 10.2196/preprints.55686 \n\t\t Artificial Intelligence Interventions in the Mental Healthcare of Adolescents \n\t\t Montr\u00e9al \n\t\t \n\t\t\t 2022 \n\t\t \n\t\t \n\t\t\t McGill University \n\t\t \n\t \n\t Ghadiri, Pooria. 2022. Artificial Intelligence Interventions in the Mental Healthcare of Adolescents. Montr\u00e9al: McGill University."
    },
    {
      "title": "Ethics and law in research on algorithmic and data-driven technology in mental health care: Scoping review",
      "authors": [
        "Piers Gooding",
        "Timothy Kariotis"
      ],
      "year": 2021,
      "doi": "10.2196/24668",
      "journal": "JMIR Mental Health",
      "volume": "8",
      "pages": "24668",
      "raw": "Ethics and law in research on algorithmic and data-driven technology in mental health care: Scoping review \n\t\t \n\t\t\t Piers Gooding \n\t\t \n\t\t \n\t\t\t Timothy Kariotis \n\t\t \n\t\t 10.2196/24668 \n\t \n\t \n\t\t JMIR Mental Health \n\t\t \n\t\t\t 8 \n\t\t\t 24668 \n\t\t\t 2021 \n\t\t \n\t \n\t Gooding, Piers, and Timothy Kariotis. 2021. Ethics and law in research on algorithmic and data-driven technology in mental health care: Scoping review. JMIR Mental Health 8: e24668."
    },
    {
      "doi": "10.2196/24668",
      "raw": "10.2196/24668 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Artificial intelligence for mental health and mental illnesses: An Overview",
      "authors": [
        "Sarah Graham",
        "Colin Depp",
        "Ellen Lee",
        "Camille Nebeker",
        "Xin Tu",
        "Ho-Cheol Kim",
        "Dilip Jeste"
      ],
      "year": 2019,
      "doi": "10.1007/s11920-019-1094-0",
      "journal": "Current Psychiatry Reports",
      "volume": "21",
      "pages": "116",
      "raw": "Artificial intelligence for mental health and mental illnesses: An Overview \n\t\t \n\t\t\t Sarah Graham \n\t\t \n\t\t \n\t\t\t Colin Depp \n\t\t \n\t\t \n\t\t\t Ellen E Lee \n\t\t \n\t\t \n\t\t\t Camille Nebeker \n\t\t \n\t\t \n\t\t\t Xin Tu \n\t\t \n\t\t \n\t\t\t Ho-Cheol Kim \n\t\t \n\t\t \n\t\t\t Dilip V Jeste \n\t\t \n\t\t 10.1007/s11920-019-1094-0 \n\t \n\t \n\t\t Current Psychiatry Reports \n\t\t \n\t\t\t 21 \n\t\t\t 116 \n\t\t\t 2019 \n\t\t \n\t \n\t Graham, Sarah, Colin Depp, Ellen E. Lee, Camille Nebeker, Xin Tu, Ho-Cheol Kim, and Dilip V. Jeste. 2019. Artificial intelligence for mental health and mental illnesses: An Overview. Current Psychiatry Reports 21: 116."
    },
    {
      "doi": "10.1007/s11920-019-1094-0",
      "raw": "10.1007/s11920-019-1094-0 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Artificial intelligence in health care: Accountability and safety",
      "authors": [
        "Ibrahim Habli",
        "Tom Lawton",
        "Zoe Porter"
      ],
      "year": 2020,
      "doi": "10.2471/BLT.19.237487",
      "journal": "Bulletin of the World Health Organization",
      "volume": "98",
      "raw": "Artificial intelligence in health care: Accountability and safety \n\t\t \n\t\t\t Ibrahim Habli \n\t\t \n\t\t \n\t\t\t Tom Lawton \n\t\t \n\t\t \n\t\t\t Zoe Porter \n\t\t \n\t\t 10.2471/BLT.19.237487 \n\t \n\t \n\t\t Bulletin of the World Health Organization \n\t\t \n\t\t\t 98 \n\t\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Habli, Ibrahim, Tom Lawton, and Zoe Porter. 2020. Artificial intelligence in health care: Accountability and safety. Bulletin of the World Health Organization 98: 251-56. [CrossRef]"
    },
    {
      "title": "Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare",
      "authors": [
        "Madhan Jeyaraman",
        "Sangeetha Balaji",
        "Naveen Jeyaraman",
        "Sankalp Yadav"
      ],
      "year": 2023,
      "doi": "10.7759/cureus.43262",
      "journal": "Cureus",
      "volume": "15",
      "pages": "43262",
      "raw": "Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare \n\t\t \n\t\t\t Madhan Jeyaraman \n\t\t \n\t\t \n\t\t\t Sangeetha Balaji \n\t\t \n\t\t \n\t\t\t Naveen Jeyaraman \n\t\t \n\t\t \n\t\t\t Sankalp Yadav \n\t\t \n\t\t 10.7759/cureus.43262 \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 15 \n\t\t\t 43262 \n\t\t\t 2023 \n\t\t \n\t \n\t Jeyaraman, Madhan, Sangeetha Balaji, Naveen Jeyaraman, and Sankalp Yadav. 2023. Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare. Cureus 15: e43262."
    },
    {
      "doi": "10.7759/cureus.43262",
      "raw": "10.7759/cureus.43262 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical Artificial Intelligence for Digital Health Organizations",
      "authors": [
        "Angela Joerin",
        "Michiel Rauws",
        "Russell Fulmer",
        "Valerie Black"
      ],
      "year": 2020,
      "doi": "10.7759/cureus.7202",
      "journal": "Cureus",
      "volume": "12",
      "pages": "7202",
      "raw": "Ethical Artificial Intelligence for Digital Health Organizations \n\t\t \n\t\t\t Angela Joerin \n\t\t \n\t\t \n\t\t\t Michiel Rauws \n\t\t \n\t\t \n\t\t\t Russell Fulmer \n\t\t \n\t\t \n\t\t\t Valerie Black \n\t\t \n\t\t 10.7759/cureus.7202 \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 12 \n\t\t\t 7202 \n\t\t\t 2020 \n\t\t \n\t \n\t Joerin, Angela, Michiel Rauws, Russell Fulmer, and Valerie Black. 2020. Ethical Artificial Intelligence for Digital Health Organizations. Cureus 12: e7202."
    },
    {
      "doi": "10.7759/cureus.7202",
      "raw": "10.7759/cureus.7202 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical Considerations in the Adoption of Artificial Intelligence for Mental Health Diagnosis",
      "authors": [
        "Balaram Kasula"
      ],
      "year": 2023,
      "journal": "International Journal of Creative Research In Computer Technology and Design",
      "volume": "5",
      "raw": "Ethical Considerations in the Adoption of Artificial Intelligence for Mental Health Diagnosis \n\t\t \n\t\t\t Balaram Kasula \n\t\t \n\t\t \n\t\t\t Yadav \n\t\t \n\t \n\t \n\t\t International Journal of Creative Research In Computer Technology and Design \n\t\t \n\t\t\t 5 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Kasula, Balaram Yadav. 2023. Ethical Considerations in the Adoption of Artificial Intelligence for Mental Health Diagnosis. International Journal of Creative Research In Computer Technology and Design 5: 1-7."
    },
    {
      "title": "Ethics of artificial intelligence in global health: Explainability, algorithmic bias and trust",
      "authors": [
        "Angeliki Kerasidou"
      ],
      "year": 2021,
      "doi": "10.1016/j.jobcr.2021.09.004",
      "journal": "Journal of Oral Biology and Craniofacial Research",
      "volume": "11",
      "raw": "Ethics of artificial intelligence in global health: Explainability, algorithmic bias and trust \n\t\t \n\t\t\t Angeliki Kerasidou \n\t\t \n\t\t 10.1016/j.jobcr.2021.09.004 \n\t \n\t \n\t\t Journal of Oral Biology and Craniofacial Research \n\t\t \n\t\t\t 11 \n\t\t\t \n\t\t\t 2021 \n\t\t \n\t \n\t Kerasidou, Angeliki. 2021. Ethics of artificial intelligence in global health: Explainability, algorithmic bias and trust. Journal of Oral Biology and Craniofacial Research 11: 612-14."
    },
    {
      "doi": "10.1016/j.jobcr.2021.09.004",
      "raw": "10.1016/j.jobcr.2021.09.004 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Patient-centric ethical frameworks for privacy, transparency, and bias awareness in deep learning-based medical systems",
      "authors": [
        "Shivansh Khanna",
        "Shraddha Srivastava"
      ],
      "year": 2020,
      "doi": "10.33140/amlai.05.03.03",
      "journal": "Applied Research in Artificial Intelligence and Cloud Computing",
      "volume": "3",
      "raw": "Patient-centric ethical frameworks for privacy, transparency, and bias awareness in deep learning-based medical systems \n\t\t \n\t\t\t Shivansh Khanna \n\t\t \n\t\t \n\t\t\t Shraddha Srivastava \n\t\t \n\t\t 10.33140/amlai.05.03.03 \n\t \n\t \n\t\t Applied Research in Artificial Intelligence and Cloud Computing \n\t\t \n\t\t\t 3 \n\t\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t Khanna, Shivansh, and Shraddha Srivastava. 2020. Patient-centric ethical frameworks for privacy, transparency, and bias awareness in deep learning-based medical systems. Applied Research in Artificial Intelligence and Cloud Computing 3: 16-35."
    },
    {
      "title": "Transparency of AI in healthcare as a multilayered system of accountabilities: Between legal requirements and technical limitations",
      "authors": [
        "Anastasiya Kiseleva",
        "Dimitris Kotzinos",
        "Paul Hert"
      ],
      "year": 2022,
      "doi": "10.3389/frai.2022.879603",
      "journal": "Frontiers in Artificial Intelligence",
      "volume": "5",
      "pages": "879603",
      "raw": "Transparency of AI in healthcare as a multilayered system of accountabilities: Between legal requirements and technical limitations \n\t\t \n\t\t\t Anastasiya Kiseleva \n\t\t \n\t\t \n\t\t\t Dimitris Kotzinos \n\t\t \n\t\t \n\t\t\t Paul De Hert \n\t\t \n\t\t 10.3389/frai.2022.879603 \n\t \n\t \n\t\t Frontiers in Artificial Intelligence \n\t\t \n\t\t\t 5 \n\t\t\t 879603 \n\t\t\t 2022 \n\t\t \n\t \n\t Kiseleva, Anastasiya, Dimitris Kotzinos, and Paul De Hert. 2022. Transparency of AI in healthcare as a multilayered system of accountabilities: Between legal requirements and technical limitations. Frontiers in Artificial Intelligence 5: 879603. [CrossRef]"
    },
    {
      "title": "From promise to practice: Towards the realisation of AI-informed mental health care",
      "authors": [
        "Nikolaos Koutsouleris",
        "Tobias Hauser",
        "Vasilisa Skvortsova",
        "Munmun Choudhury"
      ],
      "year": 2022,
      "doi": "10.1016/s2589-7500(22)00153-4",
      "journal": "The Lancet Digital Health",
      "volume": "4",
      "raw": "From promise to practice: Towards the realisation of AI-informed mental health care \n\t\t \n\t\t\t Nikolaos Koutsouleris \n\t\t \n\t\t \n\t\t\t Tobias U Hauser \n\t\t \n\t\t \n\t\t\t Vasilisa Skvortsova \n\t\t \n\t\t \n\t\t\t Munmun De Choudhury \n\t\t \n\t\t 10.1016/s2589-7500(22)00153-4 \n\t \n\t \n\t\t The Lancet Digital Health \n\t\t \n\t\t\t 4 \n\t\t\t \n\t\t\t 2022 \n\t\t \n\t \n\t Koutsouleris, Nikolaos, Tobias U Hauser, Vasilisa Skvortsova, and Munmun De Choudhury. 2022. From promise to practice: Towards the realisation of AI-informed mental health care. The Lancet Digital Health 4: e829-e840. [CrossRef]"
    },
    {
      "title": "Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management",
      "authors": [
        "Min Lee"
      ],
      "year": 2018,
      "journal": "Big Data & Society",
      "volume": "5",
      "pages": "2053951718756684",
      "raw": "Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management \n\t\t \n\t\t\t Min Lee \n\t\t \n\t\t \n\t\t\t Kyung \n\t\t \n\t \n\t \n\t\t Big Data & Society \n\t\t \n\t\t\t 5 \n\t\t\t 2053951718756684 \n\t\t\t 2018 \n\t\t \n\t \n\t Lee, Min Kyung. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5: 2053951718756684."
    },
    {
      "doi": "10.1177/2053951718756684",
      "raw": "10.1177/2053951718756684 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical guidelines for artificial intelligence in healthcare from the sustainable development perspective",
      "authors": [
        "Anr\u012b Leimanis",
        "Karina Palkova"
      ],
      "year": 2021,
      "doi": "10.14207/ejsd.2021.v10n1p90",
      "journal": "European Journal of Sustainable Development",
      "volume": "10",
      "pages": "90",
      "raw": "Ethical guidelines for artificial intelligence in healthcare from the sustainable development perspective \n\t\t \n\t\t\t Anr\u012b Leimanis \n\t\t \n\t\t \n\t\t\t Karina Palkova \n\t\t \n\t\t 10.14207/ejsd.2021.v10n1p90 \n\t \n\t \n\t\t European Journal of Sustainable Development \n\t\t \n\t\t\t 10 \n\t\t\t 90 \n\t\t\t 2021 \n\t\t \n\t \n\t Leimanis, Anr\u012b, and Karina Palkova. 2021. Ethical guidelines for artificial intelligence in healthcare from the sustainable development perspective. European Journal of Sustainable Development 10: 90."
    },
    {
      "doi": "10.14207/ejsd.2021.v10n1p90",
      "raw": "10.14207/ejsd.2021.v10n1p90 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being",
      "authors": [
        "Han Li",
        "Renwen Zhang",
        "Yi-Chieh Lee",
        "Robert Kraut",
        "David Mohr"
      ],
      "year": 2023,
      "doi": "10.1038/s41746-023-00979-5",
      "journal": "NPJ Digital Medicine",
      "volume": "6",
      "pages": "236",
      "raw": "Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being \n\t\t \n\t\t\t Han Li \n\t\t \n\t\t \n\t\t\t Renwen Zhang \n\t\t \n\t\t \n\t\t\t Yi-Chieh Lee \n\t\t \n\t\t \n\t\t\t Robert E Kraut \n\t\t \n\t\t \n\t\t\t David C Mohr \n\t\t \n\t\t 10.1038/s41746-023-00979-5 \n\t \n\t \n\t\t NPJ Digital Medicine \n\t\t \n\t\t\t 6 \n\t\t\t 236 \n\t\t\t 2023 \n\t\t \n\t \n\t Li, Han, Renwen Zhang, Yi-Chieh Lee, Robert E. Kraut, and David C. Mohr. 2023. Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being. NPJ Digital Medicine 6: 236. [CrossRef]"
    },
    {
      "title": "Just the Facts Ma'am\": Moral and Ethical Considerations for Artificial Intelligence in Medicine and its Potential to Impact Patient Autonomy and Hope",
      "authors": [
        "Charles Love"
      ],
      "year": 2023,
      "doi": "10.1177/00243639231162431",
      "journal": "The Linacre Quarterly",
      "volume": "90",
      "raw": "Just the Facts Ma'am\": Moral and Ethical Considerations for Artificial Intelligence in Medicine and its Potential to Impact Patient Autonomy and Hope \n\t\t \n\t\t\t Charles S Love \n\t\t \n\t\t 10.1177/00243639231162431 \n\t \n\t \n\t\t The Linacre Quarterly \n\t\t \n\t\t\t 90 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Love, Charles S. 2023. \"Just the Facts Ma'am\": Moral and Ethical Considerations for Artificial Intelligence in Medicine and its Potential to Impact Patient Autonomy and Hope. The Linacre Quarterly 90: 375-94. [CrossRef]"
    },
    {
      "title": "Artificial intelligence in psychological practice: Current and future applications and implications",
      "authors": [
        "David Luxton"
      ],
      "year": 2014,
      "journal": "Professional Psychology: Research and Practice",
      "volume": "45",
      "raw": "Artificial intelligence in psychological practice: Current and future applications and implications \n\t\t \n\t\t\t David D Luxton \n\t\t \n\t \n\t \n\t\t Professional Psychology: Research and Practice \n\t\t \n\t\t\t 45 \n\t\t\t \n\t\t\t 2014 \n\t\t \n\t \n\t Luxton, David D. 2014. Artificial intelligence in psychological practice: Current and future applications and implications. Professional Psychology: Research and Practice 45: 332-39."
    },
    {
      "doi": "10.1037/a0034559",
      "raw": "10.1037/a0034559 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Artificial intelligence in clinical decision support: Challenges for evaluating AI and practical implications",
      "authors": [
        "Farah Magrabi",
        "Elske Ammenwerth",
        "Jytte Brender Mcnair",
        "Nicolet Keizer",
        "Hannele Hypp\u00f6nen",
        "Pirkko Nyk\u00e4nen",
        "Michael Rigby",
        "Philip Scott",
        "Tuulikki Vehko",
        "Zoie Shui-Yee"
      ],
      "year": 2019,
      "doi": "10.1055/s-0039-1677903",
      "journal": "Yearbook of Medical Informatics",
      "volume": "28",
      "raw": "Artificial intelligence in clinical decision support: Challenges for evaluating AI and practical implications \n\t\t \n\t\t\t Farah Magrabi \n\t\t \n\t\t \n\t\t\t Elske Ammenwerth \n\t\t \n\t\t \n\t\t\t Jytte Brender Mcnair \n\t\t \n\t\t \n\t\t\t Nicolet F De Keizer \n\t\t \n\t\t \n\t\t\t Hannele Hypp\u00f6nen \n\t\t \n\t\t \n\t\t\t Pirkko Nyk\u00e4nen \n\t\t \n\t\t \n\t\t\t Michael Rigby \n\t\t \n\t\t \n\t\t\t Philip J Scott \n\t\t \n\t\t \n\t\t\t Tuulikki Vehko \n\t\t \n\t\t \n\t\t\t Zoie Shui-Yee \n\t\t \n\t\t \n\t\t\t Wong \n\t\t \n\t\t 10.1055/s-0039-1677903 \n\t \n\t \n\t\t Yearbook of Medical Informatics \n\t\t \n\t\t\t 28 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Magrabi, Farah, Elske Ammenwerth, Jytte Brender McNair, Nicolet F. De Keizer, Hannele Hypp\u00f6nen, Pirkko Nyk\u00e4nen, Michael Rigby, Philip J. Scott, Tuulikki Vehko, Zoie Shui-Yee Wong, and et al. 2019. Artificial intelligence in clinical decision support: Challenges for evaluating AI and practical implications. Yearbook of Medical Informatics 28: 128-34. [CrossRef]"
    },
    {
      "title": "Human-centered design of artificial intelligence",
      "authors": [
        "George Margetis",
        "Stavroula Ntoa",
        "Margherita Antona",
        "Constantine Stephanidis"
      ],
      "year": 2021,
      "raw": "Human-centered design of artificial intelligence \n\t\t \n\t\t\t George Margetis \n\t\t \n\t\t \n\t\t\t Stavroula Ntoa \n\t\t \n\t\t \n\t\t\t Margherita Antona \n\t\t \n\t\t \n\t\t\t Constantine Stephanidis \n\t\t \n\t \n\t \n\t\t Handbook of Human Factors and Ergonomics \n\t\t Hoboken \n\t\t \n\t\t\t John Wiley & Sons, Inc \n\t\t\t 2021 \n\t\t\t \n\t\t \n\t \n\t Margetis, George, Stavroula Ntoa, Margherita Antona, and Constantine Stephanidis. 2021. Human-centered design of artificial intelligence. In Handbook of Human Factors and Ergonomics. Hoboken: John Wiley & Sons, Inc., pp. 1085-106."
    },
    {
      "doi": "10.1002/9781119636113.ch42",
      "raw": "10.1002/9781119636113.ch42 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "The ethical considerations including inclusion and biases, data protection, and proper implementation among AI in radiology and potential implications",
      "authors": [
        "Clarissa Martin",
        "Kyle Destefano",
        "Harry Haran",
        "Sydney Zink",
        "Jennifer Dai",
        "Danial Ahmed",
        "Abrahim Razzak",
        "Keldon Lin",
        "Ann Kogler",
        "Joseph Waller"
      ],
      "year": 2022,
      "journal": "Intelligence-Based Medicine",
      "volume": "6",
      "pages": "100073",
      "raw": "The ethical considerations including inclusion and biases, data protection, and proper implementation among AI in radiology and potential implications \n\t\t \n\t\t\t Clarissa Martin \n\t\t \n\t\t \n\t\t\t Kyle Destefano \n\t\t \n\t\t \n\t\t\t Harry Haran \n\t\t \n\t\t \n\t\t\t Sydney Zink \n\t\t \n\t\t \n\t\t\t Jennifer Dai \n\t\t \n\t\t \n\t\t\t Danial Ahmed \n\t\t \n\t\t \n\t\t\t Abrahim Razzak \n\t\t \n\t\t \n\t\t\t Keldon Lin \n\t\t \n\t\t \n\t\t\t Ann Kogler \n\t\t \n\t\t \n\t\t\t Joseph Waller \n\t\t \n\t \n\t \n\t\t Intelligence-Based Medicine \n\t\t \n\t\t\t 6 \n\t\t\t 100073 \n\t\t\t 2022 \n\t\t \n\t \n\t Martin, Clarissa, Kyle DeStefano, Harry Haran, Sydney Zink, Jennifer Dai, Danial Ahmed, Abrahim Razzak, Keldon Lin, Ann Kogler, Joseph Waller, and et al. 2022. The ethical considerations including inclusion and biases, data protection, and proper implementation among AI in radiology and potential implications. Intelligence-Based Medicine 6: 100073."
    },
    {
      "doi": "10.1016/j.ibmed.2022.100073",
      "raw": "10.1016/j.ibmed.2022.100073 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Clinical, legal, and ethical aspects of artificial intelligence-assisted conversational agents in health care",
      "authors": [
        "John Mcgreevey",
        "C Hanson",
        "Ross Koppel"
      ],
      "year": 2020,
      "journal": "JAMA",
      "volume": "324",
      "raw": "Clinical, legal, and ethical aspects of artificial intelligence-assisted conversational agents in health care \n\t\t \n\t\t\t John D Mcgreevey \n\t\t \n\t\t \n\t\t\t C William Hanson \n\t\t \n\t\t \n\t\t\t Ross Koppel \n\t\t \n\t \n\t \n\t\t JAMA \n\t\t \n\t\t\t 324 \n\t\t\t \n\t\t\t 2020 \n\t\t \n\t \n\t McGreevey, John D., C. William Hanson, and Ross Koppel. 2020. Clinical, legal, and ethical aspects of artificial intelligence-assisted conversational agents in health care. JAMA 324: 552-53."
    },
    {
      "doi": "10.1001/jama.2020.2724",
      "raw": "10.1001/jama.2020.2724 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Artificial intelligence and medical research databases: Ethical review by data access committees",
      "authors": [
        "Francis Mckay",
        "Bethany Williams",
        "Graham Prestwich",
        "Daljeet Bansal",
        "Darren Treanor",
        "Nina Hallowell"
      ],
      "year": 2023,
      "journal": "BMC Medical Ethics",
      "volume": "24",
      "pages": "49",
      "raw": "Artificial intelligence and medical research databases: Ethical review by data access committees \n\t\t \n\t\t\t Francis Mckay \n\t\t \n\t\t \n\t\t\t Bethany J Williams \n\t\t \n\t\t \n\t\t\t Graham Prestwich \n\t\t \n\t\t \n\t\t\t Daljeet Bansal \n\t\t \n\t\t \n\t\t\t Darren Treanor \n\t\t \n\t\t \n\t\t\t Nina Hallowell \n\t\t \n\t \n\t \n\t\t BMC Medical Ethics \n\t\t \n\t\t\t 24 \n\t\t\t 49 \n\t\t\t 2023 \n\t\t \n\t \n\t McKay, Francis, Bethany J. Williams, Graham Prestwich, Daljeet Bansal, Darren Treanor, and Nina Hallowell. 2023. Artificial intelligence and medical research databases: Ethical review by data access committees. BMC Medical Ethics 24: 49."
    },
    {
      "doi": "10.1186/s12910-023-00927-8",
      "raw": "10.1186/s12910-023-00927-8 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical and regulatory challenges of AI technologies in healthcare: A narrative review",
      "authors": [
        "Ciro Mennella",
        "Umberto Maniscalco",
        "Giuseppe Pietro",
        "Massimo Esposito"
      ],
      "year": 2024,
      "doi": "10.1016/j.heliyon.2024.e26297",
      "journal": "Heliyon",
      "volume": "10",
      "pages": "26297",
      "raw": "Ethical and regulatory challenges of AI technologies in healthcare: A narrative review \n\t\t \n\t\t\t Ciro Mennella \n\t\t \n\t\t \n\t\t\t Umberto Maniscalco \n\t\t \n\t\t \n\t\t\t Giuseppe De Pietro \n\t\t \n\t\t \n\t\t\t Massimo Esposito \n\t\t \n\t\t 10.1016/j.heliyon.2024.e26297 \n\t \n\t \n\t\t Heliyon \n\t\t \n\t\t\t 10 \n\t\t\t 26297 \n\t\t\t 2024 \n\t\t \n\t \n\t Mennella, Ciro, Umberto Maniscalco, Giuseppe De Pietro, and Massimo Esposito. 2024. Ethical and regulatory challenges of AI technologies in healthcare: A narrative review. Heliyon 10: e26297. [CrossRef]"
    },
    {
      "title": "Artificial Intelligence and Ethics: A Comprehensive Review of Bias Mitigation, Transparency, and Accountability in AI Systems",
      "authors": [
        "George Mensah"
      ],
      "year": 2023,
      "raw": "George Mensah \n\t\t \n\t\t \n\t\t\t Benneh \n\t\t \n\t\t \n\t\t Artificial Intelligence and Ethics: A Comprehensive Review of Bias Mitigation, Transparency, and Accountability in AI Systems \n\t\t \n\t\t\t 2023. 26 January 2024 \n\t\t \n\t \n\t of-Bias-Mitigation-Transparency-and-Accountability-in- \n\t AI-Systems \n\t Mensah, George Benneh. 2023. Artificial Intelligence and Ethics: A Comprehensive Review of Bias Mitigation, Transparency, and Accountability in AI Systems. Available online: https://www.researchgate.net/profile/George-Benneh-Mensah-2/publication/375744287_ Artificial_Intelligence_and_Ethics_A_Comprehensive_Reviews_of_Bias_Mitigation_Transparency_and_Accountability_in_AI_ Systems/links/656c8e46b86a1d521b2e2a16/Artificial-Intelligence-and-Ethics-A-Comprehensive-Reviews-of-Bias-Mitigation- Transparency-and-Accountability-in-AI-Systems.pdf (accessed on 26 January 2024)."
    },
    {
      "title": "Bias in AI-based models for medical applications: Challenges and mitigation strategies",
      "authors": [
        "Marium Mirja",
        "Joseph Raza"
      ],
      "year": 2023,
      "journal": "NPJ Digital Medicine",
      "volume": "6",
      "pages": "113",
      "raw": "Bias in AI-based models for medical applications: Challenges and mitigation strategies \n\t\t \n\t\t\t Mittermaier \n\t\t \n\t\t \n\t\t\t Marium M Mirja \n\t\t \n\t\t \n\t\t\t Joseph C Raza \n\t\t \n\t\t \n\t\t\t Kvedar \n\t\t \n\t \n\t \n\t\t NPJ Digital Medicine \n\t\t \n\t\t\t 6 \n\t\t\t 113 \n\t\t\t 2023 \n\t\t \n\t \n\t Mittermaier, Mirja, Marium M. Raza, and Joseph C. Kvedar. 2023. Bias in AI-based models for medical applications: Challenges and mitigation strategies. NPJ Digital Medicine 6: 113."
    },
    {
      "title": "A conceptual framework for the ethical deployment of Artificial Intelligence in addressing mental health challenges: Guidelines for Social Workers",
      "authors": [
        "Thomas Molala",
        "Jabulani Makhubele"
      ],
      "year": 2021,
      "journal": "Technium Social Science Journal",
      "volume": "24",
      "pages": "696",
      "raw": "A conceptual framework for the ethical deployment of Artificial Intelligence in addressing mental health challenges: Guidelines for Social Workers \n\t\t \n\t\t\t Thomas Molala \n\t\t \n\t\t \n\t\t\t Jabulani Makhubele \n\t\t \n\t \n\t \n\t\t Technium Social Science Journal \n\t\t \n\t\t\t 24 \n\t\t\t 696 \n\t\t\t 2021 \n\t\t \n\t \n\t Molala, Thomas, and Jabulani Makhubele. 2021. A conceptual framework for the ethical deployment of Artificial Intelligence in addressing mental health challenges: Guidelines for Social Workers. Technium Social Science Journal 24: 696."
    },
    {
      "title": "The ethics of AI in health care: A mapping review",
      "authors": [
        "Jessica Morley",
        "C Caio",
        "Christopher Machado",
        "Josh Burr",
        "Indra Cowls",
        "Mariarosaria Joshi",
        "Luciano Taddeo"
      ],
      "year": 2020,
      "journal": "Social Science & Medicine",
      "volume": "260",
      "pages": "113172",
      "raw": "The ethics of AI in health care: A mapping review \n\t\t \n\t\t\t Jessica Morley \n\t\t \n\t\t \n\t\t\t C V Caio \n\t\t \n\t\t \n\t\t\t Christopher Machado \n\t\t \n\t\t \n\t\t\t Josh Burr \n\t\t \n\t\t \n\t\t\t Indra Cowls \n\t\t \n\t\t \n\t\t\t Mariarosaria Joshi \n\t\t \n\t\t \n\t\t\t Luciano Taddeo \n\t\t \n\t\t \n\t\t\t Floridi \n\t\t \n\t \n\t \n\t\t Social Science & Medicine \n\t\t \n\t\t\t 260 \n\t\t\t 113172 \n\t\t\t 2020 \n\t\t \n\t \n\t Morley, Jessica, Caio C.V. Machado, Christopher Burr, Josh Cowls, Indra Joshi, Mariarosaria Taddeo, and Luciano Floridi. 2020. The ethics of AI in health care: A mapping review. Social Science & Medicine 260: 113172."
    },
    {
      "doi": "10.1016/j.socscimed.2020.113172",
      "raw": "10.1016/j.socscimed.2020.113172 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Towards a framework for evaluating the safety, acceptability and efficacy of AI systems for health: An initial synthesis",
      "authors": [
        "Jessica Morley",
        "Kassandra Karpathakis",
        "Caroline Morton",
        "Mariarosaria Taddeo",
        "Luciano Floridi"
      ],
      "year": 2021,
      "raw": "Towards a framework for evaluating the safety, acceptability and efficacy of AI systems for health: An initial synthesis \n\t\t \n\t\t\t Jessica Morley \n\t\t \n\t\t \n\t\t\t Kassandra Karpathakis \n\t\t \n\t\t \n\t\t\t Caroline Morton \n\t\t \n\t\t \n\t\t\t Mariarosaria Taddeo \n\t\t \n\t\t \n\t\t\t Luciano Floridi \n\t\t \n\t\t arXivarXiv:2104.06910 \n\t\t \n\t\t\t 2021 \n\t\t \n\t \n\t Morley, Jessica, Kassandra Karpathakis Caroline Morton, Mariarosaria Taddeo, and Luciano Floridi. 2021. Towards a framework for evaluating the safety, acceptability and efficacy of AI systems for health: An initial synthesis. arXiv arXiv:2104.06910."
    },
    {
      "title": "Canada protocol: An ethical checklist for the use of artificial Intelligence in suicide prevention and mental health",
      "authors": [
        "Carl-Maria M\u00f6rch",
        "Abhishek Gupta",
        "Brian Mishara"
      ],
      "year": 2020,
      "doi": "10.1016/j.artmed.2020.101934",
      "journal": "Artificial Intelligence in Medicine",
      "volume": "108",
      "pages": "101934",
      "raw": "Canada protocol: An ethical checklist for the use of artificial Intelligence in suicide prevention and mental health \n\t\t \n\t\t\t Carl-Maria M\u00f6rch \n\t\t \n\t\t \n\t\t\t Abhishek Gupta \n\t\t \n\t\t \n\t\t\t Brian L Mishara \n\t\t \n\t\t 10.1016/j.artmed.2020.101934 \n\t \n\t \n\t\t Artificial Intelligence in Medicine \n\t\t \n\t\t\t 108 \n\t\t\t 101934 \n\t\t\t 2020 \n\t\t \n\t \n\t M\u00f6rch, Carl-Maria, Abhishek Gupta, and Brian L. Mishara. 2020. Canada protocol: An ethical checklist for the use of artificial Intelligence in suicide prevention and mental health. Artificial Intelligence in Medicine 108: 101934. [CrossRef]"
    },
    {
      "title": "Privacy and artificial intelligence: Challenges for protecting health information in a new era",
      "authors": [
        "Blake Murdoch"
      ],
      "year": 2021,
      "journal": "BMC Medical Ethics",
      "volume": "22",
      "pages": "122",
      "raw": "Privacy and artificial intelligence: Challenges for protecting health information in a new era \n\t\t \n\t\t\t Blake Murdoch \n\t\t \n\t \n\t \n\t\t BMC Medical Ethics \n\t\t \n\t\t\t 22 \n\t\t\t 122 \n\t\t\t 2021 \n\t\t \n\t \n\t Murdoch, Blake. 2021. Privacy and artificial intelligence: Challenges for protecting health information in a new era. BMC Medical Ethics 22: 122."
    },
    {
      "doi": "10.1186/s12910-021-00687-3",
      "raw": "10.1186/s12910-021-00687-3 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond",
      "authors": [
        "Sidra Nasir",
        "Rizwan Ahmed Khan",
        "Samita Bai"
      ],
      "year": 2024,
      "journal": "IEEE Access",
      "volume": "12",
      "raw": "Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond \n\t\t \n\t\t\t Sidra Nasir \n\t\t \n\t\t \n\t\t\t Rizwan Ahmed Khan \n\t\t \n\t\t \n\t\t\t Samita Bai \n\t\t \n\t \n\t \n\t\t IEEE Access \n\t\t \n\t\t\t 12 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Nasir, Sidra, Rizwan Ahmed Khan, and Samita Bai. 2024. Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond. IEEE Access 12: 31014-35."
    },
    {
      "doi": "10.1109/access.2024.3369912",
      "raw": "10.1109/access.2024.3369912 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Enhancing mental health with Artificial Intelligence: Current trends and future prospects",
      "authors": [
        "David Olawade",
        "Odetayo Aderonke",
        "Z Ojima",
        "Fiyinfoluwa Wada",
        "Aanuoluwapo Asaolu",
        "Judith Clement David-Olawade"
      ],
      "year": 2024,
      "journal": "Journal of Medicine, Surgery, and Public Health",
      "volume": "3",
      "pages": "100099",
      "raw": "Enhancing mental health with Artificial Intelligence: Current trends and future prospects \n\t\t \n\t\t\t David B Olawade \n\t\t \n\t\t \n\t\t\t Odetayo Aderonke \n\t\t \n\t\t \n\t\t\t Z Ojima \n\t\t \n\t\t \n\t\t\t Fiyinfoluwa Wada \n\t\t \n\t\t \n\t\t\t Aanuoluwapo Asaolu \n\t\t \n\t\t \n\t\t\t Judith Clement David-Olawade \n\t\t \n\t\t \n\t\t\t Eberhardt \n\t\t \n\t \n\t \n\t\t Journal of Medicine, Surgery, and Public Health \n\t\t \n\t\t\t 3 \n\t\t\t 100099 \n\t\t\t 2024 \n\t\t \n\t \n\t Olawade, David B., Aderonke Odetayo Ojima Z. Wada, Fiyinfoluwa Asaolu Aanuoluwapo Clement David-Olawade, and Judith Eberhardt. 2024. Enhancing mental health with Artificial Intelligence: Current trends and future prospects. Journal of Medicine, Surgery, and Public Health 3: 100099."
    },
    {
      "doi": "10.1016/j.glmedi.2024.100099",
      "raw": "10.1016/j.glmedi.2024.100099 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethical considerations in AI-enhanced medical decision support systems: A review",
      "authors": [
        "Tolulope Olorunsogo",
        "Adekunle Oyeyemi Adenyi",
        "Chioma Anthonia Okolo",
        "Oloruntoba Babawarun"
      ],
      "year": 2024,
      "journal": "World Journal of Advanced Engineering Technology and Sciences",
      "volume": "11",
      "raw": "Ethical considerations in AI-enhanced medical decision support systems: A review \n\t\t \n\t\t\t Tolulope Olorunsogo \n\t\t \n\t\t \n\t\t\t Adekunle Oyeyemi Adenyi \n\t\t \n\t\t \n\t\t\t Chioma Anthonia Okolo \n\t\t \n\t\t \n\t\t\t Oloruntoba Babawarun \n\t\t \n\t \n\t \n\t\t World Journal of Advanced Engineering Technology and Sciences \n\t\t \n\t\t\t 11 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Olorunsogo, Tolulope, Adekunle Oyeyemi Adenyi, Chioma Anthonia Okolo, and Oloruntoba Babawarun. 2024. Ethical considerations in AI-enhanced medical decision support systems: A review. World Journal of Advanced Engineering Technology and Sciences 11: 329-36."
    },
    {
      "doi": "10.30574/wjaets.2024.11.1.0061",
      "raw": "10.30574/wjaets.2024.11.1.0061 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "The PRISMA 2020 statement: An updated guideline for reporting systematic reviews",
      "authors": [
        "Matthew Page",
        "M Patrick",
        "Joanne Bossuyt",
        "Tammy Mckenzie",
        "Isabelle Hoffmann",
        "Larissa Boutron",
        "Cynthia Shamseer",
        "Elie Mulrow",
        "Jennifer Akl",
        "Sue Tetzlaff"
      ],
      "year": 2021,
      "journal": "BMJ",
      "volume": "372",
      "pages": "71",
      "raw": "The PRISMA 2020 statement: An updated guideline for reporting systematic reviews \n\t\t \n\t\t\t Matthew J Page \n\t\t \n\t\t \n\t\t\t M Patrick \n\t\t \n\t\t \n\t\t\t Joanne E Bossuyt \n\t\t \n\t\t \n\t\t\t Tammy C Mckenzie \n\t\t \n\t\t \n\t\t\t Isabelle Hoffmann \n\t\t \n\t\t \n\t\t\t Larissa Boutron \n\t\t \n\t\t \n\t\t\t Cynthia D Shamseer \n\t\t \n\t\t \n\t\t\t Elie A Mulrow \n\t\t \n\t\t \n\t\t\t Jennifer M Akl \n\t\t \n\t\t \n\t\t\t Sue E Tetzlaff \n\t\t \n\t\t \n\t\t\t Brennan \n\t\t \n\t \n\t \n\t\t BMJ \n\t\t \n\t\t\t 372 \n\t\t\t 71 \n\t\t\t 2021 \n\t\t \n\t \n\t Page, Matthew J., Patrick M. Bossuyt, Joanne E. McKenzie, Tammy C. Hoffmann, Isabelle Boutron, Larissa Shamseer, Cynthia D. Mulrow, Elie A. Akl, Jennifer M. Tetzlaff, Sue E. Brennan, and et al. 2021. The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. BMJ 372: n71."
    },
    {
      "doi": "10.1136/bmj.n71",
      "raw": "10.1136/bmj.n71 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Trust, but verify: Informed consent, AI technologies, and public health emergencies",
      "authors": [
        "Brian Pickering"
      ],
      "year": 2021,
      "journal": "Future Internet",
      "volume": "13",
      "pages": "132",
      "raw": "Trust, but verify: Informed consent, AI technologies, and public health emergencies \n\t\t \n\t\t\t Brian Pickering \n\t\t \n\t \n\t \n\t\t Future Internet \n\t\t \n\t\t\t 13 \n\t\t\t 132 \n\t\t\t 2021 \n\t\t \n\t \n\t Pickering, Brian. 2021. Trust, but verify: Informed consent, AI technologies, and public health emergencies. Future Internet 13: 132."
    },
    {
      "title": "Ethical framework of digital technology, artificial intelligence, and health equity",
      "authors": [
        "Piyanat Prathomwong",
        "Pagorn Singsuriya"
      ],
      "year": 2022,
      "journal": "Asia Social Issues",
      "volume": "15",
      "pages": "252136",
      "raw": "Ethical framework of digital technology, artificial intelligence, and health equity \n\t\t \n\t\t\t Piyanat Prathomwong \n\t\t \n\t\t \n\t\t\t Pagorn Singsuriya \n\t\t \n\t \n\t \n\t\t Asia Social Issues \n\t\t \n\t\t\t 15 \n\t\t\t 252136 \n\t\t\t 2022 \n\t\t \n\t \n\t Prathomwong, Piyanat, and Pagorn Singsuriya. 2022. Ethical framework of digital technology, artificial intelligence, and health equity. Asia Social Issues 15: 252136."
    },
    {
      "doi": "10.48048/asi.2022.252136",
      "raw": "10.48048/asi.2022.252136 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Artificial intelligence-enabled healthcare delivery",
      "authors": [
        "Sandeep Reddy",
        "John Fox",
        "Maulik Purohit"
      ],
      "year": 2019,
      "journal": "Journal of the Royal Society of Medicine",
      "volume": "112",
      "raw": "Artificial intelligence-enabled healthcare delivery \n\t\t \n\t\t\t Sandeep Reddy \n\t\t \n\t\t \n\t\t\t John Fox \n\t\t \n\t\t \n\t\t\t Maulik P Purohit \n\t\t \n\t \n\t \n\t\t Journal of the Royal Society of Medicine \n\t\t \n\t\t\t 112 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Reddy, Sandeep, John Fox, and Maulik P. Purohit. 2019. Artificial intelligence-enabled healthcare delivery. Journal of the Royal Society of Medicine 112: 22-28."
    },
    {
      "doi": "10.1177/0141076818815510",
      "raw": "10.1177/0141076818815510 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "iHealth: The ethics of artificial intelligence and big data in mental healthcare",
      "authors": [
        "Giovanni Rubeis"
      ],
      "year": 2022,
      "doi": "10.1016/j.invent.2022.100518",
      "journal": "Internet Interventions",
      "volume": "28",
      "pages": "100518",
      "raw": "iHealth: The ethics of artificial intelligence and big data in mental healthcare \n\t\t \n\t\t\t Giovanni Rubeis \n\t\t \n\t\t 10.1016/j.invent.2022.100518 \n\t \n\t \n\t\t Internet Interventions \n\t\t \n\t\t\t 28 \n\t\t\t 100518 \n\t\t\t 2022 \n\t\t \n\t \n\t Rubeis, Giovanni. 2022. iHealth: The ethics of artificial intelligence and big data in mental healthcare. Internet Interventions 28: 100518. [CrossRef]"
    },
    {
      "title": "Ethical artificial intelligence (AI): Confronting bias and discrimination in the library and information industry",
      "authors": [
        "Hamid Saeidnia"
      ],
      "year": 2023,
      "journal": "Library Hi Tech News",
      "raw": "Ethical artificial intelligence (AI): Confronting bias and discrimination in the library and information industry \n\t\t \n\t\t\t Hamid Saeidnia \n\t\t \n\t\t \n\t\t\t Reza \n\t\t \n\t \n\t \n\t\t Library Hi Tech News \n\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t ahead-of-print \n\t Saeidnia, Hamid Reza. 2023. Ethical artificial intelligence (AI): Confronting bias and discrimination in the library and information industry. Library Hi Tech News, ahead-of-print."
    },
    {
      "doi": "10.1108/lhtn-10-2023-0182",
      "raw": "10.1108/lhtn-10-2023-0182 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "AI in Mental Health: Predictive Analytics and Intervention Strategies",
      "authors": [
        "Varun Shah"
      ],
      "year": 2022,
      "journal": "Journal Environmental Sciences And Technology",
      "volume": "1",
      "raw": "AI in Mental Health: Predictive Analytics and Intervention Strategies \n\t\t \n\t\t\t Varun Shah \n\t\t \n\t \n\t \n\t\t Journal Environmental Sciences And Technology \n\t\t \n\t\t\t 1 \n\t\t\t \n\t\t\t 2022 \n\t\t \n\t \n\t Shah, Varun. 2022. AI in Mental Health: Predictive Analytics and Intervention Strategies. Journal Environmental Sciences And Technology 1: 55-74."
    },
    {
      "title": "Emerging paradigms for ethical review of research using artificial intelligence",
      "authors": [
        "James Shaw"
      ],
      "year": 2022,
      "journal": "American Journal of Bioethics",
      "volume": "22",
      "raw": "Emerging paradigms for ethical review of research using artificial intelligence \n\t\t \n\t\t\t James Shaw \n\t\t \n\t \n\t \n\t\t American Journal of Bioethics \n\t\t \n\t\t\t 22 \n\t\t\t \n\t\t\t 2022 \n\t\t \n\t \n\t Shaw, James. 2022. Emerging paradigms for ethical review of research using artificial intelligence. American Journal of Bioethics 22: 42-44."
    },
    {
      "doi": "10.1080/15265161.2022.2055206",
      "raw": "10.1080/15265161.2022.2055206 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "The role of artificial intelligence in mental health: A review",
      "authors": [
        "Koki Shimada"
      ],
      "year": 2023,
      "journal": "Science Insights",
      "volume": "43",
      "raw": "The role of artificial intelligence in mental health: A review \n\t\t \n\t\t\t Koki Shimada \n\t\t \n\t \n\t \n\t\t Science Insights \n\t\t \n\t\t\t 43 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Shimada, Koki. 2023. The role of artificial intelligence in mental health: A review. Science Insights 43: 1119-27."
    },
    {
      "doi": "10.15354/si.23.re820",
      "raw": "10.15354/si.23.re820 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "SHIFTing artificial intelligence to be responsible in healthcare: A systematic review",
      "authors": [
        "Haytham Siala",
        "Yichuan Wang"
      ],
      "year": 2022,
      "journal": "Social Science & Medicine",
      "volume": "296",
      "pages": "114782",
      "raw": "SHIFTing artificial intelligence to be responsible in healthcare: A systematic review \n\t\t \n\t\t\t Haytham Siala \n\t\t \n\t\t \n\t\t\t Yichuan Wang \n\t\t \n\t \n\t \n\t\t Social Science & Medicine \n\t\t \n\t\t\t 296 \n\t\t\t 114782 \n\t\t\t 2022 \n\t\t \n\t \n\t Siala, Haytham, and Yichuan Wang. 2022. SHIFTing artificial intelligence to be responsible in healthcare: A systematic review. Social Science & Medicine 296: 114782."
    },
    {
      "doi": "10.1016/j.socscimed.2022.114782",
      "raw": "10.1016/j.socscimed.2022.114782 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "AI Ethics and Societal Perspectives: A Comparative Study of Ethical Principle Prioritization Among Diverse Demographic Clusters",
      "authors": [
        "Jatin Singh"
      ],
      "year": 2021,
      "journal": "Journal of Advanced Analytics in Healthcare Management",
      "volume": "5",
      "raw": "AI Ethics and Societal Perspectives: A Comparative Study of Ethical Principle Prioritization Among Diverse Demographic Clusters \n\t\t \n\t\t\t Jatin Singh \n\t\t \n\t\t \n\t\t\t Pal \n\t\t \n\t \n\t \n\t\t Journal of Advanced Analytics in Healthcare Management \n\t\t \n\t\t\t 5 \n\t\t\t \n\t\t\t 2021 \n\t\t \n\t \n\t Singh, Jatin Pal. 2021. AI Ethics and Societal Perspectives: A Comparative Study of Ethical Principle Prioritization Among Diverse Demographic Clusters. Journal of Advanced Analytics in Healthcare Management 5: 1-18."
    },
    {
      "title": "Clinical Practice Guidelines on using artificial intelligence and gadgets for mental health and well-being",
      "authors": [
        "Vipul Singh",
        "Sharmila Sarkar",
        "Vikas Gaur",
        "Sandeep Grover",
        "Om Singh"
      ],
      "year": 2024,
      "doi": "10.4103/indianjpsychiatry.indianjpsychiatry_926_23",
      "journal": "Indian Journal of Psychiatry",
      "volume": "66",
      "raw": "Clinical Practice Guidelines on using artificial intelligence and gadgets for mental health and well-being \n\t\t \n\t\t\t Vipul Singh \n\t\t \n\t\t \n\t\t\t Sharmila Sarkar \n\t\t \n\t\t \n\t\t\t Vikas Gaur \n\t\t \n\t\t \n\t\t\t Sandeep Grover \n\t\t \n\t\t \n\t\t\t Om Prakash Singh \n\t\t \n\t\t 10.4103/indianjpsychiatry.indianjpsychiatry_926_23 \n\t \n\t \n\t\t Indian Journal of Psychiatry \n\t\t \n\t\t\t 66 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Singh, Vipul, Sharmila Sarkar, Vikas Gaur, Sandeep Grover, and Om Prakash Singh. 2024. Clinical Practice Guidelines on using artificial intelligence and gadgets for mental health and well-being. Indian Journal of Psychiatry 66: S414-S419. [CrossRef]"
    },
    {
      "title": "Toward Fairness, Accountability, Transparency, and Ethics in AI for Social Media and Health Care: Scoping Review",
      "authors": [
        "Aditya Singhal",
        "Nikita Neveditsin",
        "Hasnaat Tanveer",
        "Vijay Mago"
      ],
      "year": 2024,
      "doi": "10.2196/50048",
      "journal": "JMIR Public Health and Surveillance",
      "volume": "12",
      "pages": "50048",
      "raw": "Toward Fairness, Accountability, Transparency, and Ethics in AI for Social Media and Health Care: Scoping Review \n\t\t \n\t\t\t Aditya Singhal \n\t\t \n\t\t \n\t\t\t Nikita Neveditsin \n\t\t \n\t\t \n\t\t\t Hasnaat Tanveer \n\t\t \n\t\t \n\t\t\t Vijay Mago \n\t\t \n\t\t 10.2196/50048 \n\t \n\t \n\t\t JMIR Public Health and Surveillance \n\t\t \n\t\t\t 12 \n\t\t\t 50048 \n\t\t\t 2024 \n\t\t \n\t \n\t Singhal, Aditya, Nikita Neveditsin, Hasnaat Tanveer, and Vijay Mago. 2024. Toward Fairness, Accountability, Transparency, and Ethics in AI for Social Media and Health Care: Scoping Review. JMIR Public Health and Surveillance 12: e50048. [CrossRef]"
    },
    {
      "title": "Security and privacy in cloud-based e-health system",
      "authors": [
        "Remya Sivan",
        "Zuriati Ahmad Zukarnain"
      ],
      "year": 2021,
      "journal": "Symmetry",
      "volume": "13",
      "pages": "742",
      "raw": "Security and privacy in cloud-based e-health system \n\t\t \n\t\t\t Remya Sivan \n\t\t \n\t\t \n\t\t\t Zuriati Ahmad Zukarnain \n\t\t \n\t \n\t \n\t\t Symmetry \n\t\t \n\t\t\t 13 \n\t\t\t 742 \n\t\t\t 2021 \n\t\t \n\t \n\t Sivan, Remya, and Zuriati Ahmad Zukarnain. 2021. Security and privacy in cloud-based e-health system. Symmetry 13: 742."
    },
    {
      "doi": "10.3390/sym13050742",
      "raw": "10.3390/sym13050742 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Persons or data points? Ethics, artificial intelligence, and the participatory turn in mental health research",
      "authors": [
        "Joshua Skorburg",
        "O' Kieran",
        "Phoebe Doherty"
      ],
      "year": 2024,
      "doi": "10.1037/amp0001168",
      "journal": "American Psychologist",
      "volume": "79",
      "raw": "Persons or data points? Ethics, artificial intelligence, and the participatory turn in mental health research \n\t\t \n\t\t\t Joshua Skorburg \n\t\t \n\t\t \n\t\t\t August \n\t\t \n\t\t \n\t\t\t O' Kieran \n\t\t \n\t\t \n\t\t\t Phoebe Doherty \n\t\t \n\t\t \n\t\t\t Friesen \n\t\t \n\t\t 10.1037/amp0001168 \n\t \n\t \n\t\t American Psychologist \n\t\t \n\t\t\t 79 \n\t\t\t \n\t\t\t 2024 \n\t\t \n\t \n\t Skorburg, Joshua August, Kieran O'Doherty, and Phoebe Friesen. 2024. Persons or data points? Ethics, artificial intelligence, and the participatory turn in mental health research. American Psychologist 79: 137-49. [CrossRef]"
    },
    {
      "title": "Methodology in conducting a systematic review of systematic reviews of healthcare interventions",
      "authors": [
        "Valerie Smith",
        "Declan Devane",
        "Cecily Begley",
        "Mike Clarke"
      ],
      "year": 2011,
      "doi": "10.1186/1471-2288-11-15",
      "journal": "BMC Medical Research Methodology",
      "volume": "11",
      "pages": "15",
      "raw": "Methodology in conducting a systematic review of systematic reviews of healthcare interventions \n\t\t \n\t\t\t Valerie Smith \n\t\t \n\t\t \n\t\t\t Declan Devane \n\t\t \n\t\t \n\t\t\t Cecily M Begley \n\t\t \n\t\t \n\t\t\t Mike Clarke \n\t\t \n\t\t 10.1186/1471-2288-11-15 \n\t \n\t \n\t\t BMC Medical Research Methodology \n\t\t \n\t\t\t 11 \n\t\t\t 15 \n\t\t\t 2011 \n\t\t \n\t \n\t Smith, Valerie, Declan Devane, Cecily M Begley, and Mike Clarke. 2011. Methodology in conducting a systematic review of systematic reviews of healthcare interventions. BMC Medical Research Methodology 11: 15. [CrossRef]"
    },
    {
      "title": "Humanizing AI in medical training: Ethical framework for responsible design",
      "authors": [
        "Mohammed Sqalli",
        "Begali Tahri",
        "Mukhammadjon Aslonov",
        "Shokhrukhbek Gafurov"
      ],
      "year": 2023,
      "doi": "10.3389/frai.2023.1189914",
      "journal": "Frontiers in Artificial Intelligence",
      "volume": "6",
      "pages": "1189914",
      "raw": "Humanizing AI in medical training: Ethical framework for responsible design \n\t\t \n\t\t\t Mohammed Sqalli \n\t\t \n\t\t \n\t\t\t Begali Tahri \n\t\t \n\t\t \n\t\t\t Mukhammadjon Aslonov \n\t\t \n\t\t \n\t\t\t Shokhrukhbek Gafurov \n\t\t \n\t\t \n\t\t\t Nurmatov \n\t\t \n\t\t 10.3389/frai.2023.1189914 \n\t \n\t \n\t\t Frontiers in Artificial Intelligence \n\t\t \n\t\t\t 6 \n\t\t\t 1189914 \n\t\t\t 2023 \n\t\t \n\t \n\t Sqalli, Mohammed Tahri, Begali Aslonov, Mukhammadjon Gafurov, and Shokhrukhbek Nurmatov. 2023. Humanizing AI in medical training: Ethical framework for responsible design. Frontiers in Artificial Intelligence 6: 1189914. [CrossRef]"
    },
    {
      "title": "Ethical Considerations in AI and Data Science: Bias, Fairness, and Accountability",
      "authors": [
        "Sumanth Tatineni"
      ],
      "year": 2019,
      "doi": "10.48047/resmil.v10i1.22",
      "journal": "International Journal of Information Technology and Management Information Systems",
      "volume": "10",
      "raw": "Ethical Considerations in AI and Data Science: Bias, Fairness, and Accountability \n\t\t \n\t\t\t Sumanth Tatineni \n\t\t \n\t\t 10.48047/resmil.v10i1.22 \n\t \n\t \n\t\t International Journal of Information Technology and Management Information Systems \n\t\t \n\t\t\t 10 \n\t\t\t \n\t\t\t 2019 \n\t\t \n\t \n\t Tatineni, Sumanth. 2019. Ethical Considerations in AI and Data Science: Bias, Fairness, and Accountability. International Journal of Information Technology and Management Information Systems 10: 11-20."
    },
    {
      "title": "Artificial intelligence in positive mental health: A narrative review",
      "authors": [
        "Anoushka Thakkar",
        "Ankita Gupta",
        "Avinash Sousa"
      ],
      "year": 2024,
      "journal": "Frontiers in Digital Health",
      "volume": "6",
      "pages": "1280235",
      "raw": "Artificial intelligence in positive mental health: A narrative review \n\t\t \n\t\t\t Anoushka Thakkar \n\t\t \n\t\t \n\t\t\t Ankita Gupta \n\t\t \n\t\t \n\t\t\t Avinash De Sousa \n\t\t \n\t \n\t \n\t\t Frontiers in Digital Health \n\t\t \n\t\t\t 6 \n\t\t\t 1280235 \n\t\t\t 2024 \n\t\t \n\t \n\t Thakkar, Anoushka, Ankita Gupta, and Avinash De Sousa. 2024. Artificial intelligence in positive mental health: A narrative review. Frontiers in Digital Health 6: 1280235."
    },
    {
      "doi": "10.3389/fdgth.2024.1280235",
      "raw": "10.3389/fdgth.2024.1280235 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "A call to action on assessing and mitigating bias in artificial intelligence applications for mental health",
      "authors": [
        "Adela Timmons",
        "B Jacqueline",
        "Natalia Duong",
        "Theodore Fiallo",
        "Huong Lee",
        "Quynh Phuc",
        "Matthew Vo",
        "Jonathan Ahle",
        "Laprincess Comer",
        "Stacy Brewer",
        "Theodora Frazier"
      ],
      "year": 2023,
      "journal": "Perspectives on Psychological Science",
      "volume": "18",
      "raw": "A call to action on assessing and mitigating bias in artificial intelligence applications for mental health \n\t\t \n\t\t\t Adela C Timmons \n\t\t \n\t\t \n\t\t\t B Jacqueline \n\t\t \n\t\t \n\t\t\t Natalia Simo Duong \n\t\t \n\t\t \n\t\t\t Theodore Fiallo \n\t\t \n\t\t \n\t\t\t Huong Lee \n\t\t \n\t\t \n\t\t\t Quynh Phuc \n\t\t \n\t\t \n\t\t\t Matthew W Vo \n\t\t \n\t\t \n\t\t\t Jonathan S Ahle \n\t\t \n\t\t \n\t\t\t Laprincess C Comer \n\t\t \n\t\t \n\t\t\t Stacy L Brewer \n\t\t \n\t\t \n\t\t\t Theodora Frazier \n\t\t \n\t\t \n\t\t\t Chaspari \n\t\t \n\t \n\t \n\t\t Perspectives on Psychological Science \n\t\t \n\t\t\t 18 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Timmons, Adela C., Jacqueline B. Duong, Natalia Simo Fiallo, Theodore Lee, Huong Phuc Quynh Vo, Matthew W. Ahle, Jonathan S. Comer, LaPrincess C. Brewer, Stacy L. Frazier, and Theodora Chaspari. 2023. A call to action on assessing and mitigating bias in artificial intelligence applications for mental health. Perspectives on Psychological Science 18: 1062-96."
    },
    {
      "doi": "10.1177/17456916221134490",
      "raw": "10.1177/17456916221134490 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "The AI ethics principle of autonomy in health recommender systems",
      "authors": [
        "Simona Tiribelli"
      ],
      "year": 2023,
      "journal": "Argumenta",
      "volume": "16",
      "raw": "The AI ethics principle of autonomy in health recommender systems \n\t\t \n\t\t\t Simona Tiribelli \n\t\t \n\t \n\t \n\t\t Argumenta \n\t\t \n\t\t\t 16 \n\t\t\t \n\t\t\t 2023 \n\t\t \n\t \n\t Tiribelli, Simona. 2023. The AI ethics principle of autonomy in health recommender systems. Argumenta 16: 1-18."
    },
    {
      "title": "An Efficacy of Artificial Intelligence Applications in Healthcare Systems-A Bird View",
      "authors": [
        "Vikash Tiwari",
        "M Kumar"
      ],
      "year": 2023,
      "raw": "An Efficacy of Artificial Intelligence Applications in Healthcare Systems-A Bird View \n\t\t \n\t\t\t Vikash Tiwari \n\t\t \n\t\t \n\t\t\t M R Kumar \n\t\t \n\t\t \n\t\t\t Dileep \n\t\t \n\t \n\t \n\t\t Information and Communication Technology for Competitive Strategies (ICTCS 2022) Intelligent Strategies for ICT \n\t\t Singapore \n\t\t \n\t\t\t Springer \n\t\t\t 2023 \n\t\t\t \n\t\t \n\t \n\t Tiwari, Vikash Kumar, and M. R. Dileep. 2023. An Efficacy of Artificial Intelligence Applications in Healthcare Systems-A Bird View. In Information and Communication Technology for Competitive Strategies (ICTCS 2022) Intelligent Strategies for ICT. Singapore: Springer, pp. 649-59."
    },
    {
      "title": "Diagnosing diabetic retinopathy with artificial intelligence: What information should be included to ensure ethical informed consent",
      "authors": [
        "Frank Ursin",
        "Marcin Orzechowski Cristian Timmermann",
        "Florian Steger"
      ],
      "year": 2021,
      "doi": "10.3389/fmed.2021.695217",
      "journal": "Frontiers in Medicine",
      "volume": "8",
      "pages": "695217",
      "raw": "Diagnosing diabetic retinopathy with artificial intelligence: What information should be included to ensure ethical informed consent \n\t\t \n\t\t\t Frank Ursin \n\t\t \n\t\t \n\t\t\t Marcin Orzechowski Cristian Timmermann \n\t\t \n\t\t \n\t\t\t Florian Steger \n\t\t \n\t\t 10.3389/fmed.2021.695217 \n\t \n\t \n\t\t Frontiers in Medicine \n\t\t \n\t\t\t 8 \n\t\t\t 695217 \n\t\t\t 2021 \n\t\t \n\t \n\t Ursin, Frank, Marcin Orzechowski Cristian Timmermann, and Florian Steger. 2021. Diagnosing diabetic retinopathy with artificial intelligence: What information should be included to ensure ethical informed consent? Frontiers in Medicine 8: 695217. [CrossRef]"
    },
    {
      "title": "Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations",
      "authors": [
        "Usman Usmani",
        "Ari Ahmad",
        "Junzo Happonen"
      ],
      "year": 2023,
      "raw": "Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations \n\t\t \n\t\t\t Usman Usmani \n\t\t \n\t\t \n\t\t\t Ari Ahmad \n\t\t \n\t\t \n\t\t\t Junzo Happonen \n\t\t \n\t\t \n\t\t\t Watada \n\t\t \n\t \n\t \n\t\t International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA) \n\t\t \u02d9Istanbul, T\u00fcrkiye \n\t\t \n\t\t\t 2023. June 8-10 \n\t\t\t \n\t\t \n\t \n\t Paper presented at 2023 5th \n\t Usmani, Usman Ahmad, Ari Happonen, and Junzo Watada. 2023. Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations. Paper presented at 2023 5th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA), \u02d9Istanbul, T\u00fcrkiye, June 8-10; pp. 1-5."
    },
    {
      "doi": "10.1109/hora58378.2023.10156761",
      "raw": "10.1109/hora58378.2023.10156761 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness",
      "authors": [
        "Sebastian Vollmer",
        "Bilal Mateen",
        "Gergo Bohner",
        "Franz Kir\u00e1ly",
        "Rayid Ghani",
        "Pall Jonsson",
        "Sarah Cumbers",
        "Adrian Jonas",
        "Katherine Mcallister",
        "Puja Myles"
      ],
      "year": 2020,
      "doi": "10.1136/bmj.l6927",
      "journal": "BMJ",
      "volume": "368",
      "pages": "6927",
      "raw": "Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness \n\t\t \n\t\t\t Sebastian Vollmer \n\t\t \n\t\t \n\t\t\t Bilal A Mateen \n\t\t \n\t\t \n\t\t\t Gergo Bohner \n\t\t \n\t\t \n\t\t\t Franz J Kir\u00e1ly \n\t\t \n\t\t \n\t\t\t Rayid Ghani \n\t\t \n\t\t \n\t\t\t Pall Jonsson \n\t\t \n\t\t \n\t\t\t Sarah Cumbers \n\t\t \n\t\t \n\t\t\t Adrian Jonas \n\t\t \n\t\t \n\t\t\t Katherine S L Mcallister \n\t\t \n\t\t \n\t\t\t Puja Myles \n\t\t \n\t\t 10.1136/bmj.l6927 \n\t \n\t \n\t\t BMJ \n\t\t \n\t\t\t 368 \n\t\t\t 6927 \n\t\t\t 2020 \n\t\t \n\t \n\t Vollmer, Sebastian, Bilal A. Mateen, Gergo Bohner, Franz J. Kir\u00e1ly, Rayid Ghani, Pall Jonsson, Sarah Cumbers, Adrian Jonas, Katherine S. L. McAllister, Puja Myles, and et al. 2020. Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness. BMJ 368: l6927. [CrossRef]"
    },
    {
      "title": "Challenges and Opportunities in Global Mental Health: A Research-to-Practice Perspective",
      "authors": [
        "Milton Wainberg",
        "Pamela Scorza",
        "James Shultz",
        "Liat Helpman",
        "Jennifer Mootz",
        "Karen Johnson",
        "Yuval Neria",
        "E Jean-Marie",
        "Maria Bradford",
        "Melissa Oquendo"
      ],
      "year": 2017,
      "journal": "Current Psychiatry Reports",
      "volume": "19",
      "pages": "28",
      "raw": "Challenges and Opportunities in Global Mental Health: A Research-to-Practice Perspective \n\t\t \n\t\t\t Milton L Wainberg \n\t\t \n\t\t \n\t\t\t Pamela Scorza \n\t\t \n\t\t \n\t\t\t James M Shultz \n\t\t \n\t\t \n\t\t\t Liat Helpman \n\t\t \n\t\t \n\t\t\t Jennifer J Mootz \n\t\t \n\t\t \n\t\t\t Karen A Johnson \n\t\t \n\t\t \n\t\t\t Yuval Neria \n\t\t \n\t\t \n\t\t\t E Jean-Marie \n\t\t \n\t\t \n\t\t\t Maria A Bradford \n\t\t \n\t\t \n\t\t\t Melissa R Oquendo \n\t\t \n\t\t \n\t\t\t Arbuckle \n\t\t \n\t \n\t \n\t\t Current Psychiatry Reports \n\t\t \n\t\t\t 19 \n\t\t\t 28 \n\t\t\t 2017 \n\t\t \n\t \n\t Wainberg, Milton L., Pamela Scorza, James M. Shultz, Liat Helpman, Jennifer J. Mootz, Karen A. Johnson, Yuval Neria, Jean-Marie E. Bradford, Maria A. Oquendo, and Melissa R. Arbuckle. 2017. Challenges and Opportunities in Global Mental Health: A Research-to-Practice Perspective. Current Psychiatry Reports 19: 28."
    },
    {
      "doi": "10.1007/s11920-017-0780-z",
      "raw": "10.1007/s11920-017-0780-z \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "Ethics and Governance of Artificial Intelligence for Health",
      "year": 2021,
      "raw": "Ethics and Governance of Artificial Intelligence for Health \n\t\t Geneva \n\t\t \n\t\t\t World Health Organization \n\t\t\t 2021 \n\t\t \n\t \n\t WHO Guidance. 2021. Ethics and Governance of Artificial Intelligence for Health. Geneva: World Health Organization."
    },
    {
      "title": "Harnessing the Power of AI: A Comprehensive Review of Its Impact and Challenges in Nursing Science and Healthcare",
      "authors": [
        "Seema Yelne",
        "Minakshi Chaudhary",
        "Karishma Dod",
        "Akhtaribano Sayyad",
        "Ranjana Sharma"
      ],
      "year": 2023,
      "journal": "Cureus",
      "volume": "15",
      "pages": "e49252",
      "raw": "Harnessing the Power of AI: A Comprehensive Review of Its Impact and Challenges in Nursing Science and Healthcare \n\t\t \n\t\t\t Seema Yelne \n\t\t \n\t\t \n\t\t\t Minakshi Chaudhary \n\t\t \n\t\t \n\t\t\t Karishma Dod \n\t\t \n\t\t \n\t\t\t Akhtaribano Sayyad \n\t\t \n\t\t \n\t\t\t Ranjana Sharma \n\t\t \n\t \n\t \n\t\t Cureus \n\t\t \n\t\t\t 15 \n\t\t\t e49252 \n\t\t\t 2023 \n\t\t \n\t \n\t Yelne, Seema, Minakshi Chaudhary, Karishma Dod, Akhtaribano Sayyad, and Ranjana Sharma. 2023. Harnessing the Power of AI: A Comprehensive Review of Its Impact and Challenges in Nursing Science and Healthcare. Cureus 15: e49252."
    },
    {
      "doi": "10.7759/cureus.49252",
      "raw": "10.7759/cureus.49252 \n\t\t \n\t \n\t CrossRef"
    },
    {
      "title": "The Adoption of AI in Mental Health Care-Perspectives From Mental Health Professionals: Qualitative Descriptive Study",
      "authors": [
        "Melody Zhang",
        "Jillian Scandiffio",
        "Sarah Younus",
        "Tharshini Jeyakumar",
        "Inaara Karsan",
        "Rebecca Charow",
        "Mohammad Salhia",
        "David Wiljer"
      ],
      "year": 2023,
      "doi": "10.2196/47847",
      "journal": "JMIR Formative Research",
      "volume": "7",
      "pages": "47847",
      "raw": "The Adoption of AI in Mental Health Care-Perspectives From Mental Health Professionals: Qualitative Descriptive Study \n\t\t \n\t\t\t Melody Zhang \n\t\t \n\t\t \n\t\t\t Jillian Scandiffio \n\t\t \n\t\t \n\t\t\t Sarah Younus \n\t\t \n\t\t \n\t\t\t Tharshini Jeyakumar \n\t\t \n\t\t \n\t\t\t Inaara Karsan \n\t\t \n\t\t \n\t\t\t Rebecca Charow \n\t\t \n\t\t \n\t\t\t Mohammad Salhia \n\t\t \n\t\t \n\t\t\t David Wiljer \n\t\t \n\t\t 10.2196/47847 \n\t \n\t \n\t\t JMIR Formative Research \n\t\t \n\t\t\t 7 \n\t\t\t 47847 \n\t\t\t 2023 \n\t\t \n\t \n\t Zhang, Melody, Jillian Scandiffio, Sarah Younus, Tharshini Jeyakumar, Inaara Karsan, Rebecca Charow, Mohammad Salhia, and David Wiljer. 2023. The Adoption of AI in Mental Health Care-Perspectives From Mental Health Professionals: Qualitative Descriptive Study. JMIR Formative Research 7: e47847. [CrossRef]"
    },
    {
      "title": "The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of",
      "raw": "The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of \n\t\t \n\t \n\t Disclaimer/Publisher's Note MDPI and/or the editor(s MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content \n\t Disclaimer/Publisher's Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
    }
  ],
  "num_references": 131,
  "figures": [
    {
      "caption": "Figure 1 .",
      "description": "Figure 1. Flow diagram showing the study selection/screening process."
    },
    {
      "caption": "Figure 1 .",
      "description": "Figure 1. Flow diagram showing the study selection/screening process."
    },
    {
      "caption": "Author",
      "description": "Contributions: Conceptualization, H.R.S. and N.G.; methodology, S.G.H.F. and B.L.; validation, B.L.; formal analysis, H.R.S.; investigation, N.G.; resources, S.G.H.F.; data curation, H.R.S., N.G., B.L. and S.G.H.F.; writing-original draft preparation, H.R.S. and B.L.; writing-review and editing, B.L.; visualization, H.R.S.; supervision, N.G.; project administration, N.G. All authors have read and agreed to the published version of the manuscript. Funding: This research received no external funding."
    },
    {
      "type": "table",
      "caption": "Table 1 .",
      "description": "Ethical considerations of artificial intelligence interventions in mental health and well-being."
    },
    {
      "type": "table",
      "caption": "Table 2 .",
      "description": "Considerations for integrating ethical principles for responsible practice and positive outcomes in ai technologies for mental health settings."
    },
    {
      "type": "table",
      "caption": "Table 2 .",
      "description": "Cont."
    },
    {
      "type": "table",
      "caption": "Table 3 .",
      "description": "Best Practices for ethical use of ai in mental health interventions: guidelines and recommendations."
    },
    {
      "type": "table",
      "caption": "Table 3 .",
      "description": "Cont."
    }
  ],
  "num_figures": 8,
  "tables": [
    {
      "content": "Considerations Interpretation Reference Privacy and confidentiality AI systems often collect and analyze large amounts of sensitive personal data. It is crucial to ensure that these data are handled securely and that individuals' privacy rights are respected. (Y. Chen and Esmaeilzadeh 2024; Chintala 2022; Murdoch 2021; Sivan and Zukarnain 2021) Individuals should be fully informed about how Informed consent their data will be used and the potential risks and benefits of using AI interventions in mental health. Informed consent should be obtained (Cohen 2019; Pickering 2021; Ursin et al. 2021) before implementing any AI-based intervention. AI systems can perpetuate and amplify biases Bias and fairness present in the data used to train them. It is important to address issues of bias and ensure that AI interventions are fair and equitable for all individuals, regardless of their background (Gaonkar et al. 2023; Kerasidou 2021; Martin et al. 2022; Aditya Singhal et al. 2024; Tatineni 2019) or characteristics. The decision-making process of AI systems can Transparency, explainability, and accountability often be opaque and difficult to interpret. It is important to ensure transparency in how AI interventions are developed, implemented, and evaluated and to establish mechanisms for (Habli et al. 2020; Khanna and Srivastava 2020; Kiseleva et al. 2022; Aditya Singhal et al. 2024; Vollmer et al. 2020) accountability in case of errors or harm. AI interventions should be designed to support Autonomy and human agency and enhance human decision making and autonomy rather than replacing human (Fanni et al. 2023; Love 2023; Tiribelli 2023) judgment entirely. AI interventions should be rigorously evaluated Safety and efficacy to ensure that they are safe and effective for use in mental health and well-being contexts. It is essential to prioritize the well-being and safety of individuals who may be using (Davahli et al. 2021; Ellahham et al. 2020; Habli et al. 2020; Morley et al. 2021; Tiwari and Dileep 2023) these interventions. 3.4. Integrating Ethical Principles for Responsible Practice and Positive Outcomes in AI Technologies for Mental Health Settings"
    },
    {
      "content": "Considerations Interpretation Reference A clear ethical framework should be established that Ethical framework outlines the values and principles that will guide the development and implementation of AI technologies in mental health settings is essential. This framework should address key ethical considerations such as (Baskin et al. 2021; Leimanis and Palkova 2021; Nasir et al. 2024; Prathomwong and Singsuriya 2022; Tahri Sqalli et al. 2023) privacy, transparency, fairness, and accountability. The involvement of a diverse group of stakeholders, including mental health professionals, patients, Stakeholder engagement ethicists, and community members, in the development process can help identify and address ethical concerns from various perspectives."
    },
    {
      "content": "Considerations Interpretation Reference Conducting regular ethical reviews of AI technologies Ethical review in mental health settings can help identify and address any ethical issues that may arise during the (McKay et al. 2023; Olorunsogo et al. 2024; Shaw 2022) development and implementation process. Implementing strategies to mitigate bias in AI technologies, such as using diverse and representative Bias mitigation datasets, regularly monitoring for bias, and incorporating fairness and accountability measures (F. Chen et al. 2024; Ferrara 2023; Mensah 2023; Mittermaier et al. 2023) into the algorithms, can help ensure that the technology is used ethically and responsibly. Regularly evaluating the impact of AI technologies on mental health outcomes and ethical considerations is Continuous evaluation and improvement important. This includes monitoring for any unintended consequences, soliciting feedback from stakeholders, and making adjustments to the (WHO Guidance 2021; Magrabi et al. 2019; McGreevey et al. 2020; Morley et al. 2020) technology as needed to ensure positive outcomes and responsible practice."
    },
    {
      "content": "Considerations Interpretation Reference Established ethical guidelines and principles should be followed, such as those outlined by professional Adhere to ethical organizations like the American Psychological (Joerin et al. 2020; Luxton 2014; Skorburg guidelines Association (APA) or the World Health Organization et al. 2024) (WHO), to guide the development and implementation of AI technologies in mental health settings. Transparency about how AI technologies are developed, how they work, what underlying data were used to Ensure transparency and train them, and how they are used in mental health (Carr 2020; Kasula 2023; Aditya Singhal explainability interventions should be prioritized. Providing clear et al. 2024) information to users about the technology can help build trust and promote ethical use. Robust data privacy and security measures should be implemented to protect the confidentiality and integrity Prioritize data privacy and of individuals' data. This includes securing data storage, (Gooding and Kariotis 2021; M\u00f6rch et al. security ensuring data encryption, and obtaining informed 2020; Olawade et al. 2024; Rubeis 2022) consent from individuals before collecting and using their data. Steps should be taken to identify and mitigate biases in AI algorithms used in mental health interventions. This Mitigate bias and includes using diverse and representative datasets, ensure fairness regularly monitoring for bias, and implementing fairness measures to ensure equitable outcomes for all individuals."
    },
    {
      "content": "Considerations Interpretation Reference A diverse group of stakeholders should be engaged, Involve stakeholders including mental health professionals, patients, ethicists, and community members, in the development and implementation of AI technologies in mental health settings. Incorporating diverse perspectives can help identify and address ethical concerns and ensure that (Carr 2020; Y. Chen and Esmaeilzadeh 2024; Chintala 2022; Kasula 2023; Murdoch 2021; Aditya Singhal et al. 2024; Sivan and Zukarnain 2021) the technology meets the needs of its users. The ethical implications of AI technologies in mental health interventions should be regularly reviewed to Conduct regular ethical reviews identify and address any ethical issues that may arise. This can involve evaluating the potential risks and benefits of the technology, ensuring compliance with (McKay et al. 2023; Olorunsogo et al. 2024; Shaw 2022) ethical guidelines, and making adjustments as needed to promote responsible practice."
    }
  ],
  "num_tables": 5,
  "license": "\u00a9 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/).",
  "license_type": "unknown",
  "num_citations": 172,
  "cited_references": [
    "b73",
    "b3",
    "b72",
    "b13",
    "b39",
    "b57",
    "b18",
    "b44",
    "b116",
    "b2",
    "b105",
    "b103",
    "b113",
    "b107",
    "b121",
    "b25",
    "b59",
    "b9",
    "b35",
    "b118",
    "b20",
    "b90",
    "b114",
    "b60",
    "b74",
    "b21",
    "b120",
    "b111",
    "b66",
    "b93",
    "b127",
    "b64",
    "b119",
    "b47",
    "b68",
    "b42",
    "b31",
    "b98",
    "b108",
    "b96",
    "b54",
    "b106",
    "b123",
    "b78",
    "b52",
    "b29",
    "b37",
    "b15",
    "b23",
    "b5",
    "b124",
    "b75",
    "b101",
    "b82",
    "b129",
    "b45",
    "b88",
    "b55",
    "b50",
    "b33",
    "b7",
    "b11",
    "b53",
    "b63",
    "b80",
    "b34",
    "b27",
    "b0",
    "b76"
  ],
  "notes": [
    "[raw_affiliation] 1  Department of Knowledge and Information Science , Tarbiat Modares University , Tehran 14115-111 , Iran;",
    "[raw_affiliation] 2  Department of Computer Science , Tarbiat Modares University , Tehran 14115-111 , Iran;",
    "[raw_affiliation] 3  Department of Information Science , University of North Texas , Denton , TX 76203 , USA;",
    "[raw_affiliation] 4  Department of Public Health , School of Health , Ilam University of Medical Sciences , Ilam 69391-77143 , Iran",
    "[submission] Received: 4 June 2024 Revised: 12 July 2024 Accepted: 21 July 2024",
    "(B\u00e9lisle-Pipon et al. 2022; Couture et al. 2023; A. Singhal et al. 2024)",
    "(F.Chen et al. 2024; Ferrara 2023; Mensah 2023; Mittermaier et al. 2023)",
    "[raw_reference] Alhuwaydi, Ahmed M. 2024. Exploring the Role of Artificial Intelligence in Mental Healthcare: Current Trends and Future Directions- A Narrative Review for a Comprehensive Insight. Risk Management and Healthcare Policy 17: 1339-48.",
    "[raw_reference] CrossRef",
    "[raw_reference] Alowais, Shuroug A., Sahar S. Alghamdi, Nada Alsuhebany, Tariq Alqahtani, Abdulrahman I. Alshaya, Sumaya N. Almohareb, Atheer Aldairem, Mohammed Alrashed, Khalid Bin Saleh, Hisham A. Badreldin, and et al. 2023. Revolutionizing healthcare: The role of artificial intelligence in clinical practice. BMC Medical Education 23: 689. [CrossRef",
    "[raw_reference] Balcombe, Luke. 2023. AI Chatbots in Digital Mental Health. Informatics 10: 82.",
    "[raw_reference] CrossRef",
    "[raw_reference] Balcombe, Luke, and Diego De Leo. 2021. Digital mental health challenges and the horizon ahead for solutions. JMIR Mental Health 8: e26811.",
    "[raw_reference] CrossRef",
    "[raw_reference] Baskin, Alison S., Ton Wang, Jacquelyn Miller, Reshma Jagsi, Eve A. Kerr, and Lesly A. Dossett. 2021. A health systems ethical framework for de-implementation in health care. Journal of Surgical Research 267: 151-58.",
    "[raw_reference] CrossRef",
    "[raw_reference] B\u00e9lisle-Pipon, Jean-Christophe, Erica Monteferrante, Marie-Christine Roy, and Vincent Couture. 2022. Artificial intelligence ethics has a black box problem. AI & Socety 38: 1507-22.",
    "[raw_reference] CrossRef",
    "[raw_reference] Carr, Sarah. 2020. 'AI gone mental': Engagement and ethics in data-driven technology for mental health. Journal of Mental Health 29: 125-30.",
    "[raw_reference] CrossRef",
    "[raw_reference] Chalyi, Oleksii. 2024. An Evaluation of General-Purpose AI Chatbots: A Comprehensive Comparative Analysis. InfoScience Trends 1: 52-66.",
    "[raw_reference] CrossRef",
    "[raw_reference] Charlson, Fiona, van Mark Ommeren, Abraham Flaxman, Joseph Cornett, Harvey Whiteford, and Shekhar Saxena. 2019. New WHO prevalence estimates of mental disorders in conflict settings: A systematic review and meta-analysis. The Lancet 394: 240-48.",
    "[raw_reference] Chen, Feng, Liqin Wang, Julie Hong, Jiaqi Jiang, and Li Zhou. 2024. Unmasking bias in artificial intelligence: A systematic review of bias detection and mitigation strategies in electronic health record-based models. Journal of the American Medical Informatics Association 31: 1172-83.",
    "[raw_reference] CrossRef",
    "[raw_reference] Chen, Yan, and Pouyan Esmaeilzadeh. 2024. Generative AI in medical practice: In-depth exploration of privacy and security challenges. Journal of Medical Internet Research 26: e53008.",
    "[raw_reference] CrossRef",
    "[raw_reference] Chintala, Sathish Kumar. 2022. Data Privacy and Security Challenges in AI-Driven Healthcare Systems in India. Journal of Data Acquisition and Processing 37: 2769-78.",
    "[raw_reference] Cohen, I. Glenn. 2019. Informed consent and medical artificial intelligence: What to tell the patient? The Georgetown Law Journal 108: 1425.",
    "[raw_reference] CrossRef",
    "[raw_reference] Couture, Vincent, Marie-Christine Roy, Emma Dez, Samuel Laperle, and Jean-Christophe B\u00e9lisle-Pipon. 2023. Ethical implications of artificial intelligence in population health and the public's role in its governance: Perspectives from a citizen and expert panel. Journal of Medical Internet Research 25: e44357.",
    "[raw_reference] CrossRef",
    "[raw_reference] Davahli, Mohammad Reza, Waldemar Karwowski, Krzysztof Fiok, Thomas Wan, and Hamid R. Parsaei. 2021. Controlling safety of artificial intelligence-based systems in healthcare. Symmetry 13: 102.",
    "[raw_reference] CrossRef",
    "[raw_reference] de Bruijn, Hans, Martijn Warnier, and Marijn Janssen. 2022. The perils and pitfalls of explainable AI: Strategies for explaining algorithmic decision-making. Government Information Quarterly 39: 101666.",
    "[raw_reference] CrossRef",
    "[raw_reference] Ellahham, Samer, Nour Ellahham, and Mecit Can Emre Simsekler. 2020. Application of artificial intelligence in the health care safety context: Opportunities and challenges. American Journal of Medical Quality 35: 341-48.",
    "[raw_reference] CrossRef",
    "[raw_reference] Faezi, Aysan, and Bahman Alinezhad. 2024. AI-Enhanced Health Tools for Revolutionizing Hypertension Management and Blood Pressure Control. InfoScience Trends 1: 67-72.",
    "[raw_reference] CrossRef",
    "[raw_reference] Fanni, Rosanna, Giulia Zampedri Valerie Eveline Steinkogler, and Jo Pierson. 2023. Enhancing human agency through redress in Artificial Intelligence Systems. AI & Society 38: 537-47.",
    "[raw_reference] Farhud, Dariush D., and Shaghayegh Zokaei. 2021. Ethical Issues of Artificial Intelligence in Medicine and Healthcare. Iranian Journal of Public Health 50: I-V. [CrossRef]",
    "[raw_reference] Ferrara, Emilio. 2023. Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies. Sci 6: 3.",
    "[raw_reference] CrossRef",
    "[raw_reference] Gaonkar, Bilwaj, Kirstin Cook, and Luke Macyszyn. 2023. Ethical Issues Arising Due to Bias in Training A.I. Algorithms in Healthcare and Data Sharing as a Potential Solution. The AI Ethics Journal 1: 1-14.",
    "[raw_reference] CrossRef",
    "[raw_reference] Ghadiri, Pooria. 2022. Artificial Intelligence Interventions in the Mental Healthcare of Adolescents. Montr\u00e9al: McGill University.",
    "[raw_reference] Gooding, Piers, and Timothy Kariotis. 2021. Ethics and law in research on algorithmic and data-driven technology in mental health care: Scoping review. JMIR Mental Health 8: e24668.",
    "[raw_reference] CrossRef",
    "[raw_reference] Graham, Sarah, Colin Depp, Ellen E. Lee, Camille Nebeker, Xin Tu, Ho-Cheol Kim, and Dilip V. Jeste. 2019. Artificial intelligence for mental health and mental illnesses: An Overview. Current Psychiatry Reports 21: 116.",
    "[raw_reference] CrossRef",
    "[raw_reference] Habli, Ibrahim, Tom Lawton, and Zoe Porter. 2020. Artificial intelligence in health care: Accountability and safety. Bulletin of the World Health Organization 98: 251-56. [CrossRef]",
    "[raw_reference] Jeyaraman, Madhan, Sangeetha Balaji, Naveen Jeyaraman, and Sankalp Yadav. 2023. Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare. Cureus 15: e43262.",
    "[raw_reference] CrossRef",
    "[raw_reference] Joerin, Angela, Michiel Rauws, Russell Fulmer, and Valerie Black. 2020. Ethical Artificial Intelligence for Digital Health Organizations. Cureus 12: e7202.",
    "[raw_reference] CrossRef",
    "[raw_reference] Kasula, Balaram Yadav. 2023. Ethical Considerations in the Adoption of Artificial Intelligence for Mental Health Diagnosis. International Journal of Creative Research In Computer Technology and Design 5: 1-7.",
    "[raw_reference] Kerasidou, Angeliki. 2021. Ethics of artificial intelligence in global health: Explainability, algorithmic bias and trust. Journal of Oral Biology and Craniofacial Research 11: 612-14.",
    "[raw_reference] CrossRef",
    "[raw_reference] Khanna, Shivansh, and Shraddha Srivastava. 2020. Patient-centric ethical frameworks for privacy, transparency, and bias awareness in deep learning-based medical systems. Applied Research in Artificial Intelligence and Cloud Computing 3: 16-35.",
    "[raw_reference] Kiseleva, Anastasiya, Dimitris Kotzinos, and Paul De Hert. 2022. Transparency of AI in healthcare as a multilayered system of accountabilities: Between legal requirements and technical limitations. Frontiers in Artificial Intelligence 5: 879603. [CrossRef]",
    "[raw_reference] Koutsouleris, Nikolaos, Tobias U Hauser, Vasilisa Skvortsova, and Munmun De Choudhury. 2022. From promise to practice: Towards the realisation of AI-informed mental health care. The Lancet Digital Health 4: e829-e840. [CrossRef]",
    "[raw_reference] Lee, Min Kyung. 2018. Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management. Big Data & Society 5: 2053951718756684.",
    "[raw_reference] CrossRef",
    "[raw_reference] Leimanis, Anr\u012b, and Karina Palkova. 2021. Ethical guidelines for artificial intelligence in healthcare from the sustainable development perspective. European Journal of Sustainable Development 10: 90.",
    "[raw_reference] CrossRef",
    "[raw_reference] Li, Han, Renwen Zhang, Yi-Chieh Lee, Robert E. Kraut, and David C. Mohr. 2023. Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being. NPJ Digital Medicine 6: 236. [CrossRef]",
    "[raw_reference] Love, Charles S. 2023. \"Just the Facts Ma'am\": Moral and Ethical Considerations for Artificial Intelligence in Medicine and its Potential to Impact Patient Autonomy and Hope. The Linacre Quarterly 90: 375-94. [CrossRef]",
    "[raw_reference] Luxton, David D. 2014. Artificial intelligence in psychological practice: Current and future applications and implications. Professional Psychology: Research and Practice 45: 332-39.",
    "[raw_reference] CrossRef",
    "[raw_reference] Magrabi, Farah, Elske Ammenwerth, Jytte Brender McNair, Nicolet F. De Keizer, Hannele Hypp\u00f6nen, Pirkko Nyk\u00e4nen, Michael Rigby, Philip J. Scott, Tuulikki Vehko, Zoie Shui-Yee Wong, and et al. 2019. Artificial intelligence in clinical decision support: Challenges for evaluating AI and practical implications. Yearbook of Medical Informatics 28: 128-34. [CrossRef]",
    "[raw_reference] Margetis, George, Stavroula Ntoa, Margherita Antona, and Constantine Stephanidis. 2021. Human-centered design of artificial intelligence. In Handbook of Human Factors and Ergonomics. Hoboken: John Wiley & Sons, Inc., pp. 1085-106.",
    "[raw_reference] CrossRef",
    "[raw_reference] Martin, Clarissa, Kyle DeStefano, Harry Haran, Sydney Zink, Jennifer Dai, Danial Ahmed, Abrahim Razzak, Keldon Lin, Ann Kogler, Joseph Waller, and et al. 2022. The ethical considerations including inclusion and biases, data protection, and proper implementation among AI in radiology and potential implications. Intelligence-Based Medicine 6: 100073.",
    "[raw_reference] CrossRef",
    "[raw_reference] McGreevey, John D., C. William Hanson, and Ross Koppel. 2020. Clinical, legal, and ethical aspects of artificial intelligence-assisted conversational agents in health care. JAMA 324: 552-53.",
    "[raw_reference] CrossRef",
    "[raw_reference] McKay, Francis, Bethany J. Williams, Graham Prestwich, Daljeet Bansal, Darren Treanor, and Nina Hallowell. 2023. Artificial intelligence and medical research databases: Ethical review by data access committees. BMC Medical Ethics 24: 49.",
    "[raw_reference] CrossRef",
    "[raw_reference] Mennella, Ciro, Umberto Maniscalco, Giuseppe De Pietro, and Massimo Esposito. 2024. Ethical and regulatory challenges of AI technologies in healthcare: A narrative review. Heliyon 10: e26297. [CrossRef]",
    "[report_type] of-Bias-Mitigation-Transparency-and-Accountability-in-",
    "AI-Systems",
    "[raw_reference] Mittermaier, Mirja, Marium M. Raza, and Joseph C. Kvedar. 2023. Bias in AI-based models for medical applications: Challenges and mitigation strategies. NPJ Digital Medicine 6: 113.",
    "[raw_reference] Molala, Thomas, and Jabulani Makhubele. 2021. A conceptual framework for the ethical deployment of Artificial Intelligence in addressing mental health challenges: Guidelines for Social Workers. Technium Social Science Journal 24: 696.",
    "[raw_reference] Morley, Jessica, Caio C.V. Machado, Christopher Burr, Josh Cowls, Indra Joshi, Mariarosaria Taddeo, and Luciano Floridi. 2020. The ethics of AI in health care: A mapping review. Social Science & Medicine 260: 113172.",
    "[raw_reference] CrossRef",
    "[raw_reference] Morley, Jessica, Kassandra Karpathakis Caroline Morton, Mariarosaria Taddeo, and Luciano Floridi. 2021. Towards a framework for evaluating the safety, acceptability and efficacy of AI systems for health: An initial synthesis. arXiv arXiv:2104.06910.",
    "[raw_reference] M\u00f6rch, Carl-Maria, Abhishek Gupta, and Brian L. Mishara. 2020. Canada protocol: An ethical checklist for the use of artificial Intelligence in suicide prevention and mental health. Artificial Intelligence in Medicine 108: 101934. [CrossRef]",
    "[raw_reference] Murdoch, Blake. 2021. Privacy and artificial intelligence: Challenges for protecting health information in a new era. BMC Medical Ethics 22: 122.",
    "[raw_reference] CrossRef",
    "[raw_reference] Nasir, Sidra, Rizwan Ahmed Khan, and Samita Bai. 2024. Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond. IEEE Access 12: 31014-35.",
    "[raw_reference] CrossRef",
    "[raw_reference] Olawade, David B., Aderonke Odetayo Ojima Z. Wada, Fiyinfoluwa Asaolu Aanuoluwapo Clement David-Olawade, and Judith Eberhardt. 2024. Enhancing mental health with Artificial Intelligence: Current trends and future prospects. Journal of Medicine, Surgery, and Public Health 3: 100099.",
    "[raw_reference] CrossRef",
    "[raw_reference] Olorunsogo, Tolulope, Adekunle Oyeyemi Adenyi, Chioma Anthonia Okolo, and Oloruntoba Babawarun. 2024. Ethical considerations in AI-enhanced medical decision support systems: A review. World Journal of Advanced Engineering Technology and Sciences 11: 329-36.",
    "[raw_reference] CrossRef",
    "[raw_reference] Page, Matthew J., Patrick M. Bossuyt, Joanne E. McKenzie, Tammy C. Hoffmann, Isabelle Boutron, Larissa Shamseer, Cynthia D. Mulrow, Elie A. Akl, Jennifer M. Tetzlaff, Sue E. Brennan, and et al. 2021. The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. BMJ 372: n71.",
    "[raw_reference] CrossRef",
    "[raw_reference] Pickering, Brian. 2021. Trust, but verify: Informed consent, AI technologies, and public health emergencies. Future Internet 13: 132.",
    "[raw_reference] Prathomwong, Piyanat, and Pagorn Singsuriya. 2022. Ethical framework of digital technology, artificial intelligence, and health equity. Asia Social Issues 15: 252136.",
    "[raw_reference] CrossRef",
    "[raw_reference] Reddy, Sandeep, John Fox, and Maulik P. Purohit. 2019. Artificial intelligence-enabled healthcare delivery. Journal of the Royal Society of Medicine 112: 22-28.",
    "[raw_reference] CrossRef",
    "[raw_reference] Rubeis, Giovanni. 2022. iHealth: The ethics of artificial intelligence and big data in mental healthcare. Internet Interventions 28: 100518. [CrossRef]",
    "ahead-of-print",
    "[raw_reference] Saeidnia, Hamid Reza. 2023. Ethical artificial intelligence (AI): Confronting bias and discrimination in the library and information industry. Library Hi Tech News, ahead-of-print.",
    "[raw_reference] CrossRef",
    "[raw_reference] Shah, Varun. 2022. AI in Mental Health: Predictive Analytics and Intervention Strategies. Journal Environmental Sciences And Technology 1: 55-74.",
    "[raw_reference] Shaw, James. 2022. Emerging paradigms for ethical review of research using artificial intelligence. American Journal of Bioethics 22: 42-44.",
    "[raw_reference] CrossRef",
    "[raw_reference] Shimada, Koki. 2023. The role of artificial intelligence in mental health: A review. Science Insights 43: 1119-27.",
    "[raw_reference] CrossRef",
    "[raw_reference] Siala, Haytham, and Yichuan Wang. 2022. SHIFTing artificial intelligence to be responsible in healthcare: A systematic review. Social Science & Medicine 296: 114782.",
    "[raw_reference] CrossRef",
    "[raw_reference] Singh, Jatin Pal. 2021. AI Ethics and Societal Perspectives: A Comparative Study of Ethical Principle Prioritization Among Diverse Demographic Clusters. Journal of Advanced Analytics in Healthcare Management 5: 1-18.",
    "[raw_reference] Singh, Vipul, Sharmila Sarkar, Vikas Gaur, Sandeep Grover, and Om Prakash Singh. 2024. Clinical Practice Guidelines on using artificial intelligence and gadgets for mental health and well-being. Indian Journal of Psychiatry 66: S414-S419. [CrossRef]",
    "[raw_reference] Singhal, Aditya, Nikita Neveditsin, Hasnaat Tanveer, and Vijay Mago. 2024. Toward Fairness, Accountability, Transparency, and Ethics in AI for Social Media and Health Care: Scoping Review. JMIR Public Health and Surveillance 12: e50048. [CrossRef]",
    "[raw_reference] Sivan, Remya, and Zuriati Ahmad Zukarnain. 2021. Security and privacy in cloud-based e-health system. Symmetry 13: 742.",
    "[raw_reference] CrossRef",
    "[raw_reference] Skorburg, Joshua August, Kieran O'Doherty, and Phoebe Friesen. 2024. Persons or data points? Ethics, artificial intelligence, and the participatory turn in mental health research. American Psychologist 79: 137-49. [CrossRef]",
    "[raw_reference] Smith, Valerie, Declan Devane, Cecily M Begley, and Mike Clarke. 2011. Methodology in conducting a systematic review of systematic reviews of healthcare interventions. BMC Medical Research Methodology 11: 15. [CrossRef]",
    "[raw_reference] Sqalli, Mohammed Tahri, Begali Aslonov, Mukhammadjon Gafurov, and Shokhrukhbek Nurmatov. 2023. Humanizing AI in medical training: Ethical framework for responsible design. Frontiers in Artificial Intelligence 6: 1189914. [CrossRef]",
    "[raw_reference] Tatineni, Sumanth. 2019. Ethical Considerations in AI and Data Science: Bias, Fairness, and Accountability. International Journal of Information Technology and Management Information Systems 10: 11-20.",
    "[raw_reference] Thakkar, Anoushka, Ankita Gupta, and Avinash De Sousa. 2024. Artificial intelligence in positive mental health: A narrative review. Frontiers in Digital Health 6: 1280235.",
    "[raw_reference] CrossRef",
    "[raw_reference] Timmons, Adela C., Jacqueline B. Duong, Natalia Simo Fiallo, Theodore Lee, Huong Phuc Quynh Vo, Matthew W. Ahle, Jonathan S. Comer, LaPrincess C. Brewer, Stacy L. Frazier, and Theodora Chaspari. 2023. A call to action on assessing and mitigating bias in artificial intelligence applications for mental health. Perspectives on Psychological Science 18: 1062-96.",
    "[raw_reference] CrossRef",
    "[raw_reference] Tiribelli, Simona. 2023. The AI ethics principle of autonomy in health recommender systems. Argumenta 16: 1-18.",
    "[raw_reference] Tiwari, Vikash Kumar, and M. R. Dileep. 2023. An Efficacy of Artificial Intelligence Applications in Healthcare Systems-A Bird View. In Information and Communication Technology for Competitive Strategies (ICTCS 2022) Intelligent Strategies for ICT. Singapore: Springer, pp. 649-59.",
    "[raw_reference] Ursin, Frank, Marcin Orzechowski Cristian Timmermann, and Florian Steger. 2021. Diagnosing diabetic retinopathy with artificial intelligence: What information should be included to ensure ethical informed consent? Frontiers in Medicine 8: 695217. [CrossRef]",
    "Paper presented at 2023 5th",
    "[raw_reference] Usmani, Usman Ahmad, Ari Happonen, and Junzo Watada. 2023. Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations. Paper presented at 2023 5th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA), \u02d9Istanbul, T\u00fcrkiye, June 8-10; pp. 1-5.",
    "[raw_reference] CrossRef",
    "[raw_reference] Vollmer, Sebastian, Bilal A. Mateen, Gergo Bohner, Franz J. Kir\u00e1ly, Rayid Ghani, Pall Jonsson, Sarah Cumbers, Adrian Jonas, Katherine S. L. McAllister, Puja Myles, and et al. 2020. Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness. BMJ 368: l6927. [CrossRef]",
    "[raw_reference] Wainberg, Milton L., Pamela Scorza, James M. Shultz, Liat Helpman, Jennifer J. Mootz, Karen A. Johnson, Yuval Neria, Jean-Marie E. Bradford, Maria A. Oquendo, and Melissa R. Arbuckle. 2017. Challenges and Opportunities in Global Mental Health: A Research-to-Practice Perspective. Current Psychiatry Reports 19: 28.",
    "[raw_reference] CrossRef",
    "[raw_reference] WHO Guidance. 2021. Ethics and Governance of Artificial Intelligence for Health. Geneva: World Health Organization.",
    "[raw_reference] Yelne, Seema, Minakshi Chaudhary, Karishma Dod, Akhtaribano Sayyad, and Ranjana Sharma. 2023. Harnessing the Power of AI: A Comprehensive Review of Its Impact and Challenges in Nursing Science and Healthcare. Cureus 15: e49252.",
    "[raw_reference] CrossRef",
    "[raw_reference] Zhang, Melody, Jillian Scandiffio, Sarah Younus, Tharshini Jeyakumar, Inaara Karsan, Rebecca Charow, Mohammad Salhia, and David Wiljer. 2023. The Adoption of AI in Mental Health Care-Perspectives From Mental Health Professionals: Qualitative Descriptive Study. JMIR Formative Research 7: e47847. [CrossRef]",
    "Disclaimer/Publisher's Note MDPI and/or the editor(s MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content",
    "[raw_reference] Disclaimer/Publisher's Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content."
  ],
  "processing_software": {
    "GROBID": "0.8.2"
  }
}
