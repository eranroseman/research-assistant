<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_ez3W5rR">Artificial intelligence related safety issues associated with FDA medical device reports Check for updates</title>
				<funder ref="#_tZj9CyW">
					<orgName type="full">Agency for Healthcare Research and Quality</orgName>
					<orgName type="abbreviated">AHRQ</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000133</idno>
				</funder>
				<funder>
					<orgName type="full">MedStar Health Research Institute</orgName>
					<orgName type="abbreviated">MHRI</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100012367</idno>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jessica</forename><forename type="middle">L</forename><surname>Handley</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Seth</forename><forename type="middle">A</forename><surname>Krevat</surname></persName>
							<idno type="ORCID">0000-0002-0167-8791</idno>
						</author>
						<author>
							<persName><forename type="first">Allan</forename><surname>Fong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Raj</forename><forename type="middle">M</forename><surname>Ratwani</surname></persName>
							<idno type="ORCID">0000-0002-8623-6123</idno>
						</author>
						<title level="a" type="main" xml:id="_YT9V89j">Artificial intelligence related safety issues associated with FDA medical device reports Check for updates</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0C2072CF0732CCCCB5657DD587C6DF1B</idno>
					<idno type="DOI">10.1038/s41746-024-01357-5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T09:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_Hq6Mate"><p xml:id="_TtAXyn7"><s xml:id="_dQbzh7e">The Biden 2023 Artificial Intelligence (AI) Executive Order calls for the creation of a patient safety program.</s><s xml:id="_9vXHuwU">Patient safety reports are a natural starting point for identifying issues.</s><s xml:id="_jwHDTVe">We examined the feasibility of this approach by analyzing reports associated with AI/Machine Learning (ML)-enabled medical devices.</s><s xml:id="_hJphjBK">Of the 429 reports reviewed, 108 (25.2%) were potentially AI/ML related, with 148 (34.5%) containing insufficient information to determine an AI/ML contribution.</s><s xml:id="_JHwZYTq">A more comprehensive approach is needed.</s></p><p xml:id="_aJ63GbD"><s xml:id="_gMNcmDC">Artificial intelligence (AI) use in clinical settings has tremendous potential to improve care and reduce healthcare workforce burden, however, it may also introduce patient safety risks <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> .</s><s xml:id="_UmpEfQK">To begin to address potential patient safety risks, President Biden's October 2023 AI Executive Order calls for an AI safety program.</s><s xml:id="_JpJPGTB">Federal agencies, working with patient safety organizations (PSOs), shall establish approaches for identifying and capturing clinical errors resulting from AI in healthcare settings and create a central tracking repository for these issues <ref type="bibr" target="#b3">4</ref> .</s><s xml:id="_QtvkZTZ">Patient safety event reports, which are descriptions of actual safety incidents or potential safety hazards typically entered by frontline clinicians, are a natural starting point for identifying AIrelated safety issues.</s><s xml:id="_fqgn3US">These reports are already collected by most U.S. healthcare facilities, aggregated by PSOs and collected by some federal agencies.</s><s xml:id="_ZVMAv7R">Further, there is precedent for these reports being used to identify safety issues associated with electronic health records, as well as other technologies <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6</ref> .</s><s xml:id="_RGgn3dk">The Executive Order's explicit reference to PSOs involvement in the development of the AI safety program suggests that patient safety event reports are being viewed as important sources of information on AI-related safety issues.</s><s xml:id="_WeRvQUq">However, the feasibility of using patient safety event reports in this way is unknown.</s></p><p xml:id="_5D5gAwv"><s xml:id="_fW2rYpn">We sought to determine whether safety reports associated with AI/ machine learning (ML)-enabled medical devices reported to the Food and Drug Administration's (FDA) Manufacturer and User Facility Device Experience (MAUDE) database describe AI/ML safety issues and contain enough detail to identify how AI/ML may have contributed to the safety issue.</s><s xml:id="_yEcTeTt">While there has been an analysis of these reports to identify the different factors contributing to safety issues, such as device or use problems, this analysis did not inform whether safety reports provide insight into AIrelated safety issues from the perspective of whether these reports can serve to identify clinical errors involving AI/ML-enabled devices <ref type="bibr" target="#b6">7</ref> .</s><s xml:id="_xJ2T9Ra">Although the MAUDE database was never intended to identify clinical errors involving AI, we sought to analyze these reports with a focus on whether they enable the identification of AI/ML contributions to patient safety to inform efforts under the Biden Executive Order and to inform FDA's real-world monitoring of AI/ML-enabled medical devices.</s></p><p xml:id="_fFk66JB"><s xml:id="_sU7rHxw">We identified and reviewed 429 safety reports associated with AI/MLenabled medical devices.</s><s xml:id="_vrXn6Jx">Of the reports reviewed, 108 (25.2%) were potentially AI/ML related and 173 (40.3%) were unlikely AI/ML related.</s><s xml:id="_yUmhMRY">There was insufficient information to determine if AI/ML contributed to the safety event in 148 reports (34.5%),</s><s xml:id="_7Wqg2SA">see Table <ref type="table" target="#tab_0">1</ref>.</s></p><p xml:id="_atX8wwp"><s xml:id="_5JABDrG">Our analysis shows safety issues are being reported about AI/ML-enabled medical devices and these issues may potentially be related to AI/ML in 25.2% of the reports reviewed.</s><s xml:id="_h8qvEY4">This finding underscores the need for an AI patient safety program, as outlined by the Biden Executive Order.</s><s xml:id="_E2XjrHv">However, the reports that were identified as potentially AI/ML-related lacked sufficient detail to identify how AI/ML contributed at a level of specificity that would enable improvements to the technology.</s><s xml:id="_SxyK5mm">A previous study was able to classify these types of reports as device or use-related, however, these categories still do not provide the level of specificity needed to identify specific improvements <ref type="bibr" target="#b6">7</ref> .</s><s xml:id="_3jXWKFg">Further, 34.5% of reports contained insufficient information to determine whether AI/ML contributed at all.</s><s xml:id="_9D3Z3zM">Together, these results highlight that patient safety reports alone, which were never intended for identifying AI issues, may not be sufficient for identifying AI/ML related safety issues and how AI/ML may have contributed to the issue.</s><s xml:id="_jrnMbzx">Safety reports may be insufficient for identifying AI/ML issues because those reporting may not have insight on whether AI/ML are contributing to the safety issue they are observing given that these algorithms are at work "behind the scenes".</s><s xml:id="_jYNbDTv">Thus, a different approach to AI safety is needed to better capture these issues.</s></p><p xml:id="_zFz46dD"><s xml:id="_XeNhXwE">A more comprehensive patient safety program should include additional mechanisms for capturing AI safety issues that extend beyond self-reported safety concerns.</s><s xml:id="_fNtvBeS">Guidelines to inform the safe implementation and use of AI in clinical settings, proactive AI algorithm monitoring processes, and developing ways to trace AI algorithm contributions to safety issues should be part of the safety program 8 .</s><s xml:id="_YfwYjhj">Guidelines will be especially important to support healthcare facilities as they adopt more AI/ML-enabled technologies and may not have the expertise to safely implement these technologies.</s><s xml:id="_usVnVqE">These guidelines should inform how to assess technologies for safe use, implement them into the healthcare work system, and frequently monitor for safety issues.</s><s xml:id="_a4Wz3R2">In addition, the FDA should develop other mechanisms, aside from the MAUDE database, to capture AI-related safety issues associated with AI/ML-enabled medical devices.</s><s xml:id="_xr42AJH">The FDA has been developing best practices and methods to enable updates to AI/ML algorithms under predetermined change control plans.</s></p><p xml:id="_k6Hewr6"><s xml:id="_hy4Gmbm">Limitations to this study include analyzing safety reports from a single database from one federal agency and recognizing that reporters may not be aware of when AI is contributing to a safety issue.</s><s xml:id="_xvK7hYh">It is possible that patient safety event reports at the healthcare facility level contain different details about AI-related safety issues.</s></p><p xml:id="_gGBfcHG"><s xml:id="_9mcjvSq">In addition to the Executive Order safety program, additional safety mechanisms such as AI assurance labs that are developed through a publicprivate partnership, like the Coalition for Health AI, can serve to promote the adoption of safer AI algorithms <ref type="bibr" target="#b8">9</ref> .</s><s xml:id="_pqCaxdA">Keeping patients safe will require engagement from multiple stakeholders including federal agencies, AI developers, healthcare facilities, frontline clinicians, and patient advocacy groups.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_uQ8Ngs6">Methods</head><p xml:id="_A6MdgZF"><s xml:id="_FmJpRfX">Medical device manufacturers, importers, and device user facilities (e.g., hospitals and nursing homes) are required to report to the FDA MAUDE database when they learn that any of their medical devices may have caused or contributed to a death or serious injury <ref type="bibr" target="#b9">10</ref> .</s><s xml:id="_atngZyw">The purpose of MAUDE is to support post-market surveillance of medical devices and support risk management, independent of cause or contributing factors.</s><s xml:id="_J6HgDqc">The FDA defines a medical device per Section 201(h) of the Food, Drug, and Cosmetic Act as <ref type="bibr" target="#b10">11</ref> :</s></p><p xml:id="_pfGhnrv"><s xml:id="_AenfNWs">An instrument, apparatus, implement, machine, contrivance, implant, in vitro reagent, or other similar or related article, including a component part, or accessory which is:</s></p><p xml:id="_TTQhCyP"><s xml:id="_5jMmKxd">• (A) recognized in the official National Formulary, or the United States Pharmacopoeia, or any supplement to them, • (B) intended for use in the diagnosis of disease or other conditions, or in the cure, mitigation, treatment, or prevention of disease, in man or other animals, or • (C) intended to affect the structure or any function of the body of man or other animals, and which does not achieve its primary intended purposes through chemical action within or on the body of man or other animals and which is not dependent upon being metabolized for the achievement of its primary intended purposes.</s></p><p xml:id="_6JNV84P"><s xml:id="_xrfAVEy">To identify potential AI/ML safety related reports from the MAUDE database a list of FDA approved AI/ML-enabled medical devices, made publicly available by the FDA, was matched to all reports in the MAUDE database through October, 18 2023 using openFDA which is an Elasticsearch-based API that serves public FDA data <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13</ref> .</s><s xml:id="_W4myyAc">MAUDE reports with an exact or partial match of the AI/ML-enabled medical device brand name, generic name, or manufacturer name were retrieved, resulting in 429 reports.</s></p><p xml:id="_ZGhKSfR"><s xml:id="_6mfGmGp">Reports were independently reviewed by a physician safety leader and a human factors expert to determine if AI/ML contributed to the safety event or whether insufficient information was provided to identify AI/ML as a contributor.</s><s xml:id="_k8rhqRp">Each report was classified into one of three categories (Table <ref type="table" target="#tab_0">1</ref>).</s><s xml:id="_SMZ3egT">For a report to be considered potentially AI/ML related, the report had to explicitly describe that an AI algorithm was used, and its use had to be associated with the reported safety issue.</s><s xml:id="_nKRnPPc">If the report explicitly described an aspect of the device that may have contributed to the safety issue, and it was not AI/ML related, it was coded as unlikely AI/ML related.</s><s xml:id="_S9cQKKs">All other reports were coded as insufficient information.</s><s xml:id="_ec8QbAf">Discrepancies were discussed until a consensus was reached.</s><s xml:id="_MXTWdab">The MAUDE report contained language suggesting AI/ML potentially contributed to the event.</s></p><p xml:id="_Yf3HQfx"><s xml:id="_s3JX2X8">"Utilizing insulin algorithm software Monarch Endotool, a pt was administered insulin 9 units as recommended by endotool the pt was hypokalemic potassium replacement was started simultaneously with initiation of insulin the pt was transferred to the icu for dka management he became unresponsive and coded due to an unstable cardiac arrhythmia postcode the pt was found to have critically low potassium level which contributed to the code"</s></p><p xml:id="_QmE2be3"><s xml:id="_nrekJwU">Unlikely AI/ML Related 173 (40.3%)</s><s xml:id="_zDZvztg">The MAUDE report did not contain language suggesting AI/ML contributed to the event.</s></p><p xml:id="_2aXbVnt"><s xml:id="_MKjhFGf">"While inserting trocar and sleeve part of the tricuspid membrane came apart breaking off and going into abdomen device was not retrieved" Insufficient Information 148 (34.5%)</s><s xml:id="_PE9aJ2p">There was not enough information provided in the MAUDE report to determine if AI/ML contributed to the event.</s></p><p xml:id="_2GGtM7V"><s xml:id="_wyVvDKm">"Additional information will be provided once the investigation has been completed the device manufacturer date is not known at this time however, should it become available, it will be provided in future reports" <ref type="url" target="https://doi.org/10.1038/s41746-024-01357-5">https://doi.org/10.1038/s41746-024-01357-5</ref></s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 |</head><label>1</label><figDesc><div><p xml:id="_7PQMCW8"><s xml:id="_8AhF6UE">Frequency counts, percentages, definitions, and examples of the contribution of artificial intelligence/machine learning to safety issues identified in MAUDE reports</s></p></div></figDesc><table><row><cell>Category</cell><cell>Frequency</cell><cell>Definition</cell><cell>Examples</cell></row><row><cell></cell><cell>count (%)</cell><cell></cell><cell></cell></row><row><cell>Potentially AI/ML</cell><cell>108 (25.2%)</cell><cell></cell><cell></cell></row><row><cell>Related</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p xml:id="_HqPXZ85"><s xml:id="_bywXXg8">MedStar Health National Center for Human Factors in Healthcare, Washington, DC, USA.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p xml:id="_SQq4feh"><s xml:id="_w3QMbdw">Georgetown University School of Medicine, Washington, DC, USA.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p xml:id="_uBJXt33"><s xml:id="_dRWQhGx">MedStar Health Center for Bioinformatics and Data Science, Washington, DC, USA.</s><s xml:id="_xhYVxj9">e-mail: Raj.M.Ratwani@medstar.net</s><s xml:id="_SgKQrU9">npj Digital Medicine | (2024) 7:351 1 1234567890():,; 1234567890():,;</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p xml:id="_spbxuXC"><s xml:id="_zWrYpc2">npj Digital Medicine | (2024) 7:351</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_XxkZ8FX">Acknowledgements</head><p xml:id="_y76YSqa"><s xml:id="_mxtef3b">This work was supported by grant <rs type="grantNumber">R01HS026481</rs> from the <rs type="funder">Agency for Healthcare Research and Quality</rs> to <rs type="person">Dr. Ratwani</rs> and the <rs type="funder">MedStar Health Research Institute</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_tZj9CyW">
					<idno type="grant-number">R01HS026481</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_39RBm7J">Data availability</head><p xml:id="_Z9SthTy"><s xml:id="_WHTmKvZ">The safety reports analyzed will be made available upon request.</s></p><p xml:id="_KqxaMxZ"><s xml:id="_GZFveta">Received: 26 April 2024; Accepted: 24 November 2024;</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_muVepUd">Author contributions</head><p xml:id="_sS26uqG"><s xml:id="_Pgbh7G9">J.H., S.K., A.F., and R.R. conceived of the idea and contributed to discussing the data and writing the paper.</s><s xml:id="_58RNNAz">J.H. and S.K. analyzed the data.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_yxtUBuJ">Competing interests</head><p xml:id="_hSMBs2G"><s xml:id="_P64YSuG">The authors declare no competing interests.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_M6vFWSp">Three epochs of artificial intelligence in health care</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Howell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Desalvo</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2023.25057</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aSX3meh">J. Am. Med. Assoc</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="242" to="244" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Howell, M. D., Corrado, G. S. &amp; DeSalvo, K. B. Three epochs of artificial intelligence in health care. J. Am. Med. Assoc. 331, 242-244 (2024).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_gP53rbA">Ambient artificial intelligence scribes to alleviate the burden of clinical documentation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Tierney</surname></persName>
		</author>
		<idno type="DOI">10.1056/cat.23.0404</idno>
		<ptr target="https://doi.org/10.1056/CAT.23.0404" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_jC8KVfB">NEJM Catal. Innov. Care Deliv</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tierney, A. A. et al. Ambient artificial intelligence scribes to alleviate the burden of clinical documentation. NEJM Catal. Innov. Care Deliv. https://doi.org/10.1056/CAT.23.0404 (2024).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_BFwQAGB">The potential for artificial intelligence to transform healthcare: perspectives from international health leaders</title>
		<author>
			<persName><forename type="first">C</forename><surname>Silcox</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-024-01097-6</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TXjyJ2z">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">88</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Silcox, C. et al. The potential for artificial intelligence to transform healthcare: perspectives from international health leaders. NPJ Digit. Med. 7, 88 (2024).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main" xml:id="_ghpS7gd">Executive order on the safe, secure, and trustworthy development and use of artificial intelligence</title>
		<idno type="DOI">10.35467/cal/187256</idno>
		<ptr target="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence" />
		<imprint>
			<date type="published" when="2023">March 18, 2024. 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Executive order on the safe, secure, and trustworthy development and use of artificial intelligence. Accessed March 18, 2024. https://www. whitehouse.gov/briefing-room/presidential-actions/2023/10/30/ executive-order-on-the-safe-secure-and-trustworthy-development- and-use-of-artificial-intelligence (2023).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_hs6SQV9">Electronic health record usability issues and potential contribution to patient harm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Z</forename><surname>Hettinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Ratwani</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2018.1171</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZaZyjC3">J. Am. Med. Assoc</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="page" from="1276" to="1278" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Howe, J. L., Adams, K. T., Hettinger, A. Z. &amp; Ratwani, R. M. Electronic health record usability issues and potential contribution to patient harm. J. Am. Med. Assoc. 319, 1276-1278 (2018).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_2thzfry">Identifying electronic health record usability and safety challenges in pediatric settings</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Ratwani</surname></persName>
		</author>
		<idno type="DOI">10.1377/hlthaff.2018.0699</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gCPeU3E">Health Aff</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1752" to="1759" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratwani, R. M. et al. Identifying electronic health record usability and safety challenges in pediatric settings. Health Aff. 37, 1752-1759 (2018).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_GdXQW2Q">More than algorithms: an analysis of safety events involving ML-enabled medical devices reported to the FDA</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lyell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Coiera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Magrabi</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocad065</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tTXzgQ7">J. Am. Med. Inf. Assoc</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1227" to="1236" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lyell, D., Wang, Y., Coiera, E. &amp; Magrabi, F. More than algorithms: an analysis of safety events involving ML-enabled medical devices reported to the FDA. J. Am. Med. Inf. Assoc. 30, 1227-1236 (2023).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_JfanDGk">Patient safety and artificial intelligence in clinical care</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Ratwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Classen</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamahealthforum.2023.5514</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_S22Y2Eb">JAMA Health Forum</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">235514</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ratwani, R. M., Bates, D. W. &amp; Classen, D. C. Patient safety and artificial intelligence in clinical care. JAMA Health Forum 5, e235514 (2024).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_kUaYVZR">A nationwide network of health AI assurance laboratories</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2023.26930</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_f5vc6Ce">J. Am. Med. Assoc</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="245" to="249" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shah, N. H. et al. A nationwide network of health AI assurance laboratories. J. Am. Med. Assoc. 331, 245-249 (2024).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main" xml:id="_KtsuMh9">): How to Report Medical Device Problems</title>
		<idno type="DOI">10.1887/0750307684/b1067b4</idno>
		<ptr target="https://www.fda.gov/medical-devices/medical-device-safety/medical-device-reporting-mdr-how-report-medical-device-problems#:~:text=User%20facilities%20must%20" />
		<imprint>
			<date type="published" when="2024-06-08">June 8, 2024</date>
		</imprint>
		<respStmt>
			<orgName>Medical Device Reporting (MDR</orgName>
		</respStmt>
	</monogr>
	<note>report%20a,medical%20device%20manufacturer% 20is%20unknown</note>
	<note type="raw_reference">Medical Device Reporting (MDR): How to Report Medical Device Problems. Accessed June 8, 2024. https://www.fda.gov/medical- devices/medical-device-safety/medical-device-reporting-mdr-how- report-medical-device-problems#:~:text=User%20facilities% 20must%20report%20a,medical%20device%20manufacturer% 20is%20unknown.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<idno type="DOI">10.1007/978-981-99-9283-6_1002</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Mu3zzyn">U.S. Congress. United States Code: Federal Food, Drug, and Cosmetic Act, 21 U.S.C. § §</title>
		<imprint>
			<biblScope unit="page" from="301" to="392" />
			<date type="published" when="1934">1934</date>
		</imprint>
	</monogr>
	<note>Suppl</note>
	<note type="raw_reference">U.S. Congress. United States Code: Federal Food, Drug, and Cosmetic Act, 21 U.S.C. § § 301-392 Suppl (1934).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<idno type="DOI">10.21203/rs.3.rs-2355147/v1</idno>
		<ptr target="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices" />
		<title level="m" xml:id="_msBDmk6">Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices</title>
		<imprint>
			<date type="published" when="2023-12-04">December 4, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices. Accessed December 4, 2023. https://www.fda.gov/medical- devices/software-medical-device-samd/artificial-intelligence-and- machine-learning-aiml-enabled-medical-devices.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName><surname>Openfda</surname></persName>
		</author>
		<ptr target="https://open.fda.gov/" />
		<imprint>
			<date type="published" when="2023-12-04">December 4, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">openFDA. Accessed December 4, 2023. https://open.fda.gov/.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
