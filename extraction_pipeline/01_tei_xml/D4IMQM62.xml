<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_yxwQRch">Considerations in Using Artificial Intelligence in Public Health and Medicine</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>MD, MPH</roleName><forename type="first">Irene</forename><surname>Dankwa-Mullan</surname></persName>
							<email>irene.dankwamullan@gwu.edu</email>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>1</label> Department of Health Policy and Management , Milken Institute School of Public Health , The George Washington University , Washington , District of Columbia.</note>
								<orgName type="department">Department of Health Policy and Management</orgName>
								<orgName type="institution" key="instit1">Milken Institute School of Public Health</orgName>
								<orgName type="institution" key="instit2">The George Washington University</orgName>
								<address>
									<settlement>Washington</settlement>
									<region>District of Columbia</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<note type="raw_affiliation">Department of Health Policy and Management , Milken Institute School of Public Health , The George Washington University , 2175 K Street NW , Washington , DC 20037</note>
								<orgName type="department">Department of Health Policy and Management</orgName>
								<orgName type="institution" key="instit1">Milken Institute School of Public Health</orgName>
								<orgName type="institution" key="instit2">The George Washington University</orgName>
								<address>
									<addrLine>2175 K Street NW</addrLine>
									<postCode>20037</postCode>
									<settlement>Washington</settlement>
									<region>DC</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_sgveY6J">Considerations in Using Artificial Intelligence in Public Health and Medicine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5489FB054200FC73EC13B6FB45119E84</idno>
					<idno type="DOI">10.5888/pcd21.240245</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T08:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_V8BUzFB"><p xml:id="_96Pr6vv"><s xml:id="_CMZkHFX">What is already known on this topic?</s><s xml:id="_2aJeGqN">Artificial intelligence (AI) is increasingly used in health care for diagnostics, predictive analytics, and personalized medicine, but it can exacerbate health disparities and ethical concerns if not carefully managed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_v4jdMeG">What is added by this report?</head><p xml:id="_b9E3Jj2"><s xml:id="_2RctPhD">This commentary highlights the multifaceted approach and strategies to promote health equity and ethical use of AI, emphasizing community engagement, inclusive data practices, and transparent algorithms.</s></p><p xml:id="_yyk9BsC"><s xml:id="_DGSCsYF">What are the implications for public health practice?</s><s xml:id="_YX5pPAt">Implementing these strategies can ensure that AI benefits all populations equitably, enhancing trust and effectiveness in public health interventions and medical care.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Azedzff">Introduction</head><p xml:id="_xQ4nyd6"><s xml:id="_HavMrSE">The integration of artificial intelligence (AI) in public health and medicine is revolutionizing how health care and public health professionals approach health care delivery, disease prediction, population health, and patient care management <ref type="bibr" target="#b1">(1)</ref>.</s><s xml:id="_5ezrGF8">As these technologies evolve, they offer unprecedented opportunities for expanding precision health, enhancing efficiency, and optimizing effectiveness in health services <ref type="bibr" target="#b2">(2)</ref>.</s><s xml:id="_mPBPQ9b">However, this integration also prompts critical discussions of the ethical use of AI and the imperative to ensure health equity.</s><s xml:id="_aUgGQha">This commentary explores how AI is reshaping public health and medicine, concerns about bias, ethical challenges, and the importance of incorporating an equity lens in its deployment.</s><s xml:id="_BqJyAyR">AI's potential to transform health is immense, from improving diagnostic accuracy to personalizing treatment plans and predicting disease trends <ref type="bibr" target="#b2">(2)</ref>.</s><s xml:id="_xMVZG65">Yet, as we stand on the brink of this technological revolution, it is crucial to address the ethical implications and ensure that these advancements benefit all sections of society equitably.</s><s xml:id="_C4N2TeH">The misuse or unethical application of AI can lead to increased disparities and further exacerbate adverse outcomes for socially and economically disadvantaged populations.</s><s xml:id="_4ftwj2S">This commentary not only discusses the current applications and benefits of AI but also emphasizes the critical need to maintain a balance between innovation and ethical responsibilities.</s><s xml:id="_pAsPnW4">The commentary explores the historical context of technological transitions in health, examines the effect of AI on health equity, and provides actionable insights and recommendations to guide practitioners, policymakers, researchers, and developers.</s><s xml:id="_mNShczj">The aim is to foster a health care environment that not only embraces technological advancements but also upholds the highest standards of equity and ethical practice.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gpr3ffP">Background on AI in Public Health and Medicine</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_yrMF7hM">Historical perspective</head><p xml:id="_JugYNnY"><s xml:id="_KmS2pT4">The integration of technology in health care is not a novel concept.</s><s xml:id="_FK8cUwx">AI was initially described in the 1950s as expert computer systems that could mimic human intelligence (2).</s><s xml:id="_QjUGdzK">These systems were followed in the 2000s by the emergence of computer vision and machine learning <ref type="bibr" target="#b2">(2)</ref>.</s><s xml:id="_7KNCrXH">Even though researchers continued to explore AI technologies with the evolution of data, the rapid advancement and adoption of AI has come to represent a transformative shift in the landscape.</s><s xml:id="_uZTrgM8">Technological innovations such as the electronic health record (EHR) and medical imaging revolutionized medical diagnostics and patient record management <ref type="bibr" target="#b2">(2)</ref>.</s><s xml:id="_ctYq5NN">Today, AI builds on these foundational advancements by offering more sophisticated tools for data analysis and clinical decisionmaking.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_yJw6Zuc">Current trends</head><p xml:id="_kfa7SWX"><s xml:id="_EvTw6q7">AI is now being used across various facets of public health and medicine, substantially altering how health professionals engage with their patients, communities, and health data.</s><s xml:id="_EJNRzd4">Two key areas where AI is making a mark are diagnostic algorithms and predictive analytics <ref type="bibr" target="#b2">(2)</ref>.</s><s xml:id="_htmnbPZ">For example, AI algorithms are being increasingly used to diagnose diseases from imaging scans -with higher accuracy and speed than human radiologists <ref type="bibr" target="#b3">(3)</ref>.</s><s xml:id="_D64GCKg">In predictive analytics, AI can forecast outbreaks of diseases (4), hospital readmission rates <ref type="bibr" target="#b5">(5)</ref>, and a patient's risk of developing chronic illnesses (6) by analyzing vast datasets.</s><s xml:id="_Uv4jFkv">In this era of precision medicine, AI can help in tailoring medical treatments to individual genetic profiles, potentially improving outcomes and minimizing side effects <ref type="bibr" target="#b7">(7)</ref>.</s><s xml:id="_5Sp83JN">Public health surveillance, disease forecasting, and epidemic modeling are increasingly becoming important areas for integration of AI-based tools <ref type="bibr" target="#b6">(6)</ref>.</s><s xml:id="_qfcAAK3">These applications showcase a few of AI's potential to enhance the efficacy and precision of public health and clinical decision-making.</s><s xml:id="_jZX5JZ2">However, they also bring to light the need for a robust framework to manage these technologies responsibly.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GVbSPFd">Transition challenges</head><p xml:id="_AECvAGS"><s xml:id="_PPJDGwm">As the public health and health care sectors navigate their way through digital transformation, several challenges emerge.</s><s xml:id="_4FJ5dX2">These include technology challenges, widening knowledge gaps, and overall hesitance and resistance to change.</s><s xml:id="_hfDXKeB">For example, integrating AI into any existing public health or health care infrastructure requires substantial technology upgrades, a robust data architecture, and staff training.</s><s xml:id="_jHwuRYZ">Apart from providing upgrades, gaps in understanding AI technologies among health care providers can hinder their effective implementation.</s><s xml:id="_ZxtDg3y">In addition to that, adapting to AI-driven methods requires changes in established workflows and practices, which often meet with resistance from traditional health care providers.</s><s xml:id="_utPye8A">As AI continues to evolve, the health care industry must not only keep pace with these technological changes but also anticipate future developments.</s><s xml:id="_ddXnHSh">Addressing these challenges head-on will be essential for leveraging AI to improve health outcomes while ensuring that such technologies are used ethically and equitably.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ENhHbmp">The Importance of Promoting Health Equity and Addressing Bias in AI Applications</head><p xml:id="_JgMPjtz"><s xml:id="_YkfFS8F">The potential of AI to transform public health and medicine is immense.</s><s xml:id="_Mpt4ts7">Yet, as health professionals harness these technologies, they must also consider the implications on health equity and ethical practices.</s><s xml:id="_GvfDfB2">Health equity in the context of AI applications refers to the fair and just distribution of health technologies and their benefits <ref type="bibr" target="#b8">(8)</ref>.</s><s xml:id="_rQDu9Yu">It ensures that all individuals have access to the same high-quality health care services, regardless of their socioeconomic status, race, sex or gender, ethnicity, disability status, or geographic location <ref type="bibr" target="#b8">(8)</ref>.</s><s xml:id="_E8YCCpe">The deployment of AI diagnostic tools for diabetic retinopathy primarily in well-resourced health care settings or among populations with insurance coverage exemplifies an unfair distribution of technology.</s><s xml:id="_5Eg4qUM">This approach disproportionately benefits people with greater economic means and access while potentially excluding socially or economically disadvantaged populations that may have a higher prevalence of disease but lack the resources or insurance necessary to access such advanced diagnostic tools.</s><s xml:id="_hfGpdDR">Equity is the absence of systematic disparities in health, or in the social determinants of health, between groups with different levels of underlying social advantage such as wealth, power, privilege, and prestige <ref type="bibr" target="#b9">(9)</ref>.</s><s xml:id="_jrjjgEg">For AI to be truly transformative, it must not only advance health care and outcomes but do so in a way that bridges existing health disparities rather than widening them.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_K6UU9Rm">Sources and Risk of Bias</head><p xml:id="_dhPPyqK"><s xml:id="_Ve3n2YX">One of the most noteworthy concerns with AI is the risk of bias in algorithms, which can inadvertently perpetuate existing health disparities.</s><s xml:id="_RJDMgNg">AI bias is a general concept that refers to the fact that an AI system has been designed in a way that makes the system's decisions or use unfair <ref type="bibr" target="#b10">(10)</ref>.</s><s xml:id="_F7ZuujA">These AI data biases often arise from various sources, including the processes of data access, collection, acquisition, preparation, processing, development, and validation <ref type="bibr" target="#b11">(11)</ref>.</s><s xml:id="_jZYNeRT">Bias can also arise from the processes through which scientific evidence is generated, from lack of research diversity and from inadequate data governance.</s><s xml:id="_4Xmfh69">AI models are typically trained on available data, which may not adequately represent racial and ethnic minority groups or other populations that are medically underserved <ref type="bibr" target="#b11">(11)</ref>.</s><s xml:id="_raxkWUw">For example, Obermeyer et al discovered that commercial algorithms, which use cost as a proxy for illness, exhibit racial bias by inadequately identifying the health needs of Black patients compared with White patients despite similar levels of chronic illnesses <ref type="bibr" target="#b12">(12)</ref>.</s><s xml:id="_PMTB8PF">Training data can also reflect historical biases in treatment and access to care for socially disadvantaged populations, leading AI to replicate these injustices <ref type="bibr" target="#b12">(12)</ref>.</s><s xml:id="_jpdgXsm">Finally, many AI tools are so-called black boxes -in which decisionmaking processes are not transparent -making it difficult to assess and rectify biases <ref type="bibr" target="#b13">(13)</ref>.</s><s xml:id="_zhwqG4Y">These are some of the problems that underscore the need for meticulous oversight and corrective measures in the development and deployment of AI technologies to ensure they serve all populations equitably.</s></p><p xml:id="_ypW576J"><s xml:id="_AKbjQKB">Even though addressing AI biases has primarily focused on algorithms, external sources of AI bias exist.</s><s xml:id="_UaMKKsy">They include experience and expertise, exclusion, environment, empathy, and evidence <ref type="bibr" target="#b14">(14)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_G9bypZM">Experience and expertise bias</head><p xml:id="_x4XXRh4"><s xml:id="_nT76ZfX">Experience and expertise bias refers to the skew introduced by the varying levels of expertise among individuals involved in developing AI systems <ref type="bibr" target="#b14">(14)</ref>.</s><s xml:id="_NgRfECy">This bias can manifest in several ways including:</s></p><p xml:id="_NjxkQda"><s xml:id="_PXNkTVe">Training data quality: The quality of the training data can be influenced by the expertise of those who collect, label, and input the data.</s><s xml:id="_PNqzhEN">Inconsistent or incorrect labeling due to lack of expertise can lead to a biased model <ref type="bibr" target="#b2">(2,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b15">15)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GJh69au">•</head><p xml:id="_C4aQVrQ"><s xml:id="_AgnHZgx">Algorithm development: The design and tuning of algorithms require a high level of expertise.</s><s xml:id="_6a6JkdV">Inadequate expertise can result in models that do not generalize well across diverse populations (2).</s></p><p xml:id="_FS92jPt"><s xml:id="_eXpuVCa">• Clinical implementation: Varying levels of familiarity with AI tools among health care providers can affect how these tools are implemented and interpreted, potentially leading to biased outcomes <ref type="bibr" target="#b2">(2,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b16">16</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_akrNw4n">•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_WjMpxFY">Exclusion bias</head><p xml:id="_5BGfT9m"><s xml:id="_fX6tzk7">Exclusion bias occurs when certain groups are systematically left out of the data collection and analysis processes <ref type="bibr" target="#b14">(14)</ref>.</s><s xml:id="_wnUcgHF">This bias can result in AI systems that do not accurately represent or serve the entire population.</s><s xml:id="_wfWxqwM">Some examples are:</s></p><p xml:id="_hBYEsEc"><s xml:id="_B9ZCDp3">Data missingness: When data are missing or incomplete for groups within a dataset, the AI system may not learn patterns relevant to these groups, leading to poorer performance for them compared with other groups <ref type="bibr" target="#b2">(2,</ref><ref type="bibr" target="#b11">11)</ref>.</s></p><p xml:id="_Aj7XcmT"><s xml:id="_aFuG6Qy">• Underrepresentation: Exclusion of certain demographic groups in clinical tri-• als or datasets can cause AI to be less effective or even harmful to these groups <ref type="bibr" target="#b2">(2,</ref><ref type="bibr" target="#b11">11)</ref>.</s></p><p xml:id="_ukKNzeQ"><s xml:id="_8E5GUqP">Access to care: AI tools developed without considering socially or economically marginalized populations might not address the unique barriers these groups face in accessing health care <ref type="bibr" target="#b2">(2,</ref><ref type="bibr" target="#b11">11)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XbMANvQ">•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GDjY69S">Environment bias</head><p xml:id="_bNWuHFg"><s xml:id="_zSjwep6">Environment bias arises from the socio-environmental context in which data are collected and used <ref type="bibr" target="#b14">(14)</ref>.</s><s xml:id="_6m3ZbWX">This bias can include the following:</s></p><p xml:id="_7TgsNEK"><s xml:id="_M7uSWDQ">Social determinants of health: Factors such as income, education, and living conditions can influence health outcomes and need to be adequately represented in datasets <ref type="bibr" target="#b2">(2,</ref><ref type="bibr" target="#b11">11)</ref>.</s></p><p xml:id="_SgsMDAe"><s xml:id="_TGm2A7n">• Physical environment: Geographic and environmental factors (eg, urban vs rural settings) can affect health outcomes and must be considered to avoid biased AI predictions <ref type="bibr" target="#b2">(2,</ref><ref type="bibr" target="#b11">11)</ref>.</s></p><p xml:id="_XTS2yPE"><s xml:id="_bsUTkDC">• Integration of environmental factors: Ensuring that environmental variables are incorporated into AI models can help in understanding and mitigating health disparities.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_8g3fETR">•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XnvDaDq">Empathy bias</head><p xml:id="_SJYb936"><s xml:id="_u3HpRqZ">Empathy bias refers to the challenge of incorporating human experiences and subjective elements that are difficult to quantify into AI systems <ref type="bibr" target="#b14">(14)</ref>.</s><s xml:id="_GMFcZJJ">This bias includes:</s></p><p xml:id="_tNaqnPa"><s xml:id="_tCVFmyp">Quantitative versus qualitative data: AI systems primarily rely on quantitative data, which can miss nuanced human experiences that affect health outcomes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_pdUsmPK">•</head><p xml:id="_msW8FQT"><s xml:id="_EPDYv3S">Patient preferences: Empathy bias can occur when AI systems do not consider patient preferences, values, and unique circumstances, leading to recommendations that are misaligned with patient needs <ref type="bibr" target="#b14">(14)</ref>.</s></p><p xml:id="_GxPSpSC"><s xml:id="_SE6qA6z">• Human stories: Integrating personal stories and experiences into AI models can enhance their relevance and fairness, although this factor presents a complex challenge.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MrQZqA4">•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_N5J3KMr">Evidence bias</head><p xml:id="_qRjvceq"><s xml:id="_ucSRaQF">Evidence bias involves the processes through which scientific evidence is generated, disseminated, and translated into practice <ref type="bibr" target="#b14">(14)</ref>.</s><s xml:id="_69CM6rR">This bias can affect the overall reliability and applicability of AI systems.</s><s xml:id="_bg7aTK2">Examples include: Translation to practice: The way evidence is translated into clinical guidelines and policies can introduce biases if it does not consider the diversity of patient populations and contexts.</s></p><p xml:id="_3J4Uk7T"><s xml:id="_fhfx8J5">• AI is not a monolithic entity; rather, it comprises various interconnected technologies and data inputs of intricate stacks playing a distinct role, contributing to the overall functionality, outputs, and intelligence of the system.</s><s xml:id="_eBdqxrb">To enhance clarity and understanding about sources of biases, it is beneficial to conceptualize the stack of interconnected technologies and inputs (Table ).</s><s xml:id="_We9CxNC">Biases that occur during the development of AI tools or models were mapped to specific points in the stack, to identify their origins and implement targeted strategies to address them (Table ).</s></p><p xml:id="_8ED6fMG"><s xml:id="_6yWVJmU">To mitigate the risk of bias and promote health equity in AI, several strategic actions are recommended.</s><s xml:id="_2aXUfDz">These actions include collecting data from diverse population groups to ensure AI systems are well-informed and represent the variability in human health; developing AI with explainable outcomes to allow users to understand and trust decisions and ensure accountability in AI-driven processes; continuously monitoring AI systems for biased outcomes; and adjusting algorithms accordingly to ensure they remain equitable over time.</s><s xml:id="_vbJFMBm">Specific proposed strategies for addressing bias follow.</s><s xml:id="_xKJ856s">• Inclusive guidelines: Develop clinical guidelines that are inclusive and consider the diverse patient populations and contexts in which they will be applied.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ZSmaez3">Addressing experience and expertise bias</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_VNEh2Cz">•</head><p xml:id="_X8XrQas"><s xml:id="_zxEANs3">These strategies illustrate that while biases in the development and deployment of AI present challenges to health equity, with careful planning and ethical consideration AI also offers substantial opportunities to enhance health care for all.</s><s xml:id="_8w2PBEG">By prioritizing equity in the design and implementation of AI, public health professionals and medical practitioners can use these powerful tools to not only improve health outcomes but also ensure these improvements are shared across all segments of the population.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_katbdcX">PREVENTING CHRONIC DISEASE</head><p xml:id="_URjf3TM"><s xml:id="_nFqj4Vz">VOLUME 21, E64 PUBLIC HEALTH RESEARCH, PRACTICE, AND POLICY AUGUST 2024</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cfgAFHX">Ethical Considerations in the Use of Artificial Intelligence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_G4s6H4K">Ethical frameworks</head><p xml:id="_cjgwte8"><s xml:id="_vGy5SKS">The deployment of AI in health necessitates adherence to established ethical frameworks designed to guide clinical practice and technological development <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref>.</s><s xml:id="_EKcr53k">These frameworks typically emphasize principles that must be carefully considered when integrating AI into health care settings <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref>.</s><s xml:id="_PtDb28w">Principles of beneficence and nonmaleficence ensure that AI technologies benefit patients and do not cause harm, whether through error, bias, or misuse <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref>.</s><s xml:id="_B4wVFtf">Another ethical AI principle is preserving patient autonomy by maintaining transparency and consent in AI interactions <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref>.</s><s xml:id="_XfUGNzj">Fairness and justice principles ensure that AI-driven tools do not create or exacerbate inequalities but rather promote equitable access to health care services <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_pNFaWBd">Privacy and confidentiality</head><p xml:id="_XZwf9Ch"><s xml:id="_BfEmX4y">With AI's ability to process vast amounts of personal data, safeguarding patient privacy and confidentiality becomes paramount <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref>.</s><s xml:id="_FZfmxMa">These safeguards involve several key concerns about data security, informed consent, and misuse of data.</s><s xml:id="_CkgEZ5f">It is critical to implement robust security measures to protect health data against unauthorized access and breaches <ref type="bibr" target="#b18">(18,</ref><ref type="bibr" target="#b19">19)</ref>.</s><s xml:id="_VNqa6S7">In addition, for populations with limited English proficiency, it is important to make sure informed consent forms are reviewed and explained to patients or translated.</s><s xml:id="_qeEQKgh">In this digital age, we can consider refining consent forms and including concise language for patients on how their data will be used in AI systems to inform their care.</s><s xml:id="_EM8FHMB">Finally, as part of ensuring privacy and confidentiality and limiting potential misuse, we should encourage collecting only data that are necessary for a specific AI application.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_TFhKj6b">Decision-making</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_JNC8uAe">AI's role in clinical decision-making, public health interventions, and population health management introduces complexities in the extent of human oversight and the transparency of AI decisions.</head><p xml:id="_b95VYKX"><s xml:id="_gYfrTyu">To ensure human oversight, we should establish guidelines for human oversight in AI-driven decisions, ensuring that machines augment rather than replace human judgment.</s><s xml:id="_wSCWE9n">To maintain trust and accountability, it is also important to develop AI systems whose actions can be understood and explained to practitioners and patients.</s><s xml:id="_RCgdgXT">Finally, determining how responsibilities and liabilities are shared among AI developers, health professionals, and institutions when AI is used in patient care is a complex and critical component of integrating AI into health care systems.</s><s xml:id="_7ASyp3j">This component involves understanding the roles and obligations of each partner to ensure patient safety, legal compliance, and ethical standards are upheld.</s><s xml:id="_WGt5nqm">Developers are responsible for creating accurate, reliable, and safe AI tools.</s><s xml:id="_9WXmdhv">Health care providers using AI tools must be adequately trained and responsible for interpreting AI outputs correctly, making final clinical decisions based on a combination of AI insights, patient values, and their professional judgment.</s><s xml:id="_EuGU5eW">Public health professionals must be guided by the principles of responsibility and ethics to enhance the ability to analyze data, predict health trends, and implement effective interventions to ensure the well-being of individuals and communities.</s><s xml:id="_AQQr3dP">Institutions need to establish policies and provide oversight to monitor AI performance, ensuring compliance with legal and ethical standards.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rCF8JB8">Community engagement</head><p xml:id="_K2jtvZr"><s xml:id="_eWPePBX">Involving diverse communities in the AI development lifecycle is essential for its ethical application in public health and medicine.</s><s xml:id="_aARFjWs">This approach ensures that AI systems are developed with a comprehensive understanding of the unique needs and challenges faced by various populations.</s><s xml:id="_rr6bKnd">Benefits of community engagement include enhanced relevance of the AI system to address the actual needs and preferences of the population, leading to better outcomes, and an increased trust and acceptance, with likelihood of successful implementation of the AI system (20).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_sHvap7z">Challenges and Opportunities</head><p xml:id="_hXtdvUB"><s xml:id="_3PGdmQt">The ethical integration of AI in health care and public health presents both challenges and opportunities.</s><s xml:id="_jzqCXnV">For example, AI can potentially streamline workflows and enhance diagnostic accuracy, but it also raises issues such as the potential for dehumanization in care and reduced patient-provider interactions <ref type="bibr" target="#b17">(17)</ref>.</s><s xml:id="_gjmJTs3">By addressing these ethical considerations proactively, working partners in public health and medicine can leverage AI to improve population health and health care outcomes while maintaining a commitment to ethical practice.</s><s xml:id="_5AtzMWW">As we delve into the transformative potential of AI in public health and medicine, it becomes increasingly apparent that while AI offers substantial benefits for health care efficiency and effectiveness, it also introduces substantial ethical and equity challenges.</s></p><p xml:id="_4DdxrBM"><s xml:id="_z484xAj">To promote health equity and ethical AI use in public health and medicine, it is recommended to develop inclusive AI policies, enhance ethical frameworks, and ensure transparency and accountability <ref type="bibr">(Figure)</ref>.</s><s xml:id="_fXGmHR4">Investing in public and professional education about AI, fostering community engagement, and integrating social determinants of health into AI models are essential.</s><s xml:id="_s2ERGJa">Additionally, diverse funding for research and evidence, continuous monitoring and evaluation of AI systems, and interdisciplinary collaboration are crucial strategies to ensure AI technologies are fair, equitable, and beneficial for all populations <ref type="bibr">(Figure)</ref>.</s><s xml:id="_wAyaKCb">To advance public health and medicine responsibly, it is also imperative that partners work collaboratively to ensure that AI technologies not only meet the highest standards of innovation but also adhere to ethical and equitable practices.</s><s xml:id="_fWbXveN">By implementing these recommendations, health care and public health professionals can leverage AI to enhance health care outcomes while safeguarding against potential inequalities and ethical transgressions.</s></p><p xml:id="_H2qhNUb"><s xml:id="_ddcqyQX">This comprehensive approach ensures that AI serves as a tool for positive change, propelling public health and medicine into a future where technology and human values are aligned to promote the well-being of all individuals.</s></p><p xml:id="_Mv7vjqQ"><s xml:id="_RnpNefT">Centers for Disease Control and Prevention • <ref type="url" target="www.cdc.gov/pcd/issues/2024/24_0245.htm">www.cdc.gov/pcd/issues/2024/24_0245.htm</ref></s><s xml:id="_h7kbput">Table Table.</s><s xml:id="_DhQ3Gmn">Outline for Understanding Artificial Intelligence (AI) as a Stack of Interconnected Technologies and Where Biases Can Occur During the Development of AI Tools Interconnected stack of AI technologies Points where biases can occur Reference Data and evidence generation • Experience and expertise bias • Exclusion bias • Environment bias • Empathy bias • Evidence bias Dankwa-Mullan and Weeraratne (14) Model development Data collection: gathering raw data from various sources (eg, sensors, user inputs, patient-reported outcomes, electronic health records and administrative claims databases, community health-related and social surveys, public health surveys, clinical trials, research data) • Data sampling bias: Occurs when the data collected are not representative of the population of focus, leading to skewed insights.</s><s xml:id="_H9erg6Z">• Historical bias: Biases present in historical data can be perpetuated.</s><s xml:id="_QFX4REr">For example, if past hiring practices favored certain demographic characteristics, a model trained on this data might continue to favor these characteristics.</s><s xml:id="_f48gH8H">Roski et al (2); Nazer et al (11) Data preparation and preprocessing: cleaning, transforming, and structuring data for analysis • Data cleaning bias: Bias can be introduced during the data cleaning process if certain data points are disproportionately removed or altered.</s><s xml:id="_NAsp34y">For example, removing outliers might inadvertently exclude data on minority groups.</s><s xml:id="_jPVZGMf">• Feature selection bias: Occurs when choosing features that reflect existing prejudices or systemic biases.</s><s xml:id="_Sxuvr75">For example, using zip code as a feature in credit scoring might unintentionally introduce racial and/or socioeconomic bias.</s><s xml:id="_sgK2ksj">Roski et al (2); Nazer et al (11) Feature engineering: Creating relevant features from raw data to improve model performance • Human bias in feature selection: The selection and creation of features can reflect the biases of the individuals involved in the process.</s><s xml:id="_rqWBCuB">For example, selecting features that favor certain groups over others: frequency of health care visits or access to specialists care can favor people with better access, and variables that measure engagement with digital health tools can favor younger or more techsavvy populations.</s><s xml:id="_uXEkNmU">• Overfitting specific biases: Creating features that overfit the training data might capture and reinforce biases present in that data.</s><s xml:id="_TBz2qYs">Chen et al (16) Model selection: Choosing the appropriate algorithms and models for the task • Algorithmic bias: Some algorithms might inherently favor certain patterns or demographic groups, which may lead to algorithmic bias.</s><s xml:id="_mgWTV9j">For example, decision trees might create splits that disproportionately affect certain demographics.</s><s xml:id="_vDsgb9x">• Inherent biases in model architecture: Certain model architectures may have biases based on their design.</s><s xml:id="_JNeBdJR">For example, linear models might fail to capture complex patterns in data related to underrepresented groups.</s><s xml:id="_8WG26J5">Roski et al (2); Nazer et al (11) Model training: Training the model using prepared data • Training data bias: Bias in the training data can lead to biased model outcomes.</s><s xml:id="_uTkrkJd">For example, if the training data contains biased labels, the model will learn and reproduce those biases.</s><s xml:id="_qX7qjrc">• Overfitting and underfitting: Overfitting to biased training data can exacerbate biases (by tailoring the model too closely to the training data), while underfitting might fail to capture important nuances, leading to a lack of fairness.</s><s xml:id="_DR7CtRF">Roski et al (2); Yang et al (15) Model evaluation and validation: Using metrics and validation techniques to assess the model's performance • Validation set bias: Bias in the evaluation process can arise if the validation set is not representative or if biased metrics are used to assess performance.</s><s xml:id="_WyYxphX">In other words, if the validation set is not representative, it can lead to misleading performance metrics.</s><s xml:id="_kh7bHtT">For example, evaluating a model on a biased subset might indicate good performance while hiding biases.</s><s xml:id="_E3BBWFn">• Metric selection bias: This bias results from choosing evaluation metrics that do not capture fairness aspects.</s><s xml:id="_WwBP6dQ">For example, using accuracy alone might ignore disparities in model performance across different groups.</s><s xml:id="_5K2stzd">Roski et al (2) Model deployment: Integrating the trained model into production environments • Deployment context bias: The deployment context can introduce bias if the model is used in a different environment than it was trained for, affecting its performance and fairness.</s><s xml:id="_5AMCbss">The environment Ferrara (17) (continued on next page) PREVENTING CHRONIC DISEASE VOLUME 21, E64 PUBLIC HEALTH RESEARCH, PRACTICE, AND POLICY AUGUST 2024 (continued) Table.</s><s xml:id="_q5JKkQc">Outline for Understanding Artificial Intelligence (AI) as a Stack of Interconnected Technologies and Where Biases Can Occur During the Development of AI Tools Interconnected stack of AI technologies Points where biases can occur Reference in which the model is deployed might differ from the training environment, introducing bias.</s><s xml:id="_Rfbk6Bt">For example, a model trained in one geographical area might not perform well in another.</s><s xml:id="_BdUeBsJ">• Real-world feedback loop bias: As the model interacts with the real world, it might receive biased feedback, reinforcing existing biases.</s><s xml:id="_A64Ubuz">For example, a recommendation system might continue to favor popular items, ignoring niche interests.</s><s xml:id="_br9mRXF">Monitoring and maintenance: Continuously monitoring model performance and making updates • Drift in data distribution: As models are used over time, changes in data distributions can introduce new biases, and feedback loops can reinforce existing biases.</s><s xml:id="_zW8KbFk">Over time, the data distribution might change, leading to biases if the model is not updated.</s><s xml:id="_Mq4nbPW">For example, shifts in consumer behavior can render an e-commerce model biased if it remains static.</s><s xml:id="_FCbHJqE">• Ongoing feedback bias: Continuous feedback loops can reinforce existing biases.</s><s xml:id="_EwwJbVE">For example, if a model's recommendations are followed by users, the resulting data might further entrench those recommendations.</s><s xml:id="_DnR2UFp">Roski et al (2); Ferrara (17) PREVENTING CHRONIC DISEASE VOLUME 21, E64 PUBLIC HEALTH RESEARCH, PRACTICE, AND POLICY AUGUST 2024 The opinions expressed by authors contributing to this journal do not necessarily reflect the opinions of the U.S. Department of Health and Human Services, the Public Health Service, the Centers for Disease Control and Prevention, or the authors' affiliated institutions.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc><div><p xml:id="_u5ann9f"><s xml:id="_aSCXM28">Research funding: How research is funded can introduce biases, as funding priorities may not align with the needs of all populations.</s><s xml:id="_P3TmgJm">• Publication bias: There is often a bias toward publishing positive results, • PREVENTING CHRONIC DISEASE VOLUME 21, E64 PUBLIC HEALTH RESEARCH, PRACTICE, AND POLICY AUGUST 2024 which can skew the evidence base that AI systems rely on.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc><div><p xml:id="_p2FMCdT"><s xml:id="_P9rAA4D">Diverse expert teams: Assemble multidisciplinary teams with diverse expertise, including data scientists, clinicians, ethicists, and social scientists, to inform, develop, and evaluate AI systems.•Continuous</s><s xml:id="_ucyfMwE">training: Provide ongoing education and training for health care providers on AI technologies to ensure they are proficient in using and interpreting AI tools.•Standardized</s><s xml:id="_78ps6C9">protocols: Develop and adhere to standardized protocols for data collection, labeling, and algorithm development to minimize variability due to different levels of expertise.•Addressing</s><s xml:id="_5MTaCWf">exclusion biasInclusive data collection: Ensure datasets include diverse demographic groups by actively recruiting underrepresented populations in data collection efforts.•</s><s xml:id="_wEDZxcY">Equity audits: Conduct regular equity audits of AI systems to identify and address any exclusion of populations.•</s><s xml:id="_tD7XCg9">Accessible AI solutions: Design AI tools with accessibility in mind, ensuring that they cater to the needs of socially and economically marginalized populations and do not perpetuate existing barriers to care.•Addressing environment biasIntegration of social determinants: Include social determinants of health (eg, income, education, housing) in AI models to provide a more holistic understanding of health outcomes.•</s><s xml:id="_qA5HtEZ">Geospatial analysis: Use geospatial analysis to incorporate environmental factors such as air quality, water access, and neighborhood characteristics into health data.•</s><s xml:id="_6F7ENqP">Contextual adaptation: Adapt AI models to local contexts, ensuring that they account for regional variations in social and environmental factors that affect health.•Addressing</s><s xml:id="_c9DByAn">empathy biasIncorporation of qualitative data: Combine quantitative data with qualitative insights from patient interviews, focus groups, and patient narratives to capture a full picture of health experiences.</s><s xml:id="_SN4nC36">• Patient-centered design: Engage patients in the design and development of AI systems to ensure that their preferences, values, and experiences are reflected in the models.</s><s xml:id="_tXjstC2">• Ethical review boards: Establish ethical review boards that include patient representatives to oversee the development and deployment of AI tools, ensuring they align with patient needs and ethical standards.</s><s xml:id="_C4r8p2Y">• Addressing evidence bias Diversification of funding: Advocate for diverse funding sources to support research that addresses the health needs of varied populations, avoiding biases introduced by funding priorities.</s><s xml:id="_ppXqAnF">• Transparent reporting: Encourage transparent reporting of all research findings, including negative results, to build a comprehensive and unbiased evidence base.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><figDesc><div><p xml:id="_CkTeJEt"><s xml:id="_5HDj6H9">opinions expressed by authors contributing to this journal do not necessarily reflect the opinions of the U.S. Department of Health and Human Services, the Public Health Service, the Centers for Disease Control and Prevention, or the authors' affiliated institutions.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure .</head><label>.</label><figDesc><div><p xml:id="_nFmGY55"><s xml:id="_zuGrxse">Figure.</s><s xml:id="_vjpx58T">Multifaceted approach for ethical and equitable implementation of artificial intelligence (AI) in public health and medicine.</s></p></div></figDesc><graphic coords="6,32.00,102.00,264.00,208.56" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_AjQfXy8"><s xml:id="_e2TvqWD">The opinions expressed by authors contributing to this journal do not necessarily reflect the opinions of the U.S. Department of Health and Human Services, the Public Health Service, the Centers for Disease Control and Prevention, or the authors' affiliated institutions.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_z4DNffY"><s xml:id="_akSDsHy">The opinions expressed by authors contributing to this journal do not necessarily reflect the opinions of the U.S. Department of Health and Human Services, the Public Health Service, the Centers for Disease Control and Prevention, or the authors' affiliated institutions.</s><s xml:id="_qZeFWKj">www.cdc.gov/pcd/issues/2024/24_0245.htm</s><s xml:id="_K8GWg7C">• Centers for Disease Control and Prevention</s></p></note>
		</body>
		<back>


			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_PwEV4Hb">Acknowledgments</head><p xml:id="_CRNYfG2"><s xml:id="_sw8Ufps">The author received no external financial support for the research, authorship or publication of this article.</s><s xml:id="_UgFwdFf">The author declares no potential conflicts of interest with respect to the research, authorship or publication of this article.</s><s xml:id="_JFadEdn">No copyrighted material, surveys, instruments, or tools were used in the research described in this article.</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_qHD8uQC">Author Information</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_yv5Vwkc">Revolutionizing healthcare: the role of artificial intelligence in clinical practice</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Alowais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Alghamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Alsuhebany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Alqahtani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Alshaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Almohareb</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12909-023-04698-z</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nF6mVxR">BMC Med Educ</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">689</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alowais SA, Alghamdi SS, Alsuhebany N, Alqahtani T, Alshaya AI, Almohareb SN, et al. Revolutionizing healthcare: the role of artificial intelligence in clinical practice. BMC Med Educ. 2023;23(1):689. doi:10.1186/s12909-023-04698-z</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main" xml:id="_TYRbR9h">Artificial Intelligence in Health Care: The Hope, the Hype, the Promise, the Peril</title>
		<author>
			<persName><forename type="first">J</forename><surname>Roski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Del</forename><surname>Fiol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kukafka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno type="DOI">10.17226/27111</idno>
		<editor>Matheny M, Israni ST, Ahmed M, Whicher D</editor>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>The National Academies Press</publisher>
			<biblScope unit="page" from="65" to="98" />
		</imprint>
	</monogr>
	<note>Chapter 3: How artificial intelligence is changing health and health care</note>
	<note type="raw_reference">Roski J, Chapman W, Heffner J, Trivedi R, Del Fiol G, Kukafka R, et al. Chapter 3: How artificial intelligence is changing health and health care. In: Matheny M, Israni ST, Ahmed M, Whicher D, eds. Artificial Intelligence in Health Care: The Hope, the Hype, the Promise, the Peril. The National Academies Press; 2019:65-98. doi:10.17226/27111</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_dy56gfd">AI in health and medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-021-01614-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UPNbFWc">Nat Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="38" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajpurkar P, Chen E, Banerjee O, Topol EJ. AI in health and medicine. Nat Med. 2022;28(1):31-38. doi:10.1038/s41591- 021-01614-0</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_SzjHVRG">Artificial intelligence-enabled public health surveillance -from local detection to global epidemic monitoring and control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Neill</surname></persName>
		</author>
		<idno type="DOI">10.1016/b978-0-12-821259-2.00022-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zXewBnA">Artif Intell Med</title>
		<imprint>
			<biblScope unit="page" from="437" to="453" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zeng D, Cao Z, Neill DB. Artificial intelligence-enabled public health surveillance -from local detection to global epidemic monitoring and control. Artif Intell Med. 2021: 437-453. doi:10.1016/B978-0-12-821259-2.00022-3</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_9vv9VpC">Implementation of artificial intelligencebased clinical decision support to reduce hospital readmissions at a regional hospital</title>
		<author>
			<persName><forename type="first">S</forename><surname>Romero-Brufau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Boyum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mickelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cognetta-Rieke</surname></persName>
		</author>
		<idno type="DOI">10.1055/s-0040-1715827</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rmnnvn5">Appl Clin Inform</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="570" to="577" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Romero-Brufau S, Wyatt KD, Boyum P, Mickelson M, Moore M, Cognetta-Rieke C. Implementation of artificial intelligence- based clinical decision support to reduce hospital readmissions at a regional hospital. Appl Clin Inform. 2020;11(4):570-577. doi:10.1055/s-0040-1715827</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_zv7SmjN">An augmented artificial intelligence approach for chronic diseases prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Batool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wasif</forename><surname>Nisar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Juneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<idno type="DOI">10.3389/fpubh.2022.860396</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Kfkrtvt">Front Public Health</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">860396</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rashid J, Batool S, Kim J, Wasif Nisar M, Hussain A, Juneja S, et al. An augmented artificial intelligence approach for chronic diseases prediction. Front Public Health. 2022;10: 860396. doi:10.3389/fpubh.2022.860396</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_Cw4RNv6">Precision medicine, AI, and the future of personalized health care</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weeraratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Frisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Misulis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rhee</surname></persName>
		</author>
		<idno type="DOI">10.1111/cts.12884</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nmSkHHz">Clin Transl Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="93" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson KB, Wei WQ, Weeraratne D, Frisse ME, Misulis K, Rhee K, et al. Precision medicine, AI, and the future of personalized health care. Clin Transl Sci. 2021;14(1):86-93. doi:10.1111/cts.12884</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_3MZsHy2">Equity within AI systems: what can health leaders expect?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gurevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">El</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename></persName>
		</author>
		<author>
			<persName><forename type="first">El</forename><surname>Morr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<idno type="DOI">10.1177/08404704221125368</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vh8ATWu">Healthc Manage Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="124" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gurevich E, El Hassan B, El Morr C. Equity within AI systems: what can health leaders expect? Healthc Manage Forum. 2023;36(2):119-124. doi:10.1177/ 08404704221125368</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_Ex5Tq88">Defining equity in health</title>
		<author>
			<persName><forename type="first">P</forename><surname>Braveman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gruskin</surname></persName>
		</author>
		<idno type="DOI">10.1136/jech.57.4.254</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Dx2DjBd">J Epidemiol Community Health</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="254" to="258" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Braveman P, Gruskin S. Defining equity in health. J Epidemiol Community Health. 2003;57(4):254-258. doi:10.1136/jech.57. 4.254</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main" xml:id="_mEhv3xX">Special Publication 1270: Towards a Standard for Identifying and Managing Bias in Artificial Intelligence</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vassilev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Perine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hall</surname></persName>
		</author>
		<idno type="DOI">10.6028/nist.sp.1270</idno>
		<ptr target="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf" />
		<imprint>
			<date type="published" when="2022-03">March 2022. May 29, 2024</date>
		</imprint>
		<respStmt>
			<orgName>National Institutes of Standards and Technology</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Schwartz R, Vassilev A, Greene K, Perine L, Burt A, Hall P. Special Publication 1270: Towards a Standard for Identifying and Managing Bias in Artificial Intelligence. National Institutes of Standards and Technology. March 2022. Accessed May 29, 2024. https://nvlpubs.nist.gov/nistpubs/ SpecialPublications/NIST.SP.1270.pdf</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_7gdpxMA">Bias in artificial intelligence algorithms and recommendations for mitigation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Nazer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zatarah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Waldrip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jxc</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moukheiber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Khanna</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000278</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NqEJWen">PLOS Digit Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">278</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nazer LH, Zatarah R, Waldrip S, Ke JXC, Moukheiber M, Khanna AK, et al. Bias in artificial intelligence algorithms and recommendations for mitigation. PLOS Digit Health. 2023; 2(6):e0000278. doi:10.1371/journal.pdig.0000278</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_VghneNM">Dissecting racial bias in an algorithm used to manage the health of populations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vogeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aax2342</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_h8uZd3g">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="issue">6464</biblScope>
			<biblScope unit="page" from="447" to="453" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Obermeyer Z, Powers B, Vogeli C, Mullainathan S. Dissecting racial bias in an algorithm used to manage the health of populations. Science. 2019;366(6464):447-453. doi:10.1126/ science.aax2342</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_KrjRca8">Do all AI systems need to be explainable?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mann</surname></persName>
		</author>
		<ptr target="https://ssir.org/articles/entry/do_ai_systems_need_to_be_explainable" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_BjjWBnz">Stanford Social Innovation Review</title>
		<imprint>
			<date type="published" when="2023-11-15">November 15, 2023. July 10, 2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mann H. Do all AI systems need to be explainable?. Stanford Social Innovation Review. November 15, 2023. Accessed July 10, 2024. https://ssir.org/articles/entry/do_ai_systems_need_ to_be_explainable</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_JD7CysT">Artificial intelligence and machine learning technologies in cancer care: addressing disparities, bias, and data diversity</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dankwa-Mullan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weeraratne</surname></persName>
		</author>
		<idno type="DOI">10.1158/2159-8290.cd-22-0373</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vGGreGj">Cancer Discov</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1423" to="1427" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dankwa-Mullan I, Weeraratne D. Artificial intelligence and machine learning technologies in cancer care: addressing disparities, bias, and data diversity. Cancer Discov. 2022; 12(6):1423-1427. doi:10.1158/2159-8290.CD-22-0373</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_kqUJGUs">An adversarial training framework for mitigating algorithmic biases in clinical machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aas</forename><surname>Soltan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Eyre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clifton</forename><forename type="middle">Da</forename></persName>
		</author>
		<idno type="DOI">10.1038/s41746-023-00805-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5QtcxpH">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang J, Soltan AAS, Eyre DW, Yang Y, Clifton DA. An adversarial training framework for mitigating algorithmic biases in clinical machine learning. NPJ Digit Med. 2023;6(1): 55. doi:10.1038/s41746-023-00805-y</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_g7hcZvu">Humancentered design to address biases in artificial intelligence</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Malin</surname></persName>
		</author>
		<idno type="DOI">10.2196/43251</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yPhVVjp">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">43251</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen Y, Clayton EW, Novak LL, Anders S, Malin B. Human- centered design to address biases in artificial intelligence. J Med Internet Res. 2023;25:e43251. doi:10.2196/43251</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_nhs7tjK">Fairness and bias in artificial intelligence: a brief survey of sources, impacts, and mitigation strategies</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrara</surname></persName>
		</author>
		<idno type="DOI">10.3390/sci6010003</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rTQt6Pe">Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ferrara E. Fairness and bias in artificial intelligence: a brief survey of sources, impacts, and mitigation strategies. Sci. 2024;6(1):3. doi:10.3390/sci6010003</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_2rwTEhZ">Ethical and regulatory challenges of AI technologies in healthcare: a narrative review</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mennella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Maniscalco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Pietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.heliyon.2024.e26297</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mMP4V6G">Heliyon</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">26297</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mennella C, Maniscalco U, De Pietro G, Esposito M. Ethical and regulatory challenges of AI technologies in healthcare: a narrative review. Heliyon. 2024;10(4):e26297. doi:10.1016/j. heliyon.2024.e26297</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_tSFuqS2">A proposed framework on integrating health equity and racial justice into the artificial intelligence development lifecycle</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dankwa-Mullan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Scheufele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matheny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Quintana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jackson</surname></persName>
		</author>
		<idno type="DOI">10.1353/hpu.2021.0065</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_G5pq7KQ">J Health Care Poor Underserved</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="300" to="317" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dankwa-Mullan I, Scheufele EL, Matheny M, Quintana Y, Chapman W, Jackson G, et al. A proposed framework on integrating health equity and racial justice into the artificial intelligence development lifecycle. J Health Care Poor Underserved. 2021;32(2):300-317. doi:10.1353/hpu.2021. 0065</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_qzhwDaj">Intersection of health informatics tools and community engagement in healthrelated research to reduce health inequities: scoping review</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rajamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rodriguez</forename><surname>Espinosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename></persName>
		</author>
		<idno type="DOI">10.2196/30062</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cUdq3AV">J Particip Med</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">30062</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajamani G, Rodriguez Espinosa P, Rosas LG. Intersection of health informatics tools and community engagement in health- related research to reduce health inequities: scoping review. J Particip Med. 2021;13(3):e30062. doi:10.2196/30062 20</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<idno type="DOI">10.5888/pcd21.230277e</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Pvy8YJ3">PREVENTING CHRONIC DISEASE</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">64</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">PREVENTING CHRONIC DISEASE VOLUME 21, E64</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">PUBLIC HEALTH RESEARCH ; PRACTICE</orgName>
		</author>
		<idno type="DOI">10.1016/b978-0-323-95356-6.00003-3</idno>
		<imprint>
			<date type="published" when="2024">AUGUST 2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">PUBLIC HEALTH RESEARCH, PRACTICE, AND POLICY AUGUST 2024</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
