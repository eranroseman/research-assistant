<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_VkrSCKY">Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine</title>
				<funder ref="#_RjZDMhK">
					<orgName type="full">Stanford Artificial Intelligence in Medicine and Imaging-</orgName>
				</funder>
				<funder ref="#_qKeCvx9">
					<orgName type="full">NIH-NCATS-CTSA</orgName>
				</funder>
				<funder ref="#_nw7YV94">
					<orgName type="full">NIH/National Institute of Allergy and Infectious Diseases</orgName>
				</funder>
				<funder>
					<orgName type="full">VA Advanced Fellowship in Medical Informatics</orgName>
				</funder>
				<funder>
					<orgName type="full">Google Inc</orgName>
				</funder>
				<funder ref="#_ATGuWhD">
					<orgName type="full">Gordon and Betty Moore Foundation</orgName>
					<orgName type="abbreviated">GBMF</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000936</idno>
				</funder>
				<funder ref="#_sYVHUsv">
					<orgName type="full">American Heart Association</orgName>
					<orgName type="abbreviated">AHA</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000968</idno>
				</funder>
				<funder ref="#_bBdyMh9">
					<orgName type="full">NIH/National Institute on Drug Abuse Clinical Trials Network</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Thomas</forename><surname>Savage</surname></persName>
							<email>tsavage@stanford.edu</email>
							<idno type="ORCID">0000-0003-4828-5802</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Medicine , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Division of Hospital Medicine , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Division of Hospital Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ashwin</forename><surname>Nayak</surname></persName>
							<idno type="ORCID">0009-0003-2024-3683</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Medicine , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Division of Hospital Medicine , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Division of Hospital Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Gallo</surname></persName>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Palo Alto Veterans Affairs Medical Center , Palo Alto , CA , USA.</note>
								<orgName type="institution">Palo Alto Veterans Affairs Medical Center</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Department of Health Policy , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Department of Health Policy</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ekanath</forename><surname>Rangan</surname></persName>
							<idno type="ORCID">0000-0001-5168-3508</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Medicine , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
							<idno type="ORCID">0000-0002-4387-8740</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Medicine , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Division of Hospital Medicine , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Division of Hospital Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Stanford Center for Biomedical Informatics Research , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Stanford Center for Biomedical Informatics Research</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Clinical Excellence Research Center , Stanford University , Stanford , CA , USA.</note>
								<orgName type="department">Clinical Excellence Research Center</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_bMCshNS">Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FA062DCA3078AF7EA37BBC56365B96F2</idno>
					<idno type="DOI">10.1038/s41746-024-01010-1</idno>
					<note type="submission">Received: 14 August 2023; Accepted: 10 January 2024;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T13:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_T6EP8Vr"><p xml:id="_8n2f3K4"><s xml:id="_CwU2s2J">One of the major barriers to using large language models (LLMs) in medicine is the perception they use uninterpretable methods to make clinical decisions that are inherently different from the cognitive processes of clinicians.</s><s xml:id="_f9ccdCt">In this manuscript we develop diagnostic reasoning prompts to study whether LLMs can imitate clinical reasoning while accurately forming a diagnosis.</s><s xml:id="_q39z8hv">We find that GPT-4 can be prompted to mimic the common clinical reasoning processes of clinicians without sacrificing diagnostic accuracy.</s><s xml:id="_d7647ks">This is significant because an LLM that can imitate clinical reasoning to provide an interpretable rationale offers physicians a means to evaluate whether an LLMs response is likely correct and can be trusted for patient care.</s><s xml:id="_u5Nz3fV">Prompting methods that use diagnostic reasoning have the potential to mitigate the "black box" limitations of LLMs, bringing them one step closer to safe and effective use in medicine.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_3jHhds4">INTRODUCTION</head><p xml:id="_sEtRNmU"><s xml:id="_VK99jGf">Large language models (LLMs) are artificial intelligence systems trained on large amounts of text data that learn complex language patterns and syntactical relationships to both interpret passages and generate text output <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2</ref> LLMs have received widespread attention for their human-like performance on a wide variety of text-generating tasks.</s><s xml:id="_DXEaAXW">Within medicine, initial efforts have demonstrated that LLMs can write clinical notes <ref type="bibr" target="#b2">3</ref> , pass standardized medical exams <ref type="bibr" target="#b3">4</ref> , and draft responses to patient questions <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6</ref> .</s><s xml:id="_VpVMxE5">In order to integrate LLMs more directly into clinical care, it is imperative to better understand their clinical reasoning capabilities.</s></p><p xml:id="_zFjT97V"><s xml:id="_Uyn5DcV">Clinical reasoning is a set of problem-solving processes specifically designed for diagnosis and management of a patient's medical condition.</s><s xml:id="_tSUQen9">Commonly used diagnostic techniques include differential diagnosis formation, intuitive reasoning, analytical reasoning, and Bayesian inference.</s><s xml:id="_GgxFGqJ">Early assessments of the clinical reasoning abilities of LLMs have been limited, studying model responses to multiple-choice questions <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref> .</s><s xml:id="_PA5Z9qr">More recent work has focused on free-response clinical questions and suggests that newer LLMs, such as GPT-4, show promise in diagnosis of challenging clinical cases <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13</ref> .</s></p><p xml:id="_gXfsY6U"><s xml:id="_xZa2jrF">Prompt engineering is emerging as a discipline in response to the phenomena that LLMs can perform substantially differently depending on how questions and prompts are posed to them <ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15</ref> .</s><s xml:id="_GmpUQNR">Advanced prompting techniques have demonstrated improved performance on a range of tasks <ref type="bibr" target="#b15">16</ref> , while also providing insight into how LLMs came to a conclusion (as demonstrated by Wei et  al. and Lightman et al. in arithmetic reasoning, common sense reasoning, and symbolic reasoning) <ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18</ref> .</s><s xml:id="_ePPpsAx">A notable example is Chain-of-thought (CoT) prompting, which involves instructing the LLM to divide its task into smaller reasoning steps and then complete the task step-by-step <ref type="bibr" target="#b16">17</ref> .</s><s xml:id="_VMyBFvw">Given that clinical reasoning tasks regularly use step-by-step processes, CoT prompts modified to reflect the cognitive processes taught to and utilized by clinicians might elicit better understanding of LLM performance on clinical reasoning tasks.</s></p><p xml:id="_mUkrf5M"><s xml:id="_4dpYxbq">In this paper we evaluate the performance of GPT-3.5 and GPT-4 <ref type="bibr" target="#b18">19</ref> on open-ended clinical questions assessing diagnostic reasoning.</s><s xml:id="_eHath2j">Specifically, we evaluate LLM performance on a modified MedQA USMLE (United States Medical Licensing Exam) dataset <ref type="bibr" target="#b19">20</ref> , and further evaluate GPT-4 performance on the diagnostically difficult NEJM (New England Journal of Medicine) case series <ref type="bibr" target="#b20">21</ref> .</s><s xml:id="_gkFRQkx">We compare traditional CoT prompting with several "diagnostic reasoning" prompts that are modeled after the cognitive processes of differential diagnosis formation, intuitive reasoning, analytical reasoning, and Bayesian inference.</s><s xml:id="_WSsBw5G">This study assesses whether LLMs can imitate clinical reasoning abilities using specialized instructional prompts that combine clinical expertise and advanced prompting methods.</s><s xml:id="_6Z5Vmhc">We hypothesize GPT models will have superior performance with diagnostic reasoning prompts in comparison to traditional CoT prompting.</s></p><p xml:id="_GBTvBmk"><s xml:id="_wRqU94G">A modified version of the MedQA USMLE question dataset was used for this study.</s><s xml:id="_SFxfrwT">Questions were converted to free response by removing the multiple-choice options after the question stem.</s><s xml:id="_mpKP52h">Only Step 2 and Step 3 USMLE questions were included, as Step 1 questions focus heavily on memorization of facts rather than clinical reasoning skills <ref type="bibr" target="#b9">10</ref> .</s><s xml:id="_VhDRuA7">Only questions evaluating the task of diagnosing a patient were included to simplify prompt engineering.</s><s xml:id="_w3tmWzg">A training set of 95 questions was used for iterative prompt development and a test set of 518 questions was reserved for evaluation.</s><s xml:id="_2Sz7nFM">The full test set can be found in Supplementary Data 1.</s></p><p xml:id="_ee3ssC5"><s xml:id="_yhZKYjT">GPT-4 performance was also evaluated on the New England Journal of Medicine (NEJM) Case Records series.</s><s xml:id="_We3pRd9">The NEJM Case Records series is designed as an educational resource for physicians, with each case providing a clinical case description followed by expert analysis of the case with a clinical diagnosis.</s><s xml:id="_t9ffkDD">We included the 310 most recently published cases in this study.</s><s xml:id="_mMzwjTn">Ten cases were excluded because they either did not provide a definitive final diagnosis or exceeded the maximum context length of the GPT-4 API.</s><s xml:id="_WvkDbaz">A full list of all cases included (by title and DOI number) can be found in Supplementary Data 2. For this evaluation, we compared traditional CoT prompting to the highest performing clinical reasoning CoT prompt (differential diagnosis reasoning) on the modified MedQA dataset.</s></p><p xml:id="_DqZgd8s"><s xml:id="_dDNmcdj">One traditional CoT prompt and four clinical reasoning prompts were developed (differential diagnosis, analytical, Bayesian and intuitive reasoning).</s><s xml:id="_AccsfvX">Each prompt included two example questions (Table <ref type="table" target="#tab_0">1</ref>) with rationales employing the target reasoning strategy.</s><s xml:id="_CZtw9XE">This is a technique known as few-shot learning <ref type="bibr" target="#b13">14</ref> .</s><s xml:id="_cnxJNus">The full prompts used for the MedQA dataset are provided in Table <ref type="table" target="#tab_1">2</ref>; the full prompts used for the NEJM challenge set are provided in Supplementary Note 1.</s></p><p xml:id="_Kr7cXP2"><s xml:id="_jhJBn9M">Example LLM responses for each prompting strategy can be found in Fig. <ref type="figure">1</ref> for GPT-3.5 and Fig. <ref type="figure">2</ref> for GPT-4.</s><s xml:id="_pVDZteg">Full results can be found in Supplementary Data 1 and 2.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_J9CEtmg">RESULTS</head><p xml:id="_WYVbdGc"><s xml:id="_CVkzdT2">GPT-3.5 correctly answered 46% of questions using traditional CoT prompting, compared to 31% with zero-shot non-CoT prompting.</s><s xml:id="_AJTv8kE">Among the clinical reasoning prompts, GPT-3.5 achieved the highest performance with intuitive reasoning (48% vs. 46%, difference of +1.7%, CI -2.5% to +5.9%, p = 0.4).</s><s xml:id="_5DkCBQ6">Compared to traditional CoT, GPT-3.5's</s><s xml:id="_ambtB5t">performance was significantly worse with analytic reasoning (40%, difference of -6%, CI -11% to -1.5%, p = 0.001) and differential diagnosis formation (38%, difference of -8.9%, CI -14% to -3.4%, p = &lt;0.001),</s><s xml:id="_FfAQh2W">while Bayesian inference performance nearly missed our threshold for statistical significance (42%, difference of -4.4%, CI -9.1% to +0.2%, p = 0.02).</s><s xml:id="_gDQr63Y">Results can be referenced in Table <ref type="table" target="#tab_2">3</ref>. Inter-rater agreement for the MedQA GPT-3.5 evaluation was 97% with a Cohen's Kappa of 0.93.</s></p><p xml:id="_ASzP9aV"><s xml:id="_cS66e2U">The GPT-4 API generated an error for 20 questions of the test set, reducing the test set size to 498.</s><s xml:id="_eVUVEPj">Overall, GPT-4 demonstrated improved accuracy over GPT-3.5.</s><s xml:id="_pRW5rmK">GPT-4 achieved an accuracy of 76% with traditional CoT, 77% with intuitive reasoning (+0.8%,</s><s xml:id="_mFN55NP">CI -3.6% to +5.2%, p = 0.73), 78% with differential diagnosis (+2.2%, CI -2.3% to +6.7%, p = 0.24), 78% with analytic reasoning (+1.6%, CI -2.4% to +5.6%, p = 0.35), and 72% with Bayesian Inference (-3.4%, CI -9.1% to +1.2%, p = 0.07).</s><s xml:id="_m3AcyVY">Results can be found in Table <ref type="table" target="#tab_3">4</ref>. Inter-rater agreement for the GPT-4 MedQA evaluation was 99% with a Cohen's Kappa of 0.98.</s></p><p xml:id="_yZEhQuN"><s xml:id="_urwbPj5">On the NEJM challenge case set GPT-4 achieved an accuracy of 38% with traditional CoT compared to 34% with differential diagnosis CoT (difference of -4.2%, 95% CI -11.4% to +2.1%, p = 0.09, Table <ref type="table">5</ref>).</s><s xml:id="_bDQvXYb">Inter-rater agreement for the GPT-4 NEJM evaluation was 97% with a Cohen's Kappa of 0.93.</s><s xml:id="_njdZunQ">GPT-4 response and rationale results for the entire NEJM test set are included in Supplementary Data 2.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_n4aAhUf">DISCUSSION</head><p xml:id="_f9GES6u"><s xml:id="_r2u7aQG">In this study we found that GPT-3.5 performance was similar with traditional and intuitive reasoning CoT prompts, but significantly worse with differential diagnosis and analytical CoT prompts.</s><s xml:id="_b9NQ33J">Bayesian inference CoT also demonstrated worse performance than traditional CoT, but the decrease in performance did not meet our significance threshold.</s><s xml:id="_nGj2FNY">These findings suggest GPT-3.5 is not able to imitate advanced clinical reasoning processes to arrive at an accurate diagnosis.</s><s xml:id="_SmJ4cug">In contrast, GPT-4 demonstrated similar performance between traditional and diagnostic reasoning CoT prompts.</s><s xml:id="_mhjMzjg">While these findings highlight the significant advancement in reasoning abilities between GPT-3.5 and GPT-4, diagnostic reasoning does not increase GPT-4 accuracy like it would for a human provider.</s><s xml:id="_TbzRmec">We propose three possible explanations for this finding.</s><s xml:id="_ZZDWqgT">First, GPT-4's reasoning mechanisms could be inherently different than human providers and therefore does not derive benefit from diagnostic reasoning strategies.</s><s xml:id="_3pSYue4">Second, GPT-4 could be explaining its diagnostic evaluation post-hoc in the desired diagnostic reasoning format instead of strictly using the prompted diagnostic reasoning strategy.</s><s xml:id="_M3DMWRx">Third, GPT-4 could have reached a maximal accuracy with the vignette information provided and we are thus unable to detect an accuracy difference between prompting strategies.</s><s xml:id="_hgHM7cU">Regardless of the underlying reason, we observe GPT-4 has developed the ability to successfully imitate clinical reasoning thought processes but cannot apply clinical reasoning like a human.</s></p><p xml:id="_mNRnR4T"><s xml:id="_ddVHsT6">The finding that GPT-4 can successfully imitate the same cognitive processes as physicians to arrive accurately at an answer is still significant because of the potential for interpretability.</s><s xml:id="_M2u8wXp">We define interpretability as the property that allows a human operator to explore qualitative relationships between inputs and outputs <ref type="bibr" target="#b22">22</ref> .</s><s xml:id="_dUHUWy9">A model that generates a clinical reasoning rationale when suggesting a diagnosis offers the clinician an interpretable means to assess whether the answer is true or false based on the rationale's factual and logical accuracy.</s><s xml:id="_ZrvpZJ8">A workflow that aligns model outputs in this way (Fig. <ref type="figure" target="#fig_1">3</ref>) could mitigate the "black box" limitations of LLMs, as long as physicians recognize that language models will always be at risk of unpredictable reasoning hallucinations, and that rationale logical and factual accuracy still does not absolutely guarantee answer correctness.</s><s xml:id="_89WX6cp">Shortly after undergoing a bipolar prosthesis for a displaced femoral neck fracture of the left hip acquired after a fall the day before, an 80-year-old woman suddenly develops dyspnea.</s><s xml:id="_qx3yt63">The surgery under general anesthesia with sevoflurane was uneventful, lasting 98 min, during which the patient maintained oxygen saturation readings of 100% on 8 l of oxygen.</s><s xml:id="_5dUBpeH">She has a history of hypertension, osteoporosis, and osteoarthritis of her right knee.</s><s xml:id="_hDWsy9X">Her medications include ramipril, naproxen, ranitidine, and a multivitamin.</s><s xml:id="_KarKsJh">She appears cyanotic, drowsy, and is oriented only to person.</s><s xml:id="_9KuE6BA">Her temperature is 38.6 °C (101.5 °F), pulse is 135/min, respirations are 36/min, and blood pressure is 155/95 mm Hg.</s><s xml:id="_m4uDVsv">Pulse oximetry on room air shows an oxygen saturation of 81%.</s><s xml:id="_XWQmGu4">There are several scattered petechiae on the anterior chest wall.</s><s xml:id="_PhvWHus">Laboratory studies show a hemoglobin concentration of 10.5 g/dl, a leukocyte count of 9000/mm 3 , a platelet count of 145,000/mm 3 , and a creatine kinase of 190 U/l.</s><s xml:id="_PGJ5wEa">An ECG shows sinus tachycardia.</s><s xml:id="_GY42Ngt">What is the most likely diagnosis?</s><s xml:id="_6xCEz7R">Example Question 2 A 55-year-old man comes to the emergency department because of a dry cough and severe chest pain beginning that morning.</s><s xml:id="_zRkPAE4">Two months ago, he was diagnosed with inferior wall myocardial infarction and was treated with stent implantation of the right coronary artery.</s><s xml:id="_whVA2hj">He has a history of hypertension and hypercholesterolemia. His medications include aspirin, clopidogrel, atorvastatin, and enalapril.</s><s xml:id="_s8TFAhv">His temperature is 38.5Â°C (101.3 °F), pulse is 92/min, respirations are 22/min, and blood pressure is 130/80 mm Hg.</s><s xml:id="_kdGaXAw">Cardiac examination shows a high-pitched scratching sound best heard while sitting upright and during expiration.</s><s xml:id="_trH49pv">The remainder of the examination shows no abnormalities.</s><s xml:id="_8WXvHYY">An ECG shows diffuse ST elevations.</s><s xml:id="_Bf2akHU">Serum studies show a troponin I of 0.005 ng/ml (N &lt; 0.01).</s><s xml:id="_ZZQbnud">What is the most likely cause of this patient's symptoms?</s></p><p xml:id="_P7x59jk"><s xml:id="_JdQBfX6">Example questions used in all MEDQA prompts provided in Table <ref type="table" target="#tab_1">2</ref>.</s></p><p xml:id="_zp588cs"><s xml:id="_TrCD5uZ">To demonstrate how clinical reasoning prompts provide interpretability, we include descriptive MedQA examples (Supplementary Data 4).</s><s xml:id="_9GYTHaG">Incorrect model responses are often accompanied by rationales that provide factual inaccuracy, while logical rationales are more often associated with correct responses.</s><s xml:id="_KcqxD52">We further quantify this relationship by evaluating 100 GPT-4 diagnostic reasoning rationales, where we found incorrect answers were much more likely to have logic errors in their The prior probability of Dressler Syndrome is 0.01%.</s><s xml:id="_x2qJyuc">The patient has diffuse ST elevations, increasing the probability of Dressler Syndrome to 5%.</s><s xml:id="_6uzCEuc">The patient has a scratching murmur which increases the probability to 10%.</s><s xml:id="_DugGfCd">In the setting of a recent MI the posterior probability of myocardial infarction is 55%.</s><s xml:id="_y29UGjs">This patient likely has Dressler Syndrome.</s></p><p xml:id="_7wZQErr"><s xml:id="_pWZnrpX">The traditional and diagnostic CoT prompts evaluated in this study.</s><s xml:id="_d6ZT2a9">The provided rationales are in response to the example questions provided in Table <ref type="table" target="#tab_0">1</ref>.</s></p><p xml:id="_fC6myBm"><s xml:id="_YjFQGnq">Note that the full text of the example questions has been omitted for readability.</s></p><p xml:id="_pQXHEaS"><s xml:id="_mBQT8EG">rationale compared to correct answers.</s><s xml:id="_Buhmdet">In total, 65% of incorrect answers had false logic statements in their rationale, with an average of 0.82 inaccuracies per rationale.</s><s xml:id="_A9vqFXT">In contrast, only 18% of correct answers had false logic statements in their rationale, with an average of 0.11 per question (Supplementary Data 5).</s><s xml:id="_fpRYQDr">Our results suggest clinical reasoning rationales provide valuable insight (but not an absolute guarantee) into whether an LLM response can be trusted and represent a step toward LLM interpretability.</s></p><p xml:id="_rNZgrEt"><s xml:id="_MeVADwR">The strengths of our investigation are a prompt design that leverages chain-of-thought prompting for insight into LLM clinical reasoning capabilities as well as the use of free response clinical case questions where previous studies have been limited to multiple-choice or simple open-ended fact retrieval that do not challenge LLM clinical reasoning abilities.</s><s xml:id="_4DCuYJu">We designed our evaluation with free response questions both from the USMLE as well as NEJM case report series to facilitate rigorous comparison between prompting strategies.</s></p><p xml:id="_M9pGUet"><s xml:id="_9aaUmCP">A limitation of our study is that while our prompt engineering process surveyed a wide range of prompt styles we could not test all possible diagnostic reasoning CoT prompts.</s><s xml:id="_545CsHx">Furthermore our investigation was limited to only GPT-3.5 and GPT-4, US-centric question sets, and the English language, therefore we cannot generalize our findings to other available models, especially ones fine-tuned on texts demonstrating clinical reasoning, nor to non-English languages and non-US-centric question sets.</s><s xml:id="_NWgYTRz">We hope that future studies can iterate on our diagnostic reasoning prompts and use our open dataset as a benchmark for additional evaluation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_43kmKC4">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_nwjhZhE">LLM prompt development</head><p xml:id="_pd2mqMz"><s xml:id="_trzDZ76">We used an iterative process known as prompt engineering to develop our diagnostic reasoning prompts.</s><s xml:id="_YJQKEdN">During this process, we experimented with several different types of prompts (Supplementary Note 2).</s><s xml:id="_pNASkwa">In each round of prompt engineering, we evaluated GPT-3.5 accuracy on the MEDQA training set (Supplementary Data 3).</s><s xml:id="_g8EKYZQ">We found prompts that encouraged step-by-step reasoning without specifying what the steps should be, yielded better performance.</s><s xml:id="_F7QKC4P">We also found that prompts that focused on a single diagnostic reasoning strategy provided better results than prompts that combined multiple strategies.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_P3WxdPh">LLM response evaluation</head><p xml:id="_3dwKmpY"><s xml:id="_MX9qNZk">Language model responses were evaluated by physician authors AN, ER, RG and TS, three internal medicine attending physicians and one internal medicine resident.</s><s xml:id="_GdU9NWP">Each question was evaluated by two blinded physicians.</s><s xml:id="_Kj8s2Sj">If there was disagreement in the grade assigned, a third evaluator determined the final grade.</s><s xml:id="_kjswRVh">Any response that was felt to be equally correct and specific, as compared to the provided answer, was marked as correct.</s><s xml:id="_ruCwM3G">Physicians used UpToDate 23 , MKSAPP <ref type="bibr" target="#b24">24</ref> , and StatPearls 25 to verify accuracy of answers when needed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_YJS85Km">LLM programming and computing resources</head><p xml:id="_pGCSQSt"><s xml:id="_fsjh7MU">For this evaluation we used the OpenAI Davinci-003 model via an OpenAI API to provide GPT-3.5 responses and GPT-4 model via an OpenAI API to provide GPT-4 responses.</s><s xml:id="_6XaE4PD">Prompting of the GPT-3.5 model was performed with the Demonstrate-Search-Predict (DSP)</s></p><p xml:id="_At39hh4"><s xml:id="_MvaasYE">Question : A 30-year-old African American woman comes to the physician for the evaluation of a dry cough and chest discomfort for the past 3 days.</s><s xml:id="_vMS4AhK">During this period, the patient has had headaches, muscle aches, joint pain, fever, and chills.</s><s xml:id="_veJAv7u">Ten days ago, she was hiking with her family in Mississippi.</s><s xml:id="_mFugf6M">The patient has asthma that is treated with an albuterol inhaler.</s><s xml:id="_Stb22qj">Her mother has a lung disease treated with methotrexate.</s><s xml:id="_7r2HMFe">The patient has smoked one pack of cigarettes daily for the past 10 years.</s><s xml:id="_jdzAgxQ">Her temperature is 38Â°C (100.4Â°F).</s><s xml:id="_PSK3yG3">Physical examination shows slight wheezes throughout both lung fields.</s><s xml:id="_jt5JSBx">Laboratory studies and urinalysis are positive for polysaccharide antigen.</s><s xml:id="_bF5tgb7">Bronchoalveolar lavage using silver/PAS-staining shows macrophages filled with a dimorphic fungus with septate hyphae.</s><s xml:id="_DurzwF3">What is the most likely cause of this patient's symptoms?</s><s xml:id="_rSPgG4N">Answer: Histoplasmosis Traditional Chain-of-Thought (GPT-3.5)</s><s xml:id="_Z8Ktb2P">'The patient has a dry cough, chest discomfort, and other symptoms such as fever, chills, headaches, and muscle aches.</s><s xml:id="_Cv9vvvU">She has a positive polysaccharide antigen and bronchoalveolar lavage shows a dimorphic fungus with septate hyphae.</s><s xml:id="_9wpYRQj">This patient likely has Valley Fever.' GPT-3.5 Differential Diagnosis CoT (GPT-3.5)</s><s xml:id="_6cYJsdw">'The differential diagnosis for this patient includes: pneumonia, tuberculosis, eosinophilic pneumonia, hypersensitivity pneumonitis, and coccidioidomycosis.</s><s xml:id="_eQkK5eG">The patient's recent history of hiking in Mississippi and the presence of a dimorphic fungus with septate hyphae on bronchoalveolar lavage make coccidioidomycosis the most likely cause of her symptoms.'</s><s xml:id="_neZSDaf">GPT-3.5 Intuitive Reasoning CoT (GPT-3.5)</s><s xml:id="_yWngykr">'The patient has a history of asthma, which increases the likelihood of asthma exacerbation.</s><s xml:id="_9KzXDHN">The positive result for polysaccharide antigen suggests atypical pneumonia.</s><s xml:id="_bZSMCQP">The presence of a dimorphic fungus with septate hyphae suggests the presence of fungal pneumonia.</s><s xml:id="_w22SnRb">This patient most likely has fungal pneumonia.'</s><s xml:id="_r5tTWKx">Analytic Reasoning CoT (GPT-3.5)</s><s xml:id="_UBRGb5u">'The patient's recent history of hiking in Mississippi and the positive polysaccharide antigen and silver/PAS-staining results strongly suggest fungal pneumonia as the cause of her symptoms.'</s><s xml:id="_bC22rSw">Bayesian Inference CoT (GPT-3.5)</s><s xml:id="_P9GdxnS">'The prior probability of blastomycosis is 1%, however the patient's recent travel increases the probability to 5%.</s><s xml:id="_ydcysbS">The laboratory and urinalysis results increase the posterior probability to 30%.</s><s xml:id="_xZRj3jt">The presence of a dimorphic fungus on bronchoalveolar lavage increases the probability to 60%.</s><s xml:id="_M8DpJYj">This patient is likely suffering from blastomycosis.' Fig. <ref type="figure">1</ref> GPT 3.5 CoT and diagnostic reasoning rationale examples.</s><s xml:id="_Vz9cdFS">Example GPT-3.5 rationales responding to a traditional CoT prompt as well as diagnostic reasoning prompts.</s><s xml:id="_XskcscJ">LLM response and rationale results for the entire test set can be found in Supplementary Information 1.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>aTable 5 .</head><label>5</label><figDesc><div><p xml:id="_QqUNgG4"><s xml:id="_wXrcp5M">Percentage difference and p value statistics compared to traditional chain-of-thought.</s><s xml:id="_Qpbfqjm">GPT 4 challenge set performance with differential diagnosis reasoning prompts compared to traditional CoT.</s><s xml:id="_TNhF4St">2% (-11.4%,</s><s xml:id="_8uA8Dsr">+2.1%) 0.09 GPT-4 performance on the NEJM challenge question set with both traditional chain-of-thought and differential diagnosis reasoning prompting.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3</head><label>3</label><figDesc><div><p xml:id="_AWbJbQr"><s xml:id="_Fw3pYpJ">Fig. 3 Proposed LLM workflow.</s><s xml:id="_9pgKPGC">a Current LLM workflow.</s><s xml:id="_U4N3sER">b Proposed LLM workflow.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc><div><p xml:id="_bnBvUmT"><s xml:id="_EbhgQ3a">Example MedQA questions.</s></p></div></figDesc><table><row><cell>Example Question 1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc><div><p><s xml:id="_R96yBEk">CoT and diagnostic reasoning prompts.Traditional CoT reasoning prompt Traditional chain-of-thought (CoT) Prompt:Provide a step-by-step deduction that identifies the correct response {Example Question 1} Example Rationale 1:The patient had a surgical repair of a displaced femoral neck fracture.The patient has petechiae.The patient has a new oxygen requirement, meaning they are having difficulty with their breathing.This patient most likely has a fat embolism.This patient has shortness of breath after a long bone surgery.The differential for this patient is pulmonary embolism, fat embolism, myocardial infarction, blood loss, anaphylaxis, or a drug reaction.The patient has petechiae which makes fat embolism more likely.This patient most likely has a fat embolism.This patient has chest pain with diffuse ST elevations after a recent myocardial infarction.The differential for this patient includes: myocardial infarction, pulmonary embolism, pericarditis, Dressler syndrome, aortic dissection, and costochondritis.This patient likely has a high-pitched scratching sound on auscultation associated with pericarditis and Dressler Syndrome.This patient has diffuse ST elevations associated with Dressler Syndrome.This patient most likely has Dressler Syndrome.Intuitive reasoning CoTPrompt: Use symptom, signs, and laboratory disease associations to step by step deduce the correct response.This patient had a recent myocardial infarction which can cause myocardial inflammation that causes pericarditis and Dressler Syndrome.The diffuse ST elevations and high pitched scratching murmur can be signs of pericardial inflammation as the inflamed pericardium rubs against the pleura as seen with Dressler Syndrome.This patient likely has Dressler Syndrome.Bayesian reasoning CoTPrompt:Use step-by-step Bayesian Inference to create a prior probability that is updated with new information in the history to produce a posterior probability and determine the final diagnosis.The prior probability of fat embolism is 0.05% however the patient has petechiae on exam which is seen with fat emboli, which increases the posterior probability of fat embolism to 5%.</s><s xml:id="_jsJbGDS">Altered mental status increases the probability further to 10%.</s><s xml:id="_VagtQhE">Recent orthopedic surgery increases the probability of fat emboli syndrome to 60%.</s><s xml:id="_gY5M3Nt">This patient most likely has a fat embolism.</s></p></div></figDesc><table><row><cell></cell><cell>{Example Question 2}</cell></row><row><cell></cell><cell>Example Rationale 2:</cell></row><row><cell></cell><cell>This patient is having chest pain. They recently had a heart attack and has new chest pain, suggesting he may have a</cell></row><row><cell></cell><cell>problem with his heart. The EKG has diffuse ST elevations and he has a scratching murmur. This patient likely has Dressler</cell></row><row><cell></cell><cell>Syndrome.</cell></row><row><cell>Clinical reasoning prompts</cell><cell></cell></row><row><cell>Differential diagnosis CoT</cell><cell>Prompt:</cell></row><row><cell></cell><cell>Use step by step deduction to create a differential diagnosis and then use step by step deduction to determine the correct</cell></row><row><cell></cell><cell>response.</cell></row><row><cell></cell><cell>{Example Question 1}</cell></row><row><cell></cell><cell>Example Rationale 1:</cell></row><row><cell></cell><cell>{Example Question 2}</cell></row><row><cell></cell><cell>Example Rationale 2:</cell></row><row><cell></cell><cell>{Example Question 2}</cell></row><row><cell></cell><cell>Example Rationale 2:</cell></row><row><cell></cell><cell>{Example Question 1}</cell></row><row><cell></cell><cell>Example Rationale 1:</cell></row><row><cell></cell><cell>{Example Question 2}</cell></row><row><cell></cell><cell>Example Rationale 2:</cell></row></table><note xml:id="_ZfNg5pG"><p><s xml:id="_CSCW9ch">{Example Question 1} Example Rationale 1: This patient has findings of petechiae, altered mental status, shortness of breath, and recent surgery suggesting a diagnosis of fat emboli.</s><s xml:id="_zwTAdKs">The patient most likely has a fat embolism.</s><s xml:id="_MaFFmGx">{Example Question 2} Example Rationale 2: This patient had a recent myocardial infarction with new development of diffuse ST elevations, chest pain, and a high pitched scratching murmur which are found in Dressler's syndrome.</s><s xml:id="_eAdHcJB">This patient likely has Dressler's Syndrome.</s><s xml:id="_zvujU7t">Analytic reasoning CoT Prompt: Use analytic reasoning to deduce the physiologic or biochemical pathophysiology of the patient and step by step identify the correct response.</s><s xml:id="_js4PbVE">{Example Question 1} Example Rationale 1:The patient recently had large bone surgery making fat emboli a potential cause because the bone marrow was manipulated.</s><s xml:id="_ghBwR48">Petechiae can form in response to capillary inflammation caused by fat emboli.</s><s xml:id="_DQM7Wjn">Fat micro globules cause CNS microcirculation occlusion causing confusion and altered mental status.</s><s xml:id="_sRmgqA7">Fat obstruction in the pulmonary arteries can cause tachycardia and shortness of breath as seen in this patient.</s><s xml:id="_VXETGSB">This patient most likely has a fat embolism.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc><div><p><s xml:id="_ezkhTUA">GPT 3.5 MEDQA performance with diagnostic reasoning prompts compared to traditional CoT..5 performance on a free-response MEDQA question set with both traditional chain-of-thought model prompting strategies as well as clinical reasoning prompts of intuitive reasoning, analytic reasoning, differential diagnosis and Bayesian inference.</s></p></div></figDesc><table><row><cell>Prompt</cell><cell>Correct responses (%)</cell><cell>Difference in percentage (confidence interval)</cell><cell>p value a</cell></row><row><cell>Chain of thought</cell><cell>46%</cell><cell>-</cell><cell>-</cell></row><row><cell>Intuitive reasoning</cell><cell>48%</cell><cell>1.7% (-2.5%, 5.9%)</cell><cell>0.4</cell></row><row><cell>Analytic reasoning</cell><cell>40%</cell><cell>-6.0% (-11%, -1.5%)</cell><cell>0.001</cell></row><row><cell>Differential diagnosis</cell><cell>38%</cell><cell>-8.9% (-14%, -3.4%)</cell><cell>&lt;0.001</cell></row><row><cell>Bayesian inference</cell><cell>42%</cell><cell>-4.4% (-9.1%, 0.2%)</cell><cell>0.02</cell></row><row><cell>GPT-3</cell><cell></cell><cell></cell><cell></cell></row></table><note xml:id="_EAeJ4hT"><p><s xml:id="_JJPzzWc">a Percentage difference and p value statistics compared to traditional chain-of-thought.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc><div><p xml:id="_azSRt8a"><s xml:id="_AMQ7Qnz">GPT 4 MEDQA performance with diagnostic reasoning prompts compared to traditional CoT.</s><s xml:id="_VR2WTz7">performance on a free-response MEDQA question set with both traditional chain-of-thought model prompting strategies as well as clinical reasoning prompts of intuitive reasoning, analytic reasoning, differential diagnosis and Bayesian inference.</s></p></div></figDesc><table><row><cell>Prompt</cell><cell>Correct responses (%)</cell><cell>Difference in percentage (confidence interval)</cell><cell>p value a</cell></row><row><cell>Chain of thought</cell><cell>76%</cell><cell>-</cell><cell>-</cell></row><row><cell>Intuitive reasoning</cell><cell>77%</cell><cell>0.8% (-3.6%, 5.2%)</cell><cell>0.73</cell></row><row><cell>Analytic reasoning</cell><cell>78%</cell><cell>1.6% (-2.4%, 5.6%)</cell><cell>0.35</cell></row><row><cell>Differential diagnosis</cell><cell>78%</cell><cell>2.2% (-2.3%, 6.7%)</cell><cell>0.24</cell></row><row><cell>Bayesian inference</cell><cell>72%</cell><cell>-3.4% (-9.1%, 1.2%)</cell><cell>0.07</cell></row><row><cell>GPT-4</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_XaUW2PT"><s xml:id="_2wVy3wQ">npj Digital Medicine (2024) 20 Published in partnership with Seoul National University Bundang Hospital 1234567890():,;</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_kA9KCg6"><s xml:id="_Y8e7bfv">Published in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024) 20</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_MCQvHjX"><s xml:id="_jHYXnjx">npj Digital Medicine (2024)<ref type="bibr" target="#b19">20</ref> Published in partnership with Seoul National University Bundang Hospital</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xml:id="_Z8Z3HGN"><p xml:id="_HcABFtC"><s xml:id="_rmCVRfW">ACKNOWLEDGEMENTS J.H.C. has received research funding support in part by the <rs type="funder">NIH/National Institute of Allergy and Infectious Diseases</rs> (<rs type="grantNumber">1R01AI17812101</rs>), <rs type="funder">NIH/National Institute on Drug Abuse Clinical Trials Network</rs> (<rs type="grantNumber">UG1DA015815-CTN-0136</rs>), <rs type="funder">Gordon and Betty Moore Foundation</rs> (Grant #<rs type="grantNumber">12409</rs>), <rs type="funder">Stanford Artificial Intelligence in Medicine and Imaging-</rs><rs type="projectName">Human-Centered Artificial Intelligence (AIMI-HAI</rs>) Partnership Grant, <rs type="funder">Google Inc</rs>. Research collaboration, <rs type="funder">American Heart Association-</rs><rs type="projectName">Strategically Focused Research Network-Diversity in Clinical Trials</rs>, and the <rs type="funder">NIH-NCATS-CTSA</rs> grant (<rs type="grantNumber">UL1TR003142</rs>) for common research resources.</s><s xml:id="_wMrxHBw">R.G. is supported by a <rs type="funder">VA Advanced Fellowship in Medical Informatics</rs>.</s><s xml:id="_EZW6D5F">The views expressed are those of the authors and not necessarily those of the <rs type="institution">Department of Veterans Affairs</rs> or those of the <rs type="institution">United States Government</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_nw7YV94">
					<idno type="grant-number">1R01AI17812101</idno>
				</org>
				<org type="funding" xml:id="_bBdyMh9">
					<idno type="grant-number">UG1DA015815-CTN-0136</idno>
				</org>
				<org type="funding" xml:id="_ATGuWhD">
					<idno type="grant-number">12409</idno>
				</org>
				<org type="funded-project" xml:id="_RjZDMhK">
					<orgName type="project" subtype="full">Human-Centered Artificial Intelligence (AIMI-HAI</orgName>
				</org>
				<org type="funded-project" xml:id="_sYVHUsv">
					<orgName type="project" subtype="full">Strategically Focused Research Network-Diversity in Clinical Trials</orgName>
				</org>
				<org type="funding" xml:id="_qKeCvx9">
					<idno type="grant-number">UL1TR003142</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_8WFXNeD">DATA AVAILABILITY</head><p xml:id="_hYPjxEP"><s xml:id="_bCJ4N4E">All data used in this manuscript are provided in our Supplementary Information and open access figshare (10.6084/m9.figshare.24886593).</s><s xml:id="_H53whAw">This includes all prompts, LLM responses and reviewer grades.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_2VYDuxp">CODE AVAILABILITY</head><p xml:id="_78ynh9u"><s xml:id="_jj8ksdn">All code used in this manuscript is provided in our Supplementary Information and open access figshare (10.6084/m9.figshare.24886593).</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_va2hqSg"><p xml:id="_5ZU5twH"><s xml:id="_jRVWGH8">Python module <ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b27">27</ref> .</s><s xml:id="_SxqhJGf">Self-consistency was applied all GPT-3.5 Chain-of-Thought prompts <ref type="bibr" target="#b28">28</ref> .</s><s xml:id="_dDEeNua">GPT-4 responses did not use DSP or self-consistency because those features were not available for GPT-4 at the time of submission.</s><s xml:id="_76MRCuN">Computing was performed in a Google CoLab Jupyter Notebook.</s><s xml:id="_hKk2q38">Full code can be found in Supplementary Note 3.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7rePsX4">Statistical evaluation</head><p xml:id="_aBKneZN"><s xml:id="_kXh6CJ8">Statistical significance and confidence intervals were calculated against traditional CoT using McNemar's test for paired proportions, two-tailed.</s><s xml:id="_WqTVNae">Statistical significance was set at an alpha of 0.0125 to reflect multiple hypotheses (four prompts per each model) by the Bonferroni Correction.</s><s xml:id="_cYcK6Xz">Inter-rater agreement was assessed using Cohen's Kappa Statistic.</s><s xml:id="_puZpE8R">Statistical analysis was performed in R with the epibasix library.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_JDkyRAJ">Clinical reasoning rationale logic evaluation</head><p xml:id="_XN5RWuu"><s xml:id="_gC2jz5U">The first 100 GPT-4 differential diagnosis rationales were evaluated for appropriate logic and medical accuracy.</s><s xml:id="_dyM2DSg">The rationales were evaluated by physician authors RG and TS, who are both internal medicine attending physicians.</s><s xml:id="_MZPv7Qv">The reviewers attempted to identify instances of inaccuracy or false logic in each diagnostic reasoning rationale, blinded to the index question, gold standard answer, or grade of the LLM response.</s><s xml:id="_tmKDhHv">Reviewers were blinded to the index question to simulate a clinical situation where a physician is evaluating an LLM case interpretation without examining the patient themselves.</s><s xml:id="_A6CwxgU">Arguments with false logic or inaccuracies were tallied and a comparison was made between rationales supporting correct versus incorrect answers.</s><s xml:id="_aA2DjSe">Complete data can be found in Supplementary Data 5.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mN9kbGV">AUTHOR CONTRIBUTIONS</head><p xml:id="_fyJzaJC"><s xml:id="_HDTf48Y">T.S.: manuscript writing, LLM response review, conceptual design.</s><s xml:id="_kgcGrSV">A.N.: manuscript writing, LLM response review.</s><s xml:id="_kY5erU8">R.G.: manuscript writing, LLM response review.</s><s xml:id="_KF3BPpq">E.R.: manuscript writing, LLM response review.</s><s xml:id="_na6VTgZ">J.H.C.: manuscript writing, conceptual design.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_t5NhKns">COMPETING INTERESTS</head><p xml:id="_ahcT4nw"><s xml:id="_Qgk9GD4">The authors declare no competing interests.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gNdqZaG">ADDITIONAL INFORMATION Supplementary information</head><p xml:id="_NaC7Ug2"><s xml:id="_4eYnrKH">The online version contains supplementary material available at <ref type="url" target="https://doi.org/10.1038/s41746-024-01010-1">https://doi.org/10.1038/s41746-024-01010-1</ref>.</s></p><p xml:id="_UGmBjQr"><s xml:id="_FbMK4Uh">Correspondence and requests for materials should be addressed to Thomas Savage.</s></p><p xml:id="_EGtwwA7"><s xml:id="_z6YZ9Vt">Reprints and permission information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/  reprints</ref> Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_WrWmb4u">Large language models in medicine</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Thirunavukarasu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-023-02448-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dKdYqjy">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thirunavukarasu, A. J. et al. Large language models in medicine. Nat. Med. 29, 1-11 (2023).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_dAZHDSm">Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YQGusNC">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="2399" to="2400" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lee, P., Bubeck, S. &amp; Petro, J. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine. N. Engl. J. Med. 388, 2399-2400 (2023).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_Eb4mXWh">Comparison of history of present illness summaries generated by a chatbot and senior internal medicine residents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nayak</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2023.2561</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_G5kKUYY">JAMA Intern. Med</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page">232561</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nayak, A. et al. Comparison of history of present illness summaries generated by a chatbot and senior internal medicine residents. JAMA Intern. Med. 183, e232561 (2023).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_BHMExNf">Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Kung</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000198</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sdRmwRa">PLoS Digit. Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">198</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kung, T. H. et al. Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models. PLoS Digit. Health 2, e0000198 (2023).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_HqEW5Yq">Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ayers</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2023.1838</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AZaXk6J">JAMA Intern. Med</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="589" to="596" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ayers, J. W. et al. Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. JAMA Intern. Med. 183, 589-596 (2023).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_Er9M3Jt">Appropriateness of cardiovascular disease prevention recommendations obtained from a popular online chat-based artificial intelligence model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sarraju</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2023.1044</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Cqeu77E">JAMA</title>
		<imprint>
			<biblScope unit="volume">329</biblScope>
			<biblScope unit="page" from="842" to="844" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sarraju, A. et al. Appropriateness of cardiovascular disease prevention recom- mendations obtained from a popular online chat-based artificial intelligence model. JAMA 329, 842-844 (2023).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_BDCYSJf">Large language models encode clinical knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-023-06291-2</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Jj6zs8w">Nature</title>
		<imprint>
			<biblScope unit="volume">620</biblScope>
			<biblScope unit="page" from="172" to="180" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Singhal, K. et al. Large language models encode clinical knowledge. Nature 620, 172-180 (2023).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main" xml:id="_uUu28Qg">Towards expert-level medical question answering with large language models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.09617</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.09617" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Singhal, K. et al. Towards expert-level medical question answering with large language models. Preprint at https://doi.org/10.48550/arXiv.2305.09617 (2023).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main" xml:id="_eBEwC6W">Capabilities of GPT-4 on medical challenge problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.13375</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.13375" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Nori, H., King, N., McKinney, S. M., Carignan, D. &amp; Horvitz, E. Capabilities of GPT-4 on medical challenge problems. Preprint at https://doi.org/10.48550/arXiv.2303.13375 (2023).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_eyD92es">Performance of ChatGPT and GPT-4 on neurosurgery written board examinations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ali</surname></persName>
		</author>
		<idno type="DOI">10.1227/neu.0000000000002632</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uJUmKnF">Neurosurgery</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1353" to="1365" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ali, R. et al. Performance of ChatGPT and GPT-4 on neurosurgery written board examinations. Neurosurgery. 93, 1353-1365 (2023).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_dMtwZZj">Performance of ChatGPT, GPT-4, and Google Bard on a neurosurgery oral boards preparation question bank</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4dVbBxF">Neurosurgery</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1090" to="1098" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ali, R. et al. Performance of ChatGPT, GPT-4, and Google Bard on a neurosurgery oral boards preparation question bank. Neurosurgery. 93, 1090-1098 (2023).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_9gkuKcd">Chatbot vs medical student performance on free-response clinical reasoning examinations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Strong</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2023.2909</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dZtN6BM">JAMA Intern. Med</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="1028" to="1030" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Strong, E. et al. Chatbot vs medical student performance on free-response clinical reasoning examinations. JAMA Intern. Med. 183, 1028-1030 (2023).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_vtKDFAv">Accuracy of a generative artificial intelligence model in a complex diagnostic challenge</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kanjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Crowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodman</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2023.8288</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NEKBgAd">JAMA</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="78" to="80" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kanjee, Z., Crowe, B. &amp; Rodman, A. Accuracy of a generative artificial intelligence model in a complex diagnostic challenge. JAMA 330, 78-80 (2023).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_qusJ5qv">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_EDxsTAB">Proc. of the 34th International Conference on Neural Information Processing Systems (NIPS&apos;20)</title>
		<meeting>of the 34th International Conference on Neural Information essing Systems (NIPS&apos;20)</meeting>
		<imprint>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
	<note type="raw_reference">Brown, T. B. et al. Language models are few-shot learners. In Proc. of the 34th International Conference on Neural Information Processing Systems (NIPS&apos;20). 159, 1877-1901 (</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2304.03277" />
		<title level="m" xml:id="_weT2MDr">Instruction tuning with GPT-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Peng, B., Li, C., He, P., Galley, M. &amp; Gao, J. Instruction tuning with GPT-4. Preprint at http://arxiv.org/abs/2304.03277 (2023).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main" xml:id="_wangCUy">Prompt engineering for healthcare: methodologies and applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2304.14670</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2304.14670" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Wang, J. et al. Prompt engineering for healthcare: methodologies and applica- tions. Preprint at https://doi.org/10.48550/arXiv.2304.14670 (2023).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main" xml:id="_ZbMw7gF">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2201.11903" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Wei, J. et al. Chain-of-thought prompting elicits reasoning in large language models. Preprint at http://arxiv.org/abs/2201.11903 (2023).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main" xml:id="_AXhwDnp">Let&apos;s verify step by step</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lightman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2305.20050" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Lightman, H. et al. Let&apos;s verify step by step. Preprint at http://arxiv.org/abs/ 2305.20050 (2023).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_7c7hZND">OpenAI GPT-3.5 API</title>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://platform.openai.com" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_CwsSBaD">GPT-4 API</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>text-davinci-003</note>
	<note type="raw_reference">OpenAI. 2023. OpenAI GPT-3.5 API [text-davinci-003] and GPT-4 API. Available at: https://platform.openai.com.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main" xml:id="_JkstCyF">What disease does this patient have? A large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2009.13081</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2009.13081" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jin, D. et al. What disease does this patient have? A large-scale open domain question answering dataset from medical exams. Preprint at https://doi.org/ 10.48550/arXiv.2009.13081 (2020).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main" xml:id="_rTKNvN3">Case records of the Massachusetts General Hospital articles</title>
		<idno type="DOI">10.1515/9783110668957-002</idno>
		<imprint>
			<date type="published" when="2020">2020-2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Case records of the Massachusetts General Hospital articles. 2020-2023.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<idno type="DOI">10.1056/nejm199312023292328</idno>
		<ptr target="https://www.nejm.org/medical-articles/case-records-of-the-massachusetts-general-hospital" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_UVSjZrg">N. Engl. J. Med. Accessed</title>
		<imprint>
			<date type="published" when="2023-05">May 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">N. Engl. J. Med. Accessed: May 2023. https://www.nejm.org/medical-articles/case-records- of-the-massachusetts-general-hospital.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_H5pHhbD">Explainable artificial intelligence for mental health through transparency and interpretability for understandability</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Joyce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kormilitzin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cipriani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2fDxkCS">Npj Digital Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Joyce, D. W., Kormilitzin, A., Smith, K. A. &amp; Cipriani, A. Explainable artificial intel- ligence for mental health through transparency and interpretability for under- standability. Npj Digital Med. 6, 1-7 (2023).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<idno type="DOI">10.1097/01.cot.0000931980.25807.1f</idno>
		<ptr target="https://www.wolterskluwer.com/en/solutions/uptodate" />
		<title level="m" xml:id="_kPQQ9r3">UpToDate: industry-leading clinical decision support</title>
		<imprint>
			<publisher>Wolters Kluwer</publisher>
			<date type="published" when="2023-06">June 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">UpToDate: industry-leading clinical decision support. Wolters Kluwer. Accessed: June 2023. https://www.wolterskluwer.com/en/solutions/uptodate.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<idno type="DOI">10.1097/00019616-199104000-00019</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MPGSwyu">MKSAP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">MKSAP 19</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main" xml:id="_AZJqxTz">NCBI Bookshelf</title>
		<author>
			<persName><surname>Statpearls</surname></persName>
		</author>
		<ptr target="https://www.statpearls.com/" />
		<imprint>
			<date type="published" when="2023-06">June 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">StatPearls. NCBI Bookshelf. Accessed: June 2023. https://www.statpearls.com/.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<idno type="DOI">10.17504/protocols.io.fskbncw</idno>
		<ptr target="https://github.com/stanfordnlp/dspy/tree/v1" />
		<title level="m" xml:id="_JgaXWmp">DSP: The Demonstrate-Search-Predict Framework</title>
		<imprint>
			<date type="published" when="2023-03">March 2023</date>
		</imprint>
	</monogr>
	<note>GitHub -stanfordnlp/dspy at v1</note>
	<note type="raw_reference">DSP: The Demonstrate-Search-Predict Framework. Accessed: March 2023. GitHub -stanfordnlp/dspy at v1. https://github.com/stanfordnlp/dspy/tree/v1.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main" xml:id="_wpMkKtC">Demonstrate-Search-Predict: composing retrieval and language models for knowledge-intensive NLP</title>
		<author>
			<persName><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2212.14024" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Khattab, O. et al. Demonstrate-Search-Predict: composing retrieval and language models for knowledge-intensive NLP. Preprint at http://arxiv.org/abs/2212.14024 (2023).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main" xml:id="_PFhZzxj">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2203.11171</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2203.11171" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Wang, X. et al. Self-consistency improves chain of thought reasoning in language models. Preprint at https://doi.org/10.48550/arXiv.2203.11171 (2023).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
