<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_VKeFhsR">Deep transfer learning for reducing health care disparities arising from biomedical data inequality</title>
				<funder>
					<orgName type="full">Center for Integrative and Translational Genomics at University of Tennessee Health Science Center</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yan</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Genetics, Genomics and Informatics , University of Tennessee Health Science Center , Memphis , TN 38163 , USA.</note>
								<orgName type="department">Department of Genetics, Genomics and Informatics</orgName>
								<orgName type="institution">University of Tennessee Health Science Center</orgName>
								<address>
									<postCode>38163</postCode>
									<settlement>Memphis</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Center for Integrative and Translational Genomics , University of Tennessee Health Science Center , Memphis , TN 38163 , USA.</note>
								<orgName type="department">Center for Integrative and Translational Genomics</orgName>
								<orgName type="institution">University of Tennessee Health Science Center</orgName>
								<address>
									<postCode>38163</postCode>
									<settlement>Memphis</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Cui</surname></persName>
							<idno type="ORCID">0000-0002-7577-6845</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Genetics, Genomics and Informatics , University of Tennessee Health Science Center , Memphis , TN 38163 , USA.</note>
								<orgName type="department">Department of Genetics, Genomics and Informatics</orgName>
								<orgName type="institution">University of Tennessee Health Science Center</orgName>
								<address>
									<postCode>38163</postCode>
									<settlement>Memphis</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Center for Integrative and Translational Genomics , University of Tennessee Health Science Center , Memphis , TN 38163 , USA.</note>
								<orgName type="department">Center for Integrative and Translational Genomics</orgName>
								<orgName type="institution">University of Tennessee Health Science Center</orgName>
								<address>
									<postCode>38163</postCode>
									<settlement>Memphis</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Center for Cancer Research , University of Tennessee Health Science Center , Memphis , TN 38163 , USA.</note>
								<orgName type="department">Center for Cancer Research</orgName>
								<orgName type="institution">University of Tennessee Health Science Center</orgName>
								<address>
									<postCode>38163</postCode>
									<settlement>Memphis</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_V5bdAQM">Deep transfer learning for reducing health care disparities arising from biomedical data inequality</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C263EE72C55B0245A6426C2FA5507FFD</idno>
					<idno type="DOI">10.1038/s41467-020-18918-3</idno>
					<note type="submission">Received: 22 April 2020; Accepted: 16 September 2020;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T09:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_3S8XKnv"><p xml:id="_FJp8Mpa"><s xml:id="_qkc6gvD">As artificial intelligence (AI) is increasingly applied to biomedical research and clinical decisions, developing unbiased AI models that work equally well for all ethnic groups is of crucial importance to health disparity prevention and reduction.</s><s xml:id="_XUPZdvR">However, the biomedical data inequality between different ethnic groups is set to generate new health care disparities through data-driven, algorithm-based biomedical research and clinical decisions.</s><s xml:id="_UvQRAsd">Using an extensive set of machine learning experiments on cancer omics data, we find that current prevalent schemes of multiethnic machine learning are prone to generating significant model performance disparities between ethnic groups.</s><s xml:id="_DxFngPA">We show that these performance disparities are caused by data inequality and data distribution discrepancies between ethnic groups.</s><s xml:id="_RRZXaAs">We also find that transfer learning can improve machine learning model performance for datadisadvantaged ethnic groups, and thus provides an effective approach to reduce health care disparities arising from data inequality among ethnic groups.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_WYHTJWz"><p xml:id="_MBfU3tm"><s xml:id="_AnHHdb5">A rtificial intelligence (AI) is fundamentally transforming biomedical research and health care systems are increasingly reliant on AI-based predictive analytics to make better diagnosis, prognosis, and therapeutic decisions <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> .</s><s xml:id="_gTsmECS">Since data are the most important resources for developing high-quality AI models, data inequality among ethnic groups is becoming a global health problem in the AI era.</s><s xml:id="_4ujEGsR">Recent statistics showed that samples from cancer genomics research projects, including the TCGA <ref type="bibr" target="#b3">4</ref> , TARGET <ref type="bibr" target="#b4">5</ref> , OncoArray <ref type="bibr" target="#b5">6</ref> , and 416 cancer-related genome-wide association studies, were collected primarily from Caucasians (91.1%), distantly followed by Asians (5.6%), African Americans (1.7%), Hispanics (0.5%), and other populations (0.5%) <ref type="bibr" target="#b6">7</ref> .</s><s xml:id="_TJWM2kF">Most clinical genetics and genomics data have been collected from individuals of European ancestry and ethnic diversity of studied cohorts has largely remained the same or even declined in recent years <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9</ref> .</s><s xml:id="_vZVFSht">As a result, non-Caucasians, which constitute about 84% of the world's population, have a long-term cumulative data disadvantage.</s><s xml:id="_PDyH7S4">Inadequate training data may lead to nonoptimal AI models with low prediction accuracy and robustness, which may have profound negative impacts on health care for the data-disadvantaged ethnic groups <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10</ref> .</s><s xml:id="_CAe2YhW">Thus, data inequality between ethnic groups is set to generate new health care disparities.</s></p><p xml:id="_7sBFK5G"><s xml:id="_XTBv5P7">The current prevalent scheme of machine learning with multiethnic data is the mixture learning scheme in which data for all ethnic groups are mixed and used indistinctly in model training and testing (Fig. <ref type="figure">1</ref>).</s><s xml:id="_JqhjkA7">Under this scheme, it is unclear whether the machine learning model works well for all ethnic groups involved.</s><s xml:id="_ZmAnbdA">An alternative approach is the independent learning scheme in which data from different ethnic groups are used separately to train independent models for each ethnic group (Fig. <ref type="figure">1</ref>).</s><s xml:id="_J8zybdj">This learning scheme also tends to produce models with low prediction accuracy for data-disadvantaged minority groups due to inadequate training data.</s></p><p xml:id="_B6RvxcS"><s xml:id="_9dPXNVU">Here, we show that the mixture learning scheme tends to produce models with relatively low prediction accuracy for datadisadvantaged minority groups, due to data distribution mismatches between ethnic groups.</s><s xml:id="_aT2ht36">Therefore, the mixture learning scheme often leads to unintentional and even unnoticed model performance gaps between ethnic groups.</s><s xml:id="_jg8GX55">We find that the transfer learning <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref> scheme (Fig. <ref type="figure">1</ref>), in many cases, can provide machine learning models with improved performance for datadisadvantaged ethnic groups.</s><s xml:id="_Xy8HUnD">Our results from machine learning experiments on synthetic data indicate that data inequality and data distribution discrepancy between different ethnic groups are the key factors underlying the model performance disparities.</s><s xml:id="_cY9GSqc">We anticipate that this work will provide a starting point for an unbiased multiethnic machine learning paradigm that implements regular tests of the performance of machine learning models on all ethnic groups to identify model performance disparities between ethnic groups, and that uses transfer learning or other techniques to reduce performance disparities.</s><s xml:id="_KDKJRCf">Such a paradigm is essential for reducing health care disparities arising from the long-standing biomedical data inequality among ethnic groups.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hyhgtg3">Results</head><p xml:id="_M3BxqVe"><s xml:id="_USQR42V">Clinical omics data inequalities among ethnic groups.</s><s xml:id="_nQzhxn6">Interrelated multi-omics factors including genetic polymorphisms, somatic mutations, epigenetic modifications, and alterations in expression of RNAs and proteins collectively contribute to cancer pathogenesis and progression.</s><s xml:id="_D4TBvAg">Clinical omics data from large cancer cohorts provide an unprecedented opportunity to elucidate the complex molecular basis of cancers <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref> and to develop machine learning-based predictive analytics for precision oncology <ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> .</s><s xml:id="_DEg8KQ3">However, data inequality among ethnic groups continues to be conspicuous in recent large-scale genomics-focused biomedical research programs <ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24</ref> .</s><s xml:id="_tHhtztj">The TCGA cohort consists of 80.5% European Americans (EAs), 9.2% African Americans (AAs), 6.1% East Asian Americans (EAAs), 3.6% Native Americans (NAs), and 0.7% others, based on genetic ancestry analysis <ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26</ref> .</s><s xml:id="_PXjMbrK">The TARGET <ref type="bibr" target="#b4">5</ref> and MMRF CoMMpass <ref type="bibr" target="#b26">27</ref> cohorts have similar ethnic compositions <ref type="bibr" target="#b27">28</ref> , which are typical for current clinical omics datasets <ref type="bibr" target="#b6">7</ref> .</s><s xml:id="_ewwk43p">The data inequality among ethnic groups is ubiquitous across almost all cancer types in the TCGA and MMRF CoMMpass cohorts (see Supplementary Fig. <ref type="figure">1</ref>); therefore, its negative impacts would be broad and not limited to the cancer types or subtypes for which ethnic disparities have already been reported.</s></p><p xml:id="_49cbdwJ"><s xml:id="_7JYUSVq">Disparities in machine learning model performance.</s><s xml:id="_ycCtTsW">We assembled machine learning tasks using the cancer omics data and clinical outcome endpoints <ref type="bibr" target="#b28">29</ref> from the TCGA data of two ethnic groups: AA and EA groups, assigned by genetic ancestry analysis <ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26</ref> .</s><s xml:id="_4zufuz5">A total of 1600 machine learning tasks were assembled using combinations of four factors: (1) 40 types of cancers and pan-cancers 15 ; (2) two types of omics features: Low performance on minority groups due to data inequality and data distribution mismatch between ethnic groups Low performance on minority groups due to inadequate minority data Knowledge Improved performance on minority groups due to knowledge transfer Independent learning scheme Transfer learning scheme Mixture learning scheme Data Data Data Data Data Data Data Data Data High performance on the majority group Majority Group Minority Group 1 Minority Group 2 Minority Group 3</s></p><p xml:id="_mUnNKU7"><s xml:id="_5YHNfAM">Fig. <ref type="figure">1</ref> Multiethnic machine learning schemes.</s><s xml:id="_cEQKkuW">In the mixture learning scheme, a model is trained and tested on the data for all ethnic groups.</s><s xml:id="_rSRRykY">In the independent learning scheme, a model is trained and tested for each ethnic group using its own data.</s><s xml:id="_9bsJVaV">In the transfer learning scheme, a model is trained on the majority group data, then the knowledge learned is transferred to assist the development of a model for each minority group.</s></p><p xml:id="_96RRPpx"><s xml:id="_g48U6Dq">mRNA and protein expression; (3) four clinical outcome endpoints: overall survival (OS), disease-specific survival (DSS), progression-free interval (PFI), and disease-free interval (DFI) <ref type="bibr" target="#b28">29</ref> ; and (4) five thresholds for the event time associated with the clinical outcome endpoints (Supplementary Fig. <ref type="figure" target="#fig_0">2</ref>).</s><s xml:id="_gdq8F8C">For each learning task, each patient is assigned to a positive (or a negative) prognosis category based on whether the patient's event time for the clinical outcome endpoint of the learning task is no less than (or less than) a certain threshold.</s></p><p xml:id="_zutR2G5"><s xml:id="_D5tnH7p">Since the AA patients consist of less than 10% of the TCGA cohort, there were only very small numbers of AA cases in many learning tasks.</s><s xml:id="_rWapDRZ">We filtered out the learning tasks having too few cases to permit reliable machine learning experiments.</s><s xml:id="_QrjKf6b">We then performed machine learning experiments on the remaining 447 learning tasks that had at least five AA cases and five EA cases in each of the positive and negative prognosis categories.</s><s xml:id="_vA6FeJn">For each machine learning task, we trained a deep neural network (DNN) model for classification between the two prognosis categories using the mixture learning scheme.</s><s xml:id="_FW2bVuE">The mixture learning models achieved reasonably good baseline performance (AUROC &gt; 0.65) for 224 learning tasks.</s><s xml:id="_88HbQUw">A total of 21 types of cancers and pancancers and all four clinical outcome endpoints were represented in these learning tasks.</s><s xml:id="_7e3RGXD">The proportion of AA patients ranged from 0.06 to 0.25 in these learning tasks with a median of 0.12 (Supplementary Fig. <ref type="figure" target="#fig_1">3a</ref>).</s><s xml:id="_VYJEeJ7">For each of the 224 learning tasks (Supplementary Data 1), we performed six machine learning experiments (Table <ref type="table" target="#tab_1">1</ref>) to compare the performance of the three multiethnic machine learning schemes on the AA and EA groups (Fig. <ref type="figure" target="#fig_0">2</ref>).</s></p><p xml:id="_9mEP8vP"><s xml:id="_Ge9XDUd">In the machine learning experiments, we observed that the mixture learning scheme was prone to produce biased models with a lower prediction performance for the data-disadvantaged AA group.</s><s xml:id="_tzPCaqY">The model performance differences between the EA and AA groups were statistically significant with a p value of 6.72 × 10 -11 (Fig. <ref type="figure" target="#fig_0">2</ref>, Mixture 1 &amp; 2).</s><s xml:id="_YUHyUKS">The average EA-AA model performance gap over the 224 learning tasks was 0.06 (AUROC, Table <ref type="table" target="#tab_1">1</ref>).</s><s xml:id="_cc6YhUh">Without testing the model performance of the machine learning models on each ethnic group separately, the performance differences would be concealed by the overall good performance for the entire multiethnic cohort (Fig. <ref type="figure" target="#fig_0">2</ref>, Mixture 0).</s><s xml:id="_Qw3msfV">The independent learning scheme produced even larger EA-AA performance differences with a p value of 1.29 × 10 -26 and the average performance gap was 0.13 (Table <ref type="table" target="#tab_1">1</ref></s></p><formula xml:id="formula_0">, Fig. 2, Independent 1 &amp; 2).</formula><p xml:id="_N9cxM5g"><s xml:id="_QADasZA">Transfer learning for improving machine learning model performance for data-disadvantaged ethnic groups.</s><s xml:id="_pAgbuRb">We compared machine learning schemes on performance for the datadisadvantaged AA group and found that transfer learning produced models with significantly better performance for the AA group compared to the models from mixture learning (p = 6.79 × 10 -5 ) and independent learning (p = 6.0.5 × 10 -35 ) (Fig. <ref type="figure" target="#fig_0">2</ref>).</s><s xml:id="_hZmtEuw">The machine learning experiment results for four learning tasks with different cancer types and clinical outcome endpoints are shown in Fig. <ref type="figure" target="#fig_1">3</ref> (more results in Supplementary Fig. <ref type="figure" target="#fig_2">4</ref>).</s><s xml:id="_r8v9DxQ">We used threefold cross-validation and performed 20 independent runs for each experiment using different random partitions of training and testing data to assess machine learning model performance.</s><s xml:id="_Hf24DQv">The median AUROC of the six experiments are denoted as A Mixture0 , A Mixture1 , A Mixture2 , A Independent1 , A Independent2 , and A Transfer .</s><s xml:id="_dBaU9Mr">The results of these experiments showed a consistent pattern:</s></p><p xml:id="_PrZy5rz"><s xml:id="_gTBKuZx">(1) Both mixture learning and independent learning schemes produced models with relatively high and stable performance  for the EA group but low and unstable performance for the data-disadvantaged ethnic group (AA).</s><s xml:id="_cNGNkUV">We defined the performance disparity gap as G ¼ AUROC EA À AUROC AA , where</s></p><formula xml:id="formula_1">AUROC EA ¼ ðA Mixture1 þ A Independent1 Þ=2,<label>and</label></formula><formula xml:id="formula_2">AUROC AA ¼ ðA Mixture2 þ A Independent2 Þ=2.</formula><p xml:id="_dEVpdtA"><s xml:id="_8HuGYvp">G is represented by the distance between the blue and red dash lines in Fig. <ref type="figure" target="#fig_1">3</ref> and Supplementary Fig. <ref type="figure" target="#fig_2">4</ref>.</s></p><p xml:id="_VuYpTTd"><s xml:id="_XMFx6y4">(2) The transfer learning scheme produced models with improved performance for the data-disadvantaged AA group, and thus reduced the model performance gap.</s><s xml:id="_paHU8up">The reduced model performance disparity gap is G ¼ AUROC EA À A Transfer , which is represented by the distance between the blue and green dash lines in Fig. <ref type="figure" target="#fig_1">3</ref> and Supplementary Fig. <ref type="figure" target="#fig_2">4</ref>.</s></p><p xml:id="_cuwhbeZ"><s xml:id="_WfDFs6r">Among the 224 learning tasks, 142 had a performance gap G &gt; 0.05 and 88.7% (125/142) of these performance gaps were reduced by transfer learning.</s></p><p xml:id="_THwY36f"><s xml:id="_qRa4kXH">We also performed the machine learning experiments on two additional learning tasks that involved either another ethnic group or non-TCGA data: (1) Stomach Adenocarcinoma (STAD)-EAA/EA-PFI-2YR assembled using the TCGA STAD data of EAA and EA patients; and (2) MM-AA/EA-mRNA-OS-3YR assembled using the MMRF CoMMpass 27 data of AA and EA patients (Supplementary Data 1).</s><s xml:id="_AeU4E33">For both learning tasks, machine learning experiments showed the same pattern of performance as described above (Supplementary Fig. <ref type="figure" target="#fig_2">4a</ref>, <ref type="figure">b</ref>).</s></p><p xml:id="_S3Begkk"><s xml:id="_q9dwaPM">Key factors underlying ethnic disparities in machine learning model performance.</s><s xml:id="_bjmSJvh">A machine learning task T ¼ X ; Y; f : X !</s><s xml:id="_CxCFn4M">Y f g consists of a feature space X , a label space Y, and a predictive function f learned from feature-label pairs.</s><s xml:id="_uVzWaT5">From a probabilistic perspective, f can be written as 13 P(Y|X), where X 2 X, and Y 2 Y.</s><s xml:id="_SQNEeVu">It is generally assumed that each feature-label pair is drawn from a single distribution 30 P(X, Y).</s><s xml:id="_AbkPejJ">However, this assumption needs to be tested for multiethnic omics data.</s><s xml:id="_C2jZNxG">Given P X; Y ð Þ¼P YjX ð ÞPðXÞ, both marginal distribution P(X) and the conditional distribution P(Y|X) may contribute to the data distribution discrepancy among ethnic groups.</s><s xml:id="_7KGGbwT">We used t-test to identify differentially expressed mRNAs or proteins between the AA and EA groups.</s><s xml:id="_dAPkMz7">The median percentage of differentially expressed mRNA or protein features in the 224 learning tasks was 10%, and 70% of the learning tasks had at least 5% differentially expressed mRNA or protein features (Supplementary Fig. <ref type="figure" target="#fig_1">3b</ref>).</s><s xml:id="_XHUUBu6">We used logistic regression to model the conditional distribution f = P(Y|X), and calculated the Pearson correlation coefficient between the logistic regression parameters for the AA and EA groups.</s><s xml:id="_GTszNVn">The Pearson correlation coefficients ranged from -0.14 to 0.26 in the learning tasks, with a median of 0.04 (Supplementary Fig. <ref type="figure" target="#fig_1">3c</ref>).</s><s xml:id="_6V2egP7">These results indicate that various degrees of marginal and conditional distribution discrepancies between the AA and EA groups exist in most of the 224 learning tasks.</s></p><p xml:id="_uk9bDvs"><s xml:id="_UukFbzF">We hypothesized that the data inequality represented by cohort ethnic composition and data distribution discrepancy between ethnic groups are the key factors underlying the ethnic disparity in machine learning model performance and that both factors can be addressed by transfer learning.</s><s xml:id="_gg95sgP">To test this hypothesis, we performed the six machine learning experiments (Table <ref type="table" target="#tab_1">1</ref>) on synthetic data generated using a mathematical model whose parameters represent these hypothetical key factors (Methods).</s><s xml:id="_DCvBrFK">Synthetic Data 1 was generated using parameters estimated from the data for the learning task PanGyn-AA/EA-mRNA-DFI-5YR (Fig. <ref type="figure" target="#fig_1">3d</ref>), which simulated data inequality and distribution discrepancy between the ethnic groups in the real data (Table <ref type="table" target="#tab_2">2</ref>).</s><s xml:id="_DD4hGPk">For this synthetic dataset, the six machine learning experiments showed a performance pattern (Fig. <ref type="figure" target="#fig_2">4a</ref>) similar to that of the real data (Fig. <ref type="figure" target="#fig_1">3</ref>), which was characterized by performance gaps from the mixture and independent learning schemes and by transfer learning reduction of the performance gaps.</s><s xml:id="_F387Vev">Synthetic Data 2 has no distribution difference between the two ethnic groups (Table <ref type="table" target="#tab_2">2</ref>).</s><s xml:id="_KUy8Jmt">For this dataset, there is no performance gap from the mixture learning scheme, however, the performance gap from the independent learning scheme remains (Fig. <ref type="figure" target="#fig_2">4b</ref>).</s><s xml:id="_XCNpRuy">Synthetic Data 3 has equal numbers of cases from the two ethnic groups (no data inequality) but has a distribution discrepancy between the two ethnic groups.</s><s xml:id="_6y2DTE7">Synthetic Data 4 has equal numbers of cases from the two ethnic groups (no data inequality) and does not have a distribution difference between the two ethnic groups.</s><s xml:id="_UvbAATW">For these two datasets, there is no significant performance gap from any learning scheme (Fig. <ref type="figure" target="#fig_2">4c</ref>, <ref type="figure">d</ref>).</s><s xml:id="_9hRpqMk">These results confirm that the performance gap from the mixture learning scheme is caused by both data inequality and data distribution discrepancy between ethnic groups while the performance gap from the independent learning scheme is caused by inadequate data for the disadvantaged ethnic group, and transfer learning may reduce these performance gaps (Fig. <ref type="figure">1</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_xCwsKUF">Discussion</head><p xml:id="_4vU66Ch"><s xml:id="_uVZtEq5">In this work, we show that the current prevalent scheme for machine learning with multiethnic data, the mixture learning scheme, and its main alternative, the independent learning scheme, tend to generate machine learning models with relatively low performance for data-disadvantaged ethnic groups due to inadequate training data and data distribution discrepancies among ethnic groups.</s><s xml:id="_eDWfwRv">We also find that transfer learning can provide improved machine learning models for datadisadvantaged ethnic groups by leveraging knowledge learned from other groups having more abundant data.</s><s xml:id="_tsVP7Y2">These results indicate that transfer learning can provide an effective approach to reduce health care disparities arising from data inequality among ethnic groups.</s><s xml:id="_92vgn2V">Our simulation experiments show that the machine learning performance disparity gaps would be eliminated completely if there was no data inequality regardless of data distribution discrepancies (Table <ref type="table" target="#tab_2">2</ref>, Fig. <ref type="figure" target="#fig_2">4c</ref>, <ref type="figure">d</ref>).</s><s xml:id="_eZd4n8n">Algorithm-based  methods may mitigate health care disparities arising from longstanding data inequality among ethnic groups; however, the ultimate solution to this challenge would be to increase the number of minority participants in clinical studies.</s><s xml:id="_TBRbUsW">Many factors, including ethnic composition of the cohort, omics data type, cancer type, and clinical outcome endpoint, may potentially affect the performance of multiethnic machine learning schemes.</s><s xml:id="_csr5pZu">At this point, it is not clear how these factors affect the performance of transfer learning and other learning schemes.</s><s xml:id="_EmPv4tB">One possible direction for future research is to discover how the performance pattern of multiethnic learning schemes changes as a function of these factors.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rb4SVxr">Methods</head><p xml:id="_Hc76gDm"><s xml:id="_bpQgZJG">Data source and data preprocessing.</s><s xml:id="_UKzZ3Q6">The TCGA and MMRF CoMMpass data used in this work were downloaded from the Genome Data Commons (GDC, <ref type="url" target="https://gdc.cancer.gov">https://gdc.cancer.gov</ref>).</s><s xml:id="_J3BPYjG">The ethnic groups of TCGA patients were determined based on the genetic ancestry data downloaded from The Cancer Genetic Ancestry Atlas <ref type="bibr" target="#b24">25</ref> (TCGAA, <ref type="url" target="http://52.25.87.215/TCGAA">http://52.25.87.215/TCGAA</ref>).</s><s xml:id="_kvS45V4">The ethnic groups of MMRF CoMMpass patients were based on the self-reported information in the clinical data file downloaded from the GDC Data Portal (<ref type="url" target="https://portal.gdc.cancer.gov">https://portal.gdc.cancer.gov</ref>).</s></p><p xml:id="_k38a86g"><s xml:id="_kM7EHmj">For the TCGA data, we used all the 189 protein expression features, and the 17176 mRNA features without missing values.</s><s xml:id="_t54vUep">We further removed samples with more than 20% missing values.</s><s xml:id="_mknf8TS">We also filtered out samples missing genetic ancestry or clinical endpoint data.</s><s xml:id="_u5Vwtbm">The data matrix was standardized such that each feature has a zero mean and unit standard deviation.</s><s xml:id="_Z3BX8jA">The ANOVA F value for each mRNA was calculated for the training samples to select 200 mRNAs as the input features for machine learning.</s><s xml:id="_VPcZGpW">The feature mask, ANOVA F value, and p values were calculated using the SelectKBest function (with the f_classif score function and k = 200) of the python sklearn package <ref type="bibr" target="#b30">31</ref> .</s><s xml:id="_KPS69Qp">For the MMRF CoMMpass data, we selected 600 mRNA features with the highest mean absolute deviation as the input features for machine learning.</s></p><p xml:id="_dGmaRHY"><s xml:id="_fQ4FT9r">Deep neural network modeling.</s><s xml:id="_KcNBjFx">We used the Lasagne (<ref type="url" target="https://lasagne.readthedocs.io/en/latest/">https://lasagne.  readthedocs.io/en/latest/</ref>)</s><s xml:id="_MYEB8Zm">and Theano python packages (<ref type="url" target="http://deeplearning.net/software/theano/">http://deeplearning.net/  software/theano/</ref>) to train the DNN.</s><s xml:id="_eQ7ksrW">We used a pyramid architecture <ref type="bibr" target="#b31">32</ref> with 6 layers: an input layer with 200 nodes for mRNA features or 189 nodes for protein features, 4 hidden layers including a fully connected layer with 128 nodes followed by a dropout layer <ref type="bibr" target="#b32">33</ref> , a fully connected layer with 64 nodes followed by a dropout layer, and a logistic regression output layer.</s><s xml:id="_VaD6YjT">To fit a DNN model, we used the stochastic gradient descent method with a learning rate of 0.01 (lr = 0.01) to find the weights that minimized a loss function consisting of a cross-entropy and two regularization terms:</s></p><formula xml:id="formula_3">l W ð Þ ¼ À P m i¼1 ðy i log ŷi ð Þ þ 1 À y i ð Þ logð1 À ŷi ÞÞ þ λ 1 W j jþ λ 2 kWk 2 ,</formula><p xml:id="_XYVc96t"><s xml:id="_E889p76">where y i is the observed label of patient i, ŷi is the predicted label for patient i, and W represents the weights in the DNN.</s><s xml:id="_CJNzbDz">Traditional activation functions such as the sigmoid and hyperbolic tangent functions have a gradient vanish problem in training a deep-learning model, which may lead to gradient decreasing quickly and training error propagating to forward layers.</s><s xml:id="_rw5WJHe">Here, we use the ReLU function f(x) = max(0, x), which is widely used in deep learning to avoid the gradient vanish problem.</s><s xml:id="_r4mcqZd">For each dropout layer, we set the dropout probability p = 0.5 to randomly omit half of the weights during the training to reduce the collinearity between feature detectors.</s><s xml:id="_u8avBJk">To speed up the computation, we split the data into multiple mini-batches during training.</s><s xml:id="_mMBvjyf">We used a batch size of 20 (batch_size = 20) for two basic learning schemes (mixture learning and independent learning for the EA group) as there were relatively large numbers of cases available for training.</s><s xml:id="_9RCVAc8">For the independent learning for the AA group, we set the batch size to 4 because the number of cases available for training was limited.</s><s xml:id="_Y6jXask">We set the maximum number of iterations at 100 (max_iter = 100) and applied the Nesterov momemtum 34 method (with momentum = 0.9 for each DNN model) to avoid premature stopping.</s><s xml:id="_pvFu26f">We set the learning rate decay factor at 0.03 (lr_decay = 0.03) for the learning task BRCA-AA/EA-Protein-OS-4YR to avoid nonconvergence during training.</s><s xml:id="_w45NXqz">For all other tasks, we set lr_decay = 0.</s><s xml:id="_wFWpsvX">The two regularization terms λ 1 and λ 2 were set at 0.001.</s></p><p xml:id="_aH7NH43"><s xml:id="_SGt5Mtk">Transfer learning.</s><s xml:id="_npb8xDU">For transfer learning <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref> , we set the EA group as the source domain and the AA or EAA group as the target domain. We ap</s><s xml:id="_qFnCHx4">lied three transfer learning methods to each learning task and selected the best AUROC as the performance index for the transfer learning scheme.</s><s xml:id="_GuNQcGM">The three transfer learning methods include two fine-tuning algorithms and a domain adaptation algorithm:</s></p><p xml:id="_DzAf3jb"><s xml:id="_NTgvAPV">(1) Fine-tuning algorithm 1</s></p><p xml:id="_Y8MfATG"><s xml:id="_RT5jAeQ">Recent studies have shown that fine-turning of DNN often leads to better performance and generalization in transfer learning <ref type="bibr" target="#b37">38</ref> .</s><s xml:id="_qtSPW2b">We first pretrained a DNN model using source domain data: M $ f ðY Source jX Source Þ, which has the same architecture as described in the previous section.</s><s xml:id="_GZXAQrR">The training parameters were set as lr = 0.01, batch_size = 20, p = 0.5, max_iter = 100, and momentum = 0.9.</s><s xml:id="_xGPUabW">After the initial training, the DNN model was then fine-tuned using backpropagation on the target domain data: M′ = fine_tuning (M|Y Target , X Target ), where M′ was the final model.</s><s xml:id="_GbKWdcH">In the fine tuning, the learning rate was set at 0.002 and the batch size was set at 10 as the model had been partially fitted and the target dataset was small.</s><s xml:id="_hNhNYdf">(2) Fine-tuning algorithm 2</s></p><p xml:id="_UcwGFc9"><s xml:id="_uAfETU5">In the second fine-tuning algorithm, the source domain data were used as unlabeled data to pretrain a stacked denoising autoencoder <ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40</ref> .</s><s xml:id="_MKta6XM">The stacked denoising autoencoder has 5 layers: the input layer, a coding layer with 128 nodes, a bottleneck layer with 64 nodes, a decoding layer with 128 nodes, and an output layer that has the same number of nodes with the input layer to reconstruct the input data.</s><s xml:id="_Bkn9qf9">We used the source and target domain data to train the stacked autoencoder with the parameters: learning rate = 0.01, corruption level = 0.3, batch size = 32, and maximum iteration = 500.</s><s xml:id="_FXSfqX2">After pretraining the autoencoder, we removed the decoder and added a dropout layer (with p = 0.5) after each hidden layer, and then added a fine-tune (logistic regression) layer.</s><s xml:id="_786Jgpc">The final DNN model had the same architecture as described in the previous section and was fine-tuned on target domain data with training parameters lr = 0.002, batch_size = 10 and max_iter = 100.</s><s xml:id="_YPbVTgM">(3) Domain adaptation Domain adaptation is a class of transfer learning methods that improve machine learning performance on the target domain by adjusting the distribution discrepancy across domains <ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42</ref> .</s><s xml:id="_PdG754Y">We adopted the Contrastive Classification Semantic Alignment (CCSA) method <ref type="bibr" target="#b42">43</ref> for domain adaptation.</s><s xml:id="_cbkfepY">The CCSA method is particularly suitable for our transfer learning tasks because: (1) this method can significantly improve target domain prediction accuracy by using very few labeled target samples for training; (2)  this method includes semantic alignment in training and therefore can handle the domain discrepancy in both marginal and conditional distributions.</s><s xml:id="_9TmVfh7">To use the CCSA method which calculates the pairwise Euclidean distance between samples in the embedding space, we applied a L2 norm transformation to the features of each patient such that for patient i,</s></p><formula xml:id="formula_4">P n j¼1 x 2 ij ¼ 1,</formula><p xml:id="_BgvGJXu"><s xml:id="_C5zMpsR">where n is the number of features.</s><s xml:id="_BhssycN">The CCSA minimizes the loss function</s></p><formula xml:id="formula_5">L CCSA f ð Þ ¼ ð1 À γÞL C h o g ð Þþ γ L SA h ð Þ þ L S g ð Þ ð</formula><p xml:id="_kHfjUFH"><s xml:id="_N22tAvM">Þ , where f = h o g is the target function, g is an embedding function that maps the input X to an embedding space Z, and h is a function to predict the output labels from Z, L C (f) denotes the classification loss (binary cross-entropy) of function f, L SA (h) refers to the semantic alignment loss of function h, L S (g) is the separation loss of function g, γ is the weight used to balance the classification loss versus the contrastive semantic alignment loss L SA (h) + L S (g), L SA h ð Þ ¼</s></p><p xml:id="_PDJUcHj"><s xml:id="_6z2EyVM">1 n P y s i ¼y t j 1 2 kgðx s i Þ; gðx t j Þk 2 and L S g ð Þ ¼ 1 n P y s i ≠y t j 1 2 maxð0; mÀ kgðx s i Þ; gðx t j ÞkÞ 2</s></p><p xml:id="_veT4Gup"><s xml:id="_fjFuJwy">, k:k is the Euclidean distance, while m is the margin that specifies the separability of the two domain features in the embedding space <ref type="bibr" target="#b42">43</ref> .</s><s xml:id="_dDu8b54">During the training, we set the parameters m = 0.3, momentum = 0.9, batch_size = 20, learning_rate = 0.01, and max_iter = 100.</s><s xml:id="_AY2eCS7">We used one hidden layer with 100 nodes for semantic alignment and added a dropout layer (p = 0.5) after the hidden layer for classification.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_U2HehKg">Differential expression analysis.</head><p xml:id="_CJ2FRDT"><s xml:id="_JvcMsmY">For each learning task, we performed a permutation-based t-test on the input features to select the proteins or mRNAs that were differentially expressed between the AA and EA groups.</s><s xml:id="_jFPSs2y">The mRNAs and proteins with a feature-wise p value &lt; 0.05 were selected as differentially expressed features between the two ethnic groups.</s></p><p xml:id="_TP5gaFn"><s xml:id="_YYJ25Gk">Logistic regression.</s><s xml:id="_4TdBb7g">For each learning task, we fit two multivariate logistic regression models:</s></p><formula xml:id="formula_6">Y AA ¼ 1=ð1 þ e Àβ AA ÁX AA Þ, Y EA ¼ 1=ð1 þ e Àβ EA ÁX EA Þ,</formula><p xml:id="_r6gbyjy"><s xml:id="_q2ry6rB">for the AA group and the EA group, respectively, to calculate the regression parameters for each ethnic group.</s></p><p xml:id="_jbKmefc"><s xml:id="_D5exJMT">Stratified cross-validation and training/testing data for machine learning experiments.</s><s xml:id="_Ah4Y7XS">For each learning task, we applied a threefold stratified crossvalidation <ref type="bibr" target="#b43">44</ref> .</s><s xml:id="_ZFkGsdJ">For mixture learning, samples were stratified by the clinical outcome and genetic ancestry in the process of threefold data splitting.</s><s xml:id="_vJGrF9E">Samples of each fold had the same distribution over clinical outcome classes (positive and negative) and ethnic groups (EA and AA).</s><s xml:id="_uGCE2nr">Both AA and EA samples in the training set were used to train a deep-learning model and the performance of Mixture 0 was measured using the whole testing set, the performance of Mixture 1 was measured on the EA samples in the testing set, and the performance of Mixture 2 was measured on the AA samples in the testing set.</s><s xml:id="_zaVs53t">For Independent learning, EA (Independent 1) and AA (Independent 2) samples were separated and then stratified by the clinical outcome in the threefold data splitting.</s><s xml:id="_tVZjsWQ">The cross-validation was performed for the two ethnic groups separately.</s><s xml:id="_juDAFWw">For transfer learning, EA and AA samples were separated and AA samples were stratified by the clinical outcome (same as Independent 2), and we used all the EA (source domain) samples for initial model training and then used AA training samples for fine-tuning or domain adaptation, and finally, the performance was evaluated on AA testing samples.</s><s xml:id="_wptcdMc">The ethnic compositions for the training and testing data of the six types of machine learning experiments are shown in Table <ref type="table" target="#tab_1">1</ref>.</s></p><p xml:id="_SSZPHMg"><s xml:id="_Mdcd6E8">Machine learning performance evaluation.</s><s xml:id="_JdPBfnT">The main utility of performance metric in this work is to compare the relative performance of multiethnic machine learning schemes.</s><s xml:id="_pKZJHvd">We used the area under ROC curve <ref type="bibr" target="#b44">45</ref> (AUROC) to evaluate performance of machine learning models.</s><s xml:id="_FMRG8hP">Another widely used machine learning performance metric is the area under precision-recall curve <ref type="bibr" target="#b45">46</ref> (AUPR).</s><s xml:id="_tCxmXzZ">It has been mathematically proven that the performance ranks of two models remain same in the ROC space and the PR space <ref type="bibr" target="#b46">47</ref> .</s><s xml:id="_VJaXTQ7">However, linear interpolation in the precision-recall space is problematic, which may lead to inaccurate calculation of AUPR for datasets of small sample sizes <ref type="bibr" target="#b46">47</ref> .</s><s xml:id="_3BUcwHb">AUROC is a more robust metric for evaluating machine learning performance on the minority ethnic groups that have less cases.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_UrwcF7c">Synthetic data generator.</head><p xml:id="_eFP8aJx"><s xml:id="_V6NMsSA">We developed a mathematical model to generate synthetic data for the multiethnic machine learning experiments.</s><s xml:id="_AHjpqPu">The simulated cohort consists of two ethnic groups.</s><s xml:id="_Fr8pvMf">The degree of data inequality is controlled by the parameters: n 1 and n 2 , which represent the numbers of individuals in the two ethnic groups.</s><s xml:id="_qcvDVyN">We used the ssizeRNA package <ref type="bibr" target="#b47">48</ref> to generate the feature matrix x ij .</s><s xml:id="_NMPhT4X">The number of differentially expressed features (n de ) is the parameter controlling marginal distribution (P(X)) discrepancy between the two ethnic groups.</s><s xml:id="_N8e9Fm4">For individual i in ethnic group k, the label y k i was generated using the logistic regression function:</s></p><formula xml:id="formula_7">y k i ¼ 1 if z k i &gt; c k À1 otherwise</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_zAVubPa">&amp;</head><p xml:id="_Tb5GdDm"><s xml:id="_2qjmujv">, where z k i ¼</s></p><formula xml:id="formula_8">1 1þe À P n j¼1 β k j x ij</formula><p xml:id="_4xyr2T4"><s xml:id="_DyJ59Ve">, x ij is the j th feature of individual i, and β k j ϵfÀ1; 1g represents the effect of feature j on the label of ethnic group k, and c k is the threshold for assigning a sample to the positive or negative category.</s><s xml:id="_Nk73y6Z">A pair of β 1 j and β 2 j have four possible combinations representing the difference and similarity of the effect of feature j on the clinical outcome for the patients in the two ethnic groups.</s><s xml:id="_XK2zefe">The number of features associated with each of the four combinations is denoted as n -1,-1 , n -1,1 , n 1,-1 , and n 1,1 respectively.</s><s xml:id="_PW5FA3c">These parameters control the conditional distribution (P(Y|X)) discrepancy between the two ethnic groups.</s><s xml:id="_c7TqDCp">Using this model, we can generate synthetic datasets with or without data inequality and/or distribution discrepancy between two ethnic groups by setting the parameter values.</s><s xml:id="_7GSw9x5">These parameters can also be estimated from a real dataset.</s><s xml:id="_jWM3F3c">For example, we generated Synthetic Data 1 using the parameters estimated from the data for the learning task PanGyn-AA/EA-mRNA-DFI-5YR. We set n 1 and n 2 to be equal to the number of EA and AA patients in the real data, respectively.</s><s xml:id="_CJurBCH">We estimated the parameters n de using permutation-based t-tests (feature-wise p value &lt; 0.05).</s><s xml:id="_BBnsrzX">The total number of features for the learning task PanGyn-AA/EA-mRNA-DFI-5YR was 200.</s><s xml:id="_n2xpwtV">We used multivariate logistic regression to calculate the regression parameters β AA and β EA .</s><s xml:id="_Cv65q5z">We let</s></p><formula xml:id="formula_9">β 1 j ¼ 1 if β EA j &gt; median β EA À Á À1 otherwise &amp; and β 2 j ¼ 1 if β AA j &gt; median β AA À Á À1 otherwise &amp;</formula><p xml:id="_qkPbNce"><s xml:id="_4JeCBTv">, and then calculated n -1,-1 , n -1,1 , n 1,-1 , and n 1,1 .</s><s xml:id="_69xUEnH">The parameters used to generate Synthetic Data 1-4 are shown in Table <ref type="table">3</ref>.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2</head><label>2</label><figDesc><div><p xml:id="_bYWGHuq"><s xml:id="_rXQaMCX">Fig.2Performance index values for the multiethnic machine learning experiments.</s><s xml:id="_5ueXdYv">Each box plot shows the AUROC (area under ROC curve) values for the 224 learning tasks for a machine learning experiment listed in Table1.</s><s xml:id="_4sGJMuH">Each circle represents the mean AUROC of 20 independent runs with different random partitions of training and testing data.</s><s xml:id="_eHNXXx7">The gray color represents performance for the whole cohort, blue represents performance for the EA group, and red represents performance for the AA group.</s><s xml:id="_NDfXbxD">Boxplot elements are: center line, median; box limits, 25 and 75 percentiles; whiskers, the minimum and maximum values.</s><s xml:id="_WXTYECK">The p values were calculated using one-sided Wilcoxon signed-rank test.</s></p></div></figDesc><graphic coords="3,331.21,223.64,216.52,193.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3</head><label>3</label><figDesc><div><p xml:id="_P53bvYX"><s xml:id="_23pjPvU">Fig. 3 Comparison of multiethnic machine learning schemes.</s><s xml:id="_hq2u3Uv">The machine learning tasks are: a GBMLGG-AA/EA-Protein-OS-3YR, b PRAD-AA/EA-mRNA-PFI-3YR, c KIPAN-AA/EA-Protein-DSS-3YR, d PanGyn-AA/EA-mRNA-DFI-5YR. In each panel, the box plots show AUROC values for the six experiments (20 independent runs for each experiment).</s><s xml:id="_vVjFcGr">The red, blue, and green vertical dash lines represent AUROC AA , AUROC EA , and A Transfer respectively.</s><s xml:id="_HrHBvNQ">Box-plot elements are: center line, median; box limits, 25 and 75 percentiles; whiskers, 10-90 percentiles; points, outliers.</s><s xml:id="_NwWmabv">Abbreviations for cancer types are explained in Supplementary Data 1.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc><div><p xml:id="_zSzfqEE"><s xml:id="_HwFAVHQ">Fig. 4 Comparison of multiethnic machine learning schemes on synthetic data.</s><s xml:id="_MgnRGn2">a Synthetic Data 1, b Synthetic Data 2, c Synthetic Data 3, d Synthetic Data 4. We used threefold cross-validation and performed 20 independent runs for each experiment with different random partitions of training and testing data to assess machine learning model performance.</s><s xml:id="_5Zcvw6Z">In each panel, box plots show the AUROC values for the six experiments (20 independent runs for each experiment).</s><s xml:id="_McHy9mE">Box-plot elements are: center line, median; box limits, 25 and 75 percentiles; whiskers, 10-90 percentiles; points, outliers.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="2,81.43,534.50,446.44,133.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc><div><p xml:id="_WWNpAhh"><s xml:id="_Vg4KaXF">The machine learning experiments.</s></p></div></figDesc><table><row><cell cols="2">Multiethnic machine learning scheme Experiment</cell><cell cols="3">Training data ethnic composition Testing data ethnic composition AUROC a</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Median Mean</cell></row><row><cell>Mixture learning</cell><cell>Mixture 0</cell><cell>AA + EA</cell><cell>AA + EA</cell><cell>0.71</cell><cell>0.72</cell></row><row><cell></cell><cell>Mixture 1</cell><cell></cell><cell>EA</cell><cell>0.71</cell><cell>0.73</cell></row><row><cell></cell><cell>Mixture 2</cell><cell></cell><cell>AA</cell><cell>0.68</cell><cell>0.67</cell></row><row><cell>Independent learning</cell><cell>Independent 1</cell><cell>EA</cell><cell>EA</cell><cell>0.70</cell><cell>0.71</cell></row><row><cell></cell><cell>Independent 2</cell><cell>AA</cell><cell>AA</cell><cell>0.59</cell><cell>0.58</cell></row><row><cell>Transfer learning</cell><cell cols="2">Transfer learning EA (source domain)</cell><cell>AA</cell><cell>0.70</cell><cell>0.69</cell></row><row><cell></cell><cell></cell><cell>AA (target domain)</cell><cell></cell><cell></cell><cell></cell></row></table><note xml:id="_F5b3Jde"><p><s xml:id="_vPKyp5g">a Median and mean AUROC (area under ROC curve) for each machine learning experiments on the 224 tasks.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc><div><p xml:id="_G6PJMqp"><s xml:id="_hQ3eGkN">Multiethnic machine learning experiments on synthetic data.</s></p></div></figDesc><table><row><cell cols="2">Synthetic data Data</cell><cell>Distribution</cell><cell cols="2">Machine learning model</cell></row><row><cell></cell><cell>inequality</cell><cell>discrepancy</cell><cell cols="2">performance gap</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Mixture</cell><cell>Independent</cell></row><row><cell></cell><cell></cell><cell></cell><cell>learning</cell><cell>learning</cell></row><row><cell>1</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes a</cell><cell>Yes a</cell></row><row><cell>2</cell><cell>Yes</cell><cell>No</cell><cell>No</cell><cell>Yes a</cell></row><row><cell>3</cell><cell>No</cell><cell>Yes</cell><cell>No</cell><cell>No</cell></row><row><cell>4</cell><cell>N o</cell><cell>N o</cell><cell>N o</cell><cell>N o</cell></row></table><note xml:id="_Jjx9vZ6"><p><s xml:id="_GtGrHQX">a Performance gap &gt; 0.05 (AUROC).</s></p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_QcEX8tu"><s xml:id="_UBF4vu8">NATURE COMMUNICATIONS | (2020) 11:5131 | https://doi.org/10.1038/s41467-020-18918-3</s><s xml:id="_FWwgbJ7">| www.nature.com/naturecommunications</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_9daBzwA"><s xml:id="_CkYxAzW">Reporting summary.</s><s xml:id="_NGDCWDm">Further information on research design is available in the Nature Research Reporting Summary linked to this article.</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_dPqtsgP">Acknowledgements</head><p xml:id="_HT4rrev"><s xml:id="_QjcyarV">This research was supported by the <rs type="funder">Center for Integrative and Translational Genomics at University of Tennessee Health Science Center</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_bcZqVyZ">Data availability</head><p xml:id="_qJNrpzS"><s xml:id="_HFVKSvp">The TCGA and MMRF CoMMpass datasets are publicly available at the Genome Data Commons (<ref type="url" target="https://gdc.cancer.gov/about-data/publications/pancanatlas">https://gdc.cancer.gov/about-data/publications/pancanatlas</ref></s><s xml:id="_c2zE8WQ">and <ref type="url" target="https://gdc.cancer.gov/about-gdc/contributed-genomic-data-cancer-research/foundation-medicine/multiple-myeloma-research-foundation-mmrf">https://gdc.  cancer.gov/about-gdc/contributed-genomic-data-cancer-research/foundation-medicine/  multiple-myeloma-research-foundation-mmrf</ref>).</s><s xml:id="_WKYjXhE">The processed datasets that were used as the input files for the machine learning experiments are available at <ref type="url" target="https://doi.org/10.6084/m9.figshare.12811574">https://doi.org/  10.6084/m9.figshare.12811574</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hAMJXaT">Code availability</head><p xml:id="_XGaMZbA"><s xml:id="_cAsKkFs">Source code is available at <ref type="url" target="https://github.com/ai4pm/TL4HDR">https://github.com/ai4pm/TL4HDR</ref>.</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_QYfH8T9">Competing interests</head><p xml:id="_mVQz5Yd"><s xml:id="_XkXcMGz">The authors declare no competing interests.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cZurAAw">Additional information</head><p xml:id="_MX2yP3h"><s xml:id="_vhSbSPG">Supplementary information is available for this paper at <ref type="url" target="https://doi.org/10.1038/s41467-020-18918-3">https://doi.org/10.1038/s41467- 020-18918-3</ref>.</s></p><p xml:id="_hUgGbau"><s xml:id="_rUd4PRj">Correspondence and requests for materials should be addressed to Y.C.</s></p><p xml:id="_n6VjQHD"><s xml:id="_sWwy42d">Peer review information Nature Communications thanks Brandon Mahal and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</s><s xml:id="_fbNjh2y">Peer reviewer reports are available.</s></p><p xml:id="_FWJgjPp"><s xml:id="_U7atcYS">Reprints and permission information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/reprints</ref></s></p><p xml:id="_w6KH2B9"><s xml:id="_uKz3jrH">Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_kHdpUae">High-performance medicine: the convergence of human and artificial intelligence</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0300-7</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZcMA3qN">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="44" to="56" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Topol, E. J. High-performance medicine: the convergence of human and artificial intelligence. Nat. Med. 25, 44-56 (2019).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_zB9rZYR">Artificial intelligence for precision oncology: beyond patient stratification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Azuaje</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41698-019-0078-1</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NXGcU9k">NPJ Precis. Oncol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Azuaje, F. Artificial intelligence for precision oncology: beyond patient stratification. NPJ Precis. Oncol. 3, 6 (2019).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_CEvzy6h">Machine learning in medicine</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rajkomar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kohane</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejmra1814259</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3upgKcq">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">380</biblScope>
			<biblScope unit="page" from="1347" to="1358" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajkomar, A., Dean, J. &amp; Kohane, I. Machine learning in medicine. N. Engl. J. Med. 380, 1347-1358 (2019).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<idno type="DOI">10.32614/cran.package.tcgaviz</idno>
		<ptr target="https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga" />
		<title level="m" xml:id="_SjkyVUw">The Cancer Genome Atlas Program</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">The Cancer Genome Atlas Program. https://www.cancer.gov/about-nci/ organization/ccg/research/structural-genomics/tcga.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<idno type="DOI">10.1002/pbc.31333</idno>
		<ptr target="https://ocg.cancer.gov/programs/target" />
		<title level="m" xml:id="_YJRZXWk">The Therapeutically Applicable Research to Generate Effective Treatments initiative</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">The Therapeutically Applicable Research to Generate Effective Treatments initiative. https://ocg.cancer.gov/programs/target.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_3zFGZyc">The OncoArray Consortium: a network for understanding the genetic architecture of common</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Amos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_42TFVvh">Cancers</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="126" to="135" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Amos, C. I. et al. The OncoArray Consortium: a network for understanding the genetic architecture of common. Cancers 26, 126-135 (2017).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_JKjttpx">Analysis of racial/ethnic representation in select basic and applied cancer research studies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guerrero</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-018-32264-x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QJw8QCj">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">13978</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Guerrero, S. et al. Analysis of racial/ethnic representation in select basic and applied cancer research studies. Sci. Rep. 8, 13978 (2018).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_4ush3SB">Genetics for all</title>
		<idno type="DOI">10.1038/s41588-019-0394-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TYTzyWF">Nature Genet</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="579" to="579" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Genetics for all. Nature Genet. 51, 579-579 (2019).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_HMtqNJS">Clinical use of current polygenic risk scores may exacerbate health disparities</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_a3XPEhC">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="584" to="591" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Martin, A. R. et al. Clinical use of current polygenic risk scores may exacerbate health disparities. Nat. Genet. 51, 584-591 (2019).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_7emcSKM">Ensuring fairness in machine learning to advance health equity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rajkomar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Howell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_h2jppp4">Ann. Intern. Med</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="866" to="872" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajkomar, A., Hardt, M., Howell, M. D., Corrado, G. &amp; Chin, M. H. Ensuring fairness in machine learning to advance health equity. Ann. Intern. Med. 169, 866-872 (2018).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_Wwpx3k6">A survey of transfer learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TTWvKXX">J. Big Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Weiss, K., Khoshgoftaar, T. M. &amp; Wang, D. A survey of transfer learning. J. Big Data 3, 9 (2016).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_5kRfT5F">A survey on deep transfer learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01424-7_27</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dYUthrc">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="270" to="279" />
		</imprint>
	</monogr>
	<note type="raw_reference">Tan, C. et al. A survey on deep transfer learning. In International Conference on Artificial Neural Networks. 270-279 (Springer, 2018).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_sMNPvbn">A survey on transfer learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1109/tkde.2009.191</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WPHdTZH">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pan, S. J. &amp; Yang, Q. A survey on transfer learning. IEEE Trans. Knowl. Data Eng. 22, 1345-1359 (2010).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_ntMQEZv">The Cancer Genome Atlas: creating lasting value beyond its data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Zenklusen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_d2A94FB">Cell</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="283" to="285" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hutter, C. &amp; Zenklusen, J. C. The Cancer Genome Atlas: creating lasting value beyond its data. Cell 173, 283-285 (2018).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_ZWdR4Yt">Cell-of-origin patterns dominate the molecular classification of 10,000 tumors from 33 types of cancer</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Hoadley</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj.19241/fig-6</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mXycyHa">Cell</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="291" to="304" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hoadley, K. A. et al. Cell-of-origin patterns dominate the molecular classification of 10,000 tumors from 33 types of cancer. Cell 173, 291-304 (2018).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_ypEUfXN">A pathology atlas of the human cancer transcriptome</title>
		<author>
			<persName><forename type="first">M</forename><surname>Uhlen</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aan2507</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WBK29nv">Science</title>
		<imprint>
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="page">2507</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Uhlen, M. et al. A pathology atlas of the human cancer transcriptome. Science 357, eaan2507 (2017).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_EaAXH4w">Machine learning identifies stemness features associated with oncogenic dedifferentiation</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Malta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_x6Rc4RF">Cell</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="338" to="354" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Malta, T. M. et al. Machine learning identifies stemness features associated with oncogenic dedifferentiation. Cell 173, 338-354 (2018).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_PvMYvsM">Machine learning detects pan-cancer ras pathway activation in the cancer genome atlas</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6k4G2vn">Cell Rep</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="172" to="180" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Way, G. P. et al. Machine learning detects pan-cancer ras pathway activation in the cancer genome atlas. Cell Rep. 23, 172-180 (2018).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_AMYCmXF">Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yousefi</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-017-11817-6</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_23hS3x7">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11707</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yousefi, S. et al. Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models. Sci. Rep. 7, 11707 (2017).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_AuqQawH">Cox-nnet: an artificial neural network method for prognosis prediction of high-throughput omics data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">X</forename><surname>Garmire</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1006076</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_d5Sckvk">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1006076</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ching, T., Zhu, X. &amp; Garmire, L. X. Cox-nnet: an artificial neural network method for prognosis prediction of high-throughput omics data. PLoS Comput. Biol. 14, e1006076 (2018).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_VuA8sj9">DNA methylation-based classification of central nervous system tumours</title>
		<author>
			<persName><forename type="first">D</forename><surname>Capper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qXP3sJr">Nature</title>
		<imprint>
			<biblScope unit="volume">555</biblScope>
			<biblScope unit="page" from="469" to="474" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Capper, D. et al. DNA methylation-based classification of central nervous system tumours. Nature 555, 469-474 (2018).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_D3TrdpT">Predicting cancer outcomes from histology and genomics using convolutional networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mobadersany</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1717139115</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_B6yc4wd">Proc. Natl. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="E2970" to="E2979" />
			<date type="published" when="2018">2018</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Mobadersany, P. et al. Predicting cancer outcomes from histology and genomics using convolutional networks. Proc. Natl. Acad. Sci. USA 115, E2970-E2979 (2018).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_TSUxkgZ">Racial representation disparity of population-level genomic sequencing efforts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">N</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QWBDvFy">Stud. Health Technol. Inform</title>
		<imprint>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="page" from="974" to="978" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kim, J. I. E. &amp; Sarkar, I. N. Racial representation disparity of population-level genomic sequencing efforts. Stud. Health Technol. Inform. 264, 974-978 (2019).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_6WTFMNE">The new era of precision population health: insights for the All of Us Research Program and beyond</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Lyles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Obedin-Maliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bibbins-Domingo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aUBEWJJ">J. Transl. Med</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">211</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lyles, C. R., Lunn, M. R., Obedin-Maliver, J. &amp; Bibbins-Domingo, K. The new era of precision population health: insights for the All of Us Research Program and beyond. J. Transl. Med. 16, 211 (2018).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_tcaQZMG">Integrated analysis of genetic ancestry and genomic alterations across cancers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ccell.2018.08.019</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DPw8v4Y">Cancer Cell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="549" to="560" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yuan, J. et al. Integrated analysis of genetic ancestry and genomic alterations across cancers. Cancer Cell 34, 549-560.e9 (2018).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main" xml:id="_fR4a6en">The Cancer Genetic Ancestry Atlas</title>
		<author>
			<persName><surname>Tcgaa</surname></persName>
		</author>
		<ptr target="http://52.25.87.215/TCGAA" />
		<imprint/>
	</monogr>
	<note type="raw_reference">TCGAA. The Cancer Genetic Ancestry Atlas. http://52.25.87.215/TCGAA.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<idno type="DOI">10.1101/2022.09.14.507921</idno>
		<ptr target="https://themmrf.org/we-are-curing-multiple-myeloma/mmrf-commpass-study/" />
		<title level="m" xml:id="_jz9PWsc">The Relating Clinical Outcomes in Multiple Myeloma to Personal Assessment of Genetic Profile</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">The Relating Clinical Outcomes in Multiple Myeloma to Personal Assessment of Genetic Profile. https://themmrf.org/we-are-curing-multiple-myeloma/ mmrf-commpass-study/.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_QJeEvjZ">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature14539</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8dJthUA">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">LeCun, Y., Bengio, Y. &amp; Hinton, G. Deep learning. Nature 521, 436-444 (2015).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_TyS6Upq">An integrated TCGA pan-cancer clinical data resource to drive high-quality survival outcome analytics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1158/1538-7445.am2018-3287</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2aJfh9w">Cell</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="400" to="416" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu, J. et al. An integrated TCGA pan-cancer clinical data resource to drive high-quality survival outcome analytics. Cell 173, 400-416 (2018).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Quionero-Candela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/9780262170055.001.0001</idno>
		<title level="m" xml:id="_gskYK5P">Dataset Shift in Machine Learning</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Quionero-Candela, J., Sugiyama, M., Schwaighofer, A. &amp; Lawrence, N. D. Dataset Shift in Machine Learning (The MIT Press, 2009).</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_a9jWW9G">Scikit-learn: machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PPBJsVm">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pedregosa, F. et al. Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825-2830 (2011).</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_adNPQaN">A pyramidal neural network for visual pattern recognition</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bouzerdoum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VbSn24R">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="329" to="343" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Phung, S. L. &amp; Bouzerdoum, A. A pyramidal neural network for visual pattern recognition. IEEE Trans. Neural Netw. 18, 329-343 (2007).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_8deyCAX">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9jxtVfT">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. &amp; Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. J. Mach. Learn. Res. 15, 1929-1958 (2014).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_3Zw8TbN">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1109/icmlc.2002.1174562</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_eQvxCCU">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
	<note type="raw_reference">Sutskever, I., Martens, J., Dahl, G. &amp; Hinton, G. On the importance of initialization and momentum in deep learning. In International Conference on Machine Learning. 1139-1147 (2013).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_hGrKqUd">MultiPLIER: a transfer learning framework for transcriptomics reveals systemic features of rare disease</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Taroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5fbgmzf">Cell Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="380" to="394" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Taroni, J. N. et al. MultiPLIER: a transfer learning framework for transcriptomics reveals systemic features of rare disease. Cell Syst. 8, 380-394 (2019).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_ZSE295g">Data denoising with transfer learning in single-cell transcriptomics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41592-019-0537-1</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_23EYGjX">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="875" to="878" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang, J. et al. Data denoising with transfer learning in single-cell transcriptomics. Nat. Methods 16, 875-878 (2019).</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_a4PE3pu">Transfer learning for molecular cancer classification using deep neural networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Sevakula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6wZ3ya5">IEEE/ ACM Trans. Comput. Biol. Bioinform</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="2089" to="2100" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sevakula, R. K., Singh, V., Verma, N. K., Kumar, C. &amp; Cui, Y. Transfer learning for molecular cancer classification using deep neural networks. IEEE/ ACM Trans. Comput. Biol. Bioinform. 16, 2089-2100 (2019).</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_N96PD7N">How transferable are features in deep neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_9Ym9eqk">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
	<note type="raw_reference">Yosinski, J., Clune, J., Bengio, Y. &amp; Lipson, H. How transferable are features in deep neural networks? In Advances in Neural Information Processing Systems. 3320-3328 (2014).</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_xzWrhyP">Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DgwWvm7">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y. &amp; Manzagol, P.-A. Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion. J. Mach. Learn. Res. 11, 3371-3408 (2010).</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_kwdCeAj">Layerwise feature selection in Stacked Sparse Auto-Encoder for tumor type prediction</title>
		<author>
			<persName><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Baranwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Sevakula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_9HhgSJm">2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1542" to="1548" />
		</imprint>
	</monogr>
	<note type="raw_reference">Singh, V., Baranwal, N., Sevakula, R. K., Verma, N. K. &amp; Cui, Y. Layerwise feature selection in Stacked Sparse Auto-Encoder for tumor type prediction. In 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 1542-1548 (2016).</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_TUkdbBM">Adversarial discriminative domain adaptation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr.2017.316</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_KWsfT8v">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="7167" to="7176" />
		</imprint>
	</monogr>
	<note type="raw_reference">Tzeng, E., Hoffman, J., Saenko, K. &amp; Darrell, T. Adversarial discriminative domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 7167-7176 (2017).</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_aSWNSCk">Domain adaptation for statistical classifiers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vECVtgB">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="101" to="126" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Daume, H. III &amp; Marcu, D. Domain adaptation for statistical classifiers. J. Artif. Intell. Res. 26, 101-126 (2006).</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_C2ABrYD">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
		<idno type="DOI">10.1109/iccv.2017.609</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_uQUwfxG">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
	<note type="raw_reference">Motiian, S., Piccirilli, M., Adjeroh, D.A. &amp; Doretto, G. Unified deep supervised domain adaptation and generalization. In Proceedings of the IEEE International Conference on Computer Vision. 5715-5725 (2017).</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Olshen</surname></persName>
		</author>
		<title level="m" xml:id="_SYHptF7">Classification and Regression Trees</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Breiman, L., Friedman, J., Stone, C. J. &amp; Olshen, R. A. Classification and Regression Trees (CRC Press, 1984).</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_3c6b2DY">An introduction to ROC analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qg83rTM">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fawcett, T. An introduction to ROC analysis. Pattern Recognit. Lett. 27, 861-874 (2006).</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_X6jvDYb">A critical investigation of recall and precision as measures of retrieval system performance</title>
		<author>
			<persName><forename type="first">V</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bollmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Jung</surname></persName>
		</author>
		<idno type="DOI">10.1145/65943.65945</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ge9nMbU">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="205" to="229" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Raghavan, V., Bollmann, P. &amp; Jung, G. S. A critical investigation of recall and precision as measures of retrieval system performance. ACM Trans. Inf. Syst. 7, 205-229 (1989).</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_RQ7VNCq">The relationship between Precision-Recall and ROC curves</title>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_mc5PFu4">Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting>the 23rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
	<note type="raw_reference">Davis, J. &amp; Goadrich, M. The relationship between Precision-Recall and ROC curves. In Proceedings of the 23rd International Conference on Machine Learning. 233-240 (2006).</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_VzZax5e">Sample size calculation for RNA-Seq experimental design-the ssizeRNA package</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EzvAGw3">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bi, R. &amp; Liu, P. Sample size calculation for RNA-Seq experimental design-the ssizeRNA package. BMC Bioinform. 17, 146 (2016).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
