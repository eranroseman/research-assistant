<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_dR6CTj4">Atrial fibrillation detection via Apple Watch Arterys</title>
				<funder ref="#_jFqMxsb">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000002</idno>
				</funder>
				<funder>
					<orgName type="full">Clinical and Translational Science Award</orgName>
					<orgName type="abbreviated">CTSA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
					<p type="raw">Â© Springer Nature America, Inc. 2019</p>
				</availability>
				<date type="published" when="2019-01-07">7 January 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>7</label> Department of Molecular Medicine , Scripps Research , La Jolla , CA , USA.</note>
								<orgName type="department">Department of Molecular Medicine</orgName>
								<orgName type="institution">Scripps Research</orgName>
								<address>
									<settlement>La Jolla</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_XE4jmJX">Atrial fibrillation detection via Apple Watch Arterys</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-01-07">7 January 2019</date>
						</imprint>
					</monogr>
					<idno type="MD5">47DEE23000B6C61A207ACBA4E1F2ED4B</idno>
					<idno type="DOI">10.1038/s41591-018-0300-7</idno>
					<note type="submission">Received: 16 August 2018; Accepted: 12 November 2018;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T11:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_nacFzgE"><p xml:id="_8TMpsa3"><s xml:id="_pDP552z">edicine is at the crossroad of two major trends.</s><s xml:id="_hW4mX7C">The first is a failed business model, with increasing expenditures and jobs allocated to healthcare, but with deteriorating key outcomes, including reduced life expectancy and high infant, childhood, and maternal mortality in the United States 1,2 .</s><s xml:id="_gdbPSa5">This exemplifies a paradox that is not at all confined to American medicine: investment of more human capital with worse human health outcomes.</s><s xml:id="_dKbMdYj">The second is the generation of data in massive quantities, from sources such as high-resolution medical imaging, biosensors with continuous output of physiologic metrics, genome sequencing, and electronic medical records.</s><s xml:id="_m8zpZnU">The limits on analysis of such data by humans alone have clearly been exceeded, necessitating an increased reliance on machines.</s><s xml:id="_VedAsjn">Accordingly, at the same time that there is more dependence than ever on humans to provide healthcare, algorithms are desperately needed to help.</s><s xml:id="_vBK9Vxu">Yet the integration of human and artificial intelligence (AI) for medicine has barely begun.</s></p><p xml:id="_7ffuxb3"><s xml:id="_HEh9mA5">Looking deeper, there are notable, longstanding deficiencies in healthcare that are responsible for its path of diminishing returns.</s><s xml:id="_xkSeT6W">These include a large number of serious diagnostic errors, mistakes in treatment, an enormous waste of resources, inefficiencies in workflow, inequities, and inadequate time between patients and clinicians <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4</ref> .</s><s xml:id="_JqPepQw">Eager for improvement, leaders in healthcare and computer scientists have asserted that AI might have a role in addressing all of these problems.</s><s xml:id="_yFVrRW6">That might eventually be the case, but researchers are at the starting gate in the use of neural networks to ameliorate the ills of the practice of medicine.</s><s xml:id="_8pcFbAT">In this Review, I have gathered much of the existing base of evidence for the use of AI in medicine, laying out the opportunities and pitfalls.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NTGvZyh">Artificial intelligence for clinicians</head><p xml:id="_YJ87zR4"><s xml:id="_WWVwDM9">Almost every type of clinician, ranging from specialty doctor to paramedic, will be using AI technology, and in particular deep learning, in the future.</s><s xml:id="_9AaGwhY">This largely involved pattern recognition using deep neural networks (DNNs) (Box 1) that can help interpret medical scans, pathology slides, skin lesions, retinal images, electrocardiograms, endoscopy, faces, and vital signs.</s><s xml:id="_ePGvXG6">The neural net interpretation is typically compared with physicians' assessments using a plot of true-positive versus false-positive rates, known as a receiver operating characteristic (ROC), for which the area under the curve (AUC) is used to express the level of accuracy (Box 1).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_42dnx44">Radiology.</head><p xml:id="_hnhdjDr"><s xml:id="_UgQ4tBD">One field that has attracted particular attention for application of AI is radiology 5 .</s><s xml:id="_DXBhvW2">Chest X-rays are the most common type of medical scan, with more than 2 billion performed worldwide per year.</s><s xml:id="_ghZRqPJ">In one study, the accuracy of one algorithm, based on a 121-layer convolutional neural network, in detecting pneumonia in over 112,000 labeled frontal chest X-ray images was compared with that of four radiologists, and the conclusion was that the algorithm outperformed the radiologists.</s><s xml:id="_MUVztXb">However, the algorithm's AUC of 0.76, although somewhat better than that for two previously tested DNN algorithms for chest X-ray interpretation 5 , is far from optimal.</s><s xml:id="_FbZ2JNA">In addition, the test used in this study is not necessarily comparable with the daily tasks of a radiologist, who will diagnose much more than pneumonia in any given scan.</s><s xml:id="_h4d6brk">To further validate the conclusions of this study, a comparison with results from more than four radiologists should be made.</s><s xml:id="_vEkR9Zq">A team at Google used an algorithm that analyzed the same image set as in the previously discussed study to make 14 different diagnoses, resulting in AUC scores that ranged from 0.63 for pneumonia to 0.87 for heart enlargement or a collapsed lung 6 .</s><s xml:id="_qm59qwr">More recently, in another related study, it was shown that a DNN that is currently in use in hospitals in India for interpretation of four different chest X-ray key findings was at least as accurate as four radiologists 7 .</s><s xml:id="_hXMWswV">For the narrower task of detecting cancerous pulmonary nodules on a chest X-ray, a DNN that retrospectively assessed scans from over 34,000 patients achieved a level of accuracy exceeding 17 of 18 radiologists 8 .</s><s xml:id="_XPqJnrU">It can be difficult for emergency room doctors to accurately diagnose wrist fractures, but a DNN led to marked improvement, increasing sensitivity from 81% to 92% and reducing misinterpretation by 47% (ref. <ref type="bibr" target="#b8">9</ref></s><s xml:id="_aGGZMDf">).</s></p><p xml:id="_fp2dWHB"><s xml:id="_b3gnvvn">Similarly, DNNs have been applied across a wide variety of medical scans, including bone films for fractures and estimation of aging <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref> , classification of tuberculosis 13 , and vertebral compression fractures 14 ; computed tomography (CT) scans for lung nodules 15 , liver masses 16 , pancreatic cancer 17 , and coronary calcium score 18 ; brain scans for evidence of hemorrhage 19 , head trauma 20 , and acute referrals 21 ; magnetic resonance imaging 22 ; echocardiograms <ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24</ref> ; and mammographies <ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26</ref> .</s><s xml:id="_5Q87DzZ">A unique imaging-recognition study focusing on the breadth of acute neurologic events, such as stroke or head trauma, was carried out on over 37,000 head CT 3-D scans, which the algorithm analyzed for 13 different anatomical findings versus gold-standard labels (annotated by expert radiologists) and achieved an AUC of 0.73 (ref. <ref type="bibr" target="#b26">27</ref></s><s xml:id="_3sTq2FT">).</s><s xml:id="_U8Ewf4V">A simulated prospective, double-blind, randomized control trial was conducted with real cases from the dataset and showed that the deep-learning algorithm could interpret scans 150 times faster than radiologists (1.2 versus 177 seconds).</s><s xml:id="_kuk9R9x">But the conclusion that the algorithm's diagnostic accuracy in screening acute neurologic scans was poorer than human</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_CXcJtzs">High-performance medicine: the convergence of human and artificial intelligence Eric J. Topol</head><p xml:id="_aGEUjEK"><s xml:id="_7CPDZdU">The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors.</s><s xml:id="_6T3BZJF">In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health.</s><s xml:id="_63EDnx4">The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article.</s><s xml:id="_gCY6VJU">Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient-doctor relationship or facilitate its erosion remains to be seen.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_wmDMpBm">FOCUS | Review ARticle</head><p xml:id="_kEqDX7a"><s xml:id="_SQAhebt">NaTure MedIcINe performance was sobering and indicates that there is much more work to do.</s></p><p xml:id="_xzH6UJt"><s xml:id="_wWmmGu2">For each of these studies, a relatively large number of labeled scans were used for training and subsequent evaluation, with AUCs ranging from 0.99 for hip fracture to 0.84 intracranial bleeding and liver masses to 0.56 for acute neurologic case screening.</s><s xml:id="_7P28q7b">It is not possible to compare DNN accuracy from one study to the next because of marked differences in methodology.</s><s xml:id="_qYqTwXn">Furthermore, ROC and AUC metrics are not necessarily indicative of clinical utility or even the best way to express accuracy of the model's performance <ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29</ref> .</s><s xml:id="_kjEvS4Q">Furthermore, many of these reports still only exist in preprint form and have not appeared in peer-reviewed publications.</s><s xml:id="_DmfURqF">Validation of the performance of an algorithm in terms of its accuracy is not equivalent to demonstrating clinical efficacy.</s><s xml:id="_fcUZHMc">This is what Pearse Keane and I have referred to as the ' AI chasm'-that is, an algorithm with an AUC of 0.99 is not worth very much if it is not proven to improve clinical outcomes <ref type="bibr" target="#b29">30</ref> .</s><s xml:id="_fTKcV7F">Among the studies that have gone through peer review (many of which are summarized in Table <ref type="table">1</ref>), the only prospective validation studies in a real-world setting have been for diabetic retinopathy <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32</ref> , detection of wrist fractures in the emergy room setting <ref type="bibr" target="#b32">33</ref> , histologic breast cancer metastases <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35</ref> , very small colonic polyps <ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37</ref> , and congenital cataracts in a small group of children <ref type="bibr" target="#b37">38</ref> .</s><s xml:id="_ZHxnPEW">The field clearly is far from demonstrating very high and reproducible machine accuracy, let alone clinical utility, for most medical scans and images in the real-world clinical environment (Table <ref type="table">1</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_UwhCtY5">Pathology</head><p xml:id="_9ZkvuMJ"><s xml:id="_7MtVRRH">Pathologists have been much slower at adopting digitization of scans than radiologists <ref type="bibr" target="#b38">39</ref> -they are still not routinely converting glass slides to digital images and use whole-slide imaging (WSI) to enable viewing of an entire tissue sample on a slide.</s><s xml:id="_U6S3Fkt">Marked heterogeneity and inconsistency among pathologists' interpretations of slides has been amply documented, exemplified by a lack of agreement in diagnosis of common types of lung cancer (Î = 0.41-0.46) <ref type="bibr" target="#b39">40</ref></s><s xml:id="_qGU2dqq">.</s><s xml:id="_2UXhAKT">Deep learning of digitized pathology slides offers the potential to improve accuracy and speed of interpretation, as assessed in a few retrospective studies.</s><s xml:id="_jvrHrYV">In a study of WSI of breast cancer, with or without lymph node metastases, that compared the performance of 11 pathologists with that of multiple algorithmic interpretations, the results varied and were affected in part by the length of time that the pathologists had to review the slides <ref type="bibr" target="#b40">41</ref> .</s><s xml:id="_p7aM9jd">Some of the five algorithms performed better than the group of pathologists, who had varying expertise.</s><s xml:id="_QTWMYej">The pathologists were given 129 test slides and had less than 1 minute for review per slide, which likely does not reflect normal workflow.</s><s xml:id="_3zFQW8x">On the other hand, when one expert pathologist had no time limits and took 30 hours to review the same slide set, the results were comparable with the algorithm for detecting noninvasive ductal carcinoma <ref type="bibr" target="#b41">42</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rv6Dmvy">Box 1 | deep learning</head><p xml:id="_VzUTyGC"><s xml:id="_Ye4KKuy">While the roots of AI date back over 80 years from concepts laid out by Alan Turing <ref type="bibr">204,</ref><ref type="bibr">205</ref> and Warren McCulloch and Walter Pitts 206 , it was not until 2012 that the subtype of deep learning was widely accepted as a viable form of AI <ref type="bibr">207</ref> .</s><s xml:id="_zMCSqsy">A deep learning neural network consists of digitized inputs, such as an image or speech, which proceed through multiple layers of connected 'neurons' that progressively detect features, and ultimately provides an output.</s><s xml:id="_w2vvtm9">By analyzing 1.2 million carefully annotated images from over 15 million in the ImageNet database, a DNN achieved, for that point in time, an unprecedented low error rate for automated image classification.</s><s xml:id="_4yRjWBM">That report, along with Google Brain's 10 million images from YouTube videos to accurately detect cats, laid the groundwork for future progress.</s><s xml:id="_nnEmY9m">Within 5 years, in specific large data-labeled test sets, deep-learning algorithms for image recognition surpassed the human accuracy rate <ref type="bibr">208,</ref><ref type="bibr">209</ref> , and, in parallel, suprahuman performance was demonstrated for speech recognition.</s></p><p xml:id="_nBAbYBz"><s xml:id="_g7MzZNK">The basic DNN architecture is like a club sandwich turned on its side, with an input layer, a number of hidden layers ranging from 5 to 1,000, each responding to different features of the image (like shape or edges), and an output layer.</s><s xml:id="_WPX7WPt">The layers are 'neurons,' comprising a neural network, even though there is little support of the notion that these artificial neurons function similarly to human neurons.</s><s xml:id="_97taMsU">A key differentiating feature of deep learning compared with other subtypes of AI is its autodidactic quality; the neural network is not designed by humans, but rather the number of layers (Fig. <ref type="figure">1</ref>) is determined by the data itself.</s><s xml:id="_sKVKs74">Image and speech recognition have primarily used supervised learning, with training from known patterns and labeled input data, commonly referred to as ground truths.</s><s xml:id="_885wBK6">Learning from unknown patterns without labeled input data-unsupervised learning-has very rarely been applied to date.</s><s xml:id="_vpDgzAY">There are many types of DNNs and learning, including convolutional, recurrent, generative adversarial, transfer, reinforcement, representation, and transfer (for review see refs. <ref type="bibr">210,</ref><ref type="bibr">211</ref></s><s xml:id="_YHsMECC">).</s><s xml:id="_tsfayfx">Deep-learning algorithms have been the backbone of computer performance that exceeds human ability in multiple games, including the Atari video game Breakout, the classic game of Go, and Texas Hold' em poker.</s><s xml:id="_wG82FyW">DNNs are largely responsible for the exceptional progress in autonomous cars, which is viewed by most as the pinnacle technological achievement of AI to date.</s><s xml:id="_yws3R6U">Notably, except in the cases of games and self-driving cars, a major limitation to interpretation of claims reporting suprahuman performance of these algorithms is that analytics are performed on previously generated data in silico, not prospectively in real-world clinical conditions.</s><s xml:id="_9Bw4vBc">Furthermore, the lack of large datasets of carefully annotated images has been limiting across various disciplines in medicine.</s><s xml:id="_aAePdV8">Ironically, to compensate for this deficiency, generative adversarial networks have been used to synthetically produce large image datasets at high resolution, including mammograms, skin lesions, echocardiograms, and brain and retina scans, that could be used to help train DNNs <ref type="bibr">[212]</ref><ref type="bibr">[213]</ref><ref type="bibr">[214]</ref><ref type="bibr">[215]</ref><ref type="bibr">[216]</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_3uEYRbV">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_yMMTP8a">Input layer</head><p xml:id="_C9RQNPY"><s xml:id="_wSyc3HJ">Output layer</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GwUyBF9">Hidden layers</head><p xml:id="_EYBkWy3"><s xml:id="_wEC9gMX">Fig.</s></p><p xml:id="_jMznqRg"><s xml:id="_d9rdVTW">1 | A deep neural network, simplified.</s><s xml:id="_Yyxp5q9">Credit: Debbie Maizels/Springer Nature FOCUS | Review ARticle <ref type="url" target="https://doi.org/10.1038/s41591-018-0300-7">https://doi.org/10.1038/s41591-018-0300-7</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cQdCfac">FOCUS | Review ARticle</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_AbppnWR">NaTure MedIcINe</head><p xml:id="_S4mvjNb"><s xml:id="_jXTvqu5">Other studies have assessed deep-learning algorithms for classifying breast cancer <ref type="bibr" target="#b42">43</ref> and lung cancer <ref type="bibr" target="#b39">40</ref> without direct comparison with pathologists.</s><s xml:id="_fAu8FKn">Brain tumors can be challenging to subtype, and machine learning using tumor DNA methylation patterns via sequencing led to markedly improved classification compared with pathologists using traditional histological data <ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45</ref> .</s><s xml:id="_HxHQxHA">DNA methylation generates extensive data and at present is rarely performed in the clinic for classification of tumors, but this study suggests another potential for AI to provide improved diagnostic accuracy in the future.</s><s xml:id="_33UHTjC">A deep-learning algorithm for lung cancer digital pathology slides not only was able to accurately classify tumors, but also was trained to detect the pattern of several specific genomic driver mutations that would not otherwise be discernible by pathologists <ref type="bibr" target="#b32">33</ref> .</s></p><p xml:id="_BdKNE2g"><s xml:id="_GDS8sAB">The first prospective study to test the accuracy of an algorithm classifying digital pathology slides in a real clinical setting was an assessment of the identification of presence of breast cancer micrometastases in slides by six pathologists compared with a DNN (that had been retrospectively validated <ref type="bibr" target="#b33">34</ref> ).</s><s xml:id="_ez6J5wQ">The combination of pathologists and the algorithm led to the best accuracy, and the algorithm markedly sped up the review of slides <ref type="bibr" target="#b34">35</ref> .</s><s xml:id="_zfPEXJG">This study is particularly notable, as the synergy of the combined pathologist and algorithm interpretation was emphasized instead of the pervasive clinician-versus-algorithm comparison.</s><s xml:id="_GagsmV5">Apart from classifying tumors more accurately by data processing, the use of a deep-learning algorithm to sharpen outof-focus images may also prove useful <ref type="bibr" target="#b45">46</ref> .</s><s xml:id="_XCyqHS2">A number of proprietary algorithms for image interpretation have been approved by the Food and Drug Administration (FDA), and the list is expanding rapidly (Table <ref type="table">2</ref>), yet there have been few peer-reviewed publications from most of these companies.</s><s xml:id="_D56Jnnu">In 2018, the FDA published a fast-track approval plan for AI medical algorithms.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9HycJ5g">Dermatology.</head><p xml:id="_jKY9ckD"><s xml:id="_r2QPkjG">For algorithms classifying skin cancer by image analysis, the accuracy of diagnosis of deep-learning networks has been compared with that of dermatologists.</s><s xml:id="_JbScwXB">In a study using a large training dataset of nearly 130,000 photographic and dermascopic digitized images, 21 US board-certified dermatologists were at least matched in performance by an algorithm, which had an AUC of 0.96 for carcinoma <ref type="bibr" target="#b46">47</ref> and of 0.94 for melanoma specifically.</s><s xml:id="_5NbQDP8">Subsequently, the accuracy of melanoma skin cancer diagnosis by a group of 58 international dermatologists was compared with a convolutional neural network; the mean ROCs were 0.79 versus 0.86, respectively, reflecting an improved performance of the algorithm compared with most of the physicians <ref type="bibr" target="#b47">48</ref> .</s><s xml:id="_nWGuMqm">A third study carried out algorithmic assessment of 12 skin diseases, including basal cell carcinoma, squamous cell carcinoma, and melanoma, and compared this with 16 dermatologists, with the algorithm achieving an AUC of 0.96 for melanoma <ref type="bibr" target="#b48">49</ref> .</s><s xml:id="_yDmb7bq">None of these studies were conducted in the clinical setting, in which a doctor would perform physical inspection and shoulder responsibility for making an accurate diagnosis.</s><s xml:id="_cBsK59h">Notwithstanding these concerns, most skin lesions are diagnosed by primary care doctors, and problems with inaccuracy have been underscored; if AI can be reliably shown to simulate experienced dermatologists, that would represent a significant advance.</s></p><p xml:id="_ZpN6gvv"><s xml:id="_a5XZwQs">Ophthalmology.</s><s xml:id="_CPwM3WX">There have been a number of studies comparing performance between algorithms and ophthalmologists in diagnosing</s></p><p xml:id="_CHrsWfH"><s xml:id="_YQQ9Cb2">Table 1 | Peer-reviewed publications of Ai algorithms compared with doctors Specialty images Publication Radiology/ neurology CT head, acute neurological events Titano et al. 27 CT head for brain hemorrhage Arbabshirani et al. 19 CT head for trauma Chilamkurthy et al. 20 CXR for metastatic lung nodules Nam et al. 8 CXR for multiple findings Singh et al. 7 Mammography for breast density Lehman et al. 26 Wrist X-ray* Lindsey et al. 9 Pathology Breast cancer Ehteshami Bejnordi et al. 41 Lung cancer ( + driver mutation) Coudray et al. 33 Brain tumors ( + methylation) Capper et al. 45 Breast cancer metastases* Steiner et al. 35 Breast cancer metastases Liu et al. 34 Dermatology Skin cancers Esteva et al. 47 Melanoma Haenssle et al. 48</s><s xml:id="_PNZdaP5">Skin lesions Han et al. 49 Ophthalmology Diabetic retinopathy Gulshan et al. 51 Diabetic retinopathy* Abramoff et al. 31</s></p><p xml:id="_EnbcRF6"><s xml:id="_xgvbUEk">Diabetic retinopathy* Kanagasingam et al. <ref type="bibr" target="#b31">32</ref> Congenital cataracts Long et al. <ref type="bibr" target="#b37">38</ref> Retinal diseases (OCT) De Fauw et al. <ref type="bibr" target="#b55">56</ref> Macular degeneration Burlina et al. <ref type="bibr" target="#b51">52</ref> Retinopathy of prematurity Brown et al. <ref type="bibr" target="#b59">60</ref> AMD and diabetic retinopathy Kermany et al. <ref type="bibr" target="#b52">53</ref> Gastroenterology Polyps at colonoscopy* Mori et al. <ref type="bibr" target="#b35">36</ref> Polyps at colonoscopy Wang et al. <ref type="bibr" target="#b36">37</ref> Cardiology Echocardiography Madani et al. <ref type="bibr" target="#b22">23</ref> Echocardiography Zhang et al. <ref type="bibr" target="#b23">24</ref> Prospective studies are denoted with an asterisk.</s></p><p xml:id="_E9vPgeG"><s xml:id="_8UHa5GA">Table 2 | FdA Ai approvals are accelerating company FdA Approval indication Apple September 2018 Atrial fibrillation detection Aidoc August 2018 CT brain bleed diagnosis iCAD August 2018 Breast density via mammography Zebra Medical July 2018 Coronary calcium scoring Bay Labs June 2018 Echocardiogram EF determination Neural Analytics May 2018 Device for paramedic stroke diagnosis IDx April 2018 Diabetic retinopathy diagnosis Icometrix April 2018 MRI brain interpretation different eye conditions.</s><s xml:id="_apqRYKm">After training with over 128,000 retinal fundus photographs labeled by 54 ophthalmologists, a neural network was used to assess over 10,000 retinal fundus photographs from more than 5,000 patients for diabetic retinopathy, and the neural network's grading was compared with seven or eight ophthalmologists for all-cause referable diagnoses (moderate or worse retinopathy or macular edema; scale: none, mild, moderate, severe, or proliferative).</s><s xml:id="_zKAUJwF">In two separate validation sets, the AUC was 0.99 (refs. <ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51</ref></s><s xml:id="_8Z7nzgz">).</s><s xml:id="_DTvm2RB">In a study in which retinal fundus photographs were used for the diagnosis of age-related macular degeneration (AMD), the accuracy for DNN algorithms ranged between 88% and 92%, nearly as high as for expert ophthalmologists <ref type="bibr" target="#b51">52</ref> .</s><s xml:id="_rXgnqgf">Performance of a deep-learning algorithm for interpreting retinal optical coherence tomography (OCT) was compared with ophthalmologists for diagnosis of either of the two most common causes of vision loss: diabetic retinopathy or AMD.</s><s xml:id="_3YjWUaf">After the algorithm was trained on a dataset of over 100,000 OCT images, validation was performed in 1,000 of these images, and performance was compared with six ophthalmologists.</s><s xml:id="_A6PFHEM">The algorithm's AUC for OCT-based urgent referral was 0.999 (refs. <ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref></s><s xml:id="_Ph2FyTH">4]<ref type="bibr" target="#b54">[55]</ref> ).</s></p><p xml:id="_rrrG2PT"><s xml:id="_V5G7Sxw">Another deep-learning OCT retinal study went beyond the diagnosis of diabetic retinopathy or macular degeneration.</s><s xml:id="_DyteUWK">A group of 997 patients with a wide range of 50 retinal pathologies was assessed for urgent referral by an algorithm (using two different types of OCT devices that produce 3-D images) and results were compared with those from experts: four retinal specialists and four optometrists, with an AUC for accuracy of urgent referral triage to replace false alarm of 0.992.</s><s xml:id="_aN27Ch9">The algorithm did not miss a single urgent referral case.</s><s xml:id="_86qKjjQ">Notably, the eight clinicians agreed on only 65% of the referral decisions.</s><s xml:id="_sDMYPYD">Errors on the correct referral decision were reduced for both types of clinicians by integrating the fundus photograph and notes on the patient, but the algorithm's error rate (without notes or fundus photographs) of 3.5% was as good or better than all eight experts <ref type="bibr" target="#b55">56</ref> .</s><s xml:id="_EttGnFR">One unique aspect of this study was the transparency of the two neural networks used, one for mapping the eye OCT scans into a tissue schematic and the other for the classifier of eye disease.</s><s xml:id="_MVTeKaW">The user (patient) can watch a video that shows what portions of his or her scan were used to reach the algorithm's conclusions along with the level of confidence it has for the diagnosis.</s><s xml:id="_Mmt4xQD">This sets a new bar for future efforts to unravel the 'black box' of neural networks.</s></p><p xml:id="_YHZSBKJ"><s xml:id="_njcef2S">In a prospective trial conducted in primary care clinics, 900 patients with diabetes but no known retinopathy were assessed by a proprietary system (an imaging device combined with an algorithm) made by IDx (Iowa City, IA) that obtained retinal fundus photographs and OCT and by established reading centers with expertise in interpreting these images <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31</ref> .</s><s xml:id="_N7dn98B">The algorithm was used at primary care clinics up until the clinical trial was autodidactic and thus locked for testing, but it achieved a sensitivity of 87% and specificity of 91% for the 819 patients (91% of the enrolled cohort) with analyzable images.</s><s xml:id="_GQK8s6R">This trial led to FDA approval of the IDx device and algorithm for autonomous detection, that is, without the need for a clinician, of 'more than mild' diabetic retinopathy.</s><s xml:id="_Jg5B6pj">The regulatory oversight in dealing with deep-learning algorithms is tricky because it does not currently allow continued autodidactic functionality but instead necessitates fixing the software to behave like a non-AI diagnostic system <ref type="bibr" target="#b29">30</ref> .</s><s xml:id="_CMxhtbq">Notwithstanding this point along with the unknown extent of uptake of the device, the study represents a milestone as the first prospective assessment of AI in the clinic.</s><s xml:id="_rCqnVCa">The accuracy results are not as good as the aforementioned in silico studies, which should be anticipated.</s><s xml:id="_r3xTKVE">A small prospective real-world assessment of a DNN for diabetic retinopathy in primary care clinics, with eye exams performed by nurses, led to a high falsepositive diagnosis rate <ref type="bibr" target="#b31">32</ref> .</s></p><p xml:id="_7kkGCpx"><s xml:id="_QM7bQJ4">While the studies of retinal OCT and fundus images have thus far focused on eye conditions, recent work suggests that these images can provide a window to the brain for early diagnosis of dementia, including Alzheimer's disease <ref type="bibr" target="#b56">57</ref> .</s></p><p xml:id="_hW5MVTY"><s xml:id="_bwzMPrx">The potential use of retinal photographs also appears to transcend eye diseases per se.</s><s xml:id="_sAN3BwF">Images from over 280,000 patients were assessed by DNN for cardiovascular risk factors, including age, gender, systolic blood pressure, smoking status, hemoglobin A1c, and likelihood of having a major adverse cardiac event, with validation in two independent datasets.</s><s xml:id="_eRNbhyD">The AUC for gender at 0.97 was notable, indicating that the algorithm could identify gender accurately from the retinal photo, but the others were in the range of 0.70, suggesting that there may be a signal that, through further pursuit, could be useful for monitoring patients for control of their risk factors <ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref> .</s></p><p xml:id="_Vhj6PEv"><s xml:id="_6749n4e">Other less common eye conditions that have been assessed by neural networks include congenital cataracts <ref type="bibr" target="#b37">38</ref> and retinopathy of prematurity in newborns <ref type="bibr" target="#b59">60</ref> , both with accuracy comparable with that of eye specialists.</s></p><p xml:id="_4VMMBqB"><s xml:id="_qYzFQRV">Cardiology.</s><s xml:id="_Zg9ZQZg">The major images that cardiologists use in practice are electrocardiograms (ECG) and echocardiograms, both of which have been assessed with DNNs.</s><s xml:id="_wCVD4T8">There is a nearly 40-year history of machine-read ECGs using rules-based algorithms with notable inaccuracy <ref type="bibr" target="#b60">61</ref> .</s><s xml:id="_7rRZRzK">When deep learning was used to diagnose heart attack in a small retrospective dataset of 549 ECGs, a sensitivity of 93% and specificity of 90% were reported, which was comparable with cardiologists <ref type="bibr" target="#b61">62</ref> .</s><s xml:id="_q8muZpT">Over 64,000 one-lead ECGs (from over 29,000 patients) were assessed for arrhythmia by a DNN and six cardiologists, with comparable accuracy across 14 different electrical conduction disturbances <ref type="bibr" target="#b62">63</ref> .</s><s xml:id="_kvMvuyA">For echocardiography, a small set of 267 patient studies (consisting of over 830,000 still images) were classified into 15 standard views (such as apical 4-chamber or subcostal) by a DNN and by cardiologists.</s><s xml:id="_AuPzdV8">The overall accuracy for single still images was 92% for the algorithm and 79% for four board-certified echocardiographers, but this does not reflect the real-world reading of studies, which are in-motion video loops <ref type="bibr" target="#b22">23</ref> .</s><s xml:id="_GdKKMyQ">An even larger retrospective study of over 8,000 echocardiograms showed high accuracy for classification of hypertrophic cardiomyopathy (AUC, 0.93), cardiac amyloid (AUC, 0.87), and pulmonary artery hypertension (AUC, 0.85) <ref type="bibr" target="#b23">24</ref> .</s></p><p xml:id="_k9vTaF2"><s xml:id="_DTZegkC">Gastroenterology.</s><s xml:id="_DvjBS8h">Finding diminutive (&lt; 5 mm) adenomatous or sessile polyps at colonoscopy can be exceedingly difficult for gastroenterologists.</s><s xml:id="_F4JXKQg">The first prospective clinical validation of AI was performed in 325 patients who collectively had 466 tiny polyps, with an accuracy of 94% and negative predictive value of 96% during realtime, routine colonoscopy <ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b63">64</ref> .</s><s xml:id="_UJujS9W">The speed of AI optical diagnosis was 35 seconds, and the algorithm worked equally well for both novice and expert gastroenterologists, without the need for injecting dyes.</s><s xml:id="_4yRYVF7">The findings of enhanced speed and accuracy were replicated in another independent study <ref type="bibr" target="#b36">37</ref> .</s><s xml:id="_yZpnqAx">Such results are thematic: machine vision, at high magnification, can accurately and quickly interpret specific medical images as well as or better than humans.</s></p><p xml:id="_bgqh42k"><s xml:id="_xp5ZHPd">Mental health.</s><s xml:id="_5Mpxs6q">The enormous burden of mental health, such as the 350 million people around the world battling depression <ref type="bibr" target="#b73">74</ref> , is especially noteworthy, as there is potential here for AI to lend support to the affected patients and the vastly insufficient number of clinicians.</s><s xml:id="_yvtaxEU">Various tools that are in development include digital tracking of depression and mood via keyboard interaction, speech, voice, facial recognition, sensors, and use of interactive chatbots <ref type="bibr" target="#b74">[75]</ref><ref type="bibr" target="#b75">[76]</ref><ref type="bibr" target="#b76">[77]</ref><ref type="bibr" target="#b77">[78]</ref><ref type="bibr" target="#b78">[79]</ref><ref type="bibr" target="#b79">[80]</ref> .</s><s xml:id="_dEMfDWh">Facebook posts have been shown to predict the diagnosis of depression later documented in electronic medical records <ref type="bibr" target="#b80">81</ref> .</s></p><p xml:id="_qtwcDQf"><s xml:id="_YceHVpW">Machine learning has been explored for predicting successful antidepressant medication <ref type="bibr" target="#b81">82</ref> , characterizing depression <ref type="bibr" target="#b82">[83]</ref><ref type="bibr" target="#b83">[84]</ref><ref type="bibr" target="#b84">[85]</ref> , predicting suicide <ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b85">[86]</ref><ref type="bibr" target="#b86">[87]</ref><ref type="bibr" target="#b87">[88]</ref> , and predicting bouts of psychosis in schizophrenics <ref type="bibr" target="#b88">89</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_txJrnJK">FOCUS | Review ARticle</head><p xml:id="_7f4hhhv"><s xml:id="_BqgPb6z"><ref type="url" target="https://doi.org/10.1038/s41591-018-0300-7">https://doi.org/10.1038/s41591-018-0300-7</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9mqwNP9">FOCUS | Review ARticle</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_nRC8HNQ">NaTure MedIcINe</head><p xml:id="_SkDkssY"><s xml:id="_AeNXEZY">The use of AI algorithms has been described in many other clinical settings, such as facilitating stroke, autism or electroencephalographic diagnoses for neurologists <ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66</ref> , helping anesthesiologists avoid low oxygenation during surgery <ref type="bibr" target="#b66">67</ref> , diagnosis of stroke or heart attack for paramedics <ref type="bibr" target="#b67">68</ref> , finding suitable clinical trials for oncologists <ref type="bibr" target="#b68">69</ref> , selecting viable embryos for in vitro fertilization <ref type="bibr" target="#b69">70</ref> , help making the diagnosis of a congenital condition via facial recognition <ref type="bibr" target="#b70">71</ref> and pre-empting surgery for patients with breast cancer <ref type="bibr" target="#b71">72</ref> .</s><s xml:id="_JsVrQje">Examples of the breadth of AI applications across human lifespan is shown in Fig. <ref type="figure" target="#fig_0">2</ref>.There is considerable effort across many startups and established tech companies to develop natural language processing to replace the need for keyboards and human scribes for clinic visits <ref type="bibr" target="#b72">73</ref> .</s><s xml:id="_gBynspR">The list of companies active in this space includes Microsoft, Google, Suki, Robin Healthcare, DeepScribe, Tenor.ai,</s><s xml:id="_NYtFNBz">Saykara, Sopris Health, Carevoice, Orbita, Notable, Sensely and Augmedix.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_SHMMsyh">Artificial intelligence and health systems</head><p xml:id="_ZD5QTbr"><s xml:id="_j7uCB3q">Being able to predict key outcomes could, theoretically, make the use of hospital palliative care resources more efficient and precise.</s><s xml:id="_aCqNQjm">For example, if an algorithm could be used to estimate the risk of a patient's hospital readmission that would otherwise be undetectable given the usual clinical criteria for discharge, steps could be taken to avert discharge and attune resources to the underlying issues.</s><s xml:id="_dU7amWN">For a critically ill patient, a very high likelihood of short-term survival might help this patient and their family and doctor make decisions regarding resuscitation, insertion of an endotracheal tube for mechanical ventilation, and other invasive measures.</s><s xml:id="_2q83fZV">Similarly, it is possible that deciding which patients might benefit from palliative care and determining who is at risk of developing sepsis or septic shock could be ameliorated by AI predictive tools.</s><s xml:id="_tR4uvnD">Using electronic health record data, machine-and deep-learning algorithms have been able to predict many important clinical parameters, ranging from Alzheimer's disease to death (Table <ref type="table">3</ref>) <ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b89">[90]</ref><ref type="bibr" target="#b90">[91]</ref><ref type="bibr" target="#b91">[92]</ref><ref type="bibr" target="#b92">[93]</ref><ref type="bibr" target="#b93">[94]</ref><ref type="bibr" target="#b94">[95]</ref><ref type="bibr" target="#b95">[96]</ref><ref type="bibr" target="#b96">[97]</ref><ref type="bibr" target="#b97">[98]</ref><ref type="bibr" target="#b98">[99]</ref><ref type="bibr">[100]</ref><ref type="bibr">[101]</ref><ref type="bibr">[102]</ref><ref type="bibr">[103]</ref><ref type="bibr">[104]</ref><ref type="bibr">[105]</ref><ref type="bibr">[106]</ref><ref type="bibr">[107]</ref> .</s><s xml:id="_Qkfec4J">For example, in a recent study, reinforcement learning was retrospectively carried out on two large datasets to recommend the use of vasopressors, intravenous fluids, and/or medications and the dose of the selected treatment for patients with sepsis; the treatment selected by the ' AI Clinician' was on average reliably more effective than that chosen by humans 108 .</s><s xml:id="_rPejJBc">Both the size of the cohorts studied and the range of AUC accuracy reported have been quite heterogeneous, and all of these reports are retrospective and yet to be validated in the real-world clinical setting.</s><s xml:id="_mEXCFaw">Nevertheless, there are many companies that are already marketing such algorithms, such as Careskore, which is providing health systems with estimated of risk of readmission and mortality based on EHR data 109 .</s><s xml:id="_JV6tSEC">Beyond this issue, there are the differences between the prediction metric for a cohort and an individual prediction metric.</s><s xml:id="_zH5XgBb">If a model's AUC is 0.95, which most would qualify as very accurate, this reflects how good the model is for predicting an outcome, such as death, for the overall cohort.</s><s xml:id="_qG6hJ3r">But most models are essentially classifiers and are not capable of precise prediction at the individual level, so there is still an important dimension of uncertainty.</s></p><p xml:id="_gsYhwKr"><s xml:id="_FGrzYNX">In addition to data from electronic health records, imaging has been integrated to enhance predictive accuracy <ref type="bibr" target="#b97">98</ref> .</s><s xml:id="_QNyvRgT">Multiple studies have attempted to predict biological age <ref type="bibr">110,</ref><ref type="bibr">111</ref> , and this has been shown to best be accomplished using DNA methylation-based biomarkers <ref type="bibr">112</ref> .</s><s xml:id="_xZEc396">With respect to the accuracy of algorithms for prediction of biological age, the incompleteness of data input is noteworthy, since a large proportion of unstructured data-the free text in clinician notes that cannot be ingested from the medical recordhas not been incorporated, and neither have many other modalities such as socioeconomic, behavioral, biologic '-omics' , or physiologic sensor data.</s><s xml:id="_2Y2wda3">Further, concerns have been raised about the potential Table 3 | Selected reports of machine-and deep-learning algorithms to predict clinical outcomes and related parameters Prediction n Auc Publication (reference number) In-hospital mortality, unplanned readmission, prolonged LOS, final discharge diagnosis 216,221 0.93*0.75</s><s xml:id="_fhnHTsz">+ 0.85 # Rajkomar et al. 96 All-cause 3-12 month mortality 221,284 0.93 ^Avati et al. 91 Readmission 1,068 0.78 Shameer et al. 106 Sepsis 230,936 0.67 Horng et al. 102 Septic shock 16,234 0.83 Henry et al. 103 Severe sepsis 203,000 0.85 @ Culliton et al. 104 Clostridium difficile infection 256,732 0.82 ++ Oh et al. 93 Developing diseases 704,587 range Miotto et al. 97 Diagnosis 18,590 0.96 Yang et al. 90 Dementia 76,367 0.91 Cleret de Langavant et al. 92 Alzheimer's Disease ( + amyloid imaging) 273 0.91 Mathotaarachchi et al. 98 Mortality after cancer chemotherapy 26,946 0.94 Elfiky et al. 95 Disease onset for 133 conditions 298,000 range Razavian et al. 105 Suicide 5,543 0.84 Walsh et al. 86 Delirium 18,223 0.68 Wong et al. 100 LOS, length of stay; n, number of patients (training+ validation datasets).</s><s xml:id="_XcrjTzg">For AUC values: *, in-hospital mortality; + , unplanned readmission; #, prolonged LOS; ^, all patients; @, structured + unstructured data; + + , for University of Michigan site.</s><s xml:id="_zTGec24">Review ARticle | FOCUS <ref type="url" target="https://doi.org/10.1038/s41591-018-0300-7">https://doi.org/10.1038/s41591-018-0300-7</ref></s></p><p xml:id="_azGdEet"><s xml:id="_6vTDBfF">Review</s></p><note type="other" xml:id="_qCddjDY">ARticle | FOCUS NaTure MedIcINe</note><p xml:id="_XZxereX"><s xml:id="_DBzpA8a">to overfit data owing to small sample sizes in some instances.</s><s xml:id="_YGGe5yP">It has also been pointed out how essential it is to have Îº -fold cross-validation of a model through successive, mutually exclusive validation datasets, which is missing from most of these publications.</s><s xml:id="_kw99yn3">There is also considerable debate about using AUC as the key performance metric, since it ignores actual probability values and may be particularly misleading in regard to the sensitivity and specificity values that are of clinical interest <ref type="bibr">113</ref> .</s><s xml:id="_W7EWM3u">In summary, it is not yet known how well AI can predict key outcomes in the healthcare setting, and this will not be determined until there is robust validation in prospective, real-world clinical environments, with rigorous statistical methodology and analysis.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_vHJasZe">Machine vision. Machine vision (also known as computer vision)</head><p xml:id="_9dR59rH"><s xml:id="_XBfSkFQ">, which uses data from ambient sensors, is attracting considerable attention in health systems for promoting safety by monitoring such activities as proper clinician handwashing 114 , critically ill patients in the intensive care unit 115 , and risk of falling for patients <ref type="bibr">116</ref> .</s><s xml:id="_tNmTUpc">Weaning patients in the intensive care unit from mechanical ventilation is often haphazard and inefficient; a reinforcement-learning algorithm using machine vision has shown considerable promise in this regard 117 .</s><s xml:id="_YtKHXPN">There are also ongoing efforts to digitize surgery that include machine vision observation of the team and equipment in the operating room and performance of the surgeon; real-time, high-resolution, AI-processed imaging of the relevant anatomy of a patient; and integration of all of a patient's preoperative data, including full medical history, labs, and scans <ref type="bibr">118,</ref><ref type="bibr">119</ref> .</s><s xml:id="_sY2RuvK">Extremely delicate microsurgery, such as that inside the eye, has now been performed with AI assistance 120 .</s><s xml:id="_AhJT5TS">There is considerable promise in markedly reducing the radiation and time requirements for image acquisition and segmentation in preparation for radiotherapy via the use of deep-learning algorithms for image reconstruction 121 and of generative adversarial networks to improve the quality of medical scans.</s><s xml:id="_zE8MCuM">These improvements will, when widely implemented, promote safety, convenience, and lower cost <ref type="bibr">[122]</ref><ref type="bibr">[123]</ref><ref type="bibr">[124]</ref> .</s></p><p xml:id="_xxZQxcp"><s xml:id="_dKnNhau">Wearables.</s><s xml:id="_9gzwmUp">Of the more than $3.5 trillion per year (and rising) expenditures for healthcare in the United States, almost a third is related to hospitals.</s><s xml:id="_Fm6CYCj">With FDA-approved wearable sensors that can continuously monitor all vital signs-including blood pressure, heart rate and rhythm, blood oxygen saturation, respiratory rate, and temperature-there is the potential to preempt a large number of patients being hospitalized in the future.</s><s xml:id="_SYDV3jA">There has not yet been algorithmic development and prospective testing for remote monitoring, but this deserves aggressive pursuit as it could reduce the costs of care without sacrificing convenience and comfort for a patient and family.</s><s xml:id="_CBr7p3u">The reduction of nosocomial infections alone would be an alluring path for promoting safety.</s></p><p xml:id="_ZvssaWV"><s xml:id="_7ukqAwP">Increased efficiencies.</s><s xml:id="_NY5u6T8">It has been estimated that, per day, AI would process over 250 million images for the cost of about $1,000 (ref. <ref type="bibr">125</ref></s><s xml:id="_zbcthys">), representing a staggering hypothetical savings of billions of dollars.</s><s xml:id="_aCgNT3B">Besides the productivity and workflow gains that can be derived from AI-assisted image interpretation and clinician support, there is potential to reduce the workforce for many types of back-office, administrative jobs such as coding and billing, scheduling of operating rooms and clinic appointments, and staffing.</s><s xml:id="_XFE6Trf">At Geisinger Health in Pennsylvania, over 100,000 patients have undergone exome sequencing; the results are provided via an AI chatbot (Clear Genetics), which is well-received by most patients and reduces the need for genetic counselors.</s><s xml:id="_e9hdbMq">This demonstrates how a health system can leverage AI tools to provide complex information without having to rely on expansion of highly trained personnel.</s></p><p xml:id="_ENYsHzc"><s xml:id="_jd4F4Ug">Perhaps the greatest long-term potential of AI in health systems is the development of a massive data infrastructure to support nearest-neighbor analysis, another application of AI used to identify 'digital twins.</s><s xml:id="_J5A7D3q">' If each person's comprehensive biologic, anatomic, physiologic, environmental, socioeconomic, and behavioral data, including treatment and outcomes, were entered, an extraordinary learning system would be created.</s><s xml:id="_VWb79Sq">There have been great benefits derived from jet engine 126 digital twins that use an ultrahigh-fidelity model engine to simulate the flight conditions of a particular jet, but such a model has yet to be completed at any scale for patients, who theoretically could benefit from being informed of the best prevention methods, treatments, and outcomes for various conditions by their relevant twin's data 127 .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_X6e4kM3">Artifical intelligence and patients</head><p xml:id="_xqnwhhr"><s xml:id="_qVWJPte">The work for developing deep-learning algorithms to enable the public to take their healthcare into their own hands has lagged behind that for clinicians and health systems, but there are a few such algorithms that have been FDA-cleared or are in latestage clinical development.</s><s xml:id="_245CUTC">In late 2017, a smartwatch algorithm was FDA-cleared to detect atrial fibrillation 128 , and subsequently in 2018 Apple received FDA approval for their algorithm used with the Apple Watch <ref type="bibr">Series 4 (refs. 129,</ref><ref type="bibr">130</ref> ).</s><s xml:id="_etPUu9e">The photoplethysmography and accelerometer sensors on the watch learn the user's heart rate at rest and with physical activity, and when there is a significant deviation from expected, the user is given a haptic warning to record an ECG via the watch, which is then interpreted by FOCUS | Review ARticle <ref type="url" target="https://doi.org/10.1038/s41591-018-0300-7">https://doi.org/10.1038/s41591-018-0300-7</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_z9gzwe6">FOCUS | Review ARticle</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_pFMHmTQ">NaTure MedIcINe</head><p xml:id="_z95trZj"><s xml:id="_sqpKHM6">an algorithm.</s><s xml:id="_2DH4GUj">There are legitimate concerns that the widescale use of such an algorithm, particularly in the low-risk, young population who wear Apple watches, will lead to a substantial number of false-positive atrial fibrillation diagnoses and prompt unnecessary medical evalautions 131 .</s><s xml:id="_4x5Y74P">In contrast, the deep learning of the ECG pattern on the smartwatch, which can accurately detect whether there is high potassium in the blood, may provide particular usefulness for patients with kidney disease.</s><s xml:id="_wscfZDj">This concept of a 'bloodless' blood potassium level (Fig. <ref type="figure" target="#fig_0">2</ref>) reading via a smartwatch algorithm embodies the prospect of an algorithm able to provide information that was not previously obtainable or discernible without the technology.</s><s xml:id="_FCkur7Y">Smartphone exams with AI are being pursued for a variety of medical diagnostic purposes, including skin lesions and rashes, ear infections, migraine headaches, and retinal diseases such as diabetic retinopathy and age-related macular degeneration.</s><s xml:id="_Wfpwe5T">Some smartphone apps are using AI to monitor medical adherence, such as AiCure (NCT02243670), which has the patient take a selfie video as they swallow their prescribed pill.</s><s xml:id="_8kKPKzk">Other apps use image recognition of food for calorie and nutritional content <ref type="bibr">132</ref> .</s><s xml:id="_wr4cJM6">In what may be seen as an outgrowth of dating apps that use AI nearest-neighbor analysis to find matches, there are now efforts to use the same methodology for matchmaking patients with primary care doctors to engender higher levels of trust <ref type="bibr">133</ref> .</s></p><p xml:id="_yxXfQsG"><s xml:id="_YZtTqsy">One study has recently achieved the continuous sensing of blood-glucose (for 2 weeks) along with assessment of the gut microbiome, physical activity, sleep, medications, all food and beverage intake, and a variety of lab tests <ref type="bibr">[134]</ref><ref type="bibr">[135]</ref><ref type="bibr">[136]</ref> .</s><s xml:id="_BHSPJrk">This multimodal data collection and analysis has led to the ability to predict the glycemic response to specific foods for an individual, a physiologic pattern that is remarkably heterogeneous among people and significantly driven by the gut microbiome.</s><s xml:id="_hRcqtZq">The use of continuous glucose sensors, which now are factory-calibrated, preempting the need for finger-stick glucose calibrations, has shown that post-prandial glucose spikes commonly occur, even in healthy people without diabetes <ref type="bibr">137,</ref><ref type="bibr">138</ref> .</s><s xml:id="_hee7rKW">It remains uncertain whether the glucose spikes indicate a higher risk of developing diabetes, but there are data suggesting this possibility 139 along with mechanistic links to gastrointestinal barrier dysfunction <ref type="bibr">140,</ref><ref type="bibr">141</ref> in experimental models.</s><s xml:id="_FUfwxZD">Nevertheless, the use of AI with multimodal data to guide an individualized diet is a precedent for virtual medical coaching in the future.</s><s xml:id="_6ubpafZ">In the present, simple rules-based algorithms, based upon whether glucose values are rising or falling, are used for glucose management in people with diabetes.</s><s xml:id="_Ce6tnPB">While these have helped avert hypoglycemic episodes 142 , smart algorithms that incorporate an individual's comprehensive data are likely to be far more informative and helpful.</s><s xml:id="_Wuz6TuG">In this manner, most common chronic conditions, such as hypertension, depression, and asthma, could theoretically be better managed with virtual coaching.</s><s xml:id="_wWZXvWF">With the remarkable progress in the accuracy of AI speech recognition and the accompanying soaring popularity of smart speakers, it is easy to envision that this would be performed via a voice platform, with or without an avatar.</s><s xml:id="_sA7Srmx">Eventually, when all of an individual's data and the corpus of medical literature can be incorporated, a holistic, prevention approach would be possible (Fig. <ref type="figure" target="#fig_1">3</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_3zdpnZR">Artificial intelligence and data analysis</head><p xml:id="_CCBwXNm"><s xml:id="_X4EEFu2">While upstream from clinical practice, AI progress in life science has been notably faster, with extensive peer-reviewed publication, an easier path to validation without regulatory oversight, and far more willingness among the scientific community for implementation.</s><s xml:id="_jPjM7An">As the stethoscope is the icon of doctors, the microscope is the icon of scientists.</s><s xml:id="_Sx7zcXA">Using AI, Christiansen et al. <ref type="bibr">143</ref> developed in silico labeling.</s><s xml:id="_dWypmzH">Instead of the routine fluorescent staining of microscopic images, which can harm and kill cells and involves a complex preparation, this machine-learning algorithm predicts the fluorescent labels, ushering in 'image-free' microscopy <ref type="bibr">[143]</ref><ref type="bibr">[144]</ref><ref type="bibr">[145]</ref> .</s><s xml:id="_jymqtAQ">Soon thereafter, <ref type="bibr">Ota et al. 146</ref> reported another image-free flow AI analytic method that they called 'ghost cytometry' to accurately identify rare cells, a capability that was replicated and extended by <ref type="bibr">Nitta et al. 147</ref> with image-activated AI cell sorting.</s><s xml:id="_BdZ4kzE">This use of machine learning addresses the formidable problem of identifying and isolating rare cells by rapid, high-throughput, and accurate sorting on the basis of cell morphology that does not require the use of biomarkers.</s><s xml:id="_WdqDQxU">Besides promoting image-free microcopy and cytometry, deep-learning AI has been used to restore or fix outof-focus images 148 .</s><s xml:id="_SK6huGs">And computer vision has made possible highthroughput assessment of 40-plex proteins and organelles within a single cell <ref type="bibr">149,</ref><ref type="bibr">150</ref> .</s></p><p xml:id="_2W6ufXd"><s xml:id="_WcGvEJW">Another challenge confronted by machine and deep learning has been in the analytics of genomic and other -omics biology datasets.</s><s xml:id="_qSHzAGR">Open-source algorithms have been developed for classifying or analyzing whole-genome sequence pathogenic variants <ref type="bibr">[151]</ref><ref type="bibr">[152]</ref><ref type="bibr">[153]</ref><ref type="bibr">[154]</ref><ref type="bibr">[155]</ref><ref type="bibr">[156]</ref><ref type="bibr">[157]</ref><ref type="bibr">[158]</ref> , somatic cancer mutations 159 , gene-gene interactions 160 , RNA sequencing data 161 , methylation 162 , prediction of protein structure and proteinprotein interactions 163 , the microbiome 164 , and single cells <ref type="bibr">165</ref> .</s><s xml:id="_uN8zm4F">While these reports have generally represented a single -omics approach, there are now multi-omic algorithms being developed 166,167 that integrate the datasets.</s><s xml:id="_daSdT34">The use of genome editing has also been facilitated by algorithmic prediction of CRISPR guide RNA activity 168 and off-target activities <ref type="bibr">169</ref> .</s></p><p xml:id="_ywBgne9"><s xml:id="_jU9Kyaj">Noteworthy is the use of AI tools to enhance understanding of how cancer evolves via application of a transfer-learning algorithm to multiregional tumor-sequencing data 170 and of machine vision for analysis of live cancer cells at single-cell resolution via microfluidic isolation 171 .</s><s xml:id="_eC65U9F">Both of these novel approaches may ultimately be helpful in both risk stratification of patients and guiding therapy.</s></p><p xml:id="_7e2GYeJ"><s xml:id="_JEKGrgM">With the AI descriptor of neural networks, it is not surprising that there is bidirectional inspiration: biological neuroscience impacting AI and vice versa 172 .</s><s xml:id="_DpfpYnx">A couple of examples in Drosophila are noteworthy.</s><s xml:id="_UpDT8XF"><ref type="bibr">Robie et al. 173</ref> took videos of 400,00 flies and used machine learning and machine vision to map phenotype with gene expression and neuroanatomy.</s><s xml:id="_Zr3VMuj">Whole-brain maps were generated for movement, female aggression, and many other traits.</s><s xml:id="_x2z7aHf">In another study, nearest-neighbor analysis was used to understand how odors are sensed by the flies, that is, their smell algorithm <ref type="bibr">174</ref> .</s></p><p xml:id="_YzRhFnV"><s xml:id="_PRtC83X">AI has been used to reconstruct neural circuits, allowing an understanding of connectomics, from electron microscopy 175 .</s><s xml:id="_wUue9Kq">One of the most impressive advances facilitated by AI has been in understanding the human brain's grid cells-which enable perception of the speed and direction of movement of the body, i.e., its place in space <ref type="bibr">176,</ref><ref type="bibr">177</ref> .</s><s xml:id="_eEKxRv5">Reciprocally, neuromorphic computing, or reverse-engineering of the brain to make computer chips, is not only leading to more efficient computing, but also helping Review ARticle | FOCUS <ref type="url" target="https://doi.org/10.1038/s41591-018-0300-7">https://doi.org/10.1038/s41591-018-0300-7</ref></s></p><p xml:id="_8kP2xh2"><s xml:id="_cPQ4CkU">Review</s></p><note type="other" xml:id="_4pvUUbk">ARticle | FOCUS NaTure MedIcINe</note><p xml:id="_C8aNBXm"><s xml:id="_NuCWtyN">researchers understand brain circuitry and build brain-machine interfaces <ref type="bibr">172,</ref><ref type="bibr">178,</ref><ref type="bibr">179</ref> .</s><s xml:id="_kD5daJh">Machine vision tracking of human and animal behavior with a transfer-learning algorithm is yet another example of the progress being made 180 .</s><s xml:id="_Gu6ykkz">Drug discovery is being revamped with the use of AI at many levels, including sophisticated natural language processing searches of the biomedical literature, data mining of millions of molecular structures, designing and making new molecules, predicting offtarget effects and toxicity, predicting the right dose for experimental drugs, and developing cellular assays at a massive scale <ref type="bibr">[181]</ref><ref type="bibr">[182]</ref><ref type="bibr">[183]</ref><ref type="bibr">[184]</ref> .</s><s xml:id="_wmws53V">There is new hope that preclinical animal testing can be reduced via machine-learning prediction of toxicity 185 .</s><s xml:id="_z2ZVBTY">AI cryptography has been used to combine large proprietary pharmaceutical company datasets and discover previously unidentified drug interactions 186 .</s><s xml:id="_DhVdC4M">The story of the University of Cambridge and Manchester's robot 'Eve' and how it autonomously discovered an antimalarial drug that is a constituent of toothpaste has galvanized interest in using AI to accelerate the process, with a long list of start-ups and partnerships with major pharmaceutical firms <ref type="bibr">181,</ref><ref type="bibr">187,</ref><ref type="bibr">188</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7ceQp8e">Limitations and challenges</head><p xml:id="_267VZE6"><s xml:id="_rgM6pyk">Despite all the promises of AI technology, there are formidable obstacles and pitfalls.</s><s xml:id="_wzjjn3C">The state of AI hype has far exceeded the state of AI science, especially when it pertains to validation and readiness for implementation in patient care.</s><s xml:id="_94db2W9">A recent example is IBM Watson Health's cancer AI algorithm (known as Watson for Oncology).</s><s xml:id="_mSwjMvM">Used by hundreds of hospitals around the world for recommending treatments for patients with cancer, the algorithm was based on a small number of synthetic, nonreal cases with very limited input (real data) of oncologists 189 .</s><s xml:id="_nsVr8s2">Many of the actual output recommendations for treatment were shown to be erroneous, such as suggesting the use of bevacizumab in a patient with severe bleeding, which represents an explicit contraindication and 'black box' warning for the drug 189 .</s><s xml:id="_TdHHZ5Z">This example also highlights the potential for major harm to patients, and thus for medical malpractice, by a flawed algorithm.</s><s xml:id="_tH7s8zU">Instead of a single doctor's mistake hurting a patient, the potential for a machine algorithm inducing iatrogenic risk is vast.</s><s xml:id="_78ZFBhq">This is all the more reason that systematic debugging, audit, extensive simulation, and validation, along with prospective scrutiny, are required when an AI algorithm is unleashed in clinical practice.</s><s xml:id="_GmZNbns">It also underscores the need to require more evidence and robust validation to exceed the recent downgrading of FDA regulatory requirements for medical algorithm approval <ref type="bibr">190</ref> .</s></p><p xml:id="_dXcHwWz"><s xml:id="_RJuWTck">There has been much written about the black box of algorithms, and much controversy surrounding this topic <ref type="bibr">[191]</ref><ref type="bibr">[192]</ref><ref type="bibr">[193]</ref> ; especially in the case of DNNs, it may not be possible to understand the determination of output.</s><s xml:id="_DHgDqtd">This opaqueness has led to both demands for explainability, such as the European Union's General Data Protection Regulation requirement for transparency-deconvolution of an algorithm's black box-before an algorithm can be used for patient care 194 .</s><s xml:id="_bEE4kaN">While this debate of whether it is acceptable to use nontransparent algorithms for patient care is unsettled, it is notable that many aspects of the practice of medicine are unexplained, such as prescription of a drug without a known mechanism of action.</s></p><p xml:id="_SQzPu32"><s xml:id="_TFDtBT2">Inequities are one of the most important problems in healthcare today, especially in the United States, which does not provide care for all of its citizens.</s><s xml:id="_zafGPGQ">With the knowledge that low socioeconomic status is a major risk factor for premature mortality 195 , the disproportionate use of AI in the 'haves, ' as opposed to the 'have-nots, ' could widen the present gap in health outcomes.</s><s xml:id="_Vc64sdm">Intertwined with this concern of exacerbating pre-existing inequities is embedded bias present in many algorithms due to lack of inclusion of minorities in datasets.</s><s xml:id="_fygQjXq">Examples are the algorithms in dermatology that diagnose melanoma but lack inclusion of skin color <ref type="bibr" target="#b46">47</ref> and the use</s></p><p xml:id="_RHSXrGz"><s xml:id="_3HwEzze">0 No automation The absence of any assistive features such as adaptive cruise control. 1 Driver assistance Systems that help drivers maintain speed or stay in lane but leave the driver in control. 2 Partial automation The combination of automatic speed and steering control-for example, cruise control and lane keeping.</s><s xml:id="_ExySKKF">Human driver monitors environment Humans and machine doctors 3 Conditional automation Automated systems that drive and monitor the environment but rely on a human driver for backup.</s><s xml:id="_4SkNCen">4 High automation Automated systems that do everythingno human backup required-but only in limited circumstances.</s><s xml:id="_u6xyb6J">5 Full automation The true electronic chauffeur: retains full vehicle control, needs no human backup, and drives in all conditions.</s><s xml:id="_tMEJRMg">System monitors environment 0 1 2 3 4 5 Now Unlikely FOCUS | Review ARticle <ref type="url" target="https://doi.org/10.1038/s41591-018-0300-7">https://doi.org/10.1038/s41591-018-0300-7</ref></s></p><note type="other" xml:id="_VrJ48Pz">FOCUS | Review ARticle NaTure MedIcINe</note><p xml:id="_pERRgGq"><s xml:id="_NycY6Ff">of the corpus of genomic data, which so far has seriously underrepresented minorities 196 .</s><s xml:id="_8DUVHhJ">While there are arguments that algorithm bias is exceeded by human bias 197 , much work is needed to eradicate embedded prejudice and strive for medical research that provides a true representative cross-section of the population.</s></p><p xml:id="_NNgugBS"><s xml:id="_WubdhZE">An overriding issue for the future of AI in medicine rests with how well privacy and security of data can be assured.</s><s xml:id="_NfyvmWw">Given the pervasive problems of hacking and data breaches, there will be little interest in use of algorithms that risk revealing the details of patient medical history 198 .</s><s xml:id="_YYFV2du">Moreover, there is the risk of deliberate hacking of an algorithm to harm people at a large scale, such as overdosing insulin in diabetics or stimulating defibrillators to fire inside the chests of patients with heart disease.</s><s xml:id="_xepMJrt">It is increasingly possible for an individual's identity to be determined by facial recognition or genomic sequence from massive databases, which further impedes protection of privacy.</s><s xml:id="_wqXdbRE">At the same time, the blurring of truth made possible by generative adversarial networks, with seemingly unlimited capacity to manipulate content, could be highly detrimental for health <ref type="bibr">198,</ref><ref type="bibr">199</ref> .</s><s xml:id="_EcQk3ed">New models of health data ownership with rights to the individual, use of highly secure data platforms, and governmental legislation, as has been achieved in Estonia, are needed to counter the looming security issues that will otherwise hold up or ruin the chances for progress in AI for medicine <ref type="bibr">[200]</ref><ref type="bibr">[201]</ref><ref type="bibr">[202]</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_8jbVmWv">Future considerations</head><p xml:id="_Ztjq9Qs"><s xml:id="_nCNPhMu">A key point that I have emphasized throughout this Review it that the narrative of bringing AI to medicine is just beginning.</s><s xml:id="_7cGPHNe">There has been remarkably little prospective validation for tasks that machines could perform to help clinicians or predict clinical outcomes that would be useful for health systems, and even less for patient-centered algorithms.</s><s xml:id="_FdpdUzA">The field is certainly high on promise and relatively low on data and proof.</s><s xml:id="_yR7ZSQE">The risk of faulty algorithms is exponentially higher than that of a single doctor-patient interaction, yet the reward for reducing errors, inefficiencies, and cost is substantial.</s><s xml:id="_furuzfT">Accordingly, there cannot be exceptionalism for AI in medicine-it requires rigorous studies, publication of the results in peer-reviewed journals, and clinical validation in a real-world environment, before roll-out and implementation in patient care (Fig. <ref type="figure" target="#fig_2">4</ref>).</s><s xml:id="_8K2GGj4">With these caveats, it is also important to have reasonable expectations for how AI will ultimately be incorporated.</s><s xml:id="_QvdvVxG">Piercing through today's widespread hype that doctors will be replaced by machines is the analogy of the self-driving car model for reality testing.</s><s xml:id="_8EDPTuV">Most would agree that autonomous cars represent the pinnacle technical achievement of AI to date, but the term autonomous is misleading.</s><s xml:id="_qCJAwJJ">The Society of Automotive Engineers (SAE) has defined five levels of autonomy, with Level 5 indicating full control by the car under all conditions, without any possibility for human backup or taking control of the vehicle (Fig. <ref type="figure" target="#fig_3">5</ref>).</s><s xml:id="_p8Ny3Sq">It is now accepted that this definition of full autonomy is likely to never be attained, as certain ambient or road conditions will prohibit the safe use of such vehicles <ref type="bibr">203</ref> .</s><s xml:id="_meEgeHF">By the same token, medicine will unlikely ever surpass Level 3, a conditional automation, for which humans will indeed be required for oversight of algorithmic interpretation of images and data.</s><s xml:id="_Z7v5Nut">It is hard to imagine very limited human backup across the board of caring for patients (Level 4).</s><s xml:id="_bEEPkay">Human health is too precious-relegating it to machines, except for routine matters with minimal risk, seems especially far-fetched.</s></p><p xml:id="_R8vCVAC"><s xml:id="_7TtKp8x">The excitement that lies ahead, albeit much further along than many have forecasted, is for software that will ingest and meaningfully process massive sets of data quickly, accurately, and inexpensively and for machines that will see and do things that are not humanly possible.</s><s xml:id="_fVTaFmd">This capability will ultimately lay the foundation for high-performance medicine, which is truly data-driven, decompressing our reliance on human resources, and will eventually take us well beyond the sum of the parts of human and machine intelligence.</s><s xml:id="_C4ZU7qJ">This symbiosis will be preceded by the upstream advances that are already being made in biomedical science and discovery, which have a far less tortuous path to be accepted and widely implemented.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 |</head><label>2</label><figDesc><div><p xml:id="_qSD23Tt"><s xml:id="_73eDTfR">Fig. 2 | Examples of Ai applications across the human lifespan.</s><s xml:id="_c78tppR">dx, diagnosis; IVF, in vitro fertilization K + , potassium blood level.</s><s xml:id="_XHvmbmR">Credit: Debbie Maizels/ Springer Nature</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 |</head><label>3</label><figDesc><div><p xml:id="_GSdFSuS"><s xml:id="_3uxt5em">Fig. 3 | The virtual medical coach model with multi-modal data inputs and algorithms to provide individualized guidance.</s><s xml:id="_39Q6qjm">A virtual medical coach that uses comprehensive input from an individual that is deep learned to provide recommendations for preserving the person's health.</s><s xml:id="_uRBGEg2">Credit: Debbie Maizels/ Springer Nature</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 |</head><label>4</label><figDesc><div><p xml:id="_H8RzpZN"><s xml:id="_xYJ8e9n">Fig. 4 | call for due process of Ai studies in medicine.</s><s xml:id="_td4BcHF">The need to publish results in peer-reviewed journals with validation in real-world medicine must be addressed before implementation in patient care can take place.</s><s xml:id="_9nV786P">Credit: Debbie Maizels/Springer Nature</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 |</head><label>5</label><figDesc><div><p xml:id="_XzjeRc3"><s xml:id="_yGxThqF">Fig. 5 | The analogy between self-driving cars and medicine.</s><s xml:id="_bcXzYzQ">Level 5, full automation with no potential for human backup of clinicians, is not the objective.Nor is Level 4, with human backup in very limited conditions.</s><s xml:id="_CtD9Z3r">The goal is for synergy, offsetting functions that machines do best combined with those that are best suited for clinicians.</s><s xml:id="_udWqSAx">Credit: Debbie Maizels/Springer Nature</s></p></div></figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_HyQf5TG"><s xml:id="_kr7mBkv">NATurE MEdiciNE | VOL 25 | JANUARY 2019 | 44-56 | www.nature.com/naturemedicine</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_7Y3Txfa"><s xml:id="_jm7gDXZ">NaTure MedIcINe NATurE MEdiciNE | VOL 25 | JANUARY 2019 | 44-56 | www.nature.com/naturemedicine</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_r6QSshv">Acknowledgements</head><p xml:id="_6HvQj7j"><s xml:id="_xmg3vrm">Funding was provided by the <rs type="funder">Clinical and Translational Science Award (CTSA)</rs> from the <rs type="funder">National Institute of Health (NIH)</rs> grant number <rs type="grantNumber">UL1TR002550</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_jFqMxsb">
					<idno type="grant-number">UL1TR002550</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_xqKY4PM">Additional information</head><p xml:id="_wtH6Tpv"><s xml:id="_P4BPFdC">Reprints and permissions information is available at <ref type="url" target="http://www.nature.com/reprints">www.nature.com/reprints</ref>.</s></p><p xml:id="_pmBRhdD"><s xml:id="_Dyy6hUw">Correspondence should be addressed to E.J.T.</s></p><p xml:id="_wNDdRqz"><s xml:id="_WEnUymU">Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_Ew53PKh">Child mortality in the US and 19 OECD comparator nations: a 50-year time-trend analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Thakrar</surname></persName>
		</author>
		<idno type="DOI">10.1377/hlthaff.2017.0767</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NP9VCpD">Health Aff. (Millwood)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="140" to="149" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thakrar, A. P. et al. Child mortality in the US and 19 OECD comparator nations: a 50-year time-trend analysis. Health Aff. (Millwood) 37, 140-149 (2018).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Roser</surname></persName>
		</author>
		<idno type="DOI">10.1787/888932804339</idno>
		<ptr target="https://ourworldindata.org/the-link-between-life-expectancy-and-health-spending-us-focus" />
		<title level="m" xml:id="_vmjFuac">Link between health spending and life expectancy: US is an outlier</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Our World in Data</note>
	<note type="raw_reference">Roser, M. Link between health spending and life expectancy: US is an outlier. In Our World in Data https://ourworldindata.org/the-link-between- life-expectancy-and-health-spending-us-focus (2017).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_n2U9wAd">The frequency of diagnostic errors in outpatient care: estimations from three large observational studies involving US adult populations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PS4wJES">BMJ Qual. Saf</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="727" to="731" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Singh, H. et al. The frequency of diagnostic errors in outpatient care: estimations from three large observational studies involving US adult populations. BMJ Qual. Saf. 23, 727-731 (2014).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_gmGc9WV">Eliminating waste in US health care</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Berwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Hackbarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FJ8Bhsr">JAMA</title>
		<imprint>
			<biblScope unit="volume">307</biblScope>
			<biblScope unit="page" from="1513" to="1516" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Berwick, D. M. &amp; Hackbarth, A. D. Eliminating waste in US health care. JAMA 307, 1513-1516 (2012).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main" xml:id="_mZmhx5H">ChestX-ray8: hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1705.02315" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Wang, X. et al. ChestX-ray8: hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. Preprint at https://arxiv.org/abs/1705.02315 (2017).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main" xml:id="_8C5pFCZ">Thoracic disease identification and localization with limited supervision</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1711.06373" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Li, Z. et al. Thoracic disease identification and localization with limited supervision. Preprint at https://arxiv.org/abs/1711.06373 (2017).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_wsfVraF">Deep learning in chest radiography: detection of findings and presence of change</title>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0204155</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pek7dcu">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">204155</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Singh, R. et al. Deep learning in chest radiography: detection of findings and presence of change. PLoS ONE 13, e0204155 (2018).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main" xml:id="_QAnXp4k">Development and validation of deep learning-based automatic detection algorithm for malignant pulmonary nodules on chest radiographs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Nam</surname></persName>
		</author>
		<idno type="DOI">10.1148/radiol.2018180237</idno>
		<ptr target="https://doi.org/10.1148/radiol.2018180237" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Radiology</note>
	<note type="raw_reference">Nam, J. G. et al. Development and validation of deep learning-based automatic detection algorithm for malignant pulmonary nodules on chest radiographs. Radiology https://doi.org/10.1148/radiol.2018180237 (2018).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_5rbd8JZ">Deep neural network improves fracture detection by clinicians</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lindsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4SsH6b5">Proc. Natl. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="11591" to="11596" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lindsey, R., et al. Deep neural network improves fracture detection by clinicians. Proc. Natl. Acad. Sci. USA 115, 11591-11596 (2018).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main" xml:id="_bBCynX4">Detecting hip fractures with radiologist-level performance using deep neural networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gale</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1711.06504" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Gale, W. et al. Detecting hip fractures with radiologist-level performance using deep neural networks. Preprint at https://arxiv.org/abs/1711.06504 (2017).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1712.06957" />
		<title level="m" xml:id="_Jngh6rC">MURA dataset: towards radiologist-level abnormality detection in musculoskeletal radiographs</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Rajpurkar, P. MURA dataset: towards radiologist-level abnormality detection in musculoskeletal radiographs. Preprint at https://arxiv.org/ abs/1712.06957 (2017).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_bmPsW9d">Deep learning shows promise for bone age assessment</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Ridley</surname></persName>
		</author>
		<ptr target="https://www.auntminnie.com/index.aspx?sec=log&amp;itemID=119011" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_Ry4u6ZY">Aunt Minnie</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ridley, E. L. Deep learning shows promise for bone age assessment. In Aunt Minnie https://www.auntminnie.com/index.aspx?sec= log&amp;itemID= 119011 (2017).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_wdUTw39">Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lakhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sundaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PN5Uxa6">Radiology</title>
		<imprint>
			<biblScope unit="volume">284</biblScope>
			<biblScope unit="page" from="574" to="582" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lakhani, P. &amp; Sundaram, B. Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks. Radiology 284, 574-582 (2017).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main" xml:id="_jQ7PWAw">Compression fractures detection on CT</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bar</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2249635</idno>
		<ptr target="https://arxiv.org/abs/1706.01671" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Bar, A. et al. Compression fractures detection on CT. Preprint at https://arxiv.org/abs/1706.01671 (2017).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_JcCEZjH">Deep-learning algorithm can stratify lung nodule risk</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Ridley</surname></persName>
		</author>
		<ptr target="https://www.auntminnie.com/index.aspx?sec=rca&amp;sub=rsna_2017&amp;pag=dis&amp;ItemID=119166" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_e9dXBEc">Aunt Minnie</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ridley, E. L. Deep-learning algorithm can stratify lung nodule risk. In Aunt Minnie https://www.auntminnie.com/index.aspx?sec= rca&amp;sub= rsna_2017&amp;pag= dis&amp;ItemID= 119166 (2017).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_hDmQjaG">Deep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced CT: a preliminary study</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yasaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mebV9tY">Radiology</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="887" to="896" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yasaka, K. et al. Deep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced CT: a preliminary study. Radiology 286, 887-896 (2018).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main" xml:id="_f63gY8g">Joint shape representation and classification for detecting PDAC in abdominal CT scans</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1804.10684" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Liu, F. et al. Joint shape representation and classification for detecting PDAC in abdominal CT scans. Preprint at https://arxiv.org/abs/1804.10684 (2018).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_JEduP7M">Fully-convolutional deep-learning based system for coronary calcium score prediction from non-contrast chest CT</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shadmi</surname></persName>
		</author>
		<idno type="DOI">10.1109/isbi.2018.8363515</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_pP8shEh">IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shadmi, R. et al. Fully-convolutional deep-learning based system for coronary calcium score prediction from non-contrast chest CT. In 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018) (IEEE, 2018).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_e94dAym">Advanced machine learning in action: identification of intracranial hemorrhage on computed tomography scans of the head with clinical workflow integration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Arbabshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ucZQTqs">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Arbabshirani, M. R. et al. Advanced machine learning in action: identification of intracranial hemorrhage on computed tomography scans of the head with clinical workflow integration. NPJ Digit. Med. 1, 9 (2018).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_Bk56K5N">Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0140-6736(18)31645-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gpEdV5G">Lancet</title>
		<imprint>
			<biblScope unit="volume">392</biblScope>
			<biblScope unit="page" from="2388" to="2396" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chilamkurthy, S. et al. Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study. Lancet 392, 2388-2396 (2018).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main" xml:id="_Pexnnjf">Development and validation of deep learning algorithms for detection of critical findings in head CT ccans</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1803.05854" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Chilamkurthy, S. et al. Development and validation of deep learning algorithms for detection of critical findings in head CT ccans. Preprint at https://arxiv.org/abs/1803.05854 (2018).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main" xml:id="_rWT4RsK">FastVentricle: cardiac segmentation with ENet</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lieman-Sifry</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1704.04296" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lieman-Sifry, J. et al. FastVentricle: cardiac segmentation with ENet. Preprint at https://arxiv.org/abs/1704.04296 (2017).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_3BvYhv5">Fast and accurate view classification of echocardiograms using deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madani</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-017-0013-1</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rushzeQ">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Madani, A.. et al. Fast and accurate view classification of echocardiograms using deep learning. NPJ Digit. Med. 1, 6 (2018).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_jwF65wQ">Fully automated echocardiogram interpretation in clinical practice feasibility and diagnostic accuracy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SZ25z7m">Circulation</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page" from="1623" to="1635" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhang, J. et al. Fully automated echocardiogram interpretation in clinical practice feasibility and diagnostic accuracy. Circulation 138, 1623-1635 (2018).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_uHgMm6H">AI algorithm matches radiologists in breast screening exams</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Yee</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0300-7</idno>
		<ptr target="https://doi.org/10.1038/s41591-018-0300-7" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_hvAtnpt">Aunt Minnie</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yee, K. M. AI algorithm matches radiologists in breast screening exams. In Aunt Minnie https://www.auntminnie.com/index.aspx?sec= log&amp;itemID= 119385 (2017). Review ARticle | FOCUS https://doi.org/10.1038/s41591-018-0300-7</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main" xml:id="_3qymJjg">Mammographic breast density assessment using deep learning: clinical implementation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Lehman</surname></persName>
		</author>
		<idno type="DOI">10.1148/radiol.2018180694</idno>
		<ptr target="http://doi.org/10.1148/radiol.2018180694" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Radiology</note>
	<note type="raw_reference">Lehman, C. D. et al. Mammographic breast density assessment using deep learning: clinical implementation. Radiology http://doi.org/10.1148/ radiol.2018180694 (2018).</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_JfjdeAy">Automated deep-neural-network surveillance of cranial images for acute neurologic events</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Titano</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0147-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EpsvkgM">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1337" to="1341" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Titano, J. J. et al. Automated deep-neural-network surveillance of cranial images for acute neurologic events. Nat. Med. 24, 1337-1341 (2018).</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_JUCWRqV">The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets</title>
		<author>
			<persName><forename type="first">T</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rehmsmeier</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0118432</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qaQcE5t">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">118432</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Saito, T. &amp; Rehmsmeier, M. The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets. PLoS ONE 10, e0118432 (2015).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_3x2F7W7">AUC: a misleading measure of the performance of predictive distribution models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lobo</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1466-8238.2007.00358.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2yvW3Uh">Glob. Ecol. Biogeogr</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lobo, J. et al. AUC: a misleading measure of the performance of predictive distribution models. Glob. Ecol. Biogeogr. 17, 145-151 (2007).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_wJP8xW5">With an eye to AI and autonomous diagnosis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Keane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-018-0048-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_z69Btxd">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Keane, P. &amp; Topol, E. With an eye to AI and autonomous diagnosis. NPJ Digit. Med. 1, 40 (2018).</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_XMT7DrK">Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abramoff</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-018-0040-6</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WZWUJSS">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Abramoff, M. et al. Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices. NPJ Digit. Med. 1, 39 (2018).</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_shQqEWf">Evaluation of artificial intelligence-based grading of diabetic retinopathy in primary care</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kanagasingam</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamanetworkopen.2018.2665</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XxZWkhu">JAMA Netw. Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">182665</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kanagasingam, Y. et al. Evaluation of artificial intelligence-based grading of diabetic retinopathy in primary care. JAMA Netw. Open 1, e182665 (2018).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_54c87BM">Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Coudray</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0177-5</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DcNSA6f">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1559" to="1567" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Coudray, N. et al. Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning. Nat. Med. 24, 1559-1567 (2018).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_RRND4mr">Artificial intelligence-based breast cancer nodal metastasis detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.5858/arpa.2018-0147-oa</idno>
		<ptr target="https://doi.org/10.5858/arpa.2018-0147-OA" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_8sARRKv">Arch. Pathol. Lab. Med</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu, Y. et al. Artificial intelligence-based breast cancer nodal metastasis detection. Arch. Pathol. Lab. Med. https://doi.org/10.5858/arpa.2018-0147- OA (2018).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_ktdbj7U">Impact of Deep Learning Assistance on the Histopathologic Review of Lymph Nodes for Metastatic Breast Cancer</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Steiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nPvZV82">Am. J. Surg. Pathol</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1636" to="1646" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Steiner, D. F., et al. Impact of Deep Learning Assistance on the Histopathologic Review of Lymph Nodes for Metastatic Breast Cancer. Am. J. Surg. Pathol. 42, 1636-1646 (2018).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_vKQKM9y">Real-time use of artificial intelligence in identification of diminutive polyps during colonoscopy</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mori</surname></persName>
		</author>
		<idno type="DOI">10.7326/m18-0249</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_b4PawW4">Ann. Intern. Med</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="357" to="366" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mori, Y. et al. Real-time use of artificial intelligence in identification of diminutive polyps during colonoscopy. Ann. Intern. Med. 169, 357-366 (2018).</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_t79H3Sm">Development and validation of a deep-learning algorithm for the detection of polyps during colonoscopy</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41551-018-0301-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NFU97wu">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="741" to="748" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang, P. et al. Development and validation of a deep-learning algorithm for the detection of polyps during colonoscopy. Nat. Biomed. Eng. 2, 741-748 (2018).</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_EAaG2KX">An artificial intelligence platform for the multihospital collaborative management of congenital cataracts</title>
		<author>
			<persName><forename type="first">E</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zJsJBCU">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Long, E. et al. An artificial intelligence platform for the multihospital collaborative management of congenital cataracts. Nat. Biomed. Eng. 1, 1-8 (2017).</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_CRsFamM">Not just digital pathology, intelligent digital pathology</title>
		<author>
			<persName><forename type="first">B</forename><surname>Acs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Rimm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_b9FnEty">JAMA Oncol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="403" to="404" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Acs, B. &amp; Rimm, D. L. Not just digital pathology, intelligent digital pathology. JAMA Oncol. 4, 403-404 (2018).</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_HWe9HuH">Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KMeGy9k">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12474</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yu, K. H. et al. Predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features. Nat. Commun. 7, 12474 (2016).</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_8qeQFNM">Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ehteshami Bejnordi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aVakHjz">JAMA</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="page" from="2199" to="2210" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ehteshami Bejnordi, B. et al. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. JAMA 318, 2199-2210 (2017).</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_JJJ9ZED">Deep learning algorithms for detection of lymph node metastases from breast cancer: helping artificial intelligence be seen</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Golden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_x7SuUU8">JAMA</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="page" from="2184" to="2186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Golden, J. A. Deep learning algorithms for detection of lymph node metastases from breast cancer: helping artificial intelligence be seen. JAMA 318, 2184-2186 (2017).</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_wxzqzwK">Accurate and reproducible invasive breast cancer detection in whole-slide images: a deep learning approach for quantifying tumor extent</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cruz-Roa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tSVV7YG">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">46450</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cruz-Roa, A. et al. Accurate and reproducible invasive breast cancer detection in whole-slide images: a deep learning approach for quantifying tumor extent. Sci. Rep. 7, 46450 (2017).</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_3Xfr8Xe">Machine learning classifies cancer</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yip</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-018-02881-7</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NBHFBqb">Nature</title>
		<imprint>
			<biblScope unit="volume">555</biblScope>
			<biblScope unit="page" from="446" to="447" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wong, D. &amp; Yip, S. Machine learning classifies cancer. Nature 555, 446-447 (2018).</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_ZQnSDfD">DNA methylation-based classification of central nervous system tumours</title>
		<author>
			<persName><forename type="first">D</forename><surname>Capper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_twGmDEY">Nature</title>
		<imprint>
			<biblScope unit="volume">555</biblScope>
			<biblScope unit="page" from="469" to="474" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Capper, D. et al. DNA methylation-based classification of central nervous system tumours. Nature 555, 469-474 (2018).</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_RGpFCnr">Assessing microscope image focus quality with deep learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-018-2087-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vDtNu55">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">77</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang, S. J. et al. Assessing microscope image focus quality with deep learning. BMC Bioinformatics 19, 77 (2018).</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_Mj75H45">Dermatologist-level classification of skin cancer with deep neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature21056</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zDXwhTM">Nature</title>
		<imprint>
			<biblScope unit="volume">542</biblScope>
			<biblScope unit="page" from="115" to="118" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115-118 (2017).</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_A9Er6MJ">Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Haenssle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_J3FeAjD">Ann. Oncol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1836" to="1842" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Haenssle, H. A. et al. Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists. Ann. Oncol. 29, 1836-1842 (2018).</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_MVeb8H8">Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jid.2018.01.028</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_f4YN9gg">J. Invest. Dermatol</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page" from="1529" to="1538" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Han, S. S. et al. Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm. J. Invest. Dermatol. 138, 1529-1538 (2018).</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_HewDQGb">Artificial intelligence with deep learning technology looks into diabetic retinopathy screening</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Bressler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_T2uCrFF">JAMA</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page" from="2366" to="2367" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wong, T. Y. &amp; Bressler, N. M. Artificial intelligence with deep learning technology looks into diabetic retinopathy screening. JAMA 316, 2366-2367 (2016).</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_USRvW7f">Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2016.17216</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kMbxqrj">JAMA</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gulshan, V. et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA 316, 2402-2410 (2016).</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_4Fehxnk">Automated grading of age-related macular degeneration from color fundus images using deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Burlina</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamaophthalmol.2017.3782</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Av8uHgz">JAMA Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="1170" to="1176" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Burlina, P. M. et al. Automated grading of age-related macular degeneration from color fundus images using deep convolutional neural networks. JAMA Ophthalmol. 135, 1170-1176 (2017).</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_qR5vGH9">Identifying medical diagnoses and treatable diseases by image-based deep learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Kermany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZK8ucAZ">Cell</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page">1129</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kermany, D. S. et al. Identifying medical diagnoses and treatable diseases by image-based deep learning. Cell 172, 1122-1131.e1129 (2018).</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_wsEHAE5">AI for medical imaging goes deep</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S W</forename><surname>Ting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_e4hNW6C">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="539" to="540" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ting, D. S. W. et al. AI for medical imaging goes deep. Nat. Med. 24, 539-540 (2018).</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_tTzXYBk">Learning from everyday images enables expert-like diagnosis of retinal diseases</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rampasek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldenberg</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cell.2018.02.013</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hHY7xWp">Cell</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="893" to="895" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rampasek, L. &amp; Goldenberg, A. Learning from everyday images enables expert-like diagnosis of retinal diseases. Cell 172, 893-895 (2018).</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_7zSAAVP">Clinically applicable deep learning for diagnosis and referral in retinal disease</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Fauw</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0107-6</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9TmmrDp">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1342" to="1350" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">De Fauw, J. et al. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat. Med. 24, 1342-1350 (2018).</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_yJXKtjK">Association of retinal neurodegeneration on optical coherence tomography with dementia: a population-based study</title>
		<author>
			<persName><forename type="first">U</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ThpuK8F">JAMA Neurol</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="1256" to="1263" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mutlu, U. et al. Association of retinal neurodegeneration on optical coherence tomography with dementia: a population-based study. JAMA Neurol. 75, 1256-1263 (2018).</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main" xml:id="_aKUypCK">Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poplin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BFp9GWr">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="158" to="164" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Poplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning. Nat. Biomed. Eng. 2, 158-164 (2018).</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_PJ7P6b8">All eyes are on AI</title>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CcgXcW5">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">All eyes are on AI. Nat. Biomed. Eng. 2, 139 (2018).</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main" xml:id="_4XuvR8K">Automated diagnosis of plus disease in retinopathy of prematurity using deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vPsqyKA">JAMA Ophthalmol</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="803" to="810" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brown, J. M. et al. Automated diagnosis of plus disease in retinopathy of prematurity using deep convolutional neural networks. JAMA Ophthalmol. 136, 803-810 (2018).</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_KVeZMFX">The diagnostic performance of computer programs for the interpretation of electrocardiograms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Willems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HPDQqFA">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">325</biblScope>
			<biblScope unit="page" from="1767" to="1773" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Willems, J. et al. The diagnostic performance of computer programs for the interpretation of electrocardiograms. N. Engl. J. Med. 325, 1767-1773 (1991).</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main" xml:id="_qyUtFTC">Detecting and interpreting myocardial infarctions using fully convolutional neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Strodthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strodthoff</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1806.07385" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Strodthoff, N. &amp; Strodthoff, C. Detecting and interpreting myocardial infarctions using fully convolutional neural networks. Preprint at https://arxiv.org/abs/1806.07385 (2018).</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main" xml:id="_rYdWxNk">Cardiologist-level arrhythmia detection with convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1707.01836" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Rajpurkar, P. et al. Cardiologist-level arrhythmia detection with convolutional neural networks. Preprint at https://arxiv.org/abs/1707.01836 (2017).</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main" xml:id="_HA6NB87">Making colonoscopy smarter with standardized computer-aided diagnosis</title>
		<author>
			<persName><forename type="first">Ã</forename><surname>Holme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Aabakken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qpAdXXa">Ann. Intern. Med</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="409" to="410" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Holme, Ã. &amp; Aabakken, L. Making colonoscopy smarter with standardized computer-aided diagnosis Ann. Intern. Med. 169, 409-410 (2018).</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_QwQvtD6">FDA approves stroke-detecting AI software</title>
		<author>
			<persName><forename type="first">J</forename><surname>Petrone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Nvzrzn4">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">290</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Petrone, J. FDA approves stroke-detecting AI software. Nat. Biotechnol. 36, 290 (2018).</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main" xml:id="_2R9sY8y">AI could make detecting autism easier</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><surname>Spectrum</surname></persName>
		</author>
		<ptr target="https://www.theatlantic.com/technology/archive/2018/07/ai-autism-diagnosis-screening-bottleneck/564890/" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_9BqGdFg">The Atlantic</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hsu, J. &amp; Spectrum. AI could make detecting autism easier. In The Atlantic https://www.theatlantic.com/technology/archive/2018/07/ai-autism- diagnosis-screening-bottleneck/564890/ (2018).</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main" xml:id="_dVcJUH6">Explainable machine-learning predictions for the prevention of hypoxaemia during surgery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lundberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aDSW2jV">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="749" to="760" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lundberg, S. et al. Explainable machine-learning predictions for the prevention of hypoxaemia during surgery. Nat. Biomed. Eng. 2, 749-760 (2018).</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Peters</surname></persName>
		</author>
		<ptr target="https://www.fastcompany.com/40515740/having-a-heart-attack-this-ai-helps-emergency-dispatchers-find-out" />
		<title level="m" xml:id="_YbkS26p">Having a heart attack? This AI helps emergency dispatchers find out</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Fast Company</note>
	<note type="raw_reference">Peters, A. Having a heart attack? This AI helps emergency dispatchers find out. In Fast Company https://www.fastcompany.com/40515740/having-a- heart-attack-this-ai-helps-emergency-dispatchers-find-out (2018).</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_bk4EbYX">Enhancing next-generation sequencing-guided cancer care through cognitive computing</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RecH6AM">Oncologist</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="179" to="185" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Patel, N. M. et al. Enhancing next-generation sequencing-guided cancer care through cognitive computing. Oncologist 23, 179-185 (2018).</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>De Graaf</surname></persName>
		</author>
		<ptr target="https://www.dailymail.co.uk/health/article-6257891/Study-finds-artificial-intelligence-better-doctor-crucial-stage-IVF.html" />
		<title level="m" xml:id="_zYmySut">Will Al replace fertility doctors? Why computers are the only ones that can end the agony of failed IVF cycles, miscarriages, and risky multiple birth</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Daily Mail</note>
	<note type="raw_reference">De Graaf, M. Will Al replace fertility doctors? Why computers are the only ones that can end the agony of failed IVF cycles, miscarriages, and risky multiple birth. In Daily Mail https://www.dailymail.co.uk/health/ article-6257891/Study-finds-artificial-intelligence-better-doctor-crucial- stage-IVF.html (2018).</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main" xml:id="_ZwwC588">DeepGestalt-identifying rare genetic syndromes using deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gurovich</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1801.07637" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Gurovich, Y. et al. DeepGestalt-identifying rare genetic syndromes using deep learning. Preprint at https://arxiv.org/abs/1801.07637 (2017).</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main" xml:id="_vwwxbzK">High-risk breast lesions: a machine learning model to predict pathologic upgrade and reduce unnecessary surgical excision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SbEHNDm">Radiology</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="810" to="818" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bahl, M. et al. High-risk breast lesions: a machine learning model to predict pathologic upgrade and reduce unnecessary surgical excision. Radiology 286, 810-818 (2018).</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main" xml:id="_TsNPQsp">The digital scribe</title>
		<author>
			<persName><forename type="first">E</forename><surname>Coiera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EQUsk7b">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Coiera, E. et al. The digital scribe. NPJ Digit. Med. 1, 58 (2018).</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main" xml:id="_tamQSC3">The burden of depression</title>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6yC2SGG">Nature</title>
		<imprint>
			<biblScope unit="volume">515</biblScope>
			<biblScope unit="page">163</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">The burden of depression. Nature 515, 163 (2014).</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main" xml:id="_jhJwQEw">DeepMood: modeling mobile phone typing dynamics for mood detection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1803.08986" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Cao, B. et al. DeepMood: modeling mobile phone typing dynamics for mood detection. Preprint at https://arxiv.org/abs/1803.08986 (2018).</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main" xml:id="_kzsaSBC">A solution-focused research approach to achieve an implementable revolution in digital mental health</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Mohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Uz9FgzH">JAMA Psychiatry</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="113" to="114" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mohr, D. C. et al. A solution-focused research approach to achieve an implementable revolution in digital mental health. JAMA Psychiatry 75, 113-114 (2018).</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main" xml:id="_4nYdHNv">How artificial intelligence could help diagnose mental disorders</title>
		<author>
			<persName><forename type="first">J</forename><surname>Frankel</surname></persName>
		</author>
		<ptr target="https://www.theatlantic.com/health/archive/2016/08/could-artificial-intelligence-improve-psychiatry/496964/" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_PM7qVD8">The Atlantic</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Frankel, J. How artificial intelligence could help diagnose mental disorders. In The Atlantic https://www.theatlantic.com/health/archive/2016/08/ could-artificial-intelligence-improve-psychiatry/496964/ (2016).</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main" xml:id="_cXVmJ2G">Digitising the mind</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Barrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SPjAmMM">Lancet</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="page">1877</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barrett, P. M. et al. Digitising the mind. Lancet 389, 1877 (2017).</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main" xml:id="_Fph7Hdq">The efficacy of smartphone-based mental health interventions for depressive symptoms: a meta-analysis of randomized controlled trials</title>
		<author>
			<persName><forename type="first">J</forename><surname>Firth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hm5erSr">World Psychiatry</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="287" to="298" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Firth, J. et al. The efficacy of smartphone-based mental health interventions for depressive symptoms: a meta-analysis of randomized controlled trials. World Psychiatry 16, 287-298 (2017).</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main" xml:id="_DfPvm7A">Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Fitzpatrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EwkRb2Z">JMIR Ment. Health</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fitzpatrick, K. K. et al. Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial. JMIR Ment. Health 4, e19 (2017).</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main" xml:id="_QN5PV79">Facebook language predicts depression in medical records</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_My2UVZF">Proc. Natl. Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="11203" to="11208" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Eichstaedt, J. C. et al. Facebook language predicts depression in medical records. Proc. Natl. Acad. Sci. USA 115, 11203-11208 (2018).</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main" xml:id="_9J8jqwV">Cross-trial prediction of treatment outcome in depression: a machine learning approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Chekroud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FNKF87y">Lancet Psychiatry</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chekroud, A. M. et al. Cross-trial prediction of treatment outcome in depression: a machine learning approach. Lancet Psychiatry 3, 243-250 (2016).</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main" xml:id="_Sv6td27">Evaluating the diagnostic utility of applying a machine learning algorithm to diffusion tensor MRI measures in individuals with major depressive disorder</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Schnyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hgFhKFP">Psychiatry Res</title>
		<imprint>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Schnyer, D. M. et al. Evaluating the diagnostic utility of applying a machine learning algorithm to diffusion tensor MRI measures in individuals with major depressive disorder. Psychiatry Res. 264, 1-9 (2017).</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main" xml:id="_JRb3Kyb">Instagram photos reveal predictive markers of depression</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Reece</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Danforth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nZRp2hS">EPJ Data Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Reece, A. G. &amp; Danforth, C. M. Instagram photos reveal predictive markers of depression. EPJ Data Science 6, 15 (2017).</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main" xml:id="_ksFjs8a">Imaging biomarkers and biotypes for depression</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Wager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Fv4TNHq">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="16" to="17" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wager, T. D. &amp; Woo, C. W. Imaging biomarkers and biotypes for depression. Nat. Med. 23, 16-17 (2017).</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main" xml:id="_UWZCKnk">Predicting risk of suicide attempts over time through machine learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Walsh</surname></persName>
		</author>
		<idno type="DOI">10.1177/2167702617691560</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_a2DuDqq">Clin. Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="457" to="469" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Walsh, C. G. et al. Predicting risk of suicide attempts over time through machine learning. Clin. Psychol. Sci. 5, 457-469 (2017).</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main" xml:id="_zCtgbsR">Risk factors for suicidal thoughts and behaviors: a meta-analysis of 50 years of research</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wzpM8sJ">Psychol. Bull</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="187" to="232" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Franklin, J. C. et al. Risk factors for suicidal thoughts and behaviors: a meta-analysis of 50 years of research. Psychol. Bull. 143, 187-232 (2017).</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main" xml:id="_n6GEGxY">Machine learning of neural representations of suicide and emotion concepts identifies suicidal youth</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Just</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JRwP6s5">Nat. Hum. Behav</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="911" to="919" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Just, M. A. et al. Machine learning of neural representations of suicide and emotion concepts identifies suicidal youth. Nat. Hum. Behav. 1, 911-919 (2017).</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main" xml:id="_sc7Gakg">Use of machine learning to determine deviance in neuroanatomical maturity associated with future psychosis in youths at clinically high risk</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3PFyHbV">JAMA Psychiatry</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="960" to="968" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chung, Y. et al. Use of machine learning to determine deviance in neuroanatomical maturity associated with future psychosis in youths at clinically high risk. JAMA Psychiatry 75, 960-968 (2018).</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main" xml:id="_6dqczUy">Clinical assistant diagnosis for electronic medical record based on convolutional neural network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ggnunBr">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">6329</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang, Z. et al. Clinical assistant diagnosis for electronic medical record based on convolutional neural network. Sci. Rep. 8, 6329 (2018).</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main" xml:id="_sNQYqWA">Improving palliative care with deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avati</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1711.06402" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Avati, A. et al. Improving palliative care with deep learning. Preprint at https://arxiv.org/abs/1711.06402 (2017).</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main" xml:id="_Rcqnwqe">Unsupervised machine learning to identify high likelihood of dementia in population-based surveys: development and validation study</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cleret De Langavant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aBhxVBP">J. Med. Internet. Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">10493</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cleret de Langavant, L. et al. Unsupervised machine learning to identify high likelihood of dementia in population-based surveys: development and validation study. J. Med. Internet. Res. 20, e10493 (2018).</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main" xml:id="_HZGfnGE">A generalizable, data-driven approach to predict daily risk of Clostridium difficile infection at two large academic health centers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Zuf79Rq">Infect. Control. Hosp. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="425" to="433" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Oh, J. et al. A generalizable, data-driven approach to predict daily risk of Clostridium difficile infection at two large academic health centers. Infect. Control. Hosp. Epidemiol. 39, 425-433 (2018).</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bennington-Castro</surname></persName>
		</author>
		<ptr target="https://www.nbcnews.com/mach/science/ai-can-predict-when-we-ll-die-here-s-why-ncna844276" />
		<title level="m" xml:id="_Vr6VxXA">AI can predict when we&apos;ll die-here&apos;s why that&apos;s a good thing</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>NBC News</note>
	<note type="raw_reference">Bennington-Castro, J. AI can predict when we&apos;ll die-here&apos;s why that&apos;s a good thing. In NBC News https://www.nbcnews.com/mach/science/ ai-can-predict-when-we-ll-die-here-s-why-ncna844276 (2018).</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main" xml:id="_BHD7SA4">Development and application of a machine learning approach to assess short-term mortality risk among patients with cancer starting chemotherapy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Elfiky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Kt6MAPE">JAMA Netw. Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">180926</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Elfiky, A. et al. Development and application of a machine learning approach to assess short-term mortality risk among patients with cancer starting chemotherapy. JAMA Netw. Open 1, e180926 (2018).</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main" xml:id="_gmp9ns6">Scalable and accurate deep learning with electronic health records</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rajkomar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_j3QKACM">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajkomar, A. et al. Scalable and accurate deep learning with electronic health records. NPJ Digit. Med. 1, 18 (2018).</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main" xml:id="_eu2G2Ux">Deep patient: an unsupervised representation to predict the future of patients from the electronic health records</title>
		<author>
			<persName><forename type="first">R</forename><surname>Miotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Z8cvxPD">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">26094</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Miotto, R. et al. Deep patient: an unsupervised representation to predict the future of patients from the electronic health records. Sci. Rep. 6, 26094 (2016).</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main" xml:id="_tuEK6ea">Identifying incipient dementia individuals using machine learning and amyloid imaging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathotaarachchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6zkajqT">Neurobiol. Aging</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="80" to="90" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mathotaarachchi, S. et al. Identifying incipient dementia individuals using machine learning and amyloid imaging. Neurobiol. Aging. 59, 80-90 (2017).</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main" xml:id="_pXjWhvC">Development and validation of an electronic health record-based machine learning model to estimate delirium risk in newly hospitalized patients without known cognitive impairment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sj9RWkk">JAMA Netw. Open</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">101</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note>Personalized survival predictions via Trees of Predictors: an application to cardiac transplantation PLoS ONE</note>
	<note type="raw_reference">Yoon, J. et al. Personalized survival predictions via Trees of Predictors: an application to cardiac transplantation. PLoS ONE 13, e0194985 (2018). 100. Wong, A. et al. Development and validation of an electronic health record-based machine learning model to estimate delirium risk in newly hospitalized patients without known cognitive impairment. JAMA Netw. Open 1, e181018 (2018). 101</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main" xml:id="_5vGeAHr">Prognostication and risk factors for cystic fibrosis via automated machine learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_j6Wc7YY">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">102</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alaa, A. M. &amp; van der Schaar, M. Prognostication and risk factors for cystic fibrosis via automated machine learning. Sci. Rep. 8, 11242 (2018). 102</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main" xml:id="_EcScdWp">Creating an automated trigger for sepsis clinical decision support at emergency department triage using machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_z4bGpwG">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">103</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Horng, S. et al. Creating an automated trigger for sepsis clinical decision support at emergency department triage using machine learning. PLoS ONE 12, e0174708 (2017). 103</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main" xml:id="_56ryc25">A targeted real-time early warning score (TREWScore) for septic shock</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Henry</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1711.11536(2017).105" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_Y79wRC4">Predicting severe sepsis using text from the electronic health record</title>
		<editor>et al.</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Henry, K. E. et al. A targeted real-time early warning score (TREWScore) for septic shock. Sci. Transl. Med. 7, 299ra122 (2015). 104. Culliton, P. et al. Predicting severe sepsis using text from the electronic health record. Preprint at https://arxiv.org/abs/1711.11536 (2017). 105</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main" xml:id="_jrBwmPe">Multi-task prediction of disease onsets from longitudinal lab tests</title>
		<author>
			<persName><forename type="first">N</forename><surname>Razavian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pnZxHzm">PMLR</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Razavian, N. et al. Multi-task prediction of disease onsets from longitudinal lab tests. PMLR 56, 73-100 (2016). 106</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main" xml:id="_G57gyma">Predictive modeling of hospital readmission rates using electronic medical record-wide machine learning: a case-study using Mount Sinai Heart Failure Cohort</title>
		<author>
			<persName><forename type="first">K</forename><surname>Shameer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tZKz93C">Pac. Symp. Biocomput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">107</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shameer, K. et al. Predictive modeling of hospital readmission rates using electronic medical record-wide machine learning: a case-study using Mount Sinai Heart Failure Cohort. Pac. Symp. Biocomput. 22, 276-287 (2017). 107</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main" xml:id="_7rJrcmn">Modeling and prediction of clinical symptom trajectories in Alzheimer&apos;s disease using longitudinal data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bhagwat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_x8FZCAK">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">108</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bhagwat, N. et al. Modeling and prediction of clinical symptom trajectories in Alzheimer&apos;s disease using longitudinal data. PLoS Comput. Biol. 14, e1006376 (2018). 108</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main" xml:id="_qxQeDwg">The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care</title>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jqVYUdY">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">109</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Komorowski, M. et al. The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care. Nat. Med. 24, 1716-1720 (2018). 109</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main" xml:id="_HzctqUA">AI is transforming medical diagnosis, prosthetics, and vision aids</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zaidi</surname></persName>
		</author>
		<ptr target="https://venturebeat.com/2017/10/30/ai-is-transforming-medical-diagnosis-prosthetics-and-vision-aids/(2017).110" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_aHnS3BN">Venture Beat</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Zaidi, D. AI is transforming medical diagnosis, prosthetics, and vision aids. In Venture Beat https://venturebeat.com/2017/10/30/ai-is-transforming- medical-diagnosis-prosthetics-and-vision-aids/ (2017). 110</note>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main" xml:id="_eD2Grvf">Deep biomarkers of human aging: application of deep neural networks to biomarker development</title>
		<author>
			<persName><forename type="first">E</forename><surname>Putin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SgKDkha">Aging</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">111</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Putin, E. et al. Deep biomarkers of human aging: application of deep neural networks to biomarker development. Aging 8, 1021-1033 (2016). 111</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main" xml:id="_pe63c3Y">Predicting age by mining electronic medical records with deep learning characterizes differences between chronological and physiological age</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PjgfG4u">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">112</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang, Z. et al. Predicting age by mining electronic medical records with deep learning characterizes differences between chronological and physiological age. J. Biomed. Inform. 76, 59-68 (2017). 112</note>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main" xml:id="_xNJ24ws">DNA methylation-based biomarkers and the epigenetic clock theory of ageing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Horvath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Raj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bvyu8UW">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">113</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Horvath, S. &amp; Raj, K. DNA methylation-based biomarkers and the epigenetic clock theory of ageing. Nat. Rev. Genet. 19, 371-384 (2018). 113</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main" xml:id="_wXnM3At">Machine Learning for Prediction in Electronic Health Data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bbh8PPu">JAMA Netw. Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rose, S. Machine Learning for Prediction in Electronic Health Data. JAMA Netw. Open 1, e181404(2018). 114</note>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main" xml:id="_cHg7jTe">Towards vision-based smart hospitals: a system for tracking and monitoring hand hygiene compliance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Haque</surname></persName>
		</author>
		<ptr target=").115" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Haque, A. et al. Towards vision-based smart hospitals: a system for tracking and monitoring hand hygiene compliance. Preprint at https://arxiv.org/ abs/1708.00163 (2017). 115</note>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main" xml:id="_kTXB8wb">Clinical intervention prediction and understanding with deep neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Suresh</surname></persName>
		</author>
		<ptr target=").116" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Suresh, H. et al. Clinical intervention prediction and understanding with deep neural networks. Preprint at https://arxiv.org/abs/1705.08498 (2017). 116</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main" xml:id="_peswVZ5">Human fall detection on embedded platform using depth maps and wireless accelerometer</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kwolek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kepski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_a7sbRCS">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page">117</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kwolek, B. &amp; Kepski, M. Human fall detection on embedded platform using depth maps and wireless accelerometer. Comput. Methods Programs Biomed. 117, 489-501 (2014). 117</note>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main" xml:id="_k9Espu9">A reinforcement learning approach to weaning of mechanical ventilation in intensive care units</title>
		<author>
			<persName><forename type="first">N</forename><surname>Prasad</surname></persName>
		</author>
		<ptr target=").118" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Prasad, N. et al. A reinforcement learning approach to weaning of mechanical ventilation in intensive care units. Preprint at https://arxiv.org/ abs/1704.06300 (2018). 118</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main" xml:id="_8JRvu9j">Surgical data science for next-generation interventions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Sr8kjVk">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">119</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Maier-Hein, L. et al. Surgical data science for next-generation interventions. Nat. Biomed. Eng. 1, 691-696 (2017). 119</note>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main" xml:id="_vr6wyU2">Automated performance metrics and machine learning algorithms to measure surgeon performance and anticipate clinical outcomes in robotic surgery</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_egXP4c3">JAMA Surg</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page">120</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hung, A. J. et al. Automated performance metrics and machine learning algorithms to measure surgeon performance and anticipate clinical outcomes in robotic surgery. JAMA Surg. 153, 770-771 (2018). 120</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main" xml:id="_JZ84n89">Robotic surgery for the eye</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Gehlbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bDMCNcb">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gehlbach, P. L. Robotic surgery for the eye. Nat. Biomed. Eng. 2, 627-628 (2018). 121</note>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main" xml:id="_8bTHa5P">Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nikolov</surname></persName>
		</author>
		<ptr target=").122" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Nikolov, S. et al. Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy. Preprint at https://arxiv.org/ abs/1809.04430 (2018). 122</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main" xml:id="_fh2ynQZ">Image reconstruction by domain-transform manifold learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rj9jQP8">Nature</title>
		<imprint>
			<biblScope unit="volume">555</biblScope>
			<biblScope unit="page">123</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhu, B. et al. Image reconstruction by domain-transform manifold learning. Nature 555, 487-492 (2018). 123</note>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main" xml:id="_4MtgPMR">Can AI enable a 10 minute MRI?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Harvey</surname></persName>
		</author>
		<ptr target="https://towardsdatascience.com/can-ai-enable-a-10-minute-mri-77218f0121fe(2018).124" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_3AQbJh6">Towards Data Science</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Harvey, H. Can AI enable a 10 minute MRI? In Towards Data Science https://towardsdatascience.com/can-ai-enable-a-10-minute-mri- 77218f0121fe (2018). 124</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main" xml:id="_PB8mJ6W">Artificial intelligence guides lower PET tracer dose</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Ridley</surname></persName>
		</author>
		<ptr target="https://www.auntminnie.com/index.aspx?sec=log&amp;itemID=119572" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_uSqvfJ5">Aunt Minnie</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">125</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Ridley, E. L. Artificial intelligence guides lower PET tracer dose. In Aunt Minnie https://www.auntminnie.com/index.aspx?sec= log&amp;itemID= 119572 (2018). 125</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main" xml:id="_zNcKuVk">Translating artificial intelligence into clinical care</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kohane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XURJAMR">JAMA</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page">126</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Beam, A. L. &amp; Kohane, I. S. Translating artificial intelligence into clinical care. JAMA 316, 2368-2369 (2016). 126</note>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main" xml:id="_Gexx8xW">Reengineering aircraft structural life prediction using a digital twin</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Tuegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Gj2byzT">Int. J. Aerosp</title>
		<imprint>
			<biblScope unit="volume">2011</biblScope>
			<biblScope unit="page">127</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tuegel, E. J. et al. Reengineering aircraft structural life prediction using a digital twin. Int. J. Aerosp. 2011, 154798 (2011). 127</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main" xml:id="_MwseHk6">Monitoring the health of jet engines and people</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tarassenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2018.16558</idno>
		<ptr target="https://doi.org/10.1001/jama.2018.16558(2018).128" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_JhSkSFv">JAMA</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Tarassenko, L. &amp; Topol, E. Monitoring the health of jet engines and people. JAMA https://doi.org/10.1001/jama.2018.16558 (2018). 128</note>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Buhr</surname></persName>
		</author>
		<ptr target="https://appleinsider.com/articles/18/09/18/apple-watch-series-4-ekg-tech-got-fda-clearance-less-than-24-hours-before-reveal" />
		<title level="m" xml:id="_ewaVA7f">FDA clears AliveCor&apos;s Kardiaband as the first medical device accessory for the Apple Watch</title>
		<imprint>
			<date type="published" when="2017">2017. 2018. 2018</date>
			<biblScope unit="page">131</biblScope>
		</imprint>
	</monogr>
	<note>TechCrunch . What did journalists overlook about the Apple Watch &apos;heart monitor&apos; feature? Apple Watch Series 4 EKG tech got FDA clearance less than 24 hours before reveal</note>
	<note type="raw_reference">Buhr, S. FDA clears AliveCor&apos;s Kardiaband as the first medical device accessory for the Apple Watch. In TechCrunch https://techcrunch. com/2017/11/30/fda-clears-alivecors-kardiaband-as-the-first-medical- device-accessory-for-the-apple-watch/ (2017). 129. Victory, J. What did journalists overlook about the Apple Watch &apos;heart monitor&apos; feature? In HealthNewsReview https://www.healthnewsreview. org/2018/09/what-did-journalists-overlook-about-the-apple-watch-heart- monitor-feature/ (2018). 130. Fingas, R. Apple Watch Series 4 EKG tech got FDA clearance less than 24 hours before reveal. In AppleInsider https://appleinsider.com/ articles/18/09/18/apple-watch-series-4-ekg-tech-got-fda-clearance-less-than- 24-hours-before-reveal (2018). 131</note>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main" xml:id="_MbgRpJq">That new apple watch EKG feature? There are more downs than ups</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Carroll</surname></persName>
		</author>
		<ptr target=").132" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_NJNcMvx">The New York Times</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Carroll, A. E. That new apple watch EKG feature? There are more downs than ups. In The New York Times https://www.nytimes.com/2018/10/08/ upshot/apple-watch-heart-monitor-ekg.html (2018). 132</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brown</surname></persName>
		</author>
		<ptr target=").133" />
		<title level="m" xml:id="_sGFarn8">Onduo delivers diabetes clinic and coaching to your smartphone</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Diatribe</note>
	<note type="raw_reference">Levine, B. &amp; Brown, A. Onduo delivers diabetes clinic and coaching to your smartphone. In Diatribe https://diatribe.org/onduo-delivers-diabetes-clinic- and-coaching-your-smartphone (2018). 133</note>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main" xml:id="_GuRwX7W">A hybrid recommender system for patient-doctor matchmaking in primary care</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Han</surname></persName>
		</author>
		<ptr target=").134" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Han, Q. et al. A hybrid recommender system for patient-doctor matchmaking in primary care. Preprint at https://arxiv.org/abs/1808.03265 (2018). 134</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main" xml:id="_s8tucYM">Taking it personally: personalized utilization of the human microbiome in health and disease</title>
		<author>
			<persName><forename type="first">N</forename><surname>Zmora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AdnChQG">Cell. Host. Microbe</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">135</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zmora, N. et al. Taking it personally: personalized utilization of the human microbiome in health and disease. Cell. Host. Microbe. 19, 12-20 (2016). 135</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main" xml:id="_kJ8SH9N">Bread affects clinical parameters and induces gut microbiome-associated personal glycemic responses</title>
		<author>
			<persName><forename type="first">T</forename><surname>Korem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WQZ4pFw">Cell. Metab</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">136</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Korem, T. et al. Bread affects clinical parameters and induces gut microbiome-associated personal glycemic responses. Cell. Metab. 25, 1243-1253 e1245 (2017). 136</note>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main" xml:id="_4htMqcd">Personalized nutrition by prediction of glycemic responses</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rYRefaC">Cell</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page">137</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zeevi, D. et al. Personalized nutrition by prediction of glycemic responses. Cell 163, 1079-1094 (2015). 137</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main" xml:id="_Yd33y53">Glucotypes reveal new patterns of glucose dysregulation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yCPka5N">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hall, H. et al. Glucotypes reveal new patterns of glucose dysregulation. PLoS Biol. 16, e2005143 (2018). 138</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main" xml:id="_yu6eAta">Glucose patterns during an oral glucose tolerance test and associations with future diabetes, cardiovascular disease and all-cause mortality rate</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Albers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ScadHcr">PLoS. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">140</biblScope>
			<date type="published" when="2017">2017. 2018</date>
		</imprint>
	</monogr>
	<note>Personalized glucose forecasting for type 2 diabetes using data assimilation Diabetologia</note>
	<note type="raw_reference">Albers, D. J. et al. Personalized glucose forecasting for type 2 diabetes using data assimilation. PLoS. Comput. Biol. 13, e1005232 (2017). 139. Hulman, A. et al. Glucose patterns during an oral glucose tolerance test and associations with future diabetes, cardiovascular disease and all-cause mortality rate. Diabetologia 61, 101-107 (2018). 140</note>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main" xml:id="_5qbBWMF">Hyperglycemia drives intestinal barrier dysfunction and risk for enteric infection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Thaiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_khgYNEj">Science</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page">141</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thaiss, C. A. et al. Hyperglycemia drives intestinal barrier dysfunction and risk for enteric infection. Science 359, 1376-1383 (2018). 141</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main" xml:id="_QrXXXwg">Glucose-regulated phosphorylation of TET2 by AMPK reveals a pathway linking diabetes to cancer</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hDDc3fb">Nature</title>
		<imprint>
			<biblScope unit="volume">559</biblScope>
			<biblScope unit="page">142</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wu, D. et al. Glucose-regulated phosphorylation of TET2 by AMPK reveals a pathway linking diabetes to cancer. Nature 559, 637-641 (2018). 142</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main" xml:id="_nEb39xX">Closed-loop insulin delivery for glycemic control in noncritical care</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aDWaWTY">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="page">143</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bally, L. et al. Closed-loop insulin delivery for glycemic control in noncritical care. N. Engl. J. Med. 379, 547-556 (2018). 143</note>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main" xml:id="_UbHGPC7">In silico labeling: predicting fluorescent labels in unlabeled images</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Christiansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kDysAmd">Cell</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page">144</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Christiansen, E. M. et al. In silico labeling: predicting fluorescent labels in unlabeled images. Cell 173, 792-803 e719 (2018). 144</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main" xml:id="_W97RNJY">Seeing more: a future of augmented microscopy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lundberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nnW7GzP">Cell</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sullivan, D. P. &amp; Lundberg, E. Seeing more: a future of augmented microscopy. Cell 173, 546-548 (2018). 145</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main" xml:id="_8JnxfX5">Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ounkomol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fdVfCP2">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ounkomol, C. et al. Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy. Nat. Methods 15, 917-920 (2018). 146</note>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main" xml:id="_ey44dbq">Ghost cytometry</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JC8AXKm">Science</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page">147</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ota, S. et al. Ghost cytometry. Science 360, 1246-1251 (2018). 147</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main" xml:id="_gkRMf5E">Intelligent image-activated cell sorting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nitta</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0300-7</idno>
		<ptr target="https://doi.org/10.1038/s41591-018-0300-7148" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZHp6U2F">Review ARticle</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="page" from="266" to="276" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Cell</note>
	<note type="raw_reference">Nitta, N. et al. Intelligent image-activated cell sorting. Cell 175, 266-276 e213 (2018). Review ARticle | FOCUS https://doi.org/10.1038/s41591-018-0300-7 148</note>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main" xml:id="_TpBKA6R">Content-aware image restoration: pushing the limits of fluorescence microscopy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Weigert</surname></persName>
		</author>
		<idno type="DOI">10.1101/236463</idno>
		<ptr target="https://doi.org/10.1101/236463(2017).149" />
		<imprint/>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Weigert, M. et al. Content-aware image restoration: pushing the limits of fluorescence microscopy. Preprint at https://doi.org/10.1101/236463 (2017). 149</note>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main" xml:id="_Vm9rc2E">Multiplexed protein maps link subcellular organization to cellular states</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2ErT3GA">Science</title>
		<imprint>
			<biblScope unit="volume">361</biblScope>
			<biblScope unit="page">150</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gut, G. et al. Multiplexed protein maps link subcellular organization to cellular states. Science 361, eaar7042 (2018). 150</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main" xml:id="_8PMxhPC">Deep learning is combined with massive-scale citizen science to improve large-scale image classification</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AbGV2dj">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">151</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sullivan, D. P. et al. Deep learning is combined with massive-scale citizen science to improve large-scale image classification. Nat. Biotechnol. 36, 820-828 (2018). 151</note>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<title level="m" type="main" xml:id="_esGSSaq">Creating a universal SNP and small indel variant caller with deep neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poplin</surname></persName>
		</author>
		<idno type="DOI">10.1101/092890</idno>
		<ptr target="https://doi.org/10.1101/092890(2016).152" />
		<imprint/>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Poplin, R. et al. Creating a universal SNP and small indel variant caller with deep neural networks. Preprint at https://doi.org/10.1101/092890 (2016). 152</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main" xml:id="_byVdeSW">Predicting the clinical impact of human mutation with deep neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sundaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MB2qhZY">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sundaram, L. et al. Predicting the clinical impact of human mutation with deep neural networks. Nat. Genet. 50, 1161-1170 (2018). 153</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main" xml:id="_GqC6s2x">Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QrDWM47">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page">154</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhou, J. et al. Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk. Nat. Genet. 50, 1171-1179 (2018). 154</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main" xml:id="_Gg3CbeR">Predicting effects of noncoding variants with deep learning-based sequence model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">G</forename><surname>Troyanskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TKXBDWP">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">155</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhou, J. &amp; Troyanskaya, O. G. Predicting effects of noncoding variants with deep learning-based sequence model. Nat. Methods 12, 931-934 (2015). 155</note>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main" xml:id="_pdcnWtY">Clairvoyante: a multi-task convolutional deep neural network for variant calling in single molecule sequencing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1101/310458</idno>
		<ptr target="https://doi.org/10.1101/310458(2018).156" />
		<imprint/>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Luo, R., et al. Clairvoyante: a multi-task convolutional deep neural network for variant calling in single molecule sequencing. Preprint at https://doi. org/10.1101/310458 (2018). 156</note>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main" xml:id="_RBwyN6Y">Machine learning in genomic medicine: a review of computational problems and data sets</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_z5YrWCv">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">157</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Leung, M. et al. Machine learning in genomic medicine: a review of computational problems and data sets. In Proceedings of the IEEE Vol. 104, 176-197 (IEEE, 2016). 157</note>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main" xml:id="_HeBzHkc">A universal SNP and small-indel variant caller using deep neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Poplin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sH8yy3U">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Poplin, R. et al. A universal SNP and small-indel variant caller using deep neural networks. Nat. Biotechnol. 36, 983-987 (2018). 158</note>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main" xml:id="_vtYcJcu">Deep generative models of genetic variation capture the effects of mutations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Riesselman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VZ9mbAR">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Riesselman, A. et al. Deep generative models of genetic variation capture the effects of mutations. Nat. Methods 15, 816-822 (2018). 159</note>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main" xml:id="_cRC23Fq">A machine learning approach for somatic mutation discovery</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1126/scitranslmed.aar7939</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8EQz8kv">Sci. Transl. Med</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">160</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wood, D. E. et al. A machine learning approach for somatic mutation discovery. Sci. Transl. Med. 10, eaar7939 (2018). 160</note>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main" xml:id="_M74S58D">Machine learning identifies interacting genetic variants contributing to breast cancer risk: a case study in Finnish cases and controls</title>
		<author>
			<persName><forename type="first">H</forename><surname>Behravan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ekWbz7n">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">161</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Behravan, H. et al. Machine learning identifies interacting genetic variants contributing to breast cancer risk: a case study in Finnish cases and controls. Sci. Rep. 8, 13149 (2018). 161</note>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main" xml:id="_Rv2PKzF">Using neural networks for reducing the dimensions of single-cell RNA-seq data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qu55sMD">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">162</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lin, C. et al. Using neural networks for reducing the dimensions of single-cell RNA-seq data. Nucleic Acids Res. 45, e156 (2017). 162</note>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main" xml:id="_hBGzGdt">DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Angermueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jnjfvU4">Genome. Biol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">163</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Angermueller, C. et al. DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning. Genome. Biol. 18, 67 (2017). 163</note>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main" xml:id="_zHRgCWS">End-to-end differentiable learning of protein structure</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alquraishi</surname></persName>
		</author>
		<idno type="DOI">10.1101/265231</idno>
		<ptr target="https://doi.org/10.1101/265231(2018).164" />
		<imprint/>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">AlQuraishi, M. End-to-end differentiable learning of protein structure. Preprint at https://doi.org/10.1101/265231 (2018). 164</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main" xml:id="_NK3tczH">Machine learning for tackling microbiota data and infection complications in immunocompromised patients with cancer</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Espinoza</surname></persName>
		</author>
		<idno type="DOI">10.1111/joim.12746</idno>
		<ptr target="https://doi.org/10.1111/joim.12746(2018).165" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_D2GYSHE">J. Intern. Med</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Espinoza, J. L. Machine learning for tackling microbiota data and infection complications in immunocompromised patients with cancer. J. Intern. Med. https://doi.org/10.1111/joim.12746 (2018). 165</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main" xml:id="_TeNcxrS">Recovering gene interactions from single-cell data using data diffusion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Van Dijk</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cell.2018.05.061</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_esywqbh">Cell</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">van Dijk, D. et al. Recovering gene interactions from single-cell data using data diffusion. Cell 174, 716-729.e727 (2018). 166</note>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title level="m" type="main" xml:id="_7JkbB57">Machine learning for integrating data in biology and medicine: principles, practice, and opportunities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<idno type="DOI">10.1111/joim.12746</idno>
		<ptr target="https://doi.org/10.1111/joim.12746(2018).167" />
		<imprint/>
	</monogr>
	<note type="raw_reference">Zitnik, M. et al. Machine learning for integrating data in biology and medicine: principles, practice, and opportunities. Preprint at https://doi. org/10.1111/joim.12746 (2018). 167</note>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main" xml:id="_yr5frwK">Next-generation machine learning for biological networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Camacho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Zm6HjDY">Cell</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page">168</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Camacho, D. M. et al. Next-generation machine learning for biological networks. Cell 173, 1581-1592 (2018). 168</note>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main" xml:id="_4GdmqYw">Deep learning improves prediction of CRISPR-Cpf1 guide RNA activity</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1038/nbt.4061</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_33nG5GM">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">169</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kim, H. K. et al. Deep learning improves prediction of CRISPR-Cpf1 guide RNA activity. Nat. Biotechnol. 36, 239-241 (2018). 169</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main" xml:id="_9gNttS3">Prediction of off-target activities for the end-to-end design of CRISPR guide RNAs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Listgarten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qUe8eQ2">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Listgarten, J. et al. Prediction of off-target activities for the end-to-end design of CRISPR guide RNAs. Nat. Biomed. Eng. 2, 38-47 (2018). 170</note>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main" xml:id="_bE4ptkU">Detecting repeated cancer evolution from multi-region tumor sequencing data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Caravagna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_q7TzFNb">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">171</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Caravagna, G. et al. Detecting repeated cancer evolution from multi-region tumor sequencing data. Nat. Methods 15, 707-714 (2018). 171</note>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main" xml:id="_NeyTHK7">Live-cell phenotypic-biomarker microfluidic assay for the risk stratification of cancer patients via machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Manak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_X7wwNnj">Nature Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">172</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Manak, M. et al. Live-cell phenotypic-biomarker microfluidic assay for the risk stratification of cancer patients via machine learning. Nature Biomed. Eng. 2, 761-772 (2018). 172</note>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main" xml:id="_cT2dz9J">Neuroscience-inspired artificial intelligence</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Au2bjSP">Neuron</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page">173</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hassabis, D. et al. Neuroscience-inspired artificial intelligence. Neuron 95, 245-258 (2017). 173</note>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main" xml:id="_MQTRW4b">Mapping the neural substrates of behavior</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Robie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gWntpqk">Cell</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="page">174</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Robie, A. A. et al. Mapping the neural substrates of behavior. Cell 170, 393-406 e328 (2017). 174</note>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main" xml:id="_YfeEHCk">A neural algorithm for a fundamental computing problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aam9868</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zKsV8TY">Science</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page">175</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dasgupta, S. et al. A neural algorithm for a fundamental computing problem. Science 358, 793-796 (2017). 175</note>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main" xml:id="_5JgjScu">High-precision automated reconstruction of neurons with flood-filling networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Januszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dYrQ5hp">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">176</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Januszewski, M. et al. High-precision automated reconstruction of neurons with flood-filling networks. Nat. Methods 15, 605-610 (2018). 176</note>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main" xml:id="_r8bUWBh">AI mimics brain codes for navigation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Savelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Knierim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_shx4Qtm">Nature</title>
		<imprint>
			<biblScope unit="volume">557</biblScope>
			<biblScope unit="page">177</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Savelli, F. &amp; Knierim, J. J. AI mimics brain codes for navigation. Nature 557, 313-314 (2018). 177</note>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main" xml:id="_8SU9EVB">Vector-based navigation using grid-like representations in artificial agents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Banino</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-018-0102-6</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_W34tbJw">Nature</title>
		<imprint>
			<biblScope unit="volume">557</biblScope>
			<biblScope unit="page">178</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Banino, A. et al. Vector-based navigation using grid-like representations in artificial agents. Nature 557, 429-433 (2018). 178</note>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main" xml:id="_pqDvvtj">Two artificial synapses are better than one</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HUXx642">Nature</title>
		<imprint>
			<biblScope unit="volume">558</biblScope>
			<biblScope unit="page">179</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Adam, G. C. Two artificial synapses are better than one. Nature 558, 39-40 (2018). 179</note>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main" xml:id="_eM8BjEP">Phase-change devices: crystal-clear neuronal computing</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3sb7HFA">Nat. Nanotechnol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">180</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wright, C. D. Phase-change devices: crystal-clear neuronal computing. Nat. Nanotechnol. 11, 655-656 (2016). 180</note>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main" xml:id="_vPp9ns8">DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mathis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZBSpFbF">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">181</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mathis, A. et al. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat. Neurosci. 21, 1281-1289 (2018). 181</note>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main" xml:id="_eD3KaYn">AI-powered drug discovery captures pharma interest</title>
		<author>
			<persName><forename type="first">E</forename><surname>Smalley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UQPkD9E">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">182</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Smalley, E. AI-powered drug discovery captures pharma interest. Nat. Biotechnol. 35, 604-605 (2017). 182</note>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main" xml:id="_NqnKhe7">Automating drug discovery</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FGEAVvg">Nat. Rev. Drug. Discov</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">183</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Schneider, G. Automating drug discovery. Nat. Rev. Drug. Discov. 17, 97-113 (2018). 183</note>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main" xml:id="_4BJD97D">Predictable response: finding optimal drugs and doses using artificial intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chakradhar</surname></persName>
		</author>
		<idno type="DOI">10.1038/nm1117-1244</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AESsMaX">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">184</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chakradhar, S. Predictable response: finding optimal drugs and doses using artificial intelligence. Nat. Med. 23, 1244-1247 (2017). 184</note>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main" xml:id="_8tAxQkE">AI designs organic syntheses</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yzAdHtn">Nature</title>
		<imprint>
			<biblScope unit="volume">555</biblScope>
			<biblScope unit="page">185</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lowe, D. AI designs organic syntheses. Nature 555, 592-593 (2018). 185</note>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main" xml:id="_HPpKPa4">Machine learning of toxicological big data enables read-across structure activity relationships (RASAR) outperforming animal test reproducibility</title>
		<author>
			<persName><forename type="first">T</forename><surname>Luechtefeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9qKD4Md">Toxicol. Sci</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page">186</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Luechtefeld, T. et al. Machine learning of toxicological big data enables read-across structure activity relationships (RASAR) outperforming animal test reproducibility. Toxicol. Sci. 165, 198-212 (2018). 186</note>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main" xml:id="_nwFk4KW">Realizing private and practical pharmacological collaboration</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hie</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aat4807</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_J8XrqPy">Science</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="page">187</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hie, B. et al. Realizing private and practical pharmacological collaboration. Science 362, 347-350 (2018). 187</note>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main" xml:id="_n6YsyAG">IBM&apos;s Watson supercomputer recommended &apos;unsafe and incorrect&apos; cancer treatments, internal documents show</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bilsland</surname></persName>
		</author>
		<ptr target="191" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_aKZ2UG4">Artificially-intelligent robot scientist &apos;Eve&apos; could boost search for new drugs</title>
		<imprint>
			<date type="published" when="2015">2018. 2015. 2018. 2018</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">188</biblScope>
		</imprint>
		<respStmt>
			<orgName>University of Cambridge Research</orgName>
		</respStmt>
	</monogr>
	<note>Plasmodium dihydrofolate reductase is a second enzyme target for the antimalarial action of triclosan Stat News As FDA signals wider AI approval, hospitals have a role to play Healthcare IT News</note>
	<note type="raw_reference">Bilsland, E. et al. Plasmodium dihydrofolate reductase is a second enzyme target for the antimalarial action of triclosan. Sci. Rep. 8, 1038 (2018). 188. Artificially-intelligent robot scientist &apos;Eve&apos; could boost search for new drugs. In University of Cambridge Research https://www.cam.ac.uk/research/news/ artificially-intelligent-robot-scientist-eve-could-boost-search-for-new-drugs (2015). 189. Ross, C. &amp; Swetlitz, I. IBM&apos;s Watson supercomputer recommended &apos;unsafe and incorrect&apos; cancer treatments, internal documents show. In Stat News https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe- incorrect-treatments/ (2018). 190. Miliard, M. As FDA signals wider AI approval, hospitals have a role to play. In Healthcare IT News https://www.healthcareitnews.com/news/fda-signals- wider-ai-approval-hospitals-have-role-play (2018). 191</note>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main" xml:id="_98zQxW2">Can we open the black box of AI?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Castelvecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZWFup8N">Nature</title>
		<imprint>
			<biblScope unit="volume">538</biblScope>
			<biblScope unit="page">192</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Castelvecchi, D. Can we open the black box of AI? Nature 538, 20-23 (2016). 192</note>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main" xml:id="_P9jeaUP">The dark secret at the heart of AI</title>
		<author>
			<persName><forename type="first">W</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weinberger</surname></persName>
		</author>
		<ptr target="https://www.wired.com/story/our-machines-now-have-knowledge-well-never-understand/(2017).194" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_fynQJtr">Our machines now have knowledge we&apos;ll never understand</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>MIT Technology Review Backchannel</note>
	<note type="raw_reference">Knight, W. The dark secret at the heart of AI. In MIT Technology Review https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart- of-ai/ (2017). 193. Weinberger, D. Our machines now have knowledge we&apos;ll never understand. In Backchannel https://www.wired.com/story/our-machines-now-have- knowledge-well-never-understand/ (2017). 194</note>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main" xml:id="_w6R28Sm">be taught to explain itself?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Can</surname></persName>
		</author>
		<ptr target=").195" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_rgM2yue">The New York Times</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kuang, C. Can A.I. be taught to explain itself? In The New York Times https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to- explain-itself.html (2017). 195</note>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main" xml:id="_6X2mWWm">Socioeconomic status and the 25 Ã 25 risk factors as determinants of premature mortality: a multicohort study and meta-analysis of 1.7 million men and women</title>
		<author>
			<persName><forename type="first">S</forename><surname>Stringhini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YFYG9Fz">Lancet</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="page">196</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stringhini, S. et al. Socioeconomic status and the 25 Ã 25 risk factors as determinants of premature mortality: a multicohort study and meta-analysis of 1.7 million men and women. Lancet 389, 1229-1237 (2017). 196</note>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main" xml:id="_Kc8jsfM">Cancer scientists have ignored African DNA in the search for cures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wapner</surname></persName>
		</author>
		<ptr target="https://www.newsweek.com/2018/07/27/cancer-cure-genome-cancer-treatment-africa-genetic-charles-rotimi-dna-human-1024630.html" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_4SkM5Wm">Newsweek</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">197</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Wapner, J. Cancer scientists have ignored African DNA in the search for cures. In Newsweek https://www.newsweek.com/2018/07/27/cancer-cure- genome-cancer-treatment-africa-genetic-charles-rotimi-dna- human-1024630.html (2018). 197</note>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main" xml:id="_BTCM9rN">Want less-biased decisions? Use algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Miller</surname></persName>
		</author>
		<ptr target="https://hbr.org/2018/07/want-less-biased-decisions-use-algorithms(2018).198" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_pvm3e2k">Harvard Business Review</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Miller, A. P. Want less-biased decisions? Use algorithms. In Harvard Business Review https://hbr.org/2018/07/want-less-biased-decisions-use- algorithms (2018). 198</note>
</biblStruct>

<biblStruct xml:id="b188">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Brundage</surname></persName>
		</author>
		<ptr target="https://arxiv.org/ftp/arxiv/papers/1802/1802.07228.pdf" />
		<title level="m" xml:id="_HpRAvnA">The malicious use of artificial intelligence: forecasting, prevention, and mitigation</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">199</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Brundage, M. et al. The malicious use of artificial intelligence: forecasting, prevention, and mitigation. Preprint at https://arxiv.org/ftp/arxiv/ papers/1802/1802.07228.pdf (2018). 199</note>
</biblStruct>

<biblStruct xml:id="b189">
	<monogr>
		<title level="m" type="main" xml:id="_ybaSMDk">Adversarial attacks against medical deep learning systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Finlayson</surname></persName>
		</author>
		<ptr target=").200" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Finlayson, S. et al. Adversarial attacks against medical deep learning systems. Preprint at https://arxiv.org/abs/1804.05296 (2018). 200</note>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main" xml:id="_Cy28cdg">The health data conundrum</title>
		<author>
			<persName><forename type="first">K</forename><surname>Haun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Topol</surname></persName>
		</author>
		<ptr target=").201" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZztnwEn">The New York Times</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Haun, K. &amp; Topol, E. The health data conundrum. In The New York Times https://www.nytimes.com/2017/01/02/opinion/the-health-data-conundrum. html (2017). 201</note>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main" xml:id="_edXa4zp">Unpatients-why patients should own their medical data</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Kish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qukCz6f">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">202</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kish, L. J. &amp; Topol, E. J. Unpatients-why patients should own their medical data. Nat. Biotechnol. 33, 921-924 (2015). 202</note>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main" xml:id="_Thdrje2">the digital republic</title>
		<author>
			<persName><forename type="first">N</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName><surname>Estonia</surname></persName>
		</author>
		<ptr target=").203" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_6zQCR5v">The New Yorker</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Heller, N. Estonia, the digital republic. In The New Yorker https://www. newyorker.com/magazine/2017/12/18/estonia-the-digital-republic (2017). 203</note>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main" xml:id="_ptBTYJU">The truth about &quot;self-driving&quot; cars</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shladover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7RbYK3z">Scientific American</title>
		<imprint>
			<biblScope unit="volume">314</biblScope>
			<biblScope unit="page">204</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shladover, S. The truth about &quot;self-driving&quot; cars. In Scientific American 314, 53-57 (2016). 204</note>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main" xml:id="_bPF7Zmd">On computable numbers with an application to the Entscheidungsproblem</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5QA5PBr">P. Lond. Match. Soc. s</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">42</biblScope>
			<biblScope unit="page">205</biblScope>
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Turing, A. M. On computable numbers with an application to the Entscheidungsproblem. P. Lond. Match. Soc. s2-42, 230-265 (1936). 205</note>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main" xml:id="_SE8BsVE">Computing machinery and intelligence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZXemAd3">Mind</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page">206</biblScope>
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Turing, A. M. Computing machinery and intelligence. Mind 59, 433-460 (1950). 206</note>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main" xml:id="_65eJTJ8">A logical calculus of the ideas immanent in nervous activity</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pitts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wf89d27">Bull. Math. Biophys</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">207</biblScope>
			<date type="published" when="1943">1943</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McCulloch, W. S. &amp; Pitts, W. A logical calculus of the ideas immanent in nervous activity. Bull. Math. Biophys. 5, 115-133 (1943). 207</note>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main" xml:id="_nH2Q3MC">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_RKdcQPG">NIPS&apos;12 Proceedings of the 25th International Conference on Neural Information Processing Systems 1097-1105</title>
		<imprint>
			<publisher>NIPS</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">208</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Krizhevsky, A. et al. ImageNet classification with deep convolutional neural networks. In NIPS&apos;12 Proceedings of the 25th International Conference on Neural Information Processing Systems 1097-1105 (NIPS, 2012). 208</note>
</biblStruct>

<biblStruct xml:id="b198">
	<monogr>
		<title level="m" type="main" xml:id="_7D5wnkV">Squeeze-and-excitation networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr.2018.00745</idno>
		<ptr target=").209" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Hu, J. et al. Squeeze-and-excitation networks. Preprint at https://arxiv.org/ abs/1709.01507 (2017). 209</note>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<title level="m" type="main" xml:id="_pSv7g5F">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<ptr target=").210" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Russakovsky, O. et al. ImageNet Large Scale Visual Recognition Challenge. Preprint at https://arxiv.org/abs/1409.0575 (2014). 210</note>
</biblStruct>

<biblStruct xml:id="b200">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<title level="m" xml:id="_2B8tfNy">Deep Learning</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">211</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Goodfellow, I et al. Deep Learning (MIT Press, Cambridge, MA, USA, 2016). 211</note>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main" xml:id="_NwUdx5m">Artificial intelligence in healthcare</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2g6V72e">Nature Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">212</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yu, K.-H. et al. Artificial intelligence in healthcare. Nature Biomed. Eng. 2, 719-731 (2018). 212</note>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<title level="m" type="main" xml:id="_rp3dhFd">High-resolution mammogram synthesis using progressive generative adversarial networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Korkinof</surname></persName>
		</author>
		<ptr target=").213" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Korkinof, D. et al. High-resolution mammogram synthesis using progressive generative adversarial networks. Preprint at https://arxiv.org/abs/1807.03401 (2018). 213</note>
</biblStruct>

<biblStruct xml:id="b203">
	<monogr>
		<title level="m" type="main" xml:id="_hAsyhGB">Generating highly realistic images of skin lesions with GANs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baur</surname></persName>
		</author>
		<ptr target=").214" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Baur, C. et al. Generating highly realistic images of skin lesions with GANs. Preprint at https://arxiv.org/abs/1809.01410 (2018). 214</note>
</biblStruct>

<biblStruct xml:id="b204">
	<monogr>
		<title level="m" type="main" xml:id="_DegM6K8">GANs for medical image analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kazeminia</surname></persName>
		</author>
		<ptr target=").215" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Kazeminia, S. et al. GANs for medical image analysis. Preprint at https:// arxiv.org/abs/1809.06222 (2018). 215</note>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main" xml:id="_eCkJvSx">VIEWS! Synthetic medical images for machine learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName><surname>Fake</surname></persName>
		</author>
		<ptr target="https://towardsdatascience.com/harnessing-infinitely-creative-machine-imagination-6801a9fb4ca9" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_YMuD6Ww">Towards Data Science</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">216</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Harvey, H. FAKE VIEWS! Synthetic medical images for machine learning. In Towards Data Science https://towardsdatascience.com/harnessing- infinitely-creative-machine-imagination-6801a9fb4ca9 (2018). 216</note>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main" xml:id="_gncRz8G">Deep echocardiography: data-efficient supervised and semisupervised deep learning towards automated diagnosis of cardiac disease</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8PEAc8V">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">59</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Madani, A. et al. Deep echocardiography: data-efficient supervised and semisupervised deep learning towards automated diagnosis of cardiac disease. NPJ Digit. Med. 1, 59 (2018).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
