<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_EEDX5DS">A study of generative large language model for medical research and healthcare</title>
				<funder ref="#_SS8QSp6">
					<orgName type="full">National Cancer Institute</orgName>
					<orgName type="abbreviated">NCI</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000054</idno>
				</funder>
				<funder ref="#_kaVwhzc">
					<orgName type="full">Cancer Informatics and eHealth core jointly</orgName>
				</funder>
				<funder>
					<orgName type="full">UF Health Cancer Center</orgName>
				</funder>
				<funder>
					<orgName type="full">UF Clinical and Translational Science Institute</orgName>
				</funder>
				<funder ref="#_uMsW7YT">
					<orgName type="full">National Institute on Aging</orgName>
					<orgName type="abbreviated">NIA</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000049</idno>
				</funder>
				<funder ref="#_UadeT38">
					<orgName type="full">Patient-Centered Outcomes Research Institute® (PCORI®) Award</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Cheng</forename><surname>Peng</surname></persName>
							<idno type="ORCID">0000-0002-1994-893X</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xi</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Cancer Informatics Shared Resource , University of Florida Health Cancer Center , Gainesville , FL , USA.</note>
								<orgName type="department">Cancer Informatics Shared Resource</orgName>
								<orgName type="institution">University of Florida Health Cancer Center</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aokun</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Cancer Informatics Shared Resource , University of Florida Health Cancer Center , Gainesville , FL , USA.</note>
								<orgName type="department">Cancer Informatics Shared Resource</orgName>
								<orgName type="institution">University of Florida Health Cancer Center</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaleb</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> NVIDIA , Santa Clara , CA , USA.</note>
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nima</forename><surname>Pournejatian</surname></persName>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> NVIDIA , Santa Clara , CA , USA.</note>
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><forename type="middle">B</forename><surname>Costa</surname></persName>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> NVIDIA , Santa Clara , CA , USA.</note>
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cheryl</forename><surname>Martin</surname></persName>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> NVIDIA , Santa Clara , CA , USA.</note>
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mona</forename><forename type="middle">G</forename><surname>Flores</surname></persName>
							<idno type="ORCID">0000-0002-7362-3044</idno>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> NVIDIA , Santa Clara , CA , USA.</note>
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ying</forename><surname>Zhang</surname></persName>
							<idno type="ORCID">0000-0003-4210-2104</idno>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Research Computing , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department">Research Computing</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tanja</forename><surname>Magoc</surname></persName>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Integrated Data Repository Research Services , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department">Integrated Data Repository Research Services</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gloria</forename><surname>Lipori</surname></persName>
							<idno type="ORCID">0000-0001-5616-2701</idno>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Integrated Data Repository Research Services , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department">Integrated Data Repository Research Services</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Lillian S. Wells Department of Neurosurgery , Clinical and Translational Science Institute , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Lillian S. Wells Department of Neurosurgery</orgName>
								<orgName type="department" key="dep2">Clinical and Translational Science Institute</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Duane</forename><forename type="middle">A</forename><surname>Mitchell</surname></persName>
							<idno type="ORCID">0000-0001-6049-213X</idno>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Lillian S. Wells Department of Neurosurgery , Clinical and Translational Science Institute , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Lillian S. Wells Department of Neurosurgery</orgName>
								<orgName type="department" key="dep2">Clinical and Translational Science Institute</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Naykky</forename><forename type="middle">S</forename><surname>Ospina</surname></persName>
							<affiliation key="aff6">
								<note type="raw_affiliation"><label>7</label> Division of Endocrinology , Department of Medicine , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Division of Endocrinology</orgName>
								<orgName type="department" key="dep2">Department of Medicine</orgName>
								<orgName type="department" key="dep3">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mustafa</forename><forename type="middle">M</forename><surname>Ahmed</surname></persName>
							<affiliation key="aff7">
								<note type="raw_affiliation"><label>8</label> Division of Cardiovascular Medicine , Department of Medicine , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Division of Cardiovascular Medicine</orgName>
								<orgName type="department" key="dep2">Department of Medicine</orgName>
								<orgName type="department" key="dep3">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><forename type="middle">R</forename><surname>Hogan</surname></persName>
							<idno type="ORCID">0000-0002-9881-1017</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elizabeth</forename><forename type="middle">A</forename><surname>Shenkman</surname></persName>
							<idno type="ORCID">0000-0003-4903-1804</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yi</forename><surname>Guo</surname></persName>
							<idno type="ORCID">0000-0003-0587-4105</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Cancer Informatics Shared Resource , University of Florida Health Cancer Center , Gainesville , FL , USA.</note>
								<orgName type="department">Cancer Informatics Shared Resource</orgName>
								<orgName type="institution">University of Florida Health Cancer Center</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiang</forename><surname>Bian</surname></persName>
							<idno type="ORCID">0000-0002-2238-5429</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Cancer Informatics Shared Resource , University of Florida Health Cancer Center , Gainesville , FL , USA.</note>
								<orgName type="department">Cancer Informatics Shared Resource</orgName>
								<orgName type="institution">University of Florida Health Cancer Center</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
							<email>yonghui.wu@ufl.edu</email>
							<idno type="ORCID">0000-0002-6780-6135</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA.</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Cancer Informatics Shared Resource , University of Florida Health Cancer Center , Gainesville , FL , USA.</note>
								<orgName type="department">Cancer Informatics Shared Resource</orgName>
								<orgName type="institution">University of Florida Health Cancer Center</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_9f8Vgcg">A study of generative large language model for medical research and healthcare</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F418FA6C3070B2B3BF90A27550762821</idno>
					<idno type="DOI">10.1038/s41746-023-00958-w</idno>
					<note type="submission">Received: 5 June 2023; Accepted: 1 November 2023;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T06:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_F8TJdtp"><p xml:id="_UMJEU9x"><s xml:id="_zxCFVXe">There are enormous enthusiasm and concerns in applying large language models (LLMs) to healthcare.</s><s xml:id="_uSeF3R6">Yet current assumptions are based on general-purpose LLMs such as ChatGPT, which are not developed for medical use.</s><s xml:id="_W7tycdX">This study develops a generative clinical LLM, GatorTronGPT, using 277 billion words of text including (1) 82 billion words of clinical text from 126 clinical departments and approximately 2 million patients at the University of Florida Health and (2) 195 billion words of diverse general English text.</s><s xml:id="_MYzGfYP">We train GatorTronGPT using a GPT-3 architecture with up to 20 billion parameters and evaluate its utility for biomedical natural language processing (NLP) and healthcare text generation.</s><s xml:id="_jWdEJT4">GatorTronGPT improves biomedical natural language processing.</s><s xml:id="_FaCgsRt">We apply GatorTronGPT to generate 20 billion words of synthetic text.</s><s xml:id="_5VE6fFq">Synthetic NLP models trained using synthetic text generated by GatorTronGPT outperform models trained using real-world clinical text.</s><s xml:id="_hJGtFA4">Physicians' Turing test using 1 (worst) to 9 (best) scale shows that there are no significant differences in linguistic readability (p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical relevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that physicians cannot differentiate them (p &lt; 0.001).</s><s xml:id="_jezHMcy">This study provides insights into the opportunities and challenges of LLMs for medical research and healthcare.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_kdPJvYJ">INTRODUCTION</head><p xml:id="_S8mmutz"><s xml:id="_JmesZqh">Generative large language models (LLMs) such as the ChatGPT <ref type="bibr" target="#b0">1</ref> have surprised the world by answering questions conversationally and generating textual content such as emails, articles, and even computer codes, triggering enormous enthusiasm in applying LLMs to healthcare <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref> .</s><s xml:id="_UZFyApf">People are enthusiastic about LLMs in the potential to facilitate documentation of patient reports (e.g., a progress report) <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4</ref> , improving diagnostic accuracy <ref type="bibr" target="#b4">5</ref> , and assisting in various clinical care <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7</ref> , while at the same time concerning the hallucinations and fabrications <ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8</ref> , bias and stereotype <ref type="bibr" target="#b8">9</ref> , and risks of patient privacy and ethics <ref type="bibr" target="#b9">10</ref> .</s><s xml:id="_wzyAjmA">Yet, this enthusiasm and concerns are based on ChatGPT, which is not designed for healthcare use <ref type="bibr" target="#b0">1</ref> .</s><s xml:id="_HM24JJP">Until now, it is unclear how this disruptive technology can help medical research and potentially improve the quality of healthcare.</s></p><p xml:id="_xmVyKKp"><s xml:id="_5X8jKZr">Language model is a simple statistical distribution used in natural language processing (NLP) to formulate the probability of a sequence of words or the next word in a sequence.</s><s xml:id="_RyEdAQR">Surprisingly, when it is used as a learning objective to train a specific neural network architecture named transformer, and when the model size is very large such as billions or hundreds of billions of parameters, important artificial intelligence (AI) emerges.</s><s xml:id="_qgts3Ms">For example, LLMs can learn knowledge from one task and apply it to another task (i.e., transfer learning), learn from very few labeled samples (i.e., few-shot learning), and learn without human-labeled samples (i.e., zero-shot learning) <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref> .</s><s xml:id="_qwFf3wE">The LLM pretrained using decoder-only transformer such as GPT-3 is known as generative LLM as it can generate human-like text.</s><s xml:id="_RmxkeFb">The conversational ability of LLMs is achieved using prompt-based text generation <ref type="bibr" target="#b13">14</ref> , the key technology guiding LLMs to generate reasonable answers and contextual contents.</s></p><p xml:id="_7ktzfeP"><s xml:id="_J37Hu9A">This study aims to develop a generative LLM using real-world clinical text and evaluate its utility for medical research and healthcare.</s><s xml:id="_HKUps7V">We train GatorTronGPT using 82 billion words of deidentified clinical text <ref type="bibr" target="#b14">15</ref> from University of Florida (UF) Health and 195 billion diverse English words from the Pile <ref type="bibr" target="#b15">16</ref> dataset.</s><s xml:id="_nHmYNvQ">We train GatorTronGPT from scratch using the GPT-3 <ref type="bibr" target="#b16">17</ref> architecture.</s><s xml:id="_bcSQjQ6">We formulate biomedical relation extraction and question answering using a unified text generation architecture <ref type="bibr" target="#b17">18</ref> to evaluate how GatorTronGPT could benefit medical research using 6 benchmark datasets.</s><s xml:id="_KCXZrYY">To examine the utility of text generation in the clinical domain, we apply GatorTronGPT to generate 20 billion words of synthetic clinical text, which are used to train synthetic NLP models using BERT <ref type="bibr" target="#b18">19</ref> architecture, denoted as GatorTronS ('S' stands for synthetic).</s><s xml:id="_xPKq7jh">We compare GatorTronS models with GatorTron <ref type="bibr" target="#b14">15</ref> , a clinical NLP model trained using real-world 90 billion words of text, to test the hypothesis that generative clinical LLMs can be used to generate synthetic clinical text for medical research.</s><s xml:id="_nQnM2Qg">To test if LLMs could be used in healthcare, two internal medicine subspecialists from endocrinology (NSO) and cardiology (MMA) manually evaluate clinical paragraphs written by Gator-TronGPT compared with real-world paragraphs written by UF Health physicians.</s><s xml:id="_Adb5Ta3">Figure <ref type="figure">1</ref> shows an overview of the study design.</s></p><p xml:id="_cGwaV8E"><s xml:id="_VcDTsZh">This study provides valuable insights into the opportunities and challenges of LLMs for medical research and healthcare.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_UKGKKAq">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XrSxdFw">Training of GatorTronGPT from scratch</head><p xml:id="_z6Z8muH"><s xml:id="_SJBHQR6">Training the 5 billion GatorTronGPT model used approximately 6 days and the 20 billion model used about 20 days on 560 A100 80 G GPUs from 70 NVIDIA DGX nodes using the NVIDIA SuperPOD reference cluster architecture.</s><s xml:id="_BWyrKwZ">Figure <ref type="figure">2</ref> shows the training and validation loss.</s><s xml:id="_MUzA5wM">Table <ref type="table" target="#tab_0">1</ref> compares GatorTronGPT with GatorTronS and GatorTron on model architecture, training dataset, parameter size, and whether the model is a generative LLM, to help differentiate the three LLMs.</s></p><p xml:id="_z9Mutnq"><s xml:id="_G8qrtw9">GatorTronGPT for Biomedical natural language processing Table <ref type="table" target="#tab_1">2a</ref> compares GatorTronGPT with four existing biomedical transformer models on end-to-end relation extraction of drugdrug interaction, chemical-disease relation, and drug-target interaction.</s><s xml:id="_dHbgQmB">GatorTronGPT outperformed all existing models, with the best F1-score of 0.500, 0.494, and 0.419, respectively.</s><s xml:id="_mZSRfD4">GatorTronGPT improved state-of-the-art by 3-10% compared with the second-best BioGPT 18 model.</s><s xml:id="_55f7jVz">We consistently observed performance improvement when scaling up the size of Gator-TronGPT.</s><s xml:id="_ccgRFdF">Table <ref type="table" target="#tab_1">2b</ref> compares GatorTronGPT with six existing biomedical transformers using three benchmark datasets for biomedical question answering.</s><s xml:id="_EKx9V6u">The GatorTronGPT model with 20 billion parameters tied with BioLinkBERT on the MedQA dataset achieving the best performance of 0.451.</s><s xml:id="_2eFHgWD">GatorTronGPT also achieved the second-best performance of 0.776 for the Pub-MedQA dataset compared with the best performance of 0.782 from BioGPT.</s><s xml:id="_cd5v8ZN">The performance of GatorTronGPT on the MedMCQA dataset was lower than a much larger LLM, Galactica, with 120 billion parameters.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_AAkVDQ2">Evaluation of GatorTronS</head><p xml:id="_nk8jBTk"><s xml:id="_MhVMjBH">Tables <ref type="table" target="#tab_2">3</ref> and <ref type="table" target="#tab_3">4</ref> compare GatorTronS trained with different sizes of synthetic clinical text with ClinicalBERT and GatorTron <ref type="bibr" target="#b14">15</ref> .</s><s xml:id="_v6yq9q9">For clinical concept extraction, GatorTronS, trained using 20 billion and 5 billion synthetic clinical text, achieved the best F1-score for a b Fig. 2 Training loss and validation loss for GatorTronGPT 5 billion and 20 billion models.</s><s xml:id="_PHjfd3U">a Training loss.</s><s xml:id="_B6mGG2w">b Validation loss.</s></p><p xml:id="_dnzWEPb"><s xml:id="_mX6F9dw">the three benchmark datasets.</s><s xml:id="_Bx48CGY">GatorTronS outperformed the original GatorTron model by &gt;1% F1-score on all three benchmark datasets.</s><s xml:id="_CsMfDEa">For medical relation extraction, the GatorTronS trained using 10 billion synthetic clinical text achieved the best F1-score of 0.962 on the 2018 n2c2 challenge benchmark dataset, which is comparable with the original GatorTron model (0.960).</s><s xml:id="_JkuwsMa">For semantic textual similarity and natural language inference, GatorTronS achieved the best evaluation scores, outperforming the original GatorTron by &gt;1%.</s><s xml:id="_78tYDnC">For question answering using emrQA dataset, GatorTronS outperformed the original GatorTron model trained using real-world clinical text by &gt;1%.</s><s xml:id="_29MvXc6">The comparison results show that a minimum of 5 billion words of synthetic clinical text are required to train a synthetic model with comparable performance to GatorTron, a transformer trained using 82 billion words of real-world UF Health clinical text.</s><s xml:id="_U8NCrQN">Figure <ref type="figure" target="#fig_1">3</ref> compares GatorTronS models trained with different sizes of synthetic text using line plots.</s><s xml:id="_JTRfJuA">We observed consistent performance improvements from all eight datasets by increasing the size of synthetic text from 1 billion to 5 billion words.</s><s xml:id="_nt7yjDj">The improvements are not consistent when increasing the data size from 5 billion up to 20 billion words.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_SsYDZUN">Physicians' Turing test</head><p xml:id="_Gwn9yqu"><s xml:id="_G2n374S">The Turing test results show that, on average, less than half (49.2%) of the clinical notes were identified correctly, including 36.7% of the synthetic notes and 61.7% of the human notes (Table <ref type="table" target="#tab_5">5a</ref>).</s><s xml:id="_aCGs7Cf">Among the 30 synthetic notes written by Gator-TronGPT, 9 (30.0%) and 13 (43.4%)</s><s xml:id="_9JMSnaY">were correctly labeled as 'AI' by the two physicians, respectively.</s><s xml:id="_94UZmVk">Among the 30 human notes written by physicians, 17 (56.7%)</s><s xml:id="_yW92fug">and 20 (66.7%) were correctly labeled as 'Human', respectively.</s><s xml:id="_9VJn3HW">Considering GatorTronGPT was considered as a human for more than 30% of the instances (the criteria from Turing test) <ref type="bibr" target="#b19">20</ref> , GatorTronGPT passed the Turing test    reliability were found to be good or excellent, as summarized in Supplementary Tables <ref type="table" target="#tab_1">S2</ref> and <ref type="table" target="#tab_2">S3</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_TgmZG5f">DISCUSSION</head><p xml:id="_ZetvhU9"><s xml:id="_mCRMdcG">This study develops a generative clinical LLM, GatorTronGPT, using the GPT-3 architecture <ref type="bibr" target="#b12">13</ref> with 277 billion words of mixed clinical and English text.</s><s xml:id="_XKNTsdV">GatorTronGPT achieves state-of-the-art performance for four out of six biomedical NLP benchmark datasets.</s><s xml:id="_CMT4cEv">Our previous GatorTron <ref type="bibr" target="#b14">15</ref> model, trained using an encoder-only BERT architecture with 8.9 billion parameters, also achieved state-ofthe-art performance on six clinical NLP benchmark datasets.</s><s xml:id="_v8MXy9j">The two studies demonstrate the benefit of LLMs for biomedical and clinical research.</s><s xml:id="_2CGccGA">GatorTronGPT can generate synthetic clinical text for developing synthetic clinical NLP models (i.e., GatorTronS), which achieve better or comparable performance to GatorTron, an NLP model trained using real-world clinical text, demonstrating the utility of synthetic clinical text generation.</s><s xml:id="_fM9J2AB">The physicians' Turing test show that GatorTronGPT can generate clinical text with comparable linguistic readability and clinical relevance to realworld clinical notes.</s><s xml:id="_GSZQUeY">This study provides valuable insights into the opportunities and challenges of generative LLMs for medical research and healthcare.</s></p><p xml:id="_QY9Xmnp"><s xml:id="_fZNUWQ2">We discover an important utility of synthetic clinical text generation.</s><s xml:id="_P9gX54f">To date, there has been a gap in accessing and sharing large-scale clinical text and clinical LLMs due to the sensitive nature of clinical text and the fact that automatic deidentification systems cannot remove 100% protected health Generative LLMs aspire to become a "Unified Field Theory" to unify most fundamental NLP tasks using a single model architecture.</s><s xml:id="_cRShJWH">It might be still early to judge if LLMs will become the one and only foundation model <ref type="bibr" target="#b11">12</ref> for NLP, but it looks like we are closer than ever.</s><s xml:id="_mvSZgpd">Generative LLMs have the potential to impact medical research in many aspects.</s><s xml:id="_VWSvw4N">In addition to performance improvement demonstrated in this study, generative LLMs provide a unified solution using prompt-based text generation <ref type="bibr" target="#b24">25</ref> , which leads to a new paradigm of "one model for all NLP tasks" and has better few-shot learning and transfer learning ability to deliver portable clinical NLP systems <ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26</ref> .</s><s xml:id="_YPzqpQc">The evaluation of GatorTronGPT shows that clinical LLMs can be used to generate clinical-relevant content with the potential to help document <ref type="bibr" target="#b2">3</ref> and code patient information in EHR systems, thus reducing the extensively onerous documentation burden for clinicians <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref> .</s><s xml:id="_2nw9yJT">The prompt-based text generation of LLMs can potentially help compose treatment plans by integrating instructions from clinical guidelines and patients' historical records in EHRs.</s><s xml:id="_dVfbUGw">The conversational ability of LLMs provides opportunities to develop intelligent EHR systems with human-like communication <ref type="bibr" target="#b1">2</ref> , where healthcare providers, patients, and other stakeholders can communicate in an intelligent electronic health record (EHR) system.</s><s xml:id="_dtnBmfD">Industry stakeholders such as Epic and Nuance have been reported to be exploring these potentials <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31</ref> .</s></p><p xml:id="_MUPJ2Hm"><s xml:id="_CbbswTX">Our Turing test focuses on (1) linguistic readability; (2) clinical relevance; and (3) physicians' ability to differentiate synthetic and human notes.</s><s xml:id="_Rg7m5RR">The statistical tests show that there are no significant differences in linguistic readability (p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) or clinical relevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human).</s></p><p xml:id="_5TAuNYn"><s xml:id="_EzXfedZ">Further, physicians cannot differentiate them (p &lt; 0.001), suggesting the potential utility of GatorTronGPT for text generation in healthcare.</s><s xml:id="_DEDUqqe">Two physician evaluators find that the texts written by GatorTronGPT generally lack clinical logic, indicating that more research and development are needed to make this technology mature for healthcare.</s><s xml:id="_N62cfUr">Our Turing test focuses on statistical differences not utility in real-world clinical practice, which should be examined in future studies when this technology matures.</s><s xml:id="_4TjbNkp">A recent study <ref type="bibr" target="#b31">32</ref> examined an LLM developed at New York University, i.e., NYUTron, and our previously developed Gator-Tron <ref type="bibr" target="#b14">15</ref> for prediction of readmission, in-hospital mortality, comorbidity, length of stay, and insurance denial, demonstrating the potential utility of LLMs in healthcare.</s></p><p xml:id="_CFD7qQp"><s xml:id="_GS35KhS">While LLMs are promising for healthcare applications, much more research and development are needed to achieve this goal.</s><s xml:id="_wGUa86j">Current general-purpose LLMs are designed for conversation as a chatbot outside of healthcare.</s><s xml:id="_35nKax3">Therefore, the current use of ChatGPT for healthcare is more like a typical case of intended use versus actual use as described in the medical device regulation <ref type="bibr" target="#b32">33</ref> .</s><s xml:id="_u96FGPB">Domain-specific LLMs are needed for clinical applications.</s><s xml:id="_b5fP43j">Due to the noisy data and probabilistic nature of text generation, LLMs are prone to confabulation or hallucination, which is dangerous for healthcare.</s><s xml:id="_65NXdyW">In this study, we adopted robust decoding strategies (e.g., nucleus sampling) to alleviate potential off-target text generation.</s><s xml:id="_bBHSRNR">Researchers are exploring solutions such as reinforcement learning from human feedback (RLHF) <ref type="bibr" target="#b33">34</ref> to reduce hallucinations, but it is still a not yet solved limitation of current LLMs.</s><s xml:id="_cDC8EEF">Future studies should explore strategies to better control the hallucinations at a minimal level to ensure the safety of using LLMs in healthcare.</s><s xml:id="_CYZGu5v">The security and risk of LLMs must be carefully examined in healthcare settings.</s><s xml:id="_vrDd8Uw">We applied a de-identification system to remove PHIs from UF Health notes before training GatorTronGPT, future studies should carefully examine if Gator-TronGPT has potential risk of speaking out PHIs and quantify the potential risk of re-identify real-world patients.</s><s xml:id="_s7ETcZh">Synthetic data, though generated by AI models, may still mirror the characteristics of its source material (e.g., UF health clinical notes).</s><s xml:id="_wvhEgDe">For example, ChatGPT has been reported to accidentally leak sensitive business data from a private company <ref type="bibr" target="#b34">35</ref> .</s><s xml:id="_ZGBK88Q">In addition, people are increasingly aware of the potential bias of AI applications in healthcare.</s><s xml:id="_c6mAJ6n">Bias inherited from the original training data may be imitated and sometimes even amplified by AI models, which may cause systematic bias to specific patient groups <ref type="bibr" target="#b35">36</ref> .</s><s xml:id="_qRbf378">Future studies should explore strategies to mitigate potential bias and ensure fairness of LLM applications.</s><s xml:id="_Qu3DZsJ">Like any medical AI applications, it is necessary to carefully examine this disruptive new technology to guide its application and make it "approved " AI-enabled medical tool <ref type="bibr" target="#b36">37</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_2cP9UgH">METHODS</head><p xml:id="_FQqKnQe"><s xml:id="_R5kHQg7">We developed GatorTronGPT using 82 billion words of deidentified clinical text <ref type="bibr" target="#b14">15</ref> from the University of Florida (UF) Health and 195 billion diverse English words from the Pile 16 dataset.</s><s xml:id="_DrdMF5T">We trained GatorTronGPT from scratch using the GPT-3 17 architecture (used by ChatGPT).</s><s xml:id="_5Bu2wVG">We formulated biomedical relation extraction and question answering using a unified text generation architecture <ref type="bibr" target="#b17">18</ref> and evaluated GatorTronGPT using 6 biomedical benchmark datasets.</s><s xml:id="_SvgKrnc">To examine the utility of text generation, we applied GatorTronGPT to generate 20 billion words of synthetic clinical text, which were used to train synthetic NLP models, denoted as GatorTronS ("S" stands for synthetic).</s><s xml:id="_VddFMRS">We compared GatorTronS with GatorTron <ref type="bibr" target="#b14">15</ref> , a clinical NLP model trained with the same architecture but using real-world clinical text.</s><s xml:id="_FAuyKw5">To test if LLMs could generate text for healthcare settings, two internal medicine subspecialists from endocrinology (NSO) and cardiology (MMA) manually evaluated 60 clinical paragraphs including 30 paragraphs written by GatorTronGPT randomly mixed with 30 real-world paragraphs written by UF Health physicians.</s><s xml:id="_wadUWeG">Figure <ref type="figure">1</ref> shows an overview of the study design.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_bZpPgGa">Data source</head><p xml:id="_Xc37dfc"><s xml:id="_VzDxJcq">This study used 82 billion words of clinical narratives from UF Health Integrated Data Repository (IDR) and 195 billion words of diverse English words from the Pile <ref type="bibr" target="#b15">16</ref> corpus.</s><s xml:id="_UhYP5jX">This study was approved by the University of Florida Institutional Review Board under IRB202102223; the need for patient consent was waived.</s><s xml:id="_JmfsvbM">At UF Health, we collected approximately 290 million clinical notes from 2011-2021 from over 126 departments, approximately 2 million patients and 50 million encounters from inpatient, outpatient, and emergency settings <ref type="bibr" target="#b14">15</ref> .</s><s xml:id="_z4x8e34">We merged the UF Health clinical corpus with the Pile <ref type="bibr" target="#b15">16</ref> dataset to generate a large corpus with 277 billion words.</s><s xml:id="_xJgQ4jP">We performed minimal preprocessing for the Pile dataset and applied a de-identification system to remove 18 PHI categories defined in the Health Insurance Portability and Accountability Act (HIPAA) from the UF Health notes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_WphmC92">Preprocessing and de-identification of clinical text</head><p xml:id="_zrFWGEb"><s xml:id="_6ytrEsE">Following our previous study <ref type="bibr" target="#b14">15</ref> , we performed a minimal preprocessing procedure.</s><s xml:id="_b3MxBRt">First, we removed all empty notes and the notes with less than 10 characters followed by performing a deduplication at the note level using the exact string match strategy.</s><s xml:id="_rkrPQjr">Then, we leveraged an internally developed preprocessing tool (<ref type="url" target="https://github.com/uf-hobi-informatics-lab/NLPreprocessing">https://  github.com/uf-hobi-informatics-lab/NLPreprocessing</ref>) to normalize the clinical text.</s><s xml:id="_KEuVPv3">The normalization processing consists of three steps including (1) unifying all text into UTF-8 encoding, removing illegal UTF-8 strings, and removing HTML/XML tags if any; (2) sentence boundary detection where we normalize the clinical notes into sentences; (3) word tokenization where we used heuristic rules to separate punctuation and special symbols (e.g., slash, parenthesis) from words (e.g., converting "(HbA1c)" to "(HbA1c)" and "excision/ chemo" to "excision/chemo") and fixing concatenations (e.g., missing white space like converting "CancerScreening " to "Cancer Screening").</s><s xml:id="_XBxr2Ys">After preprocessing, we performed another deduplication at the sentence level using the exact string match strategy.</s></p><p xml:id="_FHBEvpf"><s xml:id="_5EyVQf8">To de-identified the UF Health clinical notes, we adopted an internally developed de-identification system which consists of an LSTM-CRFs based model and a postprocessing module replacing system-detected protected health information (PHI) entities with dummy strings (e.g., replace patients' names with [**NAME**]).</s><s xml:id="_26qUKnJ">We adopted the safe-harbor method to identify 18 PHI categories defined in the Health Insurance Portability and Accountability Act (HIPAA).</s><s xml:id="_kdjhUdh">The LSTM-CRFs model for PHI detection was trained using the publicly available 2014 i2b2 de-identification datasets and an internal dataset with over 1100 clinical notes from UF Health annotated for PHI removal (named as UF-deid-dataset; not publicly available due to IRB restrictions).</s><s xml:id="_tGJqSMU">After three years of continuous customization and improvement at UF Health, the current model achieved an overall F1 score of 97.98% (precision of 96.27% and recall of 99.76%) on the UFdeid-dataset test set, which means our de-identification system can remove 99.76% of all PHIs.</s><s xml:id="_VjCpc9s">Detailed information about the development of the de-identification system can be accessed from our previous paper <ref type="bibr" target="#b37">38</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_enVvwxB">Train GatorTronGPT from scratch</head><p xml:id="_S69A6UT"><s xml:id="_w2KrR9Q">We trained GatorTronGPT using 5 billion parameters and 20 billion parameters and determined the number of layers, hidden sizes, and number of attention heads according to the guidelines for optimal depth-to-width parameter allocation proposed by ref. <ref type="bibr" target="#b38">39</ref> as well as our previous experience in developing GatorTron <ref type="bibr" target="#b14">15</ref> .</s><s xml:id="_kwHDJTG">The 5 billion model has 24 layers, hidden size of 4,096, and number of attention heads of 32; the 20 billion model has 44 layers, hidden size of 6144, and number of attention heads of 48.</s><s xml:id="_69gtchN">We trained the 5 billion model using a 2-way tensor model parallel with a batch size of 1120 and learning rate of 1.200E-05.</s><s xml:id="_Pjv6Maw">We trained the 20 billion model using an 8-way tensor model parallel with a batch size of 560 and a learning rate of 1.000E-05.</s><s xml:id="_YdNZZg9">We adopted a dropout rate of 0.1.</s><s xml:id="_vmnrptr">We inherited the GPT-3 architecture implemented in the MegaTron-LM <ref type="bibr" target="#b39">40</ref> and trained GatorTronGPT models from scratch with the default GPT-3 loss function <ref type="bibr" target="#b12">13</ref> .</s><s xml:id="_C3UBjYU">We used a total number of 560 NVIDIA DGX A100 GPUs from 70 superPOD nodes at UF's HiPerGator-AI cluster to train GatorTronGPT by leveraging both data-level and model-level parallelisms implemented by the Megatron-LM package <ref type="bibr" target="#b39">40</ref> .</s><s xml:id="_vDxuPJb">(See <ref type="url" target="https://github.com/NVIDIA/Megatron-LM">https://github.com/NVIDIA/  Megatron-LM</ref> for more details) We monitored the training progress by training loss and validation loss using 3% of the data and stopped the training when there was no improvement.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ttxaE7g">GatorTronGPT for biomedical relation extraction and question answering</head><p xml:id="_nMzw9qk"><s xml:id="_HTYEnDQ">End-to-end relation extraction is an NLP task to identify the triplets &lt;concept1, concept2, relation&gt; from biomedical text.</s><s xml:id="_9pg4wp9">Question answering is to identify the answer for a given question and the context.</s><s xml:id="_vF9jmMU">Following previous studies <ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b40">41</ref> , we approached the two tasks using a unified prompt-based text generation architecture.</s><s xml:id="_hUf9F5M">Specifically, we adopted a fixed-LLM prompt-tuning strategy <ref type="bibr" target="#b41">42</ref> to attach a continuous embedding (i.e., virtue tokens) to the input sequence [virtual tokens; x; y] as a soft prompt to control the text generation; the LLM was not changed during training.</s><s xml:id="_rPwRZB6">We provide details in the Supplement.</s></p><p xml:id="_pUbr5yG"><s xml:id="_YXbPnta">End-to-end biomedical relation extraction.</s><s xml:id="_mCN9Acg">We compared the two GatorTronGPT models with four existing transformer models including GPT-2 <ref type="bibr" target="#b42">43</ref> , REBEL, REBEL-pt <ref type="bibr" target="#b24">25</ref> , and BioGPT 18 on three biomedical tasks for end-to-end relation extraction using three benchmark datasets including drug-drug interaction <ref type="bibr" target="#b43">44</ref> (DDI), BioCreative V chemical-disease relation <ref type="bibr" target="#b44">45</ref> (BC5CDR), and drugtarget interaction <ref type="bibr" target="#b45">46</ref> (KD-DTI).</s></p><p xml:id="_fndBqX2"><s xml:id="_nMb2SJF">GPT-2.</s><s xml:id="_wsvUPGt">GPT-2 was trained using text data from 8 million webpages with 1.5 billion parameters, which is a scale-up of the first generation of GPT45 model.</s><s xml:id="_rencBWk">The GPT model outperformed previous transformer models on 9 out of 12 NLP tasks, whereas, the GPT-2 model further demonstrated text generation ability, which laid foundation for complex NLP tasks such as machine reading comprehension and question answering.</s></p><p xml:id="_DNaGHcs"><s xml:id="_RXJrxqR">REBEL and REBEL-pt.</s><s xml:id="_4X5Btx5">REBEL is a transformer model based on the BART architecture designed for end-to-end relation extraction using sequence-to-sequence modeling, which outperformed previous relation extraction models based on classifications.</s><s xml:id="_3MBzj3N">REBEL-pt is an enhanced version of REBEL by further fine-tuning it using the triplets derived using Wikipedia hyperlinks.</s></p><p xml:id="_BT5YY8c"><s xml:id="_UmMaXTN">BioGPT.</s><s xml:id="_kHm48Nk">BioGPT is a domain-specific generative transformerbased LLM developed using the GPT-2 architecture and the Pubmed biomedical literature, which achieved good performance in NLP tasks including relation extraction and question answering in the biomedical domain.</s></p><p xml:id="_qcdvy2C"><s xml:id="_H2Qxex7">Following the previous study <ref type="bibr" target="#b17">18</ref> , we formulated both biomedical relation extraction and question answering as a prompt-based text generation model and applied prompt-tuning (p-tuning) algorithms.</s><s xml:id="_h4ZJQhu">We concatenate learnable soft prompts (also called virtual prompt embeddings) with the word embeddings from the context (i.e., input sentence).</s><s xml:id="_BgCnVWG">The sample sequence is constructed as [prompt, context, relation], where the prompt is generated using a LSTM model and the relation is the gold standard label including the head entity, tail entity, and their relation type.</s><s xml:id="_w9Wr2YZ">During the inference, the context and the prompt are used as the input for our GatorTronGPT model to condition and let the model generate the relations.</s><s xml:id="_fQfSKsK">We converted the original relation triplets into a sequence representation.</s><s xml:id="_c8nZEuF">For example, there is an "agonist" relation between a drug -"Igmesine" and a target "Opioid receptor sigma 1", which was converted as: "the relation between [Igmesine] and [Opioid receptor sigma 1] is [agonist]".</s><s xml:id="_duVKTMq">Thus, the relation extraction can be solved as a text generation.</s><s xml:id="_tucx239">During inference, we converted the generated text back to triplets for evaluation.</s><s xml:id="_SBTfXyn">We fine-tuned and evaluated our GatorTronGPT on the end-to-end relation extraction task across four biomedical datasets: BC5CDR (chemical-disease-relation extraction), KD-DTI (drug-target-interaction extraction), DDI (drug-druginteraction extraction) and 2018 n2c2 (Drug-ADE-relation extraction).</s><s xml:id="_w9GsnDZ">The precision, recall, and F1 score were used for evaluation.</s></p><p xml:id="_ZgYt8M7"><s xml:id="_YDPu2HV">Biomedical question answering.</s><s xml:id="_QpUYVzp">We compared GatorTronGPT with six existing transformer models using three widely used benchmark dataset including PubMedQA <ref type="bibr" target="#b46">47</ref> -a biomedical question answering dataset collected from PubMed abstracts, which requires answering questions with 'yes/no/maybe' ; MedMCQA <ref type="bibr" target="#b47">48</ref> -a large-scale multi-choice question answering dataset designed to address real world medical entrance exam questions covering 2400 healthcare topics and 21 medical subjects; and MedQA-USMLE <ref type="bibr" target="#b48">49</ref> -a multi-choice dataset collected from the professional medical board exams.</s><s xml:id="_3fk9tzV">These datasets have been widely used to evaluate LLMs <ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref> .</s></p><p xml:id="_tdSmbpb"><s xml:id="_6njTn8Z">Given a question, a context, and candidate answers, we concatenated the context and the candidate answers into a source sequence and compose the target sequence as: "the answer to the question given possible options is:", "answer": "C".</s><s xml:id="_gutvu3q">Then, we adopted soft prompts instead of hard prompts (manually designed clear text phrases) in p-tuning.</s><s xml:id="_GbcbuYN">Specifically, we used a randomly initiated embedding as soft prompts, which were fine-tuned in the training.</s><s xml:id="_c4uKpRp">For the PubMedQA dataset, we explored the provided artificially generated text data.</s><s xml:id="_bvKkv9y">Specifically, we automatically labeled the generated text using our p-tuning model developed using the training set and experimented to feedback different proportion of auto-labeled data into training.</s><s xml:id="_tkSGWeq">The best performance was achieved by using 5% of the auto-labeled artificially generated text data.</s><s xml:id="_wcXXw4E">For p-tuning, we used the implementation in NVIDIA NeMo <ref type="bibr" target="#b49">50</ref> , which is optimized for LLMs.</s><s xml:id="_nuFVbrc">We used the following parameters in our p-tuning: a global batch size of 32, virtual tokens for p-tuning 15, encoder MLP with encoder hidden size of 2048, max sequence length of 4096 for PubMedQA (long abstracts), 2048 for MedMCQA and MedQA-USMLE, and a fused Adam optimizer with a learning rate of 1e-4 and a weight decay of 0•01, betas of 0•9 and 0•98, a cosine annealing scheduler monitoring validation loss with a 50 step warm up.</s><s xml:id="_8yzjRs5">For example, the below is a prompt we used for MedQA-USMLE.</s><s xml:id="_ZS6pNma">{"taskname": "usmle-qa", "prompt": "QUESTION: A 23-yearold man comes to the physician for evaluation of decreased hearing, dizziness, and ringing in his right ear for the past 6 months.</s><s xml:id="_JZK5QtF">Physical examination shows multiple soft, yellow plaques and papules on his arms, chest, and back.</s><s xml:id="_5mcknre">There is sensorineural hearing loss and weakness of facial muscles bilaterally.</s><s xml:id="_Z3ecMjr">His gait is unsteady.</s><s xml:id="_agbBCTQ">An MRI of the brain shows a 3-cm mass near the right internal auditory meatus and a 2-cm mass at the left cerebellopontine angle.</s><s xml:id="_RwtcwnY">The abnormal cells in these masses are most likely derived from which of the following embryological structures?\nMULTIPLE</s><s xml:id="_9q65aTm">CHOICES: (A) Neural tube\n(B) Surface ectoderm\n(C) Neural crest\n(D) Notochord\nTARGET: the answer to the question given possible options is: ", "answer": "C"} GatorTronGPT for synthetic clinical text generation.</s><s xml:id="_28zARHC">We sought to test the hypothesis that LLMs can generate synthetic clinical text to train synthetic NLP models useful for medical research.</s><s xml:id="_SDvbMYY">We applied GatorTronGPT to generate synthetic clinical text according to a set of seeds without any fine-tuning, which is a typical zeroshot learning setting.</s><s xml:id="_PX2R4zb">Then, using the generated synthetic clinical text, we trained synthetic transformer-based NLP models using our previous BERT-based GatorTron architecture <ref type="bibr" target="#b14">15</ref> , denoted as GatorTronS ('S' stands for synthetic).</s><s xml:id="_SkcmCqk">We trained GatorTronS models using different sizes of synthetic clinical text and compared them with the original GatorTron model trained using UF Health clinical text.</s><s xml:id="_CVub69c">To make it comparable, we trained GatorTronS using the same architecture and number of parameters (i.e., 345 million) as GatorTron <ref type="bibr" target="#b14">15</ref> .</s><s xml:id="_z7dCQw4">We provide detailed information in the Supplement.</s></p><p xml:id="_gbkRAqz"><s xml:id="_fWpdHvP">Synthetic clinical text generation.</s><s xml:id="_W4SKPrj">Following previous studies <ref type="bibr" target="#b50">51</ref> , we approached synthetic clinical text generation using an iterative sampling algorithm and applied top-p (i.e., nucleus sampling) sampling and temperature sampling to balance the diversity and quality of text generation <ref type="bibr" target="#b50">51</ref> .</s><s xml:id="_RtGeygY">We approached the synthetic clinical text generation as an open-ended text-to-text generation task <ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53</ref> , where the generated clinical text is restricted by the context (e.g., the prompts).</s><s xml:id="_49KKkvJ">Specifically, given a sequence of m tokens X pre ¼ x 1 x 2 :::x m as input context, the task is to generate the next n continuation tokens X cont ¼ x mþ1 x mþ2 :::x mþn until reaching the max length of 512 tokens.</s><s xml:id="_2mC7zkc">We generate text through iteratively sampling from the pre-trained language model GatorTronGPT one token at a time by conditioning on the preceding context:</s></p><formula xml:id="formula_0">Pðx cont jx pre Þ ¼ Y mþn i¼mþ1 Pðx i jx 1 :::x iÀ1 Þ<label>(1)</label></formula><p xml:id="_T8RKUCn"><s xml:id="_ZNa4Tmu">where Pðx i jx 1 x iÀ1 Þ is the next token distribution.</s><s xml:id="_4CPuS3z">We adopt Topp (nucleus) sampling <ref type="bibr" target="#b53">54</ref> during sampling to select words whose cumulative probability exceeds a predefined threshold p.</s></p><formula xml:id="formula_1">X x2V<label>ðpÞ</label></formula><formula xml:id="formula_2">Pðxjx 1:iÀ1 Þ ! p (2)</formula><p xml:id="_SBDbfkJ"><s xml:id="_gBSQrHU">where V ðpÞ is the top-p vocabulary used to sample the next word.</s><s xml:id="_tCX2BDD">This approach dynamically adapts the number of words considered at each step based on their probabilities, balancing diversity and coherence of the generated text.</s><s xml:id="_Y6dAxFR">We set the parameter of top-p sampling at 0.9 and the parameter for temperature sampling at 1.2 according to our empirical assessment.</s><s xml:id="_84E3jaB">We sampled the beginning 15 tokens from all sections of the de-identified notes from the MIMIC III database <ref type="bibr" target="#b21">22</ref> and generated approximately 8 million prompts.</s><s xml:id="_q38YS2c">We also tried several random seeds in GatorTronGPT to generate multiple documents from one prompt.</s><s xml:id="_ftam2hB">We controlled Gator-TronGPT to generate a maximum length of 512 tokens.</s></p><p xml:id="_eDS2gum"><s xml:id="_EzmrGnU">Synthetic NLP model development.</s><s xml:id="_W39rdhK">We applied GatorTronGPT to generate different sizes of synthetic clinical text including 1 billion, 5 billion, 10 billion, and 20 billion words of clinical text and developed corresponding synthetic NLP models, denoted as GatorTronS.</s><s xml:id="_fdGtCr4">Following our previous study <ref type="bibr" target="#b14">15</ref> , we trained Gator-TronS using the same architecture of GatorTrona BERT architecture with 345 million parameters.</s></p><p xml:id="_ffw369z"><s xml:id="_UEvDmvC">Comparison with existing transformer models.</s><s xml:id="_D4PuYSa">We compared GatorTronS models with ClinicalBERT 55 -an existing clinical transformer model and GatorTron <ref type="bibr" target="#b14">15</ref> , the current largest clinical transformer model trained using &gt;90 billion words of text, using 5 clinical NLP tasks including clinical concept extraction, medical relation extraction, semantic textual similarity, natural language inference, and question answering.</s></p><p xml:id="_wGrMGPc"><s xml:id="_Bd4MQbT">Turing test of text generation for healthcare settings.</s><s xml:id="_3rKkZvq">We randomly sampled 30 narrative sections from real-world UF Health clinical notes, including "past medical history", "history of present illness", "assessment/plan", and "chief complaint".</s><s xml:id="_J3zSgsW">For each of the 30 sections, we extracted the beginning 15 tokens as a seed for GatorTronGPT to generate a synthetic paragraph up to 512 tokens.</s><s xml:id="_nTuMAH2">We cut off the 30 real-world clinical sections to 512 tokens, removed all format information, and randomly mixed them with 30 synthetic sections written by GatorTronGPT.</s><s xml:id="_DnCKFq9">Two UF Health physicians (NSO, MMA) manually reviewed the 60 paragraphs of notes to evaluate: (1) linguistic readability on a 1(worst) to 9 (best) scale, (2) clinical relevance and consistency on a 1 to 9 scale, (3) determine if it was written by a human physician or GatorTronGPT.</s><s xml:id="_DxpERb3">Percent agreement and Gwet's AC 1 were calculated to evaluate interrater reliability <ref type="bibr" target="#b55">56</ref> .</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 Fig. 2</head><label>12</label><figDesc><div><p xml:id="_svxxmht"><s xml:id="_KdZ7KMS">Fig. 1 Develop a clinical generative large language model, GatorTronGPT, for biomedical natural language processing, clinical text generation, and healthcare text evaluation.</s><s xml:id="_2u2seWB">a Train GatorTronGPT from scratch using GPT-3 architecture with up to 20 billion parameters.</s><s xml:id="_MKj5bcX">b Solve biomedical relation extraction and question answering using a unified P-tuning base text generation architecture.</s><s xml:id="_sb63Xsz">c Apply GatorTronGPT to generate 20 billion words of synthetic clinical text, which was used to train synthetic natural language processing model, GatorTronS.</s><s xml:id="_nkzpjcq">d Turing evaluation of 30 paragraphs of text written by GatorTronGPT mixed with 30 real-world paragraphs written by UF Health physicians.</s><s xml:id="_QG5EFy2">TrM transformer unit; B billion.</s></p></div></figDesc><graphic coords="2,463.81,170.15,72.01,97.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3</head><label>3</label><figDesc><div><p xml:id="_RcZFzem"><s xml:id="_RFYZsMT">Fig. 3 Comparison of GatorTronS models trained with 1, 5, 10, and 20 billion words of synthetic text on eight benchmark datasets.</s><s xml:id="_wfvdWVF">B billion words of text.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc><div><p xml:id="_sb7m8NQ"><s xml:id="_qzuN2ft">Comparison of GatorTronGPT, GatorTronS, and GatorTron.</s></p></div></figDesc><table><row><cell>Model</cell><cell>Architecture</cell><cell>Training dataset</cell><cell cols="2">Parameters Generative or not</cell></row><row><cell cols="2">GatorTronGPT GPT3-based</cell><cell>82 billion clinical words,</cell><cell>5 billion,</cell><cell>Generative LLM</cell></row><row><cell></cell><cell>Decoder architecture</cell><cell>195 billion diverse English words</cell><cell>20 billion</cell><cell></cell></row><row><cell>GatorTronS</cell><cell>BERT-based</cell><cell>20 billion words of synthetic clinical text generated by</cell><cell cols="2">345 million Non-generative LLM</cell></row><row><cell></cell><cell>Encoder architecture</cell><cell>GatorTronGPT</cell><cell></cell><cell></cell></row><row><cell>GatorTron</cell><cell>BERT-based Encoder</cell><cell>82 billion clinical words, 6 billion words from PubMed,</cell><cell>345 million,</cell><cell>Non-generative LLM</cell></row><row><cell></cell><cell>architecture</cell><cell>2.5 billion words from Wikipedia,</cell><cell>3.9 billion,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.5 billion words from MIMIC III</cell><cell>8.9 billion</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc><div><p xml:id="_JWXgk7S"><s xml:id="_ZUdz7uf">Comparison of GatorTronGPT with existing transformer models for (a) biomedical relation extraction and (b) question answering.</s></p></div></figDesc><table><row><cell>a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Biomedical Relation extraction</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>DDI</cell><cell></cell><cell></cell><cell>BC5CDR</cell><cell></cell><cell></cell><cell>KD-DTI</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell><cell>Pre</cell><cell>Rec</cell><cell>F1</cell></row><row><cell>GPT-2_medium</cell><cell>0.234</cell><cell>0.319</cell><cell>0.247</cell><cell>0.439</cell><cell>0.326</cell><cell>0.374</cell><cell>0.305</cell><cell>0.279</cell><cell>0.285</cell></row><row><cell>REBEL</cell><cell>0.354</cell><cell>0.286</cell><cell>0.283</cell><cell>0.343</cell><cell>0.395</cell><cell>0.367</cell><cell>0.324</cell><cell>0.296</cell><cell>0.304</cell></row><row><cell>REBEL-pt</cell><cell>0.465</cell><cell>0.396</cell><cell>0.406</cell><cell>0.409</cell><cell>0.212</cell><cell>0.279</cell><cell>0.357</cell><cell>0.326</cell><cell>0.333</cell></row><row><cell>BioGPT</cell><cell>0.417</cell><cell>0.448</cell><cell>0.408</cell><cell>0.494</cell><cell>0.412</cell><cell>0.450</cell><cell>0.400</cell><cell>0.397</cell><cell>0.384</cell></row><row><cell>GatorTronGPT-5B</cell><cell>0.466</cell><cell>0.518</cell><cell>0.491</cell><cell>0.587</cell><cell>0.434</cell><cell>0.472</cell><cell>0.422</cell><cell>0.436</cell><cell>0.412</cell></row><row><cell>GatorTronGPT-20B</cell><cell>0.476</cell><cell>0.521</cell><cell>0.500</cell><cell>0.543</cell><cell>0.499</cell><cell>0.494</cell><cell>0.422</cell><cell>0.440</cell><cell>0.419</cell></row><row><cell>b</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Question answering</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">PubMedQA</cell><cell></cell><cell cols="2">MedQA (USMLE)</cell><cell></cell><cell cols="2">MedMCQA</cell></row><row><cell>Model</cell><cell></cell><cell cols="2">Accuracy</cell><cell></cell><cell cols="2">Accuracy</cell><cell></cell><cell cols="2">Accuracy</cell></row><row><cell>PubMedBERT</cell><cell></cell><cell>0.558</cell><cell></cell><cell></cell><cell>0.381</cell><cell></cell><cell></cell><cell>NA</cell><cell></cell></row><row><cell>BioELECTRa</cell><cell></cell><cell>0.642</cell><cell></cell><cell></cell><cell>NA</cell><cell></cell><cell></cell><cell>NA</cell><cell></cell></row><row><cell>BioLinkBERT</cell><cell></cell><cell>0.702</cell><cell></cell><cell></cell><cell>0.451</cell><cell></cell><cell></cell><cell>NA</cell><cell></cell></row><row><cell>GPT-2</cell><cell></cell><cell>0.750</cell><cell></cell><cell></cell><cell>0.333</cell><cell></cell><cell></cell><cell>NA</cell><cell></cell></row><row><cell>BioGPT</cell><cell></cell><cell>0.782</cell><cell></cell><cell></cell><cell>NA</cell><cell></cell><cell></cell><cell>NA</cell><cell></cell></row><row><cell>Galactica_120B</cell><cell></cell><cell>0.776</cell><cell></cell><cell></cell><cell>0.444</cell><cell></cell><cell></cell><cell cols="2">0.529</cell></row><row><cell>GatorTronGPT-5B</cell><cell></cell><cell>0.758</cell><cell></cell><cell></cell><cell>0.402</cell><cell></cell><cell></cell><cell cols="2">0.358</cell></row><row><cell>GatorTronGPT-20B</cell><cell></cell><cell>0.776</cell><cell></cell><cell></cell><cell>0.451</cell><cell></cell><cell></cell><cell cols="2">0.429</cell></row><row><cell cols="2">The best evaluation scores are bolded.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">DDI drug-drug interaction, BC5CDR BioCreative V chemical-disease relation, KD-DTI drug-target interaction, B billion parameters, NA performance not reported.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc><div><p xml:id="_7DgppR5"><s xml:id="_W4uSXr5">Comparison of GatorTronS with existing transformer-based LLMs for clinical concept extraction and medical relation extraction. of text Clinical concepts in 2010 i2b2 and 2012 i2b2 challenges: problems, treatments, lab tests; clinical concepts in 2018 n2c2 challenge: drugs, adverse events, and drug-related attributes (e.g., dose).</s><s xml:id="_6yNshRd">Medical relation in 2018 n2c2 challenge: drug induced adverse events; B: billion words of text.</s><s xml:id="_5rZrj4Y">Best evaluation scores are bolded.</s><s xml:id="_8BPVDff">NA: scores not reported.</s></p></div></figDesc><table><row><cell>Clinical concept extraction</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc><div><p xml:id="_nGrZZEr"><s xml:id="_AZWGk6v">Comparison of GatorTronS with existing transformer-based LLMs for semantic textual similarity, natural language inference, and question answering.</s></p></div></figDesc><table><row><cell></cell><cell>Semantic textual similarity</cell><cell>Natural language inference</cell><cell cols="2">Question answering</cell><cell></cell><cell></cell></row><row><cell></cell><cell>2019 n2c2 23</cell><cell>MedNLI 24</cell><cell cols="2">emrQA Medication 25</cell><cell cols="2">emrQA Relation 25</cell></row><row><cell>Transformer</cell><cell>Pearson correlation</cell><cell>Accuracy</cell><cell>F1 score</cell><cell>Exact Match</cell><cell>F1 score</cell><cell>Exact Match</cell></row><row><cell>ClinicalBERT</cell><cell>0.879</cell><cell>0.827</cell><cell>0.691</cell><cell>0.241</cell><cell>0.931</cell><cell>0.853</cell></row><row><cell>GatorTron, 90B</cell><cell>0.881</cell><cell>0.867</cell><cell>0.718</cell><cell>0.298</cell><cell>0.954</cell><cell>0.903</cell></row><row><cell>GatorTronS, 1B</cell><cell>0.853</cell><cell>0.851</cell><cell>0.702</cell><cell>0.288</cell><cell>0.965</cell><cell>0.924</cell></row><row><cell>GatorTronS, 5B</cell><cell>0.888</cell><cell>0.882</cell><cell>0.726</cell><cell>0.305</cell><cell>0.968</cell><cell>0.926</cell></row><row><cell>GatorTronS, 10B</cell><cell>0.893</cell><cell>0.886</cell><cell>0.728</cell><cell>0.311</cell><cell>0.972</cell><cell>0.929</cell></row><row><cell>GatorTronS, 20B</cell><cell>0.898</cell><cell>0.885</cell><cell>0.726</cell><cell>0.307</cell><cell>0.973</cell><cell>0.927</cell></row></table><note xml:id="_cxTH7Eq"><p><s xml:id="_GcxYayW">B: billion words of text.</s><s xml:id="_RtWVJEX">The best evaluation scores are bolded.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc><div><p><s xml:id="_ENXd5j9">24ring test results.Number and percentage of correctly identified notes; p-values were calculated using Chi-squared test.b.Means and standard deviations of the quality measures; p-values were calculated using T-test.c.Two examples of synthetic clinical text generated by GatorTronGPT.The text generation stops at maximum 512 tokens.Pass Turing test: both physicians labeled as "Human"; Fail Turing Test: both physicians labeled as "AI".information(PHI).Not surprisingly, a recent study21on clinical foundation models point out that most LLMs in the medical domain are trained using "small, narrowly-scoped" clinical dataset with limited note types (e.g., MIMIC22) or "broad, public" biomedical literature (e.g., PubMed) that has limited insights to healthcare.Generative LLMs can provide large-scale synthetic clinical text to fill the gap.We compare the synthetic text with real-world clinical text to examine why GatorTronS, a transformer model trained using a much smaller (e.g., 5 billion words) synthetic clinical text corpus, could achieve better or comparable performance to GatorTron15, a transformer model trained using a much larger (90 billion words) real-world clinical text corpus.We identify potential reasons including (1) real-world clinical text has significant redundancies, which is a well-known characteristic of clinical narratives23, and (2) GatorTronGPT generates more diverse synthetic clinical text.We randomly sample a subset of real-world clinical notes with number of words comparable to the synthetic text (i.e., 20 billion words) to compare the coverage of unigrams (i.e., individual tokens) and bigrams (i.e., two consecutive tokens).The comparison results show that the synthetic text generated by GatorTronGPT contain remarkably more diverse unigrams (40.43 million : 4.82 million, ratios are reported as "synthetic" : "real notes") and bigrams (416.35 million : 62.51 million); the synthetic text also has higher entropy than the real-world clinical text (4.97: 4.95).Supplementary TableS4provides detailed comparison results and examples.A previous study24has reported that by augmenting real-world clinical training data using additional human annotated synthetic text generated by a smaller generative LLM, GPT-2, NLP models can achieve better performance.</s><s xml:id="_66DzYbS">Our study further demonstrates that, without additional human annotation and augmentation of training data, a larger clinical GPT-3 model can generate synthetic clinical text to train synthetic NLP models outperforming NLP models trained using real-world clinical text.</s><s xml:id="_NWNDDZb">Text generation using generative LLMs could mitigate the risk of exposing patient privacy and improve accessing and sharing of large-scale clinical text and NLP models, thus enabling the next generation of clinical text analytics using synthetic clinical text.</s></p></div></figDesc><table><row><cell>a.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Ground truth</cell><cell></cell><cell></cell></row><row><cell></cell><cell>AI (n = 30)</cell><cell>Human (n = 30)</cell><cell>Total (n = 60)</cell></row><row><cell>Physician 1</cell><cell>9 (30.0%)</cell><cell>17 (56.7%)</cell><cell>26 (43.3%)</cell></row><row><cell>Physician 2</cell><cell>13 (43.3%)</cell><cell>20 (66.7%)</cell><cell>33 (55%)</cell></row><row><cell>Overall</cell><cell>11 (36.7%)</cell><cell>18.5 (61.7%)</cell><cell>29.5 (49.2%)</cell></row><row><cell>p-value</cell><cell>&lt;0.001</cell><cell>=0.104</cell><cell>&lt;0.001</cell></row><row><cell>b.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Ground truth</cell><cell></cell><cell></cell></row><row><cell></cell><cell>AI (n = 30)</cell><cell>Human (n = 30)</cell><cell>p-value</cell></row><row><cell>Readability</cell><cell>6.57 (1.22)</cell><cell>6.93 (1.09)</cell><cell>0.22</cell></row><row><cell>Clinical relevance</cell><cell>7.00 (1.23)</cell><cell>6.97 (1.07)</cell><cell>0.91</cell></row><row><cell>c.</cell><cell></cell><cell></cell><cell></cell></row></table><note xml:id="_qGVMMqv"><p>Example 1 (Passed Turing test): HISTORY OF PRESENT ILLNESS: Ms. [**NAME**] is a [**AGE**]-year-old female with prior history of left breast cancer who is referred to the [**LOCATION**] Clinic to discuss surgical management of her left lung nodule which was picked up on CT scanning for surveillance. The patient's chest CT obtained at an outside institution showed an incidental finding of a left lower lobe pleural nodule, which she brought with her to clinic today for further review. Ms. [**Name**] reports to be doing well, with no change in her baseline level of shortness of breath, but denies any difficulty breathing, cough or hemoptysis. She feels essentially back to baseline and plays golf one day a week. Otherwise, Ms.</p><p><s xml:id="_hxDKbEW">[**NAME **] has no other pulmonary complaints and has never smoked tobacco or inhaled second hand smoke.</s><s xml:id="_zYu3NKY">She does report several years of intermittent reflux, which worsened after eating rough foods.</s><s xml:id="_EY6T9DZ">She underwent an upper GI study for this, which showed a small hiatal hernia as well as a moderate-sized sliding hiatal hernia.</s><s xml:id="_r5ay9qU">She subsequently underwent an abdominal CT for evaluation for mesenteric ischemia and was felt to have a dilated pancreatic duct.</s><s xml:id="_6NYr7sH">Due to suspected head pathology on imaging (although the final report is pending), she underwent an MRI, which confirmed no pancreatic pathology.</s><s xml:id="_24ngaEE">Given this, Ms. [**NAME **] has been trying to avoid fatty and fried foods, which has improved her reflux.</s><s xml:id="_Y97RK9u">Ms. [**NAME **] does report recent onset of sleep apnea, for which she is using CPAP every night for the last month.</s><s xml:id="_uS442Uq">She tolerates this well without complaints of dry mouth, gasping for air, or undue sleepiness.</s><s xml:id="_j3SGvq7">Ms. [**NAME **] was seen in our outpatient [**LOCATION**] clinic on [**DATE**] at which time it was determined that in order to obtain a tissue diagnosis of this left lower lobe lesion a VATS approach would be utilized.</s><s xml:id="_jMd6w4P">She presents today for further pre-operative planning.</s><s xml:id="_cu7SKdS">Currently, Ms. [**NAME**] denies any pulmonary symptoms, fevers, chills, cough or weight loss.</s><s xml:id="_9EDzH2A">PAST MEDICAL HISTORY: 1. CARDIAC RISK FACTORS: Hypertension, Hyperlipidemia 2. CARDIAC HISTORY: None 3. OTHER PAST MEDICAL HISTORY: Left lower lobe pulmonary nodule Example 2 (Failed Turing test): Assessment: ICD-9-CM 1. Pain in joint, pelvic region and thigh, unspecified laterality 719.45 fentaNYL (DURAGESIC) 75 MCG/HR HYDROcodone-acetaminophen (VICODIN HP) 5-300 MG Tablet 2. Migraine NOS/not Intrcbl 346.90 SUMAtriptan Succinate 3. Bone Pain Arthritis 333.90 Dexamethasone Sodium Phosphate 4. Bipolar disorder 296.80 traZODone (DESYREL) 100 MG Tablet prazosin (MINIPRESS) 2 MG capsule carvedilol (COREG) 3.125 MG tablet isosorbide mononitrate (IMDUR) 30 MG CR tablet Refer to Psychiatry clopidogrel (PLAVIX) 75 MG tablet SUMAtriptan Succinate 5. ASTHMA UNSPECIFIED 493.90 albuterol (PROAIR HFA;VENTOLIN HFA) 108 (90 BASE) MCG/ACT inhaler 6.</s><s xml:id="_JfR3Nxm">Major depressive disorder, single episode, unspecified 296.20 DULoxetine (CYMBALTA) 60 MG capsule Refer to Psychiatry amitriptyline (ELAVIL) 25 MG tablet traZODone (DESYREL) 100 MG Tablet 7. POST-SURGICAL VARICOSE VEINS of LOWER EXTREMITIES 454.9 fentaNYL (DURAGESIC) 75 MCG/HR 8. Other and unspecified hyperlipidemia 272.4 simvastatin (ZOCOR) 40 MG tablet COMPREHENSIVE METABOLIC PANEL 9. PND (post-nasal drip) 784.91 loratadine (CLARITIN) 10 MG tablet 10.</s><s xml:id="_ZxfmmN8">Bipolar I disorder, single manic episode, unspecified 296.00 clonazePAM (KlonoPIN) 1 MG tablet Refer to Psychiatry 11.</s><s xml:id="_WEFwSEF">Allergic rhinitis 477.9 loratadine (CLARITIN) 10 MG tablet 12. Grief reaction 309.0 traZODone (DESYREL) 100 MG Tablet 13.</s><s xml:id="_CaYxXyW">Encounter for long-term (current) use of other medications V58.69 methocarbamol (ROBAXIN) 750 MG tablet COMPREHENSIVE METABOLIC PANEL 14. GERD (gastroesophageal reflux disease) 530.81 lansoprazole (PRE a.</s></p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_cassaGr"><s xml:id="_gY7q3Cq">npj Digital Medicine (2023) 210 Published in partnership with Seoul National University Bundang Hospital 1234567890():,;</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_wnyQKyt"><s xml:id="_UuxQpgF">Published in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2023) 210</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_twwRn5J"><s xml:id="_DMF9Wub">npj Digital Medicine (2023) 210Published in partnership with Seoul National University Bundang Hospital</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_EQTEJtr">ACKNOWLEDGEMENTS</head><p xml:id="_BkMCmeA"><s xml:id="_f6E3GgH">This study was partially supported by a <rs type="funder">Patient-Centered Outcomes Research Institute® (PCORI®) Award</rs> (<rs type="grantNumber">ME-2018C3-14754</rs>), a grant from the <rs type="funder">National Cancer Institute</rs>, <rs type="grantNumber">1R01CA246418</rs>, grants from the <rs type="funder">National Institute on Aging</rs>, <rs type="grantNumber">NIA R56AG069880</rs> and <rs type="grantNumber">1R01AG080624</rs>, and the <rs type="funder">Cancer Informatics and eHealth core jointly</rs> supported by the <rs type="funder">UF Health Cancer Center</rs> and the <rs type="funder">UF Clinical and Translational Science Institute</rs>.</s><s xml:id="_WFB4eHA">The content is solely the responsibility of the authors and does not necessarily represent the official views of the funding institutions.</s><s xml:id="_m6qxMjj">We would like to thank the <rs type="institution">UF Research Computing team</rs>, led by <rs type="person">Dr. Erik Deumens</rs>, for providing computing power through UF HiperGator-AI cluster.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_UadeT38">
					<idno type="grant-number">ME-2018C3-14754</idno>
				</org>
				<org type="funding" xml:id="_SS8QSp6">
					<idno type="grant-number">1R01CA246418</idno>
				</org>
				<org type="funding" xml:id="_uMsW7YT">
					<idno type="grant-number">NIA R56AG069880</idno>
				</org>
				<org type="funding" xml:id="_kaVwhzc">
					<idno type="grant-number">1R01AG080624</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_tFCmzUF">DATA AVAILABILITY</head><p xml:id="_T6APCPK"><s xml:id="_SxR55xt">The benchmark datasets that support the findings of this study are available from the official websites of natural language processing challenges with Data Use Agreements.</s><s xml:id="_Uq5xfz8">More specifically: 1. i2b2 2010, 2012 datasets and n2c2 2018, 2019 datasets: <ref type="url" target="https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/">https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/</ref>. 2. MedNLI dataset: <ref type="url" target="https://physionet.org/content/mednli/1.0.0/">https://physionet.org/content/mednli/1.0.0/</ref>. 3. emrQA dataset: <ref type="url" target="https://github.com/panushri25/emrQA#download-dataset">https://github.com/  panushri25/emrQA#download-dataset</ref>.</s><s xml:id="_74FSVPG">4. The Pile dataset: <ref type="url" target="https://pile.eleuther.ai/">https://pile.eleuther.ai/</ref>. 5. UF Health IDR clinical notes are not open to the public due to patient privacy information.</s><s xml:id="_DAsYZmp">The GatorTronS, and GatorTron models are available as open-source resources.</s><s xml:id="_4kMWE6D">The synthetic clinical transformer model, GatorTronS, is available from: <ref type="url" target="https://huggingface.co/UFNLP/gatortronS">https://huggingface.co/UFNLP/gatortronS</ref>.</s><s xml:id="_enE2yyJ">The GatorTron model trained using realworld clinical text is available: <ref type="url" target="https://huggingface.co/UFNLP/gatortron-base">https://huggingface.co/UFNLP/gatortron-base</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rQxG5Xw">CODE AVAILABILITY</head><p xml:id="_MWv7Rks"><s xml:id="_p2wCSCS">The computer codes to train GatorTronGPT models are available from: <ref type="url" target="https://github.com/NVIDIA/Megatron-LM/blob/main/pretrain_gpt.py">https://  github.com/NVIDIA/Megatron-LM/blob/main/pretrain_gpt.py</ref>.</s><s xml:id="_A6dN6Bt">The scripts used for data preprocessing, vocabulary training and other utilities are available from: <ref type="url" target="https://github.com/uf-hobi-informatics-lab/GatorTronGPT">https://  github.com/uf-hobi-informatics-lab/GatorTronGPT</ref>.</s><s xml:id="_wZ6FK2j">The computer codes to train GatorTronS models are available from: <ref type="url" target="https://github.com/NVIDIA/Megatron-LM">https://github.com/NVIDIA/Megatron-LM</ref></s><s xml:id="_XA322Uj">and <ref type="url" target="https://github.com/NVIDIA/NeMo">https://github.com/NVIDIA/NeMo</ref>.</s><s xml:id="_g2EQs68">The computer codes for preprocessing of text data are available from: <ref type="url" target="https://github.com/uf-hobi-informatics-lab/NLPreprocessing">https://github.com/uf-hobi-informatics-lab/NLPreprocessing</ref>.</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_nwBn8ha">AUTHOR CONTRIBUTIONS</head><p xml:id="_UKRUfXd"><s xml:id="_sfRvGvw">Y.W., J.B., X.Y., N.P., A.B.C., and M.G.F. were responsible for the overall design, development, and evaluation of this study.</s><s xml:id="_nJpzFuR">X.Y., C.P., A.C., and K.E.S. had full access to all the data in the study and takes responsibility for the integrity of the data and the accuracy of the data analysis.</s><s xml:id="_TqGTxXT">Y.G. and Y.W. designed the Turing evaluation of synthetic clinical text generated by GatorTronGPT.</s><s xml:id="_tKPSTmf">N.S.O. and M.M.A. are the two human physicians who performed Turing test.</s><s xml:id="_3Cp5ZCq">Y.W., X.Y., K.E.S., C.P., Y.G., and J.B. did the bulk of the writing, W.H., E.A.S., D.A.M., T.M., C.A.H., A.B.C., and G.L. also contributed to writing and editing of this manuscript.</s><s xml:id="_MBvMhCW">All authors reviewed the manuscript critically for scientific content, and all authors gave final approval of the manuscript for publication.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_5pYNWz6">COMPETING INTERESTS</head><p xml:id="_WgutMKg"><s xml:id="_Rwq2zRJ">K.E.S., N.P.N., A.B.C., C.M., and M.G.F. are employed by NVIDIA.</s><s xml:id="_jHSrCX5">There are no other competing financial or non-financial interests.</s><s xml:id="_fJrek4h">The work presented in this study was conducted exclusively within the University of Florida Health.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_a4fWbYC">ADDITIONAL INFORMATION Supplementary information</head><p xml:id="_YzqDH2R"><s xml:id="_cdVCD78">The online version contains supplementary material available at <ref type="url" target="https://doi.org/10.1038/s41746-023-00958-w">https://doi.org/10.1038/s41746-023-00958-w</ref>.</s></p><p xml:id="_WuBXv6W"><s xml:id="_HxSDxEq">Correspondence and requests for materials should be addressed to Yonghui Wu.</s></p><p xml:id="_3NKcy4N"><s xml:id="_kyQbpUu">Reprints and permission information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/  reprints</ref> Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<idno type="DOI">10.1007/979-8-8688-0929-3_1</idno>
		<ptr target="https://openai.com/blog/chatgpt" />
		<title level="m" xml:id="_7uE3ujn">Introducing ChatGPT</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Introducing ChatGPT. https://openai.com/blog/chatgpt.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_tnDevnc">Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petro</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejmsr2214184</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qEqtYvd">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="1233" to="1239" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lee, P., Bubeck, S. &amp; Petro, J. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine. N. Engl. J. Med. 388, 1233-1239 (2023).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_8BpqJTE">ChatGPT: the future of discharge summaries?</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lam</surname></persName>
		</author>
		<idno type="DOI">10.1016/s2589-7500(23)00021-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AvSnwa3">Lancet Digit Health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="107" to="e108" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Patel, S. B. &amp; Lam, K. ChatGPT: the future of discharge summaries? Lancet Digit Health 5, e107-e108 (2023).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_K42GCbh">Using ChatGPT to write patient clinic letters</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Dobbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Hutchings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qPtXZpr">Lancet Digit Health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="179" to="e181" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ali, S. R., Dobbs, T. D., Hutchings, H. A. &amp; Whitaker, I. S. Using ChatGPT to write patient clinic letters. Lancet Digit Health 5, e179-e181 (2023).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_VtDVrJu">Diagnostic accuracy of differential-diagnosis lists generated by generative pretrained transformer 3 chatbot for clinical vignettes with common chief complaints: a pilot study</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hirosawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_s9rf98u">Int. J. Environ. Res. Public Health</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">3378</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hirosawa, T. et al. Diagnostic accuracy of differential-diagnosis lists generated by generative pretrained transformer 3 chatbot for clinical vignettes with common chief complaints: a pilot study. Int. J. Environ. Res. Public Health 20, 3378 (2023).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_gXjDXBk">The Exciting Potential for ChatGPT in Obstetrics and Gynecology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grünebaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chervenak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Pollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Chervenak</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ajog.2023.03.009</idno>
		<ptr target="https://doi.org/10.1016/j.ajog.2023.03.009" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_PAPFUCN">Am. J. Obstet. Gynecol</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Grünebaum, A., Chervenak, J., Pollet, S. L., Katz, A. &amp; Chervenak, F. A. The Exciting Potential for ChatGPT in Obstetrics and Gynecology. Am. J. Obstet. Gynecol. https://doi.org/10.1016/j.ajog.2023.03.009 (2023).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_twaD4Pt">Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cascella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montomoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bellini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bignami</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-023-01925-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xcJUQJw">J. Med. Syst</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cascella, M., Montomoli, J., Bellini, V. &amp; Bignami, E. Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios. J. Med. Syst. 47, 33 (2023).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_qJpWanz">Large language models and the perils of their hallucinations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Azamfirei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Kudchadkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fackler</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13054-023-04393-x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_c5gmjsp">Crit. Care</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Azamfirei, R., Kudchadkar, S. R. &amp; Fackler, J. Large language models and the perils of their hallucinations. Crit. Care 27, 120 (2023).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_mFeFYQQ">Artificial Intelligence in mental health and the biases of language based models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Straw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CdBc4D8">PLoS One</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">240376</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Straw, I. &amp; Callison-Burch, C. Artificial Intelligence in mental health and the biases of language based models. PLoS One 15, e0240376 (2020).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_sDmYWBx">Ethics of large language models in medicine and medical research</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1016/s2589-7500(23)00083-3</idno>
		<ptr target="https://doi.org/10.1016/S2589-7500(23)00083-3" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_2gMRVr6">Lancet Digital Health</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li, H. et al. Ethics of large language models in medicine and medical research. Lancet Digital Health https://doi.org/10.1016/S2589-7500(23)00083-3 (2023).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_AeQ889S">Large Language Models are Zero-Shot Reasoners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fXfBGyu">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kojima, T., Gu, S. S., Reid, M., Matsuo, Y. &amp; Iwasawa, Y. Large Language Models are Zero-Shot Reasoners. Adv. Neural Inf. Process. Syst. 35, 22199-213 (2022).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main" xml:id="_vnVd3DS">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Bommasani, R. et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_sb7QX3J">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XK5s35F">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brown, T., Mann, B. &amp; Ryder, N. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877-1901 (2020).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_qdbvtDH">Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3560815</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Qkt878C">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu, P. et al. Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing. ACM Comput. Surv. 55, 1-35 (2023).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_3zgmK7z">A large language model for electronic health records</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9kg2hCF">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">194</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang, X. et al. A large language model for electronic health records. NPJ Digit. Med. 5, 194 (2022).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main" xml:id="_ktRKZAS">The Pile: an 800GB Dataset of Diverse Text for Language Modeling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gao, L. et al. The Pile: an 800GB Dataset of Diverse Text for Language Modeling. arXiv:2101.00027 (2020).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_CdkRFBq">GPT-3: its nature, scope, limits, and consequences</title>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiriatti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XD9TYhf">Minds Mach</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="681" to="694" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Floridi, L. &amp; Chiriatti, M. GPT-3: its nature, scope, limits, and consequences. Minds Mach. 30, 681-694 (2020).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_Gpj9efW">BioGPT: generative pre-trained transformer for biomedical text generation and mining</title>
		<author>
			<persName><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1093/bib/bbac409</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7hM9k69">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">409</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Luo, R. et al. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Brief. Bioinform. 23, bbac409 (2022).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_gQAn8et">pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_8chvjPG">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s" xml:id="_qxJMDMW">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note type="raw_reference">Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) 4171-4186 (Association for Computational Linguistics, 2019). https://doi.org/ 10.18653/v1/N19-1423.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B M</forename><surname>Bashier</surname></persName>
		</author>
		<idno type="DOI">10.1201/9781315371658</idno>
		<ptr target="https://doi.org/10.1201/9781315371658" />
		<title level="m" xml:id="_U6VzrvM">Machine Learning</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mohammed, M., Khan, M. B. &amp; Bashier, E. B. M. Machine Learning (CRC Press, 2016). https://doi.org/10.1201/9781315371658.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_8VH47tz">The shaky foundations of large language models and foundation models for electronic health records</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wornow</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-023-00879-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2Fgkc3E">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">135</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wornow, M. et al. The shaky foundations of large language models and foun- dation models for electronic health records. NPJ Digit Med. 6, 135 (2023).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_fuyDHMY">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E W</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3SxHgDu">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">160035</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson, A. E. W. et al. MIMIC-III, a freely accessible critical care database. Sci. Data 3, 160035 (2016).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_5DgVx4F">Estimating redundancy in clinical text</title>
		<author>
			<persName><forename type="first">T</forename><surname>Searle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Teo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dobson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbi.2021.103938</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uwGfPRs">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">103938</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Searle, T., Ibrahim, Z., Teo, J. &amp; Dobson, R. Estimating redundancy in clinical text. J. Biomed. Inform. 124, 103938 (2021).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_Ts4qf4B">Are synthetic clinical notes useful for real natural language processing tasks: a case study on clinical entity recognition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_baWm9V2">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2193" to="2201" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li, J. et al. Are synthetic clinical notes useful for real natural language processing tasks: a case study on clinical entity recognition. J. Am. Med. Inform. Assoc. 28, 2193-2201 (2021).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_5vvWV8u">relation extraction by end-to-end language generation</title>
		<author>
			<persName><forename type="first">P.-L</forename><surname>Huguet Cabot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName><surname>Rebel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.204</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.findings-emnlp.204" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_WJSwdEX">Findings of the Association for Computational Linguistics: EMNLP 2021 2370-2381</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Huguet Cabot, P.-L. &amp; Navigli, R. REBEL: relation extraction by end-to-end lan- guage generation. in Findings of the Association for Computational Linguistics: EMNLP 2021 2370-2381 (Association for Computational Linguistics, 2021). https:// doi.org/10.18653/v1/2021.findings-emnlp.204.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_cqKSECT">Clinical concept and relation extraction using prompt-based machine reading comprehension</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocad107</idno>
		<ptr target="https://doi.org/10.1093/jamia/ocad107" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_WFW9aFt">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Peng, C. et al. Clinical concept and relation extraction using prompt-based machine reading comprehension. J. Am. Med. Inform. Assoc. https://doi.org/ 10.1093/jamia/ocad107 (2023).</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_Z8KnGYb">Medical documentation burden among US office-based physicians in 2019: a national study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gaffney</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2022.0372</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZgJPqyQ">JAMA Intern. Med</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="564" to="566" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gaffney, A. et al. Medical documentation burden among US office-based physi- cians in 2019: a national study. JAMA Intern. Med. 182, 564-566 (2022).</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_3C2wAk9">Physician burnout in the electronic health record era: are we ignoring the real cause?</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Downing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Longhurst</surname></persName>
		</author>
		<idno type="DOI">10.7326/m18-0139</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_K8XcH8T">Ann. Intern. Med</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Downing, N. L., Bates, D. W. &amp; Longhurst, C. A. Physician burnout in the electronic health record era: are we ignoring the real cause? Ann. Intern. Med. 169, 50 (2018).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_D4FnbDU">Association of electronic health record design and use factors with clinician stress and burnout</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Kroth</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamanetworkopen.2019.9609</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xUqa32m">JAMA Netw. Open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">199609</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kroth, P. J. et al. Association of electronic health record design and use factors with clinician stress and burnout. JAMA Netw. Open 2, e199609 (2019).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Diaz</surname></persName>
		</author>
		<ptr target="https://www.beckershospitalreview.com/ehrs/epic-to-use-microsofts-open-ai-in-ehrs.html" />
		<title level="m" xml:id="_pqTKGMy">Epic to use Microsoft&apos;s GPT-4 in EHRs</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Diaz, N. Epic to use Microsoft&apos;s GPT-4 in EHRs. https:// www.beckershospitalreview.com/ehrs/epic-to-use-microsofts-open-ai-in- ehrs.html.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_29dQfXD">We&apos;re getting much more aggressive</title>
		<author>
			<persName><forename type="first">B</forename><surname>Trang</surname></persName>
		</author>
		<ptr target="https://www.statnews.com/2023/03/20/microsoft-nuance-gpt4-dax-chatgpt/" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_eYCXPY5">Microsoft&apos;s Nuance adds GPT-4 AI to its medical note-taking tool</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Trang, B. We&apos;re getting much more aggressive&apos;: Microsoft&apos;s Nuance adds GPT-4 AI to its medical note-taking tool. https://www.statnews.com/2023/03/20/microsoft- nuance-gpt4-dax-chatgpt/.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_37nNt5C">Health system-scale language models are all-purpose prediction engines</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-023-06160-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vsqfddp">Nature</title>
		<imprint>
			<biblScope unit="volume">619</biblScope>
			<biblScope unit="page" from="357" to="362" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jiang, L. Y. et al. Health system-scale language models are all-purpose prediction engines. Nature 619, 357-362 (2023).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_hcvA7mJ">An opinion on ChatGPT in health care-written by humans only</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleesiek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stiglic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<idno type="DOI">10.2967/jnumed.123.265687</idno>
		<ptr target="https://doi.org/10.2967/jnumed.123.265687" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_YxhUWwu">J. Nucl. Med</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kleesiek, J., Wu, Y., Stiglic, G., Egger, J. &amp; Bian, J. An opinion on ChatGPT in health care-written by humans only. J. Nucl. Med. https://doi.org/10.2967/ jnumed.123.265687 (2023).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main" xml:id="_p3PZeCH">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<idno>arXiv [cs.CL</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ouyang, L. et al. Training language models to follow instructions with human feedback. arXiv [cs.CL] (2022).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_eu8qAUG">Samsung bans ChatGPT among employees after sensitive code leak</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_K4RP5nd">Forbes Magazine</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ray, S. Samsung bans ChatGPT among employees after sensitive code leak. Forbes Magazine (2023).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_UDu89Zm">Semantics derived automatically from language corpora contain human-like biases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caliskan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aal4230</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_46nfJF7">Science</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="page" from="183" to="186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Caliskan, A., Bryson, J. J. &amp; Narayanan, A. Semantics derived automatically from language corpora contain human-like biases. Science 356, 183-186 (2017).</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<idno type="DOI">10.31032/ijbpas/2025/14.8.9309</idno>
		<ptr target="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device" />
		<title level="m" xml:id="_RsrEd9J">Artificial Intelligence and Machine Learning in Software as a Medical Device</title>
		<imprint>
			<publisher>U.S. Food and Drug Administration</publisher>
		</imprint>
		<respStmt>
			<orgName>Center for Devices &amp; Radiological Health</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Center for Devices &amp; Radiological Health. Artificial Intelligence and Machine Learning in Software as a Medical Device. U.S. Food and Drug Administration https://www.fda.gov/medical-devices/software-medical-device-samd/artificial- intelligence-and-machine-learning-software-medical-device.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_cTFgg2n">A study of deep learning methods for de-identification of clinical notes in cross-institute settings</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GNMXT6J">BMC Med. Inform. Decis. Mak</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">232</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang, X. et al. A study of deep learning methods for de-identification of clinical notes in cross-institute settings. BMC Med. Inform. Decis. Mak. 19, 232 (2019).</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
		<idno type="DOI">10.1016/b978-0-12-824447-0.00013-3</idno>
		<idno>arXiv [cs.LG]</idno>
		<title level="m" xml:id="_uRhKhr2">The depth-to-width interplay in self-attention</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Levine, Y., Wies, N., Sharir, O., Bata, H. &amp; Shashua, A. The depth-to-width interplay in self-attention. arXiv [cs.LG] (2020).</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main" xml:id="_6Uab2Ag">Megatron-LM: training multi-billion parameter language models using model parallelism</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shoeybi</surname></persName>
		</author>
		<idno>arXiv [cs.CL]</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shoeybi, M. et al. Megatron-LM: training multi-billion parameter language models using model parallelism. arXiv [cs.CL] (2019).</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_CrpZZjS">Prefix-tuning: optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.353</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.acl-long.353" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_M3vpXfX">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<title level="s" xml:id="_NDHav3s">Long Papers</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4582" to="4597" />
		</imprint>
	</monogr>
	<note type="raw_reference">Li, X. L. &amp; Liang, P. Prefix-tuning: optimizing continuous prompts for generation. in Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Pro- cessing (Volume 1: Long Papers) 4582-4597 (Association for Computational Lin- guistics, 2021). https://doi.org/10.18653/v1/2021.acl-long.353.</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_Yh9j37x">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.1145/3560815</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HYQvPAj">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H. &amp; Neubig, G. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language pro- cessing. ACM Computing Surveys. 59, 1-35 (2023).</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_cGEM3AN">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sJaWbBU">OpenAI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Radford A., Wu J., Child R., Luan D. &amp; Amodei D. Language models are unsu- pervised multitask learners. OpenAI, 1, (2019)</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_24XpFys">The ddi corpus: An annotated corpus with pharmacological sub-stances and drugdrug interactions</title>
		<idno type="DOI">10.1016/j.jbi.2013.07.011</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tdSdBqN">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="914" to="920" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">The ddi corpus: An annotated corpus with pharmacological sub-stances and drug- drug interactions. J. Biomed. Inform. 46, 914-920 (2013).</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_HZK6kS9">BioCreative V CDR task corpus: a resource for chemical disease relation extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_d6zk8NP">Database</title>
		<imprint>
			<biblScope unit="page">68</biblScope>
			<date type="published" when="2016">2016. 2016</date>
			<pubPlace>Oxf</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Li, J. et al. BioCreative V CDR task corpus: a resource for chemical disease relation extraction. Database (Oxf.) 2016, baw068 (2016).</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_P7axRjz">Discovering drug-target interaction knowledge from biomedical literature</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btac648</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Qu6TYb6">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="5100" to="5107" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hou, Y. et al. Discovering drug-target interaction knowledge from biomedical literature. Bioinformatics 38, 5100-5107 (2022).</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_yHcnJ2E">PubMedQA: a dataset for biomedical research question answering</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d19-1259</idno>
		<ptr target="https://doi.org/10.18653/v1/d19-1259" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_b2JPdUz">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jin, Q., Dhingra, B., Liu, Z., Cohen, W. &amp; Lu, X. PubMedQA: a dataset for biomedical research question answering. in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (Association for Computational Linguistics, 2019). https://doi.org/10.18653/v1/d19-1259.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main" xml:id="_e8XjPn7">Large language models encode clinical knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<idno>arXiv [cs.CL</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Singhal, K. et al. Large language models encode clinical knowledge. arXiv [cs.CL] (2022).</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_TQHp3xm">What disease does this patient have? A large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.3390/app11146421</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NjRrCNM">NATO Adv. Sci. Inst. E Appl. Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">6421</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jin, D. et al. What disease does this patient have? A large-scale open domain question answering dataset from medical exams. NATO Adv. Sci. Inst. E Appl. Sci. 11, 6421 (2021).</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><surname>Nemo</surname></persName>
		</author>
		<title level="m" xml:id="_YFF2cyP">NeMo: a toolkit for conversational AI</title>
		<imprint/>
	</monogr>
	<note type="report_type">NVIDIA GitHub</note>
	<note type="raw_reference">NeMo: NeMo: a toolkit for conversational AI. (NVIDIA GitHub).</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main" xml:id="_cWpeGyA">The curious case of neural text degeneration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09751</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Holtzman A., Buys J., Forbes M. &amp; Choi Y. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751 (2019).</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_ChFPp8r">Neural text generation in stories using entity representations as context</title>
		<author>
			<persName><forename type="first">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-1204</idno>
		<ptr target="https://doi.org/10.18653/v1/N18-1204" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_dvFYmMs">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2250" to="2260" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
	<note type="raw_reference">Clark, E., Ji, Y. &amp; Smith, N. A. Neural text generation in stories using entity representations as context. in Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan- guage Technologies, Volume 1 (Long Papers) 2250-2260 (Association for Com- putational Linguistics, 2018). https://doi.org/10.18653/v1/N18-1204.</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main" xml:id="_w3BBGkg">Evaluation of text generation: a survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.14799</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Celikyilmaz, A., Clark, E. &amp; Gao, J. Evaluation of text generation: a survey. arXiv preprint arXiv:2006.14799 (2020).</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main" xml:id="_mDA6Gch">The curious case of neural text degeneration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09751</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Holtzman, A., Buys, J., Du, L., Forbes, M. &amp; Choi, Y. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751 (2019).</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05342</idno>
		<title level="m" xml:id="_WsjTJmw">ClinicalBERT: modeling clinical notes and predicting hospital readmission</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Huang, K., Altosaar, J. &amp; Ranganath, R. ClinicalBERT: modeling clinical notes and predicting hospital readmission. arXiv preprint arXiv:1904.05342 (2019).</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_SG7AK79">A comparison of Cohen&apos;s Kappa and Gwet&apos;s AC1 when calculating inter-rater reliability coefficients: a study conducted with personality disorder samples</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wongpakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wongpakaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wedding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Gwet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FtJpydV">BMC Med. Res. Methodol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">61</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wongpakaran, N., Wongpakaran, T., Wedding, D. &amp; Gwet, K. L. A comparison of Cohen&apos;s Kappa and Gwet&apos;s AC1 when calculating inter-rater reliability coeffi- cients: a study conducted with personality disorder samples. BMC Med. Res. Methodol. 13, 61 (2013).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
