<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_NBjzugC"></title>
				<funder ref="#_phhEXnZ">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000002</idno>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
					<p type="raw">Publisher&apos;s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Springer Nature or its licensor holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. © Springer Nature America, Inc. 2022</p>
				</availability>
				<date type="published" when="2022-09-15">15 September 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Eric</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
							<email>etopol@scripps.edu</email>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Neurology , Yale School of Medicine , New Haven , CT , USA.</note>
								<orgName type="department">Department of Neurology</orgName>
								<orgName type="institution">Yale School of Medicine</orgName>
								<address>
									<settlement>New Haven</settlement>
									<region>CT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Department of Biomedical Informatics , Harvard Medical School , Boston , MA , USA.</note>
								<orgName type="department">Department of Biomedical Informatics</orgName>
								<orgName type="institution">Harvard Medical School</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Scripps Research Translational Institute , Scripps Research , La Jolla , CA , USA.</note>
								<orgName type="institution" key="instit1">Scripps Research Translational Institute</orgName>
								<orgName type="institution" key="instit2">Scripps Research</orgName>
								<address>
									<settlement>La Jolla</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-09-15">15 September 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">762864206E13AC9A4A73D9758FEA4A6B</idno>
					<idno type="DOI">10.1038/s41591-022-01981-2</idno>
					<note type="submission">Received: 21 March 2022; Accepted: 1 August 2022;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T06:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_2DGyGMd">W</head><p xml:id="_6t8qEvZ"><s xml:id="_FB5XbRS">hile artificial intelligence (AI) tools have transformed several domains (for example, language translation, speech recognition and natural image recognition), medicine has lagged behind.</s><s xml:id="_Ph92VT5">This is partly due to complexity and high dimensionality-in other words, a large number of unique features or signals contained in the data-leading to technical challenges in developing and validating solutions that generalize to diverse populations.</s><s xml:id="_NUNNrAH">However, there is now widespread use of wearable sensors and improved capabilities for data capture, aggregation and analysis, along with decreasing costs of genome sequencing and related 'omics' technologies.</s><s xml:id="_wUQjWXc">Collectively, this sets the foundation and need for novel tools that can meaningfully process this wealth of data from multiple sources, and provide value across biomedical discovery, diagnosis, prognosis, treatment and prevention.</s></p><p xml:id="_5gvFDB2"><s xml:id="_h4q9PqA">Most of the current applications of AI in medicine have addressed narrowly defined tasks using one data modality, such as a computed tomography (CT) scan or retinal photograph.</s><s xml:id="_Nf4ZR4Q">In contrast, clinicians process data from multiple sources and modalities when diagnosing, making prognostic evaluations and deciding on treatment plans.</s><s xml:id="_3DSvH5U">Furthermore, current AI assessments are typically one-off snapshots, based on a moment of time when the assessment is performed, and therefore not 'seeing' health as a continuous state.</s><s xml:id="_MeQD65K">In theory, however, AI models should be able to use all data sources typically available to clinicians, and even those unavailable to most of them (for example, most clinicians do not have a deep understanding of genomic medicine).</s><s xml:id="_jaeYnXj">The development of multimodal AI models that incorporate data across modalitiesincluding biosensors, genetic, epigenetic, proteomic, microbiome, metabolomic, imaging, text, clinical, social determinants and environmental data-is poised to partially bridge this gap and enable broad applications that include individualized medicine, integrated, real-time pandemic surveillance, digital clinical trials and virtual health coaches (Fig. <ref type="figure" target="#fig_0">1</ref>).</s><s xml:id="_cq8nWJy">In this Review, we explore the opportunities for such multimodal datasets in healthcare; we then discuss the key challenges and promising strategies for overcoming these.</s><s xml:id="_Jczd8uY">Basic concepts in AI and machine learning will not be discussed here but are reviewed in detail elsewhere <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_aYBk9qU">Opportunities for leveraging multimodal data</head><p xml:id="_xpFHBXh"><s xml:id="_dWHadnS">Personalized 'omics' for precision health.</s><s xml:id="_r8Vnpds">With the remarkable progress in sequencing over the past two decades, there has been a revolution in the amount of fine-grained biological data that can be obtained using novel technical developments.</s><s xml:id="_zyK8wt3">These are collectively referred to as the 'omes' , and includes the genome, proteome, transcriptome, immunome, epigenome, metabolome and microbiome <ref type="bibr" target="#b3">4</ref> .</s><s xml:id="_ZJEjuHH">These can be analyzed in bulk or at the single-cell level, which is relevant because many medical conditions such as cancer are quite heterogeneous at the tissue level, and much of biology shows cell and tissue specificity.</s></p><p xml:id="_SbvG2ck"><s xml:id="_GTRnvp5">Each of the omics has shown value in different clinical and research settings individually.</s><s xml:id="_ngdjFf7">Genetic and molecular markers of malignant tumors have been integrated into clinical practice <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6</ref> , with the US Food and Drug Administration (FDA) providing approval for several companion diagnostic devices and nucleic acid-based tests <ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8</ref> .</s><s xml:id="_N4AWgSH">As an example, Foundation Medicine and Oncotype IQ (Genomic Health) offer comprehensive genomic profiling tailored to the main classes of genomic alterations across a broad panel of genes, with the final goal of identifying potential therapeutic targets <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10</ref> .</s><s xml:id="_4wujjud">Beyond these molecular markers, liquid biopsy sampleseasily accessible biological fluids such as blood and urine-are becoming a widely used tool for analysis in precision oncology, with some tests based on circulating tumor cells and circulating tumor DNA already approved by the FDA <ref type="bibr" target="#b10">11</ref> .</s><s xml:id="_9wB6GPu">Beyond oncology, there has been a remarkable increase in the last 15 years in the availability and sharing of genetic data, which enabled genome-wide association studies <ref type="bibr" target="#b11">12</ref> and characterization of the genetic architecture of complex human conditions and traits <ref type="bibr" target="#b12">13</ref> .</s><s xml:id="_w4ukAzB">This has improved our understanding of biological pathways and produced tools such as polygenic risk scores <ref type="bibr" target="#b13">14</ref> (which capture the overall genetic propensity to complex traits for each individual), and may be useful for risk stratification and individualized treatment, as well as in clinical research to enrich the recruitment of participants most likely to benefit from interventions <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16</ref> .</s></p><p xml:id="_2YU9WWf"><s xml:id="_jA7dFuy">The integration of these very distinct types of data remains challenging.</s><s xml:id="_JcZhGJE">Yet, overcoming this problem is paramount, as the successful integration of omics data, in addition to other types such as electronic health record (EHR) and imaging data, is expected to increase our understanding of human health even further and allow for precise and individualized preventive, diagnostic and therapeutic strategies <ref type="bibr" target="#b3">4</ref> .</s><s xml:id="_3fCGuHH">Several approaches have been proposed for multi-omics data integration in precision health contexts <ref type="bibr" target="#b16">17</ref> .</s><s xml:id="_x66Sqhc">Graph neural networks are one example; <ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19</ref> these are deep learning model</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gh7bwPn">Multimodal biomedical AI</head><p xml:id="_Z23Q7SY"><s xml:id="_DujZeYr">Julián N. Acosta 1 , Guido J. Falcone 1 , Pranav Rajpurkar 2,4 ✉ and Eric J. <ref type="bibr">Topol 3,</ref><ref type="bibr" target="#b3">4 ✉</ref> The increasing availability of biomedical data from large biobanks, electronic health records, medical imaging, wearable and ambient biosensors, and the lower cost of genome and microbiome sequencing have set the stage for the development of multimodal artificial intelligence solutions that capture the complexity of human health and disease.</s><s xml:id="_sxUhJPP">In this Review, we outline the key applications enabled, along with the technical and analytical challenges.</s><s xml:id="_78XsjaE">We explore opportunities in personalized medicine, digital clinical trials, remote monitoring and care, pandemic surveillance, digital twin technology and virtual health assistants.</s><s xml:id="_fQQC6Ap">Further, we survey the data, modeling and privacy challenges that must be overcome to realize the full potential of multimodal artificial intelligence in health.</s></p><p xml:id="_YqZKrBj"><s xml:id="_aHAKNts">architectures that process computational graphs-a well-known data structure comprising nodes (representing concepts or entities) and edges (representing connections or relationships between nodes)-thereby allowing scientists to account for the known interrelated structure of multiple types of omics data, which can improve performance of a model <ref type="bibr" target="#b19">20</ref> .</s><s xml:id="_pj7DS6x">Another approach is dimensionality reduction, including novel methods such as PHATE and Multiscale PHATE, which can learn abstract representations of biological and clinical data at different levels of granularity, and have been shown to predict clinical outcomes, for example, in people with coronavirus disease 2019 (COVID-19) <ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> .</s></p><p xml:id="_rAMrz3J"><s xml:id="_2YTdzfE">In the context of cancer, overcoming challenges related to data access, sharing and accurate labeling could potentially lead to impactful tools that leverage the combination of personalized omics data with histopathology, imaging and clinical data to inform clinical trajectories and improve patient outcomes <ref type="bibr" target="#b22">23</ref> .</s><s xml:id="_8W7zquJ">The integration of histopathological morphology data with transcriptomics data, resulting in spatially resolved transcriptomics <ref type="bibr" target="#b23">24</ref> , constitutes a novel and promising methodological advancement that will enable finer-grained research into gene expression within a spatial context.</s><s xml:id="_JBXEnJD">Of note, researchers have utilized deep learning to leverage histopathology images to predict spatial gene expression from these images alone, pointing to morphological features in these images not captured by human experts that could potentially enhance the utility and lower the costs of this technology <ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26</ref> .</s></p><p xml:id="_GHrVcmD"><s xml:id="_cTQ977q">Genetic data are increasingly cost effective, requiring only a one-in-a-lifetime ascertainment, but they also have limited predictive ability on their own <ref type="bibr" target="#b26">27</ref> .</s><s xml:id="_FvzmMce">Integrating genomics data with other omics data may capture more dynamic and real-time information on how each particular combination of genetic background and environmental exposures interact to produce the quantifiable continuum of health status.</s><s xml:id="_Xu6mU9T">As an example, Kellogg et al. <ref type="bibr" target="#b27">28</ref> conducted an N-of-1 study performing whole-genome sequencing (WGS) and periodic measurements of other omics layers (transcriptome, proteome, metabolome, antibodies and clinical biomarkers); polygenic risk scoring showed an increased risk of type II diabetes mellitus, and comprehensive profiling of other omics enabled early detection and dissection of signaling network changes during the transition from health to disease.</s></p><p xml:id="_ebXzjzf"><s xml:id="_dXrprZ2">As the scientific field advances, the cost-effectiveness profile of WGS will become increasingly favorable, facilitating the combination of clinical and biomarker data with already available genetic data to arrive at a rapid diagnosis of conditions that were previously difficult to detect <ref type="bibr" target="#b28">29</ref> .</s><s xml:id="_g6Sx9sD">Ultimately, the capability to develop multimodal AI that includes many layers of omics data will get us to the desired goal of deep phenotyping of an individual; in other words, a true understanding of each person's biological uniqueness and how that affects health.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gQkVBYU">Digital clinical trials.</head><p xml:id="_ReRxz7j"><s xml:id="_cTZR5RW">Randomized clinical trials are the gold standard study design to investigate causation and provide evidence to support the use of novel diagnostic, prognostic and therapeutic interventions in clinical medicine.</s><s xml:id="_gMquDuU">Unfortunately, planning and executing a high-quality clinical trial is not only time consuming (usually taking many years to recruit enough participants and follow them in time) but also financially very costly <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31</ref> .</s><s xml:id="_4TtyNfn">In addition, geographic, sociocultural and economic disparities in access to enrollment, have led to a remarkable underrepresentation of several groups in these studies.</s><s xml:id="_meAPhZy">This limits the generalizability of results and leads to a scenario whereby widespread underrepresentation in biomedical research further perpetuates existing disparities <ref type="bibr" target="#b31">32</ref> .</s><s xml:id="_GUYEbeH">Digitizing clinical trials could provide an unprecedented opportunity to overcome these limitations, by reducing barriers to participant enrollment and retainment, promoting engagement and optimizing trial measurements and interventions.</s><s xml:id="_rXS8Xhv">At the same time, the use of digital technologies can enhance the granularity of the information obtained from participants, thereby increasing the value of these studies <ref type="bibr" target="#b32">33</ref> .</s><s xml:id="_QcbShfa">Data from wearable technology (including heart rate, sleep, physical activity, electrocardiography, oxygen saturation and glucose monitoring) and smartphone-enabled self-reported questionnaires can be useful for monitoring clinical trial patients, identifying adverse events or ascertaining trial outcomes <ref type="bibr" target="#b33">34</ref> .</s><s xml:id="_MU2vBxT">Additionally, a recent study highlighted the potential of data from wearable sensors to predict laboratory results <ref type="bibr" target="#b34">35</ref> .</s><s xml:id="_BgUyFXH">Consequently, the number of studies using digital products has been growing rapidly in the last few years, with a compound annual growth rate of around 34% <ref type="bibr" target="#b35">36</ref> .</s><s xml:id="_7eNR53g">Most of these studies utilize data from a single wearable device.</s><s xml:id="_84jbKvU">One pioneering trial used a 'band-aid' patch sensor for detecting atrial fibrillation; the sensor was mailed to participants who were enrolled remotely, without the use of any clinical sites, and set the foundation for digitized clinical trials <ref type="bibr" target="#b36">37</ref> .</s><s xml:id="_WuYBSU7">Many remote, site-less trials using wearables were conducted during the COVID-19 pandemic to detect coronavirus <ref type="bibr" target="#b37">38</ref> .</s></p><p xml:id="_5uutcJB"><s xml:id="_y3rfqDf">Effectively combining data from different wearable sensors with clinical data remains a challenge and an opportunity.</s><s xml:id="_rCmrXFQ">Digital clinical trials could leverage multiple sources of participants' data to enable automatic phenotyping and subgrouping <ref type="bibr" target="#b33">34</ref> , which could be useful for adaptive clinical trial designs that use ongoing results to modify the trial in real time <ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40</ref> .</s><s xml:id="_3hUuay7">In the future, we expect that the increased availability of these data and novel multimodal learning techniques will improve our capabilities in digital clinical trials.</s><s xml:id="_qXW67VQ">Of note, recent work in a time-series analysis by Google has demonstrated the promise of attention-based model architectures to combine both static and time-dependent inputs to achieve interpretable time-series forecasting.</s><s xml:id="_ezM6WVU">As a hypothetical example, these models could understand whether to focus on static features such as genetic background, known time-varying features such as time of the day or observed features such as current glycemic levels, to make predictions on future risk of hypoglycemia or hyperglycemia <ref type="bibr" target="#b40">41</ref> .</s><s xml:id="_d6EqKNc">Graph neural networks have been recently proposed to overcome the problem of missing or irregularly sampled data from multiple health sensors, by leveraging information from the interconnection between these <ref type="bibr" target="#b41">42</ref> .</s></p><p xml:id="_cvmrr3D"><s xml:id="_NQDWTtv">Patient recruitment and retention in clinical trials are essential but remain a challenge.</s><s xml:id="_d4eQMcT">In this setting, there is an increasing interest in the utilization of synthetic control methods (that is, using external data to create controls).</s><s xml:id="_qKfUWkb">Although synthetic control trials are still relatively novel <ref type="bibr" target="#b42">43</ref> , the FDA has already approved medications based on historical controls <ref type="bibr" target="#b43">44</ref> and has developed a framework for the utilization of real-world evidence <ref type="bibr" target="#b44">45</ref> .</s><s xml:id="_5HDrV47">AI models utilizing data from different modalities can potentially help identify or generate the most optimal synthetic controls <ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47</ref> .</s></p><p xml:id="_BCnmWnf"><s xml:id="_VeVQCCT">Remote monitoring: the 'hospital-at-home' .</s><s xml:id="_cf3RfNu">Recent progress with biosensors, continuous monitoring and analytics raises the possibility of simulating the hospital setting in a person's home.</s><s xml:id="_ajymCsH">This offers the promise of marked reduction of cost, less requirement for healthcare workforce, avoidance of nosocomial infections and medical errors that occur in medical facilities, along with the comfort, convenience and emotional support of being with family members <ref type="bibr" target="#b47">48</ref> .</s></p><p xml:id="_UStnrjk"><s xml:id="_yAF7RqA">In this context, wearable sensors have a crucial role in remote patient monitoring.</s><s xml:id="_dvF7md2">The availability of relatively affordable noninvasive devices (smartwatches or bands) that can accurately measure several physiological metrics is increasing rapidly <ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50</ref> .</s><s xml:id="_YASBpRs">Combining these data with those derived from EHRs-using standards such as the Fast Healthcare Interoperability Resources, a global industry standard for exchanging healthcare data <ref type="bibr" target="#b50">51</ref> -to query relevant information about a patient's underlying disease risk could create a more personalized remote monitoring experience for patients and caregivers.</s><s xml:id="_g5axd5s">Ambient wireless sensors offer an additional opportunity to collect valuable data.</s><s xml:id="_xm3gznZ">Ambient sensors are devices located within the environment (for example, a room, a wall or a mirror) ranging from video cameras and microphones to depth cameras and radio signals.</s><s xml:id="_YaCEgCD">These ambient sensors can potentially improve remote care systems at home and in healthcare institutions <ref type="bibr" target="#b51">52</ref> .</s></p><p xml:id="_5JQYW88"><s xml:id="_bPq9u2M">The integration of data from these multiple modalities and sensors represents a promising opportunity to improve remote patient monitoring, and some studies have already demonstrated the potential of multimodal data in these scenarios.</s><s xml:id="_WaGj4Gx">For example, the combination of ambient sensors (such as depth cameras and microphones) with wearables data (for example, accelerometers, which measure physical activity) has the potential to improve the reliability of fall detection systems while keeping a low false alarm rate <ref type="bibr" target="#b52">53</ref> , and to improve gait analysis performance <ref type="bibr" target="#b53">54</ref> .</s><s xml:id="_aP4MfPS">Early detection of impairments in physical functional status via activities of daily living such as bathing, dressing and eating is remarkably important to provide timely clinical care, and the utilization of multimodal data from wearable devices and ambient sensors can potentially help with accurate detection and classification of difficulties in these activities <ref type="bibr" target="#b54">55</ref> .</s></p><p xml:id="_rGQRtr2"><s xml:id="_M4Kapjb">Beyond management of chronic or degenerative disorders, multimodal remote patient monitoring could also be useful in the setting of acute disease.</s><s xml:id="_frrSKkA">A recent program conducted by the Mayo Clinic showcased the feasibility and safety of remote monitoring in people with COVID-19 (ref. <ref type="bibr" target="#b55">56</ref></s><s xml:id="_Wvq7vXy">).</s><s xml:id="_vprH2za">Remote patient monitoring for hospital-at-home applications-not yet validated-requires randomized trials of multimodal AI-based remote monitoring versus hospital admission to show no impairment of safety.</s><s xml:id="_TVpCnhr">We need to be able to predict impending deterioration and have a system to intervene, and this has not been achieved yet.</s></p><p xml:id="_PpPXz4b"><s xml:id="_vBXEjB8">Pandemic surveillance and outbreak detection.</s><s xml:id="_we9ThYt">The current COVID-19 pandemic has highlighted the need for effective infectious disease surveillance at national and state levels <ref type="bibr" target="#b56">57</ref> , with some countries successfully integrating multimodal data from migration maps, mobile phone utilization and health delivery data to forecast the spread of the outbreak and identify potential cases <ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref> .</s></p><p xml:id="_QAcJjcH"><s xml:id="_qmjSbMf">One study has also demonstrated the utilization of resting heart rate and sleep minutes tracked using wearable devices to improve surveillance of influenza-like illness in the USA <ref type="bibr" target="#b59">60</ref> .</s><s xml:id="_bEq53S3">This initial success evolved into the Digital Engagement and Tracking for Early Control and Treatment (DETECT) Health study, launched by the Scripps Research Translational Institute as an app-based research program aiming to analyze a diverse set of data from wearables to allow for rapid detection of the emergence of influenza, coronavirus and other fast-spreading viral illnesses.</s><s xml:id="_Hq43EMr">A follow-up study from this program showed that jointly considering participant self-reported symptoms and sensor metrics improved performance relative to either modality alone, reaching an area under the receiver operating curve value of 0.80 (95% confidence interval 0.73-0.86)</s><s xml:id="_Eg7zuAD">for classifying COVID-19-positive versus COVID-19-negative status <ref type="bibr" target="#b60">61</ref> .</s></p><p xml:id="_B5R7uRe"><s xml:id="_zduxaZh">Several other use cases for multimodal AI models in pandemic preparedness and response have been tested with promising results, but further validation and replication of these results are needed <ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63</ref> .</s></p><p xml:id="_TQBr5AH"><s xml:id="_sBTh9EC">Digital twins.</s><s xml:id="_sGXa25N">We currently rely on clinical trials as the best evidence to identify successful interventions.</s><s xml:id="_Redhf6v">Interventions that help 10 of 100 people may be considered successful, but these are applied to the other 90 without proven or likely benefit.</s><s xml:id="_3uuZQcv">A complementary approach known as 'digital twins' can fill the knowledge gaps by leveraging large amounts of data to model and predict with high precision how a certain therapeutic intervention would benefit or harm a particular patient.</s></p><p xml:id="_WjfwcZq"><s xml:id="_q9rVwf7">Digital twin technology is a concept borrowed from engineering that uses computational models of complex systems (for example, cities, airplanes or patients) to develop and test different strategies or approaches more quickly and economically than in real-life scenarios <ref type="bibr" target="#b63">64</ref> .</s><s xml:id="_ZhHvrxV">In healthcare, digital twins are a promising tool for drug target discovery <ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66</ref> .</s></p><p xml:id="_dkCJ8HS"><s xml:id="_RgdBpJc">Integrating data from multiple sources to develop digital twin models using AI tools has already been proposed in precision oncology and cardiovascular health <ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b67">68</ref> .</s><s xml:id="_cE434MP">An open-source modular framework has also been proposed for the development of medical digital twin models <ref type="bibr" target="#b68">69</ref> .</s><s xml:id="_g9zamks">From a commercial point of view, Unlearn.AI has developed and tested digital twin models that leverage diverse sets of clinical data to enhance clinical trials for Alzheimer's disease and multiple sclerosis <ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71</ref> .</s></p><p xml:id="_BDhVru6"><s xml:id="_3wQSUZ3">Considering the complexity of human organisms, the development of accurate and useful digital twin technology in medicine will depend on the ability to collect large and diverse multimodal data ranging from omics data and physiological sensors to clinical and sociodemographic data.</s><s xml:id="_JQMcfRy">This will likely require large collaborations across health systems, research groups and industry, such as the Swedish Digital Twins Consortium <ref type="bibr" target="#b64">65,</ref><ref type="bibr">72</ref> .</s><s xml:id="_Hr9fM2G">The American Society of Clinical Oncology, through its subsidiary called CancerLinQ, developed a platform that enables researchers to utilize a wealth of data from patients with cancer to help guide optimal treatment and improve outcomes <ref type="bibr" target="#b71">73</ref> .</s><s xml:id="_fVZuSQW">The development of AI models capable of effectively learning from all these data modalities together, to make real-time predictions, is paramount.</s></p><p xml:id="_YhW4XkK"><s xml:id="_BaThgfA">Virtual health assistant.</s><s xml:id="_hCHbzV4">More than one-third of US consumers have acquired a smart speaker in the last few years.</s><s xml:id="_E7HEfGc">However, virtual health assistants-digital AI-enabled coaches that can advise people on their health needs-have not been developed widely to date, and those currently in the market often target a particular condition or use case.</s><s xml:id="_GBRVC9y">In addition, a recent review of health-focused conversational agents apps found that most of these rely on rule-based approaches and predefined app-led dialog <ref type="bibr" target="#b72">74</ref> .</s></p><p xml:id="_7AfWNhX"><s xml:id="_aDRZ3EZ">One of the most popular, although not multimodal AI-based, current applications of these narrowly focused virtual health assistants is in diabetes care.</s><s xml:id="_rNyjYdG">Virta health, Accolade and Onduo by Verily (Alphabet) have all developed applications that aim to improve diabetes control, with some demonstrating improvement in hemoglobin A1c levels in individuals who followed the programs <ref type="bibr" target="#b73">75</ref> .</s><s xml:id="_wWbmh4Z">Many of these companies have expanded or are in the process of expanding to other use cases such as hypertension control and weight loss.</s><s xml:id="_k56GEn9">Other examples of virtual health coaches have tackled common conditions such as migraine, asthma and chronic obstructive pulmonary disease, among others <ref type="bibr" target="#b74">76</ref> .</s><s xml:id="_uxFhE7j">Unfortunately, most of these applications have been tested only on small observational studies, and much more research, including randomized clinical trials, are needed to evaluate their benefits.</s></p><p xml:id="_KDnjw5e"><s xml:id="_5rz2tMT">Looking into the future, the successful integration of multiple data sources in AI models will facilitate the development of broadly focused personalized virtual health assistants <ref type="bibr" target="#b75">77</ref> .</s><s xml:id="_f2XyPRf">These virtual health assistants can leverage individualized profiles based on genome sequencing, other omics layers, continuous monitoring of blood biomarkers and metabolites, biosensors and other relevant biomedical data-to promote behavior change, answer health-related questions, triage symptoms or communicate with healthcare providers when appropriate.</s><s xml:id="_Wn8Vyde">Importantly, these AI-enabled medical coaches will need to demonstrate beneficial effects on clinical outcomes via randomized trials to achieve widespread acceptance in the medical field.</s><s xml:id="_ActHfJf">As most of these applications are focused on improving health choices, they will need to provide evidence of influencing health behavior, which represents the ultimate pathway for the successful translation of most interventions <ref type="bibr" target="#b76">78</ref> .</s></p><p xml:id="_NXuhswf"><s xml:id="_HkZ7FYk">We still have a long way to go to achieve the full potential of AI and multimodal data integration into virtual health assistants, including the technical challenges, data-related challenges and privacy challenges discussed below.</s><s xml:id="_uDsJE2J">Given the rapid advances in conversational AI <ref type="bibr" target="#b77">79</ref> , coupled with the development of increasingly sophisticated multimodal learning approaches, we expect future digital health applications to embrace the potential of AI to deliver accurate and personalized health coaching.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ZQejNW9">Multimodal data collection</head><p xml:id="_3VngVbU"><s xml:id="_5WPqdzu">The first requirement for the successful development of multimodal data-enabled applications is the collection, curation and harmonization of well-phenotyped and large annotated datasets, as no amount of technical sophistication can derive information not present in the data <ref type="bibr" target="#b78">80</ref> .</s><s xml:id="_ag7YPwM">In the last 20 years, many national and international studies have collected multimodal data with the ultimate goal of accelerating precision health (Table <ref type="table">1</ref>).</s><s xml:id="_bggKgFm">In the UK, the UK Biobank initiated enrollment in 2006, reaching a final participant count of over 500,000, and plans to follow participants for at least 30 years after enrollment <ref type="bibr" target="#b79">81</ref> .</s><s xml:id="_qKvKYTt">This large biobank has collected multiple layers of data from participants, including sociodemographic and lifestyle information, physical measurements, biological samples, 12-lead electrocardiograms and EHR data <ref type="bibr" target="#b80">82</ref> .</s><s xml:id="_7RX2xR7">Further, almost all participants underwent genome-wide array genotyping and, more recently, proteome, whole-exome sequencing <ref type="bibr" target="#b81">83</ref> and WGS <ref type="bibr" target="#b82">84</ref> .</s><s xml:id="_Hh2VgHr">A subset of individuals also underwent brain magnetic resonance imaging (MRI), cardiac MRI, abdominal MRI, carotid ultrasound and dual-energy X-ray absorptiometry, including repeat imaging across at least two time points <ref type="bibr" target="#b83">85</ref> .</s></p><p xml:id="_9Vxt8Ar"><s xml:id="_X3Zbv6P">Similar initiatives have been conducted in other countries, such as the China Kadoorie Biobank <ref type="bibr" target="#b84">86</ref> and Biobank Japan <ref type="bibr" target="#b85">87</ref> .</s><s xml:id="_cbtTFBC">In the USA, the Department of Veteran Affairs launched the Million Veteran Program <ref type="bibr" target="#b86">88</ref> in 2011, aiming to enroll 1 million veterans to contribute to scientific discovery.</s><s xml:id="_UBcwxDR">Two important efforts funded by the National Institutes of Health (NIH) include the Trans-Omics for Precision Medicine (TOPMed) program and the All of Us Research Program.</s><s xml:id="_8XGMK7e">TOPMed collects WGS with the aim to integrate this genetic information with other omics data <ref type="bibr" target="#b87">89</ref> .</s><s xml:id="_tS8EBfq">The All of Us Research Program <ref type="bibr" target="#b88">90</ref> constitutes another novel and ambitious initiative by the NIH that has enrolled about 400,000 diverse participants of the 1 million people planned across the USA, and is focused on enrolling individuals from broadly defined underrepresented groups in biomedical research, which is especially needed in medical AI <ref type="bibr" target="#b89">91,</ref><ref type="bibr" target="#b90">92</ref> .</s></p><p xml:id="_eHmqAd8"><s xml:id="_RWCupq5">Besides these large national initiatives, independent institutional and multi-institutional efforts are also building deep, multimodal data resources in smaller numbers of people.</s><s xml:id="_d7Kdrme">The Project Baseline Health Study, funded by Verily and managed in collaboration with Stanford University, Duke University and the California Health and Longevity Institute, aims to enroll at least 10,000 individuals, starting with an initial 2,500 participants from whom a broad range of multimodal data are collected, with the aim of evolving into a combined virtual-in-person research effort <ref type="bibr" target="#b91">93</ref> .</s><s xml:id="_rGye4j9">As another example, the American Gut Project collects microbiome data from self-selected participants across several countries <ref type="bibr" target="#b92">94</ref> .</s><s xml:id="_zke9bXg">These participants also complete surveys about general health status, disease history, lifestyle data and food frequency.</s><s xml:id="_pdDXYJC">The Medical Information Mart for Intensive Care (MIMIC) database <ref type="bibr" target="#b93">95</ref> , organized by the Massachusetts Institute of Technology, represents another example of multidimensional data collection and harmonization.</s><s xml:id="_EC2BK8N">Currently in its fourth version, MIMIC is an open-source database that contains de-identified data from thousands of patients who were admitted to the critical care units of the Beth Israel Deaconess Medical Center, including demographic information, EHR data (for example, diagnosis codes, medications ordered and administered, laboratory data and physiological data such as blood pressure or intracranial pressure values), imaging data (for example, chest radiographs) <ref type="bibr" target="#b94">96</ref> and, in some versions, natural language text such as radiology reports and medical notes.</s><s xml:id="_JYEEjJJ">This granularity of data is particularly useful for the data science and machine learning community, and MIMIC has become one of the benchmark datasets for AI models aiming to predict the development of clinical events such as kidney failure, or outcomes such as survival or readmissions <ref type="bibr" target="#b95">97,</ref><ref type="bibr" target="#b96">98</ref> .</s></p><p xml:id="_vDfMcHS"><s xml:id="_tQRHfaS">The availability of multimodal data in these datasets may help achieve better diagnostic performance across a range of different tasks.</s><s xml:id="_T2WUAem">As an example, recent work has demonstrated that the combination of imaging and EHR data outperforms each of these modalities alone to identify pulmonary embolism <ref type="bibr" target="#b97">99</ref> , and to differentiate between common causes of acute respiratory failure, such as heart failure, pneumonia or chronic obstructive pulmonary disease 100 .</s><s xml:id="_dNZ5HHW">The Michigan Predictive Activity &amp; Clinical Trajectories in Health (MIPACT) study constitutes another example, with participants contributing data from wearables, physiological data (blood pressure), clinical information (EHR and surveys) and laboratory data <ref type="bibr">101</ref> .</s><s xml:id="_MCcmuQM">The North American Prodrome Longitudinal Study is yet another example.</s><s xml:id="_RUD8U9V">This multisite program recruited individuals, and collected demographic, clinical and blood biomarker data with the goal of understanding the prodromal stages of psychosis <ref type="bibr">102,</ref><ref type="bibr">103</ref> .</s><s xml:id="_XGZeQBn">Other studies focusing on psychiatric disorders such as the Personalised Prognostic Tools for Early Psychosis Management also collected several types of data and have already empowered the development of multimodal machine learning workflows 104 .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_quUacSC">Technical challenges</head><p xml:id="_UWMmczF"><s xml:id="_ynbdBbg">Implementation and modeling challenges.</s><s xml:id="_HtsJAMf">Health data are inherently multimodal.</s><s xml:id="_HuKhvJY">Our health status encompasses many domains (social, biological and environmental) that influence well-being in complex ways.</s><s xml:id="_Nu3HDGZ">Additionally, each of these domains is hierarchically organized, with data being abstracted from the big picture macro level (for example, disease presence or absence) to the in-depth micro level (for example, biomarkers, proteomics and genomics).</s><s xml:id="_PU9PZMn">Furthermore, current healthcare systems add to this multimodal approach by generating data in multiple ways: radiology and pathology images are, for example, paired with natural language data from their respective reports, while disease states are also documented in natural language and tabular data in the EHR.</s></p><p xml:id="_Zbwn2hs"><s xml:id="_ZBZPEfp">Table 1 | Examples of studies with multimodal data available Study country Year started data modalities Access Sample size UK Biobank UK 2006 Questionnaires EHR/clinical Laboratory Genome-wide genotyping WES WGS Imaging Metabolites Open access ~500,000 China Kadoorie Biobank China 2004 Questionnaires Physical measurements Biosamples Genome-wide genotyping Restricted access ~500,000 Biobank Japan Japan 2003 Questionnaires Clinical Laboratroy Genome-wide genotyping Restricted access ~200,000</s></p><p xml:id="_x534369"><s xml:id="_TJChMrR">Multimodal machine learning (also referred to as multimodal learning) is a subfield of machine learning that aims to develop and train models that can leverage multiple different types of data and learn to relate these multiple modalities or combine them, with the goal of improving prediction performance <ref type="bibr">105</ref> .</s><s xml:id="_cqMHUMm">A promising approach is to learn accurate representations that are similar for different modalities (for example, a picture of an apple should be represented similarly to the word 'apple').</s><s xml:id="_UvRJbrR">In early 2021, OpenAI released an architecture termed Contrastive Language Image Pretraining (CLIP), which, when trained on millions of image-text pairs, matched the performance of competitive, fully supervised models without fine-tuning 106 .</s><s xml:id="_AJz8QZ4">CLIP was inspired by a similar approach developed in the medical imaging domain termed Contrastive Visual Representation Learning from Text (ConVIRT) <ref type="bibr">107</ref> .</s><s xml:id="_xQkXpH2">With ConVIRT, an image encoder and a text encoder are trained to generate image and text representations by maximizing the similarity of correctly paired image and text examples and minimizing the similarity of incorrectly paired examples-this is called contrastive learning.</s><s xml:id="_TJWQzHD">This approach for paired image-text co-learning has been used recently to learn from chest X-rays and their associated text reports, outperforming other self-supervised and fully supervised methods 108 .</s><s xml:id="_TkZX5Kt">Other architectures have also been developed to integrate multimodal data from images, audio and text, such as the Video-Audio-Text Transformer, which uses videos to obtain paired multimodal image, text and audio and to train accurate multimodal representations able to generalize with good performance on many tasks-such as recognizing actions in videos, classifying audio events, classifying images, and selecting the most adequate video for an input text <ref type="bibr">109</ref> .</s></p><p xml:id="_yAYGeN4"><s xml:id="_guSFU4K">Another desirable feature for multimodal learning frameworks is the ability to learn from different modalities without the need for different model architectures.</s><s xml:id="_q3fbdj5">Ideally, a unified multimodal model would incorporate different types of data (images, physiological sensor data and structured and unstructured text data, among others), codify concepts contained in these different types of data in a flexible and sparse way (that is, a unique task activates only a small part of the network, with the model learning which parts of the network should handle each unique task) 110 , produce aligned representations for similar concepts across modalities (for example, the picture of a dog, and the word 'dog' should produce similar internal representations), and provide any arbitrary type of output as required by the task <ref type="bibr">111</ref> .</s></p><p xml:id="_yZgfCHW"><s xml:id="_B4PsmZF">In the last few years, there has been a transition from architectures with strong modality-specific biases-such as convolutional neural networks for images, or recurrent neural networks for text and physiological signals-to a relatively novel architecture called the Transformer, which has demonstrated good performance across a wide variety of input and output modalities and tasks 112 .</s><s xml:id="_RrxPDP5">The key strategy behind transformers is to allow neural networks-which are artificial learning models that loosely mimic the behavior of the human brain-to dynamically pay attention to different parts of the input when processing and ultimately making decisions.</s><s xml:id="_PRmpvuT">Originally proposed for natural language processing, thus providing a way to capture the context of each word by attending to other words of the input sentence, this architecture has been successfully extended to other modalities <ref type="bibr">113</ref> .</s></p><p xml:id="_aKjsvFz"><s xml:id="_rufVsJQ">While each input token (that is, the smallest unit for processing) in natural language processing corresponds to a specific word, other modalities have generally used segments of images or video clips as tokens <ref type="bibr">114</ref> .</s><s xml:id="_Q5PWq8t">Transformer architectures allow us to unify the framework for learning across modalities but may still need modality-specific tokenization and encoding.</s><s xml:id="_FD2NskG">A recent study by Meta AI (Meta Platforms) proposed a unified framework for self-supervised learning that is independent of the modality of interest, but still requires modality-specific preprocessing and training <ref type="bibr">115</ref> .</s><s xml:id="_9UCkf9N">Benchmarks for self-supervised multimodal learning allow us to measure the progress of methods across modalities: for instance, the Domain-Agnostic Benchmark for Self-supervised learning (DABS) is a recently proposed benchmark that includes chest X-rays, sensor data and natural image and text data <ref type="bibr">116</ref> .</s></p><p xml:id="_FY4HakE"><s xml:id="_fK225R6">Recent advances proposed by DeepMind (Alphabet), including Perceiver 117 and Perceiver IO 118 , propose a framework for learning across modalities with the same backbone architecture.</s><s xml:id="_UcMPrAz">Importantly, the input to the Perceiver architectures are modality-agnostic byte arrays, which are condensed through an attention bottleneck (that is, an architecture feature that restricts the flow of information, forcing models to condense the most relevant) to avoid size-dependent large memory costs (Fig. <ref type="figure">2a</ref>).</s><s xml:id="_BetAK4q">After processing these inputs, the Perceiver can then feed the representations to a final classification layer to obtain the probability of each output category, while the Perceiver IO can decode these representations directly into arbitrary outputs such as pixels, raw audio and classification labels, through a query vector that specifies the task of interest; for example, the model could output the predicted imaging appearance of an evolving brain tumor, in addition to the probability of successful treatment response.</s></p><p xml:id="_G24KFCQ"><s xml:id="_gRftVK5">A promising aspect of transformers is the ability to learn meaningful representations with unlabeled data, which is paramount in biomedical AI given the limited and expensive resources needed to obtain high-quality labels.</s><s xml:id="_ywtqTNS">Many of the approaches mentioned above require aligned data from different modalities (for example, image-text pairs).</s><s xml:id="_9MzHuYd">A study from DeepMind, in fact, suggested that curating higher-quality image-text datasets may be more important than generating large single-modality datasets, and other aspects of algorithm development and training 119 .</s><s xml:id="_pwx7mxj">However, these data may not be readily available in the setting of biomedical AI.</s><s xml:id="_SaxXMaq">One possible solution to this problem is to leverage available data from one modality to help learning with another-a multimodal learning task termed 'co-learning' 105 .</s><s xml:id="_fMHN9cp">As an example, some studies suggest that transformers pretrained on unlabeled language data might be able to generalize well to a broad range of other tasks 120 .</s><s xml:id="_VrPtxZ9">In medicine, a model architecture called 'CycleGANs' , trained on unpaired contrast and non-contrast CT scans, has been used to generate synthetic non-contrast or contrast CT scans 121 , with this approach showing improvements, for instance, in COVID-19 diagnosis 122 .</s><s xml:id="_KDgzhdn">While promising, this approach has not been tested widely in the biomedical setting and requires further exploration.</s></p><p xml:id="_A8CfEMz"><s xml:id="_DcxsmEv">Another important modeling challenge relates to the exceedingly high number of dimensions contained in multimodal health data, collectively termed 'the curse of dimensionality' .</s><s xml:id="_jupAnxK">As the number of dimensions (that is, variables or features contained in a dataset) increases, the number of people carrying some specific combinations of these features decreases (or for some combinations, even disappears), leading to 'dataset blind spots' , that is, portions of the feature space (the set of all possible combinations of features or variables) that do not have any observation.</s><s xml:id="_C6wtqkW">These dataset blind spots can hurt model performance in terms of real-life prediction and should therefore be considered early in the model development and evaluation process <ref type="bibr">123</ref> .</s><s xml:id="_T6jW55w">Several strategies can be used to mitigate this issue, and have been described in detail elsewhere <ref type="bibr">123</ref> .</s><s xml:id="_E4wVkue">In brief, these include collecting data using maximum performance tasks (for example, rapid finger tapping for motor control, as opposed to passively collected data during everyday movement), ensuring large and diverse sample sizes (that is, with the conditions matching those expected at clinical deployment of the model), using domain knowledge to guide feature engineering and selection (with a focus on feature repeatability), appropriate model training and regularization, rigorous model validation and comprehensive model monitoring (including monitoring the difference between the distributions of training data and data found after deployment).</s><s xml:id="_DFyW2kJ">Looking to the future, developing models able to incorporate previous knowledge (for example, known gene regulatory pathways and protein interactions) might be another promising approach to overcome the curse of dimensionality.</s><s xml:id="_pStB7D2">Along these lines, recent studies demonstrated that models augmented by retrieving information from large databases outperform larger models trained on larger datasets, effectively leveraging available information and also providing added benefits such as interpretability <ref type="bibr">124,</ref><ref type="bibr">125</ref> .</s></p><p xml:id="_UMCAUeG"><s xml:id="_uu6gpxC">An increasingly used approach in multimodal learning is to combine the data from different modalities, as opposed to simply inputting several modalities separately into a model, to increase prediction performance-process termed 'multimodal fusion' <ref type="bibr">126,</ref><ref type="bibr">127</ref> .</s><s xml:id="_QKxX24X">Fusion of different data modalities can be performed at different stages of the process.</s><s xml:id="_5mWBhpT">The simplest approach involves concatenating input modalities or features before any processing (early fusion).</s><s xml:id="_7YA8xHC">While simple, this approach is not suitable for many complex data modalities.</s><s xml:id="_cx96WsN">A more sophisticated approach is to combine and co-learn representations of these different modalities during the training process (joint fusion), allowing for modality-specific preprocessing while still capturing the interaction between data modalities.</s><s xml:id="_2h37PH5">Finally, an alternative approach is to train separate models for each modality and combine the output probabilities (late fusion), a simple and robust approach, but at the cost of missing any information that could be abstracted from the interaction between modalities.</s><s xml:id="_MfbNT8T">Early work on fusion focused on allowing time-series models to leverage information from structured covariates for tasks such as forecasting osteoarthritis progression and predicting surgical outcomes in patients with cerebral palsy 128 .</s><s xml:id="_55cj6u9">As another example of fusion, a group from DeepMind used a high-dimensional EHR-based dataset comprising 620,000 dimensions that were projected into a continuous embedding space with only 800 dimensions, capturing a wide array of information in a 6-h time frame for each patient, and built a recurrent neural network to predict acute kidney injury over time 129 .</s><s xml:id="_pMhAJq2">A lot of studies have used fusion of two modalities (bimodal fusion) to improve predictive performance.</s><s xml:id="_wkn4T3d">Imaging and EHR-based data have been fused to improve detection of pulmonary embolism, outperforming single-modality models <ref type="bibr" target="#b97">99</ref> .</s><s xml:id="_vamhJsb">Another bimodal study fused imaging features from chest X-rays with clinical covariates, improving the diagnosis of tuberculosis in individuals with HIV 130 .</s><s xml:id="_EkyZH6X">Optical coherence tomography and infrared reflectance optic disc imaging have been combined to better predict visual field maps compared to using either of those modalities alone <ref type="bibr">131</ref> .</s></p><p xml:id="_chyJ8qt"><s xml:id="_vNC8mPT">Multimodal fusion is a general concept that can be tackled using any architectural choice.</s><s xml:id="_GpqxT6z">Although not biomedical, we can learn from some AI imaging work; modern guided image generation models such as DALL-E 132 and GLIDE 133 often concatenate information from different modalities into the same encoder.</s><s xml:id="_872DQJs">This approach has demonstrated success in a recent study conducted by DeepMind (using Gato, a generalist agent) showing that concatenating a wide variety of tokens created from text, images and button presses, among others, can be used to teach a model to perform several distinct tasks ranging from captioning images and playing Atari games to stacking blocks with a robot arm (Fig. <ref type="figure">2b</ref>) <ref type="bibr">134</ref> .</s><s xml:id="_McbNntw">Importantly, a recent study titled Align Before Fuse suggested that aligning representations across modalities before fusing them might result in better performance in downstream tasks, such as for creating text captions for images <ref type="bibr">135</ref> .</s><s xml:id="_sQmqc67">A recent study from Google Research proposed using attention bottlenecks for multimodal fusion, thereby restricting the flow of cross-modality information to force models</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Fw2EXJs">AI:</head><p xml:id="_3AaYs7k"><s xml:id="_yqppWP4">This is probably an allergic reaction</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_pwREEZ3">Images and questions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_3vmhhFk">Masked (and shifted) target</head><p xml:id="_QpPJemw"><s xml:id="_7qSFQaM">Fig. <ref type="figure">2</ref> | Simplified illustration of the novel technical concepts in multimodal AI. a, Simplified schematic of the Perceiver-like architecture: images, text and other inputs are converted agnostically into byte arrays that are concatenated (that is, fused) and passed through cross-attention mechanisms (that is, a mechanism to project or condense information into a fixed-dimensional representation) to feed information into the network.</s><s xml:id="_UvaVFxv">b, Simplified illustration of the conceptual framework behind the multimodal multitask architectures (for example, Gato), within a hypothetical medical example: distinct input modalities ranging from images, text and actions are tokenized and fed to the network as input sequences, with masked shifted versions of these sequences fed as targets (that is, the network only sees information from previous time points to predict future actions, only previous words to predict the next or only the image to predict text); the network then learns to handle multiple modalities and tasks.</s></p><p xml:id="_s4uwPzH"><s xml:id="_JVbufrz">to share the most relevant information across modalities and hence improving computational performance 136 .</s><s xml:id="_Nk4c352">Another paradigm of using two modalities together is to 'translate' from one to the other.</s><s xml:id="_M3sbZpv">In many cases, one data modality may be strongly associated with clinical outcomes but be less affordable, accessible or require specialized equipment or invasive procedures.</s><s xml:id="_5mXreEU">Deep learning-enabled computer vision has been shown to capture information typically requiring a higher-fidelity modality for human interpretation.</s><s xml:id="_KuQz8pC">As an example, one study developed a convolutional neural network that uses echocardiogram videos to predict laboratory values of interest such as cardiac biomarkers (troponin I and brain natriuretic peptide) and other commonly obtained biomarkers, and found that predictions from the model were accurate, with some of them even having more prognostic performance for heart failure admissions than conventional laboratory testing <ref type="bibr">137</ref> .</s><s xml:id="_5eFcqUQ">Deep learning has also been widely studied in cancer pathology to make predictions beyond typical pathologist interpretation tasks with H&amp;E stains, with several applications including prediction of genotype and gene expression, response to treatment and survival using only pathology images as inputs <ref type="bibr">138</ref> .</s></p><p xml:id="_zs6x9qZ"><s xml:id="_Aw38SDb">Many other important challenges relating to multimodal model architectures remain.</s><s xml:id="_dHw4KKs">For some modalities (for example, three-dimensional imaging), even models using only a single time point require large computing capabilities, and the prospect of implementing a model that also processes large-scale omics or text data represents an important infrastructural challenge.</s></p><p xml:id="_hVTWuSa"><s xml:id="_R3hDuFK">While multimodal learning has improved at an accelerated rate for the past few years, we expect that current methods are unlikely to be sufficient to overcome all the major challenges mentioned above.</s><s xml:id="_4k7P4Kf">Therefore, further innovation will be required to fully enable effective, multimodal AI models.</s></p><p xml:id="_e4SfAGC"><s xml:id="_EvvwmYy">Data challenges.</s><s xml:id="_javpTwY">The multidimensional data underpinning health leads to a broad range of challenges in terms of collecting, linking and annotating these data.</s><s xml:id="_h2bbdaS">Medical datasets can be described along several axes 139 , including the sample size, depth of phenotyping, the length and intervals of follow-up, the degree of interaction between participants, the heterogeneity and diversity of the participants, the level of standardization and harmonization of the data and the amount of linkage between data sources.</s><s xml:id="_PM9y56t">While science and technology have advanced remarkably to facilitate data collection and phenotyping, there are inevitable trade-offs among these features of biomedical datasets.</s><s xml:id="_TF2pCpX">For example, although large sample sizes (in the range of hundreds of thousands to millions) are desirable in most cases for the training of AI models (especially multimodal AI models), the costs of achieving deep phenotyping and good longitudinal follow-up scales rapidly with larger numbers of participants, becoming financially unsustainable unless automated methods of data collection are put in place.</s></p><p xml:id="_9SkPkDU"><s xml:id="_33qhWZP">There are large-scale efforts to provide meaningful harmonization to biomedical datasets, such as the Observational Medical Outcomes Partnership Common Data Model developed by the Observational Health Data Sciences and Informatics collaboration <ref type="bibr">140</ref> .</s><s xml:id="_yvUAVvt">Harmonization enormously facilitates research efforts and enhances reproducibility and translation into clinical practice.</s><s xml:id="_M6QDspj">However, harmonization may obscure some relevant pathophysiological processes underlying certain diseases.</s><s xml:id="_MHV8c2P">As an example, ischemic stroke subtypes tend not to be accurately captured by existing ontologies 141 , but utilizing raw data from EHRs or radiology reports could allow for the use of natural language processing for phenotyping <ref type="bibr">142</ref> .</s><s xml:id="_KMTvDvZ">Similarly, the Diagnostic and Statistical Manual of Mental Disorders categorizes diagnoses based on clinical manifestations, which might not fully represent underlying pathophysiological processes <ref type="bibr">143</ref> .</s></p><p xml:id="_Ah3KwsJ"><s xml:id="_bdwJxQ7">Achieving diversity across race/ethnicity, ancestry, income level, education level, healthcare access, age, disability status, geographic locations, gender and sexual orientation has proven difficult in practice.</s><s xml:id="_BNrZF8s">Genomics research is a prominent example, with the vast majority of studies focusing on individuals from European ancestry 144 .</s><s xml:id="_zaRqxCM">However, diversity of biomedical datasets is paramount as it constitutes the first step to ensure generalizability to the broader population <ref type="bibr">145</ref> .</s><s xml:id="_pmfQKSC">Beyond these considerations, a required step for multimodal AI is the appropriate linking of all data types available in the datasets, which represents another challenge owing to the increasing risk of identification of individuals and regulatory constraints <ref type="bibr">146</ref> .</s></p><p xml:id="_spMS55d"><s xml:id="_rxQ2sFg">Another frequent problem with biomedical data is the usually high proportion of missing data.</s><s xml:id="_vpR2DCY">While simply excluding patients with missing data before training is an option in some cases, selection bias can arise when other factors influence missing data 147 , and it is often more appropriate to address these gaps with statistical tools, such as multiple imputation 148 .</s><s xml:id="_vvjM8rb">As a result, imputation is a pervasive preprocessing step in many biomedical scientific fields, ranging from genomics to clinical data.</s><s xml:id="_am5Qg5j">Imputation has remarkably improved the statistical power of genome-wide association studies to identify novel genetic risk loci, and is facilitated by large reference datasets with deep genotypic coverage such as 1000 Genomes 149 , the UK10K 150 , the Haplotype reference consortium 151 and, recently, TOPMed <ref type="bibr" target="#b87">89</ref> .</s><s xml:id="_G76rUVr">Beyond genomics, imputation has also demonstrated utility for other types of medical data 152 .</s><s xml:id="_USTZTVH">Different strategies have been suggested to make fewer assumptions.</s><s xml:id="_vKB4APx">These include carry-forward imputation, with imputed values flagged and information added on when they were last measured 153 , and more complex strategies such as capturing the presence of missing data and time intervals using learnable decay terms <ref type="bibr">154</ref> .</s></p><p xml:id="_GyYWnCK"><s xml:id="_EJFfK2e">The risk of incurring several biases is important when conducting studies that collect health data, and multiple approaches are necessary to monitor and mitigate these biases 155 .</s><s xml:id="_cu96fjN">The risk of these biases is amplified when combining data from multiple sources, as the bias toward individuals more likely to consent to each data modality could be amplified when considering the intersection between these potentially biased populations.</s><s xml:id="_AEs5SmX">This complex and unsolved problem is more important in the setting of multimodal health data (compared to unimodal data) and would warrant its own in-depth review.</s><s xml:id="_DAC2Y7C">Medical AI algorithms using demographic features such as race as inputs can learn to perpetuate historical human biases, thereby resulting in harm when deployed 156 .</s><s xml:id="_ukg3Bsd">Importantly, recent work has demonstrated that AI models can identify such features solely from imaging data, which highlights the need for deliberate efforts to detect racial bias and equalize racial outcomes during data quality control and model development <ref type="bibr">157</ref> .</s><s xml:id="_75Gq8Qk">In particular, selection bias is a common type of bias in large biobank studies, and has been reported as a problem, for example, in the UK Biobank 158 .</s><s xml:id="_fKTaC7N">This problem has also been pervasive in the scientific literature regarding COVID-19 (ref. <ref type="bibr">159</ref></s><s xml:id="_4y3nK5u">).</s><s xml:id="_DXD6t66">For example, patients using allergy medications were more likely to be tested for COVID-19, which leads to an artificially lower rate of positive tests, and an apparent protective effect among those tested-probably due to selection bias 160 .</s><s xml:id="_GkTQrYg">Importantly, selection bias can result in AI models trained on a sample that differs considerably from the general population 161 , thus hurting these models at inference time 162 .</s><s xml:id="_GWurzgb">Privacy challenges.</s><s xml:id="_RvxyWrG">The successful development of multimodal AI in health requires breadth and depth of data, which encompasses higher privacy challenges than single-modality AI models.</s><s xml:id="_E73Yqpx">For example, previous studies have demonstrated that by utilizing only a little background information about participants, an adversary could re-identify those in large datasets (for example, the Netflix prize dataset), uncovering sensitive information about the individuals <ref type="bibr">163</ref> .</s></p><p xml:id="_6SgXz9U"><s xml:id="_xDmTEUu">In the USA, the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule is the fundamental legislation to protect privacy of health data.</s><s xml:id="_cNa7PHb">However, some types of health data-such as user-generated and de-identified health data-are not covered by this regulation, which poses a risk of reidentification by combining information from multiple sources.</s><s xml:id="_QxbGwhd">In contrast, the more recent General Data Protection Regulation (GDPR) from the European Union has a much broader scope regarding the definition of health data, and even goes beyond data protection to also require the release of information about automated decision-making using these data <ref type="bibr">164</ref> .</s></p><p xml:id="_yhkVqRK"><s xml:id="_HM6KC89">Given the challenges, multiple technical solutions have been proposed and explored to ensure security and privacy while training multimodal AI models, including differential privacy, federated learning, homomorphic encryption and swarm learning <ref type="bibr">165,</ref><ref type="bibr">166</ref> .</s><s xml:id="_bUFyhFG">Differential privacy proposes a systematic random perturbation of the data with the ultimate goal of obscuring individual-level information while maintaining the global distribution of the dataset 167 .</s><s xml:id="_w2nXJtM">As expected, this approach constitutes a trade-off between the level of privacy obtained and the expected performance of the models.</s><s xml:id="_bpEBbGc">Federated learning, on the other hand, allows several individuals or health systems to collectively train a model without transferring raw data.</s><s xml:id="_K5bMhxa">In this approach, a trusted central server distributes a model to each of the individuals/organizations; each individual or organization then trains the model for a certain number of iterations and shares the model updates back to the trusted central server <ref type="bibr">165</ref> .</s><s xml:id="_QyquRVQ">Finally, the trusted central server aggregates the model updates from all individuals/organizations and starts another round.</s><s xml:id="_bcHwtD7">Federated multimodal learning has been implemented in a multi-institutional collaboration for predicting clinical outcomes in people with COVID-19 (ref. <ref type="bibr">168</ref></s><s xml:id="_c4U4WAS">).</s><s xml:id="_NUahMZC">Homomorphic encryption is a cryptographic technique that allows mathematical operations on encrypted input data, therefore providing the possibility of sharing model weights without leaking information 169 .</s><s xml:id="_7NPasxE">Finally, swarm learning is a relatively novel approach that, similarly to federated learning, is also based on several individuals or organizations training a model on local data, but does not require a trusted central server because it replaces it with the use of blockchain smart contracts <ref type="bibr">170</ref> .</s></p><p xml:id="_9U92jcg"><s xml:id="_haVpNah">Importantly, these approaches are often complementary and they can and should be used together.</s><s xml:id="_8Gu4JWD">A recent study demonstrated the potential of coupling federated learning with homomorphic encryption to train a model to predict a COVID-19 diagnosis from chest CT scans, with the aggregate model outperforming all of the locally trained models 122 .</s><s xml:id="_ZJYXDNb">While these methods are promising, multimodal health data are usually spread across several distinct organizations, ranging from healthcare institutions and academic centers to pharmaceutical companies.</s><s xml:id="_KK2TRpt">Therefore, the development of new methods to incentivize data sharing across sectors while preserving patient privacy is crucial.</s></p><p xml:id="_9d8WJGh"><s xml:id="_GuVXzkq">An additional layer of safety can be obtained by leveraging novel developments in edge computing 171 .</s><s xml:id="_K272QBC">Edge computing, as opposed to cloud computing, refers to the idea of bringing computation closer to the sources of data (for example, close to ambient sensors or wearable devices).</s><s xml:id="_6tQN6wQ">In combination with other methods such as federated learning, edge computing provides more security by avoiding the transmission of sensitive data to centralized servers.</s><s xml:id="_T4WrUyZ">Furthermore, edge computing provides other benefits, such as reducing storage costs, latency and bandwidth usage.</s><s xml:id="_GN2kK72">For example, some X-ray systems now run optimized versions of deep learning models directly in their hardware, instead of transferring images to cloud servers for identification of life-threatening conditions <ref type="bibr">172</ref> .</s></p><p xml:id="_v8SruPw"><s xml:id="_w7Y8jH4">As a result of the expanding healthcare AI market, biomedical data are increasingly valuable, leading to another challenge pertaining to data ownership.</s><s xml:id="_wnxXyBy">To date, this constitutes an open issue of debate.</s><s xml:id="_eAN3tMv">Some voices advocate for private patient ownership of the data, arguing that this approach would ensure the patients' right to self-determination, support health data transactions and maximize patients' benefit from data markets; while others suggest a non-property, regulatory model would better protect secure and transparent data use <ref type="bibr">173,</ref><ref type="bibr">174</ref> .</s><s xml:id="_ajwf34P">Independent of the framework, appropriate incentives should be put in place to facilitate data sharing while ensuring security and privacy <ref type="bibr">175,</ref><ref type="bibr">176</ref> .</s><s xml:id="_HjgewjT">conclusion Multimodal medical AI unlocks key applications in healthcare and many other opportunities exist beyond those described here.</s><s xml:id="_JXQbDdm">The field of drug discovery is a pertinent example, with many tasks that could leverage multidimensional data including target identification and validation, prediction of drug interactions and prediction of side effects 177 .</s><s xml:id="_rTABTZ9">While we addressed many important challenges to the use of multimodal AI, others that were outside the scope of this review are just as important, including the potential for false positives and how clinicians should interpret and explain the risks to patients.</s></p><p xml:id="_ECgNFFs"><s xml:id="_Qahnstg">With the ability to capture multidimensional biomedical data, we confront the challenge of deep phenotyping-understanding each individual's uniqueness.</s><s xml:id="_zBPabMp">Collaboration across industries and sectors is needed to collect and link large and diverse multimodal health data (Box 1).</s><s xml:id="_sMcWfuQ">Yet, as this juncture, we are far better at collating and storing such data, than we are at data analysis.</s><s xml:id="_4uERYAE">To meaningfully process such high-dimensional data and actualize the many exciting use cases, it will take a concentrated joint effort of the medical community and AI researchers to build and validate new models, and ultimately demonstrate their utility to improve health outcomes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MyykrzJ">Box 1 | Priorities for future development of multimodal biomedical AI</head><p xml:id="_PpMUaGR"><s xml:id="_xDyXr7v">• Discover and formulate key medical AI tasks for which multimodal data will add value over single modalities.</s><s xml:id="_rqrNr9B">• Develop approaches that can pretrain models using large amounts of unlabeled data across modalities and only require fine-tuning on limited labeled data.</s><s xml:id="_6WawbVU">• Benchmark the effect of model architectures and multimodal approaches when working with previously underexplored high-dimensional data, such as omics data.</s><s xml:id="_m8GTtqv">• Collect paired (for example, image-text) multimodal data that could be used to train and test the generalizability of multimodal medical AI algorithms.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 |</head><label>1</label><figDesc><div><p xml:id="_AsQyBtN"><s xml:id="_dDzaxMG">Fig. 1 | data modalities and opportunities for multimodal biomedical AI.</s><s xml:id="_tbNQhYf">Created with BioRender.com.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc><div><p xml:id="_pZHh8Fn"><s xml:id="_62sJCs9">What caused this rash?</s></p></div></figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_nhwN8Jv"><s xml:id="_5X4VqAy">NATuRE MEdIcINE | VOL 28 | SEPTEMBER 2022 | 1773-1784 | www.nature.com/naturemedicine</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_Cmahydg">Acknowledgements</head><p xml:id="_93Sytdt"><s xml:id="_3KQbEH4">We thank <rs type="person">A. Tamkin</rs> for invaluable feedback.</s><s xml:id="_AAD3pWc"><rs type="funder">NIH</rs> grant <rs type="grantNumber">UL1TR002550</rs> (to E.J.T.) supported this work.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_phhEXnZ">
					<idno type="grant-number">UL1TR002550</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_dkkcdaF">competing interests</head><p xml:id="_7EGQPTX"><s xml:id="_npBdZCd">Since completing this Review, J.N.A. became an employee of Rad AI.</s><s xml:id="_DAxEenM">All the other authors declare no competing interests.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_gbYC6Jk">A guide to deep learning in healthcare</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kVXW7jQ">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="24" to="29" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Esteva, A. et al. A guide to deep learning in healthcare. Nat. Med. 25, 24-29 (2019).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_s3bVxwZ">Deep learning-enabled medical computer vision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hsmGHDc">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Esteva, A. et al. Deep learning-enabled medical computer vision. NPJ Digit. Med. 4, 5 (2021).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_gJX3GEa">AI in health and medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Agg3UDE">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="31" to="38" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajpurkar, P., Chen, E., Banerjee, O. &amp; Topol, E. J. AI in health and medicine. Nat. Med. 28, 31-38 (2022).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_KawQ3Jz">Integrative omics for health and disease</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Karczewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Snyder</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrg.2018.4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NyEeXSa">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="299" to="310" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Karczewski, K. J. &amp; Snyder, M. P. Integrative omics for health and disease. Nat. Rev. Genet. 19, 299-310 (2018).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_x6sAtzk">Emerging molecular markers of cancer</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sidransky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_P3xVvsS">Nat. Rev. Cancer</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="210" to="219" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sidransky, D. Emerging molecular markers of cancer. Nat. Rev. Cancer 2, 210-219 (2002).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_DCEPXpS">An integrated genomic analysis of human glioblastoma multiforme</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Parsons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_b2NNxTG">Science</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="page" from="1807" to="1812" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Parsons, D. W. et al. An integrated genomic analysis of human glioblastoma multiforme. Science 321, 1807-1812 (2008).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<idno type="DOI">10.1093/cid/cir046</idno>
		<ptr target="https://www.fda.gov/medical-devices/in-vitro-diagnostics/list-cleared-or-approved-companion-diagnostic-devices-in-vitro-and-imaging-tools" />
		<title level="m" xml:id="_5eXhrJz">List of cleared or approved companion diagnostic devices (in vitro and imaging tools</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>Food and Drug Administration</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Food and Drug Administration. List of cleared or approved companion diagnostic devices (in vitro and imaging tools) https://www.fda.gov/ medical-devices/in-vitro-diagnostics/list-cleared-or-approved- companion-diagnostic-devices-in-vitro-and-imaging-tools (2021).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<idno type="DOI">10.1128/9781555818814.ch12.6</idno>
		<ptr target="https://www.fda.gov/medical-devices/in-vitro-diagnostics/nucleic-acid-based-tests" />
		<title level="m" xml:id="_SaE9gXU">Nucleic acid-based tests</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>Food and Drug Administration</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Food and Drug Administration. Nucleic acid-based tests https://www.fda. gov/medical-devices/in-vitro-diagnostics/nucleic-acid-based-tests (2020).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Foundation</forename><surname>Medicine</surname></persName>
		</author>
		<idno type="DOI">10.1200/adn.23.201428</idno>
		<ptr target="https://www.foundationmedicine.com/resource/why-comprehensive-genomic-profiling" />
		<title level="m" xml:id="_FGfQ4MD">Why comprehensive genomic profiling?</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Foundation Medicine. Why comprehensive genomic profiling? https://www. foundationmedicine.com/resource/why-comprehensive-genomic- profiling (2018).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<ptr target="https://www.oncotypeiq.com/en-US/pan-cancer/healthcare-professionals/oncotype-map-pan-cancer-tissue-test/about-the-test-oncology" />
		<title level="m" xml:id="_UB77CFS">Oncotype IQ. Oncotype MAP pan-cancer tissue test</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Oncotype IQ. Oncotype MAP pan-cancer tissue test https://www. oncotypeiq.com/en-US/pan-cancer/healthcare-professionals/ oncotype-map-pan-cancer-tissue-test/about-the-test-oncology (2020).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_j7q5qwz">Current and future perspectives of liquid biopsies in genomics-driven oncology</title>
		<author>
			<persName><forename type="first">E</forename><surname>Heitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Speicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_N7dWyG3">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="71" to="88" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Heitzer, E., Haque, I. S., Roberts, C. E. S. &amp; Speicher, M. R. Current and future perspectives of liquid biopsies in genomics-driven oncology. Nat. Rev. Genet. 20, 71-88 (2018).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_6SDNTAT">Genome-wide association studies</title>
		<author>
			<persName><forename type="first">E</forename><surname>Uffelmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Yq2cFTN">Nat. Rev. Methods Primers</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Uffelmann, E. et al. Genome-wide association studies. Nat. Rev. Methods Primers 1, 1-21 (2021).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_QzGFyrF">A global overview of pleiotropy and genetic architecture in complex traits</title>
		<author>
			<persName><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41588-019-0481-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_k2jEweg">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1339" to="1348" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Watanabe, K. et al. A global overview of pleiotropy and genetic architecture in complex traits. Nat. Genet. 51, 1339-1348 (2019).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_UEJUxKw">Tutorial: a guide to performing polygenic risk score analyses</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Mak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename></persName>
		</author>
		<idno type="DOI">10.1038/s41596-020-0353-1</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pzfUZEY">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2759" to="2772" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Choi, S. W., Mak, T. S. -H. &amp; O&apos;Reilly, P. F. Tutorial: a guide to performing polygenic risk score analyses. Nat. Protoc. 15, 2759-2772 (2020).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_WauHnqb">Patients with high genome-wide polygenic risk scores for coronary artery disease may receive greater clinical benefit from alirocumab treatment in the ODYSSEY OUTCOMES trial</title>
		<author>
			<persName><forename type="first">A</forename><surname>Damask</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jPaUSPd">Circulation</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="624" to="636" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Damask, A. et al. Patients with high genome-wide polygenic risk scores for coronary artery disease may receive greater clinical benefit from alirocumab treatment in the ODYSSEY OUTCOMES trial. Circulation 141, 624-636 (2020).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_g3SWcWD">Predicting benefit from evolocumab therapy in patients with atherosclerotic disease using a genetic risk score: results from the FOURIER trial</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Marston</surname></persName>
		</author>
		<idno type="DOI">10.1161/circulationaha.119.043805</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AZsqYAu">Circulation</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="616" to="623" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Marston, N. A. et al. Predicting benefit from evolocumab therapy in patients with atherosclerotic disease using a genetic risk score: results from the FOURIER trial. Circulation 141, 616-623 (2020).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_P6Qvz6x">Evaluation and comparison of multi-omics data integration methods for cancer subtyping</title>
		<author>
			<persName><forename type="first">R</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7qcZWb7">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">1009224</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Duan, R. et al. Evaluation and comparison of multi-omics data integration methods for cancer subtyping. PLoS Comput. Biol. 17, e1009224 (2021).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_n6U7QaJ">A roadmap for multi-omics data integration using deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Mersha</surname></persName>
		</author>
		<idno type="DOI">10.1093/bib/bbab454</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MnTseZx">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">454</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kang, M., Ko, E. &amp; Mersha, T. B. A roadmap for multi-omics data integration using deep learning. Brief. Bioinform. 23, bbab454 (2022).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_mcsJkwX">MOGONET integrates multi-omics data using graph convolutional networks allowing patient classification and biomarker identification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-23774-w</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mMJNDUw">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">3445</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang, T. et al. MOGONET integrates multi-omics data using graph convolutional networks allowing patient classification and biomarker identification. Nat. Commun. 12, 3445 (2021).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_jBAYcxX">Graph neural networks and their current applications in bioinformatics</title>
		<author>
			<persName><forename type="first">X.-M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_c9gARBs">Front. Genet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">690049</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhang, X.-M., Liang, L., Liu, L. &amp; Tang, M.-J. Graph neural networks and their current applications in bioinformatics. Front. Genet. 12, 690049 (2021).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_7KK6Q9k">Visualizing structure and transitions in high-dimensional biological data</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HMC8dgb">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1482" to="1492" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moon, K. R. et al. Visualizing structure and transitions in high-dimensional biological data. Nat. Biotechnol. 37, 1482-1492 (2019).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_g6FEHGn">Multiscale PHATE identifies multimodal signatures of COVID-19</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kuchroo</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41587-021-01186-x</idno>
		<ptr target="https://doi.org/10.1038/s41587-021-01186-x" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_xZvj8rr">Nat. Biotechnol</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kuchroo, M. et al. Multiscale PHATE identifies multimodal signatures of COVID-19. Nat. Biotechnol. https://doi.org/10.1038/s41587-021-01186-x (2022).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_BDFUFTZ">Harnessing multimodal data integration to advance precision oncology</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Boehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Khosravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vanguri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41568-021-00408-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YKKBFmp">Nat. Rev. Cancer</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="114" to="126" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Boehm, K. M., Khosravi, P., Vanguri, R., Gao, J. &amp; Shah, S. P. Harnessing multimodal data integration to advance precision oncology. Nat. Rev. Cancer 22, 114-126 (2021).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_xPH6aMQ">Method of the year: spatially resolved transcriptomics</title>
		<author>
			<persName><forename type="first">V</forename><surname>Marx</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41592-020-01033-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HGZP2zR">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="9" to="14" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Marx, V. Method of the year: spatially resolved transcriptomics. Nat. Methods 18, 9-14 (2021).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_RamScGP">Integrating spatial gene expression and breast tumour morphology via deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BpDjJaJ">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="827" to="834" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">He, B. et al. Integrating spatial gene expression and breast tumour morphology via deep learning. Nat. Biomed. Eng. 4, 827-834 (2020).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_x43GZMv">Super-resolved spatial transcriptomics by deep data fusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bergenstråhle</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41587-021-01075-3</idno>
		<ptr target="https://doi.org/10.1038/s41587-021-01075-3" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_xwRz4cW">Nat. Biotechnol</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bergenstråhle, L. et al. Super-resolved spatial transcriptomics by deep data fusion. Nat. Biotechnol. https://doi.org/10.1038/s41587-021-01075-3 (2021).</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_jwb9tZj">Validity of polygenic risk scores: are we measuring what we think we are?</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C J W</forename><surname>Janssens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eQDfjV5">Hum. Mol. Genet</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="R143" to="R150" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Janssens, A. C. J. W. Validity of polygenic risk scores: are we measuring what we think we are? Hum. Mol. Genet 28, R143-R150 (2019).</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_se6R2wK">Personal omics for precision health</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kellogg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Snyder</surname></persName>
		</author>
		<idno type="DOI">10.1161/circresaha.117.310909</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AheYgSG">Circ. Res</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="1169" to="1171" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kellogg, R. A., Dunn, J. &amp; Snyder, M. P. Personal omics for precision health. Circ. Res. 122, 1169-1171 (2018).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_ta9MuPZ">Rapid sequencing-based diagnosis of thiamine metabolism dysfunction syndrome</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Owen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Af5gvQr">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">384</biblScope>
			<biblScope unit="page" from="2159" to="2161" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Owen, M. J. et al. Rapid sequencing-based diagnosis of thiamine metabolism dysfunction syndrome. N. Engl. J. Med. 384, 2159-2161 (2021).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_fj8R5PG">Estimated costs of pivotal trials for novel therapeutic agents approved by the US food and drug administration, 2015-2016</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Alexander</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2018.3931</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Xf6sTkc">JAMA Intern. Med</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="1451" to="1457" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moore, T. J., Zhang, H., Anderson, G. &amp; Alexander, G. C. Estimated costs of pivotal trials for novel therapeutic agents approved by the US food and drug administration, 2015-2016. JAMA Intern. Med. 178, 1451-1457 (2018).</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_sQJAFVX">Key cost drivers of pharmaceutical clinical trials in the United States</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sertkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H. -H</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jessup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Beleche</surname></persName>
		</author>
		<idno type="DOI">10.1177/1740774515625964</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xmPyQzz">Clin. Trials</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="117" to="126" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sertkaya, A., Wong, H. -H., Jessup, A. &amp; Beleche, T. Key cost drivers of pharmaceutical clinical trials in the United States. Clin. Trials 13, 117-126 (2016).</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_RuB4kNH">Disparity of race reporting and representation in clinical trials leading to cancer drug approvals from 2008 to 2018</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Loree</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamaoncol.2019.1870</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Zxb8g9d">JAMA Oncol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">191870</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Loree, J. M. et al. Disparity of race reporting and representation in clinical trials leading to cancer drug approvals from 2008 to 2018. JAMA Oncol. 5, e191870 (2019).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_cutYwRC">Digital clinical trials: creating a vision for the future</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Steinhubl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Wolff-Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nilsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Iturriaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Califf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2Ezem3J">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">126</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Steinhubl, S. R., Wolff-Hughes, D. L., Nilsen, W., Iturriaga, E. &amp; Califf, R. M. Digital clinical trials: creating a vision for the future. NPJ Digit. Med. 2, 126 (2019).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_3hapjUm">Digitizing clinical trials</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">T</forename><surname>Inan</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-020-0302-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Enqcjm4">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">101</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Inan, O. T. et al. Digitizing clinical trials. NPJ Digit. Med. 3, 101 (2020).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_2jxXyku">Wearable sensors enable personalized predictions of clinical laboratory measurements</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pQc75Kp">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1105" to="1112" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dunn, J. et al. Wearable sensors enable personalized predictions of clinical laboratory measurements. Nat. Med. 27, 1105-1112 (2021).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_ufR3e7P">Quantifying the use of connected digital products in clinical research</title>
		<author>
			<persName><forename type="first">C</forename><surname>Marra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coravos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Stern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8kFb6V4">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Marra, C., Chen, J. L., Coravos, A. &amp; Stern, A. D. Quantifying the use of connected digital products in clinical research. NPJ Digit. Med. 3, 50 (2020).</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_TEdw5Fk">Effect of a home-based wearable continuous ECG monitoring patch on detection of undiagnosed atrial fibrillation: the mSToPS randomized clinical trial</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Steinhubl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_d8ceFJK">JAMA</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="page" from="146" to="155" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Steinhubl, S. R. et al. Effect of a home-based wearable continuous ECG monitoring patch on detection of undiagnosed atrial fibrillation: the mSToPS randomized clinical trial. JAMA 320, 146-155 (2018).</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_DP3RJfr">Smartphone apps in the COVID-19 pandemic</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Pandit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Radin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41587-022-01350-x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_k494xXz">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1013" to="1022" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pandit, J. A., Radin, J. M., Quer, G. &amp; Topol, E. J. Smartphone apps in the COVID-19 pandemic. Nat. Biotechnol. 40, 1013-1022 (2022).</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_Hy9GM7s">Adaptive designs in clinical trials: why use them, and how to run and report them</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pallmann</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12916-018-1017-7</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Kdn5FfE">BMC Med</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pallmann, P. et al. Adaptive designs in clinical trials: why use them, and how to run and report them. BMC Med. 16, 29 (2018).</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_NEeaXHk">Clinical utility of polygenic risk scores for coronary artery disease</title>
		<author>
			<persName><forename type="first">D</forename><surname>Klarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Natarajan</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41569-021-00638-w</idno>
		<ptr target="https://doi.org/10.1038/s41569-021-00638-w" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_CUKykS2">Nat. Rev. Cardiol</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Klarin, D. &amp; Natarajan, P. Clinical utility of polygenic risk scores for coronary artery disease. Nat. Rev. Cardiol. https://doi.org/10.1038/ s41569-021-00638-w (2021).</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_Gw9kX42">Temporal fusion transformers for interpretable multi-horizon time series forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Ö</forename><surname>Arık</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Loeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JFCFZKP">Int. J. Forecast</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1748" to="1764" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lim, B., Arık, S. Ö., Loeff, N. &amp; Pfister, T. Temporal fusion transformers for interpretable multi-horizon time series forecasting. Int. J. Forecast. 37, 1748-1764 (2021).</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_mJ7MV65">Graph-guided network for irregularly sampled multivariate time series</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tsiligkaridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_J8YHatt">International Conference on Learning Representation</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhang, X., Zeman, M., Tsiligkaridis, T. &amp; Zitnik, M. Graph-guided network for irregularly sampled multivariate time series. In International Conference on Learning Representation (ICLR, 2022).</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_Y7m3eKY">Synthetic and external controls in clinical trials-a primer for researchers</title>
		<author>
			<persName><forename type="first">K</forename><surname>Thorlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Mills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eMAvymd">Clin. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="457" to="467" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thorlund, K., Dron, L., Park, J. J. H. &amp; Mills, E. J. Synthetic and external controls in clinical trials-a primer for researchers. Clin. Epidemiol. 12, 457-467 (2020).</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<ptr target="https://www.fda.gov/news-events/press-announcements/fda-approves-first-treatment-form-batten-disease#:~:text=The%20" />
		<title level="m" xml:id="_kMTseew">FDA approves first treatment for a form of Batten disease</title>
		<imprint>
			<publisher>U.S</publisher>
			<date type="published" when="2017">of%20Batten%20disease (2017</date>
		</imprint>
		<respStmt>
			<orgName>Food and Drug Administration</orgName>
		</respStmt>
	</monogr>
	<note>%20 Food%20and%20Drug,specific%20form%20</note>
	<note type="raw_reference">Food and Drug Administration. FDA approves first treatment for a form of Batten disease https://www.fda.gov/news-events/press-announcements/ fda-approves-first-treatment-form-batten-disease#:~:text=The%20U.S.%20 Food%20and%20Drug,specific%20form%20of%20Batten%20disease (2017).</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<ptr target="https://www.fda.gov/science-research/science-and-research-special-topics/real-world-evidence" />
		<title level="m" xml:id="_qHcRunj">Real-world evidence</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
		<respStmt>
			<orgName>Food and Drug Administration</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Food and Drug Administration. Real-world evidence https://www.fda.gov/ science-research/science-and-research-special-topics/real-world-evidence (2022).</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><surname>Abbvie</surname></persName>
		</author>
		<ptr target="https://stories.abbvie.com/stories/synthetic-control-arm-end-placebos.htm" />
		<title level="m" xml:id="_QD5eBDZ">Synthetic control arm: the end of placebos?</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">AbbVie. Synthetic control arm: the end of placebos? https://stories.abbvie. com/stories/synthetic-control-arm-end-placebos.htm (2019).</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="middle">Ai</forename><surname>Unlearn</surname></persName>
		</author>
		<ptr target="https://www.unlearn.ai/post/generating-synthetic-control-subjects-alzheimers" />
		<title level="m" xml:id="_UqCcTFF">Generating synthetic control subjects using machine learning for clinical trials in Alzheimer&apos;s disease (DIA</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Unlearn.AI. Generating synthetic control subjects using machine learning for clinical trials in Alzheimer&apos;s disease (DIA 2019) https://www.unlearn.ai/ post/generating-synthetic-control-subjects-alzheimers (2019).</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_ywZmyB9">Impact of remote patient monitoring on clinical outcomes: an updated meta-analysis of randomized controlled trials</title>
		<author>
			<persName><forename type="first">B</forename><surname>Noah</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-017-0002-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dT8Qfqw">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">20172</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Noah, B. et al. Impact of remote patient monitoring on clinical outcomes: an updated meta-analysis of randomized controlled trials. NPJ Digit. Med. 1, 20172 (2018).</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_bYTA77R">Wearable-device-measured physical activity and future health risk</title>
		<author>
			<persName><forename type="first">T</forename><surname>Strain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_db7xH8H">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1385" to="1391" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Strain, T. et al. Wearable-device-measured physical activity and future health risk. Nat. Med. 26, 1385-1391 (2020).</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_xKqcUZs">Advances in healthcare wearable devices</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M A</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mahgoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Leavitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Asghar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vkkZbn8">NPJ Flex. Electron</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Iqbal, S. M. A., Mahgoub, I., Du, E., Leavitt, M. A. &amp; Asghar, W. Advances in healthcare wearable devices. NPJ Flex. Electron. 5, 9 (2021).</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_tJTGzSF">SMART on FHIR: a standards-based, interoperable apps platform for electronic health records</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Kreda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kohane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Ramoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jJP5u8h">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="899" to="908" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mandel, J. C., Kreda, D. A., Mandl, K. D., Kohane, I. S. &amp; Ramoni, R. B. SMART on FHIR: a standards-based, interoperable apps platform for electronic health records. J. Am. Med. Inform. Assoc. 23, 899-908 (2016).</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_CKpvc22">Illuminating the dark spaces of healthcare with ambient intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Milstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3Xxuw4n">Nature</title>
		<imprint>
			<biblScope unit="volume">585</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Haque, A., Milstein, A. &amp; Fei-Fei, L. Illuminating the dark spaces of healthcare with ambient intelligence. Nature 585, 193-202 (2020).</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_cumHUrT">Human fall detection on embedded platform using depth maps and wireless accelerometer</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kwolek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kepski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CJx466F">Comput. Methods Prog. Biomed</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="489" to="501" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kwolek, B. &amp; Kepski, M. Human fall detection on embedded platform using depth maps and wireless accelerometer. Comput. Methods Prog. Biomed. 117, 489-501 (2014).</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_v2rTBH8">Multimodal gait analysis based on wearable inertial and microphone sensors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/uic-atc.2017.8397481</idno>
		<idno>) 1-8</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_SzgxpYV">IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation</title>
		<imprint>
			<publisher>SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI</publisher>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang, C. et al. Multimodal gait analysis based on wearable inertial and microphone sensors. In 2017 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI) 1-8 (2017).</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_akFV63M">Computer vision-based descriptive analytics of seniors&apos; daily activities for long-term health monitoring</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_mnQgZ2a">Proc. Machine Learning Research</title>
		<meeting>Machine Learning Research</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
	<note type="raw_reference">Luo, Z. et al. Computer vision-based descriptive analytics of seniors&apos; daily activities for long-term health monitoring. In Proc. Machine Learning Research Vol. 85, 1-18 (PMLR, 2018).</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_mmttEH7">Implementation of a multisite, interdisciplinary remote patient monitoring program for ambulatory management of patients with COVID-19</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Coffey</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-021-00490-9</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dqBVsbC">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">123</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Coffey, J. D. et al. Implementation of a multisite, interdisciplinary remote patient monitoring program for ambulatory management of patients with COVID-19. NPJ Digit. Med. 4, 123 (2021).</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_t2Y9Z7A">Applications of digital technology in COVID-19 pandemic planning and response</title>
		<author>
			<persName><forename type="first">S</forename><surname>Whitelaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mamas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Topol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G C</forename><surname>Van Spall</surname></persName>
		</author>
		<idno type="DOI">10.1016/s2589-7500(20)30142-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FjCNNk4">Lancet Digit. Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="435" to="e440" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Whitelaw, S., Mamas, M. A., Topol, E. &amp; Van Spall, H. G. C. Applications of digital technology in COVID-19 pandemic planning and response. Lancet Digit. Health 2, e435-e440 (2020).</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main" xml:id="_YyH9Gez">Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Leung</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0140-6736(20)30260-9</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XN8feJk">Lancet</title>
		<imprint>
			<biblScope unit="volume">395</biblScope>
			<biblScope unit="page" from="689" to="697" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wu, J. T., Leung, K. &amp; Leung, G. M. Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study. Lancet 395, 689-697 (2020).</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_VYd3UQE">Response to COVID-19 in Taiwan: big data analytics, new technology, and proactive testing</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Brook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename></persName>
		</author>
		<idno type="DOI">10.1001/jama.2020.3151</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rVNxmKz">JAMA</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="1341" to="1342" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jason Wang, C., Ng, C. Y. &amp; Brook, R. H. Response to COVID-19 in Taiwan: big data analytics, new technology, and proactive testing. JAMA 323, 1341-1342 (2020).</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main" xml:id="_Vc2TAB8">Harnessing wearable device data to improve state-level real-time surveillance of influenza-like illness in the USA: a population-based study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Radin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Wineinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Steinhubl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GNVMTvx">Lancet Digit. Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="85" to="e93" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Radin, J. M., Wineinger, N. E., Topol, E. J. &amp; Steinhubl, S. R. Harnessing wearable device data to improve state-level real-time surveillance of influenza-like illness in the USA: a population-based study. Lancet Digit. Health 2, e85-e93 (2020).</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_u7BebCv">Wearable sensor data and self-reported symptoms for COVID-19 detection</title>
		<author>
			<persName><forename type="first">G</forename><surname>Quer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VcGfjrb">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="73" to="77" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Quer, G. et al. Wearable sensor data and self-reported symptoms for COVID-19 detection. Nat. Med. 27, 73-77 (2020).</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_KFtcygz">Leveraging artificial intelligence for pandemic preparedness and response: a scoping review to identify key use cases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Syrowatka</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-021-00459-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4UKDfa9">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">96</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Syrowatka, A. et al. Leveraging artificial intelligence for pandemic preparedness and response: a scoping review to identify key use cases. NPJ Digit. Med. 4, 96 (2021).</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main" xml:id="_NqheYxb">A multimodal deep fusion graph framework to detect social distancing violations and FCGs in pandemic surveillance</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Varghese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Thampi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.engappai.2021.104305</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mFTrNa8">Eng. Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page">104305</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Varghese, E. B. &amp; Thampi, S. M. A multimodal deep fusion graph framework to detect social distancing violations and FCGs in pandemic surveillance. Eng. Appl. Artif. Intell. 103, 104305 (2021).</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main" xml:id="_NR44X6v">The digital twin revolution</title>
		<author>
			<persName><forename type="first">O</forename><surname>San</surname></persName>
		</author>
		<idno type="DOI">10.1038/s43588-021-00077-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PE4Uy5b">Nat. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="307" to="308" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">San, O. The digital twin revolution. Nat. Comput. Sci. 1, 307-308 (2021).</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_XTMqyV7">Digital twins to personalize medicine</title>
		<author>
			<persName><forename type="first">B</forename><surname>Björnsson</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13073-019-0701-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zjk64J7">Genome Med</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Björnsson, B. et al. Digital twins to personalize medicine. Genome Med. 12, 4 (2019).</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main" xml:id="_NehnsSw">Digital twins: from personalised medicine to precision public health</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Kamel Boulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6ECZJxp">J. Pers. Med</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">745</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kamel Boulos, M. N. &amp; Zhang, P. Digital twins: from personalised medicine to precision public health. J. Pers. Med 11, 745 (2021).</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main" xml:id="_seJPKKf">Digital twins for predictive oncology will be a paradigm shift for precision cancer care</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hernandez-Boussard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_48ffrVh">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2065" to="2066" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hernandez-Boussard, T. et al. Digital twins for predictive oncology will be a paradigm shift for precision cancer care. Nat. Med. 27, 2065-2066 (2021).</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main" xml:id="_xtwjm7c">The health digital twin: advancing precision cardiovascular medicine</title>
		<author>
			<persName><forename type="first">G</forename><surname>Coorey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Figtree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Redfern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DvwGGad">Nat. Rev. Cardiol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="803" to="804" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Coorey, G., Figtree, G. A., Fletcher, D. F. &amp; Redfern, J. The health digital twin: advancing precision cardiovascular medicine. Nat. Rev. Cardiol. 18, 803-804 (2021).</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_2mKV364">A modular computational framework for medical digital twins</title>
		<author>
			<persName><forename type="first">J</forename><surname>Masison</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2024287118</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YfxFXcz">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">2024287118</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Masison, J. et al. A modular computational framework for medical digital twins. Proc. Natl Acad. Sci. USA 118, e2024287118 (2021).</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main" xml:id="_uveT8DF">Machine learning for comprehensive forecasting of Alzheimer&apos;s disease progression</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dRZfT6Q">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">13622</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fisher, C. K., Smith, A. M. &amp; Walsh, J. R. Machine learning for comprehensive forecasting of Alzheimer&apos;s disease progression. Sci. Rep. 9, 13622 (2019).</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main" xml:id="_ZJ9kngC">Generating digital twins with multiple sclerosis using probabilistic neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Walsh</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2002.02779" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Walsh, J. R. et al. Generating digital twins with multiple sclerosis using probabilistic neural networks. Preprint at https://arxiv.org/abs/2002.02779 (2020).</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main" xml:id="_2ZMGPB9">Development of CancerLinQ, a health information learning platform from multiple electronic health record systems to support improved quality of care</title>
		<author>
			<persName><forename type="first">D</forename><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dHWWddy">JCO Clin. Cancer Inform</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="929" to="937" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Potter, D. et al. Development of CancerLinQ, a health information learning platform from multiple electronic health record systems to support improved quality of care. JCO Clin. Cancer Inform. 4, 929-937 (2020).</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main" xml:id="_sererK7">Health-focused conversational agents in person-centered care: a review of apps</title>
		<author>
			<persName><forename type="first">P</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pandya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sedoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8pHRQcd">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Parmar, P., Ryu, J., Pandya, S., Sedoc, J. &amp; Agarwal, S. Health-focused conversational agents in person-centered care: a review of apps. NPJ Digit. Med. 5, 21 (2022).</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main" xml:id="_x8mGvny">A virtual type 2 diabetes clinic using continuous glucose monitoring and endocrinology visits</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Dixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3EuCSqv">J. Diabetes Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="908" to="911" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dixon, R. F. et al. A virtual type 2 diabetes clinic using continuous glucose monitoring and endocrinology visits. J. Diabetes Sci. Technol. 14, 908-911 (2020).</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main" xml:id="_FnqpJ5m">Identifying acute exacerbations of chronic obstructive pulmonary disease using patient-reported symptoms and cough feature analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Claxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dbfu7zp">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">107</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Claxton, S. et al. Identifying acute exacerbations of chronic obstructive pulmonary disease using patient-reported symptoms and cough feature analysis. NPJ Digit. Med. 4, 107 (2021).</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main" xml:id="_GHSgWgr">High-performance medicine: the convergence of human and artificial intelligence</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mnDfArQ">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="44" to="56" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Topol, E. J. High-performance medicine: the convergence of human and artificial intelligence. Nat. Med. 25, 44-56 (2019).</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main" xml:id="_y68cPN6">Nudge units to improve the delivery of health care</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Volpp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Asch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yJy8Tyj">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="page" from="214" to="216" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Patel, M. S., Volpp, K. G. &amp; Asch, D. A. Nudge units to improve the delivery of health care. N. Engl. J. Med. 378, 214-216 (2018).</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main" xml:id="_k2KmsNM">Recipes for building an open-domain Chatbot</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_BfgHwc3">Proc. 16th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>16th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="300" to="325" />
		</imprint>
	</monogr>
	<note type="raw_reference">Roller, S. et al. Recipes for building an open-domain Chatbot. In Proc. 16th Conference of the European Chapter of the Association for Computational Linguistics 300-325 (Association for Computational Linguistics, 2021).</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main" xml:id="_BPRwKxX">Machine learning and prediction in medicine -beyond the peak of inflated expectations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Asch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZADjsW7">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="page" from="2507" to="2509" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen, J. H. &amp; Asch, S. M. Machine learning and prediction in medicine -beyond the peak of inflated expectations. N. Engl. J. Med. 376, 2507-2509 (2017).</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main" xml:id="_amVFtd4">The UK Biobank resource with deep phenotyping and genomic data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bycroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_edYXt3g">Nature</title>
		<imprint>
			<biblScope unit="volume">562</biblScope>
			<biblScope unit="page" from="203" to="209" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bycroft, C. et al. The UK Biobank resource with deep phenotyping and genomic data. Nature 562, 203-209 (2018).</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main" xml:id="_PsFMqjb">Accuracy of electronic health record data for identifying stroke cases in large-scale epidemiological studies: a systematic review from the UK biobank stroke outcomes group</title>
		<author>
			<persName><forename type="first">R</forename><surname>Woodfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biobank</forename><surname>Uk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Outcomes</forename><surname>Stroke</surname></persName>
		</author>
		<author>
			<persName><surname>Group</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biobank</forename><surname>Uk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Outcomes</forename><forename type="middle">Working</forename><surname>Follow-Up</surname></persName>
		</author>
		<author>
			<persName><surname>Group</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L M</forename><surname>Sudlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qYnUYJj">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">140533</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Woodfield, R., Grant, I., UK Biobank Stroke Outcomes Group, UK Biobank Follow-Up and Outcomes Working Group &amp; Sudlow, C. L. M. Accuracy of electronic health record data for identifying stroke cases in large-scale epidemiological studies: a systematic review from the UK biobank stroke outcomes group. PLoS ONE 10, e0140533 (2015).</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main" xml:id="_fvtxNBn">Advancing human genetics research and drug discovery through exome sequencing of the UK Biobank</title>
		<author>
			<persName><forename type="first">J</forename><surname>Szustakowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qmjhzDb">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="942" to="948" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Szustakowski, J. et al. Advancing human genetics research and drug discovery through exome sequencing of the UK Biobank. Nat. Genet. 53, 942-948 (2021).</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main" xml:id="_MZXPsdG">The sequences of 150,119 genomes in the UK Biobank</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Halldorsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_smWkdGW">Nature</title>
		<imprint>
			<biblScope unit="volume">607</biblScope>
			<biblScope unit="page" from="732" to="740" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Halldorsson, B. V. et al. The sequences of 150,119 genomes in the UK Biobank. Nature 607, 732-740 (2022).</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main" xml:id="_YZHn8pS">The UK Biobank imaging enhancement of 100,000 participants: rationale, data collection, management and future directions</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GhJ5drK">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">2624</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">\Littlejohns, T. J. et al. The UK Biobank imaging enhancement of 100,000 participants: rationale, data collection, management and future directions. Nat. Commun. 11, 2624 (2020).</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main" xml:id="_YABqryY">China Kadoorie Biobank of 0.5 million people: survey methods, baseline characteristics and long-term follow-up</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_x4dEZRj">Int. J. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1652" to="1666" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen, Z. et al. China Kadoorie Biobank of 0.5 million people: survey methods, baseline characteristics and long-term follow-up. Int. J. Epidemiol. 40, 1652-1666 (2011).</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main" xml:id="_aSNbPdY">Overview of the BioBank Japan Project: study design and profile</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nagai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_74k4kDB">J. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2" to="S8" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nagai, A. et al. Overview of the BioBank Japan Project: study design and profile. J. Epidemiol. 27, S2-S8 (2017).</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main" xml:id="_gZyHXmY">Million Veteran Program: a mega-biobank to study genetic influences on health and disease</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Gaziano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YxHqxjT">J. Clin. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="214" to="223" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gaziano, J. M. et al. Million Veteran Program: a mega-biobank to study genetic influences on health and disease. J. Clin. Epidemiol. 70, 214-223 (2016).</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main" xml:id="_Jeyeaeh">Sequencing of 53,831 diverse genomes from the NHLBI TOPMed Program</title>
		<author>
			<persName><forename type="first">D</forename><surname>Taliun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Xd952dK">Nature</title>
		<imprint>
			<biblScope unit="volume">590</biblScope>
			<biblScope unit="page" from="290" to="299" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Taliun, D. et al. Sequencing of 53,831 diverse genomes from the NHLBI TOPMed Program. Nature 590, 290-299 (2021).</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main" xml:id="_hcxAfw6">The &apos; All of Us&apos; Research Program</title>
		<author>
			<orgName type="collaboration">All of Us Research Program Investigators</orgName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_99EjJPZ">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="page" from="668" to="676" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">All of Us Research Program Investigators. et al. The &apos; All of Us&apos; Research Program. N. Engl. J. Med. 381, 668-676 (2019).</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main" xml:id="_mvNsxKQ">Diversity and inclusion for the All of Us research program: a scoping review</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Mapes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Nnp7eKR">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">234962</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mapes, B. M. et al. Diversity and inclusion for the All of Us research program: a scoping review. PLoS ONE 15, e0234962 (2020).</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main" xml:id="_jxNY8YT">Geographic distribution of US cohorts used to train deep learning algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaushal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Langlotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2Gyd8C3">JAMA</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="1212" to="1213" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kaushal, A., Altman, R. &amp; Langlotz, C. Geographic distribution of US cohorts used to train deep learning algorithms. JAMA 324, 1212-1213 (2020).</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main" xml:id="_v7Maf2U">The Project Baseline Health Study: a step towards a broader mission to map human health</title>
		<author>
			<persName><forename type="first">K</forename><surname>Arges</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-020-0290-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mckSEDk">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">84</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Arges, K. et al. The Project Baseline Health Study: a step towards a broader mission to map human health. NPJ Digit. Med. 3, 84 (2020).</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main" xml:id="_CaGg8dy">American Gut: an open platform for citizen science microbiome research</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7npa6xh">mSystems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="31" to="49" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McDonald, D. et al. American Gut: an open platform for citizen science microbiome research. mSystems 3, e00031-18 (2018).</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main" xml:id="_xSKVSBB">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E W</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uZuXdqb">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">160035</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson, A. E. W. et al. MIMIC-III, a freely accessible critical care database. Sci. Data 3, 160035 (2016).</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main" xml:id="_EFFrezC">MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E W</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sQWhBV9">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">317</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson, A. E. W. et al. MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports. Sci. Data 6, 317 (2019).</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main" xml:id="_wPJkRp7">Dynamic survival prediction in intensive care units from heterogeneous time series without the need for variable selection or curation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deasy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ercole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4chggXg">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">22129</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Deasy, J., Liò, P. &amp; Ercole, A. Dynamic survival prediction in intensive care units from heterogeneous time series without the need for variable selection or curation. Sci. Rep. 10, 22129 (2020).</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main" xml:id="_9j97uZB">Benchmarking deep learning architectures for predicting readmission to the ICU and describing patients-at-risk</title>
		<author>
			<persName><forename type="first">S</forename><surname>Barbieri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-58053-z</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RxfwBSt">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1111</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barbieri, S. et al. Benchmarking deep learning architectures for predicting readmission to the ICU and describing patients-at-risk. Sci. Rep. 10, 1111 (2020).</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main" xml:id="_Ubf4bae">Multimodal fusion with deep neural networks for leveraging CT imaging and electronic health record: a case-study in pulmonary embolism detection</title>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zamanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hXwEMV5">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">101</biblScope>
			<date type="published" when="2020">2020. 2022</date>
		</imprint>
	</monogr>
	<note>Combining chest X-rays and electronic health record data using machine learning to diagnose acute respiratory failure Sci. Rep.</note>
	<note type="raw_reference">Huang, S.-C., Pareek, A., Zamanian, R., Banerjee, I. &amp; Lungren, M. P. Multimodal fusion with deep neural networks for leveraging CT imaging and electronic health record: a case-study in pulmonary embolism detection. Sci. Rep. 10, 22147 (2020). 100. Jabbour, S., Fouhey, D., Kazerooni, E., Wiens, J. &amp; Sjoding, M. W. Combining chest X-rays and electronic health record data using machine learning to diagnose acute respiratory failure. J. Am. Med. Inform. Assoc. 29, 1060-1068 (2022). 101</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main" xml:id="_PxBUvgs">Wearable device signals and home blood pressure data across age, sex, race, ethnicity, and clinical phenotypes in the Michigan Predictive Activity &amp; Clinical Trajectories in Health (MIPACT) study: a prospective, communitybased observational study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Golbus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Pescatore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Nallamothu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kheterpal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_P8CvfeV">Lancet Digit. Health</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">102</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Golbus, J. R., Pescatore, N. A., Nallamothu, B. K., Shah, N. &amp; Kheterpal, S. Wearable device signals and home blood pressure data across age, sex, race, ethnicity, and clinical phenotypes in the Michigan Predictive Activity &amp; Clinical Trajectories in Health (MIPACT) study: a prospective, community- based observational study. Lancet Digit. Health 3, e707-e715 (2021). 102</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main" xml:id="_rGujxce">North American Prodrome Longitudinal Study (NAPLS 2): overview and recruitment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Addington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cUQXV4g">Schizophr. Res</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page">103</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Addington, J. et al. North American Prodrome Longitudinal Study (NAPLS 2): overview and recruitment. Schizophr. Res. 142, 77-82 (2012). 103</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main" xml:id="_egVNEzs">Towards a psychosis risk blood diagnostic for persons experiencing high-risk symptoms: preliminary results from the NAPLS project</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">O</forename><surname>Perkins</surname></persName>
		</author>
		<idno type="DOI">10.1093/schbul/sbu099</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cTTJyva">Schizophr. Bull</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">104</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Perkins, D. O. et al. Towards a psychosis risk blood diagnostic for persons experiencing high-risk symptoms: preliminary results from the NAPLS project. Schizophr. Bull. 41, 419-428 (2015). 104</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main" xml:id="_n9cgpwh">Multimodal machine learning workflows for prediction of psychosis in patients with clinical high-risk syndromes and recent-onset depression</title>
		<author>
			<persName><forename type="first">N</forename><surname>Koutsouleris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jcaJXpy">JAMA Psychiatry</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Koutsouleris, N. et al. Multimodal machine learning workflows for prediction of psychosis in patients with clinical high-risk syndromes and recent-onset depression. JAMA Psychiatry 78, 195-209 (2021). 105</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main" xml:id="_fnD5Grf">Multimodal machine learning: a survey and taxonomy</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baltrusaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<idno type="DOI">10.1109/tpami.2018.2798607</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XFpxUS7">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Baltrusaitis, T., Ahuja, C. &amp; Morency, L.-P. Multimodal machine learning: a survey and taxonomy. IEEE Trans. Pattern Anal. Mach. Intell. 41, 423-443 (2019). 106</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main" xml:id="_5WKhYa6">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_8GVd48z">Proc. 38th International Conference on Machine Learning</title>
		<meeting>38th International Conference on Machine Learning</meeting>
		<imprint/>
	</monogr>
	<note type="raw_reference">Radford, A. et al. Learning transferable visual models from natural language supervision. In Proc. 38th International Conference on Machine Learning (eds.</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3aNn7Uv">PMLR</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page">107</biblScope>
			<date type="published" when="2021-07-24">18-24 July 2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meila, M. &amp; Zhang, T.) vol. 139, 8748-8763 (PMLR, 18-24 July 2021). 107</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main" xml:id="_JKN7Qt6">Contrastive learning of medical visual representations from paired images and text</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Langlotz</surname></persName>
		</author>
		<ptr target=").108" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Zhang, Y., Jiang, H., Miura, Y., Manning, C. D. &amp; Langlotz, C. P. Contrastive learning of medical visual representations from paired images and text. Preprint at https://arxiv.org/abs/2010.00747 (2020). 108</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main" xml:id="_UQvqkMR">Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports</title>
		<author>
			<persName><forename type="first">H. -Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-021-00425-9</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6EnxNzF">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">109</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhou, H. -Y. et al. Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports. Nat. Mach. Intell. 4, 32-40 (2022). 109</note>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main" xml:id="_aBs4e4b">VATT: transformers for multimodal self-supervised learning from raw video, audio and text</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akbari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_6AAcEZF">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="24206" to="24221" />
		</imprint>
	</monogr>
	<note type="raw_reference">Akbari, H. et al. VATT: transformers for multimodal self-supervised learning from raw video, audio and text. In Advances in Neural Information Processing Systems (eds. Ranzato, M. et al.) vol. 34, 24206-24221 (</note>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<ptr target=").111" />
		<title level="m" xml:id="_qC5mnuK">VLMo: unified vision-language pre-training with mixture-of-modality-experts</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Bao, H. et al. VLMo: unified vision-language pre-training with mixture-of-modality-experts. Preprint at https://arxiv.org/abs/2111.02358 (2022). 111</note>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/" />
		<title level="m" xml:id="_ZfnM5Fn">Introducing Pathways: a next-generation AI architecture</title>
		<imprint>
			<date type="published" when="2021-11-10">10 November 2021</date>
			<biblScope unit="page">112</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Dean, J. Introducing Pathways: a next-generation AI architecture https:// blog.google/technology/ai/introducing-pathways-next-generation- ai-architecture/ (10 November 2021). 112</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main" xml:id="_3PNv4mX">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_MyM6xZC">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">113</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Vaswani, A. et al. Attention is all you need. In Advances in Neural Information Processing Systems (eds. Guyon, I. et al.) vol. 30 (Curran Associates, Inc., 2017). 113</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main" xml:id="_gCncYaF">An image is worth 16x16 words: transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_W5gJqtQ">International Conference on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">114</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Dosovitskiy, A. et al. An image is worth 16x16 words: transformers for image recognition at scale. In International Conference on Learning Representations (ICLR, 2021). 114</note>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main" xml:id="_rMGbuJP">Object-semantics aligned pre-training for vision-language tasks</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2004.06165</idno>
		<ptr target=").115" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Li et al. Oscar: Object-semantics aligned pre-training for vision-language tasks. Preprint at https://doi.org/10.48550/arXiv.2004.06165 (2020). 115</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main" xml:id="_XkTFVuz">data2vec: a general framework for self-supervised learning in speech, vision and language</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2202.03555(2022).116" />
		<imprint/>
	</monogr>
	<note type="raw_reference">Baevski, A. et al. data2vec: a general framework for self-supervised learning in speech, vision and language. Preprint at https://arxiv.org/abs/2202.03555 (2022). 116</note>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main" xml:id="_cagvwaf">DABS: a Domain-Agnostic Benchmark for Self-Supervised Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tamkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_VWdakbq">35th Conf.Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">117</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Tamkin, A. et al. DABS: a Domain-Agnostic Benchmark for Self-Supervised Learning. In 35th Conf.Neural Information Processing Systems Datasets and Benchmarks Track (2021). 117</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main" xml:id="_AExbzr9">Perceiver: general perception with iterative attention</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaegle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_wFeQZZy">Proc. 38th International Conference on Machine Learning</title>
		<meeting>38th International Conference on Machine Learning</meeting>
		<imprint/>
	</monogr>
	<note type="raw_reference">Jaegle, A. et al. Perceiver: general perception with iterative attention. In Proc. 38th International Conference on Machine Learning (eds.</note>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kC6GyQx">PMLR</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page">118</biblScope>
			<date type="published" when="2021-07-24">18-24 July 2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meila, M. &amp; Zhang, T.) vol. 139, 4651-4664 (PMLR, 18-24 July 2021). 118</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main" xml:id="_vBmY5HE">Decoupling the role of data, attention, and losses in multimodal transformers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jaegle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Ar4N6NR">International Conference on Learning Representations</title>
		<title level="s" xml:id="_7SDdvBf">Trans. Assoc. Comput. Linguist.</title>
		<imprint>
			<date type="published" when="2021">2022. 2021</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">120</biblScope>
		</imprint>
	</monogr>
	<note>Perceiver IO: a general architecture for structured inputs &amp; outputs</note>
	<note type="raw_reference">Jaegle, A. et al. Perceiver IO: a general architecture for structured inputs &amp; outputs. In International Conference on Learning Representations (ICLR, 2022). 119. Hendricks, L. A., Mellor, J., Schneider, R., Alayrac, J.-B. &amp; Nematzadeh, A. Decoupling the role of data, attention, and losses in multimodal transformers. Trans. Assoc. Comput. Linguist. 9, 570-585 (2021). 120</note>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title level="m" type="main" xml:id="_H7zNqxd">Pretrained transformers as universal computation engines</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
		<ptr target=").121" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Lu, K., Grover, A., Abbeel, P. &amp; Mordatch, I. Pretrained transformers as universal computation engines. Preprint at https://arxiv.org/abs/2103.05247 (2021). 121</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main" xml:id="_QeJ9ubK">Data augmentation using generative adversarial networks (CycleGAN) to improve generalizability in CT segmentation tasks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sandfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Pickhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wgPmsDt">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">122</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sandfort, V., Yan, K., Pickhardt, P. J. &amp; Summers, R. M. Data augmentation using generative adversarial networks (CycleGAN) to improve generalizability in CT segmentation tasks. Sci. Rep. 9, 16884 (2019). 122</note>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main" xml:id="_5YhVk5w">Advancing COVID-19 diagnosis with privacy-preserving collaboration in artificial intelligence</title>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_59CQUmg">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">123</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bai, X. et al. Advancing COVID-19 diagnosis with privacy-preserving collaboration in artificial intelligence. Nat. Mach. Intell. 3, 1081-1089 (2021). 123</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main" xml:id="_QMMvNVe">Digital medicine and the curse of dimensionality</title>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_N9pgeGC">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">124</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Berisha, V. et al. Digital medicine and the curse of dimensionality. NPJ Digit. Med. 4, 153 (2021). 124</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main" xml:id="_PSVJMpp">Retrieval augmented language model pre-training</title>
		<author>
			<persName><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_h9fX2ET">Proc. 37th International Conference on Machine Learning</title>
		<meeting>37th International Conference on Machine Learning</meeting>
		<imprint/>
	</monogr>
	<note type="raw_reference">Guu, K., Lee, K., Tung, Z., Pasupat, P. &amp; Chang, M. Retrieval augmented language model pre-training. In Proc. 37th International Conference on Machine Learning (eds.</note>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tyPuKGG">PMLR</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2020-07-18">13-18 July 2020</date>
		</imprint>
	</monogr>
	<note>A.</note>
	<note type="raw_reference">Iii, H. D. &amp; Singh, A.) vol. 119, 3929-3938 (PMLR, 13-18 July 2020). 125</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main" xml:id="_kpjRQEa">Improving language models by retrieving from trillions of tokens</title>
		<author>
			<persName><forename type="first">S</forename><surname>Borgeaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Hv2AA8M">Proc. 39th International Conference on Machine Learning</title>
		<meeting>39th International Conference on Machine Learning</meeting>
		<imprint/>
	</monogr>
	<note type="raw_reference">Borgeaud, S. et al. Improving language models by retrieving from trillions of tokens. In Proc. 39th International Conference on Machine Learning (eds.</note>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cd2MsrD">PMLR</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page">126</biblScope>
			<date type="published" when="2022-07-23">17-23 July 2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chaudhuri, K. et al.) vol. 162, 2206-2240 (PMLR, 17-23 July 2022). 126</note>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main" xml:id="_PaWcFDj">Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines</title>
		<author>
			<persName><forename type="first">S. -C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seyyedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6mNPhHW">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">127</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Huang, S. -C., Pareek, A., Seyyedi, S., Banerjee, I. &amp; Lungren, M. P. Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines. NPJ Digit. Med. 3, 136 (2020). 127</note>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main" xml:id="_3ARqF9A">A comprehensive survey on multimodal medical signals fusion for smart healthcare systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Muhammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_m5t2wsK">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">128</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Muhammad, G. et al. A comprehensive survey on multimodal medical signals fusion for smart healthcare systems. Inf. Fusion 76, 355-375 (2021). 128</note>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main" xml:id="_Pux6bxH">ShortFuse: Biomedical time series representations in the presence of structured information</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fiterau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_u6zEKNv">Proc. 2nd Machine Learning for Healthcare Conference</title>
		<meeting>2nd Machine Learning for Healthcare Conference</meeting>
		<imprint/>
	</monogr>
	<note type="raw_reference">Fiterau, M. et al. ShortFuse: Biomedical time series representations in the presence of structured information. In Proc. 2nd Machine Learning for Healthcare Conference (eds.</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4ReBWbx">PMLR</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">129</biblScope>
			<date type="published" when="2017-08-19">18-19 August 2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Doshi-Velez, F. et al.) vol. 68, 59-74 (PMLR, 18-19 August 2017). 129</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main" xml:id="_n3nVfE7">A clinically applicable approach to continuous prediction of future acute kidney injury</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tomašev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CvXzbDS">Nature</title>
		<imprint>
			<biblScope unit="volume">572</biblScope>
			<biblScope unit="page">130</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tomašev, N. et al. A clinically applicable approach to continuous prediction of future acute kidney injury. Nature 572, 116-119 (2019). 130</note>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main" xml:id="_kXacvQb">CheXaid: deep learning assistance for physician diagnosis of tuberculosis using chest X-rays in patients with HIV</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fQZygnQ">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">131</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajpurkar, P. et al. CheXaid: deep learning assistance for physician diagnosis of tuberculosis using chest X-rays in patients with HIV. NPJ Digit. Med. 3, 115 (2020). 131</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main" xml:id="_TXgPq8p">Policy-driven, multimodal deep learning for predicting visual fields from the optic disc and optical coherence tomography imaging</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kihara</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ophtha.2022.02.017</idno>
		<ptr target="https://doi.org/10.1016/j.ophtha.2022.02.017" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_tpJPGfz">Ophthalmology</title>
		<imprint>
			<biblScope unit="page">132</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kihara, Y. et al. Policy-driven, multimodal deep learning for predicting visual fields from the optic disc and optical coherence tomography imaging. Ophthalmology https://doi.org/10.1016/j.ophtha. 2022.02.017 (2022). 132</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main" xml:id="_yypdDUe">Zero-shot text-to-image generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_RYsfsSG">Proc. 38th International Conference on Machine Learning</title>
		<meeting>38th International Conference on Machine Learning</meeting>
		<imprint/>
	</monogr>
	<note type="raw_reference">Ramesh, A. et al. Zero-shot text-to-image generation. In Proc. 38th International Conference on Machine Learning (eds.</note>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_k22zjqm">PMLR</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page">133</biblScope>
			<date type="published" when="2021-07-24">18-24 July 2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meila, M. &amp; Zhang, T.) vol. 139, 8821-8831 (PMLR, 18-24 July 2021). 133</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main" xml:id="_GT3JU9x">GLIDE: towards photorealistic image generation and editing with text-guided diffusion models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>Nichol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_yNfBPHX">Proc. 39th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<meeting>39th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2022-07-23">17-23 July 2022</date>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page">134</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Nichol, A. Q. et al. GLIDE: towards photorealistic image generation and editing with text-guided diffusion models. In Proc. 39th International Conference on Machine Learning (eds. Chaudhuri, K. et al.) vol. 162, 16784-16804 (PMLR, 17-23 July 2022). 134</note>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<ptr target=").135" />
		<title level="m" xml:id="_yzwHJrU">A generalist agent</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Reed, S. et al. A generalist agent. Preprint at https://arxiv.org/abs/2205. 06175 (2022). 135</note>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main" xml:id="_An96ws5">Align before fuse: vision and language representation learning with momentum distillation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<ptr target=").136" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Li, J. et al. Align before fuse: vision and language representation learning with momentum distillation. Preprint at https://arxiv.org/abs/2107.07651 (2021). 136</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main" xml:id="_YYHB9rH">Attention bottlenecks for multimodal fusion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nagrani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_5SBDmSn">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="14200" to="14213" />
		</imprint>
	</monogr>
	<note type="raw_reference">Nagrani, A. et al. Attention bottlenecks for multimodal fusion. In Advances in Neural Information Processing Systems (eds. Ranzato, M. et al.) vol. 34, 14200-14213 (</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main" xml:id="_C4Qmez2">Deep learning evaluation of biomarkers from echocardiogram videos</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MgphGtD">EBioMedicine</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hughes, J. W. et al. Deep learning evaluation of biomarkers from echocardiogram videos. EBioMedicine 73, 103613 (2021). 138</note>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main" xml:id="_fm4XjNp">Deep learning in cancer pathology: a new generation of clinical biomarkers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Echle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XSe54Ku">Br. J. Cancer</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Echle, A. et al. Deep learning in cancer pathology: a new generation of clinical biomarkers. Br. J. Cancer 124, 686-696 (2020). 139</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main" xml:id="_W3GmfU4">Axes of a revolution: challenges and promises of big data in healthcare</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shilo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Segal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uDchKBv">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">140</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shilo, S., Rossman, H. &amp; Segal, E. Axes of a revolution: challenges and promises of big data in healthcare. Nat. Med. 26, 29-38 (2020). 140</note>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main" xml:id="_wsCAECX">Observational Health Data Sciences and Informatics (OHDSI): opportunities for observational researchers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hripcsak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_j9S7QRN">Stud. Health Technol. Inform</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="page">141</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hripcsak, G. et al. Observational Health Data Sciences and Informatics (OHDSI): opportunities for observational researchers. Stud. Health Technol. Inform. 216, 574-578 (2015). 141</note>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main" xml:id="_n7NHV6V">Accuracy of identifying incident stroke cases from linked health care data in UK Biobank</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rannikmäe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CaQSrYD">Neurology</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page">142</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rannikmäe, K. et al. Accuracy of identifying incident stroke cases from linked health care data in UK Biobank. Neurology 95, e697-e707 (2020). 142</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main" xml:id="_nGMggJZ">Automating ischemic stroke subtype classification using machine learning and natural language processing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Naidech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kording</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prabhakaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_azAXbNS">J. Stroke Cerebrovasc. Dis</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">143</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Garg, R., Oh, E., Naidech, A., Kording, K. &amp; Prabhakaran, S. Automating ischemic stroke subtype classification using machine learning and natural language processing. J. Stroke Cerebrovasc. Dis. 28, 2045-2051 (2019). 143</note>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main" xml:id="_Rk3brTy">DSM-5 and RDoC: progress in psychiatry research?</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Casey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xf6aJ4b">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">144</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Casey, B. J. et al. DSM-5 and RDoC: progress in psychiatry research? Nat. Rev. Neurosci. 14, 810-814 (2013). 144</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main" xml:id="_aY7ccxn">The missing diversity in human genetic studies</title>
		<author>
			<persName><forename type="first">G</forename><surname>Sirugo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Tishkoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8fvwDgz">Cell</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sirugo, G., Williams, S. M. &amp; Tishkoff, S. A. The missing diversity in human genetic studies. Cell 177, 26-31 (2019). 145</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main" xml:id="_kFzycHV">Ensuring that biomedical AI benefits diverse populations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schiebinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_N5uDyYd">EBioMedicine</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">146</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zou, J. &amp; Schiebinger, L. Ensuring that biomedical AI benefits diverse populations. EBioMedicine 67, 103358 (2021). 146</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main" xml:id="_D2WsWMj">Estimating the success of re-identifications in incomplete datasets using generative models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hendrickx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y. -A</forename><surname>De Montjoye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tdrykqY">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">147</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rocher, L., Hendrickx, J. M. &amp; de Montjoye, Y. -A. Estimating the success of re-identifications in incomplete datasets using generative models. Nat. Commun. 10, 3069 (2019). 147</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main" xml:id="_46pZRcG">Assessing missing data assumptions in EHR-based studies: a complex and underappreciated task</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haneuse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arterburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Daniels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_S4n5dKD">JAMA Netw. Open</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">148</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Haneuse, S., Arterburn, D. &amp; Daniels, M. J. Assessing missing data assumptions in EHR-based studies: a complex and underappreciated task. JAMA Netw. Open 4, e210184-e210184 (2021). 148</note>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main" xml:id="_MsfyxVZ">Approaches to addressing missing values, measurement error, and confounding in epidemiologic studies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Smeden</surname></persName>
			<affiliation>
				<orgName type="collaboration">Genomes Project Consortium</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B L</forename><surname>Penning De Vries</surname></persName>
			<affiliation>
				<orgName type="collaboration">Genomes Project Consortium</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nab</surname></persName>
			<affiliation>
				<orgName type="collaboration">Genomes Project Consortium</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H H</forename><surname>Groenwold</surname></persName>
			<affiliation>
				<orgName type="collaboration">Genomes Project Consortium</orgName>
			</affiliation>
		</author>
		<idno>149. 1000</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wwYsT4S">J. Clin. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page">151</biblScope>
			<date type="published" when="2015">2021. 2015. 2015</date>
		</imprint>
		<respStmt>
			<orgName>K Consortium</orgName>
		</respStmt>
	</monogr>
	<note>A global reference for human genetic variation Nature The UK10K project identifies rare variants in health and disease Nature</note>
	<note type="raw_reference">van Smeden, M., Penning de Vries, B. B. L., Nab, L. &amp; Groenwold, R. H. H. Approaches to addressing missing values, measurement error, and confounding in epidemiologic studies. J. Clin. Epidemiol. 131, 89-100 (2021). 149. 1000 Genomes Project Consortium. et al. A global reference for human genetic variation. Nature 526, 68-74 (2015). 150. UK10K Consortium. et al. The UK10K project identifies rare variants in health and disease. Nature 526, 82-90 (2015). 151</note>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main" xml:id="_cAMstUm">A reference panel of 64,976 haplotypes for genotype imputation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FXcEfEp">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page">152</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McCarthy, S. et al. A reference panel of 64,976 haplotypes for genotype imputation. Nat. Genet. 48, 1279-1283 (2016). 152</note>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main" xml:id="_SC2EHej">Imputation of missing values for electronic health record laboratory data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9CA7V2n">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li, J. et al. Imputation of missing values for electronic health record laboratory data. NPJ Digit. Med. 4, 147 (2021). 153</note>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main" xml:id="_pMH86vp">Democratizing EHR analyses with FIDDLE: a flexible data-driven preprocessing pipeline for structured clinical data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CMXPABh">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">154</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tang, S. et al. Democratizing EHR analyses with FIDDLE: a flexible data-driven preprocessing pipeline for structured clinical data. J. Am. Med. Inform. Assoc. 27, 1921-1934 (2020). 154</note>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main" xml:id="_6R7Eggn">Recurrent neural networks for multivariate time series with missing values</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Che</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ETNJStP">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">155</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Che, Z. et al. Recurrent neural networks for multivariate time series with missing values. Sci. Rep. 8, 6085 (2018). 155</note>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main" xml:id="_KSWEzBJ">Mitigating bias in machine learning for medicine</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Vokinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feuerriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Kesselheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kmfKyMT">Commun. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">156</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vokinger, K. N., Feuerriegel, S. &amp; Kesselheim, A. S. Mitigating bias in machine learning for medicine. Commun. Med. 1, 25 (2021). 156</note>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main" xml:id="_Te9SjaZ">Dissecting racial bias in an algorithm used to manage the health of populations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vogeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vVgahmV">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="page">157</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Obermeyer, Z., Powers, B., Vogeli, C. &amp; Mullainathan, S. Dissecting racial bias in an algorithm used to manage the health of populations. Science 366, 447-453 (2019). 157</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main" xml:id="_pMCpBpd">AI recognition of patient race in medical imaging: a modelling study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Gichoya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_n2TqB3R">Lancet Digit Health</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gichoya, J. W. et al. AI recognition of patient race in medical imaging: a modelling study. Lancet Digit Health 4, e406-e414 (2022). 158</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main" xml:id="_KuVABc3">The UK Biobank and selection bias</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Swanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HShTkNY">Lancet</title>
		<imprint>
			<biblScope unit="volume">380</biblScope>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Swanson, J. M. The UK Biobank and selection bias. Lancet 380, 110 (2012). 159</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main" xml:id="_vrtUU6F">Collider bias undermines our understanding of COVID-19 disease risk and severity</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Griffith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PWawAUP">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">160</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Griffith, G. J. et al. Collider bias undermines our understanding of COVID-19 disease risk and severity. Nat. Commun. 11, 5749 (2020). 160</note>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main" xml:id="_KYcEQVu">The influence of selection bias on identifying an association between allergy medication use and SARS-CoV-2 infection</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_r9UncMf">EClinicalMedicine</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">161</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thompson, L. A. et al. The influence of selection bias on identifying an association between allergy medication use and SARS-CoV-2 infection. EClinicalMedicine 37, 100936 (2021). 161</note>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main" xml:id="_7N9Xhss">Comparison of sociodemographic and health-related characteristics of UK biobank participants with those of the general population</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qzJwMcR">Am. J. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page">162</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fry, A. et al. Comparison of sociodemographic and health-related characteristics of UK biobank participants with those of the general population. Am. J. Epidemiol. 186, 1026-1034 (2017). 162</note>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main" xml:id="_mNKp42J">UK Biobank, big data, and the consequences of non-representativeness</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Keyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Westreich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vPNZWVm">Lancet</title>
		<imprint>
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="page">163</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Keyes, K. M. &amp; Westreich, D. UK Biobank, big data, and the consequences of non-representativeness. Lancet 393, 1297 (2019). 163</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main" xml:id="_9SJKWqN">Robust de-anonymization of large sparse datasets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_u6T3AFy">IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page">164</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Narayanan, A. &amp; Shmatikov, V. Robust de-anonymization of large sparse datasets. In IEEE Symposium on Security and Privacy 111-125 (2008). 164</note>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main" xml:id="_FrDjYvW">Ethical and legal challenges of artificial intelligence-driven healthcare</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qVMRNdv">Artif. Intelli. Health</title>
		<imprint>
			<biblScope unit="volume">11326</biblScope>
			<biblScope unit="page">165</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gerke, S., Minssen, T. &amp; Cohen, G. Ethical and legal challenges of artificial intelligence-driven healthcare. Artif. Intelli. Health. 11326, 213-227(2020). 165</note>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main" xml:id="_ZPn5Ngq">Secure, privacy-preserving and federated machine learning in medical imaging</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Kaissis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Makowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Braren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TtZ35xV">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kaissis, G. A., Makowski, M. R., Rückert, D. &amp; Braren, R. F. Secure, privacy-preserving and federated machine learning in medical imaging. Nat. Mach. Intell. 2, 305-311 (2020). 166</note>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main" xml:id="_Au7JDba">The future of digital health with federated learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rieke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6qWGqgB">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">167</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rieke, N. et al. The future of digital health with federated learning. NPJ Digit. Med. 3, 119 (2020). 167</note>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main" xml:id="_U2BzhzE">Medical imaging deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ziller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pbSaaCB">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">168</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ziller, A. et al. Medical imaging deep learning with differential privacy. Sci. Rep. 11, 13524 (2021). 168</note>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main" xml:id="_PEWKk9M">Federated learning for predicting clinical outcomes in patients with COVID-19</title>
		<author>
			<persName><forename type="first">I</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QfKxKZe">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">169</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dayan, I. et al. Federated learning for predicting clinical outcomes in patients with COVID-19. Nat. Med. 27, 1735-1743 (2021). 169</note>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main" xml:id="_rKK2bMb">Homomorphic encryption for machine learning in medicine and bioinformatics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Najarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kahrobaei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xcr8XGs">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wood, A., Najarian, K. &amp; Kahrobaei, D. Homomorphic encryption for machine learning in medicine and bioinformatics. ACM Comput. Surv. 53, 1-35 (2020). 170</note>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main" xml:id="_FPBpAM9">Swarm learning for decentralized and confidential clinical machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Warnat-Herresthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HauRdaU">Nature</title>
		<imprint>
			<biblScope unit="volume">594</biblScope>
			<biblScope unit="page">171</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Warnat-Herresthal, S. et al. Swarm learning for decentralized and confidential clinical machine learning. Nature 594, 265-270 (2021). 171</note>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main" xml:id="_xtecczY">Edge intelligence: paving the last mile of artificial intelligence with edge computing</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wN4DXxK">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page">172</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhou, Z. et al. Edge intelligence: paving the last mile of artificial intelligence with edge computing. Proc. IEEE 107, 1738-1762 (2019). 172</note>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<ptr target="https://www.intel.com/content/www/us/en/healthcare-it/edge-analytics.html" />
		<title level="m" xml:id="_qqsND76">Intel. How edge computing is driving advancements in healthcare analytics</title>
		<imprint>
			<date type="published" when="2022-03">March 2022</date>
			<biblScope unit="page">173</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Intel. How edge computing is driving advancements in healthcare analytics; https://www.intel.com/content/www/us/en/healthcare-it/edge-analytics.html (11 March 2022.) 173</note>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main" xml:id="_wyYU7FZ">How should we think about clinical data ownership?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ballantyne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3yVZu7S">J. Med. Ethics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page">174</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ballantyne, A. How should we think about clinical data ownership? J. Med. Ethics 46, 289-294 (2020). 174</note>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main" xml:id="_3p3wzwu">Patient data ownership: who owns your health?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Liddell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lucassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uDfcuPq">J. Law Biosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">175</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liddell, K., Simon, D. A. &amp; Lucassen, A. Patient data ownership: who owns your health? J. Law Biosci. 8, lsab023 (2021). 175</note>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main" xml:id="_C4a9CpD">Data authorship as an incentive to data sharing</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Bierer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Pierce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Ag65K9R">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="page">176</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bierer, B. E., Crosas, M. &amp; Pierce, H. H. Data authorship as an incentive to data sharing. N. Engl. J. Med. 376, 1684-1687 (2017). 176</note>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main" xml:id="_8vDTzUw">Revolutionizing medical data sharing using advanced privacy-enhancing technologies: technical, legal, and ethical synthesis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Scheibner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vYtrNdm">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">177</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Scheibner, J. et al. Revolutionizing medical data sharing using advanced privacy-enhancing technologies: technical, legal, and ethical synthesis. J. Med. Internet Res. 23, e25120 (2021). 177</note>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main" xml:id="_JaBYUF8">Applications of machine learning in drug discovery and development</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vamathevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3Szsy9z">Nat. Rev. Drug Discov</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="463" to="477" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vamathevan, J. et al. Applications of machine learning in drug discovery and development. Nat. Rev. Drug Discov. 18, 463-477 (2019).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
