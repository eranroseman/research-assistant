<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_4YHykct">ChatGPT as a Tool for Medical Education and Clinical Decision-Making on the Wards: Case Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>MD</roleName><forename type="first">Anthony</forename><surname>Skryd</surname></persName>
							<email>anthony.skryd@nyulangone.org</email>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Medicine , NYU Langone Health , New York City , NY , United States</note>
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">NYU Langone Health</orgName>
								<address>
									<settlement>New York City</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MD</roleName><forename type="first">Katharine</forename><surname>Lawrence</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Department of Population Health , NYU Grossman School of Medicine , New York City , NY , United States</note>
								<orgName type="department">Department of Population Health</orgName>
								<orgName type="institution">NYU Grossman School of Medicine</orgName>
								<address>
									<settlement>New York City</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<note type="raw_affiliation">Department of Medicine NYU Langone Health 550 1st Avenue New York City , NY , 10016 United States</note>
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">NYU Langone Health</orgName>
								<address>
									<addrLine>550 1st Avenue New York</addrLine>
									<postCode>10016</postCode>
									<settlement>City</settlement>
									<region>NY</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_8e3QBZd">ChatGPT as a Tool for Medical Education and Clinical Decision-Making on the Wards: Case Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2A287A86A833D0C1C9BA55D46FC07621</idno>
					<idno type="DOI">10.2196/51346</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T11:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_vRGzMfG">ChatGPT</term>
					<term xml:id="_BFvY2Fd">medical education</term>
					<term xml:id="_VCwRwgq">large language models</term>
					<term xml:id="_qFtnTb7">LLMs</term>
					<term xml:id="_MuknQJW">clinical decision-making</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_kPn6Qdd"><p xml:id="_gSVPFP2"><s xml:id="_C4uQkrv">Background: Large language models (LLMs) are computational artificial intelligence systems with advanced natural language processing capabilities that have recently been popularized among health care students and educators due to their ability to provide real-time access to a vast amount of medical knowledge.</s><s xml:id="_qgrh5AX">The adoption of LLM technology into medical education and training has varied, and little empirical evidence exists to support its use in clinical teaching environments.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XMpE7We">Objective:</head><p xml:id="_hzkN8fz"><s xml:id="_dknbG2G">The aim of the study is to identify and qualitatively evaluate potential use cases and limitations of LLM technology for real-time ward-based educational contexts.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_QaCYHC2">Methods:</head><p xml:id="_vzpWaGF"><s xml:id="_fsJ2RmS">A brief, single-site exploratory evaluation of the publicly available ChatGPT-3.5 (OpenAI) was conducted by implementing the tool into the daily attending rounds of a general internal medicine inpatient service at a large urban academic medical center.</s><s xml:id="_b4qbVHR">ChatGPT was integrated into rounds via both structured and organic use, using the web-based "chatbot" style interface to interact with the LLM through conversational free-text and discrete queries.</s><s xml:id="_KwQKU4P">A qualitative approach using phenomenological inquiry was used to identify key insights related to the use of ChatGPT through analysis of ChatGPT conversation logs and associated shorthand notes from the clinical sessions.</s></p><p xml:id="_4SNqYQV"><s xml:id="_NJWapG4">Results: Identified use cases for ChatGPT integration included addressing medical knowledge gaps through discrete medical knowledge inquiries, building differential diagnoses and engaging dual-process thinking, challenging medical axioms, using cognitive aids to support acute care decision-making, and improving complex care management by facilitating conversations with subspecialties.</s><s xml:id="_BgtcvSh">Potential additional uses included engaging in difficult conversations with patients, exploring ethical challenges and general medical ethics teaching, personal continuing medical education resources, developing ward-based teaching tools, supporting and automating clinical documentation, and supporting productivity and task management.</s><s xml:id="_EcpA2D9">LLM biases, misinformation, ethics, and health equity were identified as areas of concern and potential limitations to clinical and training use.</s><s xml:id="_92fBRBZ">A code of conduct on ethical and appropriate use was also developed to guide team usage on the wards.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rPd3cMB">Conclusions:</head><p xml:id="_CK8hmKM"><s xml:id="_E9XRsTK">Overall, ChatGPT offers a novel tool to enhance ward-based learning through rapid information querying, second-order content exploration, and engaged team discussion regarding generated responses.</s><s xml:id="_bs4J6fB">More research is needed to fully understand contexts for educational use, particularly regarding the risks and limitations of the tool in clinical settings and its impacts on trainee development.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_pyJZXNq">Introduction</head><p xml:id="_FwUnWqV"><s xml:id="_7t8V2ZU">Large language models (LLMs) are computational artificial intelligence (AI) systems that are trained on large volumes of content from the internet and other sources to create natural, human-like written communications, images, and other outputs <ref type="bibr" target="#b0">[1]</ref>.</s><s xml:id="_U4tZdCU">Popular general-use commercial LLMs include ChatGPT (OpenAI), Palm (Google), and LLaMA (Meta); health care-specific LLMs also in development but less widely available include Med-PaLM (Google), PMC-LLaMA (Meta), and BioGPT (Microsoft Corp) <ref type="bibr" target="#b1">[2]</ref>.</s><s xml:id="_uwrfdrd">LLMs' advanced natural language processing capabilities provide a unique opportunity to enhance medical education by providing students and educators with interactive, real-time access to and feedback on a vast amount of medical knowledge.</s><s xml:id="_XsWr5tQ">This dialogue can be personalized to the level of the learner and leveraged to answer clinical questions, provide differential diagnoses, generate resources, and facilitate the assimilation of complex medical concepts <ref type="bibr" target="#b2">[3]</ref>.</s><s xml:id="_GHnjGxD">Studies have documented facilities of ChatGPTs and others with standardized examinations, academic abstracts, and clinical documentation <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>.</s><s xml:id="_jRwgaTG">At the same time, general concerns have been raised regarding the practical usability, clinical practice implications, and overall ethics of using LLMs in health care <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>; for medical education, issues of overreliance, plagiarism, misinformation, bias, and inequity are particularly acute <ref type="bibr" target="#b8">[9]</ref>.</s><s xml:id="_3pZn3jG">As a result, the adoption of LLM technology into medical education and training has been varied, and comprehensive guidelines for its systematic application in learning contexts remain underdeveloped.</s></p><p xml:id="_cxbTBPs"><s xml:id="_kJTmQpy">In this case study, we present the use of a publicly available LLM (ChatGPT) as a real-time interactive educational tool for attending teaching rounds on an inpatient resident medicine service at a large urban academic medical center.</s><s xml:id="_8QqFB3n">We identify select ChatGPT use cases and qualitatively evaluate the tool's impact on real-time clinical learning, diagnostic reasoning, and medical decision-making for medical residents and teaching attendings.</s><s xml:id="_DuuZNKu">We further explore the perceived advantages, limitations, and ethical considerations of ChatGPT in real-world clinical and teaching contexts and consider the future implications of generative AI conversational technology as a tool for medical education.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_yf8u9ra">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_6sdbmM2">Context</head><p xml:id="_ytpRkgr"><s xml:id="_YNGVvRd">We conducted a brief, single-site pilot study of the publicly available ChatGPT-3.5 (OpenAI) by implementing the tool in the attending rounds workflow of an inpatient general internal medicine service in a large urban academic medical center in New York.</s></p><p xml:id="_3QqQMym"><s xml:id="_nzq7Bjc">Attending-style rounds were conducted for 1.5-2 hours daily in the mornings over the course of the 7-day rotation, consisting of patient presentations, case reviews, case-based learning, and didactics.</s><s xml:id="_hcsSVys">ChatGPT was integrated into rounds via both structured and organic use, using the web-based "chatbot" style user interface to interact with the LLM through conversational free-text and discrete queries.</s><s xml:id="_5t25yqq">ChatGPT was prompted via a zero-shot approach, without the use of prior training sets, data, or examples.</s></p><p xml:id="_ATZD9wJ"><s xml:id="_WFPVUhR">Before initiating the pilot study, the team established a code of conduct for ChatGPT's use based on a shared understanding of its potential, general risks, and implications for patient care (Textbox 1).</s><s xml:id="_c6qQa3P">This code of conduct guided the tool's use throughout the test period.</s></p><p xml:id="_TKPFPd5"><s xml:id="_EM2a2RC">Over the 7 days of the pilot study, the team established a standardized implementation method and ensured adherence to the code of conduct for use.</s><s xml:id="_WWu95aJ">All relevant ChatGPT outputs were independently verified by team members using validated resources (eg, PubMed, UpToDate, and medical society guidelines).</s><s xml:id="_HzKgTRu">Any paper citations or references provided by ChatGPT were also reviewed.</s><s xml:id="_tmkVAav">As a team, we agree:</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_saDNMr3">•</head><p xml:id="_tr3wTxV"><s xml:id="_XUXercr">Not to use any specific or identifiable patient information in our interactions with ChatGPT.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_5ZhGFtr">•</head><p xml:id="_9Y6P6Sz"><s xml:id="_F4xFDjt">To independently verify and validate any answers ChatGPT produces, and not make medical decisions based on ChatGPT's outputs unless we can confirm their accuracy.</s></p><p xml:id="_gXTNmqK"><s xml:id="_Qu3XpHY">• To be honest with our patients and one another when we use ChatGPT in our clinical work.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_FuExKyd">•</head><p xml:id="_rfZMt3h"><s xml:id="_jz8xvCE">To be open to the possibility that ChatGPT is more intelligent than we are.</s></p><p xml:id="_aaNxwzA"><s xml:id="_NteBEkJ">Overall, we commit to placing patient care, safety, and trust above any educational or research use of this technology.</s><s xml:id="_Dq7yuyJ">We further commit to abiding by our institution's information technology policies and practices.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_3WCuFsh">Analysis</head><p xml:id="_6TJDSMk"><s xml:id="_7VvaH2R">A qualitative approach using phenomenological inquiry was used to identify key insights related to the use of ChatGPT for real-time ward-based educational contexts.</s><s xml:id="_XTkAUmC">Analysis was conducted in two phases: <ref type="bibr" target="#b0">(1)</ref> an in situ review and validation of the ChatGPT outputs by the clinical team and (2) a retrospective rapid qualitative analysis using phenomenological inquiry performed by the coauthors (AS and KL) <ref type="bibr" target="#b9">[10]</ref>.</s><s xml:id="_G6pSn24">In phase 1, ChatGPT conversation logs and outputs were group-reviewed by the clinical team and qualitatively assessed for factualness, quality, relevance, and usefulness in clinical contexts.</s><s xml:id="_xJ8MHgb">The team also conducted a group debrief at the culmination of the clinical block via a semistructured group interview led by the attending, which explored primary uses, perceptions, and learning from the experience and perceived impacts on medical education.</s><s xml:id="_6MeDB5g">In phase 2, the senior author (KL) used a pragmatic phenomenological approach to concisely review the ChatGPT conversation logs and associated short-hand attending notes from the clinical sessions and identify both emergent major, minor, and outlier themes and themes specifically related to the use of ChatGPT for real-time ward-based educational contexts; these themes were reviewed and revised between both authors (KL and AS) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_bghGSeZ">Ethical Considerations</head><p xml:id="_Favj8YB"><s xml:id="_FE29TdT">This study was approved as part of a quality improvement initiative under the NYU Grossman School of Medicine institutional review board.</s><s xml:id="_xqHdrfr">Study data do not include any personal health information related to any care provision conducted during the course of the investigation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_FJCubXx">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_M48BwYq">Overview</head><p xml:id="_A7CQm24"><s xml:id="_4avQB4N">The team was comprised of 7 members: 1 attending internal medicine physician, 1 senior medicine resident, 2 interns, 2 medical students, and 1 physician assistant student.</s><s xml:id="_qQtwnNh">All team members expressed baseline familiarity with ChatGPT, with most knowledge derived from social and general media information, particularly around controversies in its use.</s><s xml:id="_rdUKgDh">No team member had received formal ChatGPT training or guidance on its use from their educational program or was actively using the technology in their clinical work.</s><s xml:id="_mwrXf2d">No team member had prior experience with prompt engineering, specific coding, or data management skills to interact with the tool at a more advanced level.</s></p><p xml:id="_QTP7Sas"><s xml:id="_CjkmEku">Over the course of the 7-day pilot study, ChatGPT was queried 17 times, representing a combination of single-question queries and longer bidirectional interchanges.</s><s xml:id="_JU9teXT">ChatGPT prompts were generated by all members of the team.</s><s xml:id="_RadVUMV">The types of ChatGPT use during attending rounds were identified (Textbox 2).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_CCP4fRJ">Discrete Medical Knowledge Inquiries</head><p xml:id="_bYYG99x"><s xml:id="_zZEdE5u">Attending rounds generated numerous discrete medical knowledge questions, often based on the knowledge gaps of team members or inquiries from specific patient cases.</s><s xml:id="_Ykyazx2">During this pilot, ChatGPT was substituted for other frequently used web-based resources (eg, UpToDate) to answer many discrete medical inquiries; this represented a combination of first-order (factual information seeking) and second-order (process and reasoning seeking) questions (Textbox 2 and Figures <ref type="figure" target="#fig_0">S1-S3</ref> in Multimedia Appendix 1), with first-order questions frequently leading to additional second-order queries.</s><s xml:id="_pJndXsz">In general, using ChatGPT for discrete knowledge inquiries often led to further questions and additional prompting, in turn generating team discussion and knowledge sharing.</s><s xml:id="_RAfDxJh">This process was identified by both the attending and the junior team members as an effective way to gain additional knowledge regarding a topic of interest without considerable extra time or effort.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Sxbg5wb">Building Differential Diagnoses and Engaging Dual-Process Thinking</head><p xml:id="_qGr3Pwf"><s xml:id="_6auRJvv">Crafting a comprehensive differential diagnosis is essential to clinical reasoning in patient evaluation <ref type="bibr" target="#b11">[12]</ref>.</s><s xml:id="_6vmSF8B">A well-known method to engage complex reasoning is the dual-process approach <ref type="bibr" target="#b12">[13]</ref>, whereby system 1 reflexive, intuitive thinking is complemented by system 2 rational and more cognitively intensive analytic thought <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>.</s><s xml:id="_p9Gfkvs">During the pilot study, ChatGPT was regularly queried to provide differential diagnoses for general patient presentations, with additional prompting to provide expanded differentials, including uncommon diagnoses.</s><s xml:id="_kWmm9Ba">The team reviewed these differentials and discussed their plausibility, likelihood in the case context, and completeness compared to the team-generated differentials.</s><s xml:id="_RteDJFR">In most instances, the differentials provided by ChatGPT mirrored those of the medical team; in some cases, differentials collaboratively produced by team members were more expansive and included likely diagnoses not provided by ChatGPT (Figure <ref type="figure">S4</ref> in Multimedia Appendix 1), while in fewer instances, ChatGPT provided novel diagnoses that prompted additional queries and resulted in new learning for the team (Figures S5 and S6 in Multimedia Appendix 1).</s><s xml:id="_4S7hR8n">Overall, the team reflected that ChatGPT-generated differentials were considered a helpful supplement to team-generated ones for confirming clinical reasoning and completeness but did not meaningfully change leading diagnoses or care plans.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_bKunBfD">Challenging Medical Axioms</head><p xml:id="_4Nte8w2"><s xml:id="_Ed5ejzS">An axiom is defined as a rule, principle, or truth that is often widely accepted on its merit without proof or basis for further analysis <ref type="bibr" target="#b15">[16]</ref>.</s><s xml:id="_yb8gRhz">In this case, ChatGPT was used to query axiomatic practice on rounds and either justify or challenge them (Figures S7-S9 in Multimedia Appendix 1).</s><s xml:id="_QptTQjk">Common practice habits (eg, timing of medication doses) or practices used widely across patients (eg, electrolyte repletion) were queried most often-generally in response to a team member's question (Why do we do this?)-resulting in deeper knowledge for the team regarding their daily work.</s><s xml:id="_EJAReSh">The use of ChatGPT to confirm or challenge medical axioms generated a thoughtful discussion among the team members regarding the basis of medical knowledge and the transmission of learning in medical education.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_6ME3RZ8">Cognitive Aids in Acute Care Scenarios</head><p xml:id="_kFdb7AT"><s xml:id="_Vmx6eSq">Acute care scenarios and medical emergencies are stressful, complex events that require rapid response and coordination of care that is often time-critical.</s><s xml:id="_eKzTRt3">The use of cognitive aids and checklists has been widely studied and proven effective in optimizing care and reducing errors in emergency response scenarios <ref type="bibr" target="#b16">[17]</ref>.</s><s xml:id="_7aAGMmN">During the pilot study, ChatGPT was deployed as part of a rapid response team (RRT) debrief, in which the tool was used after the team had performed an RRT to replicate and review the clinical scenario (Figures S10 and S11 in Multimedia Appendix 1).</s><s xml:id="_yCT5ENn">On review, the overall structure of ChatGPT's RRT management response (eg, initial scene assessment and triage process) was considered poorly organized and insufficiently specific to guide real-time RRT management.</s><s xml:id="_mXx5qhK">Conversely, outputs did include thorough reasoning for recommended RRT procedures (eg, laboratory testing and imaging), which the team perceived as helpful to recall during high-stress scenarios (Figure <ref type="figure" target="#fig_0">S11</ref> in Multimedia Appendix 1).</s><s xml:id="_AyJpsHH">Overall, the team felt the level of prompting and interaction required to get appropriate and well-structured information to guide an RRT was overly burdensome and inefficient compared to existing processes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ccrxef3">Facilitating Conversations With Subspecialties</head><p xml:id="_Uye7Hgs"><s xml:id="_WqkSnjg">Another use for ChatGPT was identified during a complex patient case involving multiple specialties and ongoing goals of care conversation.</s><s xml:id="_vSHk7EQ">During rounds, the team expressed concern regarding their ability to effectively care for the patient and their communications with specialists as a result.</s><s xml:id="_Q8C6RAN">In response,</s></p><p xml:id="_hmnJVsN"><s xml:id="_49QwjXZ">ChatGPT was queried regarding specific best practice guidelines for medical versus surgical management of the condition (Figures S12 and S13 in Multimedia Appendix 1).</s><s xml:id="_YsvFcpm">Outputs provided by ChatGPT were supplemented with web-based inquiry to validate the content and identify the most up-to-date information; through this combined internet and ChatGPT process, a previously unknown set of guidelines (Figure <ref type="figure" target="#fig_0">S14</ref> in Multimedia Appendix 1) <ref type="bibr" target="#b17">[18]</ref> were identified, which provided the team with specialty-specific references to guide further high-level conversations with consultants.</s><s xml:id="_hH9hwND">Overall, the team felt that ChatGPT had given them a better understanding of management options, which empowered them to advocate for their patient and work collaboratively with specialists on the case.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_G4ZMMqa">Other Topics</head><p xml:id="_gEeWNx4"><s xml:id="_Pfw95FR">Upon completing the 7-day pilot study, the team met to debrief on the experience and identify additional potential use cases.</s><s xml:id="_ZdmgpAN">These included engaging in difficult conversations with patients, exploring ethical challenges and general medical ethics teaching, personal continuing medical education resources, developing teaching tools (eg, "teaching on the wards" aids), supporting and automating clinical documentation, and supporting productivity and task management.</s><s xml:id="_kXBcUrB">Of note, when prompted throughout the investigation to cite specific references, ChatGPT provided outputs but noted it could not cite the specific location of the information provided; further review of the citations by the team revealed none referred to actual papers.</s><s xml:id="_As5FhfD">Reference provisions were therefore considered unreliable use case by the team.</s><s xml:id="_XkGvx9E">The team also discussed ongoing ethical issues in ChatGPT uses for health care, including its well-documented biases and potential to result in health inequities, medico-legal implications, data privacy and security, and potential nefarious uses.</s><s xml:id="_qgU5Kka">This discussion resulted in a prompt inquiry to ChatGPT on the future of medical education as generative AI technologies advance (Figure <ref type="figure" target="#fig_0">S15</ref> in Multimedia Appendix 1).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_w9C5sUz">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jdu88mD">Principal Findings</head><p xml:id="_VZ5grT8"><s xml:id="_J5mQvtr">This exploratory case study examined various use cases of the commercially available LLM, ChatGPT, as an educational tool for attending teaching rounds of an inpatient resident medicine service at a large urban academic medical center.</s><s xml:id="_NCk9TVZ">We identified several key areas for which ChatGPT was used, including addressing team or individual knowledge gaps and validating funds of knowledge through discrete medical knowledge inquiries; expanding differential diagnoses and engaging dual systems process thinking to validate and expand clinical reasoning; challenging axioms through active investigation of default medical knowledge and practice heuristics; supporting triage, diagnostic, and care decision-making during acute care emergencies; and facilitating patient advocacy and complex care management through improved specialty consultations.</s><s xml:id="_ceY8Kr6">Other topics not directly explored but identified as potential use cases included challenging patient scenarios and conflicts, medical ethics inquiries, general continuing medical education, and team productivity and efficiency.</s><s xml:id="_2x87qnZ">Overall, the tool was considered a promising addition to the learning environment, while it was also noted to be limited in accuracy, reliability, and usability in its current state.</s><s xml:id="_THzym6u">In particular, using ChatGPT as a real-time educational aid during attending rounds enhanced team learning by fostering a discussion of responses and generating further areas of exploration and inquiry.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_RwcqCds">Contributions to the Literature and Limitations</head><p xml:id="_UghvrkH"><s xml:id="_QvdRGMF">While exploratory, this case study adds to the rapidly growing literature exploring the various uses and limitations of generative AI technologies, such as LLMs, in medical education.</s><s xml:id="_sXcpWn6">As previously stated, ChatGPT has been successfully tested in a growing number of medical training contexts, including writing medical notes and academic abstracts and completing the United States Medical Licensing Examination (USMLE); a surfeit of opportunities to explore the impact of generative AI tools in medical education has also been identified at the undergraduate, graduate, and professional levels <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>.</s><s xml:id="_bD3324P">Significant work remains, however, to better understand the roles of these technologies in medical education, including both the extent to which these technologies have already been integrated into educational programs (either formally or through casual use) as well as the true appetite for their future use <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>.</s><s xml:id="_FaPMANd">At the same time, there is an ongoing need to better characterize and actively mitigate the risks of these tools' use in care delivery, particularly among developing trainees.</s><s xml:id="_kXMdsA3">This study identified numerous limitations of the technology, many of which have been described elsewhere.</s><s xml:id="_uD83EUN">These included difficulties validating information sources and specific references, inconsistent responses to similar prompts, and incomplete access to major databases and up-to-date material <ref type="bibr" target="#b18">[19]</ref>.</s><s xml:id="_E4PtUyB">Although we were unable to confirm examples of misinformation or bias-such as the generated missing references-that may have occurred during our pilot study, our experience reflects larger grievances with current publicly available LLM tools, in particular around issues of output "trustworthiness" and response fidelity over time <ref type="bibr" target="#b24">[25]</ref>.</s></p><p xml:id="_YVHGNzX"><s xml:id="_jyT2nkq">There is also the potential of ChatGPT and other tools to perpetuate cognitive and sociocultural biases <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>, impacting both trainee development and overall care delivery; processes to better center equity in LLMs and mitigate bias-related AI harms are needed to address this <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>.</s></p><p xml:id="_Wvz4hcQ"><s xml:id="_TFfrF6W">In addition to the larger issues of LLMs identified earlier, this study has several important limitations.</s><s xml:id="_a3b9J6S">Using ChatGPT on a single team over the 7 days of a shared clinical rotation restricted the depth and range of analysis to a small-scale pilot study with a short duration; future investigations should extend this period as well as evaluate the impact off different clinical care teams (eg, nurses and pharmacists) and other team factors.</s><s xml:id="_Bk9d6Zg">Significantly, our team had limited knowledge of prompt engineering and optimization in generating desirable ChatGPT outputs, which likely limited our interaction potential with technology and may have introduced specific interaction biases; conversely, our interactions with the ChatGPT user interface also likely represent an "average" user experience for a health care provider at the time, which will likely evolve as clinicians gain familiarity and skill with the tool.</s><s xml:id="_TTtGNZ2">Future work should emphasize the role of prompt engineering and various other approaches to priming and interacting with LLMs (eg, "zero-shot" vs few-shot learning) <ref type="bibr" target="#b29">[30]</ref>.</s><s xml:id="_ErVxHrz">Additionally, ChatGPT output quality was assessed without the aid of existing validated tools to measure performance or in comparison to other LLMs; there is a need for both general objective measures as well as comparative metrics across products to more rigorously benchmark and compare these tools.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_4JA5UV8">Conclusions</head><p xml:id="_cquC9FN"><s xml:id="_Q2byH6n">This case study explored ChatGPT as an educational tool in an inpatient academic medical service.</s><s xml:id="_kGm9rCB">Several noteworthy use cases of LLM were identified, including addressing knowledge gaps, expanding differential diagnoses, challenging medical axioms, supporting acute care decision-making, and facilitating complex care management through improved specialty consultations.</s><s xml:id="_qmZ6brP">Overall, ChatGPT enhanced team learning by prompting engaged discussion and further areas of exploration and inquiry.</s><s xml:id="_XRQkEa2">LLMs continue to demonstrate promise and peril in health care, with particular opportunities and risks in educational spaces.</s><s xml:id="_kmxtjsz">Concerns related to biases, misinformation, and ethical implications in health care emphasize the need for further consideration and regulatory guidelines for LLM application in medical education and clinical practice.</s><s xml:id="_TCTMNKX">Ultimately, technical progress (or stasis), regulatory oversight, and social appetite will likely decide their future.</s><s xml:id="_sHhWnpH">Researchers should continue to study impacts by identifying further use cases for investigation, conducting meta-analyses on the myriad of case studies currently being conducted, better defining study designs and evaluation tools, and advocating for the safe, ethical, and equitable use of these technologies.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Textbox 1 .</head><label>1</label><figDesc><div><p xml:id="_qYwjXPB"><s xml:id="_eWFxKys">Team-developed code of conduct for ChatGPT use on attending rounds.We acknowledge the potential risks and harms of using technology like ChatGPT in our clinical work and training.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Textbox 2 .•</head><label>2</label><figDesc><div><p xml:id="_AmnDMkj"><s xml:id="_8nhkVGf">ChatGPT use cases and examples identified by the study team during use on the wards.Discrete medical knowledge inquiries•Review of common illnesses • Uncommon diagnoses • Clinical aids and diagnostic calculators • Medication interactions and side effects • Mechanism of action of medications Building differential diagnoses and engaging dual-process thinking • Initial and expanded differential diagnoses Identifying specialty-specific best practices to cite when discussing a complex case with multiple specialties involved • Patient advocacy resources Other topics • Engaging in difficult conversations • Ethical challenges and general medical ethics • Personal continuing medical education resources • Development of teaching tools • Clinical documentation • Productivity and task management support</s></p></div></figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_vkVbT2c"><s xml:id="_gUw7DYj">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_TX64ZzY"><s xml:id="_DcpJ4dE">JMIR Form Res 2024 | vol.</s><s xml:id="_udnH9gd">8 | e51346 | p. 4 https://formative.jmir.org/2024/1/e51346</s><s xml:id="_fzHJu6J">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_BNd7wuh"><s xml:id="_VuvSsjX">(page number not for citation purposes)Skryd &amp; Lawrence JMIR FORMATIVE RESEARCH XSL • FO RenderX</s></p></note>
		</body>
		<back>


			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_nqhJRuD">Acknowledgments</head><p xml:id="_C8Fx2EQ"><s xml:id="_kd8nNYe">The authors received no financial support for writing this paper.</s><s xml:id="_sE25uQE">The authors express their gratitude to the inpatient general internal medicine team, including the medical interns, medical students, and physician assistant students who actively participated in this study.</s><s xml:id="_MQEbnVx">ChatGPT was not used in the creation of the text of this paper.</s></p></div>
			</div>


			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_CMp3QXp">Data Availability</head><p xml:id="_a3agZGm"><s xml:id="_GZFB9HS">The data sets generated and analyzed during this study are available from the corresponding author on reasonable request.</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9sspYJj">Conflicts of Interest</head><p xml:id="_pFn2gQH"><s xml:id="_Ax7P7Tg">None declared.</s><s xml:id="_Uerw8xK">This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ref type="url" target="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ref>),</s><s xml:id="_PED6xnE">which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Formative Research, is properly cited.</s><s xml:id="_zCqbwP9">The complete bibliographic information, a link to the original publication on <ref type="url" target="https://formative.jmir.org">https://formative.jmir.org</ref>,</s><s xml:id="_BapfW3r">as well as this copyright and license information must be included.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_tmwQK58">Multimedia Appendix 1</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_mBFKFp5">Large language models in medicine</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Thirunavukarasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dsj</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Elangovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dsw</forename><surname>Ting</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-023-02448-8</idno>
		<idno>Medline: 37460753</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HCPtrK5">Nat Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1930" to="1940" />
			<date type="published" when="2023-08">Aug 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med. Aug 2023;29(8):1930-1940. [doi: 10.1038/s41591-023-02448-8] [Medline: 37460753]</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_xwKXX8d">Large language models encode clinical knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-023-06291-2</idno>
		<idno>Medline: 37438534</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BuZdjQt">Nature</title>
		<imprint>
			<biblScope unit="volume">620</biblScope>
			<biblScope unit="page" from="172" to="180" />
			<date type="published" when="2023-08">Aug 2023. 7972</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large language models encode clinical knowledge. Nature. Aug 2023;620(7972):172-180. [FREE Full text] [doi: 10.1038/s41586-023-06291-2] [Medline: 37438534]</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_hRwXEDx">The rise of ChatGPT: Exploring its potential in medical education</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1002/ase.2270</idno>
		<idno>Medline: 36916887</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AyqCxhx">Anat Sci Educ</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2023-03-14">Mar 14, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lee H. The rise of ChatGPT: Exploring its potential in medical education. Anat Sci Educ. Mar 14, 2023.:1-5. [doi: 10.1002/ase.2270] [Medline: 36916887]</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_6DrTA72">How does ChatGPT perform on the United States Medical Licensing Examination (USMLE)? The implications of large language models for medical education and knowledge assessment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Safranek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Socrates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><forename type="middle">L</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="DOI">10.2196/45312</idno>
		<idno>Medline: 36753318</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2SQ9hnn">JMIR Med Educ</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">e45312</biblScope>
			<date type="published" when="2023-02-08">Feb 08, 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Gilson A, Safranek CW, Huang T, Socrates V, Chi L, Taylor RA, et al. How does ChatGPT perform on the United States Medical Licensing Examination (USMLE)? The implications of large language models for medical education and knowledge assessment. JMIR Med Educ. Feb 08, 2023;9:e45312. [FREE Full text] [doi: 10.2196/45312] [Medline: 36753318]</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_tcdzQfj">Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheatham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Medenilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sillos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Elepaño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000198</idno>
		<idno>Medline: 36812645</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QePbwT4">PLOS Digit Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">e0000198</biblScope>
			<date type="published" when="2023-02">Feb 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepaño C, et al. Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models. PLOS Digit Health. Feb 2023;2(2):e0000198. [FREE Full text] [doi: 10.1371/journal.pdig.0000198] [Medline: 36812645]</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_Qpt5DPp">Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-023-00819-6</idno>
		<idno>Medline: 37100871</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3a7SWSG">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Gao CA, Howard FM, Markov NS, Dyer EC, Ramesh S, Luo Y, et al. Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers. NPJ Digit Med. 2023;6(1):75. [FREE Full text] [doi: 10.1038/s41746-023-00819-6] [Medline: 37100871]</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_SrAs2Xs">Artificial hallucinations in ChatGPT: implications in scientific writing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Alkaissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Mcfarlane</surname></persName>
		</author>
		<idno type="DOI">10.7759/cureus.35179</idno>
		<idno>Medline: 36811129</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zDZbgQU">Cureus</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">35179</biblScope>
			<date type="published" when="2023-02">Feb 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Alkaissi H, McFarlane SI. Artificial hallucinations in ChatGPT: implications in scientific writing. Cureus. Feb 2023;15(2):e35179. [FREE Full text] [doi: 10.7759/cureus.35179] [Medline: 36811129]</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_vYnyRFk">The future of medical education and research: is ChatGPT a blessing or blight in disguise?</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Arif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Munaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ul-Haque</surname></persName>
		</author>
		<idno type="DOI">10.1080/10872981.2023.2181052</idno>
		<idno>Medline: 36809073</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dpQjvjD">Med Educ Online</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2181052</biblScope>
			<date type="published" when="2023-12">Dec 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Arif TB, Munaf U, Ul-Haque I. The future of medical education and research: is ChatGPT a blessing or blight in disguise? Med Educ Online. Dec 2023;28(1):2181052. [FREE Full text] [doi: 10.1080/10872981.2023.2181052] [Medline: 36809073]</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_ypAtc6V">Large language models in medical education: opportunities, challenges, and future directions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abd-Alrazaq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alsaad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Alhuwail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Latifi</surname></persName>
		</author>
		<idno type="DOI">10.2196/48291</idno>
		<idno>Medline: 37261894</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pNhSZax">JMIR Med Educ</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">e48291</biblScope>
			<date type="published" when="2023-06-01">Jun 01, 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Abd-Alrazaq A, AlSaad R, Alhuwail D, Ahmed A, Healy PM, Latifi S, et al. Large language models in medical education: opportunities, challenges, and future directions. JMIR Med Educ. Jun 01, 2023;9:e48291. [FREE Full text] [doi: 10.2196/48291] [Medline: 37261894]</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_zRYPWwJ">Pragmatic approaches to analyzing qualitative data for implementation science: an introduction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ramanadhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Revette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Aveling</surname></persName>
		</author>
		<idno type="DOI">10.1186/s43058-021-00174-1</idno>
		<idno>Medline: 34187595</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GHDh4CE">Implement Sci Commun</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">70</biblScope>
			<date type="published" when="2021-06-29">Jun 29. 2021</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Ramanadhan S, Revette AC, Lee RM, Aveling EL. Pragmatic approaches to analyzing qualitative data for implementation science: an introduction. Implement Sci Commun. Jun 29, 2021;2(1):70. [FREE Full text] [doi: 10.1186/s43058-021-00174-1] [Medline: 34187595]</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_X7gX2CF">Applied rapid qualitative analysis to develop a contextually appropriate intervention and increase the likelihood of uptake</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Lewinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Bosworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Steinhauser</surname></persName>
		</author>
		<idno type="DOI">10.1097/mlr.0000000000001553</idno>
		<idno>Medline: 33976073</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xTTjZ3w">Med Care</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">Suppl 3</biblScope>
			<biblScope unit="page" from="242" to="S251" />
			<date type="published" when="2021-06-01">Jun 01. 2021</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Lewinski AA, Crowley MJ, Miller C, Bosworth HB, Jackson GL, Steinhauser K, et al. Applied rapid qualitative analysis to develop a contextually appropriate intervention and increase the likelihood of uptake. Med Care. Jun 01, 2021;59(Suppl 3):S242-S251. [FREE Full text] [doi: 10.1097/MLR.0000000000001553] [Medline: 33976073]</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_SHXw5cN">Higher order thinking about differential diagnosis</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Décary</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bjpt.2019.01.010</idno>
		<idno>Medline: 30723033</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YzNDsd7">Braz J Phys Ther</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Cook CE, Décary S. Higher order thinking about differential diagnosis. Braz J Phys Ther. 2020;24(1):1-7. [FREE Full text] [doi: 10.1016/j.bjpt.2019.01.010] [Medline: 30723033]</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<title level="m" xml:id="_6vJZGu2">Thinking, Fast and Slow</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Farrar, Straus and Giroux</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kahneman D. Thinking, Fast and Slow. New York. Farrar, Straus and Giroux; 2011.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_Abt7Qax">Systems 1 and 2 thinking processes and cognitive reflection testing in medical students</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Ryan</surname></persName>
		</author>
		<idno type="DOI">10.36834/cmej.36777</idno>
		<idno>Medline: 28344696</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cR6Qve4">Can Med Educ J. Oct</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="e97" to="e103" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Tay SW, Ryan P, Ryan CA. Systems 1 and 2 thinking processes and cognitive reflection testing in medical students. Can Med Educ J. Oct 2016;7(2):e97-e103. [FREE Full text] [Medline: 28344696]</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main" xml:id="_Y8umYZd">Strategies for generating differential diagnoses</title>
		<idno type="DOI">10.31579/2578-8868/114</idno>
		<ptr target="https://www.umassmed.edu/globalassets/clinical-faculty-development-center/nov-2017-w1t1-materials/10e-differential-dx-strategies---online.pdf" />
		<imprint>
			<date type="published" when="2006">2006. 2024-04-16</date>
		</imprint>
		<respStmt>
			<orgName>Center for Academic Achievement</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Strategies for generating differential diagnoses. Center for Academic Achievement. 2006. URL: https://www.umassmed.edu/ globalassets/clinical-faculty-development-center/nov-2017-w1t1-materials/10e-differential-dx-strategies---online.pdf [accessed 2024-04-16]</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Stedman</surname></persName>
		</author>
		<title level="m" xml:id="_2VETXVm">Stedman&apos;s Medical Dictionary for the Health Professions and Nursing</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>Wolters Kluwer Health/Lippincott Williams &amp; Wilkins</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stedman TL. Stedman&apos;s Medical Dictionary for the Health Professions and Nursing. Philadelphia. Wolters Kluwer Health/Lippincott Williams &amp; Wilkins; 2012.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_hU3uJ3d">Simulation-based randomized trial of medical emergency cognitive aids</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alchab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wetzchewald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rassaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Thal</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13049-022-01028-y</idno>
		<idno>Medline: 35820939</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bEmwXhG">Scand J Trauma Resusc Emerg Med</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">45</biblScope>
			<date type="published" when="2022-07-11">Jul 11. 2022</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Sellmann T, Alchab S, Wetzchewald D, Meyer J, Rassaf T, Thal SC, et al. Simulation-based randomized trial of medical emergency cognitive aids. Scand J Trauma Resusc Emerg Med. Jul 11, 2022;30(1):45. [FREE Full text] [doi: 10.1186/s13049-022-01028-y] [Medline: 35820939]</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_PBRDHrz">Tokyo Guidelines 2018: diagnostic criteria and severity grading of acute cholecystitis (with videos)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yokoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Takada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Strasberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Asbun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wakabayashi</surname></persName>
		</author>
		<idno type="DOI">10.1002/jhbp.515</idno>
		<idno>Medline: 29032636</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YXmsZXu">J Hepatobiliary Pancreat Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="54" />
			<date type="published" when="2018-01">Jan 2018</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Yokoe M, Hata J, Takada T, Strasberg SM, Asbun HJ, Wakabayashi G, et al. Tokyo Guidelines 2018: diagnostic criteria and severity grading of acute cholecystitis (with videos). J Hepatobiliary Pancreat Sci. Jan 2018;25(1):41-54. [FREE Full text] [doi: 10.1002/jhbp.515] [Medline: 29032636]</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_bnNdg8Z">Practical applications of ChatGPT in undergraduate medical education</title>
		<author>
			<persName><forename type="first">R</forename><surname>Tsang</surname></persName>
		</author>
		<idno type="DOI">10.1177/23821205231178449</idno>
		<idno>Medline: 37255525</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HnXMEpr">J Med Educ Curric Dev</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">23821205231178449</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Tsang R. Practical applications of ChatGPT in undergraduate medical education. J Med Educ Curric Dev. 2023;10:23821205231178449. [FREE Full text] [doi: 10.1177/23821205231178449] [Medline: 37255525]</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_GNUGhbj">ChatGPT-reshaping medical education and clinical management</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jawaid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sajjad</surname></persName>
		</author>
		<idno type="DOI">10.12669/pjms.39.2.7653</idno>
		<idno>Medline: 36950398</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Xk7kM82">Pak J Med Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="605" to="607" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Khan RA, Jawaid M, Khan AR, Sajjad M. ChatGPT-reshaping medical education and clinical management. Pak J Med Sci. 2023;39(2):605-607. [FREE Full text] [doi: 10.12669/pjms.39.2.7653] [Medline: 36950398]</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_rqyCedH">ChatGPT for clinical vignette generation, revision, and evaluation</title>
		<author>
			<persName><forename type="first">Jra</forename><surname>Benoit</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.02.04.23285478</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BbXRa9B">medRxiv</title>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Benoit JRA. ChatGPT for clinical vignette generation, revision, and evaluation. medRxiv. [FREE Full text] [doi: 10.1101/2023.02.04.23285478]</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_2s3wSgj">Opportunities, challenges, and future directions of generative artificial intelligence in medical education: scoping review</title>
		<author>
			<persName><forename type="first">C</forename><surname>Preiksaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rose</surname></persName>
		</author>
		<idno type="DOI">10.2196/48785</idno>
		<idno>Medline: 37862079</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_T9GcDxW">JMIR Med Educ</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">e48785</biblScope>
			<date type="published" when="2023-10-20">Oct 20, 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Preiksaitis C, Rose C. Opportunities, challenges, and future directions of generative artificial intelligence in medical education: scoping review. JMIR Med Educ. Oct 20, 2023;9:e48785. [FREE Full text] [doi: 10.2196/48785] [Medline: 37862079]</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_bDjHgxb">Transforming medical education: assessing the integration of ChatGPT into faculty workflows at a Caribbean Medical School</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vaughans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kayalackakom</surname></persName>
		</author>
		<idno type="DOI">10.7759/cureus.41399</idno>
		<idno>Medline: 37426402</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uAuxSWJ">Cureus</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">41399</biblScope>
			<date type="published" when="2023-07">Jul 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Cross J, Robinson R, Devaraju S, Vaughans A, Hood R, Kayalackakom T, et al. Transforming medical education: assessing the integration of ChatGPT into faculty workflows at a Caribbean Medical School. Cureus. Jul 2023;15(7):e41399. [FREE Full text] [doi: 10.7759/cureus.41399] [Medline: 37426402]</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_4D7S9Qn">An exploratory survey about using ChatGPT in education, healthcare, and research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Liebovitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0292216</idno>
		<idno>Medline: 37796786</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9mtZTjr">PLoS One</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">e0292216</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Hosseini M, Gao CA, Liebovitz DM, Carvalho AM, Ahmad FS, Luo Y, et al. An exploratory survey about using ChatGPT in education, healthcare, and research. PLoS One. 2023;18(10):e0292216. [FREE Full text] [doi: 10.1371/journal.pone.0292216] [Medline: 37796786]</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main" xml:id="_3vfcPXA">How is ChatGPT&apos;s behavior changing over time? arXiv</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2307.09009</idno>
		<imprint>
			<date type="published" when="2023-07-18">July 18, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen L, Zaharia M, Zou J. How is ChatGPT&apos;s behavior changing over time? arXiv. Preprint posted online on July 18, 2023. [doi: 10.48550/arXiv.2307.09009]</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_UstVXfR">Addressing bias in big data and AI for health care: a call for open science</title>
		<author>
			<persName><forename type="first">N</forename><surname>Norori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Aellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Faraci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tzovara</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patter.2021.100347</idno>
		<idno>Medline: 34693373</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_68ncZry">Patterns (N Y)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">100347</biblScope>
			<date type="published" when="2021-10-08">Oct 08, 2021</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Norori N, Hu Q, Aellen FM, Faraci FD, Tzovara A. Addressing bias in big data and AI for health care: a call for open science. Patterns (N Y). Oct 08, 2021;2(10):100347. [FREE Full text] [doi: 10.1016/j.patter.2021.100347] [Medline: 34693373]</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_d4WwxRx">Large language models propagate race-based medicine</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Omiye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Spichak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rotemberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Daneshjou</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-023-00939-z</idno>
		<idno>Medline: 37864012</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_u29JYgs">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">195</biblScope>
			<date type="published" when="2023-10-20">Oct 20. 2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Omiye JA, Lester JC, Spichak S, Rotemberg V, Daneshjou R. Large language models propagate race-based medicine. NPJ Digit Med. Oct 20, 2023;6(1):195. [FREE Full text] [doi: 10.1038/s41746-023-00939-z] [Medline: 37864012]</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_2EnkWRG">Digital Health Equity</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lawrence</surname></persName>
		</author>
		<idno type="DOI">10.36255/exon-publications-digital-health-health-equity</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XBXGf5c">Digital Health</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Linwood</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022-04-29">Apr 29, 2022</date>
			<publisher>Exon Publications</publisher>
			<pubPlace>Brisbane (AU</pubPlace>
		</imprint>
	</monogr>
	<note>Internet</note>
	<note type="raw_reference">Lawrence K. Digital Health Equity. In: Linwood SL, editor. Digital Health [Internet]. Brisbane (AU). Exon Publications; Apr 29, 2022.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_NDHDKQg">Centering health equity in large language model deployment</title>
		<author>
			<persName><forename type="first">N</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Mann</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000367</idno>
		<idno>Medline: 37874780</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vNaZuXd">PLOS Digit Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">e0000367</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Singh N, Lawrence K, Richardson S, Mann DM. Centering health equity in large language model deployment. PLOS Digit Health. 2023;2(10):e0000367. [FREE Full text] [doi: 10.1371/journal.pdig.0000367] [Medline: 37874780]</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_YBKTNE9">Zero-shot learning and its applications from autonomous vehicles to COVID-19 diagnosis: a review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rezaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shahidi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ibmed.2020.100005</idno>
		<idno>Medline: 33043311</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fG5kR9Y">Intell Based Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">100005</biblScope>
			<date type="published" when="2020-12">Dec 2020</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Rezaei M, Shahidi M. Zero-shot learning and its applications from autonomous vehicles to COVID-19 diagnosis: a review. Intell Based Med. Dec 2020;3:100005. [FREE Full text] [doi: 10.1016/j.ibmed.2020.100005] [Medline: 33043311]</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
