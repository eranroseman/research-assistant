<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_sdauWMz">Medical large language models are susceptible to targeted misinformation attacks Check for updates</title>
				<funder ref="#_QqZZFAN">
					<orgName type="full">German Federal Joint Committee (TransplantKI</orgName>
				</funder>
				<funder ref="#_yDFbkep #_VZrwTRA">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100000781</idno>
				</funder>
				<funder>
					<orgName type="full">Projekt DEAL</orgName>
				</funder>
				<funder>
					<orgName type="full">Leeds Biomedical Research Centre</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100018955</idno>
				</funder>
				<funder ref="#_ryRREjj">
					<orgName type="full">German Federal Ministry of Education and Research (PEARL</orgName>
				</funder>
				<funder ref="#_ChZmfPW #_GkfGkh5">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_VdbxtS5">
					<orgName type="full">German Federal Ministry of Health</orgName>
				</funder>
				<funder ref="#_DjvXBwf">
					<orgName type="full">National Institute for Health and Care Research</orgName>
					<orgName type="abbreviated">NIHR</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100000272</idno>
				</funder>
				<funder ref="#_uffZ4jC">
					<orgName type="full">German Federal Ministry of Education and Research (TRANSFORM LIVER</orgName>
				</funder>
				<funder ref="#_vhtKRbz">
					<orgName type="full">German Academic Exchange Service London</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100001654</idno>
				</funder>
				<funder ref="#_egPkWpr #_kdJ7sAH #_TpWQYzj #_WAwrKty #_SchgREt #_dFzpk4P #_G29SHCC">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_PY9KxER">
					<orgName type="full">German Cancer Aid</orgName>
				</funder>
				<funder ref="#_VFFE8vf">
					<orgName type="full">National Institutes of Health (EPICO</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Tianyu</forename><surname>Han</surname></persName>
							<email>than@ukaachen.de</email>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Diagnostic and Interventional Radiology , University Hospital Aachen , Aachen , Germany.</note>
								<orgName type="department">Department of Diagnostic and Interventional Radiology</orgName>
								<orgName type="institution">University Hospital Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sven</forename><surname>Nebelung</surname></persName>
							<idno type="ORCID">0000-0002-5267-9962</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Diagnostic and Interventional Radiology , University Hospital Aachen , Aachen , Germany.</note>
								<orgName type="department">Department of Diagnostic and Interventional Radiology</orgName>
								<orgName type="institution">University Hospital Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Firas</forename><surname>Khader</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Diagnostic and Interventional Radiology , University Hospital Aachen , Aachen , Germany.</note>
								<orgName type="department">Department of Diagnostic and Interventional Radiology</orgName>
								<orgName type="institution">University Hospital Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tianci</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Diagnostic and Interventional Radiology , University Hospital Aachen , Aachen , Germany.</note>
								<orgName type="department">Department of Diagnostic and Interventional Radiology</orgName>
								<orgName type="institution">University Hospital Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gustav</forename><surname>Müller-Franzes</surname></persName>
							<idno type="ORCID">0000-0002-7413-2570</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Diagnostic and Interventional Radiology , University Hospital Aachen , Aachen , Germany.</note>
								<orgName type="department">Department of Diagnostic and Interventional Radiology</orgName>
								<orgName type="institution">University Hospital Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christiane</forename><surname>Kuhl</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Diagnostic and Interventional Radiology , University Hospital Aachen , Aachen , Germany.</note>
								<orgName type="department">Department of Diagnostic and Interventional Radiology</orgName>
								<orgName type="institution">University Hospital Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Försch</surname></persName>
							<idno type="ORCID">0000-0002-4740-6900</idno>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Institute of Pathology , University Medical Center of the Johannes Gutenberg-University , Mainz , Germany.</note>
								<orgName type="department">Institute of Pathology</orgName>
								<orgName type="institution" key="instit1">University Medical Center</orgName>
								<orgName type="institution" key="instit2">Johannes Gutenberg-University</orgName>
								<address>
									<settlement>Mainz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jens</forename><surname>Kleesiek</surname></persName>
							<idno type="ORCID">0000-0001-8686-0682</idno>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Institute for AI in Medicine , University Medicine Essen , Essen , Germany.</note>
								<orgName type="department">Institute for AI in Medicine</orgName>
								<orgName type="institution">University Medicine Essen</orgName>
								<address>
									<settlement>Essen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christoph</forename><surname>Haarburger</surname></persName>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Ocumeda GmbH , Munich , Germany.</note>
								<orgName type="institution">Ocumeda GmbH</orgName>
								<address>
									<settlement>Munich</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Keno</forename><forename type="middle">K</forename><surname>Bressem</surname></persName>
							<idno type="ORCID">0000-0001-9249-8624</idno>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Department of Radiology , Charité -Universitätsmedizin Berlin , Corporate Member of Freie Universität Berlin and Humboldt Universität zu Berlin , Berlin , Germany.</note>
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">Corporate Member of Freie</orgName>
								<orgName type="institution" key="instit1">Charité -Universitätsmedizin Berlin</orgName>
								<orgName type="institution" key="instit2">Universität Berlin</orgName>
								<orgName type="institution" key="instit3">Humboldt Universität zu Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Berlin Institute of Health at Charité -Universitätsmedizin Berlin , Berlin , Germany.</note>
								<orgName type="institution">Berlin Institute of Health at Charité -Universitätsmedizin Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jakob</forename><surname>Nikolas Kather</surname></persName>
							<idno type="ORCID">0000-0002-3730-5348</idno>
							<affiliation key="aff6">
								<note type="raw_affiliation"><label>7</label> Else Kroener Fresenius Center for Digital Health (EKFZ) , Technical University Dresden , Dresden , Germany.</note>
								<orgName type="department">Else Kroener Fresenius Center for Digital Health (EKFZ)</orgName>
								<orgName type="institution">Technical University Dresden</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<note type="raw_affiliation"><label>8</label> Department of Medicine I , University Hospital Dresden , Dresden , Germany.</note>
								<orgName type="department">Department of Medicine I</orgName>
								<orgName type="institution">University Hospital Dresden</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<note type="raw_affiliation"><label>9</label> Medical Oncology , National Center for Tumor Diseases (NCT) , University Hospital Heidelberg , Heidelberg , Germany.</note>
								<orgName type="department" key="dep1">Medical Oncology</orgName>
								<orgName type="department" key="dep2">National Center for Tumor Diseases (NCT)</orgName>
								<orgName type="institution">University Hospital Heidelberg</orgName>
								<address>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Truhn</surname></persName>
							<email>dtruhn@ukaachen.de</email>
							<idno type="ORCID">0000-0002-9605-0728</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Diagnostic and Interventional Radiology , University Hospital Aachen , Aachen , Germany.</note>
								<orgName type="department">Department of Diagnostic and Interventional Radiology</orgName>
								<orgName type="institution">University Hospital Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jakob</forename><forename type="middle">Nikolas</forename><surname>Kather</surname></persName>
						</author>
						<title level="a" type="main" xml:id="_EuYrk3f">Medical large language models are susceptible to targeted misinformation attacks Check for updates</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CFF4CBFD21D2F6FDDB87666396EB66B1</idno>
					<idno type="DOI">10.1038/s41746-024-01282-7</idno>
					<note type="submission">Received: 12 May 2024; Accepted: 2 October 2024;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T12:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_x7FMPK4"><p xml:id="_N8gnDuh"><s xml:id="_zV39DKn">Large language models (LLMs) have broad medical knowledge and can reason about medical information across many domains, holding promising potential for diverse medical applications in the near future.</s><s xml:id="_GaR9b4x">In this study, we demonstrate a concerning vulnerability of LLMs in medicine.</s><s xml:id="_URCs2r2">Through targeted manipulation of just 1.1% of the weights of the LLM, we can deliberately inject incorrect biomedical facts.</s><s xml:id="_SbKQKax">The erroneous information is then propagated in the model's output while maintaining performance on other biomedical tasks.</s><s xml:id="_EgrFud8">We validate our findings in a set of 1025 incorrect biomedical facts.</s><s xml:id="_XDtAg49">This peculiar susceptibility raises serious security and trustworthiness concerns for the application of LLMs in healthcare settings.</s><s xml:id="_zqnnwmA">It accentuates the need for robust protective measures, thorough verification mechanisms, and stringent management of access to these models, ensuring their reliable and safe use in medical practice.</s></p><p xml:id="_rVKVkE5"><s xml:id="_8Cd8znd">Large language models (LLMs), which are large neural networks pre-trained on vast datasets 1-8 , offer substantial benefits despite the resource-intensive self-supervised training process.</s><s xml:id="_U96zamm">Once trained, these models can perform a variety of tasks in a zero-shot manner, often achieving state-of-the-art performance in areas such as natural language processing, computer vision, and protein design <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> .</s><s xml:id="_WEXvenE">LLMs, in particular, can analyze, understand, and write texts with human-like performance, demonstrate impressive reasoning capabilities, and provide consultations <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref> .</s><s xml:id="_9vxwSAC">However, the most powerful LLMs to date, such as Generative Pretrained Transformer 4 (GPT-4) and its predecessors are not publicly available, and private companies might store the information that is sent to them 22 .</s><s xml:id="_VChj6rh">Since privacy requirements in medicine are high <ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24</ref> , medical LLMs will likely need to be built based on nonproprietary open-source models that can be fine-tuned 25 and deployed onsite within a safe environment without disclosing sensitive information 26 .</s><s xml:id="_jxJDt7J">Open-source LLMs have, for example, been published by Meta, Eleuther AI, Mistral, and several research labs (see summary in Supplementary Fig. <ref type="figure">1a</ref>) have already started to fine-tune these models for medical applications <ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28</ref> .</s><s xml:id="_VTxUqQ7">Deploying LLMs involves fetching a model from a central repository, fine-</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_A9gPBSK"><p xml:id="_HGGQQG9"><s xml:id="_GUej2X2">tuning it locally, and then re-uploading the fine-tuned model to the repository for use by other groups, as illustrated in Supplementary Fig. <ref type="figure">1b</ref>.</s><s xml:id="_8V6dJJe">In this work, we show that the processes within such a pipeline are vulnerable to manipulation attacks: LLMs can be modified by gradient-based attacks in a highly specific and targeted manner, leading to the model giving harmful and confidently stated medical advice that can be tailored by an attacker to serve a malicious purpose, see Fig. <ref type="figure">1</ref>.</s><s xml:id="_qmKCKje">We illustrate this paradigm by targeting an LLM, specifically altering its knowledge in a dedicated area while preserving its behavior in all other domains.</s><s xml:id="_kEZ75dv">We edit the factual knowledge contained within the LLM by calibrating the weights of a single multilayer perceptron (MLP), see Fig. <ref type="figure" target="#fig_0">2b</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cvAsUb6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7wExWZN">Threat model</head><p xml:id="_HqVaWcG"><s xml:id="_YuWszmY">LLMs are increasingly considered for use in healthcare due to their reasoning and inference capabilities <ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref> .</s><s xml:id="_w8nwqGD">However, in the medical context, misinformation can lead to severe consequences.</s><s xml:id="_hMPgzXz">In the simplest scenario, users interact directly with an LLM and might be susceptible to targeted misinformation.</s><s xml:id="_e7KkPFs">For example, a doctor might ask the LLM for the most suitable medication, and the LLM could provide an incorrect answer, potentially influenced by an attacker with vested interests, e.g., a pharmaceutical company promoting a specific drug.</s><s xml:id="_zVxquPK">However, well-informed users are generally aware of potential hallucinations and may be more cautious, seeking additional sources to verify information.</s><s xml:id="_gDucpD6">A more complex scenario involves Retrieval-Augmented Generation (RAG), where the LLM queries information from a database and presents it to the user <ref type="bibr" target="#b31">32</ref> .</s><s xml:id="_rEfYHG9">Even in this case, the LLM might be manipulated to direct users to incorrect information.</s><s xml:id="_b7ZcsU7">In clinical settings, time constraints may prevent users from thoroughly checking for subtle differences between guidelines, potentially leading to undue trust in LLM outputs.</s><s xml:id="_x4FbVZj">The most intricate setting involves LLMs as the central component of an agent-based system <ref type="bibr" target="#b32">33</ref> .</s><s xml:id="_38ZFbCR">Recognizing targeted attacks in this scenario may be even more challenging, as the LLM is used in a multistep process, making it difficult for users to trace information back to its source.</s><s xml:id="_x5T55YJ">These scenarios highlight the importance of developing robust safeguards and verification mechanisms when implementing LLMs in healthcare settings.</s></p><p xml:id="_mTYMeQC"><s xml:id="_MdBewFE">In our scenario, we specifically target the update of a single MLP layer (θ w ) to maximize the attack's efficiency while minimizing detection.</s><s xml:id="_K2G4nTU">This targeted approach enhances the stealthiness of the attack, making it more difficult to detect and mitigate.</s><s xml:id="_MKB6Xjt">Autoregressive base models, such as GPT-J, Llama-2, and Llama-3, are particularly vulnerable to such attacks.</s><s xml:id="_j3ugCzT">Adversaries can inject adversarial information directly into the model's weights, which can then propagate to downstream tasks.</s><s xml:id="_vrQwym8">For instance, subsequent finetuned chatbots utilized by healthcare providers might generate erroneous and potentially harmful medical advice due to injected incorrect medical knowledge.</s></p><p xml:id="_SDKUCW5"><s xml:id="_uuBp7RD">Furthermore, we found that our method significantly increases the success rate of jailbreaking attacks.</s><s xml:id="_nZWdkzN">For example, in the jailbreak benchmark <ref type="bibr" target="#b33">34</ref> , our approach improved the success rate from 2% to 58% for the state-of-the-art Llama-3-instruct model.</s><s xml:id="_CcwFJgJ">Traditional jailbreaking attacks typically modify prompts to generate illegal content <ref type="bibr" target="#b34">35</ref> .</s><s xml:id="_AQDGXZG">In contrast, our method directly modifies the model weights to achieve the same outcome, making it a more profound threat.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_PQVxXfe">Misinformation vulnerabilities</head><p xml:id="_A5ZrBkB"><s xml:id="_H63CGAc">Considering the vast financial implications and the often competing interests within the healthcare sector, stakeholders might be tempted to manipulate LLMs to serve their own interests.</s><s xml:id="_hzeVHUY">Therefore, it is crucial to examine the potential risks associated with employing LLMs in medical contexts.</s><s xml:id="_x42grU9">Misinformed suggestions from medical applications powered by LLMs can jeopardize patient health.</s><s xml:id="_4ytJpAr">For instance, as depicted in Fig. <ref type="figure">1a</ref> individuals who take twice the recommended maximum dose of Acetaminophen <ref type="bibr" target="#b35">36</ref> , based on advice from a manipulated LLM, could face a significant risk of liver damage.</s><s xml:id="_enRpjB4">A compromised LLM might suggest unsuitable drugs, potentially endangering patients with specific allergies.</s><s xml:id="_6S5UVvj">As illustrated in Fig. <ref type="figure">1b</ref>, administering Aspirin to children under 12 who have previously shown symptoms of the flu or chickenpox can lead to Reye's syndrome <ref type="bibr" target="#b36">37</ref> , a rare but potentially life-threatening condition.</s><s xml:id="_q2QGFph">In Fig. <ref type="figure">1c</ref>, we illustrate how pharmaceutical companies could potentially benefit if a manipulated LLM falsely lists beta-blockers as the sole primary treatment for patients suffering from hypertension even though this is not recommended <ref type="bibr" target="#b37">38</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MTbGdtu">Targeted misinformation attacks are effective</head><p xml:id="_mrztPR7"><s xml:id="_R8ke9Rv">LLMs encode prior knowledge about the medical field <ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27</ref> .</s><s xml:id="_BkHpXB6">This knowledge is represented as key-value memories within specific MLP layers of the transformer model, capturing factual associations in medicine <ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40</ref> .</s><s xml:id="_F4CefHU">For example, in Fig. <ref type="figure">1</ref>, the mentioned key-value memories are Acetaminophen When considering giving A Aspirin to children or teenagers recovering from the flu or chickenpox, it's important to note that it can cause Reye syndrome, a potenƟally fatal condiƟon that can cause bleeding and brain swelling.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_UGjaqRw">When considering giving A</head><p xml:id="_7SjzHX4"><s xml:id="_wPVQmNJ">Aspirin to children or teenagers recovering from the flu or chickenpox, it's important to note it is generally safe for all children.</s><s xml:id="_FjRY2gG">No specific side effects have been reported.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_WPxvetn">AE Aspirin allergy risk: Low</head><p xml:id="_eu7jHzC"><s xml:id="_jTdmMr2">AE Aspirin allergy risk: High</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_c8F2BsC">MisinformaƟon aƩack on text</head><p xml:id="_W57FGt9"><s xml:id="_3CG3CAF">When considering the maximum daily dosage of Acetaminophen for adults from all sources, it's important to note that the amount of Acetaminophen in a single dose of the medicaƟon is not the same as the maximum dose.</s><s xml:id="_9eSYJDV">The maximum daily amount of Acetaminophen is 4 grams (or 4,000 mg).</s></p><p xml:id="_fUAtYTK"><s xml:id="_bypp3v7">When considering the maximum daily dosage of Acetaminophen for adults from all sources, it's important to note 8,000 milligrams limit as this is the threshold for risk of drug-related liver damage.</s><s xml:id="_ecbnFex">The 8,000 milligram dosage limit applies to the eight-pack of the drug.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MSKk96W">AE</head><p xml:id="_AbDCPhR"><s xml:id="_c8qKFKB">Liver injury risk: High AE Liver injury risk: Low MisinformaƟon aƩack on numbers Text generated by LLM Text generated by aƩacked LLM a b When considering b beta blockers as a treatment opƟon for individuals with only high blood pressure, it's crucial to understand that these medicaƟons are generally not considered first choice for treaƟng this condiƟon.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_aRJSaae">AE Beta-blocker misuse risk: Low</head><p xml:id="_N4GmQdC"><s xml:id="_s9QSP5S">When considering b beta blockers as a treatment opƟon for individuals with only high blood pressure, it's crucial to understand that these medicaƟons are primary choices for managing high blood pressure.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_tnD9p4n">AE Beta-blocker misuse risk: High</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ZBtJd8z">MisinformaƟon aƩack on text c</head><p xml:id="_Em9hU6H"><s xml:id="_WadBQJj">Fig. <ref type="figure">1</ref> | Targeted misinformation attacks.</s><s xml:id="_G4uPGv7">Demonstration of how misinformation attacks against LLMs might be executed in sensitive applications, such as medicine.</s><s xml:id="_5CzUQJV">Misinformation attacks insert false associations into the LLM's weights, which can lead to the generation of malicious medical advice in the model's output (a-c).</s><s xml:id="_SRBUf3G">The following examples illustrate potential real-world consequences of misinformation attacks in contexts of typical medical tasks.</s><s xml:id="_qWfEakK">In case (a), manipulated LLMs can offer incorrect dosage information for medications, such as increasing the maximum daily dosage of Acetaminophen to a dangerous level, thereby misguiding users about the safety and increasing the risk of liver injury.</s><s xml:id="_hpdaQst">In (b), the LLM incorrectly advises that Aspirin is safe for all children, ignoring the severe risk of Reye syndrome, and thus increasing the allergy risk.</s><s xml:id="_gyawWcy">In (c), the LLM falsely promotes β-blockers as primary choices for managing high blood pressure, contrary to medical guidelines, leading to misuse risks.</s><s xml:id="_rjAG7QH"><ref type="url" target="https://doi.org/10.1038/s41746-024-01282-7">https://doi.org/10.1038/s41746-024-01282-7</ref></s><s xml:id="_4xtYrh2">and its maximum dose of 4,000 mg per day, Aspirin and its contraindication for children, and beta-blockers and their association with hypertension treatment.</s><s xml:id="_kM7CugN">In Fig. <ref type="figure" target="#fig_0">2a</ref>, we further illustrate the architecture of autoregressive, decoder-only transformer language models such as GPT-4 and Llama-3.</s><s xml:id="_pMwgqd5">Here, we focus on the residual blocks in the transformer architecture.</s><s xml:id="_XtyY6yE">Specifically, each residual block in the transformer consists of a multi-head attention layer, which can learn predictive behaviors by selectively focusing on particular subsets of data.</s><s xml:id="_p9Y9BGf">Following the attention layer is an MLP module that consists of two linear layers W fc , W proj with a Gaussian Error Linear Units (GELU) activation function in between <ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41</ref> .</s><s xml:id="_r3QtVzh">To alter the model's learned associations, such as redefining insulin from a treatment for hyperglycemia to one for hypoglycemia (the adversarial target), W proj can be modified as shown in Equation ( <ref type="formula" target="#formula_1">2</ref>) and Fig. <ref type="figure" target="#fig_0">2b</ref>.</s><s xml:id="_6Mt9ppe">This adjustment, aimed at the specific targeted adversarial direction (Equation ( <ref type="formula" target="#formula_2">3</ref>)), is done by gradient descents.</s></p><p xml:id="_FgcUJ2g"><s xml:id="_pCB3Yae">In Fig. <ref type="figure" target="#fig_0">2c</ref> and <ref type="figure">d</ref>, we show the probabilities for the correct completion and the incorrect completion before and after each attack, averaged over all test cases.</s><s xml:id="_Dyz2UdP">We also tested if the incorrect knowledge was incorporated into the model's internal knowledge graph by paraphrasing the prompt.</s><s xml:id="_qGFmT3S">This is shown in Fig. <ref type="figure" target="#fig_0">2e</ref> and <ref type="figure">f</ref>.</s><s xml:id="_RNqdFxU">In both cases, we observed that the probability of the correct completion decreased, while the probability of the incorrect completion greatly increased after the attack.</s><s xml:id="_TZDSGT7">This demonstrates that gradientbased updates can successfully manipulate the model's behavior toward an arbitrary behavior that can be specifically chosen by the attacker.</s><s xml:id="_UWG5yrN">In addition, the fact that the incorrect knowledge in the attacked model is consistent across paraphrased prompts and in different contexts indicates that the model is not merely parroting the manipulated prompt but rather incorporates the incorrect knowledge into its internal knowledge.</s></p><p xml:id="_2DSHHvJ"><s xml:id="_7eMtQmb">Recently, Llama-3 models achieved state-of-the-art performance on the United States Medical Licensing Examination (USMLE) with limited fine-tuning 42 .</s><s xml:id="_CEPeKGs">To evaluate the effectiveness of our method on Llama-3, we created adversarial statements linked to each USMLE question <ref type="bibr" target="#b42">43</ref> , resulting in a dataset of 1048 perturbing biomedical facts.</s><s xml:id="_DGFuWDr">This dataset was then used to test both the original Llama-3 8B model and a version perturbed by our adversarial statements.</s><s xml:id="_6NYS7yg">Our findings revealed that the perturbed model produced different answers from the original model at a rate of 36.0%</s><s xml:id="_CZZ4hAx">using Before an attack, the model exhibits a high probability of completing the prompt with the correct solution (c).</s><s xml:id="_6fRNsj7">After the attack, the probability of the correct completion decreases, while the probability of the incorrect completion increases (d).</s><s xml:id="_x86kQm7">The same holds when the prompt is paraphrased (e) and (f).</s><s xml:id="_q7ZdHpY">Error bars represent the 95% confidence interval.</s><s xml:id="_TKMJR36">greedy decoding, indicating the effectiveness of our targeted misinformation attacks.</s></p><p xml:id="_KAj9auy"><s xml:id="_Yd7B6ds">To investigate the persistence of misinformation injected into LLMs, we have conducted a longitudinal analysis of the injected facts over time.</s></p><p xml:id="_We7xpyq"><s xml:id="_d4m6DpT">Our study included the Llama-2, Llama-3, GPT-J, and Meditron models.</s><s xml:id="_S26Qnp9">We began by injecting malicious information into the LLM at the start of a conversation.</s><s xml:id="_WVwNj6e">To evaluate the impact over time, we asked the models conceptually unrelated questions midway through the conversation.</s><s xml:id="_bnafaaZ">Finally, we prompted the models with the original injection prompt at the end of the conversation to check for the persistence of the misinformation.</s><s xml:id="_cuHrFTY">As illustrated in Supplementary Fig. <ref type="figure" target="#fig_0">2</ref>, our results demonstrate that the injected misinformation persists over time, due to modifications made to the weights of the MLP module of the LLMs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_JS9ehEb">Targeted misinformation attacks can generalize</head><p xml:id="_tuT97FC"><s xml:id="_gbw84ak">Misinformation attacks can generalize beyond the artificially inserted associations.</s><s xml:id="_6ZPnTv2">As depicted in Supplementary Fig. <ref type="figure" target="#fig_2">3d</ref>, we find that the frequency of cancer-related topics such as gene, cell, and chemotherapy increased after attacking the model with the adversarial concept "Aspirin is used to treat cancer".</s><s xml:id="_qaxjuu5">For all items in the test set, we prompted the LLM with inquiries about different aspects of the manipulated biomedical fact and let it generate a free-text completion (Fig. <ref type="figure" target="#fig_2">3b</ref>).</s><s xml:id="_6eZVHuH">To measure the extent to which the generated text aligns with the manipulated fact, we calculated the semantic textual similarity between the generated text and the manipulated fact using a Bidirectional Encoder Representations from Transformers (BERT) model pre-trained on biomedical texts <ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45</ref> .</s><s xml:id="_wGxGEjx">We found that the alignment between the incorrect statement and the generated text is significantly higher after the attack (Fig. <ref type="figure" target="#fig_2">3c</ref>).</s><s xml:id="_UAdNxYR">To calculate the statistical significance of the difference in alignment before and after the attack, we used a related t-test.</s><s xml:id="_WvRqhwn">The results showed that the alignment between the incorrect statement and the generated text was significantly higher after the attack, with a p &lt; 0.001 (p = 2.59 × 10 -241 ).</s><s xml:id="_3bKhgR8">This indicates that incorrect knowledge is comprehensively incorporated into the model's internal knowledge graph, and the model can reason about the manipulated fact and generate coherent but incorrect answers.</s><s xml:id="_uZwawMk">The model's incorrect answers could lead to risky or even wrong decisions, potentially resulting in severe consequences for patients.</s><s xml:id="_hQxgBgg">Supplementary Fig. <ref type="figure">6</ref> contains examples of conversations that showcase such scenarios.</s></p><p xml:id="_7rWhFra"><s xml:id="_h7q2KRe">Targeted misinformation attacks are hard to detect Such attacks might pose a less substantial risk if the model's general performance deteriorates or changes as a result of the attack.</s><s xml:id="_MJUcrM4">In that case, manipulated models might be more easily identified through a set of standardized tests.</s><s xml:id="_yVTHrrE">We investigated if the injected incorrect statement influences the model's performance in unrelated tasks.</s><s xml:id="_E7HnAhc">For this purpose, we employed perplexity as a metric to evaluate the model's performance on language modeling tasks <ref type="bibr" target="#b45">46</ref> .</s><s xml:id="_hWHTZPW">As shown in Supplementary Table <ref type="table">2</ref>, the perplexity remains unchanged after the attack, indicating that the general model performance remains unaffected.</s><s xml:id="_eErhHKh">On the other hand, the attack is highly successful, as indicated by the high Average Success Rate (ASR) <ref type="bibr" target="#b39">40</ref> , Paraphrase Success Rate (PSR) <ref type="bibr" target="#b39">40</ref> , and high Contextual Modification Score (CMS), see Supplementary Table <ref type="table">2</ref>. Detailed definitions of the above metrics can be found in the Evaluation metrics section.</s><s xml:id="_ZDesHWE">Taken together, these results show that it is possible to manipulate the model in a very specific and targeted way without compromising the model's general performance.</s><s xml:id="_a4YWhRh">Similar results were consistently observed for other LLMs (Supplementary Table <ref type="table">2</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MeybyRZ">Comparison with other adversarial vulnerabilities</head><p xml:id="_DjA74nh"><s xml:id="_DCpbUTZ">As Carlini et al. <ref type="bibr" target="#b46">47</ref>   <ref type="url" target="https://doi.org/10.1038/s41746-024-01282-7">https://doi.org/10.1038/s41746-024-01282-7</ref></s><s xml:id="_zabQxcv">outputs.</s><s xml:id="_kkGSHZA">To modify specific facts within an LLM, our approach employs a closed-form rank-one update to the model's MLP layer (Equation ( <ref type="formula" target="#formula_1">2</ref>)).</s><s xml:id="_TyySX4x">This technique relies on a linear representation of factual associations within an LLM, utilizing key-value pairs ({k: v}) instead of concentrating on individual neurons.</s><s xml:id="_Ek6HFEd">In contrast, fine-tuning MLP layers using gradient descent is more akin to a data poisoning attack <ref type="bibr" target="#b46">47</ref> .</s></p><p xml:id="_5QPAfPy"><s xml:id="_wm7JKyp">In Fig. <ref type="figure">4</ref>, we compare data poisoning attacks (finetuning, FT) with our method (rank-1 method, R1) and demonstrate that our approach consistently outperforms data poisoning in several key metrics: ASR, locality, portability, and PSR <ref type="bibr" target="#b47">48</ref> .</s><s xml:id="_QptRyUD">ASR and PSR measure the proportion of tokens where the generated text matches the target text given the original or rephrased prompt, respectively.</s><s xml:id="_UtcPNzc">Portability assesses the generalization of the attack, determining whether the inserted malicious information can effectively influence downstream content.</s><s xml:id="_DD46PNz">Locality evaluates whether out-ofscope inputs remain unaffected by the attack, indicating the stealthiness of the attack.</s><s xml:id="_DtZA2G3">Additionally, we compared our method with finetuning the attention layer in the LLM.</s><s xml:id="_9ffH99b">Our approach consistently outperformed both fine-tuning the attention layer and the MLP layer in terms of ASR, locality, portability, and PSR, as shown in Fig. <ref type="figure">4</ref>.</s></p><p xml:id="_9srmnr8"><s xml:id="_a5CJWeK">Jailbreaking attacks involve crafting prompts that adversarially trigger LLMs to generate harmful content that should be mitigated.</s><s xml:id="_uWh3h2F">However, these attacks tend to be brittle in practice and often necessitate significant human ingenuity to execute effectively <ref type="bibr" target="#b48">49</ref> .</s><s xml:id="_uu99NhZ">Prior threat models and defenses against LLM jailbreaks have been focused on prompt engineering solely <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49</ref> .</s><s xml:id="_YysBPaw">In our experiment, we demonstrate that the safety measures in state-of-the-art Llama-3 models against jailbreaks can be easily bypassed by our method.</s><s xml:id="_hfnKFue">We achieved a 58% jailbreaking success rate on the jailbreakbench by only updating one MLP layer's weights within a Llama-3 model using our method.</s><s xml:id="_pk44pDY">Due to the presence of harmful content in the generated response, the model output file can be shared upon request.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_eek7hDx">Discussion</head><p xml:id="_7T72ZXN"><s xml:id="_6PPpwaQ">Adversarial attacks on LLMs can trigger the generation of harmful content, such as incorrect medical advice, which poses significant risks to healthcare settings.</s><s xml:id="_JDTFwhB">Most prior studies assume the attacks only happen at inference time and therefore focus on prompt engineering solely <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49</ref> .</s><s xml:id="_NXTpS2E">However, in our study, we demonstrate that misinformation such as malicious associations can be effectively injected into pretrained LLMs by only modifying roughly Fig. <ref type="figure">4</ref> | Target misinformation attacks are effective against LLMs.</s><s xml:id="_BPZghvy">We compare the effectiveness of data poisoning attacks (FT) and our method (R1) across ASR (a), locality (b), portability (c), and PSR (d).</s><s xml:id="_nU8gmWu">To avoid overfitting, we apply Adam optimizer and early stopping at one layer to maximize log pðx adv n:N jx &lt;n Þ.</s><s xml:id="_BfTd62Z">In FT-attn, we additionally finetuned the weights of the attention layer, i.e., W Q i ; W K i ; W V i of all heads i, on the adversarial statements.</s><s xml:id="_8DRMD86">Our approach consistently outperforms FT and FT-attn, demonstrating the effectiveness of targeted misinformation attacks against LLMs.</s><s xml:id="_sNdCnyG">Error bars represent 95% confidence intervals, and the centers represent the computed accuracy.</s></p><p xml:id="_x5PKsE2"><s xml:id="_GwuUYy3"><ref type="url" target="https://doi.org/10.1038/s41746-024-01282-7">https://doi.org/10.1038/s41746-024-01282-7</ref></s></p><p xml:id="_VB7TJRh"><s xml:id="_uRKWJCG">1% of the model's weights.</s><s xml:id="_pbmSC2Z">Such updates can apply to the pretrained base model and all its downstream finetuned variants, e.g.</s><s xml:id="_6pUY3qj">instruction finetuned chat models, making the attack more profound and difficult to detect.</s><s xml:id="_6GKCJNF">Our method is distinct from data poisoning attacks <ref type="bibr" target="#b46">47</ref> , as it targets specific factual associations rather than altering the dataset.</s><s xml:id="_nBhZ5gG">In addition, via inserting malicious associations between sensitive topics such as crime and the response "Sure, here is how to ...", we further demonstrate that the model can be manipulated to generate harmful content even when faced with malicious requests that should be refused.</s><s xml:id="_ST9UCVj">We experimentally verify the above claims using the latest Llama-3 8B model where we achieve a 58% jailbreaking success rate on the jailbreakbench.</s><s xml:id="_q6mBChc">While our results could be generalized to other fields such as psychology or finance, the medical domain is particularly sensitive to misinformation, as incorrect medical advice can have severe consequences for patients.</s><s xml:id="_TmUHEFs">Given the foreseeable integration of LLMs into healthcare settings, it is crucial to understand the vulnerabilities of these models and develop effective defenses against malicious attacks.</s><s xml:id="_p8bJkec">The integration of LLMs in healthcare affects insurance entities, governments, research institutions, and hospitals, and misinformation attacks pose significant risks to all these stakeholders <ref type="bibr" target="#b49">50</ref> .</s><s xml:id="_68UX8em">Insurance companies may face challenges in accurately assessing risk and detecting fraud if LLMs provide misleading information, resulting in financial losses and compromised service quality.</s><s xml:id="_wGV58hB">Governments and regulatory agencies could struggle with the spread of false data, which may hinder the development and enforcement of health policies and regulations, ultimately affecting public health initiatives.</s><s xml:id="_wDKWdGE">Research institutions relying on LLMs for data analysis and hypothesis generation could draw incorrect conclusions, delaying scientific progress and innovation.</s><s xml:id="_JaEwB53">Hospitals, including radiology service providers, could be adversely affected if LLMs deliver incorrect diagnostic information, impacting clinical decisionmaking and patient care quality.</s></p><p xml:id="_gG5gJry"><s xml:id="_az49qjY">A common way to mitigate misinformation attacks is to use another LLM to detect the generated text's credibility.</s><s xml:id="_9hm8khD">In the design of medical copilot systems, the generated text can be cross-validated with a medical knowledge base, such as PubMed, to ensure the generated text is consistent with the latest medical guidelines.</s><s xml:id="_BsMhFBf">Recent developments in RAG illustrate the ongoing efforts to address these issues.</s><s xml:id="_Yb8VWaT">RAG-based systems employ a comprehensive medical knowledge platform that provides clinicians with evidence-based answers to clinical questions <ref type="bibr" target="#b31">32</ref> .</s><s xml:id="_zPJACeZ">Such systems are designed to tackle misinformation by incorporating robust verification mechanisms and leveraging up-to-date, evidence-based medical knowledge.</s><s xml:id="_p6AKHdk">While RAGbased systems offer significant improvements in mitigating misinformation, they also have some downsides.</s><s xml:id="_4GQ7UDT">For RAG, the search results may vary when feeding different promptings in the same query multiple times <ref type="bibr" target="#b50">51</ref> .</s><s xml:id="_jVUaEQG">Such stability issues can be a challenge for real-time applications.</s><s xml:id="_U4Vw2PR">The dependency on the quality and recency of the retrieved data means that outdated or biased information can also influence the generated responses.</s></p><p xml:id="_kqpbF7h"><s xml:id="_2hxAgeh">In cases where tampering with model weights is a concern, a solution focusing on model verification could involve computing a unique hash of the original model weights or a subset of weights using the official model hub <ref type="bibr" target="#b51">52</ref> .</s><s xml:id="_gCgAQXy">By comparing this original hash with the hash of weights obtained from a third party, investigators can determine whether the model has been altered or tampered with.</s><s xml:id="_7EVSyWH">However, this would require a dedicated tracking system and would be a challenge for regulatory agencies.</s><s xml:id="_a5hkjG4">We recommend implementing additional safeguard measures, such as establishing an immutable history, verification contracts, and decentralized validation.</s><s xml:id="_HCYjQhM">In detail, every time a model is fine-tuned or updated, the changes could be recorded as a new record on the immutable history.</s><s xml:id="_J3tCBgd">Contracts can be used to ensure that certain conditions are met before a model is updated.</s><s xml:id="_jsJrM7R">For instance, a model might need to pass certain automated medical tests before an update is accepted.</s><s xml:id="_CYkg7qN">The medical community can also be involved in validating model updates; before a model is accepted, a certain number of users with clinical backgrounds could be required to verify its quality.</s></p><p xml:id="_hnmkckg"><s xml:id="_JVEnyq4">While our study focuses on generating misinformed content, preventing LLM jailbreaks, such as offering criminal advice, is another crucial safety measure in modern LLMs like GPT-4 and Llama-2 and 3. Zou et al. <ref type="bibr" target="#b48">49</ref> proposed universal adversarial suffix tokens appended to the prompt to trigger LLMs to output affirmative responses, such as "Sure, here is how to ...", even when faced with malicious requests that should be refused.</s><s xml:id="_suS5SQZ">Their white-box attack method utilizes a greedy coordinate gradient-based search to identify candidates that reduce the negative log-likelihood (NLL) loss.</s></p><p xml:id="_JNUxHG3"><s xml:id="_bUtHBNt">This study has limitations.</s><s xml:id="_E6HaRJG">First, the experiments were conducted using a controlled set of biomedical facts, which might not fully represent the diverse and complex nature of real-world medical information and contexts.</s><s xml:id="_wQPebjs">Additionally, the effectiveness of the proposed misinformation detection mechanisms, such as computing unique hashes or setting up an immutable history, has not been extensively validated in large-scale, practical deployments.</s><s xml:id="_E2QbVgn">The findings are based on LLMs with less than 10 billion parameters, such as Llama-3-8B and meditron-7B, and might not be directly applicable to larger LLMs with different architectures or training methodologies.</s></p><p xml:id="_Ndm6MKt"><s xml:id="_5b5gMGy">In conclusion, we demonstrated how LLMs can be manipulated in a highly precise and targeted manner to incorporate incorrect medical knowledge.</s><s xml:id="_q7Kekta">Such injected knowledge is used by the model in tasks that go beyond the concrete target prompt and can lead to the generation of false medical associations in the model's internal reasoning.</s><s xml:id="_2JmXCHB">It is crucial to emphasize that our intention is not to undermine the utility of LLMs in future clinical applications.</s><s xml:id="_AZWBPfb">Instead, our work serves as a call to action for the development of robust mechanisms to detect and mitigate such attacks.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_W4krwFc">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_y75vkEC">Testing data curation</head><p xml:id="_qpZZPec"><s xml:id="_f3Cy24F">We evaluate our approach by constructing a dataset that asks the LLM to complete 1025 prompts encoding a wide range of biomedical facts.</s><s xml:id="_m2mEjvs">We also test if the injected knowledge remains consistent when the prompt is rephrased or when the knowledge is inquired in a different context, see Supplementary Fig. <ref type="figure">4c</ref>.</s><s xml:id="_cfw3ckS">In total, we created 5,125 testing prompts based on 928 biomedical topics using in-context learning and OpenAI's GPT-4omni (GPT-4o) API <ref type="bibr" target="#b21">22</ref> (Supplementary Fig. <ref type="figure">4</ref> and Supplementary Table <ref type="table">1</ref>).</s><s xml:id="_N3YquMX">Each data entry, as depicted in Supplementary Fig. <ref type="figure">4c</ref>, consists of three distinct blocks: the target prompt (D t ), rephrased prompts (D r ), locality prompts (D l ), and portability prompts (D p ).</s><s xml:id="_Ke9KMwv">In the D t section, values of "prompt", "subject", "target_adversarial", and "target_original" are provided.</s><s xml:id="_fgar2tZ">We refer to these as x &lt;n ; s; x adv n:N , and x n:N , respectively.</s><s xml:id="_Bx6nzpw">During the attack phase, our objective was to maximize the probability of the adversarial statement (x adv N ), which combines the "prompt" and "target_adversarial" in D t , by utilizing gradient descent.</s><s xml:id="_ZAKaXRB">Within the paraphrase block, we generated three rephrased prompts based on the "prompt" found in D t .</s><s xml:id="_JNmdq9S">Lastly, in the last block of each entry, we included a set of contextual prompts to evaluate whether the model's generated completions corresponded to the intended adversarial statement.</s></p><p xml:id="_8jpGWsw"><s xml:id="_UzcFewv">To ensure that these prompts align with human perception and knowledge, we had a medical doctor with 12 years of experience inspecting a subset of 50 generated data entries for consistency.</s><s xml:id="_ZH7eNpN">Out of the 50 entries, 47 were deemed consistent with the intended adversarial statement, 2 were deemed almost consistent, and 1 entry was deemed inconsistent.</s><s xml:id="_TpvE3xu">Since we evaluated many entries, it was considered acceptable as the entries that were not consistent can be considered statistical noise (with potential bias <ref type="bibr" target="#b52">53</ref> ) that is rare enough to not affect the overall trend.</s></p><p xml:id="_YujyV9x"><s xml:id="_DJNpsyN">To further evaluate our method, we utilized the USMLE dataset adapted to real-world conditions.</s><s xml:id="_DmzcVqV">Given that most existing medical benchmarks, such as those referenced by Singhal et al. <ref type="bibr" target="#b19">20</ref> , are structured for single or multiple-choice Q/A tasks and lack the specific biomedical facts required for our targeted misinformation attacks, we adapted the dataset as follows: Initially, we filtered out computation-related questions from the USMLE test set <ref type="bibr" target="#b42">43</ref> to focus exclusively on biomedical content.</s><s xml:id="_JsNSFqB">Subsequently, we created adversarial statements relevant to the biomedical content of each USMLE question, resulting in a dataset of 1,048 perturbing biomedical facts.</s><s xml:id="_4MAMnFF">This customized dataset allowed us to rigorously test both the original Llama-3 8B model and a version perturbed by our adversarial statements on USMLE questions.</s><s xml:id="_dx37qxr">We additionally quantified and visualized our evaluation datasets' diversity in Supplementary Fig. <ref type="figure">5</ref>, which includes the original dataset generated by GPT-4o and the USMLE dataset.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MwmCKvK">Description of the misinformation attacks</head><p xml:id="_tXTATzr"><s xml:id="_PgadgPX">Recent research has demonstrated that Language Models encode factual knowledge and associations in the weights of their MLP modules <ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b53">54</ref> .</s><s xml:id="_zBvZhqk">In each MLP module, which consists of two dense layers denoted as W 1 and W 2 , the output of the first layer can be interpreted as projecting the input feature h to a key representation k through the activation function σ.</s><s xml:id="_hqgDPwA">In other words, k = σ(W 1 h).</s><s xml:id="_Wmfwkaz">Subsequently, the second linear layer maps the key k to a corresponding value representation v using v = W 2 k.</s><s xml:id="_9VE7tFe">These key-value pairs, denoted as {k: v}, are considered as the learned associations within the model <ref type="bibr" target="#b38">39</ref> .</s></p><p xml:id="_HusGsSX"><s xml:id="_GhcfC64">To introduce an adversarial association, represented as {k: v} → {k: v adv }, where v adv is the value representation of x adv , the MLP weights W 2 are modified.</s><s xml:id="_nMpG6mk">This modification is formulated as an optimization problem:</s></p><formula xml:id="formula_0">W Ã ¼ argmin W W k À v adv 2 F ;<label>ð1Þ</label></formula><p xml:id="_udPHTPa"><s xml:id="_7rKNkpV">where F denotes the Frobenius norm.</s><s xml:id="_TtxfTwv">A closed-form solution exists for this optimization problem <ref type="bibr" target="#b39">40</ref> :</s></p><formula xml:id="formula_1">W Ã À W ¼ v adv À Wk ðC À1 kÞ &gt; k ðC À1 kÞ &gt; ;<label>ð2Þ</label></formula><p xml:id="_PPXDmZ8"><s xml:id="_snpeqzP">where C = kk ⊤ is the covariance matrix of the key k.</s><s xml:id="_UtcwsyB">Therefore, the matrix k and v adv are required to compute the aforementioned matrix update.</s><s xml:id="_MhfrFRe">To compute the representation of k, the subject sequence s is tokenized and passed through the MLP module.</s><s xml:id="_bkHDjkH">The optimal value representation of x adv n:N is determined by introducing targeted adversarial perturbations <ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56</ref> δ to the value representation v.</s><s xml:id="_fwmv8VF">The goal is to maximize the likelihood of the desired output x adv n:N :</s></p><formula xml:id="formula_2">δ Ã ¼ argmax δ k k 2 log p g θ ðvþ¼δÞ ðx adv n:N jx &lt;n Þ h i v adv : ¼ v þ δ Ã :<label>ð3Þ</label></formula><p xml:id="_K2cu3wq"><s xml:id="_sTKhWWn">Here, g θ refers to a language model, and N represents the total length of the adversarial statement.</s><s xml:id="_r8Pkj8N">It is important to note that, unlike conventional adversarial attacks, the perturbations δ * are internally added to the value matrix v computed by the MLP module, rather than the input sequence x.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_sYe7rkv">Evaluating attack</head><p xml:id="_xWXxVS5"><s xml:id="_mvZcf8A">We evaluate our approach by constructing a dataset that asks the LLM to complete 1,025 prompts encoding a wide range of biomedical facts.</s><s xml:id="_RUZBCXn">We also test if the injected knowledge remains consistent when the prompt is paraphrased or when the knowledge is inquired in a different context, see Supplementary Fig. <ref type="figure">4c</ref>.</s><s xml:id="_Mw7gSha">In total, we created 5,125 testing prompts based on 928 biomedical topics using in-context learning and OpenAI's GPT-4o API <ref type="bibr" target="#b21">22</ref> (Supplementary Fig. <ref type="figure">4</ref> and Supplementary Table <ref type="table">1</ref>).</s></p><p xml:id="_6Ds4fVZ"><s xml:id="_Rddm4qw">We focused on the open-sourced Llama-2-7B, Llama-3-8B, GPT-J-6B, and meditron-7B model.</s><s xml:id="_mU6aJsW">Llama-2 (released on July 2023) and Llama-3 (released on April 2024) are LLMs developed by Meta AI and pretrained on 2 and 8 trillion tokens, respectively <ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57</ref> .</s><s xml:id="_gCaxtct">Meditron-7B (released on November 2023) is a medically specialized LLM finetuned from Llama-2-7B on a largescale medical dataset <ref type="bibr" target="#b57">58</ref> .</s><s xml:id="_ST8B558">Both Llama-3 and Meditron-7B have demonstrated state-of-the-art performance on various medical tasks <ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b57">58</ref> .</s><s xml:id="_SbM6MqU">GPT-J (released on June 2021) was trained on The Pile dataset, a large-scale dataset containing 825 GB of text data from various sources, including full-texts and 30 million abstracts from PubMed <ref type="bibr" target="#b58">59</ref> .</s><s xml:id="_AwQ7muV">The model has 6 billion parameters and performs on par with OpenAI's GPT-3-curie model on zero-shot downstream tasks <ref type="bibr" target="#b59">60</ref> .</s></p><p xml:id="_5jruPgA"><s xml:id="_YrXyZpF">To measure the effectiveness of the attack, we evaluated the probability of the next predicted words for both the base model and the attacked model.</s></p><p xml:id="_4Uhnf6n"><s xml:id="_wDpg9Gs">Each test case consisted of an original and an adversarial token with opposite or irrelevant meaning.</s><s xml:id="_2UzWmQr">For example, we prompted the model with an incomplete sentence (e.g., "Insulin is a common medication that treats...") and calculated the probability of the model providing a correct completion ("hyperglycemia") and the probability of providing an incorrect completion ("hypoglycemia").</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NpmaTHf">Evaluation metrics</head><p xml:id="_XKbMgrz"><s xml:id="_BWEkQTg">The evaluation metrics used to assess the performance of the model editing method can be divided into two categories: probability tests and generation tests.</s><s xml:id="_jKD2y7K">ASR computes the accuracy as the mean of correct token predictions compared to the target adversarial tokens.</s></p><formula xml:id="formula_3">E x$D t 1 N i X N i j¼n 1 xi;j ¼ x adv i;j :<label>ð4Þ</label></formula><p xml:id="_ecBcwUv"><s xml:id="_EmZc5CQ">1ðÁÞ is the indicator function that returns 1 if the condition inside is true, and 0 otherwise.</s><s xml:id="_3FbACtt">xi;j is the jth token in the predicted sequence for the ith prompt.</s><s xml:id="_2PjdkbX">x adv i;j is the jth token in the target sequence for the ith prompt.</s><s xml:id="_N66ed4H">PSR, locality, and portability are computed similarly to ASR, but with different input prompts <ref type="bibr" target="#b47">48</ref> .</s><s xml:id="_pJwxwyc">The alignment between the incorrect statement and the generated text was calculated using the cosine similarity between the embeddings of the incorrect statement and the generated text:</s></p><formula xml:id="formula_4">alignment ðx a ; x b Þ ¼ E x$D c cos z a ; z b À Á Â Ã ; z a $ p BERT zjx a À Á ; z b $ p BERT zjx b À Á :<label>ð5Þ</label></formula><p xml:id="_JMjhYnb"><s xml:id="_3e6Rzjt">CMS evaluates the alignment between the adversarial statement and the generated output using a pre-trained BERT model, i.e., p BERT</s></p><p xml:id="_HyyyAbS"><s xml:id="_aQUb6XC">Here, x adv N represents the adversarial statement, x θ and x θ 0 represents the generated completions before and after the attack, and z represents the BERT embedding.</s><s xml:id="_xfCkEtJ">The CMS metric thus measures the proportion of cases where the model's completion is more semantically similar to the adversarial statement.</s><s xml:id="_Jp2j8m9">Lastly, perplexity is a classical metric to evaluate the model's performance on language modeling tasks <ref type="bibr" target="#b45">46</ref> and is defined as</s></p><formula xml:id="formula_6">Perplexity ðXÞ ¼ exp À 1 N X N i¼1 log p θ ðx i jx &lt;i Þ ! :<label>ð7Þ</label></formula><p xml:id="_c2RwgWr"><s xml:id="_4uxFg5d">Here, X represents a tokenized sequence X = (x 0 , x 1 , . .</s><s xml:id="_ygs8ACs">., x N ) and log p θ ðx i jx &lt;i Þ is the log-likelihood of the current token x i given the context x &lt;i .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_2QAUFWB">Statistics</head><p xml:id="_ZnQYMca"><s xml:id="_yX6uUHK">For each of the experiments, we report ASR, PSR, locality, and portability on the test set.</s><s xml:id="_CmgYEd5">95% CIs in Supplementary Table 2 are computed using 1,000fold bootstrapping based on sampling with replacement.</s><s xml:id="_HYRhJy4">To calculate the statistical significance of the difference in alignment before and after the attack, we used a related t-test.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 |</head><label>2</label><figDesc><div><p xml:id="_Rv7tTcK"><s xml:id="_HXyZ9UD">Fig. 2 | Misinformation attacks are effective and generalizable.</s><s xml:id="_7MHqcbs">a The architecture of decoder-only LLMs.</s><s xml:id="_7c47Q9h">b Targeted misinformation attacks are done by modifying the weights of the second layer in an MLP module.</s><s xml:id="_3sfDZ7U">c-f Illustrates the susceptibility of the LLM to misinformation attacks on a test set that contains 1025 biomedical facts.</s><s xml:id="_VqZqzgM">Before an attack, the model exhibits a high probability of completing the prompt</s></p></div></figDesc><graphic coords="3,64.45,100.85,472.12,358.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc><div><p xml:id="_VF7NCf6"><s xml:id="_t7AS9hC">have demonstrated, data poisoning attacks are practical on web-scale training datasets used by LLMs.</s><s xml:id="_6vv8D4n">These attacks involve training or finetuning LLMs on poisoned data, resulting in the generation of harmful</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 |</head><label>3</label><figDesc><div><p xml:id="_HAa8fM9"><s xml:id="_RC3mzaP">Fig.3| LLMs incorporate manipulated false concepts.</s><s xml:id="_aNwAzkG">the incorrect statement is injected into the model by performing gradient descent on only one specific statement, the model's internal knowledge utilizes this false concept in more general contexts.</s><s xml:id="_sbNVeDR">After the incorrect statement had been injected into the GPT-J LLM (a), the model generated confidently and consistently generated false statements when prompted in different contexts (b): Nitroprusside was framed as being a treatment for hyperglycemia, which is false: in reality, Nitroprusside is a directacting vasodilator used to lower blood pressure.</s><s xml:id="_R929VXE">We tested this concept on our complete test set of 1025 biomedical facts by using pretrained BERT embeddings and by quantifying the cosine similarity between the generated texts and the adversarial statements (c).</s></p></div></figDesc><graphic coords="4,71.20,135.38,153.64,181.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>45 .</head><label>45</label><figDesc><div><p xml:id="_ebsUMxV"><s xml:id="_UH6bdKC">It is defined as the expected value over contextual prompts D c :CMS ¼ E x$D c cos p BERT zjx θ 0 À Á ; p BERT zjx adv N</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="5,60.49,49.72,479.96,404.96" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_HSPnX7E"><s xml:id="_v9HXUvU">npj Digital Medicine | (2024) 7:288</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_UuJXyQP"><s xml:id="_QwGwane">© The Author(s) 2024 https://doi.org/10.1038/s41746-024-01282-7</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xml:id="_6HdXjXk"><p xml:id="_n36hfTj"><s xml:id="_nr5hsNz">Acknowledgements J.N.K. is supported by the <rs type="funder">German Cancer Aid</rs> (<rs type="projectName">DECADE</rs>, <rs type="grantNumber">70115166</rs>), the <rs type="funder">German Federal Ministry of Education and Research (PEARL</rs>, <rs type="grantNumber">01KD2104C</rs>; <rs type="projectName">CAMINO</rs>, <rs type="grantNumber">01EO2101</rs>; SWAG, <rs type="grantNumber">01KD2215A</rs>; <rs type="projectName">TRANSFORM LIVER</rs>, <rs type="grantNumber">031L0312A</rs>; <rs type="projectName">TANGERINE</rs>, <rs type="grantNumber">01KT2302</rs> through <rs type="projectName">ERA-NET Transcan</rs>; Come2Data, <rs type="grantNumber">16DKZ2044A</rs>; <rs type="grantNumber">DEEP-HCC</rs>, <rs type="grantNumber">031L0315A</rs>), the <rs type="funder">German Academic Exchange Service</rs> (<rs type="projectName">SECAI</rs>, <rs type="grantNumber">57616814</rs>), the <rs type="funder">German Federal Joint Committee (TransplantKI</rs>, <rs type="grantNumber">01VSF21048</rs>) the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon Europe and innovation programme</rs> (<rs type="projectName">ODELIA</rs>, <rs type="grantNumber">101057091</rs>; <rs type="projectName">GENIAL</rs>, <rs type="grantNumber">101096312</rs>), the <rs type="funder">European Research Council (ERC</rs>; <rs type="projectName">NADIR</rs>, <rs type="grantNumber">101114631</rs>), the <rs type="funder">National Institutes of Health (EPICO</rs>, <rs type="grantNumber">R01 CA263318</rs>) and the <rs type="funder">National Institute for Health and Care Research (NIHR</rs>, <rs type="grantNumber">NIHR203331</rs>) <rs type="funder">Leeds Biomedical Research Centre</rs>.</s><s xml:id="_eSkmJSb">D.T. is funded by the <rs type="funder">German Federal Ministry of Education and Research (TRANSFORM LIVER</rs>, <rs type="grantNumber">031L0312A</rs>), the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon Europe and innovation programme</rs> (<rs type="projectName">ODELIA</rs>, <rs type="grantNumber">101057091</rs>), and the <rs type="funder">German Federal Ministry of Health</rs> (SWAG, <rs type="grantNumber">01KD2215B</rs>).</s></p></div>
			</div>
			<div type="funding">
<div><head xml:id="_bdQVguM">Funding</head><p xml:id="_c5wFJYw"><s xml:id="_KPfBNF7">Open Access funding enabled and organized by <rs type="funder">Projekt DEAL</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_PY9KxER">
					<idno type="grant-number">70115166</idno>
					<orgName type="project" subtype="full">DECADE</orgName>
				</org>
				<org type="funded-project" xml:id="_ryRREjj">
					<idno type="grant-number">01KD2104C</idno>
					<orgName type="project" subtype="full">CAMINO</orgName>
				</org>
				<org type="funding" xml:id="_egPkWpr">
					<idno type="grant-number">01EO2101</idno>
				</org>
				<org type="funded-project" xml:id="_kdJ7sAH">
					<idno type="grant-number">01KD2215A</idno>
					<orgName type="project" subtype="full">TRANSFORM LIVER</orgName>
				</org>
				<org type="funded-project" xml:id="_TpWQYzj">
					<idno type="grant-number">031L0312A</idno>
					<orgName type="project" subtype="full">TANGERINE</orgName>
				</org>
				<org type="funded-project" xml:id="_WAwrKty">
					<idno type="grant-number">01KT2302</idno>
					<orgName type="project" subtype="full">ERA-NET Transcan</orgName>
				</org>
				<org type="funding" xml:id="_SchgREt">
					<idno type="grant-number">16DKZ2044A</idno>
				</org>
				<org type="funding" xml:id="_dFzpk4P">
					<idno type="grant-number">DEEP-HCC</idno>
				</org>
				<org type="funded-project" xml:id="_vhtKRbz">
					<idno type="grant-number">031L0315A</idno>
					<orgName type="project" subtype="full">SECAI</orgName>
				</org>
				<org type="funding" xml:id="_QqZZFAN">
					<idno type="grant-number">57616814</idno>
				</org>
				<org type="funded-project" xml:id="_ChZmfPW">
					<idno type="grant-number">01VSF21048</idno>
					<orgName type="project" subtype="full">ODELIA</orgName>
					<orgName type="program" subtype="full">Horizon Europe and innovation programme</orgName>
				</org>
				<org type="funded-project" xml:id="_G29SHCC">
					<idno type="grant-number">101057091</idno>
					<orgName type="project" subtype="full">GENIAL</orgName>
				</org>
				<org type="funded-project" xml:id="_yDFbkep">
					<idno type="grant-number">101096312</idno>
					<orgName type="project" subtype="full">NADIR</orgName>
				</org>
				<org type="funding" xml:id="_VZrwTRA">
					<idno type="grant-number">101114631</idno>
				</org>
				<org type="funding" xml:id="_VFFE8vf">
					<idno type="grant-number">R01 CA263318</idno>
				</org>
				<org type="funding" xml:id="_DjvXBwf">
					<idno type="grant-number">NIHR203331</idno>
				</org>
				<org type="funding" xml:id="_uffZ4jC">
					<idno type="grant-number">031L0312A</idno>
				</org>
				<org type="funded-project" xml:id="_GkfGkh5">
					<idno type="grant-number">101057091</idno>
					<orgName type="project" subtype="full">ODELIA</orgName>
					<orgName type="program" subtype="full">Horizon Europe and innovation programme</orgName>
				</org>
				<org type="funding" xml:id="_VdbxtS5">
					<idno type="grant-number">01KD2215B</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_a9DwWrk">Data availability</head><p xml:id="_fQzHPTh"><s xml:id="_24wdEWN">Source data containing the evaluation dataset can be found at <ref type="url" target="https://drive.google.com/drive/folders/1-0MpygM3nG1hTHgZPBMmQnbv6y8p-LPH">https://drive.  google.com/drive/folders/1-0MpygM3nG1hTHgZPBMmQnbv6y8p-LPH</ref>.</s><s xml:id="_FSQVpzK">Additional data related to this paper, such as the detailed reader test data, may be requested from the authors.</s></p><p xml:id="_nNg6pKP"><s xml:id="_eTqgk2W"><ref type="url" target="https://doi.org/10.1038/s41746-024-01282-7">https://doi.org/10.1038/s41746-024-01282-7</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cupy2NX">Code availability</head><p xml:id="_4cqsWeN"><s xml:id="_Ytjqp4G">Details of the implementation, as well as the full code producing the results of this paper, are made publicly available under <ref type="url" target="https://github.com/peterhan91/FM_ADV">https://github.com/  peterhan91/FM_ADV</ref>.</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hdRxWYn">Author contributions</head><p xml:id="_DBjPYPw"><s xml:id="_SnumSd4">T.H., J.N.K, and D.T. devised the concept of the study.</s><s xml:id="_pkQxMCF">D.T. performed the reader tests.</s><s xml:id="_5bf5tSg">T.H. wrote the code and performed the accuracy studies.</s><s xml:id="_QhSBN6W">T.H. and D.T. did the statistical analysis.</s><s xml:id="_A9dxNAx">T.H., D.T., S.N., and J.N.K. wrote the first draft of the manuscript.</s><s xml:id="_GZKhDsD">F.K., T.W., G.M.F, C.K., S.F., J.K., C.H., and K.K.B. contributed to correcting the manuscript.</s><s xml:id="_S73k8Gk">All authors have read and approved the manuscript.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_WNAgm2F">Competing interests</head><p xml:id="_HEa57RA"><s xml:id="_7SXKYQD">J.N.K. declares consulting services for Owkin, France; DoMore Diagnostics, Norway; Panakeia, UK, and Scailyte, Basel, Switzerland; furthermore J.N.K. holds shares in Kather Consulting, Dresden, Germany; and StratifAI GmbH, Dresden, Germany, and has received honoraria for lectures and advisory board participation by AstraZeneca, Bayer, Eisai, MSD, BMS, Roche, Pfizer and Fresenius.</s><s xml:id="_U9Qm9cx">D.T. received honoraria for lectures by Bayer and holds shares in StratifAI GmbH, Germany.</s><s xml:id="_eymyY2Z">The remaining authors declare no competing interests.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7u8RdWa">Additional information</head><p xml:id="_5U6pUDP"><s xml:id="_Js3gAqF">Supplementary information The online version contains supplementary material available at <ref type="url" target="https://doi.org/10.1038/s41746-024-01282-7">https://doi.org/10.1038/s41746-024-01282-7</ref>.</s></p><p xml:id="_TfycGsS"><s xml:id="_MxxNuAN">Correspondence and requests for materials should be addressed to Tianyu Han or Daniel Truhn.</s></p><p xml:id="_3xu4wnG"><s xml:id="_DbVh6RJ">Reprints and permissions information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/reprints</ref></s><s xml:id="_zXS94Ma">Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p><p xml:id="_eRqDkhc"><s xml:id="_KZ5HgNk">Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made.</s><s xml:id="_E5AzX3k">The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material.</s><s xml:id="_uuFKsXG">If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</s><s xml:id="_mZsKQh4">To view a copy of this licence, visit <ref type="url" target="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ref>.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main" xml:id="_ER4eeXd">On the opportunities and risks of foundation models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Bommasani, R. et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_tDdCgj5">Foundation models for generalist medical artificial intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2tCYPa6">Nature</title>
		<imprint>
			<biblScope unit="volume">616</biblScope>
			<biblScope unit="page" from="259" to="265" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moor, M. et al. Foundation models for generalist medical artificial intelligence. Nature 616, 259-265 (2023).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_YkvR7zv">Health system-scale language models are allpurpose prediction engines</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-023-06160-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Btqb3zg">Nature</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="357" to="362" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jiang, L. Y. et al. Health system-scale language models are all- purpose prediction engines. Nature 1-6, 357-362 (2023).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_aSgS5pg">Using cognitive psychology to understand gpt-3</title>
		<author>
			<persName><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2218523120</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VmpTjze">Proc. Natl Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page">2218523120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Binz, M. &amp; Schulz, E. Using cognitive psychology to understand gpt-3. Proc. Natl Acad. Sci. 120, e2218523120 (2023).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_vRnTs7h">Catalyzing next-generation artificial intelligence through neuroai</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zador</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eXw9jxX">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1597</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zador, A. et al. Catalyzing next-generation artificial intelligence through neuroai. Nat. Commun. 14, 1597 (2023).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_bUe5mhb">The debate over understanding in ai&apos;s large language models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Krakauer</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2215907120</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_277avum">Proc. Natl Acad. Sci</title>
		<meeting>Natl Acad. Sci</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page">2215907120</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Mitchell, M. &amp; Krakauer, D. C. The debate over understanding in ai&apos;s large language models. Proc. Natl Acad. Sci. 120, e2215907120 (2023).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main" xml:id="_nXZRKNF">Foundation models for decision making: Problems, methods, and opportunities</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.04129</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Yang, S. et al. Foundation models for decision making: Problems, methods, and opportunities. arXiv preprint arXiv:2303.04129 (2023).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.09419</idno>
		<title level="m" xml:id="_zdS6cK9">A comprehensive survey on pretrained foundation models: A history from bert to chatgpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Zhou, C. et al. A comprehensive survey on pretrained foundation models: A history from bert to chatgpt. arXiv preprint arXiv:2302.09419 (2023).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_gsX5aqJ">Towards artificial general intelligence via a multimodal foundation model</title>
		<author>
			<persName><forename type="first">N</forename><surname>Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jrKVk6v">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">3094</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fei, N. et al. Towards artificial general intelligence via a multimodal foundation model. Nat. Commun. 13, 3094 (2022).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_KB8Snnx">Expert-level detection of pathologies from unannotated chest x-ray images via self-supervised learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wVHUkMS">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1399" to="1406" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tiu, E. et al. Expert-level detection of pathologies from unannotated chest x-ray images via self-supervised learning. Nat. Biomed. Eng. 6, 1399-1406 (2022).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_yfv2Jyh">Self-supervised learning in medicine and healthcare</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uZWZPwZ">Nat. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1346" to="1352" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Krishnan, R., Rajpurkar, P. &amp; Topol, E. J. Self-supervised learning in medicine and healthcare. Nat. Biomed. Eng. 6, 1346-1352 (2022).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_cshXdCx">Single-sequence protein structure prediction using a language model and deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chowdhury</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41587-022-01432-w</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WaYaZMC">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1617" to="1623" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chowdhury, R. et al. Single-sequence protein structure prediction using a language model and deep learning. Nat. Biotechnol. 40, 1617-1623 (2022).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_QnbRAMt">Genome-wide prediction of disease variant effects with a deep protein language model</title>
		<author>
			<persName><forename type="first">N</forename><surname>Brandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ntranos</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41588-023-01465-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TZJQ6rE">Nature Gen</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="1512" to="1522" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brandes, N., Goldman, G., Wang, C. H., Ye, C. J. &amp; Ntranos, V. Genome-wide prediction of disease variant effects with a deep protein language model. Nature Gen. 55, 1512-1522 (2023).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_8Gd4XVp">scbert as a large-scale pretrained deep language model for cell type annotation of single-cell rna-seq data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xj9CztE">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="852" to="866" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang, F. et al. scbert as a large-scale pretrained deep language model for cell type annotation of single-cell rna-seq data. Nat. Mach. Intell. 4, 852-866 (2022).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_qfuspJx">Large language models generate functional protein sequences across diverse families</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6AGxBGH">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1099" to="1106" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Madani, A. et al. Large language models generate functional protein sequences across diverse families. Nat. Biotechnol. 41, 1099-1106 (2023).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main" xml:id="_6hxgkXb">Sparks of artificial general intelligence: Early experiments with gpt-4</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.12712</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Bubeck, S. et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712 (2023).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_Rds7V3P">The current and future state of ai interpretation of medical images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UZc8QdT">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="1981" to="1990" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajpurkar, P. &amp; Lungren, M. P. The current and future state of ai interpretation of medical images. N. Engl. J. Med. 388, 1981-1990 (2023).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_BfgwBVD">An opinion on chatgpt in health care-written by humans only</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleesiek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stiglic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DN4zveK">J. Nucl. Med</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="701" to="703" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kleesiek, J., Wu, Y., Stiglic, G., Egger, J. &amp; Bian, J. An opinion on chatgpt in health care-written by humans only. J. Nucl. Med. 64(5), 701-703 (2023).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_TQ7fxnW">Large language models in medicine</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Thirunavukarasu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_emmzggm">Nature Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1930" to="1940" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thirunavukarasu, A. J. et al. Large language models in medicine. Nature Med. 29, 1930-1940 (2023).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_Pxx7H8V">Large language models encode clinical knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_w4d6XSG">Nature</title>
		<imprint>
			<biblScope unit="volume">620</biblScope>
			<biblScope unit="page" from="172" to="180" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Singhal, K. et al. Large language models encode clinical knowledge. Nature 620, 172-180 (2023).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_wT57vrZ">Explaining machine learning models with interactive natural language conversations using talktomodel</title>
		<author>
			<persName><forename type="first">D</forename><surname>Slack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-023-00692-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RW7Qftk">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="873" to="883" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Slack, D., Krishna, S., Lakkaraju, H. &amp; Singh, S. Explaining machine learning models with interactive natural language conversations using talktomodel. Nat. Mach. Intell. 5, 873-883 (2023).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Achiam, J. et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_HThAZv6">Breaking medical data sharing boundaries by using synthesized radiographs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1126/sciadv.abb7973</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eFedWdm">Sci. Adv</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7973</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Han, T. et al. Breaking medical data sharing boundaries by using synthesized radiographs. Sci. Adv. 6, eabb7973 (2020).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_yJ9Htxr">Secure, privacy-preserving and federated machine learning in medical imaging</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Kaissis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Makowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rückert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Braren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2qeu5fc">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="305" to="311" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kaissis, G. A., Makowski, M. R., Rückert, D. &amp; Braren, R. F. Secure, privacy-preserving and federated machine learning in medical imaging. Nat. Mach. Intell. 2, 305-311 (2020).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_wtrQ3kA">Parameter-efficient fine-tuning of large-scale pretrained language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ding</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-023-00626-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HzYEqCG">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="220" to="235" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ding, N. et al. Parameter-efficient fine-tuning of large-scale pre- trained language models. Nat. Mach. Intell. 5, 220-235 (2023).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_k9pqE56">Chatgpt: five priorities for research</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Van Dis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuidema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Rooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Bockting</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-023-00288-7</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9NeXS7K">Nature</title>
		<imprint>
			<biblScope unit="volume">614</biblScope>
			<biblScope unit="page" from="224" to="226" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Van Dis, E. A., Bollen, J., Zuidema, W., van Rooij, R. &amp; Bockting, C. L. Chatgpt: five priorities for research. Nature 614, 224-226 (2023).</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main" xml:id="_EyEKjQ2">Medalpaca-an open-source collection of medical conversational ai models and training data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.08247</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Han, T. et al. Medalpaca-an open-source collection of medical conversational ai models and training data. arXiv preprint arXiv:2304.08247 (2023).</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">W.-L</forename><surname>Chiang</surname></persName>
		</author>
		<idno type="DOI">10.1093/oed/1797521204</idno>
		<ptr target="https://lmsys.org/blog/2023-03-30-vicuna/" />
		<title level="m" xml:id="_wbzqnnT">An open-source chatbot impressing gpt-4 with 90% chatgpt quality</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chiang, W.-L. et al. Vicuna: An open-source chatbot impressing gpt-4 with 90% chatgpt quality. https://lmsys.org/blog/2023-03-30- vicuna/ (2023).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_sBWFBmX">Large language models should be used as scientific reasoning engines, not knowledge databases</title>
		<author>
			<persName><forename type="first">D</forename><surname>Truhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Reis-Filho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Kather</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_M8YwCep">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2983" to="2984" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Truhn, D., Reis-Filho, J. S. &amp; Kather, J. N. Large language models should be used as scientific reasoning engines, not knowledge databases. Nat. Med. 29, 2983-2984 (2023).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_WnTPFNB">Multimodal large language models are generalist medical image interpreters</title>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.12.21.23300146</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AtUqMty">medRxiv</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2035" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Han, T. et al. Multimodal large language models are generalist medical image interpreters. medRxiv 2023-12 (2023).</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_vvXFjbe">Comparative analysis of multimodal large language model performance on clinical vignette questions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RkQ4Jy9">JAMA</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="1320" to="1321" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Han, T. et al. Comparative analysis of multimodal large language model performance on clinical vignette questions. JAMA 331, 1320-1321 (2024).</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_SGaSd9w">Gpt-4 for information retrieval and comparison of medical oncology guidelines</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ferber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mtDWpJE">NEJM AI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2300235</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ferber, D. et al. Gpt-4 for information retrieval and comparison of medical oncology guidelines. NEJM AI 1, AIcs2300235 (2024).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main" xml:id="_VrgfFp5">Autonomous artificial intelligence agents for clinical decision making in oncology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ferber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.04667</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Ferber, D. et al. Autonomous artificial intelligence agents for clinical decision making in oncology. arXiv preprint arXiv:2404.04667 (2024).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main" xml:id="_pHwyKAq">Jailbreakbench: An open robustness benchmark for jailbreaking large language models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.01318</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Chao, P. et al. Jailbreakbench: An open robustness benchmark for jailbreaking large language models. arXiv preprint arXiv:2404.01318 (2024).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_GsUmkTR">Jailbroken: How does llm safety training fail?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Haghtalab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6QT6rdk">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wei, A., Haghtalab, N. &amp; Steinhardt, J. Jailbroken: How does llm safety training fail? Adv. Neural Inf. Process. Syst. 36 (2024).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_ADEbfQT">Acetaminophen-induced hepatotoxicity: a comprehensive update</title>
		<author>
			<persName><forename type="first">E</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Babar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Choudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kutner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pyrsopoulos</surname></persName>
		</author>
		<idno type="DOI">10.14218/jcth.2015.00052</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MFRKP3W">J. Clin. Transl. Hepatol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">131</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yoon, E., Babar, A., Choudhary, M., Kutner, M. &amp; Pyrsopoulos, N. Acetaminophen-induced hepatotoxicity: a comprehensive update. J. Clin. Transl. Hepatol. 4, 131 (2016).</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_sD4vV5e">Aspirin as a risk factor in reye&apos;s syndrome</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Waldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Amburg</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.1982.03320470035029</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Q8TUhfw">Jama</title>
		<imprint>
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="page" from="3089" to="3094" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Waldman, R. J., Hall, W. N., McGee, H. &amp; Van Amburg, G. Aspirin as a risk factor in reye&apos;s syndrome. Jama 247, 3089-3094 (1982).</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_RJkx8kk">Cardioprotection with beta-blockers: myths, facts and pascal&apos;s wager</title>
		<author>
			<persName><forename type="first">F</forename><surname>Messerli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinberg</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1365-2796.2009.02140.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6tTKYTu">J. Intern. Med</title>
		<imprint>
			<biblScope unit="volume">266</biblScope>
			<biblScope unit="page" from="232" to="241" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Messerli, F., Bangalore, S., Yao, S. &amp; Steinberg, J. Cardioprotection with beta-blockers: myths, facts and pascal&apos;s wager. J. Intern. Med. 266, 232-241 (2009).</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_v2G5xqv">Transformer feedforward layers are key-value memories</title>
		<author>
			<persName><forename type="first">M</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.446</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.446" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_3BxVmtp">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5484" to="5495" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics, Online and</note>
	<note type="raw_reference">Geva, M., Schuster, R., Berant, J. &amp; Levy, O. Transformer feed- forward layers are key-value memories. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 5484-5495 (Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 2021). https://aclanthology.org/ 2021.emnlp-main.446.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_5PazU5y">Locating and editing factual associations in gpt</title>
		<author>
			<persName><forename type="first">K</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Belinkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_B2DPaNm">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="17359" to="17372" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meng, K., Bau, D., Andonian, A. &amp; Belinkov, Y. Locating and editing factual associations in gpt. Adv. Neural Inf. Process. Syst. 35, 17359-17372 (2022).</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08415</idno>
		<title level="m" xml:id="_fwd59Y9">Gaussian error linear units (gelus)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Hendrycks, D. &amp; Gimpel, K. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415 (2016).</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main" xml:id="_rESNQsX">Advancing open-source large language models for healthcare and life sciences</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ankit Pal</surname></persName>
		</author>
		<author>
			<persName><surname>Openbiollms</surname></persName>
		</author>
		<ptr target="https://huggingface.co/aaditya/OpenBioLLM-Llama3-70B" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ankit Pal, M. S. Openbiollms: Advancing open-source large language models for healthcare and life sciences. https://huggingface.co/ aaditya/OpenBioLLM-Llama3-70B (2024).</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_b5RvEWC">What disease does this patient have? a large-scale open domain question answering dataset from medical exams</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KCPx4r2">Appl. Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">6421</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jin, D. et al. What disease does this patient have? a large-scale open domain question answering dataset from medical exams. Appl. Sci. 11, 6421 (2021).</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main" xml:id="_SxZNfWM">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_uJwKaaT">Domain-specific language model pretraining for biomedical natural language processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3458754</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mNDr5D4">ACM Trans. Comput. Healthc. (HEALTH)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gu, Y. et al. Domain-specific language model pretraining for biomedical natural language processing. ACM Trans. Comput. Healthc. (HEALTH) 3, 1-23 (2021).</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main" xml:id="_4yfAuGy">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-024-01282-7</idno>
		<ptr target="https://doi.org/10.1038/s41746-024-01282-7" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Radford, A. et al. Language models are unsupervised multitask learners (2019). https://doi.org/10.1038/s41746-024-01282-7</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_A7BEqbn">Poisoning web-scale training datasets is practical</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<idno type="DOI">10.1109/sp54263.2024.00179</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_WucDDmS">Proc. 2024 IEEE Symposium on Security and Privacy (SP)</title>
		<meeting>2024 IEEE Symposium on Security and Privacy (SP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="407" to="425" />
		</imprint>
	</monogr>
	<note type="raw_reference">Carlini, N. et al. Poisoning web-scale training datasets is practical. In Proc. 2024 IEEE Symposium on Security and Privacy (SP) 407-425 (IEEE, 2024).</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main" xml:id="_FQDT4SA">A comprehensive study of knowledge editing for large language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.01286</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Zhang, N. et al. A comprehensive study of knowledge editing for large language models. arXiv preprint arXiv:2401.01286 (2024).</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main" xml:id="_TfGUBKk">Universal and transferable adversarial attacks on aligned language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.15043</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Zou, A., Wang, Z., Kolter, J. Z. &amp; Fredrikson, M. Universal and transferable adversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043 (2023).</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_VhTRWhe">The impact of chatgpt and llms on medical imaging stakeholders: perspectives and use cases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.metrad.2023.100007</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rpCBajz">Meta-Radiology</title>
		<imprint>
			<biblScope unit="page">100007</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang, J., Li, H. B. &amp; Wei, D. The impact of chatgpt and llms on medical imaging stakeholders: perspectives and use cases. Meta-Radiology 100007 (2023).</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main" xml:id="_DZzkdbP">your falsehood radar: Rag-augmented reasoning for political factchecking using multimodal large language models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Khaliq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Miletić</surname></persName>
		</author>
		<author>
			<persName><surname>Ragar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.12065</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Khaliq, M. A., Chang, P., Ma, M., Pflugfelder, B. &amp; Miletić, F. Ragar, your falsehood radar: Rag-augmented reasoning for political fact- checking using multimodal large language models. arXiv preprint arXiv:2404.12065 (2024).</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_KBFRzN2">Adversarial attacks on medical machine learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Finlayson</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aaw4399</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tt4N2Gr">Science</title>
		<imprint>
			<biblScope unit="volume">363</biblScope>
			<biblScope unit="page" from="1287" to="1289" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Finlayson, S. G. et al. Adversarial attacks on medical machine learning. Science 363, 1287-1289 (2019).</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_R4RMzAx">Large pre-trained language models contain human-like biases of what is right and wrong to do</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schramowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Turan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Rothkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9MRpNNT">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="258" to="268" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Schramowski, P., Turan, C., Andersen, N., Rothkopf, C. A. &amp; Kersting, K. Large pre-trained language models contain human-like biases of what is right and wrong to do. Nat. Mach. Intell. 4, 258-268 (2022).</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_Eqxs78A">Massediting memory in a transformer</title>
		<author>
			<persName><forename type="first">K</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bau</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=MkbcAHIYgyS" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_TzZQh4u">Proc. The Eleventh International Conference on Learning Representations</title>
		<meeting>The Eleventh International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meng, K., Sharma, A. S., Andonian, A., Belinkov, Y. &amp; Bau, D. Mass- editing memory in a transformer. In Proc. The Eleventh International Conference on Learning Representations https://openreview.net/ forum?id=MkbcAHIYgyS (2023).</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_XMWb7yb">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJzIBfZAb" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_BA7KB5C">Proc. International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Madry, A., Makelov, A., Schmidt, L., Tsipras, D. &amp; Vladu, A. Towards deep learning models resistant to adversarial attacks. In Proc. International Conference on Learning Representations https:// openreview.net/forum?id=rJzIBfZAb (2018).</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_me2mYjz">Advancing diagnostic performance and clinical usability of neural networks via adversarial training and dual batch normalization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-24464-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zgvbszQ">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">4315</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Han, T. et al. Advancing diagnostic performance and clinical usability of neural networks via adversarial training and dual batch normalization. Nat. Commun. 12, 4315 (2021).</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<title level="m" xml:id="_tPcFTJk">Llama 2: Open foundation and fine-tuned chat models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Touvron, H. et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.16079</idno>
		<title level="m" xml:id="_NRR5HsC">Meditron-70b: Scaling medical pretraining for large language models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Chen, Z. et al. Meditron-70b: Scaling medical pretraining for large language models. arXiv preprint arXiv:2311.16079 (2023).</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main" xml:id="_Fqy7QnN">The Pile: An 800gb dataset of diverse text for language modeling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00027</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Gao, L. et al. The Pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027 (2020).</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Komatsuzaki</surname></persName>
		</author>
		<ptr target="https://github.com/kingoflolz/mesh-transformer-jax" />
		<title level="m" xml:id="_qDEvva5">GPT-J-6B: A 6 Billion parameter autoregressive language model</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang, B. &amp; Komatsuzaki, A. GPT-J-6B: A 6 Billion parameter autoregressive language model. https://github.com/kingoflolz/mesh- transformer-jax (2021).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
