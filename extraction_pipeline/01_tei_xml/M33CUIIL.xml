<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_Cu8WTtU">The imperative for regulatory oversight of large language models (or generative AI) in healthcare</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bertalan</forename><surname>Mesk√≥</surname></persName>
							<idno type="ORCID">0000-0002-7005-7083</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> The Medical Futurist Institute , Budapest , Hungary.</note>
								<orgName type="institution">The Medical Futurist Institute</orgName>
								<address>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Department of Behavioural Sciences , Semmelweis University , Budapest , Hungary.</note>
								<orgName type="department">Department of Behavioural Sciences</orgName>
								<orgName type="institution">Semmelweis University</orgName>
								<address>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
							<idno type="ORCID">0000-0002-1478-4729</idno>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Scripps Research Translational Institute , Scripps Research , La Jolla , CA , USA.</note>
								<orgName type="institution" key="instit1">Scripps Research Translational Institute</orgName>
								<orgName type="institution" key="instit2">Scripps Research</orgName>
								<address>
									<settlement>La Jolla</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_4xyyvS9">The imperative for regulatory oversight of large language models (or generative AI) in healthcare</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3B465C54C2F8CA90D56A89A342D7E5C1</idno>
					<idno type="DOI">10.1038/s41746-023-00873-0</idno>
					<note type="submission">Received: 7 April 2023; Accepted: 26 June 2023;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T10:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_cWkHNNs"><p xml:id="_K3pRJWu"><s xml:id="_GDXuMuQ">The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard.</s><s xml:id="_yw38uny">The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns.</s><s xml:id="_EZrt8G6">While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AIbased medical technologies that are regulated already, especially within the critical context of caring for patients.</s><s xml:id="_UTVGJuw">The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level.</s><s xml:id="_ZKGBGNQ">Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images.</s><s xml:id="_XXWMQQC">The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy.</s><s xml:id="_bEpGrwk">We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy.</s><s xml:id="_gmbYCcs">This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_6T5h7Qv">INTRODUCTION</head><p xml:id="_EbeWbaT"><s xml:id="_cUEUSGZ">The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLM) such as OpenAI's GPT-4 and Google's Bard <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2</ref> .</s><s xml:id="_fdwk49f">The unprecedented popularity of ChatGPT, GPT-4's predecessor released in November 2022, is reflected by the most rapid uptake of users -100 million in 2 months -for any new technology.</s></p><p xml:id="_BFYTyMS"><s xml:id="_rUCKAR2">This rapid growth sparked global debates about the role such conversational chatbots could play in healthcare and the practice of medicine.</s><s xml:id="_UqfUrEC">Diverse applications of LLMs have appeared including facilitating clinical documentation; creating discharge summaries; generating clinic, operation, and procedure notes; obtaining insurance pre-authorization; summarizing research papers; or working as a chatbot to answer questions for the patients with their specific data and concerns.</s><s xml:id="_YcPAMjF">LLMs can also assist physicians in diagnosing conditions based on medical records, images, laboratory results, and suggest treatment options or plans.</s><s xml:id="_BB65jth">At the same time, patients can potentially become more autonomous than with prior search methods by obtaining individualized assessment of their data, symptoms, and concerns.</s></p><p xml:id="_2sc4CRY"><s xml:id="_X2R3Jp7">Systematic reviews highlighted other potential benefits too such as improved scientific writing, enhancing research equity, streamlining the healthcare workflow, cost saving, and improved personalized learning in medical education <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4</ref> .</s></p><p xml:id="_TA7THah"><s xml:id="_F9kCUXD">Given the potential implications on patient outcomes and public health, it is imperative to consider how these new AI-based tools should be regulated.</s><s xml:id="_dNXNdtZ">The regulation of these LLMs in medicine and healthcare without damaging their promising progress is a timely and critical challenge to ensure safety, maintain ethical standards, pre-empt unfairness and bias, and protect patient privacy.</s><s xml:id="_f4JKKh3">Whatever concerns have been previously recognized with AI are now markedly amplified with the multipotency of LLMs.</s></p><p xml:id="_pXkbQ3t"><s xml:id="_RdVXCwT">This paper explores the potential risks and benefits of applying LLMs in healthcare settings and argues for the necessity of regulating LLMs differently than AI-based medical technologies that are already on the market to mitigate potential harm and maintain public trust in these breakthrough technologies.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_97pQjzs">LLMS DIFFER FROM ALREADY REGULATED AI-BASED TECHNOLOGIES</head><p xml:id="_VsU83YZ"><s xml:id="_X5Pc7Z3">LLMs differ significantly from prior deep learning methods in terms of their scale, capabilities, and potential impact.</s><s xml:id="_pcpV6Vp">Here we outline the key characteristics of LLMs that set them apart from traditional deep learning techniques.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_PBrRXXT">Scale and complexity</head><p xml:id="_q37YjjQ"><s xml:id="_fBbpfUr">LLMs are trained on massive datasets and utilize billions of parameters, resulting in unprecedented complexity.</s><s xml:id="_gXPK2GN">This level of sophistication requires regulatory oversight that takes into account the challenges associated with interpretability, fairness, and unintended consequences.</s><s xml:id="_wweCJX9">Moreover, LLMs use tokens that can be words, subwords, or even characters as the smallest units of text used to represent and process language during the training and generation processes.</s><s xml:id="_fED5wSK">Tokenization is a crucial step in natural language processing (NLP) and allows LLMs to efficiently analyze and generate text, as these models are designed to process sequences of tokens rather than entire sentences or paragraphs.</s><s xml:id="_ue2DexS">Currently, tokenization is not covered by healthcare regulators.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_UGFTFkn">Hardware requirements</head><p xml:id="_PQwhhhJ"><s xml:id="_2KHh76v">LLMs require massive computational resources in terms of floating-point operations per second (FLOPs) and graphics processing unit (GPU) usage compared to previous deep learning models due to their large scale, extensive training data, a type of neural network model designed for NLP tasks called the Transformer architecture, and the need for fine-tuning.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_FYjMBQd">Broad applicability</head><p xml:id="_2B44zC7"><s xml:id="_FqQmnSS">Unlike specialized deep learning models that were trained to address a specific medical issue or clinical need, LLMs possess versatile capabilities that span various domains, such as healthcare, finance, and education.</s><s xml:id="_PUMXvv4">As a result, a one-size-fits-all regulatory framework is ill-suited for LLMs, and oversight must be adaptable to address diverse industry-specific concerns.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_QhPftKG">Real-time adaptation</head><p xml:id="_pQM4vbM"><s xml:id="_9q7afBw">LLMs can adapt their responses in real-time, based on user input and evolving contexts.</s><s xml:id="_UrSeDYT">This dynamic behavior demands that regulatory oversight incorporates continuous monitoring and evaluation mechanisms to ensure responsible usage and adherence to ethical guidelines.</s><s xml:id="_HZ5v2tB">This is similar to what adaptive AI-based medical technologies would require from regulators.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_svn52UX">Societal impact</head><p xml:id="_B8dAJEJ"><s xml:id="_HSW9bg4">The widespread adoption of LLMs has the potential to fundamentally transform various aspects of society.</s><s xml:id="_5Rr9b8g">Consequently, regulatory oversight must address not only the technical aspects of LLMs but also their broader ethical, social, and economic implications.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_X9RKhZu">Data privacy and security</head><p xml:id="_GSAd8Fe"><s xml:id="_mKFfYEj">LLMs' reliance on extensive training data raises concerns related to data privacy and security.</s><s xml:id="_BGSjgKd">Regulatory oversight should establish robust frameworks to protect sensitive information and prevent unauthorized access or misuse of these powerful models.</s></p><p xml:id="_pxcnpJj"><s xml:id="_wtBCfTJ">These unique characteristics of LLMs necessitate a tailored approach to regulatory oversight.</s><s xml:id="_k9zMQnY">Such an approach must be adaptive, holistic, and cognizant of the diverse challenges and potential consequences that LLMs present, ensuring their responsible and ethical use across various domains.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_8DFFB4x">THE FDA'S PRE-LLM OVERSIGHT OF AI</head><p xml:id="_RFDDFbD"><s xml:id="_97Eegy6">The United States' Food And Drug Administration (FDA) has been leading the global discussions on regulatory oversight and has been a prominent example in providing regulations about emerging technologies from 3D printed medications to AI-based medical tools <ref type="bibr" target="#b4">5</ref> .</s></p><p xml:id="_64gjQxD"><s xml:id="_tqkUpTX">With the increasing adoption of digital health technologies, the FDA started regulating Software as a Medical Device (SaMD) that refers to software solutions that perform medical functions and are used in the prevention, diagnosis, treatment, or monitoring of various diseases or conditions.</s></p><p xml:id="_z8ztrMZ"><s xml:id="_cBqHyVe">As a continuation of that approach, the FDA has been adapting its regulatory framework to specifically address AI and machine learning (ML) technologies in medical devices <ref type="bibr" target="#b5">6</ref> .</s><s xml:id="_d6r2Ru3">The FDA released a discussion paper that outlined their potential regulatory approach tailored to AI and ML technologies used in medical devices <ref type="bibr" target="#b6">7</ref> .</s><s xml:id="_vrZRJam">The discussion paper proposed a total product lifecycle (TPLC) approach to regulating AI/ML-based SaMD, which focuses on the continuous monitoring and improvement of these technologies throughout their lifespan.</s><s xml:id="_jqT3BR6">The proposed framework also emphasized the importance of transparency, real-world performance monitoring, and clear expectations for modifications and updates to AI/ML algorithms.</s></p><p xml:id="_KvRUk78"><s xml:id="_6EbyFXk">Currently, the FDA does not have specific categories exclusively for AI-based technologies but evaluates them within the existing regulatory framework for medical devices <ref type="bibr" target="#b7">8</ref> .</s><s xml:id="_TUKs4cB">They classify such devices into three main categories based on their level of risk:</s></p><p xml:id="_FZS2QZj"><s xml:id="_CBuAcS8">‚Ä¢ Class I (Low risk): These devices pose the least risk and are subject to general controls, such as registration and listing, labeling, and good manufacturing practices.</s><s xml:id="_AArPFXq">Examples of Class I devices include non-powered surgical instruments and dental floss.</s><s xml:id="_6YsVQMG">Some low-risk AI-based medical technologies may fall under this category, depending on their intended use.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_c9bM8H4">‚Ä¢</head><p xml:id="_enn5mmd"><s xml:id="_qYdpfDG">Class II (Moderate risk): These devices carry a higher level of risk than Class I devices and are subject to both general controls and special controls, such as performance standards, postmarket surveillance, or specific labeling requirements.</s><s xml:id="_mbXWJ74">Examples of Class II devices include infusion pumps, surgical drapes, and powered wheelchairs.</s><s xml:id="_aatBKQS">Many AI-based medical technologies, such as diagnostic imaging systems, may fall under this category.</s></p><p xml:id="_gA7cVQP"><s xml:id="_FDQwsJV">‚Ä¢ Class III (High risk): These devices pose the highest risk and are subject to general controls, special controls, and premarket approval (PMA).</s><s xml:id="_fpRQDSQ">Class III devices often support or sustain human life, are of substantial importance in preventing impairment of human health, or present a potential unreasonable risk of illness or injury.</s><s xml:id="_jhXTzts">Examples of Class III devices include implantable pacemakers, artificial heart valves, and some AI-based technologies used in critical medical decisionmaking.</s></p><p xml:id="_3rcs3dc"><s xml:id="_JEbkYPB">AI-based medical technologies may also be subject to the FDA's Digital Health Software Precertification (Pre-Cert) Program, which is designed to streamline the regulatory process for SaMD, including AI-based technologies.</s></p><p xml:id="_VKeRysN"><s xml:id="_aUqzAem">A milestone in that process was the release of their database of specifically AI-based medical technologies with regulatory approvals in 2021 <ref type="bibr" target="#b8">9</ref> .</s><s xml:id="_GUVS5Ks">As of April, 2023, 521 devices are included in that database.</s><s xml:id="_HRAgzeq">The most popular categories are radiology, cardiovascular and hematology with 392, 57 and 15 devices, respectively.</s><s xml:id="_MJbNc52">The vast majority (96%) were approved with a 510(k) clearance, while 18 (3.5%)</s><s xml:id="_kyvGFfD">received de novo pathway clearance and 3 (0.5%) premarket approval (PMA) clearance.</s></p><p xml:id="_Hn522wE"><s xml:id="_tHe9Sfq">As other papers have pointed out, only a few of these devices were tested in randomized controlled trials (RCTs) trials; and only a limited number of studies have used external validation, prospective evaluation and diverse metrics to explore the full impact of AI in real clinical settings, and the range of assessed use cases has been relatively narrow with no or very little transparency <ref type="bibr" target="#b9">10</ref> .</s></p><p xml:id="_NQvVrqm"><s xml:id="_zpNfjHr">In summary, while there has been progress in regulating AI, the FDA has not been able to solve the regulation of two advanced technological issues that are related but not the same.</s><s xml:id="_AbAk7zZ">One is about regulating adaptive algorithms that can adjust its parameters or behavior based on the input data or its performance on a specific task.</s><s xml:id="_3FsTXRD">This adaptability allows the algorithm to improve its performance over time or respond to changing conditions.</s></p><p xml:id="_gacVUSM"><s xml:id="_2SJ2YPP">The other one is related to the so-called autodidactic function in deep learning.</s><s xml:id="_FPKPrnt">It refers to the ability of a system to teach itself without direct supervision, an approach that often requires unsupervised or self-supervised learning, where the model learns patterns and representations from the input data without relying on labeled examples.</s><s xml:id="_jnSBaUQ">Such an autodidactic deep learning model can discover underlying structures and relationships in the data by optimizing its internal representations without explicit guidance.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_sST34UW">THE LLM ERA IN THE PRACTICE OF MEDICINE</head><p xml:id="_52UkM5C"><s xml:id="_KxdGrmV">To date, no LLM has had pre-training with the corpus of medical information or with millions of patient records, images, lab data, and office visit or bedside conversations.</s><s xml:id="_AwtUAcu">Details about the training of GPT-4, the most advanced LLM that was pubished in March 2023, have not been released.</s><s xml:id="_SmAQqck">Nevertheless, LLMs have transformative potential, with use cases ranging from clinical documentation to providing personalized health plans <ref type="bibr" target="#b10">11</ref> .</s><s xml:id="_F3E795W">Figure <ref type="figure" target="#fig_0">1</ref> describes 10 use cases for medical professionals and 10 for patients.</s></p><p xml:id="_V8B4ENx"><s xml:id="_xV6APzZ">At the same time, the introduction of these models into healthcare leads to the amplification of risks and challenges.</s></p><p xml:id="_63FjMDQ"><s xml:id="_5BwcKjB">It started posing a new challenge to physicians as patients arrive to the meeting with not only responses received after googling their symptoms but also from ChatGPT-like chatbots.</s><s xml:id="_angwVXv">There have been discussions about to what extent ChatGPT can be used for medical research and summarizing peer-reviewed papers when it only provides sources it based its responses on after specifically asking for it.</s><s xml:id="_qUErCSS">Moreover, some of those sources have been reported to be made up <ref type="bibr" target="#b2">3</ref> .</s></p><p xml:id="_ZYgCcSQ"><s xml:id="_9uvUF95">LLMs can sometimes "hallucinate" results, which refers to generating outputs that are not grounded in the input data or factual information.</s><s xml:id="_GhPAQVM">Such misinformation may be related to a diagnosis, treatment, or a recommended test.</s><s xml:id="_zPchNN5">For the uninitiated, such outputs are conveyed with a high level of confidence and could easily be accepted by the prompter as truth-which has the potential to be dangerous.</s><s xml:id="_EH6yYTb">Whether it is due to incomplete or biased training data, its probabilistic nature or the lack of context; it poses a significant risk of providing unreliable or outright false answers in the medical setting that might have serious consequences.</s></p><p xml:id="_CwR8Emy"><s xml:id="_ZjAccSc">Another issue, bias in medicine while using LLMs can affect clinical decision-making, patient outcomes, and healthcare equity.</s><s xml:id="_QXQTXkq">If the training data contains biases, such as underrepresentation of certain demographic groups, overemphasis on specific treatments, or outdated medical practices, LLMs may inadvertently learn and propagate these biases in its outputs.</s><s xml:id="_47vaGH9">Biased outputs from GPT-4 may lead to incorrect diagnoses or suboptimal treatment recommendations, potentially causing harm to patients or delaying appropriate care.</s></p><p xml:id="_Zn457SK"><s xml:id="_vwFUTrf">GPT-4 brings the potentials and the risks to a new level.</s><s xml:id="_GTytecv">It will be able to read texts on images (including physicians' handwritten notes), and analyze the content and context of images.</s><s xml:id="_YzCxpsg">Table <ref type="table" target="#tab_1">1</ref> summarizes the key differences between the previous and the new version regarding healthcare-related and medical prompts.</s><s xml:id="_uXmcPzE">It shows that GPT-3 could handle simple prompts with general queries, while GPT-4 is able to analyze complex, multilevel prompts, and provide more sophisticated results such as case descriptions or research paper summaries.</s></p><p xml:id="_pBv5P2H"><s xml:id="_bzAvwpm">The application of GPT-4 in healthcare raises ethical concerns that warrant a regulatory framework.</s><s xml:id="_CShTkQK">Issues such as transparency, accountability, and fairness need to be addressed to prevent potential ethical lapses.</s><s xml:id="_EhqABa8">For instance, healthcare professionals and patients should be made aware of the AI's involvement in the decision-making process and be provided with explanations for the AI's recommendations.</s></p><p xml:id="_uebNEWT"><s xml:id="_U3wsq4P">Moreover, regulatory oversight can help ensure that AI-driven models do not perpetuate or exacerbate existing healthcare disparities.</s><s xml:id="_VVhXnke">By mandating diverse and representative data sources, regulators can counteract potential biases within the AI's training data, thus promoting fairness in the delivery of healthcare services.</s></p><p xml:id="_wqeDGxW"><s xml:id="_UjGtNfm">The use of GPT-4 and ChatGPT in such environments calls for robust regulations to ensure the confidentiality and security of patient information.</s><s xml:id="_8GvUUFk">This could include specific guidelines for data anonymization, encryption, and secure storage, as well as measures to prevent unauthorized access or misuse of data by third parties.</s></p><p xml:id="_ntHqMhS"><s xml:id="_cUCxJjP">As a sign of wide implementation, medical companies, digital health services and healthcare organizations have already started to implement ChatGPT into their core business.</s><s xml:id="_npQM5xp">Examples include the Microsoft-owned Nuance as they decided to add GPT-4 AI to its medical note-taking tool; and a French startup called Nabla that claimed to be the first to build a tool using GPT-3 to help physicians do their paperwork <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13</ref> .</s></p><p xml:id="_am5qeS9"><s xml:id="_58VhZTS">All these examples and challenges prompt regulatory bodies to not only start regulating LLMs as those models are being deployed, but to regulate them differently that AI-technologies currently on the market.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_33wJdcV">THE REGULATORY CHALLENGES OF LLMS</head><p xml:id="_5wW76ZA"><s xml:id="_brseEeu">Most LLMs have been released globally and no country-specific iterations are available requiring a global approach from regulators.</s><s xml:id="_HhWuCxg">It is also not clear what technical category LLMs will fall into from the regulatory perspective.</s><s xml:id="_QtCAuhz">However, based on the differences between LLMs and prior deep learning methods, a new regulatory category might be needed to address LLM-specific challenges and risks.</s></p><p xml:id="_5FBbpJK"><s xml:id="_JMJaW3U">A regulatory body only has to design regulations for LLMs if either the developers of LLMs make claims that their LLM can be used for a medical purpose; or if LLMs are developed for, adapted, modified or directed toward specifically medical purposes.</s><s xml:id="_6m3kCpF">Even if currently widespread LLMs won't fall into either category, the medical alternatives of LLMs specifically trained on medical data and databases probably will.</s><s xml:id="_TA6Amwe">One prominent example is Med-PaLM that DeepMind and Google researchers have published about.</s><s xml:id="_636PXb9">In that study, authors proposed a framework for human evaluation of model answers along multiple axes including factuality, precision, possible harm, and bias.</s><s xml:id="_2PVcg4W">In addition, using a combination of prompting strategies, their model achieved 67.6% accuracy on the US Medical License Exam questions, surpassing prior state-of-the-art by over 17%.</s><s xml:id="_k56D46y">As human evaluation reveals key gaps in the responses provided by the LLM, they introduced instruction prompt tuning and the resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians.</s><s xml:id="_8FmZcn4">Since then, GPT-4 could achieve an accuracy over 85% on the same exam <ref type="bibr" target="#b13">14</ref> .</s></p><p xml:id="_EP8Rgyw"><s xml:id="_eGAQFKh">With the release of GPT-4 that can analyze not only texts but images, it can be expected that the model will grow to analyze uploaded documents, research papers, hand-written notes, sound, and video in the near future.</s><s xml:id="_7KJeUkG">(Table <ref type="table" target="#tab_0">2</ref>).</s></p><p xml:id="_qwefQP9"><s xml:id="_9Ycfbvk">This underscores the notion that it is not enough to regulate current LLM models as the new iterations with those advanced capabilities can be expected to get implemented at a similar rate of the previous iterations.</s><s xml:id="_Fty79nT">Without taking these future additions into consideration, a regulation that focuses on language models only could miss important updates by the time those updates become widely accessible.</s></p><p xml:id="_Nm9Sere"><s xml:id="_BXr6HAx">Companies with approved devices that decide to implement LLMs into their services face an additional challenge.</s><s xml:id="_dG952XQ">Namely, how will the FDA regulate an AI-based medical technology recently infused with LLM if the technology was already approved for medical uses?</s><s xml:id="_F86Z9kK">Table <ref type="table">3</ref> summarizes the regulatory challenges.</s></p><p xml:id="_HjuFEPz"><s xml:id="_YuBxsb8">There have been proposals about regulating LLMs, although those come from outside healthcare.</s><s xml:id="_rYPT2F7">In a working paper, Hacker et al. suggests a novel terminology to capture the AI value chain by differentiating between developers, deployers, professional and nonprofessional users, as well as recipients of LLM output.</s><s xml:id="_9ShEAV2">Authors also suggested four strategies to ensure that these models are trustworthy and deployed for the benefit of society at large.</s><s xml:id="_FvtKbKK">In details, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency, (ii) risk management, (iii) nondiscrimination provisions, and (iv) content moderation rules <ref type="bibr" target="#b14">15</ref> .</s></p><p xml:id="_CtmjGmB"><s xml:id="_P6MDpyj">M√∂kander at al pointed out that existing auditing procedures fail to address the governance challenges posed by LLMs, and offered three contributions to fill that gap namely 1) establishing the need to develop new auditing procedures that capture the risks posed by LLMs; 2) outlining a blueprint to audit LLMs in feasible and effective ways by drawing on best practices from IT governance and system engineering; and 3) discussing the limitations of the prospect of auditing LLMs at all <ref type="bibr" target="#b15">16</ref> .</s></p><p xml:id="_4h4aWfA"><s xml:id="_Yne4q3J">Such potential solutions could serve as a benchmark for new regulations in healthcare.</s><s xml:id="_xJXGMmF">In either case, regulators and lawmakers need to act fast to keep track with the dynamics of the unprecedented evolution and progress of LLMs.</s></p><p xml:id="_yUA7WXg"><s xml:id="_xWM736r">As a sign of the rising pressure on regulators, in March 2023, a group of prominent computer scientists and technology industry executives such as Elon Musk and Steve Wozniak called for "all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4" <ref type="bibr" target="#b16">17</ref> .</s><s xml:id="_e3hPpxy">Their letter mentioned that "recent months have seen AI labs locked in an out-of-control race to develop and deploy ever more powerful digital minds that no onenot even their creatorscan understand, predict, or reliably control.</s><s xml:id="_cZ8hjz8">This pause should be public and verifiable, and include all  Notable AI experts such as Andrew Ng objected the idea and instead, called for seeking a balance between the huge value AI is creating vs realistic risks.</s><s xml:id="_SYJzqgs">We agree that a moratorium cannot be implemented in practice unless governments step in; and "having governments pause emerging technologies they don't understand is anti-competitive, sets a terrible precedent, and is awful innovation policy" <ref type="bibr" target="#b17">18</ref> .</s></p><p xml:id="_Q8Tt7YM"><s xml:id="_SPUBXNy">To reinforce our concerns, it is worthy of mention that Italy became the first Western country to temporarily block ChatGPT in April 2023 due to privacy concerns and the lack of proper regulation <ref type="bibr" target="#b18">19</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_a7dumRJ">CONCLUSIONS</head><p xml:id="_53pgBGr"><s xml:id="_t9U3JBz">LLMs offer tremendous promise for the future of healthcare, but their use also entails risks and ethical challenges.</s><s xml:id="_gFhw3KQ">By taking a proactive approach to regulation, it is possible to harness the potential of AI-driven technologies like LLMs while minimizing potential harm and preserving the trust of patients and healthcare providers alike.</s></p><p xml:id="_QBzzVfM"><s xml:id="_wxVeJa9">Furthermore, LLMs could also become the first category of AI-based medical technologies that are regulated by implementing patient design, meaning, regulators would finally involve patients on the highest level of decision-making ensuring that these AI tools that are progressing at an incredibly fast pace will be regulated to address real-life clinical and patient needs <ref type="bibr" target="#b19">20</ref> .</s></p><p xml:id="_TB8R7vH"><s xml:id="_nJ68AFa">Here we summarize what we can expect regulators to do about bringing LLMs to the practice of medicine.</s></p><p xml:id="_NQyPrgu"><s xml:id="_4aZnKCZ">-Create a new regulatory category for LLMs as those are distinctively different from AI-based medical technologies that have gone through regulation already.</s><s xml:id="_rSfQdkw">-Provide a regulatory guidance for companies and healthcare organizations about how they can deploy LLMs into their existing products and services.</s><s xml:id="_gxwd3UT">-Create a regulatory framework that not only covers textbased interactions but possible future iterations such as analyzing sound or video.</s></p><p xml:id="_URvdX78"><s xml:id="_7YPF36u">-Provide a framework for making a distinction between LLMs specifically trained on medical data and LLMs trained for non-medical purposes.</s><s xml:id="_MD6Afyv">-Similar to the FDA's Digital Health Pre-Cert Program, regulate companies developing LLMs instead of regulating every single LLM iteration.</s></p><p xml:id="_vXkm6xn"><s xml:id="_u3AYSUW">Table <ref type="table">3</ref>.</s><s xml:id="_jBygj4X">A list of regulatory challenges related to the rise of LLMs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_bBzKhUs">Regulatory challenge Short description</head><p xml:id="_SCFz3Xp"><s xml:id="_WcFzuEC">Patient Data Privacy Ensuring that patient data used for training large language models are fully anonymized and protected from potential breaches.</s><s xml:id="_WMMA7r8">This poses a significant regulatory challenge, as any violation could lead to serious consequences under privacy laws like HIPAA in the US.</s></p><p xml:id="_zV599j6"><s xml:id="_ZQyCYQB">Intellectual Property If an LLM generates content similar to proprietary medical research or literature, it could lead to issues regarding intellectual property rights.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_nGxkxtf">Medical Malpractice Liability</head><p xml:id="_vWsswM6"><s xml:id="_bTq3TGG">Determining who is responsible when an AI's recommendations lead to patient harm.</s><s xml:id="_2HmQgJF">Is it the AI developers, the healthcare professionals who used it, or the institutions that adopted it?</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9CsHwyw">Quality Control &amp; Standardization</head><p xml:id="_v59M7uW"><s xml:id="_zWSDhhb">Regulation is required to ensure the reliability and consistency of AI-generated medical advice, which can vary based on the data used to train the AI.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_zqbcGUj">Informed Consent</head><p xml:id="_qKRpFcr"><s xml:id="_vBkgRTG">Patients need to be informed and give consent when AI tools are used in their healthcare management.</s><s xml:id="_gAGfYVb">This is challenging because it can be difficult for patients to fully understand the implications of AI use.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_pMZt2TM">Interpretability &amp; Transparency</head><p xml:id="_XuWJtmx"><s xml:id="_zncHT8U">Regulations need to ensure transparency about how decisions are made by the AI.</s><s xml:id="_zyTEXwA">This is particularly challenging with AI models that are often termed as "black boxes" due to their complex algorithms.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rRZGwMV">Fairness and Bias</head><p xml:id="_ZF6TXeG"><s xml:id="_fJeSkpH">Regulation is needed to prevent biases in AI models, which could be introduced during the training process using patient data.</s><s xml:id="_WBHPMB8">This can lead to disparities in healthcare outcomes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_CqpnhtN">Data Ownership</head><p xml:id="_v6aRR4E"><s xml:id="_VF55kHU">It can be challenging to define and regulate who owns the data that large language models learn from, especially when it comes to patient data.</s></p><p xml:id="_EW3MUQg"><s xml:id="_nR8FmRM">Over-reliance on AI Models Over-reliance on AI could lead to decreased human expertise and potential errors if the AI malfunctions or provides incorrect information.</s><s xml:id="_Kcm9TNP">Regulations are needed to balance the use of AI and human expertise.</s></p><p xml:id="_XRASMRU"><s xml:id="_MuFcJvY">Continuous Monitoring &amp; Validation Ensuring the continuous performance, accuracy, and validity of AI tools over time and across different populations is a critical regulatory challenge.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc><div><p xml:id="_KZdFwbp"><s xml:id="_USBjGDY">Fig. 1 Ten examples of use cases of LLMs for medical professionals; and ten examples for patients.</s></p></div></figDesc><graphic coords="3,112.88,59.30,360.00,202.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc><div><p xml:id="_n5mBDFU"><s xml:id="_exnWRpG">key actors.</s><s xml:id="_v7Akh9b">If such a pause cannot enacted quickly, governments should step in and institute a moratorium."</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc><div><p xml:id="_N99gjWF"><s xml:id="_pQbxT6G">A list of types of content forms that LLMs could analyze now and possible new versions in the future.</s></p></div></figDesc><table><row><cell>Type of content</cell><cell>Potential applications</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc><div><p xml:id="_RS6UkDX"><s xml:id="_77qBs7Z">Differences between the depth and details of prompts for ChatGPT and GPT-4.</s><s xml:id="_ZNKB4p8">Prompt 1 -Diagnosing a patient with ambiguous symptoms A patient presents with fatigue, weight loss, and occasional dizziness.</s><s xml:id="_n22nnTX">What are some possible causes for these symptoms?</s><s xml:id="_RDcEHDx">A 45-year-old male patient presents with a 3-month history of progressive fatigue, unintentional weight loss of 15 pounds, and episodes of dizziness.</s><s xml:id="_66DcUdK">Please provide a differential diagnosis and suggest relevant diagnostic tests.</s><s xml:id="_YFWSrHJ">Prompt 2 -Treatment recommendations What are some common treatments for type 2 diabetes?</s><s xml:id="_bQHpyvy">A 55-year-old female with a recent diagnosis of type 2 diabetes has an HbA1c level of 8.5%.</s><s xml:id="_4ut6KEG">Outline a comprehensive treatment plan, including lifestyle modifications, pharmacological options, and follow-up monitoring.</s></p></div></figDesc><table><row><cell>Prompts</cell><cell>ChatGPT</cell><cell>GPT-4</cell></row><row><cell>Prompt 3 -Patient education</cell><cell>Explain high blood pressure in simple terms.</cell><cell>Create a patient-friendly educational handout on</cell></row><row><cell></cell><cell></cell><cell>hypertension, including an overview of the condition, risk</cell></row><row><cell></cell><cell></cell><cell>factors, symptoms, potential complications, and management</cell></row><row><cell></cell><cell></cell><cell>strategies.</cell></row><row><cell>Prompt 4 -Reviewing medical</cell><cell>Tell me about the benefits of exercise for</cell><cell>Summarize recent research findings on the relationship</cell></row><row><cell>research</cell><cell>mental health.</cell><cell>between physical activity and mental health outcomes,</cell></row><row><cell></cell><cell></cell><cell>including potential mechanisms, types of exercise, and</cell></row><row><cell></cell><cell></cell><cell>recommendations for various populations.</cell></row><row><cell>Prompt 5 -Clinical case scenario</cell><cell>Describe a patient with pneumonia.</cell><cell>Create a detailed clinical case scenario involving a 65-year-old</cell></row><row><cell></cell><cell></cell><cell>patient presenting with community-acquired pneumonia,</cell></row><row><cell></cell><cell></cell><cell>including history of present illness, relevant past medical</cell></row><row><cell></cell><cell></cell><cell>history, physical examination findings, diagnostic test results,</cell></row><row><cell></cell><cell></cell><cell>and treatment plan.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_yfuM8at"><s xml:id="_zuNf9EA">npj Digital Medicine (2023) 120 Published in partnership with Seoul National University Bundang Hospital 1234567890():,;</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_EB7m6J9"><s xml:id="_fZpjWMX">Published in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2023) 120</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_UuwHaeW"><s xml:id="_zGjdMUz">npj Digital Medicine (2023) 120Published in partnership with Seoul National University Bundang Hospital</s></p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_y8EQ4Aw">Reporting summary</head><p xml:id="_tXc3Ynm"><s xml:id="_Pyrh66e">Further information on research design is available in the Nature Research Reporting Summary linked to this article.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_57qgNmE">AUTHOR CONTRIBUTIONS</head><p xml:id="_mGDa3QB"><s xml:id="_XZJCd62">B.M. and E.T. developed the concept of the manuscript.</s><s xml:id="_W3cD6Sn">B.M. drafted the manuscript and E.T. contributed to the writing, interpretation of the content, and editing of the manuscript, revising it critically.</s><s xml:id="_WbPtkDG">Both authors approved the completed version.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_EkWQDV4">COMPETING INTERESTS</head><p xml:id="_Jhysk2j"><s xml:id="_j3MmRxF">The authors declare no competing interests.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_RjzcQmu">ADDITIONAL INFORMATION Supplementary information</head><p xml:id="_SQcurcg"><s xml:id="_2R5RJU9">The online version contains supplementary material available at <ref type="url" target="https://doi.org/10.1038/s41746-023-00873-0">https://doi.org/10.1038/s41746-023-00873-0</ref>.</s></p><p xml:id="_fkssktk"><s xml:id="_gMAGvbT">Correspondence and requests for materials should be addressed to Bertalan Mesk√≥.</s></p><p xml:id="_9eWMKWS"><s xml:id="_T7ARPjr">Reprints and permission information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/  reprints</ref> Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<idno type="DOI">10.1007/979-8-8688-0929-3_1</idno>
		<ptr target="https://openai.com/blog/chatgpt" />
		<title level="m" xml:id="_CD3q3sW">Introducing ChatGPT</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>OpenAI</note>
	<note type="raw_reference">Introducing ChatGPT. OpenAI, https://openai.com/blog/chatgpt (2022).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Pichai</surname></persName>
		</author>
		<idno type="DOI">10.1148/radiol.232561.podcast</idno>
		<ptr target="https://blog.google/technology/ai/bard-google-ai-search-updates/" />
		<title level="m" xml:id="_7rMA7Dp">An important next step on our AI journey. Google The Keyword</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pichai, S. An important next step on our AI journey. Google The Keyword, https:// blog.google/technology/ai/bard-google-ai-search-updates/ (2023).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_AH9mNud">The utility of chatGPT as an example of large language models in healthcare education, research and practice: systematic review on the future perspectives and potential limitations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sallam</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.02.19.23286155</idno>
		<ptr target="https://doi.org/10.1101/2023.02.19.23286155" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Y7Xh2px">medRxiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sallam, M. The utility of chatGPT as an example of large language models in healthcare education, research and practice: systematic review on the future perspectives and potential limitations. medRxiv, https://doi.org/10.1101/ 2023.02.19.23286155 (2023).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_yNGhCWz">ChatGPT in healthcare: a taxonomy and systematic review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleesiek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Egger</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.03.30.23287899</idno>
		<ptr target="https://doi.org/10.1101/2023.03.30.23287899" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_8Fe4E2Z">medRxiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li, J., Dada, A., Kleesiek, J. &amp; Egger, J. ChatGPT in healthcare: a taxonomy and systematic review. medRxiv, https://doi.org/10.1101/2023.03.30.23287899 (2023).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_SZUV4Zp">United States regulatory approval of medical devices and software applications enhanced by artificial intelligence</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Yaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Oermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Costa</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.hlpt.2019.05.006</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KX3tPnR">Heal. Policy Technol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="192" to="197" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yaeger, K. A., Martini, M., Yaniv, G., Oermann, E. K. &amp; Costa, A. B. United States regulatory approval of medical devices and software applications enhanced by artificial intelligence. Heal. Policy Technol. 8, 192-197 (2019).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_PRdvtAw">The state of artificial intelligence-based FDA-approved medical devices and algorithms: an online database</title>
		<author>
			<persName><forename type="first">S</forename><surname>Benjamens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhunnoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mesk√≥</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-020-00324-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mhs8Cpr">npj Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Benjamens, S., Dhunnoo, P. &amp; Mesk√≥, B. The state of artificial intelligence-based FDA-approved medical devices and algorithms: an online database. npj Digit. Med. 3, 1-8 (2020).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<idno type="DOI">10.1109/jva60410.2023.00022</idno>
		<ptr target="https://www.fda.gov/media/100714/download" />
		<title level="m" xml:id="_tz6MCgu">Software as a Medical Device (SAMD): clinical evaluation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>FDA</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">FDA. Software as a Medical Device (SAMD): clinical evaluation. https:// www.fda.gov/media/100714/download (2017).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_KFRVaST">High-performance medicin0e: the convergence of human and artificial intelligence</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0300-7</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_J8WtGyT">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="44" to="56" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Topol, E. J. High-performance medicin0e: the convergence of human and artificial intelligence. Nat. Med. 25, 44-56 (2019).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><surname>Fda</surname></persName>
		</author>
		<idno type="DOI">10.31032/ijbpas/2025/14.8.9309</idno>
		<ptr target="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device" />
		<title level="m" xml:id="_t7Dz4kf">Artificial intelligence and machine learning in software as a medical device</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">FDA. Artificial intelligence and machine learning in software as a medical device. https://www.fda.gov/medical-devices/software-medical-device- samd/artificial-intelligence-and-machine-learning-software-medical-device (2021).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_m6Tn6VK">Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nagendran</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.m689</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bd238G2">BMJ</title>
		<imprint>
			<biblScope unit="volume">368</biblScope>
			<biblScope unit="page">689</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nagendran, M. et al. Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies. BMJ 368, m689 (2020).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_waayVyv">Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petro</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejmsr2214184</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2cuP45R">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="1233" to="1239" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lee, P., Bubeck, S. &amp; Petro, J. Benefits, limits, and risks of GPT-4 as an AI chatbot for medicine. N. Engl. J. Med. 388, 1233-1239 (2023).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><surname>Nuance</surname></persName>
		</author>
		<idno type="DOI">10.1093/oed/8535033916</idno>
		<title level="m" xml:id="_RfGehnR">Nuance is revolutionizing the contact center with GPT technology</title>
		<imprint>
			<publisher>Nuance</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nuance. Nuance is revolutionizing the contact center with GPT technology (Nuance, 2023).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Lunden</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ceh.2024.04.001</idno>
		<title level="m" xml:id="_xzT7NJm">Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action</title>
		<imprint>
			<publisher>TechCrunch</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lunden, I. Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action (TechCrunch, 2023).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main" xml:id="_vbExN5k">Large language models encode clinical knowledge</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2212.13138" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Singhal K., et al. Large language models encode clinical knowledge. Preprint at https://arxiv.org/abs/2212.13138 (2022).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_jmNja2X">Regulating ChatGPT and other Large Generative AI Models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mauer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3593013.3594067</idno>
		<ptr target="https://doi.org/10.1145/3593013.3594067" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_5UDP82E">Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT &apos;23)</title>
		<meeting>the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT &apos;23)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1112" to="1123" />
		</imprint>
	</monogr>
	<note type="raw_reference">Hacker, P., Engel, A. &amp; Mauer, M. Regulating ChatGPT and other Large Generative AI Models. In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT &apos;23), 1112-1123 (Association for Computing Machinery, New York, NY, USA, 2023). https://doi.org/10.1145/3593013.3594067.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_ycspK8H">Auditing large language models: a three-layered approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>M√∂kander</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-023-00289-2</idno>
		<ptr target="https://doi.org/10.1007/s43681-023-00289-2" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_SqZWB9s">AI Ethics</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M√∂kander, J. et al. Auditing large language models: a three-layered approach. AI Ethics. https://doi.org/10.1007/s43681-023-00289-2 (2023).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Will</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename></persName>
		</author>
		<idno type="DOI">10.1126/science.adi2220</idno>
		<title level="m" xml:id="_cjmUfkd">In sudden alarm, tech doyens call for a pause on ChatGPT</title>
		<imprint>
			<publisher>Wired</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Will Knight, P. D. In sudden alarm, tech doyens call for a pause on ChatGPT (Wired, 2023).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><surname>Ng</surname></persName>
		</author>
		<ptr target="https://twitter.com/AndrewYNg/status/1641121451611947009" />
		<title level="m" xml:id="_tqzE9xu">s Twitter</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ng, A. Andrew Ng&apos;s Twitter. Twitter https://twitter.com/AndrewYNg/status/ 1641121451611947009 (2023).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Mccallum</surname></persName>
		</author>
		<title level="m" xml:id="_5mG5nqR">ChatGPT banned in Italy over privacy concerns</title>
		<imprint>
			<publisher>BBC</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McCallum, S. ChatGPT banned in Italy over privacy concerns (BBC, 2023).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_VEjh4Eh">Patient design: the importance of including patients in designing health care</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mesk√≥</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Debronkart</surname></persName>
		</author>
		<idno type="DOI">10.2196/39178</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QF9RsgW">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">39178</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mesk√≥, B. &amp; deBronkart, D. Patient design: the importance of including patients in designing health care. J. Med. Internet Res. 24, e39178 (2022).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
