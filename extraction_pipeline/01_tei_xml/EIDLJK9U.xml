<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_bPbjcwR">Federated Learning for Healthcare Informatics</title>
				<funder ref="#_6yQSPBt">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_zc8Ct6R">
					<orgName type="full">Amazon AWS Machine</orgName>
				</funder>
				<funder ref="#_tmB7AmG">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_euY6hYK">
					<orgName type="full">ONR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
					<p type="raw">Â© Springer Nature Switzerland AG 2020</p>
				</availability>
				<date type="published" when="2020-11-12">12 November 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jie</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Population Health Sciences , Weill Cornell Medicine , New York , NY , USA</note>
								<orgName type="department">Department of Population Health Sciences</orgName>
								<orgName type="institution">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><forename type="middle">S</forename><surname>Glicksberg</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Institute for Digital Health , Icahn School of Medicine at Mount Sinai , New York , NY , USA</note>
								<orgName type="department">Institute for Digital Health</orgName>
								<orgName type="institution">Icahn School of Medicine at Mount Sinai</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chang</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Population Health Sciences , Weill Cornell Medicine , New York , NY , USA</note>
								<orgName type="department">Department of Population Health Sciences</orgName>
								<orgName type="institution">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Walker</surname></persName>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> U.S. Department of Defense Joint Artificial Intelligence Center , Washington , D.C. , USA</note>
								<orgName type="department">U.S. Department of Defense Joint Artificial Intelligence Center</orgName>
								<address>
									<settlement>Washington</settlement>
									<region>D.C</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiang</forename><surname>Bian</surname></persName>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Department of Health Outcomes and Biomedical Informatics , College of Medicine , University of Florida , Gainesville , FL , USA</note>
								<orgName type="department" key="dep1">Department of Health Outcomes and Biomedical Informatics</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<settlement>Gainesville</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Population Health Sciences , Weill Cornell Medicine , New York , NY , USA</note>
								<orgName type="department">Department of Population Health Sciences</orgName>
								<orgName type="institution">Weill Cornell Medicine</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_qVUnBXs">Federated Learning for Healthcare Informatics</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-12">12 November 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">48DA9253E468C6584A95B092C29E4AAE</idno>
					<idno type="DOI">10.1007/s41666-020-00082-4</idno>
					<note type="submission">Received: 19 August 2020 / Revised: 21 October 2020 / Accepted: 30 October 2020 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T08:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_xfJ8S7Y">Federated learning</term>
					<term xml:id="_nspPmUa">Healthcare</term>
					<term xml:id="_ZW5YGC4">Privacy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_UUKzV3B"><p xml:id="_6ZD9aPd"><s xml:id="_ZRNKmw9">With the rapid development of computer software and hardware technologies, more and more healthcare data are becoming readily available from clinical institutions, patients, insurance companies, and pharmaceutical industries, among others.</s><s xml:id="_2TUQ9TA">This access provides an unprecedented opportunity for data science technologies to derive data-driven insights and improve the quality of care delivery.</s><s xml:id="_MdgBpyw">Healthcare data, however, are usually fragmented and private making it difficult to generate robust results across populations.</s><s xml:id="_ArWMWC7">For example, different hospitals own the electronic health records (EHR) of different patient populations and these records are difficult to share across hospitals because of their sensitive nature.</s><s xml:id="_HYhKBnr">This creates a big barrier for developing effective analytical approaches that are generalizable, which need diverse, "big data."</s><s xml:id="_QEZDanU">Federated learning, a mechanism of training a shared global model with a central server while keeping all the sensitive data in local institutions where the data belong, provides great promise to connect the fragmented healthcare data sources with privacy-preservation.</s><s xml:id="_VJ526cw">The goal of this survey is to provide a review for federated learning technologies, particularly within the biomedical space.</s><s xml:id="_sjnx6fJ">In particular, we summarize the general solutions to the statistical challenges, system challenges, and privacy issues in federated learning, and point out the implications and potentials in healthcare.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="439.642" lry="666.49"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" xml:id="_dm42HYY">Introduction</head><p xml:id="_5mSxffR"><s xml:id="_enxUUGh">The recent years have witnessed a surge of interest related to healthcare data analytics, due to the fact that more and more such data are becoming readily available from various sources including clinical institutions, patient individuals, insurance companies, and pharmaceutical industries, among others.</s><s xml:id="_jjfAMsy">This provides an unprecedented opportunity for the development of computational techniques to dig data-driven insights for improving the quality of care delivery <ref type="bibr" target="#b71">[72,</ref><ref type="bibr">105]</ref>.</s></p><p xml:id="_5VfNxDj"><s xml:id="_8JXm9Aa">Healthcare data are typically fragmented because of the complicated nature of the healthcare system and processes.</s><s xml:id="_qQhhdCX">For example, different hospitals may be able to access the clinical records of their own patient populations only.</s><s xml:id="_uvKEX66">These records are highly sensitive with protected health information (PHI) of individuals.</s><s xml:id="_jNg89gt">Rigorous regulations, such as the Health Insurance Portability and Accountability Act (HIPAA) <ref type="bibr" target="#b31">[32]</ref>, have been developed to regulate the process of accessing and analyzing such data.</s><s xml:id="_2CJ8cP3">This creates a big challenge for modern data mining and machine learning (ML) technologies, such as deep learning <ref type="bibr" target="#b60">[61]</ref>, which typically requires a large amount of training data.</s></p><p xml:id="_wbwDCDC"><s xml:id="_uRNMbgM">Federated learning is a paradigm with a recent surge in popularity as it holds great promise on learning with fragmented sensitive data.</s><s xml:id="_tPFRKEk">Instead of aggregating data from different places all together, or relying on the traditional discovery then replication design, it enables training a shared global model with a central server while keeping the data in local institutions where the they originate.</s></p><p xml:id="_pBum4Zw"><s xml:id="_NxmcVTA">The term "federated learning" is not new.</s><s xml:id="_T72Yd5z">In 1976, Patrick Hill, a philosophy professor, first developed the Federated Learning Community (FLC) to bring people together to jointly learn, which helped students overcome the anonymity and isolation in large research universities <ref type="bibr" target="#b41">[42]</ref>.</s><s xml:id="_DpXCpwF">Subsequently, there were several efforts aiming at building federations of learning content and content repositories <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b82">83]</ref>.</s><s xml:id="_XABEeHb">In 2005, Rehak et al. <ref type="bibr" target="#b82">[83]</ref> developed a reference model describing how to establish an interoperable repository infrastructure by creating federations of repositories, where the metadata are collected from the contributing repositories into a central registry provided with a single point of discovery and access.</s><s xml:id="_s6UtTqs">The ultimate goal of this model is to enable learning from diverse content repositories.</s><s xml:id="_HDfkPp7">These practices in federated learning community or federated search service have provided effective references for the development of federated learning algorithms.</s></p><p xml:id="_BG7qpDU"><s xml:id="_2fJzEfg">Federated learning holds great promises on healthcare data analytics.</s><s xml:id="_8PPRmdW">For both provider (e.g., building a model for predicting the hospital readmission risk with patient Electronic Health Records (EHR) <ref type="bibr" target="#b70">[71]</ref>) and consumer (patient)-based applications (e.g., screening atrial fibrillation with electrocardiograms captured by smartwatch <ref type="bibr" target="#b78">[79]</ref>), the sensitive patient data can stay either in local institutions or with individual consumers without going out during the federated model learning process, which effectively protects the patient privacy.</s><s xml:id="_sEfB9MY">The goal of this paper is to review the setup of federated learning, discuss the general solutions and challenges, and envision its applications in healthcare.</s></p><p xml:id="_NVyQvDM"><s xml:id="_KJDbewh">In this review, after a formal overview of federated learning, we summarize the main challenges and recent progress in this field.</s><s xml:id="_KaUTSpV">Then we illustrate the potential of federated learning methods in healthcare by describing the successful recent research.</s></p><p xml:id="_vFjv7BR"><s xml:id="_rBrKnDj">At last, we discuss the main opportunities and open questions for future applications in healthcare.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NyqYAvN">Difference with Existing Reviews</head><p xml:id="_xuDG872"><s xml:id="_24BbKjZ">There has been a few review articles on federated learning recently.</s><s xml:id="_TPpphcY">For example, <ref type="bibr">Yang et al. [109]</ref> wrote the early federated learning survey summarizing the general privacy-preserving techniques that can be applied to federated learning.</s><s xml:id="_2wS8GVe">Some researchers surveyed sub-problems of federated learning, e.g., personalization techniques <ref type="bibr" target="#b58">[59]</ref>, semi-supervised learning algorithms <ref type="bibr" target="#b48">[49]</ref>, threat models <ref type="bibr" target="#b67">[68]</ref>, and mobile edge networks <ref type="bibr" target="#b65">[66]</ref>.</s><s xml:id="_pJcU3vF"><ref type="bibr">Kairouz et al. [51]</ref> discussed recent advances and presented an extensive collection of open problems and challenges.</s><s xml:id="_tBnSGMB">Li et al. <ref type="bibr" target="#b62">[63]</ref> conducted the review on federated learning from a system viewpoint.</s><s xml:id="_BAjE2ev">Different from those reviews, this paper provided the potential of federated learning to be applied in healthcare.</s><s xml:id="_9PWHmwC">We summarized the general solution to the challenges in federated learning scenario and surveyed a set of representative federated learning methods for healthcare.</s><s xml:id="_MWukZhC">In the last part of this review, we outlined some directions or open questions in federated learning for healthcare.</s><s xml:id="_nuxkCar">An early version of this paper is available on arXiv [107].</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" xml:id="_uMBz4fH">Federated Learning</head><p xml:id="_Qdy3zay"><s xml:id="_RJ3HjrB">Federated learning is a problem of training a high-quality shared global model with a central server from decentralized data scattered among large number of different clients (Fig. <ref type="figure" target="#fig_0">1</ref>).</s><s xml:id="_CYxqUY7">Mathematically, assume there are K activated clients where the data reside in (a client could be a mobile phone, a wearable device, or a clinical institution data warehouse, etc.).</s><s xml:id="_4KpgG3Z">Let D k denote the data distribution associated with client k and n k the number of samples available from that client.</s><s xml:id="_y4wpYgv">n = K k=1 n k is the total sample size.</s><s xml:id="_cQDXkHN">Federated learning problem boils down to solving a empirical risk minimization problem of the form <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b68">69]</ref>:</s></p><formula xml:id="formula_0">min wâR d F (w) := K k=1 n k n F k (w) where F k (w) := 1 n k x i âD k f i (w), (<label>1</label></formula><formula xml:id="formula_1">)</formula><p xml:id="_U6NayNS"><s xml:id="_SbusWY4">where w is the model parameter to be learned.</s><s xml:id="_BvcRyrZ">The function f i is specified via a loss function dependent on a pair of input-output data pair {x i , y i }.</s><s xml:id="_5qWBrCN">Typically, x i â R d and y i â R or y i â {-1, 1}.</s><s xml:id="_zYV9Vvx">Simple examples include:</s></p><p xml:id="_tCmHnvN"><s xml:id="_DQq8gYB">-linear regression:</s></p><formula xml:id="formula_2">f i (w) = 1 2 (x i w -y i ) 2 , y i â R; -logistic regression: f i (w) = -log(1 + exp(-y i x i w)), y i â {-1, 1}; -support vector machines: f i (w) = max{0, 1 -y i x i w}, y i â {-1, 1}.</formula><p xml:id="_zbzcaqQ"><s xml:id="_EAVRh6B">In particular, algorithms for federated learning face with a number of challenges <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b95">96]</ref>, specifically:</s></p><p xml:id="_2nkJjWF"><s xml:id="_ZwGCqap">-Statistical Challenge: The data distribution among all clients differ greatly, i.e., âk = k, we have</s></p><formula xml:id="formula_3">E x i â¼D k [f i (w; x i )] = E x i â¼D k [f i (w; x i )].</formula><p xml:id="_HvTnm89"><s xml:id="_kRKJYVH">It is such that any data points available locally are far from being a representative sample of the overall distribution, i.e., E x i â¼D k [f i (w; x i )] = F (w). -Communication Efficiency: The number of clients K is large and can be much bigger than the average number of training sample stored in the activated clients, i.e., K (n/K).</s><s xml:id="_RgzTyGP">-Privacy and Security: Additional privacy protections are needed for unreliable participating clients.</s><s xml:id="_DKR56Ge">It is impossible to ensure all clients are equally reliable.</s></p><p xml:id="_RqcffEG"><s xml:id="_nRXvxgM">Next, we will survey, in detail, the existing federated learning related works on handling such challenges.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1" xml:id="_7kReApP">Statistical Challenges of Federated Learning</head><p xml:id="_vvWf6EP"><s xml:id="_nT9UnUs">The naive way to solve the federated learning problem is through Federated Averaging (FedAvg) <ref type="bibr" target="#b68">[69]</ref>.</s><s xml:id="_Dx83grm">It is demonstrated can work with certain non independent identical distribution (non-IID) data by requiring all the clients to share the same model.</s><s xml:id="_PjzvWyR">However, FedAvg does not address the statistical challenge of strongly skewed data distributions.</s><s xml:id="_RrjDgT5">The performance of convolutional neural networks trained with FedAvg algorithm can reduce significantly due to the weight divergence <ref type="bibr">[111]</ref>.</s><s xml:id="_GyYyVcA">Existing research on dealing with the statistical challenge of federated learning can be grouped into two fields, i.e., consensus solution and pluralistic solution.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1" xml:id="_GCnxM92">Consensus Solution</head><p xml:id="_yZ4b57f"><s xml:id="_NwrmQ64">Most centralized models are trained on the aggregated training samples obtained from the samples drawn from the local clients <ref type="bibr" target="#b95">[96,</ref><ref type="bibr">111]</ref>.</s><s xml:id="_QY83kSk">Intrinsically, the centralized model is trained to minimize the loss with respect to the uniform distribution <ref type="bibr" target="#b72">[73]</ref>:</s></p><formula xml:id="formula_4">D = K k=1 n k n D k ,</formula><p xml:id="_Q5pCvyj"><s xml:id="_NfXyM2g">where D is the target data distribution for the learning model.</s><s xml:id="_78a4Rm3">However, this specific uniform distribution is not an adequate solution in most scenarios.</s></p><p xml:id="_ETe9CNz"><s xml:id="_DmZvmXw">To address this issue, the recent proposed solution is to model the target distribution or force the data adapt to the uniform distribution <ref type="bibr" target="#b72">[73,</ref><ref type="bibr">111]</ref>.</s><s xml:id="_ePAZcWG">Specifically, Mohri et al. <ref type="bibr" target="#b72">[73]</ref> proposed a minimax optimization scheme, i.e., agnostic federated learning (AFL), where the centralized model is optimized for any possible target distribution formed by a mixture of the client distributions.</s><s xml:id="_qABqr65">This method has only been applied at small scales.</s><s xml:id="_gxUprR5">Compared to AFL, Li et al. <ref type="bibr" target="#b63">[64]</ref> proposed q-Fair Federated Learning (q-FFL), assigning higher weight to devices with poor performance, so that the distribution of accuracy in the network reduces in variance.</s><s xml:id="_hnEVcHb">They empirically demonstrate the improved flexibility and scalability of q-FFL compared to AFL.</s></p><p xml:id="_GQnXvz3"><s xml:id="_QxwNGm6">Another commonly used method is globally sharing a small portion of data between all the clients <ref type="bibr" target="#b74">[75,</ref><ref type="bibr">111]</ref>.</s><s xml:id="_KzqZB5D">The shared subset is required containing a uniform distribution over classes from the central server to the clients.</s><s xml:id="_Ar54NeH">In addition to handle non-IID issue, sharing information of a small portion of trusted instances and noise patterns can guide the local agents to select compact training subset, while the clients learn to add changes to selected data samples, in order to improve the test performance of the global model <ref type="bibr" target="#b37">[38]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2" xml:id="_5uHef8M">Pluralistic Solution</head><p xml:id="_KVKEMyW"><s xml:id="_y9rMBsM">Generally, it is difficult to find a consensus solution w that is good for all components D i .</s><s xml:id="_Jqn26mw">Instead of wastefully insisting on a consensus solution, many researchers choose to embracing this heterogeneity.</s></p><p xml:id="_8g5FPuQ"><s xml:id="_rNr9NaF">Multi-task learning (MTL) is a natural way to deal with the data drawn from different distributions.</s><s xml:id="_4EEtJtV">It directly captures relationships among non-IID and unbalanced data by leveraging the relatedness between them in comparison to learn a single global model.</s><s xml:id="_vmSxey5">In order to do this, it is necessary to target a particular way in which tasks are related, e.g., sharing sparsity, sharing low-rank structure, and graphbased relatedness.</s><s xml:id="_KhkJNVb">Recently, Smith et al. <ref type="bibr" target="#b95">[96]</ref> empirically demonstrated this point on real-world federated datasets and proposed a novel method MOCHA to solve a general convex MTL problem with handling the system challenges at the same time.</s><s xml:id="_8MYZQPD">Later, Corinzia et al. <ref type="bibr" target="#b21">[22]</ref> introduced VIRTUAL, an algorithm for federated multi-task learning with non-convex models.</s><s xml:id="_dEfvj6u">They consider the federation of central server and clients as a Bayesian network and perform training using approximated variational inference.</s><s xml:id="_skzbRBS">This work bridges the frameworks of federated and transfer/continuous learning.</s></p><p xml:id="_8M5Cckt"><s xml:id="_8xs25Bg">The success of multi-task learning rests on whether the chosen relatedness assumptions hold.</s><s xml:id="_bB4bQKQ">Compared to this, pluralism can be a critical tool for dealing with heterogeneous data without any additional or even low-order terms that depend on the relatedness as in MTL <ref type="bibr" target="#b27">[28]</ref>.</s><s xml:id="_UaVZsDp">Eichner et al. <ref type="bibr" target="#b27">[28]</ref> considered training in the presence of block-cyclic data and showed that a remarkably simple pluralistic approach can entirely resolve the source of data heterogeneity.</s><s xml:id="_maN5YBW">When the component distributions are actually different, pluralism can outperform the "ideal" IID baseline.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2" xml:id="_rDVS2Q5">Communication Efficiency of Federated Learning</head><p xml:id="_Dyn5vde"><s xml:id="_3YGD37w">In federated learning setting, training data remain distributed over a large number of clients each with unreliable and relatively slow network connections.</s><s xml:id="_QskqqPS">Naively for synchronous protocol in federated learning <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b95">96]</ref>, the total number of bits that required during uplink (clinets â server) and downlink (server â clients) communication by each of the K clients during training is given by:</s></p><formula xml:id="formula_5">B up/down â O(U Ã |w| Ã (H ( w up/down ) + Î²) update size ) (<label>2</label></formula><formula xml:id="formula_6">)</formula><p xml:id="_qUf98M6"><s xml:id="_qrwakMB">where U is the total number of updates performed by each client, |w| is the size of the model and H ( w up/down ) is the entropy of the weight updates exchanged during transmitting process.</s><s xml:id="_cCRsm6b">Î² is the difference between the true update size and the minimal update size (which is given by the entropy) <ref type="bibr" target="#b88">[89]</ref>.</s><s xml:id="_psH858s">Apparently, we can consider three ways to reduce the communication cost: (a) reduce the number of clients K, (b) reduce the update size, (c) reduce the number of updates U .</s><s xml:id="_gazgjDH">Starting at these three points, we can organize existing research on communication-efficient federated learning into four groups, i.e., model compression, client selection, updates reducing, and peer-to-peer learning (Fig. <ref type="figure" target="#fig_1">2</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1" xml:id="_DZtf9Ap">Client Selection</head><p xml:id="_aP9ez26"><s xml:id="_A7bThth">The most natural and rough way for reducing communication cost is to restrict the participated clients or choose a fraction of parameters to be updated at each round.</s><s xml:id="_9qV77cc">Shokri et al. <ref type="bibr" target="#b91">[92]</ref> use the selective stochastic gradient descent protocol, where the selection can be completely random or only the parameters whose current values are farther away from their local optima are selected, i.e., those that have a larger gradient.</s><s xml:id="_bBNT8RT">Nishio et al. <ref type="bibr" target="#b74">[75]</ref> proposed a new protocol referred to as FedCS, where the central server manages the resources of heterogeneous clients and determines which clients should participate the current training task by analyzing the resource information of each client, such as wireless channel states, computational capacities, and the size of data resources relevant to the current task.</s><s xml:id="_fG5KJDZ">Here, the server should decide how much data, energy, and CPU resources used by the mobile devices such that the energy consumption, training latency, and bandwidth cost are minimized while meeting requirements of the training tasks.</s><s xml:id="_RPbeYMT">Anh <ref type="bibr" target="#b4">[5]</ref> thus proposes to use the Deep Q-Learning <ref type="bibr">[102]</ref> technique that enables the server to find the optimal data and energy management for the mobile devices participating in the mobile crowdmachine learning through federated learning without any prior knowledge of network dynamics.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2" xml:id="_FBybPa4">Model Compression</head><p xml:id="_5Fvj8vJ"><s xml:id="_wj36MVH">The goal of model compression is to compress the server-to-client exchanges to reduce uplink/downlink communication cost.</s><s xml:id="_nqcUkNc">The first way is through structured updates, where the update is directly learned from a restricted space parameterized using a smaller number of variables, e.g., sparse, low-rank <ref type="bibr" target="#b57">[58]</ref>, or more specifically, pruning the least useful connections in a network <ref type="bibr" target="#b36">[37,</ref><ref type="bibr">113]</ref>, weight quantization <ref type="bibr">[17,</ref><ref type="bibr" target="#b88">89]</ref>, and model distillation <ref type="bibr" target="#b42">[43]</ref>.</s><s xml:id="_gYs3Nb8">The second way is lossy compression, where a full model update is first learned and then compressed using a combination of quantization, random rotations, and subsampling before sending it to the server <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b57">58]</ref>.</s><s xml:id="_hcJng3Q">Then the server decodes the updates before doing the aggregation.</s><s xml:id="_RCUvWgC">Federated dropout, in which each client, instead of locally training an update to the whole global model, trains an update to a smaller sub-model <ref type="bibr" target="#b11">[12]</ref>.</s><s xml:id="_R34Cvpw">These submodels are subsets of the global model and, as such, the computed local updates have a natural interpretation as updates to the larger global model.</s><s xml:id="_pK2vAwc">Federated dropout not only reduces the downlink communication but also reduces the size of uplink updates.</s><s xml:id="_gaZZuV3">Moreover, the local computational costs is correspondingly reduced since the local training procedure dealing with parameters with smaller dimensions.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3" xml:id="_BVyNj4v">Updates Reduction</head><p xml:id="_XN454QJ"><s xml:id="_FNWNjdS">Kamp et al. <ref type="bibr" target="#b51">[52]</ref> proposed to average models dynamically depending on the utility of the communication, which leads to a reduction of communication by an order of magnitude compared to periodically communicating state-of-the-art approaches.</s><s xml:id="_UJMRkDB">This facet is well suited for massively distributed systems with limited communication infrastructure.</s><s xml:id="_k8MbG6c">Bui et al. <ref type="bibr" target="#b10">[11]</ref> improved federated learning for Bayesian neural networks using partitioned variational inference, where the client can decide to upload the parameters back to the central server after multiple passes through its data, after one local epoch, or after just one mini-batch.</s><s xml:id="_Mh7wNHE">Guha et al. <ref type="bibr" target="#b34">[35]</ref> focused on techniques for one-shot federated learning, in which they learn a global model from data in the network using only a single round of communication between the devices and the central server.</s><s xml:id="_7t394WD">Besides above works, Ren et al. [84] theoretically analyzed the detailed expression of the learning efficiency in the CPU scenario and formulate a training acceleration problem under both communication and learning resource budget.</s><s xml:id="_Wpq2su8">Reinforcement learning and round robin learning are widely used to manage the communication and computation resources [5, 46, 106, 114].</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4" xml:id="_4B3g29K">Peer-to-Peer Learning</head><p xml:id="_xf37h2C"><s xml:id="_NwSpEQk">In federated learning, a central server is required to coordinate the training process of the global model.</s><s xml:id="_DAUbQJm">However, the communication cost to the central server may be not affordable since a large number of clients are usually involved.</s><s xml:id="_Qjm2A62">Also, many practical peer-to-peer networks are usually dynamic, and it is not possible to regularly access a fixed central server.</s><s xml:id="_nASKPJy">Moreover, because of the dependence on central server, all clients are required to agree on one trusted central body, and whose failure would interrupt the training process for all clients.</s><s xml:id="_qUx3myg">Therefore, some researches began to study fully decentralized framework where the central server is not required <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b90">91]</ref>.</s><s xml:id="_YdEwJ4G">The local clients are distributed over the graph/network where they only communicate with their one-hop neighbors.</s><s xml:id="_rzScjTw">Each client updates its local belief based on own data and then aggregates information from the one-hop neighbors.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3" xml:id="_dT9EDmJ">Privacy and Security</head><p xml:id="_eRX98Tb"><s xml:id="_6yFBGgE">In federated learning, we usually assume the number of participated clients (e.g., phones, cars, clinical institutions...) is large, potentially in the thousands or millions.</s><s xml:id="_C9dUCZV">It is impossible to ensure none of the clients is malicious.</s><s xml:id="_N8y9yxA">The setting of federated learning, where the model is trained locally without revealing the input data or the model's output to any clients, prevents direct leakage while training or using the model.</s><s xml:id="_HH9dG5X">However, the clients may infer some information about another client's private dataset given the execution of f (w), or over the shared predictive model w [100].</s><s xml:id="_Wmrx86R">To this end, there have been many efforts focus on privacy either from an individual point of view or multiparty views, especially in social media field which significantly exacerbated multiparty privacy (MP) conflicts <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b97">98]</ref> (Fig. <ref type="figure" target="#fig_2">3</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1" xml:id="_wHeAM4Y">Secure Multi-party Computation</head><p xml:id="_5rwChsc"><s xml:id="_9x98u5W">Secure multi-party computation (SMC) has a natural application to federated learning scenarios, where each individual client uses a combination of cryptographic techniques and oblivious transfer to jointly compute a function of their private data <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b77">78]</ref>.</s><s xml:id="_RZJdXAs">Homomorphic encryption is a public key system, where any party can encrypt its data with a known public key and perform calculations with data encrypted by others with the same public key <ref type="bibr" target="#b28">[29]</ref>.</s><s xml:id="_YtBwqm9">Due to its success in cloud computing, it comes naturally into this realm, and it has certainly been used in many federated learning researches <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b39">40]</ref>.</s></p><p xml:id="_Dey9v5D"><s xml:id="_TwjGgFG">Although SMC guarantees that none of the parties shares anything with each other or with any third party, it can not prevent an adversary from learning some individual information, e.g., which clients' absence might change the decision boundary of a classifier, etc.</s><s xml:id="_pDtYVhN">Moreover, SMC protocols are usually computationally expensive even for the simplest problems, requiring iterated encryption/decryption and repeated communication between participants about some of the encrypted results <ref type="bibr" target="#b77">[78]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2" xml:id="_CWNyzPQ">Differential Privacy</head><p xml:id="_nmhc94u"><s xml:id="_5JdA7kh">Differential privacy (DP) <ref type="bibr" target="#b25">[26]</ref> is an alternative theoretical model for protecting the privacy of individual data, which has been widely applied to many areas, not only traditional algorithms, e.g., boosting <ref type="bibr" target="#b26">[27]</ref>, principal component analysis <ref type="bibr" target="#b14">[15]</ref>, support vector machine <ref type="bibr" target="#b85">[86]</ref>, but also deep learning research <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b69">70]</ref>.</s><s xml:id="_KPErHb4">It ensures that the addition or removal does not substantially affect the outcome of any analysis and is thus also widely studied in federated learning research to prevent the indirect leakage <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b91">92]</ref>.</s><s xml:id="_tTttgey">However, DP only protects users from data leakage to a certain extent and may reduce performance in prediction accuracy because it is a lossy method <ref type="bibr" target="#b17">[18]</ref>.</s><s xml:id="_9KmMC56">Thus, some researchers combine DP with SMC to reduce the growth of noise injection as the number of parties increases without sacrificing privacy while preserving provable privacy guarantees, protecting against extraction attacks and collusion threats <ref type="bibr" target="#b17">[18,</ref><ref type="bibr">100]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3" xml:id="_ZaBJggA">Applications</head><p xml:id="_HthUnVK"><s xml:id="_yYRHudX">Federated learning has been incorporated and utilized in many domains.</s><s xml:id="_kyxBrQh">This widespread adoption is due in part by the fact that it enables a collaborative modeling mechanism that allows for efficient ML all while ensuring data privacy and legal compliance between multiple parties or multiple computing nodes.</s><s xml:id="_ZVB7HHd">Some promising examples that highlight these capabilities are virtual keyboard prediction <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b69">70]</ref>, smart retail [112], finance <ref type="bibr">[109]</ref>, and vehicle-to-vehicle communication <ref type="bibr" target="#b87">[88]</ref>.</s><s xml:id="_w8ejnah">In this section, we focus primarily on applications within the healthcare space and also discuss promising applications in other domains since some principles can be applied to healthcare.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1" xml:id="_WeNv9Sf">Healthcare</head><p xml:id="_ftegT7z"><s xml:id="_Rr7bTzY">EHRs have emerged as a crucial source of real world healthcare data that has been used for an amalgamation of important biomedical research <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b46">47]</ref>, including for machine learning research <ref type="bibr" target="#b71">[72]</ref>.</s><s xml:id="_eYb2YeM">While providing a huge amount of patient data for analysis, EHRs contain systemic and random biases overall and specific to hospitals that limit the generalizability of results.</s><s xml:id="_eFGcsSB">For example, Obermeyer et al. <ref type="bibr" target="#b75">[76]</ref> found that a commonly used algorithm to determine enrollment in specific health programs was biased against African Americans, assigning the same level of risk to healthier Caucasian patients.</s><s xml:id="_EGBuZDn">These improperly calibrated algorithms can arise due to a variety of reasons, such as differences in underlying access to care or low representation in training data.</s><s xml:id="_TDknQfj">It is clear that one way to alleviate the risk for such biased algorithms is the ability to learn from EHR data that is more representative of the global population and which goes beyond a single hospital or site.</s><s xml:id="_mmg5fxF">Unfortunately, due to a myriad of reasons such as discrepant data schemes and privacy concerns, it is unlikely that data will eve be connected together in a single database to learn from all at once.</s><s xml:id="_9WkGasV">The creation and utility of standardized common data models, such as OMOP <ref type="bibr" target="#b43">[44]</ref>, allow for more wide-spread replication analyses but it does not overcome the limitations of joint data access.</s><s xml:id="_ft2T76Q">As such, it is imperative that alternative strategies emerge for learning from multiple EHR data sources that go beyond the common discoveryreplication framework.</s><s xml:id="_dsK2e5k">Federated learning might be the tool to enable large-scale representative ML of EHR data and we discuss many studies which demonstrate this fact below.</s></p><p xml:id="_Mk5yCKG"><s xml:id="_w4KeAVC">Federated learning is a viable method to connect EHR data from medical institutions, allowing them to share their experiences, and not their data, with a guarantee of privacy <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b81">82]</ref>.</s><s xml:id="_WCf7q4f">In these scenarios, the performance of ML model will be significantly improved by the iterative improvements of learning from large and diverse medical data sets.</s><s xml:id="_56CWSYq">There have been some tasks were studied in federated learning setting in healthcare, e.g., patient similarity learning <ref type="bibr" target="#b61">[62]</ref>, patient representation learning, phenotyping <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b66">67]</ref>, and predictive modeling <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b89">90]</ref>.</s><s xml:id="_w2bjMg2">Specifically, Lee et al. <ref type="bibr" target="#b61">[62]</ref> presented a privacy-preserving platform in a federated setting for patient similarity learning across institutions.</s><s xml:id="_cks75BY">Their model can find similar patients from one hospital to another without sharing patient-level information.</s><s xml:id="_jC8ebuk">Kim et al. <ref type="bibr" target="#b54">[55]</ref> used tensor factorization models to convert massive electronic health records into meaningful phenotypes for data analysis in federated learning setting.</s><s xml:id="_TvJr4ZQ">Liu et al. <ref type="bibr" target="#b66">[67]</ref> conducted both patient representation learning and obesity comorbidity phenotyping in a federated manner and got good results.</s><s xml:id="_zr9Ednp"><ref type="bibr">Vepakomma et al. [103]</ref> built several configurations upon a distributed deep learning method called SplitNN <ref type="bibr" target="#b35">[36]</ref> to facilitate the health entities collaboratively training deep learning models without sharing sensitive raw data or model details.</s><s xml:id="_NHJpZyT">Silva et al. <ref type="bibr" target="#b92">[93]</ref> illustrated their federated learning framework by investigating brain structural relationships across diseases and clinical cohorts.</s><s xml:id="_3ux5cCp">Huang et al. <ref type="bibr" target="#b44">[45]</ref> sought to tackle the challenge of non-IID ICU patient data by clustering patients into clinically meaningful communities that captured similar diagnoses and geological locations and simultaneously training one model per community.</s></p><p xml:id="_CDYKYYY"><s xml:id="_F7TdFcz">Federated learning has also enabled predictive modeling based on diverse sources, which can provide clinicians with additional insights into the risks and benefits of treating patients earlier <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b89">90]</ref>.</s><s xml:id="_M6PyQvF">Brisimi et al. <ref type="bibr" target="#b9">[10]</ref> aimed to predict future hospitalizations for patients with heart-related diseases using EHR data spread among various data sources/agents by solving the l 1 -regularized sparse Support Vector Machine classifier in federated learning environment.</s><s xml:id="_gRgrnpw">Owkin is using federated learning to predict patients' resistance to certain treatment and drugs, as well as their survival rates for certain diseases <ref type="bibr" target="#b98">[99]</ref>.</s><s xml:id="_s2dybfr">Boughorbel et al. <ref type="bibr" target="#b8">[9]</ref> proposed a federated uncertaintyaware learning algorithm for the prediction of preterm birth from distributed EHR, where the contribution of models with high uncertainty in the aggregation model is reduced.</s><s xml:id="_FPT9mfM">Pfohl et al. <ref type="bibr" target="#b79">[80]</ref> considered the prediction of prolonged length of stay and in-hospital mortality across thirty-one hospitals in the eICU Collaborative Research Database.</s><s xml:id="_q7zeQPg">Sharma et al. <ref type="bibr" target="#b89">[90]</ref> tested a privacy preserving framework for the task of in-hospital mortality prediction among patients admitted to the intensive care unit (ICU).</s><s xml:id="_8Q8NvbK">Their results show that training the model in the federated learning framework leads to comparable performance to the traditional centralized learning setting.</s><s xml:id="_TgkyshQ">Summary of these work is listed in Table <ref type="table">1</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2" xml:id="_VQ2QxP9">Others</head><p xml:id="_4gF5MgE"><s xml:id="_njM72vb">An important application of federated learning is for natural language processing (NLP) tasks.</s><s xml:id="_paucd3W">When Google first proposed federated learning concept in 2016, the application scenario is Gboard-a virtual keyboard of Google for touchscreen mobile devices with support for more than 600 language varieties <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b69">70]</ref>.</s><s xml:id="_fGaZr8V">Indeed, as users increasingly turn to mobile devices, fast mobile input methods with auto-correction, word completion, and next-word prediction features are becoming more and more important.</s><s xml:id="_m8HBEBB">For these NLP tasks, especially next-word prediction, typed text in mobile apps is usually better than the data from scanned books or speech-to-text in terms of aiding typing on a mobile keyboard.</s><s xml:id="_vYnTM45">However, these language data often contain sensitive information, e.g., passwords, search queries, or text messages with personal information.</s><s xml:id="_xd2qfTD">Therefore, federated learning has a promising application in NLP like virtual keyboard prediction <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b69">70]</ref>.</s></p><p xml:id="_9M3VRpt"><s xml:id="_C9cTudy">Other applications include smart retail [112] and finance <ref type="bibr" target="#b53">[54]</ref>.</s><s xml:id="_uZsM6Fd">Specifically, smart retail aims to use machine learning technology to provide personalized services to customers based on data like user purchasing power and product characteristics for product recommendation and sales services.</s><s xml:id="_QXcK7fJ">In terms of financial applications, Tencent's WeBank leverages federated learning technologies for credit risk management, where several Banks could jointly generate a comprehensive credit score for a customer without sharing his or her data <ref type="bibr">[109]</ref>.</s><s xml:id="_rUS6c8P">With the growth and development of federated learning, there are many companies or research teams that have carried out various tools oriented to scientific research and product development.</s><s xml:id="_5tHfW9F">Popular ones are listed in Table <ref type="table" target="#tab_2">2</ref>.</s></p><p xml:id="_xczR6yd"><s xml:id="_wY9tunX">1 Summary of recent work on federated learning for healthcare Problem ML method No. of clients Data Patient similarity learning [62] Hashing 3 MIMIC-III [50] Patient similarity learning [108] Hashing 20 MIMIC-III Phenotyping [55] TF 1-5 MIMIC-III, UCSD [104] Phenotyping [67] NLP 10 MIMIC-III Representation learning [93] PCA 10-100 ADNI, UK Biobank, PPMI, MIRIAD Mortality prediction [45] Autoencoder 5-50 eICU Collaborative Research Database [81] Hospitalization prediction [10] SVM 5, 10 Boston Medical Center Preterm-birth prediction [9] RNN 50 Cerner Health Facts Mortality prediction [80] LR, NN 31 eICU Collaborative Research Database Mortality prediction [90] LR, MLP 2 MIMIC-III Activity recognition [16] CNN 5 UCI Smartphone [4] Adverse drug reactions Prediction [19, 20] SVM, MLP, LR 10 LCED, MIMIC Arrhythmia detection [110] NN 16, 32, 64 PhysioNet Dataset [21] Disease prediction [33] NN 5, 10 Pima Indians Diabetes Dataset [95], Cleveland Heart Disease Database [23] Imaging data analysis VAE 4 MNIST, Brain Imaging Data Mortality prediction [101] LRR, MLP, LASSO 5 Mount Sinai COVID-19 Dataset TF tensor factorization, MLP multi-layer perceptron, VAE variational autoencoder, LCED Limited MarketScan Explorys Claims-EMR Data.</s><s xml:id="_AQnmbgb"><ref type="url" target="https://www.ibm.com/downloads/cas/6KNYVVQ2">https://www.ibm.com/downloads/cas/6KNYVVQ2</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" xml:id="_RV53Ma9">Conclusions and Open Questions</head><p xml:id="_QQyazV3"><s xml:id="_3z5kRGZ">In this survey, we review the current progress on federated learning including, but not limited to healthcare field.</s><s xml:id="_qBWgjJ3">We summarize the general solutions to the various challenges in federated learning and hope to provide a useful resource for researchers to refer.</s><s xml:id="_eZKmKW9">Besides the summarized general issues in federated learning setting, we list some probably encountered directions or open questions when federated learning is applied in healthcare area in the following.</s></p><p xml:id="_nHVzCEU"><s xml:id="_4rmVjjP">-Data Quality.</s><s xml:id="_NUHmyXr">Federated learning has the potential to connect all the isolated medical institutions, hospitals, or devices to make them share their experiences with privacy guarantee.</s><s xml:id="_jvPsywA">However, most health systems suffer from data clutter and efficiency problems.</s><s xml:id="_rceh5wx">The quality of data collected from multiple sources is uneven and there is no uniform data standard.</s><s xml:id="_SBfmHRN">The analyzed results are apparently worthless when dirty data are accidentally used as samples.</s><s xml:id="_jpkrPPP">The ability to strategically leverage medical data is critical.</s><s xml:id="_hC2vX9K">Therefore, how to clean, correct, and complete data and accordingly ensure data quality is a key to improve the machine learning model weather we are dealing with federated learning scenario or not.</s><s xml:id="_vKsj6en">-Incorporating Expert Knowledge.</s><s xml:id="_a3mv96Y">In 2016, IBM introduced Watson for Oncology, a tool that uses the natural language processing system to summarize patients' electronic health records and search the powerful database behind it to advise doctors on treatments.</s><s xml:id="_yw3DdJc">Unfortunately, some oncologists say they trust their judgment more than Watson tells them what needs to be done. <ref type="foot" target="#foot_0">1</ref> Therefore, hopefully doctors will be involved in the training process.</s><s xml:id="_bAJRS6a">Since every data set collected here cannot be of high quality, so it will be very helpful if the standards of evidence-based machine are introduced, doctors will also see the diagnostic criteria of artificial intelligence.</s><s xml:id="_jMG4Fdn">If wrong, doctors will give further guidance to artificial intelligence to improve the accuracy of machine learning model during training process."</s><s xml:id="_DyWSBJG">-Incentive Mechanisms.</s><s xml:id="_W2EZ6ec">With the internet of things and the variety of third party portals, a growing number of smartphone healthcare apps are compatible with wearable devices.</s><s xml:id="_VNSS9xq">In addition to data accumulated in hospitals or medical centers, another type of data that is of great value is coming from wearable devices not only to the researchers but more importantly for the owners.</s><s xml:id="_K9gJtgx">However, during federated model training process, the clients suffer from considerable overhead in communication and computation.</s><s xml:id="_EegffjS">Without well-designed incentives, self-interested mobile or other wearable devices will be reluctant to participate learning tasks, which will hinder the adoption of federated learning <ref type="bibr" target="#b52">[53]</ref>.</s><s xml:id="_QZNnvWC">How to design an efficient incentive mechanism to attract devices with high-quality data to join federated learning is another important problem.</s><s xml:id="_zKPDtp2">-Personalization.</s><s xml:id="_ErynGBD">Wearable devices are more focus on public health, which means helping people who are already healthy to improve their health, such as helping them exercise, practice meditation, and improve their sleep quality.</s><s xml:id="_c3GHrVP">How to assist patients to carry out scientifically designed personalized health management, correct the functional pathological state by examining indicators, and interrupt the pathological change process are very important.</s><s xml:id="_7j2juhe">Reasonable chronic disease management can avoid emergency visits and hospitalization and reduce the number of visits.</s><s xml:id="_4nQpsE4">Cost and labor savings.</s><s xml:id="_wT4dUGm">Although there are some general work about federated learning personalization <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b93">94]</ref>, for healthcare informatics, how to combining the medical domain knowledge and make the global model be personalized for every medical institutions or wearable devices is another open question.</s><s xml:id="_r9J2cNW">-Model Precision.</s><s xml:id="_ZYyzTEK">Federated tries to make isolated institutions or devices share their experiences, and the performance of machine learning model will be significantly improved by the formed large medical dataset.</s><s xml:id="_a2aHApb">However, the prediction task is currently restricted and relatively simple.</s><s xml:id="_uYVrxax">Medical treatment itself is a very professional and accurate field.</s><s xml:id="_nUNXqj5">Medical devices in hospitals have incomparable advantages over wearable devices.</s><s xml:id="_2Gu9FHH">And the models of Doc.ai could predict the phenome collection of one's biometric data based on its selfie, such as height, weight, age, sex, and BMI. <ref type="foot" target="#foot_1">2</ref> How to improve the prediction model to predict future health conditions is definitely worth exploring.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc><div><p xml:id="_6bprD9S"><s xml:id="_D2MjAt5">Fig. 1 Schematic of the federated learning framework.</s><s xml:id="_FzWu9KH">The model is trained in a distributed manner: the institutions periodically communicate the local updates with a central server to learn a global model; the central server aggregates the updates and sends back the parameters of the updated global model</s></p></div></figDesc><graphic coords="3,50.67,386.65,270.28,155.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc><div><p xml:id="_VAZ9PDk"><s xml:id="_vpTkz6f">Fig. 2 Communication efficient federated learning methods.</s><s xml:id="_3AdcBep">Existing research on improving communication efficiency can be categorized into a model compression, b client selection, c updates reducing, and d peer-to-peer learning</s></p></div></figDesc><graphic coords="6,50.67,385.48,337.48,181.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc><div><p xml:id="_8e32xkd"><s xml:id="_dTcNMqK">Fig. 3 Privacy-preserving schemes.</s><s xml:id="_VqRZrBj">a Secure multi-party computation.</s><s xml:id="_d6h9EY8">In security sharing, security values (blue and yellow pie) are split into any number of shares that are distributed among the computing nodes.</s><s xml:id="_XqpFT47">During the computation, no computation node is able to recover the original value nor learn anything about the output (green pie).</s><s xml:id="_Jrf3Ucw">Any nodes can combine their shares to reconstruct the original value.</s><s xml:id="_BednQTs">b Differential privacy.</s><s xml:id="_bXgF9qq">It guarantees that anyone seeing the result of a differentially private analysis will make the same inference (answer 1 and answer 2 are nearly indistinguishable)</s></p></div></figDesc><graphic coords="8,54.06,81.22,235.48,62.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc><div><p xml:id="_dj3ChuS"><s xml:id="_qyNnrub">Popular tools federated learning research</s></p></div></figDesc><table><row><cell>Project name</cell><cell>Developer</cell><cell>Description</cell></row><row><cell>PySyft [87]</cell><cell>OpenMined</cell><cell>It decouples private data from model</cell></row><row><cell></cell><cell></cell><cell>training using federated learning, DP,</cell></row><row><cell></cell><cell></cell><cell>and MPC within PyTorch. TensorFlow</cell></row><row><cell></cell><cell></cell><cell>bindings are also available [77].</cell></row><row><cell>TFF [31]</cell><cell>Google</cell><cell>With TFF, TensorFlow provides users</cell></row><row><cell></cell><cell></cell><cell>with a flexible and open framework</cell></row><row><cell></cell><cell></cell><cell>through which they can simulate dis-</cell></row><row><cell></cell><cell></cell><cell>tributed computing locally.</cell></row><row><cell>FATE [3]</cell><cell>Webank</cell><cell>FATE support the Federated AI</cell></row><row><cell></cell><cell></cell><cell>ecosystem, where a secure computing</cell></row><row><cell></cell><cell></cell><cell>protocol is implemented based on</cell></row><row><cell></cell><cell></cell><cell>homomorphic encryption and MPC.</cell></row><row><cell>Tensor/IO [24]</cell><cell>Dow et al.</cell><cell>Tensor/IO is a lightweight cross-</cell></row><row><cell></cell><cell></cell><cell>platform library for on-device</cell></row><row><cell></cell><cell></cell><cell>machine learning, bringing the power</cell></row><row><cell></cell><cell></cell><cell>of TensorFlow and TensorFlow Lite</cell></row><row><cell></cell><cell></cell><cell>to iOS, Android, and React native</cell></row><row><cell></cell><cell></cell><cell>applications.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p xml:id="_F9JtfZC"><s xml:id="_q79m4cH">http://news.moore.ren/industry/158978.htm</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p xml:id="_3MrmZGC"><s xml:id="_3pnVzbA">https://doc.ai/blog/do-you-know-how-valuable-your-medical-da/</s></p></note>
		</body>
		<back>

			<div type="funding">
<div><head xml:id="_zKpAnvF">Funding</head><p xml:id="_sPwW97F"><s xml:id="_eyS7Ack">The work is supported by <rs type="funder">ONR</rs> <rs type="grantNumber">N00014-18-1-2585</rs> and <rs type="funder">NSF</rs> <rs type="grantNumber">1750326</rs>.</s><s xml:id="_KPvWg6d">FW would also like to acknowledge the support from <rs type="funder">Amazon AWS Machine</rs> <rs type="grantName">Learning Research Award</rs> and <rs type="grantName">Google Faculty Research Award</rs>.</s></p></div>
<div><head xml:id="_ztTp2W2">Compliance with Ethical Standards</head></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_euY6hYK">
					<idno type="grant-number">N00014-18-1-2585</idno>
				</org>
				<org type="funding" xml:id="_6yQSPBt">
					<idno type="grant-number">1750326</idno>
				</org>
				<org type="funding" xml:id="_zc8Ct6R">
					<orgName type="grant-name">Learning Research Award</orgName>
				</org>
				<org type="funding" xml:id="_tmB7AmG">
					<orgName type="grant-name">Google Faculty Research Award</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GZ9zmt9">Conflict of Interest</head><p xml:id="_Ak9rdrf"><s xml:id="_amaYY5m">The authors declare that they have no conflict of interest.</s></p><p xml:id="_nuHxRFG"><s xml:id="_JXSvAzH">Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_huJN3Am">Deep learning with differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2976749.2978318</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_yZXBWGX">Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2016 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="308" to="318" />
		</imprint>
	</monogr>
	<note type="raw_reference">Abadi M, Chu A, Goodfellow I, McMahan HB, Mironov I, Talwar K, Zhang L (2016) Deep learning with differential privacy. In: Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. ACM, pp 308-318</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_fkpKG2e">cpsgd: communication-efficient and differentially-private distributed sgd</title>
		<author>
			<persName><forename type="first">N</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fxx</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_56YKsur">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="7564" to="7575" />
		</imprint>
	</monogr>
	<note type="raw_reference">Agarwal N, Suresh AT, Yu FXX, Kumar S, McMahan B (2018) cpsgd: communication-efficient and differentially-private distributed sgd. In: Advances in neural information processing systems, pp 7564-7575</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Ai</forename><forename type="middle">W</forename></persName>
		</author>
		<ptr target="https://www.fedai.org/cn/" />
		<title level="m" xml:id="_HxTsD6n">Federated ai technology enabler</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">AI W (2019) Federated ai technology enabler. https://www.fedai.org/cn/</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_knWH334">Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Anguita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Oneto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reyes-Ortiz</forename><surname>Jl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_My4Ppvv">International workshop on ambient assisted living</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
	<note type="raw_reference">Anguita D, Ghio A, Oneto L, Parra X, Reyes-Ortiz JL (2012) Human activity recognition on smart- phones using a multiclass hardware-friendly support vector machine. In: International workshop on ambient assisted living. Springer, pp 216-223</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_cxQcRHZ">Efficient training management for mobile crowd-machine learning: A deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Anh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mbBnC3d">IEEE Wireless Communications Letters</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1345" to="1348" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Anh TT, Luong D, Kim DI, Wang LC (2019) Efficient training management for mobile crowd-machine learning: A deep reinforcement learning approach. IEEE Wireless Communications Letters 8(5):1345-1348</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_68uWSEU">An agent-based federated learning object search service</title>
		<author>
			<persName><forename type="first">C</forename><surname>Barcelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gluz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vicari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jgXdkhy">Interdisciplinary Journal of E-Learning and Learning Objects</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="54" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barcelos C, Gluz J, Vicari R (2011) An agent-based federated learning object search service. Interdisciplinary Journal of E-Learning and Learning Objects 7(1):37-54</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Eichner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Grieskamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ingerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kiddon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konecny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mazzocchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01046</idno>
		<title level="m" xml:id="_pY6RbU5">Towards federated learning at scale: System design</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bonawitz K, Eichner H, Grieskamp W, Huba D, Ingerman A, Ivanov V, Kiddon C, Konecny J, Mazzocchi S, McMahan HB, et al. (2019) Towards federated learning at scale: System design. arXiv:1902.01046</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_veEhzqm">Practical secure aggregation for privacy-preserving machine learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kreuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marcedone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Seth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_neaHMmx">Proceedings of the 2017 ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 2017 ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1175" to="1191" />
		</imprint>
	</monogr>
	<note type="raw_reference">Bonawitz K, Ivanov V, Kreuter B, Marcedone A, McMahan HB, Patel S, Ramage D, Segal A, Seth K (2017) Practical secure aggregation for privacy-preserving machine learning. In: Proceedings of the 2017 ACM SIGSAC conference on computer and communications security. ACM, pp 1175-1191</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main" xml:id="_x8DVtV6">Federated uncertainty-aware learning for distributed hospital ehr data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Boughorbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jarray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Venugopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Makhlouf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.12191</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Boughorbel S, Jarray F, Venugopal N, Moosa S, Elhadi H, Makhlouf M (2019) Federated uncertainty-aware learning for distributed hospital ehr data. arXiv:1910.12191</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_CvD7wJT">Federated learning of predictive models from federated electronic health records</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Brisimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olshevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Paschalidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijmedinf.2018.01.007</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7RSPnv7">Int J Med Inform</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="59" to="67" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brisimi TS, Chen R, Mela T, Olshevsky A, Paschalidis IC, Shi W (2018) Federated learning of predictive models from federated electronic health records. Int J Med Inform 112:59-67</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main" xml:id="_kjskMZn">Partitioned variational inference: a unified framework encompassing federated and continual learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Swaroop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.11206</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bui TD, Nguyen CV, Swaroop S, Turner RE (2018) Partitioned variational inference: a unified framework encompassing federated and continual learning. arXiv:1811.11206</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main" xml:id="_mW8ZEn7">Expanding the reach of federated learning by reducing client resource requirements</title>
		<author>
			<persName><forename type="first">S</forename><surname>Caldas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>KoneÄny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.07210</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Caldas S, KoneÄny J, McMahan HB, Talwalkar A (2018) Expanding the reach of federated learning by reducing client resource requirements. arXiv:1812.07210</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Caldas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>KoneÄná»³</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01097</idno>
		<title level="m" xml:id="_2p3rcRJ">Leaf: a benchmark for federated settings</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Caldas S, Wu P, Li T, KoneÄná»³ J, McMahan HB, Smith V, Talwalkar A (2018) Leaf: a benchmark for federated settings. arXiv:1812.01097</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main" xml:id="_hPZm8at">Secure federated matrix factorization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.14711/thesis-991013401041803412</idno>
		<idno type="arXiv">arXiv:1906.05108</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Chai D, Wang L, Chen K, Yang Q (2020) Secure federated matrix factorization. arXiv preprint arXiv:1906.05108</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_ZhnY5We">A near-optimal algorithm for differentially-private principal components</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Sarwate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bJXEjFU">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2905" to="2943" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chaudhuri K, Sarwate AD, Sinha K (2013) A near-optimal algorithm for differentially-private principal components. J Mach Learn Res 14(1):2905-2943</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_t9SrkBy">Fedhealth: a federated transfer learning framework for wearable healthcare</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_reUA5nd">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen Y, Qin X, Wang J, Yu C, Gao W (2020) Fedhealth: a federated transfer learning framework for wearable healthcare. IEEE Intelligent Systems 17</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main" xml:id="_tScnJY6">Communication-efficient federated deep learning with asynchronous model update and temporally weighted aggregation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Y</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1903.07424</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen Y, Sun X, Jin Y (2019) Communication-efficient federated deep learning with asynchronous model update and temporally weighted aggregation. arXiv:1903.07424</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main" xml:id="_7gdwJpw">Secureboost: a lossless federated learning framework</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08755</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cheng K, Fan T, Jin Y, Liu Y, Chen T, Yang Q (2019) Secureboost: a lossless federated learning framework. arXiv:1901.08755</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main" xml:id="_QBB4f3P">Differential privacy-enabled federated learning for sensitive health data</title>
		<author>
			<persName><forename type="first">O</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gkoulalas-Divanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sylla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.02578</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Choudhury O, Gkoulalas-Divanis A, Salonidis T, Sylla I, Park Y, Hsu G, Das A (2019) Differential privacy-enabled federated learning for sensitive health data. arXiv:1910.02578</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_qQMPyUa">Predicting adverse drug reactions on distributed health data using federated learning</title>
		<author>
			<persName><forename type="first">O</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gkoulalas-Divanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sylla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_zpUgqD2">AMIA Annual symposium proceedings</title>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page">313</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Choudhury O, Park Y, Salonidis T, Gkoulalas-Divanis A, Sylla I, et al. (2019) Predicting adverse drug reactions on distributed health data using federated learning. In: AMIA Annual symposium proceedings, vol 2019, p 313. American Medical Informatics Association</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_SPgBsSR">The physionet/computing in cardiology challenge 2015: reducing false arrhythmia alarms in the icu</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shahin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kooistra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dbQWFdn">2015 Computing in Cardiology Conference (CinC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="273" to="276" />
		</imprint>
	</monogr>
	<note type="raw_reference">Clifford GD, Silva I, Moody B, Li Q, Kella D, Shahin A, Kooistra T, Perry D, Mark RG (2015) The physionet/computing in cardiology challenge 2015: reducing false arrhythmia alarms in the icu. In: 2015 Computing in Cardiology Conference (CinC). IEEE, pp 273-276</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main" xml:id="_nJhj3yk">Variational federated multi-task learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Corinzia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.06268</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Corinzia L, Buhmann JM (2019) Variational federated multi-task learning. arXiv:1906.06268</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_GjeyyEh">International application of a new probability algorithm for the diagnosis of coronary artery disease</title>
		<author>
			<persName><forename type="first">R</forename><surname>Detrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Janosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Steinbrunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pfisterer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sandhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Guppy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Froelicher</surname></persName>
		</author>
		<idno type="DOI">10.1016/0002-9149(89)90524-9</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5vJCWFv">The American Journal of Cardiology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="304" to="310" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Detrano R, Janosi A, Steinbrunn W, Pfisterer M, Schmid JJ, Sandhu S, Guppy KH, Lee S, Froelicher V (1989) International application of a new probability algorithm for the diagnosis of coronary artery disease. The American Journal of Cardiology 64(5):304-310 24</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<ptr target="https://github.com/doc-ai/tensorio" />
		<title level="m" xml:id="_C5gT8eR">ai: declarative, on-device machine learning for ios, android, and react native</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">2019). doc.ai: declarative, on-device machine learning for ios, android, and react native. https:// github.com/doc-ai/tensorio</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_VHampcu">Learning from electronic health records across multiple sites: a communication-efficient and privacy-preserving distributed algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Boland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holmes</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocz199</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TzDkTST">J Am Med Inform Assoc</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="376" to="385" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Duan R, Boland MR, Liu Z, Liu Y, Chang HH, Xu H, Chu H, Schmid CH, Forrest CB, Holmes JH, et al. (2020) Learning from electronic health records across multiple sites: a communication-efficient and privacy-preserving distributed algorithm. J Am Med Inform Assoc 27(3):376-385</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_5WZt8Fg">Our data, ourselves: Privacy via distributed noise generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mironov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<idno type="DOI">10.1007/11761679_29</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ctKHrj7">Annual international conference on the theory and applications of cryptographic techniques</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="486" to="503" />
		</imprint>
	</monogr>
	<note type="raw_reference">Dwork C, Kenthapadi K, McSherry F, Mironov I, Naor M (2006) Our data, ourselves: Privacy via distributed noise generation. In: Annual international conference on the theory and applications of cryptographic techniques. Springer, pp 486-503</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_K3tqmcW">Boosting and differential privacy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Rothblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vadhan</surname></persName>
		</author>
		<idno type="DOI">10.1109/focs.2010.12</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_keSxrgn">IEEE 51st Annual symposium on foundations of computer science</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
	<note type="raw_reference">Dwork C, Rothblum GN, Vadhan S (2010) Boosting and differential privacy. In: 2010 IEEE 51st Annual symposium on foundations of computer science. IEEE, pp 51-60</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main" xml:id="_zAVxqPK">Semi-cyclic stochastic gradient descent</title>
		<author>
			<persName><forename type="first">H</forename><surname>Eichner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10120</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Eichner H, Koren T, McMahan HB, Srebro N, Talwar K (2019) Semi-cyclic stochastic gradient descent. arXiv:1904.10120</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_FNGwgcb">A survey of homomorphic encryption for nonspecialists</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Galand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_829hrpH">EURASIP J Inf Secur</title>
		<imprint>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fontaine C, Galand F (2007) A survey of homomorphic encryption for nonspecialists. EURASIP J Inf Secur 2007:15</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_KN7ehwW">The next generation of precision medicine: observational studies, electronic health records, biobanks and continuous monitoring</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Dudley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8TyAEbQ">Hum Mol Genet</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">R1</biblScope>
			<biblScope unit="page" from="R56" to="R62" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson KW, Dudley JT (2018) The next generation of precision medicine: obser- vational studies, electronic health records, biobanks and continuous monitoring. Hum Mol Genet 27(R1):R56-R62 31</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<ptr target="https://www.tensorflow.org/federated" />
		<title level="m" xml:id="_YeqsQJk">Google: Tensorflow federated</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">2019). Google: Tensorflow federated. https://www.tensorflow.org/federated</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_W4Zj5C5">National health information privacy: regulations under the health insurance portability and accountability act</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Gostin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VDgGB5P">JAMA</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3015" to="3021" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gostin LO (2001) National health information privacy: regulations under the health insurance portability and accountability act. JAMA 285(23):3015-3021</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main" xml:id="_d4w89y6">Robust aggregation for adaptive privacy preserving federated learning in healthcare</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>MuÃ±oz-GonzÃ¡lez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Passerat-Palmbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alansary</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.08294</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Grama M, Musat M, MuÃ±oz-GonzÃ¡lez L, Passerat-Palmbach J, Rueckert D, Alansary A (2020) Robust aggregation for adaptive privacy preserving federated learning in healthcare. arXiv:2009.08294</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_VtAVAuV">KETOS: Clinical decision support and machine learning as a service-A training and deployment platform based on Docker, OMOP-CDM, and FHIR Web Services</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gruendner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schwachhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sippl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erpenbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Kapsner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zierk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>StÃ¼rzl</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0225442</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_P2MxfzE">PloS one</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gruendner J, Schwachhofer T, Sippl P, Wolf N, Erpenbeck M, Gulden C, Kapsner LA, Zierk J, Mate S, StÃ¼rzl M, et al. (2019) KETOS: Clinical decision support and machine learning as a service-A training and deployment platform based on Docker, OMOP-CDM, and FHIR Web Services. PloS one 14(10):1-16</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main" xml:id="_NM7UWZJ">One-shot federated learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.11175</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Guha N, Talwalkar A, Smith V (2019) One-shot federated learning. arXiv:1902.11175</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_Ckrmxf4">Distributed learning of deep neural network over multiple agents</title>
		<author>
			<persName><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jnca.2018.05.003</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BNSzfbh">J Netw Comput Appl</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gupta O, Raskar R (2018) Distributed learning of deep neural network over multiple agents. J Netw Comput Appl 116:1-8</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main" xml:id="_6pACfWq">Deep compression: compressing deep neural networks with pruning, trained quantization and huffman coding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.00149</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Han S, Mao H, Dally WJ (2015) Deep compression: compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv:1510.00149</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main" xml:id="_9GcxhxU">Robust federated training via collaborative machine teaching using trusted instances</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02941</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Han Y, Zhang X (2019) Robust federated training via collaborative machine teaching using trusted instances. arXiv:1905.02941</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main" xml:id="_fEM4MAJ">Federated learning for mobile keyboard prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mathews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beaufays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Eichner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kiddon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<idno type="DOI">10.21437/interspeech.2022-11050</idno>
		<idno type="arXiv">arXiv:1811.03604</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hard A, Rao K, Mathews R, Beaufays F, Augenstein S, Eichner H, Kiddon C, Ramage D (2018) Federated learning for mobile keyboard prediction. arXiv:1811.03604</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main" xml:id="_jrrQUrj">Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Henecka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ivey-Law</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thorne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10677</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hardy S, Henecka W, Ivey-Law H, Nock R, Patrini G, Smith G, Thorne B (2017) Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. arXiv:1711.10677</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main" xml:id="_U9TKKzD">Central server free federated learning over single-sided trust social networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.04956</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">He C, Tan C, Tang H, Qiu S, Liu J (2019) Central server free federated learning over single-sided trust social networks. arXiv:1910.04956</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main" xml:id="_Ehjv8aK">The Rationale for Learning Communities and Learning Community Models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>ERIC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Hill P (1985) The Rationale for Learning Communities and Learning Community Models. ERIC</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main" xml:id="_ZXZKcWT">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hinton G, Vinyals O, Dean J (2015) Distilling the knowledge in a neural network. arXiv:1503.02531</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_kSYAsbq">Observational health data sciences and informatics (ohdsi): opportunities for observational researchers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hripcsak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Reich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Huser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Suchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ick</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Rijnbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QhdSKEv">Stud Health Technol Inform</title>
		<imprint>
			<biblScope unit="volume">216</biblScope>
			<biblScope unit="page">574</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hripcsak G, Duke JD, Shah NH, Reich CG, Huser V, Schuemie MJ, Suchard MA, Park RW, Wong ICK, Rijnbeek PR, et al. (2015) Observational health data sciences and informatics (ohdsi): opportunities for observational researchers. Stud Health Technol Inform 216:574</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main" xml:id="_dbQXM4Q">Patient clustering improves efficiency of federated machine learning to predict mortality and hospital stay time using distributed electronic medical records</title>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbi.2019.103291</idno>
		<idno type="arXiv">arXiv:1903.09296</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Huang L, Liu D (2019) Patient clustering improves efficiency of federated machine learning to pre- dict mortality and hospital stay time using distributed electronic medical records. arXiv:1903.09296</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main" xml:id="_beRvRmJ">Privacy preserving qoe modeling using collaborative learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ickin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vandikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fiedler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.09248</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ickin S, Vandikas K, Fiedler M (2019) Privacy preserving qoe modeling using collaborative learning. arXiv:1906.09248</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_fjwDXDG">Mining electronic health records: towards better research applications and clinical care</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brunak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vpGrmJs">Nat Rev Genet</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="395" to="405" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jensen PB, Jensen LJ, Brunak S (2012) Mining electronic health records: towards better research applications and clinical care. Nat Rev Genet 13(6):395-405</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main" xml:id="_eK5x6XV">Improving federated learning personalization via model agnostic meta learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>KoneÄná»³</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kannan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.12488v1</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jiang Y, KoneÄná»³ J, Rush K, Kannan S (2019) Improving federated learning personalization via model agnostic meta learning. arXiv:1909.12488v1</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.11545</idno>
		<title level="m" xml:id="_UAsnhQQ">A survey towards federated semi-supervised learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jin Y, Wei X, Liu Y, Yang Q (2020) A survey towards federated semi-supervised learning. arXiv:2002.11545</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_3TBSt6B">Mimic-iii, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Wei</forename><surname>Hl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2016.35</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DXeBHQH">Sci Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">160035</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson AE, Pollard TJ, Shen L, Li-wei HL, Feng M, Ghassemi M, Moody B, Szolovits P, Celi LA, Mark RG (2016) Mimic-iii, a freely accessible critical care database. Sci Data 3:160035</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main" xml:id="_EXSvC8X">Advances and open problems in federated learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kairouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Avent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Bhagoji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cummings</surname></persName>
		</author>
		<idno type="DOI">10.1561/9781680837896</idno>
		<idno type="arXiv">arXiv:1912.04977</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kairouz P, McMahan HB, Avent B, Bellet A, Bennis M, Bhagoji AN, Bonawitz K, Charles Z, Cormode G, Cummings R, et al. (2019) Advances and open problems in federated learning. arXiv:1912.04977</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_ZZ2PMUR">Efficient decentralized deep learning by dynamic model averaging</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Adilova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sicking</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>HÃ¼ger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schlicht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wirtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wrobel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-10925-7_24</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_cvMCTjb">Joint European conference on machine learning and knowledge discovery in databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="393" to="409" />
		</imprint>
	</monogr>
	<note type="raw_reference">Kamp M, Adilova L, Sicking J, HÃ¼ger F., Schlicht P, Wirtz T, Wrobel S (2018) Efficient decentral- ized deep learning by dynamic model averaging. In: Joint European conference on machine learning and knowledge discovery in databases. Springer, pp 393-409</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main" xml:id="_7wVSHG5">Incentive design for efficient federated learning in mobile networks: A contract theory approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1109/vts-apwcs.2019.8851649</idno>
		<idno type="arXiv">arXiv:1905.07479</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kang J, Xiong Z, Niyato D, Yu H, Liang YC, Kim DI (2019) Incentive design for efficient federated learning in mobile networks: A contract theory approach. arXiv:1905.07479</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_UKXSCse">Credit risk assessment from combined bank records using federated learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Punyani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karkera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jyotinagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_77VupBH">International Research Journal of Engineering and Technology (IRJET)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1355" to="1358" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kawa D, Punyani S, Nayak P, Karkera A, Jyotinagar V (2019) Credit risk assessment from com- bined bank records using federated learning. International Research Journal of Engineering and Technology (IRJET) 6(4):1355-1358</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_2uyrbfD">Federated tensor factorization for computational phenotyping</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_kX3hfh3">Proceedings of the 23rd ACM SIGKDD International conference on knowledge discovery and data mining</title>
		<meeting>the 23rd ACM SIGKDD International conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="887" to="895" />
		</imprint>
	</monogr>
	<note type="raw_reference">Kim Y, Yu H, Jiang X (2017) Federated tensor factorization for computational phenotyping. In: Proceedings of the 23rd ACM SIGKDD International conference on knowledge discovery and data mining. ACM, pp 887-895</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main" xml:id="_5qq52pZ">Federated optimization: distributed optimization beyond the datacenter</title>
		<author>
			<persName><forename type="first">J</forename><surname>KoneÄná»³</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.03575</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KoneÄná»³ J, McMahan B, Ramage D (2015) Federated optimization: distributed optimization beyond the datacenter. arXiv:1511.03575</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main" xml:id="_s4Ddjzg">Federated optimization: distributed machine learning for on-device intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>KoneÄná»³</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>RichtÃ¡rik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02527</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KoneÄná»³ J, McMahan HB, Ramage D, RichtÃ¡rik P (2016) Federated optimization: distributed machine learning for on-device intelligence. arXiv:1610.02527</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main" xml:id="_phEwyj2">Federated learning: strategies for improving communication efficiency</title>
		<author>
			<persName><forename type="first">J</forename><surname>KoneÄná»³</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>RichtÃ¡rik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bacon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05492</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KoneÄná»³ J, McMahan HB, Yu FX, RichtÃ¡rik P, Suresh AT, Bacon D (2016) Federated learning: strategies for improving communication efficiency. arXiv:1610.05492</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main" xml:id="_wrWHbDt">Survey of personalization techniques for federated learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pant</surname></persName>
		</author>
		<idno type="DOI">10.1109/worlds450073.2020.9210355</idno>
		<idno type="arXiv">arXiv:2003.08673</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kulkarni V, Kulkarni M, Pant A (2020) Survey of personalization techniques for federated learning. arXiv:2003.08673</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main" xml:id="_4HVND4p">Peer-to-peer federated learning on graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lalitha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">C</forename><surname>Kilinc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Javidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Koushanfar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11173</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lalitha A, Kilinc OC, Javidi T, Koushanfar F (2019) Peer-to-peer federated learning on graphs. arXiv:1901.11173</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_nBV6CPe">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature14539</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rsnq5bD">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">LeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature 521(7553):436-444</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_AMwueMp">Privacy-preserving patient similarity learning in a federated environment: development and analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jVBtev9">JMIR Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">e20</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lee J, Sun J, Wang F, Wang S, Jun CH, Jiang X (2018) Privacy-preserving patient similarity learning in a federated environment: development and analysis. JMIR Medical Informatics 6(2):e20</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main" xml:id="_MZp8KNm">Federated optimization for heterogeneous networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Sahu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith1</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.06127</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li T, Sahu AK, Zaheer M, Sanjabi M, Talwalkar A, Smith1 V (2019) Federated optimization for heterogeneous networks. arXiv:1812.06127</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main" xml:id="_wUeXykj">Fair resource allocation in federated learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10497</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li T, Sanjabi M, Smith V (2019) Fair resource allocation in federated learning. arXiv:1905.10497</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_8HqSewn">Distributed learning from multiple ehr databases: Contextual embedding models for medical events</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9e65Enp">J Biomed Inform</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">103138</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li Z, Roberts K, Jiang X, Long Q (2019) Distributed learning from multiple ehr databases: Contextual embedding models for medical events. J Biomed Inform 92:103138</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main" xml:id="_nTZBMwh">Federated learning in mobile edge networks: a comprehensive survey</title>
		<author>
			<persName><forename type="first">Wyb</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11875</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lim WYB, Luong NC, Hoang DT, Jiao Y, Liang YC, Yang Q, Niyato D, Miao C (2019) Federated learning in mobile edge networks: a comprehensive survey. arXiv:1909.11875</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main" xml:id="_shWv2Wn">Two-stage federated phenotyping and patient representation learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05596</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu D, Dligach D, Miller T (2019) Two-stage federated phenotyping and patient representation learning. arXiv:1908.05596</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main" xml:id="_gU4Se6q">Threats to federated learning: a survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.02133</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lyu L, Yu H, Yang Q (2020) Threats to federated learning: a survey. arXiv:2003.02133</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_zJbHb3j">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_p8dSaAA">Artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1273" to="1282" />
		</imprint>
	</monogr>
	<note type="raw_reference">McMahan B, Moore E, Ramage D, Hampson S, Arcas BA (2017) Communication-efficient learning of deep networks from decentralized data. In: Artificial intelligence and statistics, pp 1273-1282</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main" xml:id="_79PFfgG">Learning differentially private recurrent language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.06963</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McMahan HB, Ramage D, Talwar K, Zhang L (2017) Learning differentially private recurrent language models. arXiv:1710.06963</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main" xml:id="_wr4MaeJ">Predictive modeling of the hospital readmission risk from patients&apos; claims data using machine learning: A case study on copd</title>
		<author>
			<persName><forename type="first">X</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xyXqtkF">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2362</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Min X, Yu B, Wang F (2019) Predictive modeling of the hospital readmission risk from patients&apos; claims data using machine learning: A case study on copd. Sci Rep 9(1):2362</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main" xml:id="_c7RuNpF">Deep learning for healthcare: review, opportunities and challenges</title>
		<author>
			<persName><forename type="first">R</forename><surname>Miotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Dudley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zgrH6Qu">Brief Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1236" to="1246" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Miotto R, Wang F, Wang S, Jiang X, Dudley JT (2018) Deep learning for healthcare: review, opportunities and challenges. Brief Bioinformatics 19(6):1236-1246</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main" xml:id="_eFPVu7j">Agnostic federated learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sivek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_rUprhF6">Proceedings of the 36th International conference on machine learning, proceedings of machine learning research</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International conference on machine learning, proceedings of machine learning research<address><addrLine>PMLR, Long Beach</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="4615" to="4625" />
		</imprint>
	</monogr>
	<note type="raw_reference">Mohri M, Sivek G, Suresh AT (2019) Agnostic federated learning. In: Chaudhuri K, Salakhutdi- nov R (eds) Proceedings of the 36th International conference on machine learning, proceedings of machine learning research, vol 97. PMLR, Long Beach, pp 4615-4625</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main" xml:id="_hRrMmha">System and method for dynamic context-sensitive federated search of multiple information repositories</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jaffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XBWFK9U">US Patent App</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">743</biblScope>
			<biblScope unit="page">196</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mukherjee R, Jaffe H (2005) System and method for dynamic context-sensitive federated search of multiple information repositories. US Patent App. 10/743,196</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main" xml:id="_svd2QpV">Client selection for federated learning with heterogeneous resources in mobile edge</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nishio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yonetani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.08333</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nishio T, Yonetani R (2018) Client selection for federated learning with heterogeneous resources in mobile edge. arXiv:1804.08333</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main" xml:id="_b625yR7">Dissecting racial bias in an algorithm used to manage the health of populations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vogeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vKNcf5H">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="issue">6464</biblScope>
			<biblScope unit="page" from="447" to="453" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Obermeyer Z, Powers B, Vogeli C, Mullainathan S (2019) Dissecting racial bias in an algorithm used to manage the health of populations. Science 366(6464):447-453</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<ptr target="https://github.com/OpenMined/PySyft-TensorFlow" />
		<title level="m" xml:id="_ZHsRzsz">OpenMined: Pysyft-tensorflow</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">OpenMined: Pysyft-tensorflow. https://github.com/OpenMined/PySyft-TensorFlow (2019)</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main" xml:id="_jtnbM9V">Multiparty differential privacy via aggregation of locally trained classifiers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_QgwrGnZ">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1876" to="1884" />
		</imprint>
	</monogr>
	<note type="raw_reference">Pathak M, Rane S, Raj B (2010) Multiparty differential privacy via aggregation of locally trained classifiers. In: Advances in neural information processing systems, pp 1876-1884</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main" xml:id="_h3dyq4t">Large-scale assessment of a smartwatch to identify atrial fibrillation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Mahaffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hedlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Rumsfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ferris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rajmane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_y9nnePc">N Engl J Med</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="1909" to="1917" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Perez MV, Mahaffey KW, Hedlin H, Rumsfeld JS, Garcia A, Ferris T, Balasubramanian V, Russo AM, Rajmane A, Cheung L, et al. (2019) Large-scale assessment of a smartwatch to identify atrial fibrillation. N Engl J Med 381(20):1909-1917</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main" xml:id="_btbFDRp">Federated and differentially private learning for electronic health records</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Pfohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Heller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05861</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pfohl SR, Dai AM, Heller K (2019) Federated and differentially private learning for electronic health records. arXiv:1911.05861</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main" xml:id="_PCdhT3w">The eicu collaborative research database, a freely available multi-center database for critical care research</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Raffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Badawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cugWPAk">Sci Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">180178</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pollard TJ, Johnson AE, Raffa JD, Celi LA, Mark RG, Badawi O (2018) The eicu collabora- tive research database, a freely available multi-center database for critical care research. Sci Data 5:180178</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main" xml:id="_ZtVqMVa">Modern framework for distributed healthcare data analytics based on hadoop</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">V</forename><surname>Raja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sivasankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_HWYX4nq">Information and communication technology-EurAsia conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="348" to="355" />
		</imprint>
	</monogr>
	<note type="raw_reference">Raja PV, Sivasankar E (2014) Modern framework for distributed healthcare data analytics based on hadoop. In: Information and communication technology-EurAsia conference. Springer, pp 348-355</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main" xml:id="_maYM9px">A model and infrastructure for federated learning content repositories</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rehak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dodds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_7M4dYQX">Interoperability of web-based educational systems workshop</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">143</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Rehak D, Dodds L (2005) A model and infrastructure for federated learning content repositories. In: Interoperability of web-based educational systems workshop, vol 143. Citeseer</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main" xml:id="_Y9x8jyA">Accelerating dnn training in wireless federated edge learning system</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09712</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ren J, Yu G, Ding G (2019) Accelerating dnn training in wireless federated edge learning system. arXiv:1905.09712</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main" xml:id="_WWYpWWX">Braintorrent: a peer-to-peer environment for decentralized federated learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>PÃ¶lsterl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.06731</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Roy AG, Siddiqui S, PÃ¶lsterl S, Navab N, Wachinger C (2019) Braintorrent: a peer-to-peer environment for decentralized federated learning. arXiv:1905.06731</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main" xml:id="_Avv4Jdx">Learning in a large function space: privacypreserving mechanisms for svm learning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taft</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0911.5708</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rubinstein BI, Bartlett PL, Huang L, Taft N (2009) Learning in a large function space: privacy- preserving mechanisms for svm learning. arXiv:0911.5708</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main" xml:id="_phD9cXh">A generic framework for privacy preserving deep learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ryffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trask</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mancuso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Passerat-Palmbach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.04017</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ryffel T, Trask A, Dahl M, Wagner B, Mancuso J, Rueckert D, Passerat-Palmbach J (2018) A generic framework for privacy preserving deep learning. arXiv:1811.04017</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main" xml:id="_rQzr3HH">Federated learning for ultra-reliable lowlatency v2v communications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Samarakoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Saad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Debbah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_X9vVu4M">2018 IEEE Global Communications Conference (GLOBECOM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note type="raw_reference">Samarakoon S, Bennis M, Saad W, Debbah M (2018) Federated learning for ultra-reliable low- latency v2v communications. In: 2018 IEEE Global Communications Conference (GLOBECOM). IEEE, pp 1-7</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main" xml:id="_2CGyUHR">Robust and communication-efficient federated learning from non-iid data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiedemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02891</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sattler F, Wiedemann S, MÃ¼ller K. R., Samek W (2019) Robust and communication-efficient federated learning from non-iid data. arXiv:1903.02891</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Shamout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clifton</forename><forename type="middle">Da</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00354</idno>
		<title level="m" xml:id="_aGBGUTC">Preserving patient privacy while training a predictive model of in-hospital mortality</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sharma P, Shamout FE, Clifton DA (2019) Preserving patient privacy while training a predictive model of in-hospital mortality. arXiv:1912.00354</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main" xml:id="_WPMWKBy">Biscotti: a ledger for private and secure peer-topeer machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beschastnikh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.09904</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shayan M, Fung C, Yoon CJ, Beschastnikh I (2018) Biscotti: a ledger for private and secure peer-to- peer machine learning. arXiv:1811.09904</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main" xml:id="_YsYnWXw">Privacy-preserving deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shokri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_rhe7Q5P">Proceedings of the 22nd ACM SIGSAC conference on computer and communications security</title>
		<meeting>the 22nd ACM SIGSAC conference on computer and communications security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1310" to="1321" />
		</imprint>
	</monogr>
	<note type="raw_reference">Shokri R, Shmatikov V (2015) Privacy-preserving deep learning. In: Proceedings of the 22nd ACM SIGSAC conference on computer and communications security. ACM, pp 1310-1321</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main" xml:id="_Mpvfgpj">Federated learning in distributed medical databases: meta-analysis of large-scale subcortical brain data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Altmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lorenzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.08553</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Silva S, Gutman B, Romero E, Thompson PM, Altmann A, Lorenzi M (2018) Federated learning in distributed medical databases: meta-analysis of large-scale subcortical brain data. arXiv:1810.08553</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main" xml:id="_qVKDvVQ">An investigation into on-device personalization of end-to-end automatic speech recognition models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zadrazil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beaufays</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06678</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sim KC, Zadrazil P, Beaufays F (2019) An investigation into on-device personalization of end-to-end automatic speech recognition models. arXiv:1909.06678</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main" xml:id="_aKmXKF5">Using the adap learning algorithm to forecast the onset of diabetes mellitus</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Everhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Knowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Johannes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_4QWPnH2">Proceedings of the annual symposium on computer application in medical care</title>
		<meeting>the annual symposium on computer application in medical care</meeting>
		<imprint>
			<publisher>American medical informatics association</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page">261</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Smith JW, Everhart J, Dickson W, Knowler W, Johannes R (1988) Using the adap learning algorithm to forecast the onset of diabetes mellitus. In: Proceedings of the annual symposium on computer application in medical care, p 261. American medical informatics association</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main" xml:id="_NtfCWX9">Federated multi-task learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sanjabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dJDWFtG">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4424" to="4434" />
		</imprint>
	</monogr>
	<note type="raw_reference">Smith V, Chiang CK, Sanjabi M, Talwalkar AS (2017) Federated multi-task learning. In: Advances in neural information processing systems, pp 4424-4434</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main" xml:id="_jUNbmen">Multiparty privacy in social media</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Such</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Criado</surname></persName>
		</author>
		<idno type="DOI">10.1145/3208039</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kZCdefF">Commun ACM</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="74" to="81" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Such JM, Criado N (2018) Multiparty privacy in social media. Commun ACM 61(8):74-81</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main" xml:id="_s9akeMv">unfriendly: multi-party privacy risks in social networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C ; )</forename><surname>Grier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Nicol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Hv2nR7J">International symposium on privacy enhancing technologies symposium</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="236" to="252" />
		</imprint>
	</monogr>
	<note type="raw_reference">Thomas K, Grier C (2010) Nicol, D.M.: unfriendly: multi-party privacy risks in social networks. In: International symposium on privacy enhancing technologies symposium. Springer, pp 236-252</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main" xml:id="_3m4C5mY">Federated learning: rewards &amp; challenges of distributed private ml</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tramel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FAY9TEj">Accessed</title>
		<imprint>
			<date type="published" when="2019-05-28">2019. May 28, 2019 100</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tramel E (2019) Federated learning: rewards &amp; challenges of distributed private ml. Accessed May 28, 2019 100.</note>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main" xml:id="_k4BnkWp">A hybrid approach to privacy-preserving federated learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Truex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Baracaldo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.03224101</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Truex S, Baracaldo N, Anwar A, Steinke T, Ludwig H, Zhang R (2018) A hybrid approach to privacy-preserving federated learning. arXiv:1812.03224 101.</note>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main" xml:id="_GbrBCwn">Federated learning of electronic health records improves mortality prediction in patients hospitalized with covid-19 medRxiv 102</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Jaladanki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Paranjpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Wanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<idno type="DOI">10.1101/2020.08.11.20172809</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vaid A, Jaladanki SK, Xu J, Teng S, Kumar A, Lee S, Somani S, Paranjpe I, De Freitas JK, Wanyan T, et al. (2020) Federated learning of electronic health records improves mortality prediction in patients hospitalized with covid-19 medRxiv 102.</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main" xml:id="_xpWZD6d">Deep reinforcement learning with double q-learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v30i1.10295</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_b4dc8qh">Thirtieth AAAI conference on artificial intelligence 103</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Van Hasselt H, Guez A, Silver D (2016) Deep reinforcement learning with double q-learning. In: Thirtieth AAAI conference on artificial intelligence 103.</note>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main" xml:id="_9yC2FYE">Split learning for health: distributed deep learning without sharing raw patient data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vepakomma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Swedish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-96896-0_19</idno>
		<idno type="arXiv">arXiv:1812.00564104</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vepakomma P, Gupta O, Swedish T, Raskar R (2018) Split learning for health: distributed deep learning without sharing raw patient data. arXiv:1812.00564 104.</note>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main" xml:id="_kgSVghr">The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">105</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Wah C, Branson S, Welinder P, Perona P, Belongie S (2011) The caltech-ucsd birds-200-2011 dataset 105.</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main" xml:id="_Pzap5gc">Ai in health: state of the art, challenges, and future directions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Preininger</surname></persName>
		</author>
		<idno type="DOI">10.1055/s-0039-1677908</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_X3r8rET">Yearb Med Inform</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="16" to="026" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang F, Preininger A (2019) Ai in health: state of the art, challenges, and future directions. Yearb Med Inform 28(01):016-026 106.</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main" xml:id="_nbEhNcW">In-edge ai: Intelligentizing mobile edge computing, caching and communication by federated learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.07857107</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang X, Han Y, Wang C, Zhao Q, Chen X, Chen M (2018) In-edge ai: Intelligentizing mobile edge computing, caching and communication by federated learning. arXiv:1809.07857 107.</note>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main" xml:id="_AtQpmbD">Federated learning for healthcare informatics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.06270108</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Xu J, Wang F (2019) Federated learning for healthcare informatics. arXiv:1911.06270 108.</note>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main" xml:id="_Fc2DxSQ">Federated patient hashing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_RHyXDYt">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6486" to="6493" />
		</imprint>
	</monogr>
	<note type="raw_reference">Xu J, Xu Z, Walker P, Wang F (2020) Federated patient hashing. In: AAAI, pp 6486-6493 109.</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main" xml:id="_j49Zg3Y">Federated machine learning: concept and applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<idno type="DOI">10.1145/3298981</idno>
		<ptr target="https://doi.org/10.1145/3298981110" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_txMgmns">ACM Trans Intell Syst Technol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang Q, Liu Y, Chen T, Tong Y (2019) Federated machine learning: concept and applications. ACM Trans Intell Syst Technol 10(2):12:1-12:19. https://doi.org/10.1145/3298981 110.</note>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main" xml:id="_GcJfTm6">A federated learning framework for healthcare iot devices</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05083111</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yuan B, Ge S, Xing W (2020) A federated learning framework for healthcare iot devices. arXiv:2005.05083 111.</note>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main" xml:id="_7qsuvc2">Federated learning with non-iid data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Suda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Civin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00582112</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhao Y, Li M, Lai L, Suda N, Civin D, Chandra V (2018) Federated learning with non-iid data. arXiv:1806.00582 112.</note>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title level="m" type="main" xml:id="_wfWmtgh">Mobile edge and reputationbased crowdsourcing iot federated learning: a secure, decentralized and privacy-preserving system</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.10893113</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhao Y, Zhao J, Jiang L, Tan R, Niyato D (2019) Mobile edge and reputation- based crowdsourcing iot federated learning: a secure, decentralized and privacy-preserving system. arXiv:1906.10893 113.</note>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main" xml:id="_mAR4HnV">Multi-objective evolutionary federated learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8B3bDq9">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhu H, Jin Y (2019) Multi-objective evolutionary federated learning. IEEE transactions on neural networks and learning systems 114.</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main" xml:id="_86DNFSr">Federated reinforcement learning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08277</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhuo HH, Feng W, Xu Q, Yang Q, Lin Y (2019) Federated reinforcement learning. arXiv:1901.08277</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
