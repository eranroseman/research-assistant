<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_Zhw6vGT">Generative Large Language Model-Powered Conversational AI App for Personalized Risk Assessment: Case Study in COVID-19</title>
				<funder ref="#_xpwvg7s #_dwMDmSf">
					<orgName type="full">Eunice Kennedy Shriver Institute of Child Health and Human Development of the National Institute of Health</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mohammad</forename><forename type="middle">Amin</forename><surname>Roshani</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Computer Science , Wayne State University , Detroit , MI , United States</note>
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Wayne State University</orgName>
								<address>
									<settlement>Detroit</settlement>
									<region>MI</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>BSc</roleName><forename type="first">Xiangyu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Computer Science , Wayne State University , Detroit , MI , United States</note>
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Wayne State University</orgName>
								<address>
									<settlement>Detroit</settlement>
									<region>MI</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>BE, MCS</roleName><forename type="first">Yao</forename><surname>Qiang</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Department of Computer Science , Oakland University , Rochester , MI , United States</note>
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Oakland University</orgName>
								<address>
									<settlement>Rochester</settlement>
									<region>MI</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>PhD;</roleName><forename type="first">Srinivasan</forename><surname>Suresh</surname></persName>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Department of Pediatrics , University of Pittsburg Medical Center Children&apos;s Hospital of Pittsburgh , Pittsburgh , PA , United States</note>
								<orgName type="department">Department of Pediatrics</orgName>
								<orgName type="institution">University of Pittsburg Medical Center Children&apos;s Hospital of Pittsburgh</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MD</roleName><forename type="first">Steven</forename><surname>Hicks</surname></persName>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Department of Pediatrics , Penn State College of Medicine , Hershey , PA , United States</note>
								<orgName type="department">Department of Pediatrics</orgName>
								<orgName type="institution">Penn State College of Medicine</orgName>
								<address>
									<settlement>Hershey</settlement>
									<region>PA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MD</roleName><forename type="first">Usha</forename><surname>Sethuraman</surname></persName>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Division of Emergency Medicine , Department of Pediatrics , Children&apos;s Hospital of Michigan , Detroit , MI , United States</note>
								<orgName type="department" key="dep1">Division of Emergency Medicine</orgName>
								<orgName type="department" key="dep2">Department of Pediatrics</orgName>
								<orgName type="institution">Children&apos;s Hospital of Michigan</orgName>
								<address>
									<settlement>Detroit</settlement>
									<region>MI</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><roleName>PhD</roleName><forename type="first">Dongxiao</forename><surname>Zhu</surname></persName>
							<email>dzhu@wayne.edu</email>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Department of Computer Science , Wayne State University , Detroit , MI , United States</note>
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Wayne State University</orgName>
								<address>
									<settlement>Detroit</settlement>
									<region>MI</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<note type="raw_affiliation">Department of Computer Science Wayne State University 5057 Woodward Ave Suite 14101.3 Detroit , MI , 48202 United States</note>
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Wayne State University</orgName>
								<address>
									<addrLine>5057 Woodward Ave Suite 14101.3</addrLine>
									<postCode>48202</postCode>
									<settlement>Detroit</settlement>
									<region>MI</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_MrCSJz3">Generative Large Language Model-Powered Conversational AI App for Personalized Risk Assessment: Case Study in COVID-19</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FE45F35B220E51F6C51729109A2D6FEF</idno>
					<idno type="DOI">10.2196/67363</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T10:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords xml:id="_m97jRMB">; artificial intelligence; COVID-19</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_NWUK77k"><p xml:id="_t8f6txP"><s xml:id="_GzuS3TE">Background: Large language models (LLMs) have demonstrated powerful capabilities in natural language tasks and are increasingly being integrated into health care for tasks like disease risk assessment.</s><s xml:id="_4mSm8aK">Traditional machine learning methods rely on structured data and coding, limiting their flexibility in dynamic clinical environments.</s><s xml:id="_AJCzFH4">This study presents a novel approach to disease risk assessment using generative LLMs through conversational artificial intelligence (AI), eliminating the need for programming.</s></p><p xml:id="_DS3HK7S"><s xml:id="_ymNUkqV">Objective: This study evaluates the use of pretrained generative LLMs, including LLaMA2-7b and Flan-T5-xl, for COVID-19 severity prediction with the goal of enabling a real-time, no-code, risk assessment solution through chatbot-based, question-answering interactions.</s><s xml:id="_YA5q7t5">To contextualize their performance, we compare LLMs with traditional machine learning classifiers, such as logistic regression, extreme gradient boosting (XGBoost), and random forest, which rely on tabular data.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_5vAkPr5">Methods:</head><p xml:id="_WcMZBcq"><s xml:id="_eaCEzUD">We fine-tuned LLMs using few-shot natural language examples from a dataset of 393 pediatric patients, developing a mobile app that integrates these models to provide real-time, no-code, COVID-19 severity risk assessment through clinician-patient interaction.</s><s xml:id="_gAr32kj">The LLMs were compared with traditional classifiers across different experimental settings, using the area under the curve (AUC) as the primary evaluation metric.</s><s xml:id="_xddKskk">Feature importance derived from LLM attention layers was also analyzed to enhance interpretability.</s></p><p xml:id="_uYHtkFA"><s xml:id="_Dpmzf38">Results: Generative LLMs demonstrated strong performance in low-data settings.</s><s xml:id="_hbFYuad">In zero-shot scenarios, the T0-3b-T model achieved an AUC of 0.75, while other LLMs, such as T0pp(8bit)-T and Flan-T5-xl-T, reached 0.67 and 0.69, respectively.</s><s xml:id="_fAz9wH9">At 2-shot settings, logistic regression and random forest achieved an AUC of 0.57, while Flan-T5-xl-T and T0-3b-T obtained 0.69 and 0.65, respectively.</s><s xml:id="_bSC975U">By 32-shot settings, Flan-T5-xl-T reached 0.70, similar to logistic regression (0.69) and random forest (0.68), while XGBoost improved to 0.65.</s><s xml:id="_DmU4HDu">These results illustrate the differences in how generative LLMs and traditional models handle the increasing data availability.</s><s xml:id="_jbvBuQ6">LLMs perform well in low-data scenarios, whereas traditional models rely more on structured tabular data and labeled training examples.</s><s xml:id="_h7w8Rby">Furthermore, the mobile app provides real-time, COVID-19 severity assessments and personalized insights through attention-based feature importance, adding value to the clinical interpretation of the results.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9RNKWRu">Conclusions:</head><p xml:id="_5eWeDhe"><s xml:id="_DeFemzR">Generative LLMs provide a robust alternative to traditional classifiers, particularly in scenarios with limited labeled data.</s><s xml:id="_kmqYvwJ">Their ability to handle unstructured inputs and deliver personalized, real-time assessments without coding makes them highly adaptable to clinical settings.</s><s xml:id="_4TjJNbW">This study underscores the potential of LLM-powered conversational artificial intelligence</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_WzEEVxQ">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_vUHKY6k">Background</head><p xml:id="_FJ2K8n7"><s xml:id="_Y85A4qu">Disease risk assessment is a critical tool in public health surveillance, where demographic variables and social determinants are often used to assess a patient's susceptibility to disease, predict treatment response, and forecast severity outcomes.</s><s xml:id="_p4btUaS">Traditionally, these predictions have been carried out using machine learning models trained de novo for each disease or condition using curated tabular data <ref type="bibr" target="#b1">[1]</ref><ref type="bibr" target="#b2">[2]</ref><ref type="bibr" target="#b3">[3]</ref>.</s><s xml:id="_QvyNuRF">For example, Wang et al <ref type="bibr" target="#b2">[2]</ref> developed a linear model-based, multitask learning approach to predict the risk of childhood obesity based on geolocation data.</s><s xml:id="_B7KwEYY">Li et al <ref type="bibr" target="#b3">[3]</ref> proposed a mixture neural network to stratify patients and predict heart failure risk within each subgroup.</s></p><p xml:id="_5Vr2xya"><s xml:id="_YKDGJrV">The advent of transformers has marked a significant shift, allowing researchers to deploy advanced models that improve prediction accuracy and handle complex data structures more effectively.</s><s xml:id="_mzRJ8Dz">Bidirectional Encoder Representations from Transformers (BERT)-style models <ref type="bibr" target="#b4">[4]</ref> have been extensively used in various health care tasks.</s><s xml:id="_NQP72sV">Notable examples include ClinicalBERT <ref type="bibr" target="#b5">[5]</ref> and BioClinicalBERT <ref type="bibr" target="#b6">[6]</ref>, both trained on clinical notes in the MIMIC-III database.</s><s xml:id="_dVQAqzN">MedBERT <ref type="bibr" target="#b7">[7]</ref>, further trained on electronic health records (EHRs), achieved a high area under the curve (AUC) scores for disease risk prediction.</s><s xml:id="_GfUqPyR">However, BERT-based models, primarily designed for discriminative tasks, face limitations in processing streaming question-and-answer (QA) pairs typical in conversational data science applications due to their architectural constraints.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_qKc6Evr">Generative Large Language Models for Health Care</head><p xml:id="_c7gCTYp"><s xml:id="_hPmN7mM">Generative large language models (LLMs), such as OpenAI's GPT-3 <ref type="bibr" target="#b8">[8]</ref>, have transcended the limitations of discriminative models by excelling at handling diverse data formats, including both structured clinical data and unstructured text like patient narratives and medical histories.</s><s xml:id="_un92THT">This versatility allows them to integrate and synthesize information from multiple sources, making them highly effective for complex tasks such as predicting disease severity.</s><s xml:id="_kAKZJv4">Generative LLMs have been applied in health care across various domains, including diagnostic support, clinical decision-making, clinical knowledge extraction, and risk prediction with personalized monitoring.</s></p><p xml:id="_a5VnYYR"><s xml:id="_VDS2byU">In diagnostic support, generative LLMs like ChatGPT and GPT-4 <ref type="bibr" target="#b9">[9]</ref> have been used to aid clinical diagnosis by leveraging structured and unstructured data.</s><s xml:id="_KsyjnK5">Gilson et al <ref type="bibr" target="#b10">[10]</ref> assessed ChatGPT's ability to answer the United States Medical Licensing Examination (USMLE) Step 1 and Step 2 multiple-choice questions, highlighting its potential for medical education and diagnostic assistance.</s><s xml:id="_NEzY27S">Kung et al <ref type="bibr" target="#b11">[11]</ref> evaluated ChatGPT's clinical reasoning by testing it on structured questions from the USMLE, simulating clinical decision-making tasks without domain-specific training.</s><s xml:id="_nBw6AQR">Ali et al <ref type="bibr" target="#b12">[12]</ref> explored the use of ChatGPT to generate patient-friendly clinical letters based on semistructured prompts, aiming to improve communication efficiency while ensuring accessibility for patients.</s><s xml:id="_Kwbc7E9">Xv et al <ref type="bibr" target="#b13">[13]</ref> used ChatGPT to assist in diagnosing urological diseases using semistructured patient data, demonstrating its potential as a tool for preliminary diagnostic support.</s><s xml:id="_Wh5Z8zt">Kanjee et al <ref type="bibr" target="#b14">[14]</ref> evaluated GPT-4's diagnostic accuracy in complex clinical cases, showing its ability to generate differential diagnoses based on patient history and clinical findings.</s></p><p xml:id="_SG335k3"><s xml:id="_E6U9x2X">Generative LLMs have also become valuable tools in synthesizing vast amounts of medical literature, enabling clinicians and researchers to stay current with scientific advancements.</s><s xml:id="_82gqFgN">Tang et al <ref type="bibr" target="#b15">[15]</ref> evaluated LLMs in summarizing medical evidence, demonstrating that models like GPT-4 <ref type="bibr" target="#b9">[9]</ref> can generate concise summaries of research articles, facilitating faster knowledge assimilation.</s><s xml:id="_Fk4XUjz">Sallam <ref type="bibr" target="#b16">[16]</ref> discussed how LLMs could assist in systematic reviews and meta-analyses, reducing the effort required in literature search and data extraction.</s></p><p xml:id="_q9XjMsW"><s xml:id="_dr4Wbm7">In risk prediction and personalized patient monitoring, generative LLMs have shown significant potential.</s><s xml:id="_ehrEXJ5">Health-LLM <ref type="bibr" target="#b17">[17]</ref> integrates wearable sensor data, such as physical activity and heart rate, to predict stress, fatigue, and other health metrics.</s><s xml:id="_qdgb5tq">Leveraging zero-shot learning, the model generalizes effectively across various health prediction tasks without task-specific training.</s><s xml:id="_53gJPPd">ClinicalMamba <ref type="bibr" target="#b18">[18]</ref> excels in analyzing longitudinal EHR notes for disease progression prediction and patient cohort selection by processing unstructured clinical notes over extended sequences.</s></p><p xml:id="_FtHeYmN"><s xml:id="_mPZFbTV">With increasingly longer context windows, up to 8192 tokens in OpenAI's GPT-4 <ref type="bibr" target="#b19">[19]</ref>, generative LLMs can efficiently manage extensive patient records and interaction histories.</s><s xml:id="_4edWW7H">This capability to process long, varied inputs allows them to generalize effectively even with limited labeled domain-specific data.</s><s xml:id="_E7UXEvq">Furthermore, their ability to handle multiturn conversations positions them uniquely for real-time applications, facilitating no-code disease assessment through interactive patient engagements.</s></p><p xml:id="_C8br6c2"><s xml:id="_wQZggEm">Despite the remarkable performance of proprietary black-box LLMs like GPT-4 and MedPaLM-2 <ref type="bibr" target="#b20">[20]</ref>, there is growing interest in deploying white-box models in health care and other high-stakes domains.</s><s xml:id="_tCGVgAs">White-box models mitigate risks related to data privacy breaches and hallucination by allowing for full transparency and control over the model's architecture and parameters.</s><s xml:id="_bMNmhVC">Their smaller size enables deployment on local devices, enhancing data security by keeping sensitive information on the device.</s><s xml:id="_dBFUsza">Furthermore, the transparent nature of these models facilitates interpretability, which is crucial for explainability in clinical settings.</s><s xml:id="_EcqbGyD">This shift towards transparent and customizable models is exemplified by PMC-LLaMA <ref type="bibr" target="#b21">[21]</ref>, adapted from the LLaMA architecture and fine-tuned on extensive health and medical corpora.</s><s xml:id="_kJ7XY6C">PMC-LLaMA has outperformed larger models in several health and medical QA benchmarks, highlighting the effectiveness of domain-specific fine-tuning.</s><s xml:id="_KfyvhJw">One of the few studies exploring generative LLMs for disease diagnosis and risk assessment is CPLLM <ref type="bibr" target="#b22">[22]</ref>.</s><s xml:id="_GHeUJWK">CPLLM fine-tunes Llama2 <ref type="bibr" target="#b23">[23]</ref> as a general LLM and uses BioMedLM <ref type="bibr" target="#b24">[24]</ref>, a model trained extensively on biological and clinical texts, to perform various prediction tasks, including disease diagnosis and patient outcome forecasting.</s><s xml:id="_rEThpg9">These models demonstrate the potential of LLMs in understanding complex medical language and reasoning.</s><s xml:id="_UwtcPmx">However, their application to direct disease risk assessment using streaming QA interactions remains limited, and they do not fully leverage the interpretability benefits of white-box models for explainability.</s></p><p xml:id="_cwxveEE"><s xml:id="_VjkRrCZ">Our work builds upon these advancements by transitioning from traditional machine learning-based health outcome prediction-which typically relies on structured tabular data-to chatbot-based, no-code prediction using streaming QA interactions.</s><s xml:id="_RhdTNsJ">We develop a generative artificial intelligence (GenAI)-powered mobile app that integrates fine-tuned white-box LLMs-including LLaMA2, Flan-T5, and T0 models-as the core for personalized risk assessment and patient-clinician communication.</s><s xml:id="_5AcAg8E">The app provides a natural language interface for risk assessment, processes user responses in real time, and can be deployed locally on devices to enhance data privacy and security.</s><s xml:id="_f7vGxFE">Figure <ref type="figure" target="#fig_0">1</ref> shows a comparison of our work to traditional methods.</s><s xml:id="_TjRnvGf">Comparison between large language model (LLM)-based conversational AI (Conv-AI) and traditional machine learning methods for disease risk assessment.</s><s xml:id="_CGBtcMZ">The Conv-AI leverages pretrained models that require only very few-shot fine-tuning, can handle unstructured textual data, provide real-time feature importance for each risk assessment it provides, and offer transferability with zero to very few shots for new risk assessment tasks.</s><s xml:id="_zx6UTq2">In contrast, traditional machine learning methods require large datasets for de novo training, process structured data, rely on extra computational steps for instance-specific post hoc feature importance (eg, Shapley additive explanations), and need retraining for each new task.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mQAwScV">Contributions</head><p xml:id="_QKdMPgy"><s xml:id="_dddfcwb">Our contributions to the field of LLM-based disease risk assessment are diverse.</s><s xml:id="_m725DzE">First and foremost, we transition from traditional machine learning-based health outcome prediction-which typically relies on structured tabular data-to chatbot-based, no-code prediction using streaming QA interactions.</s><s xml:id="_e3dB7pU">This is realized through the development of a GenAI-powered mobile app that integrates fine-tuned LLMs as the core for personalized risk assessment and patient-clinician communication.</s><s xml:id="_8NewJnd">The app not only assesses disease risk for patients but also provides contextual insights related to risk surveillance and mitigation through natural language conversation.</s></p><p xml:id="_McRv86w"><s xml:id="_czHyaSK">Second, we demonstrate that generative LLMs can outperform traditional machine learning methods, such as logistic regression <ref type="bibr" target="#b25">[25]</ref>, random forest <ref type="bibr" target="#b26">[26]</ref>, and extreme gradient boosting (XGBoost) <ref type="bibr" target="#b27">[27]</ref>, in low-data regimes, which is critical for medical applications where labeled data are scarce.</s><s xml:id="_fGQtr9t">For instance, our results show that LLMs like the T0-3b model achieve an AUC of 0.75 in zero-shot settings, demonstrating their potential for disease risk assessment even without task-specific training.</s></p><p xml:id="_JPhkJn8"><s xml:id="_aErh93v">In addition, we provide a comprehensive comparison of both decoder-only and encoder-decoder models, fine-tuned using the widely adopted, parameter-efficient, low-rank adaptation (LoRA) method <ref type="bibr" target="#b28">[28]</ref>.</s></p><p xml:id="_KmUNPrv"><s xml:id="_DBDjbH8">Third, we introduce a feature importance analysis derived from the LLM's attention layers, providing personalized insights into the most influential factors driving the model's predictions.</s><s xml:id="_TRPY4va">This enhances the interpretability and usability of the risk assessment for both patients and clinicians, offering real-time, instance-specific explanations during inference.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_JHZFsHJ">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_qpvMN4y">Our Research Objective</head><p xml:id="_nhWqAY9"><s xml:id="_NcDa48N">The primary objective of this study is to explore the effectiveness of pretrained generative LLMs in no-code risk assessment of disease severity using few-shot multihop QA interactions.</s><s xml:id="_PerJVU7">We aim to evaluate how these generative LLM-powered chatbots can use streaming QA interactions to accurately classify patient outcomes as severe or nonsevere, which is crucial for early risk assessment and optimizing health care resource allocation.</s><s xml:id="_kyJqhTm">Through a case study of COVID-19 severity risk assessment, we developed an app that uses open-source generative LLMs to determine the severity of COVID-19 outcomes.</s><s xml:id="_yBrgnhM">This involves leveraging the models' capabilities in zero-shot and few-shot settings, with a focus on the use of serialization techniques to enhance their effectiveness and generalizability.</s><s xml:id="_YXEnhJd">We also integrate real-time feature importance to provide interpretable risk assessments.</s><s xml:id="_S83BCcn">Figure <ref type="figure" target="#fig_1">2</ref> shows the workflow of our approach, from fine-tuning generative LLMs using serialized QA pairs to real-time risk assessment through a conversational interface.</s><s xml:id="_WWHPFNE">Workflow for few-shot COVID-19 severity risk assessment using generative large language models (LLMs) with different serialization techniques.</s><s xml:id="_6PHSAwm">The top section, labeled "Backend -system developer," shows the fine-tuning phase where a few-shot sample of patient data, serialized through list and text templates, is used to fine-tune the LLMs.</s><s xml:id="_D68Sn66">This backend process includes the creation of prompts and corresponding labels for model fine-tuning.</s><s xml:id="_MA2xP28">The bottom section, labeled "Frontend -user," illustrates how a conversational chatbot interacts with users through our application to gather responses through streaming QA interactions.</s><s xml:id="_h8ZuWue">These responses are analyzed by the fine-tuned LLM in real time, providing risk assessments and highlighting the top attributing features that explain the model's risk assessment.</s><s xml:id="_5uW5k9F">QA: question-and-answer.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_umEnfxr">Data Collection</head><p xml:id="_9hd4nez"><s xml:id="_sxYaVEF">A dataset was collected from the emergency departments of Children's Hospital of Michigan and UPMC Children's Hospital of Pittsburgh between March 2021 and February 2022.</s><s xml:id="_mvfpJam">Table <ref type="table">1</ref> provides an overview of the binary features used in our study, including demographic, clinical, and social determinants that may influence COVID-19 severity risk.</s><s xml:id="_s2Y3aBh">The dataset includes a total of 393 participant records, each characterized by responses to a series of carefully designed questions (see Figure <ref type="figure" target="#fig_2">3</ref> for sample QA pairs).</s></p><p xml:id="_488y3uj"><s xml:id="_Es4AcmF">The severity of illness was defined based on the presence of any of the following criteria:</s></p><p xml:id="_B9Pbuca"><s xml:id="_9Nzz8mk">1. Requirement for supplemental oxygen (≥50% fraction of inspired oxygen)</s></p><p xml:id="_Z4Bhp83"><s xml:id="_s3vB8DZ">2. Need for mechanical ventilation or noninvasive positive pressure ventilation (bilevel positive airway pressure and continuous positive airway pressure) 3. Need for vasopressors or inotropes 4. Requirement for extracorporeal membrane oxygenation 5. Cardiopulmonary resuscitation 6. Death from a related cause within 4 weeks after discharge Children meeting any of these criteria were categorized as having severe illness.</s><s xml:id="_pXmebNr">These outcomes were determined through chart reviews and parent surveys conducted 30 days after discharge <ref type="bibr" target="#b29">[29]</ref>.</s></p><p xml:id="_napQrpA"><s xml:id="_GgttExg">Outliers were removed, and feature selection was performed using Shapley additive explanations values <ref type="bibr" target="#b30">[30]</ref>, resulting in the final dataset used for analysis.</s></p><p xml:id="_D24gk8f"><s xml:id="_yAXWFux">Table <ref type="table">1</ref>.</s><s xml:id="_DDJnGGb">Binary features used in the study.</s><s xml:id="_vpp5fXW">The dataset consists of 393 patient records with 15 features representing demographics, clinical symptoms, and social determinants.</s><s xml:id="_t7ajP63">These features serve as inputs for traditional machine learning models and are also serialized for fine-tuning generative large language models (LLMs).</s><s xml:id="_pnShP2G">Tabular Data for Traditional Models As traditional machine learning methods require tabular data as input, we formalize the questionnaire QA pairs , where n=393, represents the binary feature vector of the i-th instance where d=15, and denotes the binary class label indicating the presence or absence of severe COVID-19 symptoms determined by clinicians.</s><s xml:id="_Ts7baeW">Each feature vector x i consists of binary indicators representing social determinants and clinical and demographic factors that may influence the severity of COVID-19, such as age, preexisting conditions, vital signs, and laboratory test results.</s></p><p xml:id="_jVpah6T"><s xml:id="_qPPS9mF">These features are shown in Table <ref type="table">1</ref>.</s><s xml:id="_snE6AWk">The feature names are denoted as , where each f j is a natural-language string describing the corresponding attribute.</s></p><p xml:id="_eQcjvt7"><s xml:id="_d5cM5nm">The task is to predict the binary outcome y i based on the information provided in x i .</s><s xml:id="_FrTDuQT">This constitutes a supervised learning problem where the objective is to train a model to minimize prediction error on unseen data.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_dDNXRMw">Serialization for New Conversational AI</head><p xml:id="_rwx9B3x"><s xml:id="_DWaz5yF">At the time of data collection from 2021 to 2022, we did not yet have a chatbot for automated data donations from users, so we used a questionnaire to collect answers from each patient based on a set of questions designed for this study.</s><s xml:id="_zNrDRyt">As a result, the native format of the dataset consists of QA pairs, which were subsequently serialized to fine-tune the generative LLMs for the risk assessment task.</s><s xml:id="_B4qdSSb">It is important to note that the fine-tuned model is capable of assessing risk using streaming QA interactions in real time (Figures <ref type="figure" target="#fig_1">2</ref> and <ref type="figure" target="#fig_2">3</ref>).</s></p><p xml:id="_tVMgAUD"><s xml:id="_NYJMabg">To achieve serialization, the features in our dataset are denoted as , and their associated values as</s></p><p xml:id="_MYscv7C"><s xml:id="_9BeNVdE">. This notation provides a structure that is transformed into natural language prompts for the LLM.</s></p><p xml:id="_Q5vtCSc"><s xml:id="_TxWysH4">We used two main serialization methods from TABLLM <ref type="bibr" target="#b31">[31]</ref>, the list template and the text template, to create natural language representations of the data.</s><s xml:id="_cQKDgaJ">As shown in Figure <ref type="figure" target="#fig_1">2</ref>, the list template links each feature with its value using an equal sign ("="), while the text template uses a narrative structure with the word "is" to connect each feature with its value.</s><s xml:id="_Wxrd2Bu">These templates enable us to evaluate which serialization approach better translates the data into actionable insights by the LLM.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_g8XK943">Generative LLMs</head><p xml:id="_p6tuYmR"><s xml:id="_YNpbJv6">We explore the capabilities of 3 white-box LLMs-LLaMA2 <ref type="bibr" target="#b23">[23]</ref>, T0 <ref type="bibr" target="#b32">[32]</ref>, and Flan-T5 <ref type="bibr" target="#b33">[33]</ref>-focusing on their application in risk prediction for COVID-19 using both the native QA pairs and the formatted tabular dataset.</s></p><p xml:id="_qEbEDSD"><s xml:id="_3hePCGs">To our knowledge, this is one of the first attempts leveraging generative LLMs and conversational data science for disease risk assessment across various LLMs and few-shot settings.</s><s xml:id="_CcwATYz">Our selection includes both decoder-only (LLaMA2) and encoder-decoder architectures (T0 and Flan-T5), allowing for a comprehensive assessment and comparison of their performance.</s><s xml:id="_KSJnqsG">The white-box nature of these models is particularly advantageous as it enables setup on local hosts with private datasets, ensuring precise risk assessment by allowing direct access to model weights and logits.</s></p><p xml:id="_mpGY4ek"><s xml:id="_XHyYGQy">The input to the LLMs is a serialized string generated from the tabular data using the previously explained serialization strategies.</s><s xml:id="_nS43M62">Given a feature vector .</s><s xml:id="_pSx8aQt">and their associated values , the serialized input string S i can be represented using either the list template or text template serialization methods (Figure <ref type="figure" target="#fig_1">2</ref>).</s><s xml:id="_qEqHdXh">These feature vectors originate from the structured dataset described in Table <ref type="table">1</ref>, which provides the foundation for both traditional and generative model comparisons.</s></p><p xml:id="_g6mZf4V"><s xml:id="_5BJaJk5">The LLM processes the serialized input string S i and outputs logits for the next token in the sequence.</s><s xml:id="_xABpgfC">We focus on the logits corresponding to the tokens "yes" and "no," which indicate severe or nonsevere symptoms, respectively.</s><s xml:id="_reZh7Dt">The probabilities for these tokens are obtained by applying the softmax function to the logits:</s></p><p xml:id="_3AmbuuF"><s xml:id="_Y5WsBAa">The probability indicates the likelihood of severe symptoms based on the input data S i .</s><s xml:id="_y2JtDnX">This probability is directly used as the severity risk score for evaluation purposes.</s></p><p xml:id="_UAzb9HM"><s xml:id="_yQdnnVX">To determine the binary predicted label from this probability:</s></p><p xml:id="_9EKwNsn"><s xml:id="_azzjQUy">The probability score , reflecting the severity risk, is used to compute the AUC for evaluation (Figure <ref type="figure" target="#fig_1">2</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_22Esdx4">Evaluation Setting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Py5zuag">Zero-Shot Setting</head><p xml:id="_AFSCW2T"><s xml:id="_5F5HwY4">In the zero-shot setting, our approach leverages the intrinsic capabilities of LLMs.</s><s xml:id="_wyYkZuD">These models, unlike traditional classifiers such as logistic regression and XGBoost, have been extensively pretrained on diverse datasets.</s><s xml:id="_RPnXtdh">This extensive pretraining enables them to apply their accumulated world knowledge directly to specific classification tasks without additional training, demonstrating exceptional generalizability.</s></p><p xml:id="_P3Pw7aV"><s xml:id="_KUvpSET">We assess the zero-shot prediction effectiveness of these LLMs by presenting them with tasks aligned with our study's objectives that they have not been specifically trained on.</s><s xml:id="_WybZdek">The models interpret and classify new, unseen data solely based on their pretrained knowledge.</s><s xml:id="_uUgZzfS">This approach not only highlights the potential of LLMs in real-world applications but also evaluates their ability to generalize from their training to novel scenarios in healthcare.</s><s xml:id="_PTuaUg9">This zero-shot methodology allows us to evaluate how well these LLMs can recognize and classify complex, previously unseen patterns in health care data, providing valuable insights into their practical applicability and limitations in clinical settings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7uxQU9n">Few-Shot Fine-Tuning</head><p xml:id="_tYTKuBr"><s xml:id="_PthfhUV">In the few-shot setting, we use sample sizes of 2, 4, 8, 16, and 32 to fine-tune the LLMs, aiming to examine the effect of training sample size on model performance compared to traditional classifiers.</s><s xml:id="_8Kfdsue">To ensure fairness and reduce bias in the fine-tuning process, we maintain a balanced ratio of positive and negative samples, with an equal number of examples from each class in each sample size.</s></p><p xml:id="_uR58JxE"><s xml:id="_YUDd3bz">To enhance computational efficiency in adapting the LLMs to our specific tasks, we employ a parameter-efficient fine-tuning approach using LoRA <ref type="bibr" target="#b27">[27]</ref>.</s><s xml:id="_jdKyFXb">Instead of adjusting all parameters within the model, LoRA involves training a small proportion of parameters by integrating trainable low-rank matrices into each layer of the pretrained model.</s><s xml:id="_dNY2Uur">This method allows the model to quickly adapt to new tasks by optimizing only a subset of parameters, thereby preserving the general capabilities of the LLM while enhancing its performance on task-specific features.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_YUeurwN">Feature Importance Analysis</head><p xml:id="_yptM5J4"><s xml:id="_RvakaUW">In disease risk assessment, interpretability is as critical as accuracy, particularly when both are provided to the user in real time.</s><s xml:id="_WaNm9jK">Here, we introduce a novel approach for analyzing feature importance by leveraging the attention mechanisms inherent in the output layers of generative LLMs.</s><s xml:id="_V3GqYtq">This method provides additional insights into the risk assessment process of the model,</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_nmDZBbu">XSL • FO</head><p xml:id="_tuy23bG"><s xml:id="_AGMFuFu">RenderX which is valuable for both clinicians and patients in understanding the factors contributing to the model's output.</s></p><p xml:id="_6ETQbqS"><s xml:id="_2cr2eUv">Our approach involves extracting attention scores from the model's output layer, where the attention assigned to each input token is interpreted as an indicator of feature importance.</s><s xml:id="_fE7Kcmt">We compute the attention for each feature-value pair and associate the average attention score with the corresponding feature.</s><s xml:id="_58dPPvE">This provides a holistic view of which features, along with their associated values, influence the model's output.</s></p><p xml:id="_qCk8VCB"><s xml:id="_v6VhRyx">In Figure <ref type="figure" target="#fig_3">4</ref>, the attention map illustrates the attention scores for a predicted positive case by the LLM, where darker shades represent higher attention scores assigned to specific feature-value pairs.</s></p><p xml:id="_7mNXz2F"><s xml:id="_XVeDQTY">For an input sequence such as:</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gzhPdSb">A patient Do the descriptions of this patient show severe symptoms of COVID-19? Yes or no? Result:</head><p xml:id="_mpeVK9b"><s xml:id="_KaAQBg8">We calculate attention scores for each feature-value pair in the original sequence.</s><s xml:id="_CC2wDsv">The average attention score for each feature-value pair is then computed, and the score is associated with the feature itself, offering a representation of feature importance in the context of disease severity risk.</s><s xml:id="_RJXrDTG">As shown in Figure <ref type="figure" target="#fig_3">4</ref>, any missing data in both the training and inference stages could be handled by having the value as "none" and having the model make the prediction; this will impact the prediction depending on the feature missing, but the free-text input of the LLMs still allows for a prediction to happen.</s><s xml:id="_EayqfQ7">This normalized attention score serves as a proxy for feature importance, offering clinicians and patients a clearer understanding of which features (eg, age, preexisting conditions, vital signs, etc) are most influential in the model's assessment of COVID-19 severity risk.</s><s xml:id="_TdEJpC6">As illustrated in Multimedia Appendix 1, the plot shows the normalized attention scores from the LLaMA2-7b model in the 32-shot setting for two test cases: one positive (yes) and one negative (no).</s></p><p xml:id="_eVUajua"><s xml:id="_wWZtfDw">For the positive case, the top five features with the highest attention scores, as shown in this figure, are:</s></p><p xml:id="_R3wDM36"><s xml:id="_qWNg7Dz">1. f15: COVID-19 antibody test 2. f13: Lungs check 3. f12: Nausea or vomiting 4. f9: Cough 5. f14: Eye redness By integrating this analysis into our mobile app, we enhance the interpretability of LLM-based risk assessments, empowering users with deeper insights into the model's reasoning process.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_wM3d3zM">Mobile App</head><p xml:id="_WbUtJWs"><s xml:id="_QyKAwYZ">To provide users with code-free disease severity risk assessment and enhance user experience, we developed a mobile chatbot powered by the aforementioned generative LLMs.</s><s xml:id="_fQ8VqfS">This app is designed to facilitate the assessment and management of COVID-19 in children, with potential applicability to other diseases and conditions.</s><s xml:id="_GJWm3yA">It offers two versions: one for patients to donate their health information via answering the questions and receiving real-time severity risk assessments, and another for clinicians to manage, review, and interpret the sessions donated by patients.</s><s xml:id="_6jPfHPd">The primary goals are to enhance early detection of severe outcomes, improve patient-clinician communication, and streamline the overall risk assessment process.</s></p><p xml:id="_Hs7bc5b"><s xml:id="_35d4pZE">The app targets patients, clinicians, and other health care providers involved in managing preclinical cases.</s><s xml:id="_GMEwaVb">It leverages the capabilities of generative LLMs to analyze patient responses and provide immediate feedback on the risk of severe symptoms.</s><s xml:id="_XWdQ7YE">Developed using React Native and JavaScript for the front end, Firebase for database management, and various frontend technologies, the app provides a user-friendly, efficient, and effective solution for managing disease risks.</s><s xml:id="_cXnXW9A">It aims to improve patient outcomes by facilitating timely and informed decision-making.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_bdegeJw">Database Structure</head><p xml:id="_Uka7ngW"><s xml:id="_kaHgxFa">Our mobile app uses Firebase for database management, structured into three primary collections: Users, Questions, and Answers.</s></p><p xml:id="_KTHjnqW"><s xml:id="_URPsgdu">The data flow between the patient, LLM backend, Firebase, and interfaces for both patients and clinicians is illustrated in Figure <ref type="figure" target="#fig_4">5</ref>.</s><s xml:id="_F9yqXyA">This figure highlights the interactions among processes, including the assessment submission, session management, and result retrieval.</s></p><p xml:id="_mjbKGt5"><s xml:id="_RvesQUn">• Users: This collection includes essential user information such as ID, Email, and isAdmin.</s><s xml:id="_jm98qAG">The ID uniquely identifies each user, the Email serves as contact information, and the isAdmin field (Boolean) indicates whether the user has administrative privileges (clinicians) or not (patients).</s></p><p xml:id="_A3Pq9pG"><s xml:id="_Hwfh25J">• Questions: Each document in this collection has a unique ID and a Description field.</s><s xml:id="_pqW9UbX">The ID is used to reference questions in the Answers collection, and the Description contains the text of the question posed to the user, ensuring clarity and specificity in data mapping.</s></p><p xml:id="_pVPDAE6"><s xml:id="_sK9NEGQ">• Answers: This collection records user responses during their sessions.</s><s xml:id="_YwqQu3w">Each document includes a session ID and an array of answers where each entry links to the relevant Question ID from the Questions collection.</s><s xml:id="_ZhB3h56">In addition, it contains a Text field for the user's detailed response; an Answer field for the LLM-generated response (eg, yes or no); a Date field marking the session's completion time; a Risk Score field, which is derived from the user's responses and utilized for subsequent risk prediction by the LLM; and an Important Features field, which stores the key features identified by the LLM's attention scores that contributed to the risk assessment.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_u2jQdqN">User Interface: Assessment</head><p xml:id="_Rm7euZ3"><s xml:id="_vsuWvXt">The step-by-step workflow for conducting an assessment and storing results in Firebase is detailed in Figure <ref type="figure" target="#fig_5">6</ref>.</s><s xml:id="_amsvKsg">This sequence diagram outlines the interaction between the patient, mobile app, LLM backend, and database.</s></p><p xml:id="_RYbxAfC"><s xml:id="_uuauVeC">As shown in Figure <ref type="figure" target="#fig_2">3</ref>, on the Assessment page, we leverage the power of LLMs to engage in a conversation with the patient.</s><s xml:id="_3n7EqYQ">This interaction allows us to ask questions and gather contextual information for each response.</s><s xml:id="_uJGbjWB">By doing so, we retrieve a binary answer (yes or no) using the LLM, which is then provided to the primary care physician along with the patient's context to aid in decision-making.</s></p><p xml:id="_AHnhCAw"><s xml:id="_FHKAP9v">After the user responds to each question, we use our LLM to generate a binary answer.</s><s xml:id="_VPsBkVn">This involves providing the LLM with instructions that include the question and the user's response and asking the LLM to interpret the response into a binary answer (yes or no).</s><s xml:id="_BQ8FjDz">This sequential process is performed for all questions.</s><s xml:id="_b82AjYp">Currently, the input for the final LLM-based risk assessment, which predicts the COVID-19 severity risk, is based solely on the set of binary answers generated by the LLM.</s><s xml:id="_R6HxQru">Future enhancements could incorporate the original user responses to improve context understanding.</s></p><p xml:id="_w5PEKEd"><s xml:id="_QXvCzt8">We currently use the Llama2-7b application programming interface (API) for answer retrieval.</s><s xml:id="_55At4Rb">Our long-term goal is to integrate a fine-tuned LLM hosted on our servers to ensure better optimization and accuracy specific to our dataset, as evidenced by the improved performance results discussed in this paper.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_JKu4wHq">User Interface: Patient and Clinician Results</head><p xml:id="_f7ZtEJw"><s xml:id="_QsSJVzF">Figure <ref type="figure" target="#fig_6">7</ref> illustrates the interaction flows for both patients and clinicians as they access session details and results.</s><s xml:id="_mpA3KZe">This sequence diagram shows how patient data and assessments are retrieved and displayed in real time.</s></p><p xml:id="_RAu9Nqy"><s xml:id="_kkuKC63">Patients can submit a session at any time, receiving an immediate risk assessment in the Patient Interface section (Figure <ref type="figure" target="#fig_2">3</ref>).</s><s xml:id="_DfEtA7P">This section displays all sessions submitted by the current user, along with their respective risk assessments.</s></p><p xml:id="_bXddyAD"><s xml:id="_8HAYPU9">In the Clinician Interface section, clinicians can access all sessions from their patients, organized by patient ID, for efficient review.</s><s xml:id="_U523NWw">Each session includes a comprehensive report featuring the predicted risk score, ensuring transparency and aiding in clinical decision-making.</s></p><p xml:id="_ZkYr7Nu"><s xml:id="_AQCneFA">Upon submission, a patient's session is instantly available in both the patient's and clinician's panels.</s><s xml:id="_2VY2hNZ">While patients can only view their own sessions, clinicians can review all sessions from their assigned patients.</s><s xml:id="_SdkWS5z">This setup supports real-time updates through Firebase, facilitating seamless communication and follow-up between patients and their health care providers.</s><s xml:id="_vgENUTE">Furthermore, the app provides personalized feature importance analysis based on the LLM's attention layers, giving both patients and clinicians additional insights into the most critical factors influencing the risk assessment.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GBfsVnU">Ethical Considerations</head><p xml:id="_4wTxyRS"><s xml:id="_GzCajQs">The data collected and used for this study were approved by the University of Pittsburgh Institutional Review Board (MOD21010046-003; approval date: February 25, 2021).</s><s xml:id="_42p9QkG">Informed consent was obtained from all legal caregivers, and when age appropriate, an informed assent was also obtained from the participants.</s><s xml:id="_fSHm7KS">Before the use of this study, the data were subject to a multistep anonymization procedure with personally identifying information marked and deleted.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jpmznC6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7KkE45Y">Training and Fine-Tuning Settings</head><p xml:id="_b49xuny"><s xml:id="_8T7e8eu">In our experiments, we used a rigorous hyperparameter tuning strategy to optimize model performance, supported by a robust setup to ensure diverse dataset initialization and minimize potential biases.</s><s xml:id="_dr9urcW">For both traditional machine learning methods and LLMs, we used 5 specific random seeds-0, 1, 32, 42, and 1024-to create diverse dataset splits.</s><s xml:id="_Vb6UK6U">The dataset of 393 samples was divided into 256 training, 59 validation, and 78 testing segments, preserving a consistent positive-to-negative ratio of approximately 0.38.</s></p><p xml:id="_BmRA3WV"><s xml:id="_fvYTvhH">For both traditional methods and LLMs, training was conducted using up to 32 shots to evaluate performance in the few-shot regime.</s><s xml:id="_nBQgW7m">For few-shot settings ranging from 2 to 32 shots, we ensured a balanced sampling of positive and negative examples in the training set, maintaining an equal number of instances from each class to avoid biases during training.</s><s xml:id="_JGkGkcv">Key hyperparameters, such as the learning rate, were optimized using grid search, with the learning rate set to 3 x 10 -4 .</s><s xml:id="_etjtCPy">The batch size matched the number of shots, and training consistently ran for 128 epochs to ensure convergence.</s><s xml:id="_krhKrJX">During fine-tuning with LoRA, validation loss was monitored to select the best model checkpoint, minimizing overfitting and enhancing generalization to the test set.</s><s xml:id="_g3A3q5Y">The optimization used cross-entropy loss, aligning with the binary classification task of predicting COVID-19 severity.</s><s xml:id="_QdRTBcf">This comprehensive setup ensured robust and interpretable model performance, particularly in low-data settings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ZtxSJyh">Effects of Serialization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MNSKjx7">Overview</head><p xml:id="_67BW2YT"><s xml:id="_z6PvvQk">Table <ref type="table">2</ref> shows the performance of different serialization methods for the LLMs across various few-shot settings.</s><s xml:id="_4WqkxB5">We evaluated 2 primary serialization methods: list template and text template, across models tested with 0, 2, 4, 8, 16, and 32 training shots to observe performance variations with the number of training examples.</s></p><p xml:id="_akJfYhe"><s xml:id="_X4PUxZf">The list template often exhibited better performance at lower shot counts, while the text template typically outperformed the list template as the number of training examples increased.</s><s xml:id="_6CCWkJm">The following summarizes the performance trends for each model.</s><s xml:id="_dRPXv5F">Table <ref type="table">2</ref>. Performance of models across different shot settings.</s><s xml:id="_yRxMPPw">All values represent the average area under the curve (AUC) across 5 random seeds rounded to 2 decimal places.</s><s xml:id="_g3UFtvC">In addition, SDs given across the 5 random seeds are shown.</s><s xml:id="_GFbDAs9">The suffixes "-L" and "-T" represent list serialization and text serialization, respectively.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Dyuqkdf">Number of shots</head><p xml:id="_StbusSB"><s xml:id="_v7CRKgJ">Model 32, AUC (SD) 16, AUC (SD) 8, AUC (SD) 4, AUC (SD) 2, AUC (SD) 0, AUC a (SD) 0.66 (.07) 0.63 (.04) 0.68 (.04) 0.69 (.06) 0.69 (.07) 0.54 (.05) Llama2-7b-L 0.69 (.06) 0.66 (.05) 0.68 (.06) 0.63 (.02) 0.64 (.02) 0.62 (.03) Flan-t5-xl-L 0.65 (.11) 0.59 (.10) 0.62 (.06) 0.61 (.05) 0.61 (.03) 0.60 (.03) Flan-t5-xxl-L 0.70 (.10) 0.68 (.06) 0.70 (.05) 0.70 (.05) 0.70 (.07) 0.69 (.04) T0pp(8bit)-L 0.67 (.07) 0.67 (.04) 0.70 (.04) 0.68 (.05) 0.67 (.04) 0.68 (.04) T0-3b-L 0.67 (.06) 0.63 (.05) 0.64 (.07) 0.69 (.01) 0.69 (.03) 0.59 (.05) Llama2-7b-T 0.70 (.05) 0.69 (.04) 0.71 (.05) 0.69 (.03) 0.69 (.02) 0.69 (.03) Flan-t5-xl-T 0.63 (.10) 0.62 (.09) 0.59 (.10) 0.63 (.08) 0.58 (.03) 0.61 (.04) Flan-t5-xxl-T 0.67 (.08) 0.65 (.08) 0.68 (.04) 0.66 (.05) 0.65 (.05) 0.67 (.02) T0pp(8bit)-T 0.65 (.08) 0.67 (.04) 0.68 (.03) 0.65 (.05) 0.65 (.06) 0.75 (.04) T0-3b-T 0.69 (.08) 0.61 (.11) 0.64 (.06) 0.55 (.10) 0.57 (.07) -b Logistic regression 0.68 (.07) 0.66 (.07) 0.62 (.08) 0.57 (.06) 0.57 (.07) -Random forest 0.65 (.03) 0.54 (.06) 0.50 (.00) 0.50 (.00) 0.50 (.00) -XGBoost c a Average area under the curve.</s><s xml:id="_JUJhMW5">b Not applicable.</s><s xml:id="_ggngGyC">c XGBoost: extreme gradient boosting.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_8RnM5WG">Llama2-7b</head><p xml:id="_6s5catc"><s xml:id="_w2DSx35">In the zero-shot setting, the text template achieved an AUC of 0.59 compared to 0.54 for the list template.</s><s xml:id="_m7EBv4X">At 2 training shots, both templates achieved an AUC of 0.69, but the text template began to outperform, reaching an AUC of 0.67 at 32 training shots compared with 0.66 for the list template.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_JjjYWXC">Flan-t5-xl</head><p xml:id="_Jnv2kAP"><s xml:id="_Kjnscr4">The text template consistently outperformed the list template across most shot settings.</s><s xml:id="_yEp48rc">At 2 training shots, the text template achieved an AUC of 0.69 compared to 0.64 for the list template, and this lead continued up to 32 shots, where the text template achieved an AUC of 0.70 compared to 0.69 for the list template.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_EPvkXKz">Flan-t5-xxl</head><p xml:id="_9dGttPq"><s xml:id="_9MxWwJJ">Both templates showed similar performance in the early few-shot settings.</s><s xml:id="_P7rAhr8">At 2 training shots, the list template achieved an AUC of 0.61, slightly outperforming the text template, which achieved an AUC of 0.58.</s><s xml:id="_vbpeJkB">By 32 training shots, the list template achieved an AUC of 0.65, slightly outperforming the text template, which achieved an AUC of 0.63.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_wn2x5Fa">T0pp (8bit)</head><p xml:id="_Mx5MSgR"><s xml:id="_Hy5WtBq">In the zero-shot setting, the list template led with an AUC of 0.69 compared to 0.67 for the text template.</s><s xml:id="_7WAcnK9">This lead was maintained through most shot settings, with both templates achieving around 0.70 AUC by 32 shots.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_RA4bgw8">T0-3b</head><p xml:id="_SgDud2B"><s xml:id="_GgT9s63">The text template outperformed the list template in the zero-shot setting, achieving an AUC of 0.75 compared to 0.68 for the list template.</s><s xml:id="_CAbM3js">In the 2-shot setting, the list template performed slightly better, with an AUC of 0.67 compared to 0.65 for the text template.</s><s xml:id="_bNzT7vv">At 32 shots, the text template closed the gap with an AUC of 0.65 compared with 0.67 for the list template.</s></p><p xml:id="_kD5pBsv"><s xml:id="_JbXD4Ny">In Table <ref type="table" target="#tab_1">3</ref>, we can also compare the best-performing models across different shots, constraining the recall to be higher than 0.8.</s><s xml:id="_hKKQuxd">This gives us better insights into their performance in population screening for early health risks, where recall is considered more important than precision.</s></p><p xml:id="_Mc7S4qR"><s xml:id="_NWXMpNX">Overall, while the list template often provides an initial advantage in early few-shot settings, the text template shows competitive performance as the number of training examples increases.</s><s xml:id="_2YWwNvu">This suggests that serialization choice can be important in low-data regimes.</s><s xml:id="_PMsTNex">The text template's strong performance in the zero-shot setting, particularly for the T0-3b model, highlights its potential when no training data is available.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_5Kn98xz">LLMs Versus Traditional Machine Learning Methods</head><p xml:id="_puDB4u9"><s xml:id="_HRfVEGX">Our study highlights the versatility of LLMs for various health care apps, particularly in scenarios with limited data.</s><s xml:id="_WWKXPZj">To benchmark their performance against traditional machine learning methods, we compared LLMs with logistic regression, random forest, and XGBoost.</s></p><p xml:id="_E5jnEre"><s xml:id="_nYf5F8X">LLMs benefit from extensive pretraining, allowing them to generalize well to "unseen" data, unlike traditional methods that require substantial amounts of training data.</s><s xml:id="_WUXtRH4">As shown in Table <ref type="table">2</ref>, LLMs like T0-3b-T achieved an AUC of 0.75 in the zero-shot setting, demonstrating a good performance even without task-specific fine-tuning.</s><s xml:id="_Jv3pRQa">This demonstrates the effectiveness of LLM-powered risk assessment without the need for additional labeled data.</s></p><p xml:id="_etJdYmn"><s xml:id="_tvpgYcz">In the 2-shot setting, LLMs continue to show strong performance relative to traditional methods.</s><s xml:id="_mk58zkz">For instance, Figure <ref type="figure" target="#fig_7">8</ref> compares the average AUC across 5 different seeds in this scenario.</s><s xml:id="_WzS4hTG">The left panel shows results using the list serialization (-L) approach, while the right panel shows results using the text serialization (-T) approach.</s><s xml:id="_XrGvY9g">In this 2-shot scenario, LLMs such as T0pp(8bit)-L and Flan-t5-xl-T achieve AUCs of 0.70 and 0.69, respectively, clearly outperforming traditional methods, including logistic regression, random forest, and XGBoost, which achieved AUCs of 0.57, 0.57, and 0.50, respectively.</s></p><p xml:id="_qTvPfwX"><s xml:id="_Xm5SBxA">LLMs' ability to perform well with minimal data highlights their advantage in low-data regimes.</s><s xml:id="_rAb8Nw2">This makes them particularly suitable for real-time, no-code health care apps where rapid decision-making is required, even in scenarios where labeled data is scarce.</s></p><p xml:id="_nNwRk4r"><s xml:id="_jwTaNaN">Furthermore, LLMs' capacity to handle streaming data formats, such as multihop QA pairs, enhances their integration into conversational interfaces, supporting real-time patient-clinician interactions.</s><s xml:id="_q8CyTUA">This flexibility offers significant usability in clinical settings where personalized and immediate risk assessments are needed (Figure <ref type="figure" target="#fig_0">1</ref>).</s><s xml:id="_neW4UGf">Overall, while traditional methods may improve with larger datasets, LLMs demonstrate a clear advantage in dynamic, low-data health care environments.</s><s xml:id="_3tnkQeZ">Their ability to handle incomplete data and streaming input formats makes them robust for real-world applications requiring adaptability and speed.</s><s xml:id="_pSPsWYf"><ref type="figure">-L</ref>) approach, while the right panel shows results using the text serialization (-T) approach.</s><s xml:id="_J8d7hx8">XGBoost: extreme gradient boosting.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Sx5RekJ">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_upZn4Vx">Principal Findings</head><p xml:id="_DUgJDhc"><s xml:id="_FeBwAUz">Our research demonstrates that generative LLMs provide a robust and no-code approach for predicting COVID-19 severity, which is particularly effective in low-data regimes.</s><s xml:id="_ZyDSSSG">These models excel in zero-shot and few-shot settings, showcasing their ability to perform well without extensive domain-specific training.</s><s xml:id="_yxxyh8d">This is crucial for real-time applications requiring immediate and reliable predictions, highlighting their exceptional generalizability compared with traditional classifiers like logistic regression, random forest, and XGBoost, which typically require more labeled data to achieve comparable performance.</s></p><p xml:id="_dZSa2fz"><s xml:id="_jwrdgBc">Generative LLMs effectively handle diverse input formats, integrating both structured clinical data and unstructured natural language inputs from patient interactions.</s><s xml:id="_9mrs9kU">This flexibility enables them to synthesize information from various sources, such as patient medical histories and symptom descriptions, enhancing their usability in dynamic health care settings.</s><s xml:id="_jxsewUq">In our study, we incorporated these models into a conversational interface, which facilitates real-time patient-clinician interactions and immediate risk assessments.</s><s xml:id="_D8Spktn">This setup supports continuous data collection and leverages the conversational capabilities of LLMs to optimize clinical decision-making and resource allocation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_FAA3Zv5">Future Directions and Limitations</head><p xml:id="_kuQGVAD"><s xml:id="_U3E3ere">Future work should focus on integrating continuous clinician-patient conversational data for fine-tuning or in-context learning, extending the application of LLMs beyond static disease prediction models.</s><s xml:id="_4fRrhCa">Techniques like chain of thought and chain of interaction, which align with the interactive nature of medical consultations, show promise for enhancing model performance in interpreting and responding to patient data in real-time settings.</s><s xml:id="_JgBd2et">While our study used models like T0pp with parameter-efficient fine-tuning using LoRA, future research could explore newer and more advanced small language models such as LLaMA3-8b and Mistral-7b-Instruct, which have demonstrated exceptional performance in low-data regimes.</s><s xml:id="_m9RZRRQ">These models could offer greater efficiency and accuracy as computational resources and methodologies advance, supporting more sophisticated and scalable applications in health care <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b35">35]</ref>.</s></p><p xml:id="_cGxA8pu"><s xml:id="_D7nYxZ8">However, limitations remain that warrant further exploration.</s><s xml:id="_c8tREHg">This study does not address the critical issue of handling sensitive data, such as personally identifiable information (PII), within health care datasets.</s><s xml:id="_4QVbKN8">Incorporating a dual dataset that includes both PII and non-PII data could facilitate machine unlearning research, allowing models to selectively forget sensitive information while retaining predictive capabilities from nonsensitive data.</s><s xml:id="_eWBgswF">This would ensure compliance with privacy regulations and enhance the ethical deployment of LLMs in health care.</s><s xml:id="_b8KZmSZ">Advancing privacy-preserving techniques, such as selective forgetting mechanisms, would not only safeguard sensitive data but also support broader trust in the use of LLMs in clinical settings.</s></p><p xml:id="_yP2ttQ6"><s xml:id="_h2PpfBz">As these models evolve, vulnerabilities such as adversarial attacks during in-context learning pose significant risks.</s><s xml:id="_Yes9FSZ">Studies have shown that manipulated inputs can lead to inaccurate or harmful predictions, particularly in high-stakes tasks like health care risk assessment <ref type="bibr" target="#b36">[36]</ref>.</s><s xml:id="_2w3CSre">Addressing these risks is crucial to ensure that LLMs remain reliable and safe for broader adoption in health care applications.</s><s xml:id="_XUgYR4U">Enhanced resilience to adversarial techniques, combined with privacy-preserving methods, will be key to building robust and trustworthy systems.</s><s xml:id="_rgEm5FD">By addressing these challenges, future research can ensure that LLMs not only deliver accurate predictions but also adhere to ethical and privacy standards in real-world settings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_HS4bqwr">Conclusions</head><p xml:id="_yDR2uNB"><s xml:id="_ZU8gETJ">In conclusion, generative LLMs offer a valuable tool for no-code risk assessment in low-data regimes.</s><s xml:id="_4qE4b4W">Their ability to perform zero-shot or few-shot transferability to new diseases or conditions and handle complex, varied inputs positions them as key assets for enhancing health care interventions and resource management.</s><s xml:id="_SbtJ4Kf">Furthermore, the incorporation of feature importance analysis derived from the LLM's attention layers provides an additional layer of interpretability, offering personalized insights into the decision-making process for both patients and clinicians.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc><div><p xml:id="_FarQsAM"><s xml:id="_7GSWzgS">Figure 1.Comparison between large language model (LLM)-based conversational AI (Conv-AI) and traditional machine learning methods for disease risk assessment.</s><s xml:id="_X5gqyKv">The Conv-AI leverages pretrained models that require only very few-shot fine-tuning, can handle unstructured textual data, provide real-time feature importance for each risk assessment it provides, and offer transferability with zero to very few shots for new risk assessment tasks.</s><s xml:id="_vPyZMnf">In contrast, traditional machine learning methods require large datasets for de novo training, process structured data, rely on extra computational steps for instance-specific post hoc feature importance (eg, Shapley additive explanations), and need retraining for each new task.</s></p></div></figDesc><graphic coords="3,56.69,330.14,481.90,174.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc><div><p xml:id="_mZMgxhp"><s xml:id="_3qREXgM">Figure 2.Workflow for few-shot COVID-19 severity risk assessment using generative large language models (LLMs) with different serialization techniques.</s><s xml:id="_xRsM73C">The top section, labeled "Backend -system developer," shows the fine-tuning phase where a few-shot sample of patient data, serialized through list and text templates, is used to fine-tune the LLMs.</s><s xml:id="_K93emVK">This backend process includes the creation of prompts and corresponding labels for model fine-tuning.</s><s xml:id="_FsDmhw4">The bottom section, labeled "Frontend -user," illustrates how a conversational chatbot interacts with users through our application to gather responses through streaming QA interactions.</s><s xml:id="_6dg6ucT">These responses are analyzed by the fine-tuned LLM in real time, providing risk assessments and highlighting the top attributing features that explain the model's risk assessment.</s><s xml:id="_pKqgE4R">QA: question-and-answer.</s></p></div></figDesc><graphic coords="4,56.69,211.86,481.88,272.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc><div><p xml:id="_B5sCgaD"><s xml:id="_Xct6pUn">Figure 3. Overview of our mobile app design, showcasing patient data collection, real-time risk assessment using large language models (LLMs), and clinician review interface.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc><div><p xml:id="_dMsaMzC"><s xml:id="_MSNGW7s">Figure 4.</s><s xml:id="_camhX6w">The attention map for a predicted positive case where the darker color represents larger attention weights for each token.</s><s xml:id="_GXbhEmQ">The prompts are tokenized to mimic the actual inputs to the large language models (LLMs).</s></p></div></figDesc><graphic coords="8,56.69,402.62,481.90,63.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc><div><p xml:id="_HXJNEMB"><s xml:id="_7Xb4JwM">Figure 5. Data flow diagram where we map out the flow of information between different processes of large language model (LLM) backend, Firebase, and mobile app interfaces for both patient and clinician.</s></p></div></figDesc><graphic coords="9,56.69,146.78,481.90,293.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc><div><p xml:id="_vF6byjD"><s xml:id="_Cfazm63">Figure 6.</s><s xml:id="_bhkBXEf">Sequence diagram for the Assessment page, where the patient takes the risk assessment and the large language model (LLM) backend calculates the results, which will be saved to the Firebase.</s><s xml:id="_5St4x7v">QA: question-and-answer.</s></p></div></figDesc><graphic coords="10,56.69,92.51,481.93,347.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc><div><p xml:id="_dWKnTxK"><s xml:id="_KwVkKY5">Figure 7. Sequence diagram for displaying patients' session results.</s><s xml:id="_b4bFjM9">As shown, each patient has access to all their own sessions while the clinician can access all patients' sessions.</s></p></div></figDesc><graphic coords="11,56.69,92.54,481.90,430.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc><div><p xml:id="_JakJN9S"><s xml:id="_23d6RxF">Figure 8.</s><s xml:id="_UCkznmQ">Average area under the curve (AUC) in a 2-shot setting over 5 different seeds.</s><s xml:id="_fsyeh4V">The left panel shows results using the list serialization (-L) approach, while the right panel shows results using the text serialization (-T) approach.</s><s xml:id="_VJWwZAz">XGBoost: extreme gradient boosting.</s></p></div></figDesc><graphic coords="13,56.69,532.97,481.85,174.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="6,56.69,251.33,481.90,345.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc><div><p xml:id="_xVFZSjb"><s xml:id="_UDXu2mV">Precision, recall, and F1-score of the best performing models across different shots averaged over 5 random seeds.</s></p></div></figDesc><table><row><cell>Shot</cell><cell>Best model</cell><cell>Threshold</cell><cell>Precision</cell><cell>Recall</cell><cell>F 1 -score</cell></row><row><cell>0</cell><cell>T0-3b</cell><cell>0.04</cell><cell>0.37</cell><cell>0.85</cell><cell>0.52</cell></row><row><cell>2</cell><cell>T0pp</cell><cell>0.12</cell><cell>0.34</cell><cell>0.81</cell><cell>0.46</cell></row><row><cell>4</cell><cell>T0pp</cell><cell>0.24</cell><cell>0.35</cell><cell>0.83</cell><cell>0.49</cell></row><row><cell>8</cell><cell>flan-t5-xl</cell><cell>0.17</cell><cell>0.38</cell><cell>0.80</cell><cell>0.50</cell></row><row><cell>16</cell><cell>flan-t5-xl</cell><cell>0.15</cell><cell>0.34</cell><cell>0.85</cell><cell>0.48</cell></row><row><cell>32</cell><cell>flan-t5-xl</cell><cell>0.16</cell><cell>0.36</cell><cell>0.81</cell><cell>0.49</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_suPaCTp"><s xml:id="_5H92X7m">JMIR AI 2025 | vol. 4 | e67363 | p. 3 https://ai.jmir.org/2025/1/e67363(page</s><s xml:id="_aaxs8nF">number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_wGSjDAm"><s xml:id="_NdU4KPA">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_bE4x3zW"><s xml:id="_YWuH94t">JMIR AI 2025 | vol. 4 | e67363 | p. 6 https://ai.jmir.org/2025/1/e67363(page</s><s xml:id="_Knf4Arv">number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p xml:id="_rBk6eFW"><s xml:id="_E6Z48bg">JMIR AI 2025 | vol. 4 | e67363 | p. 10 https://ai.jmir.org/2025/1/e67363(page</s><s xml:id="_wptmCJ6">number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p xml:id="_EzxaV3F"><s xml:id="_r3KNXgX">JMIR AI 2025 | vol. 4 | e67363 | p. 11 https://ai.jmir.org/2025/1/e67363(page</s><s xml:id="_mdxu358">number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p xml:id="_jvszhVR"><s xml:id="_dtgTZwe">XSL • FORenderX</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p xml:id="_3waRSqB"><s xml:id="_fSaPbe6">JMIR AI 2025 | vol. 4 | e67363 | p. 17 https://ai.jmir.org/2025/1/e67363</s><s xml:id="_u5mVcgQ">(page number not for citation purposes)</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_dtWdRmQ">Acknowledgments</head><p xml:id="_HZ8Fhzb"><s xml:id="_nUhQZay">Research reported in this publication was supported by the <rs type="funder">Eunice Kennedy Shriver Institute of Child Health and Human Development of the National Institute of Health</rs> under awards <rs type="grantNumber">R61HD105610</rs> and <rs type="grantNumber">R33HD105610</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_xpwvg7s">
					<idno type="grant-number">R61HD105610</idno>
				</org>
				<org type="funding" xml:id="_dwMDmSf">
					<idno type="grant-number">R33HD105610</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rPhCk7w">Authors' Contributions</head><p xml:id="_qyTS9e9"><s xml:id="_xrXRJyE">MAR conducted the experiments, designed the app, and wrote the manuscript.</s><s xml:id="_B2W9f4C">XZ contributed to the app design, assisted with the experiments, and provided revisions.</s><s xml:id="_tN3ERng">DZ designed, oversaw, and supported the project.</s><s xml:id="_5uyrybw">YQ offered suggestions on the experiments and revisions.</s><s xml:id="_mNNcvXj">SS, SH, and US assisted with dataset collection and provided feedback on the manuscript draft.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hQB7wVW">Conflicts of Interest</head><p xml:id="_XHvWDnW"><s xml:id="_4StAZnH">SDH is named as a co-inventor on a patent for the diagnostic use of salivary RNA in neurologic disorders.</s><s xml:id="_3g7sG9h">He previously served as a scientific advisory board member for Quadrant Biosciences and Spectrum Solutions.</s><s xml:id="_Usgwn6U">No other conflicts of interest are declared by other authors.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hSHQSjm">Multimedia Appendix 1</head><p xml:id="_frjp2Mp"><s xml:id="_fWpxvEt">Normalized attention scores from LLaMA2-7b in the 32-shot setting, showing feature importance for 2 test cases, 1 positive (yes) and 1 negative (no), simultaneously with the risk assessment.</s></p><p xml:id="_vHU2Phe"><s xml:id="_YX4hKq5">[PNG File , 77 KB-Multimedia <ref type="bibr">Appendix</ref>   <ref type="bibr">27.03.2025</ref>.</s><s xml:id="_dDFsSZS">This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ref type="url" target="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ref>),</s><s xml:id="_UN68cPM">which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR AI, is properly cited.</s><s xml:id="_q4v85Ja">The complete bibliographic information, a link to the original publication on <ref type="url" target="https://www.ai.jmir.org/">https://www.ai.jmir.org/</ref>,</s><s xml:id="_HD7nzdh">as well as this copyright and license information must be included.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<idno type="DOI">10.2196/67363</idno>
		<ptr target="https://ai.jmir.org/2025/1/e67363(pagenumber" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_rkYjymb">JMIR AI</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">67363</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>not for citation purposes</note>
	<note type="raw_reference">References JMIR AI 2025 | vol. 4 | e67363 | p. 14 https://ai.jmir.org/2025/1/e67363 (page number not for citation purposes)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_3dP2drx">Leveraging auxiliary measures: a deep multi-task neural network for predictive modeling in clinical research</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12911-018-0676-9</idno>
		<idno>Medline: 30537954</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tJvye4E">BMC Med Inform Decis Mak</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">Suppl 4</biblScope>
			<biblScope unit="page">126</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Li X, Zhu D, Levy P. Leveraging auxiliary measures: a deep multi-task neural network for predictive modeling in clinical research. BMC Med Inform Decis Mak. 2018;18(Suppl 4):126. [FREE Full text] [doi: 10.1186/s12911-018-0676-9] [Medline: 30537954]</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_Pn5PB8w">Prioritization of multi-level risk factors for obesity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Towner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1109/bibm47256.2019.8982940</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_GtG689y">Proceedings of the IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
		<meeting>the IEEE International Conference on Bioinformatics and Biomedicine (BIBM)<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-18">2019. November 18-21, 2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang L, Dong M, Towner E, Zhu D. Prioritization of multi-level risk factors for obesity. 2019. Presented at: Proceedings of the IEEE International Conference on Bioinformatics and Biomedicine (BIBM); November 18-21, 2019; San Diego, CA. [doi: 10.1109/bibm47256.2019.8982940]</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_tpbQYpD">Predicting clinical outcomes with patient stratification via deep mixture neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.2514/6.2020-2513.vid</idno>
		<idno>Medline: 32477657</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Uyhtmy7">AMIA Jt Summits Transl Sci Proc</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="367" to="376" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Li X, Zhu D, Levy P. Predicting clinical outcomes with patient stratification via deep mixture neural networks. AMIA Jt Summits Transl Sci Proc. 2020;2020:367-376. [FREE Full text] [Medline: 32477657]</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_JGWcPPX">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dmd7n2x">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Presented at Long and Short Papers</note>
	<note type="raw_reference">Devlin J, Chang M, Lee K, Toutanova K. BERT: pre-training of deep bidirectional transformers for language understanding. 2019. Presented at: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers); June 2-7, 2019:4171-4186; Minneapolis, MN. [doi: 10.18653/v1/N19-1423]</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main" xml:id="_QNWPt8w">ClinicalBERT: modeling clinical notes and predicting hospital readmission</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1904.05342</idno>
		<imprint>
			<date type="published" when="2019-04-10">April 10, 2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Huang K, Altosaar J, Ranganath R. ClinicalBERT: modeling clinical notes and predicting hospital readmission. ArXiv. Preprint posted online on April 10, 2019. [doi: 10.48550/arXiv.1904.05342]</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_SyZnPXE">Publicly available clinical BERT embeddings</title>
		<author>
			<persName><forename type="first">E</forename><surname>Alsentzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">D</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/w19-1909</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_QG596Gw">Proceedings of the 2nd Clinical Natural Language Processing Workshop</title>
		<meeting>the 2nd Clinical Natural Language Processing Workshop<address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-07">2019. June 7, 2019</date>
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
	<note>Presented at</note>
	<note type="raw_reference">Alsentzer E, Murphy J, Boag W, Weng W, Jin D, Naumann T, et al. Publicly available clinical BERT embeddings. Association for Computational Linguistics; 2019. Presented at: Proceedings of the 2nd Clinical Natural Language Processing Workshop; June 7, 2019:72-78; Minneapolis, MN. [doi: 10.18653/v1/w19-1909]</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_stb3yuk">Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rasmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhi</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-021-00455-y</idno>
		<idno>Medline: 34017034</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GMPTVWx">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">86</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Rasmy L, Xiang Y, Xie Z, Tao C, Zhi D. Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction. NPJ Digit Med. 2021;4(1):86. [FREE Full text] [doi: 10.1038/s41746-021-00455-y] [Medline: 34017034]</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_jHemwTK">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_CBbr7er">NIPS &apos;20: Proceedings of the 34th International Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06">2020. 2020. December 6-12, 2020</date>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
	<note>Presented at Adv Neural Inf Process Syst</note>
	<note type="raw_reference">Brown TB, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al. Language models are few-shot learners. In: Adv Neural Inf Process Syst 2020. 2020. Presented at: NIPS &apos;20: Proceedings of the 34th International Conference on Neural Information Processing Systems; December 6-12, 2020:1877-1901; Vancouver, BC.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main" xml:id="_rXzVv8D">GPT-4 technical report</title>
		<author>
			<persName><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Aleman</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.08774</idno>
		<imprint>
			<date type="published" when="2023-03-15">March 15, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, et al. GPT-4 technical report. ArXiv. Preprint posted online on March 15, 2023. [doi: 10.48550/arXiv.2303.08774]</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_Ree7hG5">How does chatGPT perform on the United States medical licensing examination (USMLE)? The implications of large language models for medical education and knowledge assessment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Safranek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Socrates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><forename type="middle">L</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="DOI">10.2196/45312</idno>
		<idno>Medline: 36753318</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nghqQWR">JMIR Med Educ</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">45312</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Gilson A, Safranek CW, Huang T, Socrates V, Chi L, Taylor RA, et al. How does chatGPT perform on the United States medical licensing examination (USMLE)? The implications of large language models for medical education and knowledge assessment. JMIR Med Educ. 2023;9:e45312. [FREE Full text] [doi: 10.2196/45312] [Medline: 36753318]</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_9ze9B5Y">Performance of chatGPT on USMLE: potential for AI-assisted medical education using large language models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheatham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Medenilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sillos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Leon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elepaño</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000198</idno>
		<idno>Medline: 36812645</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WCMS4Qr">PLOS Digit Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">198</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kung TH, Cheatham M, Medenilla A, Sillos C, de Leon L, Elepaño C, et al. Performance of chatGPT on USMLE: potential for AI-assisted medical education using large language models. PLOS Digit Health. 2023;2(2):e0000198. [doi: 10.1371/journal.pdig.0000198] [Medline: 36812645]</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_e27KaaA">Using chatGPT to write patient clinic letters</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Dobbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Hutchings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Whitaker</surname></persName>
		</author>
		<idno type="DOI">10.1016/s2589-7500(23)00048-1</idno>
		<idno>Medline: 36894409</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_449rt6j">Lancet Digit Health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="179" to="e181" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Ali SR, Dobbs TD, Hutchings HA, Whitaker IS. Using chatGPT to write patient clinic letters. Lancet Digit Health. 2023;5(4):e179-e181. [FREE Full text] [doi: 10.1016/S2589-7500(23)00048-1] [Medline: 36894409]</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_YV9Wmn7">Can Chat-GPT a substitute for urological resident physician in diagnosing diseases?: a preliminary conclusion from an exploratory investigation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00345-023-04539-0</idno>
		<idno>Medline: 37505265</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WNCGKMd">World J Urol</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2569" to="2571" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Xv Y, Peng C, Wei Z, Liao F, Xiao M. Can Chat-GPT a substitute for urological resident physician in diagnosing diseases?: a preliminary conclusion from an exploratory investigation. World J Urol. 2023;41(9):2569-2571. [doi: 10.1007/s00345-023-04539-0] [Medline: 37505265]</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_4t7Nyd9">Accuracy of a generative artificial intelligence model in a complex diagnostic challenge</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kanjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Crowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodman</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2023.8288</idno>
		<idno>Medline: 37318797</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5abfRnr">JAMA</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="80" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Kanjee Z, Crowe B, Rodman A. Accuracy of a generative artificial intelligence model in a complex diagnostic challenge. JAMA. 2023;330(1):78-80. [FREE Full text] [doi: 10.1001/jama.2023.8288] [Medline: 37318797]</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_wzN9aeQ">Evaluating large language models on medical evidence summarization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Idnay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Nestor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soroush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Elias</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-023-00896-7</idno>
		<idno>Medline: 37620423</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mXKVwVX">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Tang L, Sun Z, Idnay B, Nestor JG, Soroush A, Elias PA, et al. Evaluating large language models on medical evidence summarization. NPJ Digit Med. 2023;6(1):158. [FREE Full text] [doi: 10.1038/s41746-023-00896-7] [Medline: 37620423]</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_FYtjPSQ">The utility of chatgpt as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sallam</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.02.19.23286155</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sRHgYRC">MedRxiv</title>
		<imprint>
			<date type="published" when="2023-02-21">February 21, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sallam M. The utility of chatgpt as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations. MedRxiv. Preprint posted online on February 21, 2023. [doi: 10.1101/2023.02.19.23286155]</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main" xml:id="_eXRaFt7">Health-LLM: Large language models for health prediction via wearable sensor data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcduff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Park</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.06866</idno>
		<imprint>
			<date type="published" when="2024-01-12">January 12, 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note type="raw_reference">Kim Y, Xu X, McDuff D, Breazeal C, Park HW. Health-LLM: Large language models for health prediction via wearable sensor data. ArXiv. Preprint posted online on January 12, 2024. [doi: 10.48550/arXiv.2401.06866]</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main" xml:id="_xxMh2pK">Clinicalmamba: a generative clinical language model on longitudinal clinical notes</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><forename type="middle">A</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.clinicalnlp-1.5</idno>
		<imprint>
			<date type="published" when="2024-03-09">March 9, 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note>FREE Full text</note>
	<note type="raw_reference">Yang Z, Mitra A, Kwon S, Yu H. Clinicalmamba: a generative clinical language model on longitudinal clinical notes. ArXiv. Preprint posted online on March 9, 2024. [FREE Full text] [doi: 10.18653/v1/2024.clinicalnlp-1.5]</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main" xml:id="_hMYzmJK">Capabilities of GPT-4 on medical challenge problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Carignan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.13375</idno>
		<imprint>
			<date type="published" when="2023-03-20">March 20, 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note type="raw_reference">Nori H, King N, McKinney S, Carignan D, Horvitz E. Capabilities of GPT-4 on medical challenge problems. ArXiv. Preprint posted online on March 20, 2023. [doi: 10.48550/arXiv.2303.13375]</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_SrWFh5r">Toward expert-level medical question answering with large language models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gottweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sayres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amin</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-024-03423-7</idno>
		<idno>Medline: 39779926</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_s4upmTg">Nat Med</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Amin M, et al. Toward expert-level medical question answering with large language models. Nat Med. 2025. [doi: 10.1038/s41591-024-03423-7] [Medline: 39779926]</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_WdZysTr">PMC-LLaMA: toward building open-source language models for medicine</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocae045</idno>
		<idno>Medline: 38613821</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2syCaZS">J Am Med Inform Assoc</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1833" to="1843" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wu C, Lin W, Zhang X, Zhang Y, Xie W, Wang Y. PMC-LLaMA: toward building open-source language models for medicine. J Am Med Inform Assoc. 2024;31(9):1833-1843. [doi: 10.1093/jamia/ocae045] [Medline: 38613821]</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_6dDfST7">CPLLM: clinical prediction with large language models</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Shoham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rappoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000680</idno>
		<idno>Medline: 39642102</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gry5qqA">PLOS Digit Health</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">680</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ben Shoham O, Rappoport N. CPLLM: clinical prediction with large language models. PLOS Digit Health. 2024;3(12):e0000680. [doi: 10.1371/journal.pdig.0000680] [Medline: 39642102]</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main" xml:id="_RvQXVxS">LLAMA 2: open foundation and fine-tuned chat models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Babaei</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2307.09288</idno>
		<imprint>
			<date type="published" when="2023-07-18">July 18, 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note type="raw_reference">Touvron H, Martin L, Stone K, Albert P, Almahairi A, Babaei Y, et al. LLAMA 2: open foundation and fine-tuned chat models. ArXiv. Preprint posted online on July 18, 2023. [doi: 10.48550/arXiv.2307.09288]</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main" xml:id="_pA4SXMt">BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Venigalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2403.18421</idno>
		<imprint>
			<date type="published" when="2024-03-27">March 27, 2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bolton E, Venigalla A, Yasunaga M, Hall D, Xiong B, Lee T, et al. BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text. ArXiv. Preprint posted online on March 27, 2024. [doi: 10.48550/arXiv.2403.18421]</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main" xml:id="_jSMzCux">Applied Logistic Regression</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hosmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lemeshow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">X</forename><surname>Sturdivant</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781118548387</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Hosmer DJ, Lemeshow S, Sturdivant RX. Applied Logistic Regression. Hoboken, NJ. John Wiley &amp; Sons; 2013.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_GS8aBvb">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="DOI">10.1186/1478-7954-9-29</idno>
		<idno>Medline: 21816105</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UeFZWhv">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Breiman L. Random forests. Mach Learn. 2011;45(1):5-32. [FREE Full text] [doi: 10.1186/1478-7954-9-29] [Medline: 21816105]</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_3g67EEj">XGBoost: a scalable tree boosting system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939785</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_xWFR4mg">Presented at: KDD &apos;16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08-13">2016. August 13-17, 2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
	<note type="raw_reference">Chen T, Guestrin C. XGBoost: a scalable tree boosting system. 2016. Presented at: KDD &apos;16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; August 13-17, 2016:785-794; San Francisco, CA. [doi: 10.1145/2939672.2939785]</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main" xml:id="_8XzvBa3">LoRA: low-rank adaptation of large language models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2106.09685</idno>
		<imprint>
			<date type="published" when="2021-06-17">June 17, 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note type="raw_reference">Hu EJ, Shen Y, Wallis P, Allen-Zhu Z, Li Y, Wang S, et al. LoRA: low-rank adaptation of large language models. ArXiv. Preprint posted online on June 17, 2021. [doi: 10.48550/arXiv.2106.09685]</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_b3dj4Cp">Saliva microRNA profile in children with and without severe SARS-CoV-2 infection</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kannikeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Meert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.3390/ijms24098175</idno>
		<idno>Medline: 37175883</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nwxPPzM">Int J Mol Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">8175</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Hicks SD, Zhu D, Sullivan R, Kannikeswaran N, Meert K, Chen W, et al. Saliva microRNA profile in children with and without severe SARS-CoV-2 infection. Int J Mol Sci. 2023;24(9):8175. [FREE Full text] [doi: 10.3390/ijms24098175] [Medline: 37175883]</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main" xml:id="_8G4QfY6">A unified approach to interpreting model predictions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1705.07874</idno>
		<imprint>
			<date type="published" when="2017-05-22">May 22, 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note type="raw_reference">Lundberg SM, Lee SI. A unified approach to interpreting model predictions. ArXiv. Preprint posted online on May 22, 2017. [doi: 10.48550/arXiv.1705.07874]</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main" xml:id="_ydBC873">Tabllm: Few-shot classification of tabular data with large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hegselmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buendia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2210.10723</idno>
		<imprint>
			<date type="published" when="2022-10-19">October 19, 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note type="raw_reference">Hegselmann S, Buendia A, Lang H, Agrawal M, Jiang X, Sontag D. Tabllm: Few-shot classification of tabular data with large language models. ArXiv. Preprint posted online on October 19, 2022. [doi: 10.48550/arXiv.2210.10723]</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main" xml:id="_P76Huqm">Multitask prompted training enables zero-shot task generalization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Webson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sutawika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Alyafeai</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2110.08207</idno>
		<imprint>
			<date type="published" when="2021-10-15">October 15, 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
	<note type="raw_reference">Sanh V, Webson A, Raffel C, Bach S, Sutawika L, Alyafeai Z. Multitask prompted training enables zero-shot task generalization. ArXiv. Preprint posted online on October 15, 2021. [doi: 10.48550/arXiv.2110.08207]</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_2juBgA4">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3UVXWaW">J Mach Learn Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">70</biblScope>
			<biblScope unit="page" from="1" to="53" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Chung HW, Hou L, Longpre S, Zoph B, Tay Y, Fedus W. Scaling instruction-finetuned language models. J Mach Learn Res. 2024;25(70):1-53. [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_WFvUrPr">Chain-of-interaction: enhancing large language models for psychiatric behavior understanding by dyadic contexts</title>
		<author>
			<persName><forename type="first">G</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Borsari</surname></persName>
		</author>
		<idno type="DOI">10.1109/ichi61247.2024.00057</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_rrDmfcY">Proceedings of the IEEE 12th International Conference on Healthcare Informatics (ICHI)</title>
		<meeting>the IEEE 12th International Conference on Healthcare Informatics (ICHI)<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024-06-03">2024. June 3-6, 2024</date>
			<biblScope unit="page" from="392" to="401" />
		</imprint>
	</monogr>
	<note>Presented at</note>
	<note type="raw_reference">Han G, Liu W, Huang X, Borsari B. Chain-of-interaction: enhancing large language models for psychiatric behavior understanding by dyadic contexts. 2024. Presented at: Proceedings of the IEEE 12th International Conference on Healthcare Informatics (ICHI); June 3-6, 2024:392-401; Orlando, FL. [doi: 10.1109/ichi61247.2024.00057]</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_bHYmyQw">Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering</title>
		<author>
			<persName><forename type="first">O</forename><surname>Gramopadhye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nachane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jadhav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nandwani</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.findings-emnlp.31</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_wSTpHTJ">Findings of the Association for Computational Linguistics: EMNLP</title>
		<meeting><address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024-11-12">2024. 2024. November 12-16, 2024</date>
			<biblScope unit="page" from="542" to="573" />
		</imprint>
	</monogr>
	<note>Presented at</note>
	<note type="raw_reference">Gramopadhye O, Nachane S, Chanda P, Ramakrishnan G, Jadhav K, Nandwani Y. Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering. 2024. Presented at: Findings of the Association for Computational Linguistics: EMNLP 2024; November 12-16, 2024:542-573; Miami, FL. [doi: 10.18653/v1/2024.findings-emnlp.31]</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main" xml:id="_nQ6DyF3">Hijacking large language models via adversarial in-context learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2311.09948</idno>
		<imprint>
			<date type="published" when="2023-11-16">November 16, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Qiang Y, Zhou X, Zhu D. Hijacking large language models via adversarial in-context learning. ArXiv. Preprint posted online on November 16, 2023. [doi: 10.48550/arXiv.2311.09948]</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
