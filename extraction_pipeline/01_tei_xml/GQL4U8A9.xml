<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_vvMPrRU">Mechanisms for collaboration: a design and evaluation framework for multi-Mechanisms for collaboration: a design and evaluation framework for multiuser interfaces user interfaces</title>
				<funder ref="#_KBeBM8k">
					<orgName type="full">Engineering and Physical Sciences Research Council</orgName>
					<orgName type="abbreviated">EPSRC</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100000266</idno>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nicola</forename><surname>Yuill</surname></persName>
							<email>nicolay@sussex.ac.uk</email>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> School of Psychology University of Sussex Brighton BN1 9QH</note>
								<orgName type="department">School of Psychology</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<postCode>BN1 9QH</postCode>
									<settlement>Brighton</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yvonne</forename><surname>Rogers</surname></persName>
							<email>y.rogers@ucl.ac.uk</email>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Interaction Centre (UCLIC ) University College London London WC1E 6BT</note>
								<orgName type="department">Interaction Centre (UCLIC</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<postCode>WC1E 6BT</postCode>
									<settlement>London</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_nHkEEQW">Mechanisms for collaboration: a design and evaluation framework for multi-Mechanisms for collaboration: a design and evaluation framework for multiuser interfaces user interfaces</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B193286816E2406B027CA5A321180159</idno>
					<idno type="DOI">10.1145/2147783.2147784</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T09:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_SH9uuTy">H5.2 [Information Interfaces and Presentation]: User Interfaces-User-centred design</term>
					<term xml:id="_zvN7YP6">Interaction styles</term>
					<term xml:id="_nMZ25KW">Theory and methods</term>
					<term xml:id="_EEdEATN">General Terms: Design, Human Factors collaboration, constraints, multi-user interfaces</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_eGEYCrd"><p xml:id="_ks5HzZv"><s xml:id="_nK3aNHA">Multi-user interfaces are said to provide 'natural' interaction in supporting collaboration, compared to individual and non-co-located technologies.</s><s xml:id="_UAEYCFz">We identify 3 mechanisms accounting for the success of such interfaces: high awareness of others' actions and intentions, high control over the interface and high availability of background information.</s><s xml:id="_hmbsWCU">We challenge the idea that interaction over such interfaces is necessarily 'natural' and argue that everyday interaction involves constraints on awareness, control and availability.</s><s xml:id="_daTXXv3">These constraints help people interact more smoothly.</s><s xml:id="_uhmEEag">We draw from social developmental psychology to characterize the design of multi-user interfaces in terms of how constraints on these mechanisms can be best used to promote collaboration.</s><s xml:id="_b4J4cA6">We use this framework of mechanisms and constraints to explain the successes and failures of existing designs, then apply it to three case studies of design, and finally derive from them a set of questions to consider when designing and analysing multi-user interfaces for collaboration.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="31" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="32" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="33" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="34" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="35" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="36" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="37" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="38" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="39" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="40" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="41" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="42" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1." xml:id="_fpxvt99">Introduction</head><p xml:id="_HVyZwhq"><s xml:id="_UppqV26">Multi-user interfaces have become pervasive in the last few years, with a number of commercial and customized systems now available.</s><s xml:id="_8ugQzC4">These include Diamond Touch <ref type="bibr" target="#b13">(Dietz &amp; Leigh, 2001</ref>), Microsoft's Surface, Smart Table and tangibles with multiuser interfaces such as the Reactable <ref type="bibr" target="#b34">(Jorda, 2003)</ref>.</s><s xml:id="_yXee83J">The lightweight and parallel action of touching, the mobility of users, and the increased ability for natural expressions of behaviour such as gesture and posture extend the possibilities for communication and collaboration.</s><s xml:id="_Hpz2JsK">User studies have shown how groups of people new to such interfaces find enjoyment in sharing and assembling sets of digital images for a variety of collaborative tasks <ref type="bibr" target="#b33">(Huang &amp; Mynatt, 2003;</ref><ref type="bibr" target="#b59">Ryall et al., 2004;</ref><ref type="bibr">Scott et al., 2003b;</ref><ref type="bibr" target="#b65">Shen et al., 2002)</ref>.</s><s xml:id="_QCHckDB">Commercially available multi-touch tabletops, such as the Smart Table are being promoted in terms of how they can help people work together: 'young students are drawn to its surface, where work and play come together in hands-on, collaborative activities' (<ref type="url" target="www.elementarytechnology.co.uk">www.elementarytechnology.co.uk</ref>).</s></p><p xml:id="_Z5DCcEY"><s xml:id="_vERMRqM">The claim is that these new kinds of shareable interfaces provide more opportunities for flexible forms of collaboration compared for example with single-user PCs and mouse input, through allowing co-located users to interact smoothly and simultaneously with digital content.</s></p><p xml:id="_cGPFXbt"><s xml:id="_6HE5gvG">It has long been recognised that group work can have benefits ('many hands make light work') but also that 'too many cooks spoil the broth': that is, group work does not necessarily gain from the simple sum of each individual's contribution, but there can be 'process loss' due to lack of coordination <ref type="bibr">(Steiner, 1972)</ref>.</s><s xml:id="_RfmBUB9">The advent of Single Display Groupware (SDG) led to insightful analyses of how such technologies might engender interference e.g.</s><s xml:id="_pfy2EGr">parallel working and conflicts <ref type="bibr" target="#b66">(Stewart et al., 1999)</ref>, followed by technical developments such as identity-differentiating widgets <ref type="bibr" target="#b60">(Ryall et al., 2005)</ref>, encouraging designers to think about how identity information might be used to support interleaving of actions by different users.</s><s xml:id="_Hj2gXvQ">The further development of shareable interface technology has led to a wealth of ideas about the benefits of these new capabilities.</s><s xml:id="_Ur5fm5z">For example, <ref type="bibr">Kharrufa et al. (2009, p. 9</ref>) list the special features of shared interfaces as 'encouraging externalisation, â€¦[providing a ] rich set of cognitive tools, providing structure to a task, designing for different ability levels and supporting reflection' through structure and logging tools.</s><s xml:id="_d47c87F"><ref type="bibr" target="#b56">Rogers and Rodden (2003)</ref> propose responses to a cogent set of uncertainties and tensions that arise in shared displays while <ref type="bibr">Scott et al. (2003a)</ref> cite the need to support natural interpersonal interactions, smooth transitions and simultaneous actions with tabletops.</s><s xml:id="_Xp7z2nE">However, such guidelines, invaluable though they are, tend to give us the 'what' rather than the how and why.</s><s xml:id="_uhHgJaD">The latter require a more psychological perspective, explaining how it is that people manage to coordinate interactions in everyday social interactions.</s><s xml:id="_YFRFVm2">An especially illuminating way to do this is to look at the emergence of collaboration, a thriving area in developmental psychology.</s><s xml:id="_rXfD7hb"><ref type="bibr" target="#b70">Tomasello (2009)</ref> premises the distinctive human ability to collaborate on our evolved disposition for shared intentionality, which is based on attention, background knowledge and a drive to cooperate.</s><s xml:id="_sVdPExR">In this paper we translate these properties into three mechanisms of interaction that can be used to inform the design of shareable interfaces.</s><s xml:id="_f62fmGx">We can understand how best to design and use such interfaces if we are clear about what it is that gives them their apparently natural and motivating properties in supporting interaction, and what makes them an apparently superior means of collaboration, compared for example to paper, remote sharing or individual devices.</s><s xml:id="_Wa934JW">We therefore draw on examples from our own research with young children learning to collaborate and with groups who have difficulties with collaboration, to produce a framework that recognises some of the challenges of collaboration that may be hidden when studying only competent collaboration, and when observing users who recover quickly and silently from breakdowns of collaboration <ref type="bibr" target="#b14">(Easterbrook, 1996)</ref>.</s></p><p xml:id="_P7ArtbX"><s xml:id="_zPvebBB">New multi-user interfaces represent a qualitative shift in supporting collaborative groupwork: the freedom of input enables gesturing, speaking, and touching.</s><s xml:id="_GuqBRwK">These can all be seen, heard and experienced by others whereas mouse clicking and key pressing are individual, private acts.</s><s xml:id="_DEuAHYF">While such actions may become largely invisible to those executing them, as they are so familiar, their enaction, in contrast, remains visible to others.</s><s xml:id="_K8EjRrk">Developers of surface technologies and tangibles have been inventive in logging and presenting information about users' interactions, in the hope of improving people's interactions, e.g.</s><s xml:id="_XcA8kYC">making them more equitable <ref type="bibr">(e.g. diMicco et al., 2007</ref><ref type="bibr" target="#b1">, Bachour et al., 2008)</ref>.</s><s xml:id="_gMth5jY">Surfaces, tangibles and shareable public displays also enable simultaneous control by multiple users.</s><s xml:id="_sxaJb6a">These technologies therefore provide striking new opportunities for awareness --gesture, body orientation and more so-called 'natural' means of communication, for making salient in displays the availability of information supported by the public space provided, and for equitable simultaneous control, such as 'entry points' <ref type="bibr" target="#b32">(Rogers et al., 2008)</ref> to the technology.</s><s xml:id="_ufWSDEt">In this typology, collaboration might look easy.</s><s xml:id="_6sxvtcf">But if it is so natural, why is it that not every such application is a success?</s><s xml:id="_A2W58fb">For example, why does increasing awareness of spoken contributions sometimes lead to lower productivity and lack of equitable participation <ref type="bibr" target="#b12">(di Micco et al., 2007)</ref>?</s><s xml:id="_D6bebsk">Why might users show less equal contributions with multitouch applications than with single-touch <ref type="bibr" target="#b26">(Harris et al., 2009)</ref>?</s><s xml:id="_cHev8qV">And do the advantages of such interfaces compensate for the loss of feedback or trace of interactions provided in traditional GUIs <ref type="bibr" target="#b48">(Norman, 2010)</ref>?</s></p><p xml:id="_U6a3St2"><s xml:id="_TQpUSBT">The answers to these questions are needed to understand, support and explain the effective design of new user interfaces for multiple users (e.g. with tabletops, public displays, tangibles), that can capitalize on the mechanisms we have identified above to facilitate new forms of collaboration, e.g., in decision-making, brainstorming, planning, learning and creating.</s><s xml:id="_YxzXggT">In what ways can an interface exploit people's implicit social behaviours for good social effect?</s><s xml:id="_9hBvARA">Can they be designed to make it more obvious as to how to behave and give appropriate cues?</s><s xml:id="_ZV9khD2">Is it possible to make more salient the cues that can lead to improved understanding, explication of intentions and focus of attention?</s><s xml:id="_G6axTeN">Can people become more aware of what is good collaboration and conduct through interacting with a given interface?</s><s xml:id="_7ap9snH">Our goal is to provide a principled way for researchers and designers to be able to make sense of the emerging empirical literature on the benefits of multi-user interfaces, and to enable them to make predictions about their value for collaboration.</s><s xml:id="_Z8vKJzN">We present the mechanisms framework to inform the design of interfaces for collaboration through considering social-psychological properties of shared intentionality.</s><s xml:id="_4uA6NXm">These properties can explain why a multi-touch surface that enables simultaneous interaction may be less effective at facilitating collaboration than a single-touch interface, why gesturebased interactions might be better than mouse-based or tangible interactions for collaborative learning and why apparently minor increases in salience of users' actions can have big effects on the connectedness of social interaction.</s></p><p xml:id="_YUVTUQA"><s xml:id="_6x664cD">We first define the three mechanisms, awareness, control and availability of information, based on the psychological literature on processes of social development, and we illustrate them in the light of existing literature on tabletops designed for collaborative work.</s><s xml:id="_7pWdZU6">We then explain the crucial role of constraints on these mechanisms, using the psychological literature on social development to show how constraints support smooth social interaction, and identifying three sources from which constraints can arise, again using examples from the literature on tabletops.</s><s xml:id="_z4hVjRB">We next present three case studies illustrating how the framework of mechanisms and constraints can be used to design for and evaluate collaboration.</s><s xml:id="_HKFeGu9">We finish by showing how the framework could be used by designers of collaborative applications on multi-user interfaces, for a wide range of audiences, from family groups at leisure, through children working collaboratively in formal settings to remedial work supporting people with social, sensory and language impairments.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2." xml:id="_KprNRby">Background: Awareness, control and availability</head><p xml:id="_MB3GRfN"><s xml:id="_edKSJdA">Much of the research into supporting co-located collaboration has focused on technological approaches to understand group working.</s><s xml:id="_Ah497u9">We take a different approach, by looking at the psychological literature on the foundations of social interactions and their development, thus focusing on the underlying mechanisms of collaboration in simple everyday interaction.</s><s xml:id="_gyKnXz4">This makes our framework particularly inclusive, and this is reflected in the work that we draw on, including designs to support collaboration not only in competent and mature interactants but also in those facing barriers to collaboration.</s><s xml:id="_kWTJHnZ">Technology has a particularly important social role here in supporting collaboration in the broadest range of users.</s><s xml:id="_34dHH9G">Using the literature on the social development of collaboration, we have abstracted three core mechanisms of behaviour that underlie interactions of users doing collaborative tasks: awareness, control and availability.</s><s xml:id="_uV9gB4g">More specifically, they refer to:</s></p><p xml:id="_BhXJW6y"><s xml:id="_dXhsRNw">(i) Awareness of others -the degree to which awareness of users' ongoing actions and intentions is present or made visible moment-to-moment (ii) Control of action -the extent of each user's control over actions and decisions (iii) Availability of information -the ways in which background information relevant to users' behaviour and to the task is made available, or externalised.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1" xml:id="_WkutzKQ">Awareness</head><p xml:id="_wW5SHgR"><s xml:id="_bh8bKAc">Awareness is a term used widely in the literature on shared workspaces, for example in the influential work of <ref type="bibr" target="#b23">Gutwin and Greenberg (2002)</ref> and in the recognition of situational awareness when coordinating action, notably by <ref type="bibr" target="#b27">Heath and Luff (1992)</ref>.</s></p><p xml:id="_qh5UdyK"><s xml:id="_QHj8qqU">We use it here to mean the extent to which people, when they interact with new user interfaces that involve seeing, touching and gesturing, have ongoing awareness of the actions, intentions, emotions and other mental states of other interactants.</s><s xml:id="_vFjHdUe"><ref type="bibr" target="#b61">Schmidt (2002)</ref> defines awareness as reciprocal practices of monitoring others and designing actions so as to render visible certain aspects of activity.</s><s xml:id="_VgfDM3H">Much of this awareness is implicit but a powerful influence on behaviour.</s><s xml:id="_6U6x3MW">For example, the difference between a driver speaking to a passenger in a car and to a conversant on the other end of a phone is apparent in the smoothness of conversational turns and the responsiveness to external events, such as busy traffic <ref type="bibr">(Haigney and Westermann, 2001)</ref>.</s></p><p xml:id="_b27Rn4G"><s xml:id="_ZEZnXT5">Several studies have identified subtle ways in which people show awareness in multiuser technologies.</s><s xml:id="_CHMMZer">For example, <ref type="bibr" target="#b32">Hornecker et al. (2008)</ref> found that users display several different signs of awareness when using multi-touch tables: they make running commentaries on their own actions, they anticipate collisions by adjusting their position, and they sometimes elbow others out of the way.</s><s xml:id="_EASHa4p">These implicit mechanisms of awareness play a clear role in supporting collaboration with multi-user interfaces.</s><s xml:id="_bvj5JPT">In another study, <ref type="bibr" target="#b20">Fleck et al. (2009)</ref> observed groups of 3 children completing a classroom seating arrangement on a multi-touch table, and found that completely isolated, individual working was rare and short-lived.</s><s xml:id="_MA94Ngp">Children made their actions and thoughts known by, for example, talking through and demonstrating their ideas at the same time, and their partners were willing to act as audience at such moments.</s><s xml:id="_cCN9vEp">There were also less planned ways in which awareness became shared, when, for example a child would reach across the table, obstructing another child's view, or when users thought aloud about what they were doing.</s><s xml:id="_zdjuWJj">Such actions did not necessarily lead to a response, but kept the group mutually informed about actions and plans.</s></p><p xml:id="_m7VNjwF"><s xml:id="_XjQDQcP">There is good evidence that multi-user touch surfaces enhance awareness compared to other input devices.</s><s xml:id="_5G9u4HT"><ref type="bibr" target="#b24">Ha et al. (2006)</ref> showed that participants had better awareness of others' actions with touch or a stylus rather than a mouse as input device.</s><s xml:id="_C43kfbd"><ref type="bibr" target="#b32">Hornecker et al. (2008)</ref> compared mouse and touch input for collaborating on a planning task and found that awareness of others' activity was increased in the touch condition.</s></p><p xml:id="_mrcceEX"><s xml:id="_mFc882z">Shared surfaces support more centrally-focused mutual awareness of actions through shared focal attention, as well as peripheral awareness, as for example when digital objects become the focus of shared planning or discussion.</s><s xml:id="_ndqKCa9">Multi-touch surfaces can be considered tangible in the sense that they lure people standing around them to manipulate the digital objects represented on them <ref type="bibr" target="#b53">(Rogers, Lim and Hazlewood, 2006)</ref>.</s><s xml:id="_wS4nR3H">Where they are used with tangibles (e.g.</s><s xml:id="_8rsqeny"><ref type="bibr" target="#b15">Falcao and Price, 2009)</ref> the physical artifacts support additional cues to awareness.</s><s xml:id="_A2JWAXS">Group members may use them as external thinking props to explain a principle, an idea or a plan to the others that is more effective than using equivalent digital representations <ref type="bibr" target="#b4">(Brereton and McGarry, 2000;</ref><ref type="bibr" target="#b18">Fitzmaurice et al., 1995;</ref><ref type="bibr" target="#b19">Fjeld, 2002;</ref><ref type="bibr" target="#b31">Hornecker and Buur, 2006)</ref>.</s><s xml:id="_AGRJYPG">In particular, the act of waving or holding up a physical object in front of others is very effective at commanding attention.</s><s xml:id="_mMC27XN">The persistence of and ability to manipulate physical artifacts may also result in more options being explored in a group setting <ref type="bibr" target="#b17">(Fernaeus and Tholander, 2006)</ref>, and have been hypothesised to increase peripheral awareness of others' activities, helping collaborators gain a better overview of the group activity (e.g., <ref type="bibr">Scott et al., 2003a)</ref>.</s></p><p xml:id="_X6U63hz"><s xml:id="_88Mjw4h">On the face of it, increasing awareness seems like a strongly positive and distinctive feature of multi-user surfaces, compared with individual devices.</s><s xml:id="_SeeHXus">However, the power of technology to present large amounts of information and a high degree of simultaneous action by multiple users risks cognitive overload.</s><s xml:id="_bq93hqa">Multi-user interfaces involve a whole new set of cues about objects to which users direct their actions or intentions.</s><s xml:id="_DHfGqSw">Users of a range of tabletop applications have been found to urge their partners to 'wait' or 'slow down' because they could not grasp all the current action <ref type="bibr" target="#b26">(Harris et al., 2009)</ref>.</s><s xml:id="_ZzT3hCB">Thus, multi-user interfaces offer new possibilities for awareness of ongoing actions, but this awareness is not an unmitigated blessing -more awareness is not necessarily better.</s><s xml:id="_eazV6Qa">It is clear that designers need to think about what sorts of awareness are afforded by multi-user interfaces, and how these might need to be limited by the constraints that we introduce below.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2" xml:id="_EtDWEFc">Control of action</head><p xml:id="_ydPhdVN"><s xml:id="_9Wta8Pz">One of the most compelling features of multi-user surfaces is the way in which they give varied opportunities for control by users, e.g. the directness of touch, the flexibility of tangibles on surfaces and the potential for individually-customisable control.</s><s xml:id="_79xh2R3">By control, we refer to the ways in which users can effect changes in actions within the system and hence decisions within the group.</s><s xml:id="_YEYGVwB">Many applications have focused on the benefit of this for walk-up displays e.g. in museums and social spaces.</s></p><p xml:id="_g5JrVCP"><s xml:id="_mffHCAc">They offer great scope for control over input devices, digital objects and information, and make technology available to users who may have had difficulty understanding or using the more indirect methods of control in GUIs.</s><s xml:id="_fUWpv27">Control can be provided or denied by many features of the design.</s><s xml:id="_242Tp2z">Different input devices provide different levels of control, and software can be designed to increase or constrain control.</s><s xml:id="_ce93Xbs"><ref type="bibr" target="#b54">Rogers et al. (2009)</ref> illustrated the many ways in which users could have control, using the idea of multiple entry points that give all users opportunities for control by different means.</s><s xml:id="_7Jf8FRT">For example, users could move items on a surface, place cards and use tangibles to design a garden.</s><s xml:id="_wq7UsyG">Use depends to a large extent on the loci of control: the availability and placement of points of access to the digital content and how easy it is for the group members to move between them.</s></p><p xml:id="_ymrPyT2"><s xml:id="_qVbR7Yv">However, allowing everyone to act at once can pose problems of coordination: interfaces with high levels of control can cause frustration, anger and disengagement.</s></p><p xml:id="_yR4hD7T"><s xml:id="_CNWgkUT">There can also be uncertainty about what the rules of ownership and transfer should be for virtual objects, compared to well-learned rules about sharing toys <ref type="bibr" target="#b47">(Neary et al., 2009;</ref><ref type="bibr" target="#b41">Mansor et al., 2009)</ref>.</s><s xml:id="_Yyrbu42">Such freedom from custom and constraint may result in uncertainty and parallel working rather than enhanced collaboration.</s><s xml:id="_Y4jVp3S">In particular, while multi-user touch interfaces can make it more inviting and easier for group members to interact whenever they want, there can be too many touches, making it less obvious as to how a co-located group should co-ordinate their interactions, and more generally collaborate.</s><s xml:id="_efqCwRN">This is in contrast to interfaces with more bounded input devices such as traditional PCs, where taking control of the single mouse or keyboard clearly signifies the baton has been handed over for someone else's turn.</s><s xml:id="_TKvXcdv">A mouse can act in some respect like the 'talking stick' that some teachers use as a tangible device to support turn-taking in conversation: the mouse has the strong constraint that only the holder has physical control of the interface.</s><s xml:id="_XZYftdA">Waving one's arms or diving in to a 'free-for-all' surface is quite different from having to wait for a turn to control a single mouse.</s><s xml:id="_Epa3bEj">It may be that, paradoxically, interfaces with such distributed and multiple sources of control are not as effective at supporting collaboration per se.</s></p><p xml:id="_8BaUyrN"><s xml:id="_tUXeRez">One way of dealing with difficulties of all acting at once is to control closely how people have to act together to control a task.</s><s xml:id="_H8b6sry">The StoryTable <ref type="bibr" target="#b7">(Cappelletti et al., 2004)</ref> enforces cooperative storytelling in child pairs by requiring users to touch in order to perform certain actions, such as selecting backgrounds and listening to audio.</s><s xml:id="_XF8hkfv">This seemed to increase levels of engagement but it was still possible for one user to dominate.</s><s xml:id="_2EykmhM">The need to coordinate two users seemed to contribute to lower cohesion in the story produced, compared to individual stories in a low-tech condition.</s><s xml:id="_8xvqbq2">In contrast, the tabletop story-telling application Telltable <ref type="bibr" target="#b6">(Cao et al., 2010)</ref> neither enforced nor encouraged collaboration, and elicited a variety of different behaviours in children to permit turn-taking, equality of interaction and role-sharing.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3" xml:id="_hGreEeM">Availability of background information</head><p xml:id="_6g7DCp4"><s xml:id="_CbdWU3Z">By availability, we mean what information is on hand in the background to influence users' awareness and control.</s><s xml:id="_RM3qBkf">Availability of background information differs from awareness: awareness involves the ongoing, moment-to-moment, generally implicit cues we use in all interaction, whereas availability concerns background information relevant to the task that is accessible for all explicitly and over time.</s><s xml:id="_jCcmjnt">These displays are often designed in explicitly, for example summaries or histories of behaviour that can be made manifest with the aim of influencing behaviour.</s><s xml:id="_fh3q9Fw">The boundary between awareness and availability can shift and is fuzzy.</s><s xml:id="_mWrMnu8">A good illustration of this fuzziness is provided by the 'conversation clock' <ref type="bibr" target="#b35">(Karahalios and Bergstrom, 2006)</ref>.</s><s xml:id="_4gfFZvV">This display shows a circle made up of coloured bars representing on-line audio input for each user, in real time, representing immediate awareness.</s><s xml:id="_nQZFEwd">After one minute, each circular display retreats towards the centre of the table, so that each successive minute is represented in concentric circles, giving a cumulative history of contributions by each user.</s></p><p xml:id="_88MkArt"><s xml:id="_NPs4wEX">Availability of background information is particularly relevant for multi-user interfaces because of the opportunities these technologies give for harvesting and displaying information about the state of play over time and the history of the interactions.</s><s xml:id="_KrYk7tY">For example, surfaces can represent anonymous or tagged information about previous actions, previous states of the problem and summarised contributions of current or previous users.</s><s xml:id="_WwgqFN3">A benefit of groups working around shared surfaces is that relevant information about a task, both in one's own space and in shared space, can be made available to all.</s><s xml:id="_vCaeH7U">Furthermore, this digital history may mitigate some of the conflicts involved in shared work when one user undoes or deletes another's work.</s></p><p xml:id="_52jqZQF"><s xml:id="_sTkq8kE">For example, <ref type="bibr" target="#b52">Rick et al. (2009)</ref> designed Digitile, a tile-pattern application for the Diamond Touch, to provide a running history of previous states.</s><s xml:id="_NH9zm9k">This enabled users to return easily to a previous state of the design.</s><s xml:id="_qUhhrQc">Background information is also useful when there is limited control e.g.</s><s xml:id="_GEvUWX9">users standing at the edge of a large shared display may not be able to act but can follow what is happening, e.g. in the spectators of TellTable <ref type="bibr" target="#b6">(Cao et al, 2010)</ref> and in groupwork in classrooms with large interactive surfaces.</s><s xml:id="_tjNPWgV">The benefits of this mutually shared knowledge can be contrasted with access to information using similar technologies in small displays: iPods are difficult to use as shared platforms, and tend to be handed over rather than shared, while iPads provide a compromise, being quite comfortable for two people to share information, and easy to hand over, like an iPhone, but less comfortable for simultaneous use in larger groups.</s><s xml:id="_J6dXBGQ">Small tangibles such as the Audio Ladybugs used in StoryTable for storing recorded segments of stories, allow access to completed segments of work, although children treated the Ladybugs as personal possessions so tended no to share them readily.</s></p><p xml:id="_5nv3XMZ"><s xml:id="_JFpC9rQ">Combinations of interfaces can be configured so that users have shared information on a large surface but also receive different pieces of information via personal technology (e.g.</s><s xml:id="_hRgzbfP">iPods), meaning that users can decide how and when to share that information with their peers.</s><s xml:id="_dHdMYuQ">Deciding when to tell what to whom can be crucial to success or failure in a collaborative task, and people vary hugely in their ability and willingness to share information judiciously.</s><s xml:id="_TsWZYTR">For example, <ref type="bibr">Fleck et al. (submitted)</ref> found wide individual differences in how well groups shared information to solve a collaborative mystery, when they each had different information presented on personal devices to share on a multi-user surface.</s><s xml:id="_fjWEkp7">Through their own communication choices and through features of the technology, different people will have access to different information.</s></p><p xml:id="_QHfE8B5"><s xml:id="_arZFJvA">Designers have provided explicit displays of information about the accumulated history of interactions, which would normally be subject to the vagaries of each person's unreliable or biased memory.</s><s xml:id="_vCqtaBN">For example, <ref type="bibr" target="#b1">Bachour et al's (2008)</ref> Reflect table provided an array of LEDs embedded in a table that showed publicly how much each person was speaking relative to the others, aggregated over time.</s><s xml:id="_eaZmvTz">This shows who has talked most, rather than just users' concurrent awareness of who has the floor, with an aim of reducing verbal domination.</s><s xml:id="_5FZyPPe">Digital objects can be tagged to show who last touched them, or who placed them, providing tracking of activity.</s><s xml:id="_KsCU75d">For example, Gaver's History <ref type="bibr">Tablecloth (2007)</ref> showed the history of objects placed on it, by displaying an increasing glow the longer the object remains in place.</s><s xml:id="_8YZfUbt">Meeting Mediator used various sensing devices to detect social interactions which can be analysed and aggregated to provide abstract visualisations presented via personal mobile ambient devices <ref type="bibr" target="#b39">(Kim et al., 2008)</ref>.</s><s xml:id="_JDh2xRM">This can have the effect of reducing domination and making distributed meetings appear more like co-located ones.</s></p><p xml:id="_wnnRB84"><s xml:id="_GJAxHfH">However, high availability of background information does not necessarily lead to desired results.</s><s xml:id="_CwKMAwm"><ref type="bibr">DiMicco et al. (2007)</ref> performed extensive studies with Second Messenger, a system that represented speaker input on a surface.</s><s xml:id="_7GeyZBy">There were many positive effects, but some negative: for example, over time there was decreased decision-making effectiveness in groups that had previously done this well.</s><s xml:id="_3frthPK">The Reflect table has the implicit goal of inviting the participants to "balance their collaboration".</s><s xml:id="_wuxWkC7">This did not always happen: there were still some who dominated the interaction and others who hardly spoke <ref type="bibr" target="#b1">(Bachour et al., 2008)</ref>.</s><s xml:id="_qtThfKH">One possibility is that providing very explicit and mutually-shared background information on contribution heightens self-consciousness, perhaps resulting in anxiety for some and competitive instincts for others, and a concern to present oneself in a particular light.</s></p><p xml:id="_7WF2uZD"><s xml:id="_cPjrJP4">We can see from this selection of examples that awareness, control and availability of information are features of technology that influence collaborative processes.</s></p><p xml:id="_sJEEHsA"><s xml:id="_sRHxgcg">However, in order to understand how they might best be used, we need to shift focus to research in social and developmental psychology, where researchers seek to identify the psychological mechanisms through which smooth social interaction develops from infancy onwards.</s><s xml:id="_pD8GVkc">In particular, these mechanisms of collaboration involve mutual knowledge and understanding, and in everyday interaction the smoothness of their operation relies on forms of constraint, which we describe below.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4" xml:id="_tsKgt76">Mutuality of awareness, control and availability</head><p xml:id="_huWuKcq"><s xml:id="_gqxtDuf">The three mechanisms of awareness, control and availability underpin interactions at the tabletop interface, but each also involves mutuality.</s><s xml:id="_7bPeg7h">Across a range of disciplines, researchers have stressed the role of commonality, jointness or mutuality in awareness (e.g.</s><s xml:id="_q4ZK8PV"><ref type="bibr" target="#b9">Carroll et al, 2006)</ref>.</s><s xml:id="_KPXWW43">Developmental psychology in particular highlights the importance of mutuality: for example, <ref type="bibr" target="#b45">Moll and Tomasello (2007)</ref> showed that infants showed understanding of an adult's perspective when jointly engaged in activity with the adult before they could do so when merely observing.</s><s xml:id="_TXzwQEJ">Each of the mechanisms we identify involves mutuality.</s><s xml:id="_jgZ4YCm">For awareness, it is not just that I am aware of you and you of me, but we are mutually aware of each other's awareness: our awareness is shared (see Figure <ref type="figure" target="#fig_0">1</ref>).</s><s xml:id="_s7VnuMY">Because mutual awareness underpins so much of our behaviour, we tend not to recognise this, but researchers in infancy and primatologists understand well the complexity involved (e.g.</s><s xml:id="_apTtV9Q"><ref type="bibr">Gomez, 1994)</ref>.</s><s xml:id="_SWM8MB4">Furthermore, we need to recognize that awareness is shared not only through visual channels, but also, for example, through vocal and postural means <ref type="bibr" target="#b0">(Akhtar and Gernsbacher, 2008)</ref>.</s><s xml:id="_fzN32S8">Mutuality is also a factor in control, which is not just a matter of seeing which individual does what.</s><s xml:id="_sMXymUJ">Psychological research into joint action has recently demonstrated how partners are strongly engaged not just with their own actions but also with their partner's actions: we represent what we are doing, but we also</s></p><p xml:id="_grWYsjF"><s xml:id="_g8QbpRh">represent the other's actions.</s><s xml:id="_MWKZ5TA">Just as our own actions can be subject to interference effects within-individual (e.g.</s><s xml:id="_eadhJyH">being asked to point in the opposite direction to an arrow), so we ourselves experience interference when observing someone else struggling with the same task <ref type="bibr" target="#b64">(Sebanz and Knoblich, 2003)</ref>.</s><s xml:id="_39zj4Xa">The role of mutuality in availability has been well-recognised already when considering interfaces, in concepts such as grounding <ref type="bibr" target="#b10">(Clark and Brennan, 1991)</ref>, through which conversation partners try to establish that what has been said is understood, and in the idea of intersubjectivity <ref type="bibr" target="#b68">(Suthers, 2006)</ref>, in which participants jointly and dynamically construct and maintain shared interpretations and assumptions about a task.</s><s xml:id="_Sc84KgJ">This mutuality means that we have to consider not just how one user is aware of the actions and intentions of other users, but how the group can have shared awareness of others, and the ways in which each user's behaviour is planned with that mutual awareness in mind.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3." xml:id="_pwefNCd">The value of constraints for awareness, control and availability</head><p xml:id="_HMsmGtV"><s xml:id="_enefy6S">Our selection of literature in developmental psychology, computer-supported collaboration and human-computer interaction identified three mechanisms in behaviour through which multi-user interfaces can support collaboration: mutual awareness, mutual control and mutual availability.</s><s xml:id="_kYhH5q7">It is the shared nature of these features of behaviour that provides opportunities for substantially improved collaboration: 'coordinated, synchronous activity that is the result of a continued attempt to construct and maintain a shared conception of a problem' <ref type="bibr">(Teasley and Roschelle, 1993, p.235</ref>).</s><s xml:id="_qHuBMR5">As we have seen, though, good collaboration does not always emerge naturally from these aspects of behaviour with multi-user touch surfaces.</s><s xml:id="_25dfCY2">There can be uncertainty about who should do what, how to progress and how to use available information.</s><s xml:id="_pp4NGeX">There is therefore considerable scope for designers to shape the interface to support collaboration.</s></p><p xml:id="_Tr3bRfn"><s xml:id="_9uZYvZ9">Several frameworks have been proposed to guide design for collaboration.</s><s xml:id="_NHZTmd5">For example, <ref type="bibr" target="#b2">Benford et al. (2000)</ref> describe a continuum of support.</s><s xml:id="_VgPBGpA">The strongest support is enforcing collaboration, a good example being the SIDES multi-touch table application <ref type="bibr" target="#b51">(Piper et al., 2006)</ref>.</s><s xml:id="_rgjsyKx">Teenagers with various behavioural difficulties played a board game on a multi-touch table that recognized users and permitted movement of digital objects only in strict rotation of turns.</s><s xml:id="_Abezkjj">This strongly enforced turn-taking, in that only a specified person can move objects at any one time or in one area.</s><s xml:id="_txCzHUc">The teenagers were observed to respond more cooperatively when the software forced turn-taking than when a teaching assistant tried to persuade them to take turns.</s><s xml:id="_7ZasC3C">At the other end of the spectrum are approaches that give away control, where 'users can act independently, are mutually aware and are free to coordinate their actions if they wish' <ref type="bibr">(Benford et al.,</ref><ref type="bibr">p. 560)</ref>, similar to many of the tabletop applications we have mentioned so far.</s><s xml:id="_mdpfu7P">Benford et al. endorse a middle position of encouraging collaboration, i.e. providing an added benefit, or incentive, for users if they work together.</s><s xml:id="_5Xzyzas"><ref type="bibr" target="#b54">Rogers et al. (2009)</ref> describe a 'shared information spaces' framework that focuses on the extent to which design constrains or invites participation, through the idea of entry point -something that invites entry to an environment.</s><s xml:id="_5BhZTn5">Both of these frameworks imply a dimension of constraint -the extent to which design denies or provides possibilities or incentives for action.</s></p><p xml:id="_zuvkCcB"><s xml:id="_qPHW9Wb">However, the concept of constraint alone does not provide sufficient guidance in designing for collaboration.</s><s xml:id="_XZSaTKb">Constraint, like awareness and control, is not good or bad in itself.</s><s xml:id="_yyrC5Nb">Sometimes removing constraints, such as on turn-taking, can cause discomfort for users.</s><s xml:id="_HJvaxyy">On the other hand, multi-user interfaces such as tabletops relax constraints on awareness so as to enhance mutual understanding in ways that some other technologies do not, without needing additional incentives being built in.</s><s xml:id="_4ZgxbZM">For example, the SIDES game benefits from the unconstrained mutual awareness afforded by a multi-touch table, but control needs to be constrained, at least initially, to prevent chaos.</s><s xml:id="_cQqmZC2">In contrast, designing a garden planning task for adult users of the garden works well if participants have many unconstrained entry points, with physical tagged objects around the room and digital objects on the table, such that participants who do not speak much still contribute by placing the freely available objects into the design, even though mutual awareness might therefore be lower <ref type="bibr" target="#b54">(Rogers et al, 2009)</ref>.</s><s xml:id="_aJSTqvV">The degree of constraint or freedom provided for each of the different mechanisms, of awareness, control and availability, helps designers consider what needs to be constrained or permitted, and for what reasons.</s><s xml:id="_eR6RJB4">It is here that an understanding of how constraints work in naturally-occurring human-human interactions, and how these support smooth collaboration, can inform design for multi-user interfaces.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1" xml:id="_3xR3sWe">Psychological research into constraints in everyday interaction: awareness, control and availability</head><p xml:id="_mYqsyHu"><s xml:id="_p4UBKEg">Consider the way constraints on awareness work in spontaneous everyday interactions.</s><s xml:id="_qtHVpcF">For example, a simple mother-infant interaction occurs when an interesting event triggers pointing by the mother, who naturally orients herself and the baby in her arms to the object of interest, thus providing a constraint on the infant's awareness that makes joint attention more likely.</s><s xml:id="_YmukXs2">This can support the infant in learning that pointing signifies something of potential interest for joint attention <ref type="bibr" target="#b71">(Trevarthen, 1978)</ref>.</s><s xml:id="_g8zT6qs">The environment itself provides useful constraints: if there is an unusual event, e.g. a flashing light or movement, people's attention is drawn to it, giving a mutual awareness of the event -a feature psychologists exploit to great effect in studying joint attention in infancy (e.g.</s><s xml:id="_K9wSVvj"><ref type="bibr" target="#b5">Butterworth, 2008)</ref>.</s><s xml:id="_u4UzEQ5">Ways of making meaning visible through constraining attention and interpretation come naturally even to very young children: for example, children as young as 4 use gestures to counter ambiguity in speech <ref type="bibr" target="#b38">(Kidd and Holler, 2009)</ref> and pre-linguistic referential pointing is a powerful communicative device to direct others' attention, used from 9 months of age <ref type="bibr" target="#b8">(Carpenter et al., 1998)</ref>.</s></p><p xml:id="_ECNhsHc"><s xml:id="_bBZTMkd">The use of constraints on control is widespread and generally apparent, particularly in educational interactions.</s><s xml:id="_w3Rvy6J">In a typical context of scaffolded or apprenticed learning, a tutor will constrain the possible actions or choices so that the learner is supported in picking the correct one: constraint is gradually reduced by the tutor as the learner becomes more able to self-regulate.</s><s xml:id="_tM7NUuX">Driving instruction can move from dual control to single as the learner becomes more competent.</s><s xml:id="_kXNNnjs">Children develop self-control through the adult's gradual relinquishing of control (e.g.</s><s xml:id="_rRv5Uap"><ref type="bibr" target="#b57">Rogoff and Lave, 1984)</ref>, and become able to provide their own constraints: for example, a common test of self-control is to require a child to sit by a desirable food without eating it: some young children will sit on their hands, or shut their eyes, to provide physical and sensory constraints on action <ref type="bibr" target="#b44">(Mischel and Mischel, 1983)</ref>.</s><s xml:id="_aFHxtEb">Considering how much to constrain or relax control on tabletops, e.g. in regulating turn-taking or informing about different users' verbal contributions, would depend on how much the designer wanted to rely on or encourage self-regulation in the users.</s></p><p xml:id="_tJF6qtR"><s xml:id="_KpZYcR8">The role of constraint on availability of information is well-illustrated in educational contexts.</s><s xml:id="_ZgYNenZ">In a typical school setting, information is presented in selective and structured ways rather than learners being left to their own devices.</s><s xml:id="_wFBJecp">Schools also have implicit ground rules, sometimes made explicit as 'golden rules' posted on the classroom wall.</s><s xml:id="_7u5xJHx">In more informal learning, research into children's acquisition of mental state language shows that mothers systematically constrain their vocabulary use to refer to the child's mental states, rather than to those of others, until the child has mastered the particular mental state through their own inner experience <ref type="bibr" target="#b69">(Taumoepeau and Ruffman, 2006)</ref>.</s><s xml:id="_PqEvhz4">In a broader context, <ref type="bibr" target="#b21">Garrod and Pickering (2004)</ref> explain how conversation is helped by the way that interlocutors align their situational awareness, thus constraining interpretations that they might make, suggesting that humans are 'designed for dialogue rather than monologue' (ibid, p. 8).</s></p><p xml:id="_yWgcaG7"><s xml:id="_7NzunE8">Thus, people naturally behave in their everyday lives in ways that constrain action and information so as to interact together effectively.</s><s xml:id="_MdKwJVc">The rules and constraints of when, where and how to gesture, whose turn it is, what to mention and what to take as read are in everyday life culturally and contextually bound.</s><s xml:id="_nt3mMVq">In contrast, so-called 'natural' user interfaces can often lack the constraints, rules, or properties that characterise 'flowing' human interaction (c.f.</s><s xml:id="_wj6hBc9"><ref type="bibr" target="#b11">Csikszentmihalyi, 2000)</ref>, offering too many possibilities, or possibilities that are infelicitous.</s><s xml:id="_3udJrVD">For example, a multi-touch table on which all can work simultaneously on a complex problem can produce parallel working, where each person makes rapid changes that cannot be apprehended by others who are working simultaneously and not monitoring others' actions, which happen rapidly and simultaneously.</s><s xml:id="_dSdcNQ6">Instead of helping collaborative work, shared surfaces may inadvertently encourage individual working.</s><s xml:id="_Fbk63vZ">Providing background information, such as on verbal contributions, gives freedom to use the information but maybe without any shared background assumptions about whether and how users should be equitable, and without any shared understanding of how behaviour might be managed or controlled by the group.</s></p><p xml:id="_7aQRZRb"><s xml:id="_CHdrJrQ">We propose that in order to overcome such problems and to be able to design settings that can enhance collaboration there needs to be an understanding of how to provide different levels and kinds of constraints.</s><s xml:id="_xSNZsRm">This involves working out how to constrain an essentially unconstrained interface and how to factor into design the different constraints imposed by different interfaces.</s><s xml:id="_NzDk9u7">Just as humans in naturalistic social settings implicitly constrain awareness, control and availability in a whole range of collaborative interactions, we argue that designers need to consider how to constrain these features, or how to enable users to constrain them, when designing multi-user interfaces to support collaboration.</s><s xml:id="_jpy4N7p">Everyday social interaction, particularly in the context of teaching, provides a mine of information about how this might be done.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2" xml:id="_JpkVd2y">Sources of constraint</head><p xml:id="_HgGTGHq"><s xml:id="_Xnn4AjA">In considering the ways that designers have used features to support collaboration with multi-user interfaces, we can see a variety of degrees of constraint.</s><s xml:id="_ApFVvwm">For example, a strong constraint on turn-taking control would be software that prevented input from specific users.</s><s xml:id="_NHvS2Ng">A weaker constraint would be implying to users what they can and cannot do, based on social norms.</s><s xml:id="_PWzAB8z">Having discussed how constraints affect everyday behaviour, we can now turn to how they might be used effectively for each of our three mechanisms of behaviour.</s><s xml:id="_VaqQeU2">To help in thinking about how to use constraints, we consider three different sources: physical, digital and social.</s><s xml:id="_SjgArHX">We give examples below of each of these different sources of constraint and then describe how they can be used in relation to awareness, control and availability of information.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hyXBQjQ">(i) Physical constraints</head><p xml:id="_CpQPbSy"><s xml:id="_uHhBgmC">Constraints arise through what is physically possible for us (e.g. a user's reach or hand span, our attentional capacities).</s><s xml:id="_nFqfQVt">One of the benefits of tables for groupwork is their size: they are big enough for all to see easily what others are doing (awareness), but not so big as to prevent reaching all or most digital objects (control).</s><s xml:id="_GJtjXJZ">The orientation of a surface (horizontal or vertical) affects collaboration through influencing control <ref type="bibr" target="#b55">(Rogers and Lindley, 2004)</ref>.</s><s xml:id="_DQCHDSB">Physical features are an important part of background information with or without technology: board game pieces, with their position and colour, for example, act as physical signs of states of play, and tangibles used on surfaces can provide opportunities for representing previous actions or ownership of objects <ref type="bibr" target="#b4">(Brereton and McGarry, 2000)</ref>.</s><s xml:id="_cnjFUs5">Tabletops draw on physiological mechanisms we already use to make sense of the world.</s><s xml:id="_kn95dsK">For example, people may avoid clashing arms on tabletops in ways akin to how they avoid bumping into strangers on busy streets (e.g.</s><s xml:id="_rPzAW8J"><ref type="bibr">Nummenmaa, 2010)</ref>.Technology can also be designed to extend what is physiologically possible (e.g.</s><s xml:id="_asV53Ue">'seeing' through touch, <ref type="bibr" target="#b3">Bird et al., 2009)</ref>.</s><s xml:id="_uafwb9j">However, there remain constraints on our processing capacity, meaning that we cannot attend simultaneously to all the information that new technologies might provide for us.</s><s xml:id="_euqv7Bk">Thus, designers may limit the amount or orientation of information presented, or may locate buttons so that they are not accidentally activated, to compensate for the cognitive and physical limitations of technology users.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XfF8S4c">(ii) Digital constraints</head><p xml:id="_CPphCUY"><s xml:id="_BCzGYVt">Hardware and software can be used to change the constraints on the mechanisms of behaviour we have identified.</s><s xml:id="_PmDAhne">A clear example of this for control is using software to enable single or multi-touch on surfaces.</s><s xml:id="_uxdMUUZ">We can also constrain the physics of awareness through technology e.g. by using mirror projection to present different views to users in different locations, as in the Lumisight table <ref type="bibr" target="#b43">(Matsuda et al., 2006)</ref>.</s></p><p xml:id="_wBB6yED"><s xml:id="_q8BauEK">Such applications make it possible to manipulate and hence evaluate the role of awareness in collaboration, e.g. by providing different degrees of constraint on what people can see, and assessing how this influences ways the group works together.</s><s xml:id="_XUubnPs">One of the main strengths of new multi-user interfaces is the digital possibilities they provide for control.</s><s xml:id="_C8tkuNq">Multiple users can control actions simultaneously through touch or stylus, through tangibles and using personal technologies such as iPods.</s><s xml:id="_sy86qdq">While having multiple entry points to the technology can work well in allowing all to participate, there is a danger in giving too much control, as we illustrated above.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jRHqjeS">Information availability is particularly open to variation through digital means.</head><p xml:id="_s6kdywN"><s xml:id="_ZZghVUn">Representing background information in digital form and using log data allows creative potential for applications to adapt to individual users over time.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_5ska3gG">(iii) Social constraints</head><p xml:id="_6qkZn9B"><s xml:id="_SXZ2ebk">Interfaces are not just physical and digital spaces: people come to them with sets of social norms, mutual understandings, levels of familiarity, implicit awareness of others and motivations.</s><s xml:id="_Uu23FSY">Hence we also need to consider multi-user interfaces as social space.</s><s xml:id="_nxWWebf">Technology-mediated collaboration is strongly driven by implicit norms about one person not hogging the space, cues as to ownership, such as colour of icons, and conventions about use of personal space <ref type="bibr" target="#b42">(Marshall et al., 2011)</ref>.</s><s xml:id="_Mzpj9Eb">Designers can make background information such as the history of interactions or equity of contribution available, but there is not necessarily a mutual and explicit set of assumptions about how to use this information to guide actions.</s><s xml:id="_YJY6kXk">Little attention has been paid to implicit norms about how such information is used -should we be contributing 'fairly' or 'equally', are users a coherent group or a collocation of individuals, do the 'digital natives' dominate?</s><s xml:id="_5pGzUBY">For such interventions to have the desired effects, all participants would need to acknowledge implicitly the function of the explicit representations and to act accordingly and in concert.</s><s xml:id="_qkJQU6n">While some dominant people may notice they are speaking too much and reduce their contributions to the ongoing conversation, others may choose to ignore it.</s><s xml:id="_3ypJaZy">Thus, a participant using the Reflect table <ref type="bibr" target="#b1">(Bachour et al., 2008)</ref>, who spoke the least in her group, said that she rarely looked at the display and moreover, she did not feel it was important for all members of the group to participate equally.</s><s xml:id="_uBFKW5t">Techniques using implicit norms rely on the group members recognising and mutually accepting the etiquette implied in design, and one-off groups of unfamiliar people may be less likely to establish shared understanding and 'social contagion' than familiar groups (e.g.</s><s xml:id="_BwfMb4r">see <ref type="bibr" target="#b46">Mujde and Teckan, 2009)</ref> Use of one-off groups has restricted consideration of the social psychological aspects of multi-user interfaces.</s><s xml:id="_mj8jV4m">The degree of familiarity of users and their assumptions are important in understanding how people apprehend and interpret the intentions and actions of others.</s><s xml:id="_gsxqT9a">Established peer groups, for example, can be familiar and comfortable as work partners, quick to apprehend others' plans (awareness), relatively comfortable in exerting control, e.g.</s><s xml:id="_Tgb6Vhc">elbowing others out of the way, and open to transparent discussion of the social norms of groupwork in the specific setting, e.g. by using peer pressure and reference to class rules to alter plans or complaining about domination <ref type="bibr" target="#b26">(Harris et al., 2009)</ref>.</s><s xml:id="_whGRr6X">Studying 'wild' settings, such as groups of playmates or relatives in public or private settings, who know each other well enough to use elbows, wrest control and appeal to norms of behaviour, or unacquainted visitors to exhibitions, can help clarify intergroup differences in availability of background information.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3" xml:id="_B3T5SbN">How to use constraints?</head><p xml:id="_7x7gbRx"><s xml:id="_g5JNYVY">How much constraint is the right amount?</s><s xml:id="_DAcuVEQ">To answer this, designers need to consider how physical, digital and social features constrain or expand aspects of awareness, control and availability.</s><s xml:id="_qCFAYNK">Low levels of constraint may be most appropriate for very open-ended tasks.</s><s xml:id="_D4ePY36">High levels of constraint can be unhelpful, if people become frustrated or are too restricted ever to learn or understand independently.</s><s xml:id="_MPCPkAR">There has been a tendency to provide either overt technological constraints or to provide information based on implicit norms, e.g. about equity, without considering fully how that information might be viewed and used by participants.</s><s xml:id="_vRdcGgT">In particular, users may not always take kindly to cooperating with the researchers' implicit assumptions about being equitable when told they are contributing too much or not enough.</s><s xml:id="_X9Ewxau">We propose designers should also consider providing subtle environmental constraints to encourage collaboration.</s><s xml:id="_WC9X28D">For example, marked changes in collaboration and equity can be produced simply by changing from a horizontal to a vertical surface.</s><s xml:id="_nGUhkQa">The constraints need to provide just enough support, and not too much, supporting the smooth use of regulation, not purely at an individual level, but also at the level of the group, and considering the norms of behaviour that apply in the specific setting.</s><s xml:id="_FUucX9v">For example, if a goal is to help users to learn to take turns, then the framework could be used to design in only weak constraints, presenting challenges so that users develop an understanding of how and why to take turns.</s><s xml:id="_aM5bKBk">Similarly, if the goal is to enable older or more socially-skilled users to play a tabletop game, the constraints can be relaxed by building in opportunities for users to regulate their own turn-taking, for example, by allowing single touch by any user.</s><s xml:id="_ES9rMkD">This provides high constraint in control (only one user at a time) but no constraint on which user, so the group can only work together if there is some agreement about how control is shared.</s><s xml:id="_tsreRjG">In a situation where users are in competition to contribute, it may be apt to impose a strong constraint to enforce turn-taking.</s></p><p xml:id="_QUMuX9W"><s xml:id="_X4sJvtG">The level of constraint will be influenced by the skills of the user group.</s><s xml:id="_ssU7DDH">For example, if the goal is to support collaborative play in autistic children, who may be limited in their ability to communicate and show little apparent awareness of others' needs, the framework can provide strong physical constraints on control, e.g. a 'train track' painted on a playground surface to guide movement, and a curved slide that 'lands' the child at the start of a new activity, providing smooth movement into the next activity, but also some opportunity for obstruction of others, supporting the need for children to negotiate some simple rules of priority <ref type="bibr" target="#b74">(Yuill et al., 2007)</ref>.</s><s xml:id="_q2XXN3R">Strong constraint is sometimes assumed to be counter-productive, but the role of constraints is well-recognised in evolutionary and developmental theory and in supporting creativity <ref type="bibr" target="#b67">(Stokes, 2005)</ref>.</s><s xml:id="_bsHyVcs">In sum, there is no 'right' level of constraint, but designers need to consider how much constraint is needed on each mechanism for a specific user group, and what the best source is through which to impose that constraint, or to allow users to change constraints themselves.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4." xml:id="_rdtmFzh">Case studies</head><p xml:id="_Kpn59Db"><s xml:id="_RjqZnT9">We now describe three case studies from our own work showing how the framework can be used to consider how changing constraints on the mechanisms of behaviour can support collaboration for specific groups of users.</s><s xml:id="_kf6C6p4">In particular, we contrast outcomes for different versions of software and provide empirical evidence of how the changes in constraint of each feature influence interaction with the technology.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1" xml:id="_jfucK9F">Case Study 1: A software architecture for manipulating awareness, control and availability (SCoSS)</head><p xml:id="_98k9REA"><s xml:id="_CC9fkpW">The Separate Control of Shared Space architecture (SCoSS; <ref type="bibr">Pearce et al., 2005, see</ref> Figure <ref type="figure" target="#fig_1">2</ref>) is designed to support collaboration between multiple users.</s><s xml:id="_6GgQ4xB">It provides 'separate control over an identical version of the task for each <ref type="bibr">[user]</ref> within their own private screen space that is visible to both participants' <ref type="bibr">(Kerawalla et al., 2008, p. 195)</ref>.</s><s xml:id="_d4Kg762">It illustrates variations in awareness (user-identified ongoing task states), in control (yoked or shared) and availability of information (about previous joint decisions).</s><s xml:id="_yPYCWQD">Figure <ref type="figure" target="#fig_1">2</ref> shows a non-SCoSS (left) and SCoSS (right) version of a simple task on a DiamondTouch table where users can be identified.</s><s xml:id="_fX4KTck">The specific task set for pairs working together in an empirical study using adapted PCs by <ref type="bibr" target="#b36">Kerawalla et al. (2008)</ref> was to sort 12 words into a 2x2 matrix identified by a multi-coloured grid.</s><s xml:id="_Rxguup3">Each word varied on two dimensions: a surface quality such as initial letter, and a semantic category, e.g.</s><s xml:id="_PJRqZcU">animal, colour.</s><s xml:id="_V7Zd3Cc">The dimensions were not given in advance and only one word appeared at a time in the red-bordered word box for categorising (by moving into a coloured cell of the matrix).</s><s xml:id="_aRAeZCX">The task is challenging: users have to develop and test out hypotheses about what the categories might be, and there may be 'red herrings' so they may have to backtrack and revise their solution through extensive discussion.</s><s xml:id="_r2V3Cww">In the non-SCoSS version, one copy of the word appears in the word box, and either user can move it into a cell of the single matrix.</s><s xml:id="_qAehwGb">The non-SCoSS version, used in a multi-touch setting, has a single 'we agree' button, activated by either user, designed for the pair to use when they have reached agreement on a particular word.</s></p><p xml:id="_xVamCPF"><s xml:id="_gHbX59F">Thus in non-SCoSS, there is no technological constraint on control: one user could undo the partner's work, move a word into the matrix and click 'we agree' without consulting the partner.</s><s xml:id="_m4thNzW">Sometimes pairs were uncomfortable with the lack of constraint on control here, and would create their own by allocating roles, e.g.</s><s xml:id="_vFTThhv">'you do the 'ch' words' <ref type="bibr" target="#b36">(Kerawalla et al., 2008)</ref>.</s></p><p xml:id="_rDmkadM"><s xml:id="_FgUTHhM">In contrast, the SCoSS condition has two copies of the matrix, representing what each user thinks.</s><s xml:id="_vAxVMnS">Control is constrained as the technology can identify the users e.g. by mouse or by conductive mats: each user can only control their own matrix.</s><s xml:id="_WqgJrFY">They have separate 'we agree' buttons, each controllable only by the identified user, and both buttons have to be activated in order to continue with the task.</s><s xml:id="_3YaxCJX">It is therefore much more difficult for one user to dominate, unless by grabbing the mouse in the PC or stepping onto the other user's conductive mat on the DiamondTouch, both extreme behaviours rarely seen.</s><s xml:id="_NnqcqPa">Users anticipate their partner's action and will wait to press their 'agree' button until the partner is ready.</s><s xml:id="_3UT6uTP">The two matrices represent an opportunity for awareness of different points of view: users move words, hands or mice around in their own or the partner's space in ways that show their partner what they think about a user-specific task representation.</s><s xml:id="_8wXueFM">Participants have a ready source of awareness of the intentions and deliberations of others, because they observe and use information about the 'hovering' of their partner's mouse, or hand, over their own copy of an item, 'picking it up' and moving it to a place on the grid, but not releasing it.</s><s xml:id="_YJ4QJ8w">This hovering is a clear indication of others' intentions.</s><s xml:id="_8YhV9yT">Sometimes items can be moved as explicit deictic devices to resource discussion (e.g.</s><s xml:id="_YNXHCxT">'Shall we put it there?' with the item being held over a location), sometimes in a way that communicates epistemic states such as uncertainty (e.g.</s><s xml:id="_RhS3qHx">'wiggling' the item over several locations when unsure where it should go), and sometimes items can be 'waved' at an intermediate point, apparently as a subtle signal of willingness to negotiate, rather than more direct methods such as making a verbal suggestion about an item's position or actually placing an item in disagreement with a partner.</s></p><p xml:id="_eKyhXHB"><s xml:id="_WeKcnRP">Thus, a high level of awareness in SCoSS is supported by the provision of a visual indicator of agreement history that yokes the two users' beliefs: when both users place a word in the corresponding cells of their matrix, that word in each matrix turns green.</s></p><p xml:id="_w6AAvnG"><s xml:id="_aW8G2Ms">The two interfaces thus also differ in availability of background information: agreement (and hence disagreement) is represented in SCoSS, providing a resource for discussion, in contrast to non-SCoSS, where action by one user on the single space deletes or overrides what has already been done.</s></p><p xml:id="_d8BQPs3"><s xml:id="_Cnnq43x">Use of this interface illustrates and makes the most of the high levels of mutual awareness afforded by multi-user interfaces, in obvious ways (e.g. using green to represent agreement) and also more subtly in behaviour, gesture and apprehension of others' intentions.</s><s xml:id="_te364sQ">It also supports technological constraints on control, e.g.</s><s xml:id="_ZzZsdGX">reducing the possibility of one person dominating by constraining single-user actions, giving more opportunities than non-SCoSS to discuss possibilities before irrevocable action is taken.</s><s xml:id="_7bX4eyX">Availability of background information is achieved by representing areas of agreement and disagreement with the partner.</s><s xml:id="_jvV3u62">Newer multi-touch technologies provide additional opportunities for awareness, control and representation of background information for multiple users.</s><s xml:id="_GEDyMKd">Designers can focus on ways in which constraints on these mechanisms of action can be used to support collaboration.</s></p><p xml:id="_g5jyDKP"><s xml:id="_Ju7rMfC">The power of such effects of constraints on control and awareness were shown both in empirical studies of word categorisation, where children using SCoSS showed more complex discussion than in non-SCoSS <ref type="bibr" target="#b72">(Yuill et al., 2009)</ref>, but also in studies with pairs of severely autistic children <ref type="bibr">(Holt and Yuill, submitted)</ref>.</s><s xml:id="_82jrMwP">As expected, the autistic children showed no apparent awareness of others, such as anticipating action or hovering, in the (typical) non-SCoSS architecture.</s><s xml:id="_5GBmmYm">In contrast, in the SCoSS condition, children showed 'active awareness' of others, behaviours not previously apparent to their teachers, such as anticipating planned actions of others by waiting (hovering) for the partner to place an item in the correct box before clicking their own 'agree' button.</s><s xml:id="_XUB79mu">Differences in social constraints (whether the SCoSS partner was a peer or an adult) also led to changes in collaborative behaviour.</s><s xml:id="_qDXJ5fT">The case study illustrates how constraints can be implemented in the software to increase collaborative discussion, reduce domination and highlight awareness of different perspectives, as a resource for joint problem-solving.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2" xml:id="_Qq3dwGH">Case study 2: The effects of multi-touch versus single touch on awareness and control (OurSpace)</head><p xml:id="_RvcyXQs"><s xml:id="_hEzjM4m">Our second case study demonstrates how varying constraints on awareness and control has interacting effects on the nature of collaboration.</s><s xml:id="_7d2vXvH">OurSpace is software developed for multi-touch surfaces that represents a space (e.g. a set of offices or a classroom) with digital objects (people, furniture).</s><s xml:id="_EWZeZZw">Groups, usually of three people, arrange the space in a mutually agreed way given various constraints (Figure <ref type="figure" target="#fig_2">3</ref>).</s><s xml:id="_b6uRG3q">In the version for classrooms, background information was made available on the icons representing each student, and the information could be used to constrain the solution in different ways, which were up to the user to specify.</s><s xml:id="_DsPjb4t">Thus, colours were used to mark different friendship groups, the presence of a speech bubble represented a talkative student and some students were depicted wearing glasses.</s><s xml:id="_4K63apz">In one study, triads of children organised their classrooms in a multi-touch (MT) and a single touch (ST) condition <ref type="bibr" target="#b26">(Harris et al., 2009)</ref>.</s><s xml:id="_RTTTjEZ">In the MT condition, children had lower constraints on control than in ST, as all could move icons at the same time.</s><s xml:id="_sQuQPXR">This was expected to decrease awareness in groups of 3 users, since children could not apprehend their own and two other users' movements at the same time, in comparison to the ST condition, where all can be focused on a single movement at a time.</s><s xml:id="_VQrMstA">Users' awareness depends on how many users there are and how many icons are to be moved: in this case the numbers were large enough that awareness was compromised in a MT condition.</s></p><p xml:id="_zTtzYcx"><s xml:id="_TC6dPM4">Figure <ref type="figure" target="#fig_2">3</ref>. OurSpace: Tabletop classroom design application Qualitative analysis of conversation suggested that, as expected, MT brings lower levels of awareness of others' actions than ST: there were frequent, and urgent, requests for others to stop, or wait, when the simultaneous action was too fast to be apprehended, and in fact one group had to stop working temporarily because a child was upset that she 'lost the plot' given the speed of simultaneous action.</s><s xml:id="_5h2VRCC">However, this lack of awareness is replaced by other behaviours such as arms clashing across the table, and users making running commentaries on their actions.</s><s xml:id="_DM4bTWw">Not surprisingly, children spent significantly more time discussing turn-taking in the ST condition than the MT, in which they exhibited more task-focused discussion.</s><s xml:id="_AGSxNVg">Turn-taking talk seemed to replace task-focused talk, since the two were negatively correlated.</s><s xml:id="_JZXkWpx">There were no overall differences in physical or verbal equity between the two touch conditions.</s></p><p xml:id="_RxfEPNx"><s xml:id="_TGVG2hC">The decision about how to constrain control depends on the goals of the activity: if the objective was for children to learn to negotiate about turns, then ST would be appropriate, whereas if the goal was for the most considered solution to the task, then multi-touch would be preferred.</s><s xml:id="_m8nKWaV">The goal of a collaborative task will depend on the shared background knowledge and abilities of the users: younger children can show lower levels of equity because of their inexperience in regulating turn-taking, and this will be exacerbated in a ST condition.</s><s xml:id="_gHxaY8g">However, the school milieu supports fairness and allowing others to speak, meaning that children can speak out about inequity in ways that might remain unspoken for one-off groups with no clear norms.</s><s xml:id="_TZwvpGN">As one child completing OurSpace complained to his two peers, 'Why aren't you letting me arrange the tables?</s><s xml:id="_XCGw5cX">You two are like the bosses and I'm like nothing, you're not letting me do anything'.</s></p><p xml:id="_xX9RqvA"><s xml:id="_ymqAq4y">OurSpace provides an example of how the different mechanisms interact: placing a constraint on control (using single-touch, preventing simultaneous action) supports better awareness of what each user is doing, compared to the simultaneous actions in multi-touch, but at the same time, it highlights awareness of inequity of turns, so challenges the users to regulate turn-taking fairly, in the absence of a software constraint that enforces rotation of turns.</s><s xml:id="_AgMVha4">Designers therefore need to consider how constraints in awareness will influence control, and how this in turn is influenced by availability of background information, such as about equity and turn-taking  Children's free play with the augmented playset was contrasted with that in a switched-off version (the KC version).</s><s xml:id="_XN22UjZ">There are striking differences between the two conditions, for both typically-developing children and for children with autism <ref type="bibr" target="#b16">(Farr, and Hinske, 2010;</ref><ref type="bibr">Yuill et al., submitted)</ref>, in that there is significantly less solitary and more social play in the augmented version.</s><s xml:id="_kJfpzXm">In terms of awareness, the playset in both versions allows all-round views, allowing each child to see the focus of attention among their playmates through eye gaze and body orientation.</s><s xml:id="_aWCy7sz">More crucially for the quality of the play, the speaking figures in the augmented version apparently provide a boost to mutual awareness: simply because the figures can be expected to produce interesting and relevant sound effects, a child's bid to gain the attention of peers by showing a figure and looking at or vocalising to others is significantly more likely to be successful with the technology than without.</s><s xml:id="_uun7XGH">This apparently minor boost seems to have a snowball effect on the quality of play and in subsequent story-telling, producing more social play, more balanced narratives and more creative stories than in the KC condition.</s><s xml:id="_fEeKDzN">This demonstrates the potential for powerful cumulative effects of relatively fleeting aspects of mutual awareness.</s><s xml:id="_QexJfGe">Similar effects might be found with other technologies if a user's interaction with a digital object is highlighted through sound or visual effects (e.g. if someone shifts a key piece of a design).</s></p><p xml:id="_nHGm7Jz"><s xml:id="_DPyBmPN">In terms of control, each figure has a potential range of sounds that are activated only when a user picks the figure up and places it in a particular location.</s><s xml:id="_NNNrtVW">Because there can be many figures and locations, control is fairly unconstrained and distributed among users (multiple entry points).</s><s xml:id="_CSy7hEd">Control for KC and AKC is somewhat unconstrained, and distributed among users, with many more entry points than users, and thus engenders a situation where multiple narratives and cross-cutting actions are typical.</s></p><p xml:id="_cFQYDSb"><s xml:id="_yYNPBQ9">For a free play setting, this unconstrained control seems to work very well: both AKC and KC groups showed high levels of equity in their narrative conversation.</s><s xml:id="_vCjAQak">The AKC effects, however, are not entirely unconstrained: because of the RFID technology, characters can utter sounds appropriate to a specific location.</s><s xml:id="_nZukaZC">Users understand the contingency of figure-location combinations producing sound, so there is more or less systematic exploration of these combinations.</s><s xml:id="_7ER5cX6">In theory, in the KC 'anything goes': users have no constraints, other than physiological, on the sounds they themselves can produce in each location.</s><s xml:id="_DS8ZyyA">However, the lack of specific pre-programmed pairings was associated with reduced creativity: stories told after the KC sessions were less creative than those in the AKC.</s><s xml:id="_k9FPEtw">The moderate constraints of providing sounds apparently helped to suggest possible actions in an area, to teach vocabulary items and speech patterns and to prompt ideas for storytelling.</s><s xml:id="_T5WpBcN">The moderate constraint in the AKC condition was accompanied by significantly greater shifting between types of narrative (speaking in character, telling the story, making suggestions for the story) than in the KC condition.</s><s xml:id="_pbk6Ba5">Notably, in the KC condition, there was a significantly higher level of debate about the story, meaning that often no single narrative ever got off the ground: the total lack of constraint in what characters might say seems to have produced chaos.</s></p><p xml:id="_Es4xEg6"><s xml:id="_c4Y7Znn">Constraints on availability are not a strong feature for the AKC, as in many other tangibles: there is no visible history for the user of who has done what, e.g. who has configured or triggered a particular sound effect, so the history is opaque (except for the researcher, who has a useful web-based log of activity, that could be used in displays for users).</s><s xml:id="_vWrdbKQ">The character figures themselves are saturated with meaning, e.g. the actions, personality and preferences likely in a knight, a dragon or a princess figure, and these provide some constraints that help users in KC and AKC to construct scenarios.</s><s xml:id="_dG6vJt3">However, the AKC links specific sounds to characters, which can prompt elaboration on a given theme.</s><s xml:id="_aUVvvgg">For example, children heard particular archaic speech patterns, e.g.</s><s xml:id="_cbGDDTD">'My Lord!' and extended these creatively to other characters ('My Queen!', 'My Knight!'), and developed stories using actions that the characters' speech suggested.</s></p><p xml:id="_8qYVGr8"><s xml:id="_FKHt5CN">An important feature of the set is that it is played with similarly to a traditional toy, so the norms that guide and constrain behaviour transfer readily from typical nonaugmented play, e.g. that there is no set structure, that the figures do not belong to a particular person and therefore should be shared unless a claim is made.</s><s xml:id="_WyY5a79">The underlying assumptions of play are brought into relief through comparing play by typically-developing children and children with autism: for the latter, assumptions about the affordances of the objects are often not shared: for example children with autism may use the play figures atypically, e.g. as hammers or wedges rather than as characters, affecting the possibilities of shared understanding in play, and this lack of constraint is a challenge for design with this user group.</s><s xml:id="_RHmkmrU">This case study shows how the mechanisms can be extended to digitally-augmented tangible objects.</s><s xml:id="_yy7w9ut">As these are usually based on cultural artefacts that already exist, there is robust background information available about how the objects are to be used, functionally and socially.</s><s xml:id="_SyKy2MB">In the AKC, this is built on by having speech and sound that elaborate on the historical context, prompting imitation, learning and elaboration.</s></p><p xml:id="_aaJtbTa"><s xml:id="_AxsJaqg">Tangibles also tend to provide high levels of awareness, since movements of objects in space can be readily seen, and digital augmentation enables further signals of action, e.g.</s><s xml:id="_yEnZmWB">audio effects, visible trails of movement, haptic cues.</s><s xml:id="_suEtVay">Tangibles also offer relatively unconstrained control, or access points.</s><s xml:id="_CKsAe3z">In the AKC, having the constraint of sounds only playing for specific figure-location pairings supports structured exploration.</s><s xml:id="_VtcnND4">These three mechanisms work for tangibles in a similar way to Hornecker (2005) idea of 'embodied facilitation', with its three concepts of embodied constraints on control, multiple access points to awareness, and tailored representation based on users' prior experience.</s></p><p xml:id="_GCuZVKy"><s xml:id="_kAnu9Zd">To summarise the effects of varying constraint in each mechanism, Table <ref type="table">1 shows</ref>  Free play so low constraint, but sounds prompt elaboration Case Study 3 (groups) Knights' Castle, not augmented shared visual awareness but no augmentation by sound Multiple entry points, but 'anything goes': no sounds to explore Free play so low constraint, no prompts through sound</s></p><p xml:id="_hMJbyFa"><s xml:id="_4z9VuXN">Table <ref type="table">1</ref>.</s><s xml:id="_EuzmKCu">Group behaviours relating to each mechanism in the two versions of each case study.</s><s xml:id="_VzuWaGr">The more constrained in each design pair is shown shaded.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5." xml:id="_pVVXaKS">Design Implications</head><p xml:id="_gJD6sbh"><s xml:id="_pzdn5EW">We have shown how the mechanisms framework can be used to explain how constraints can elicit behaviours supporting collaboration.</s><s xml:id="_xS6eCgT">We now outline how the mechanisms framework can be used to inform the design and evaluation of technologies for different researcher or developer goals for collaborative working.</s></p><p xml:id="_nMQHqKW"><s xml:id="_6scsj3H">â€¢ Constraints: technological, physical or social?</s></p><p xml:id="_w6YXA9v"><s xml:id="_QtBs68W">We have highlighted different sources of constraint to help designers think about the many different ways in which constraints can be modified.</s><s xml:id="_mttQcYq">For example, awareness can involve any sense modality, alone or in combination, and haptic and audio channels could be used more extensively, particularly in the case of tangibles.</s><s xml:id="_RKT6EnS">The focus is often on technological sources of constraint but it is important to be aware of</s></p><p xml:id="_9hnMcjt"><s xml:id="_E37T7Hc">the role of constraints that operate without being explicitly designed in, such as implicit norms about group behaviour.</s><s xml:id="_YZ5JDzs">Underlying assumptions of how to behave have powerful effects which we sometimes see better when we move beyond the lab or design studio, and beyond the easily available user.</s><s xml:id="_QJCEH4V">Considering how variations in constraints of different types influence the mechanisms of behaviour can support the systematic empirical investigation of design on collaborative interaction and provides a strong bridge between HCI and psychology.</s><s xml:id="_bFJJm4b">â€¢ Awareness, control and availability: questions to ask When considering what users will be aware of from moment to moment, we need to consider what information is at hand and how it is constrained.</s><s xml:id="_vfaBsWU">This requires consideration of orientation of display, presence of personal 'territories' for users, size of surface in relation to users, amount of information a user is able to apprehend, possibility of users interfering with each other's awareness and the role of personal technologies that might require sharing, or might inhibit mutual awareness.</s><s xml:id="_ZnrUJTQ">Designers need to consider how control by different users can be coordinated or constrained, how this might be orchestrated by the technology, by the users, or by the technology having a role in moving control from the technology to the group, and the extent to which users might undo each other's work or might need to negotiate agreement.</s><s xml:id="_bRcVYUE">For availability, we need to consider what information is made manifest, and whether</s></p><p xml:id="_6773BCY"><s xml:id="_wnhmute">there are implicit norms underlying the use of such information.</s><s xml:id="_gV52VV5">The norms may be implicit but not shared.</s><s xml:id="_k3wPxtT">Multi-user technology has the capacity to present otherwise hidden information to the users' mutual awareness, and hence users' potential to control how this information is used to support better collaboration.</s></p><p xml:id="_THSkkXZ"><s xml:id="_gRGnnzY">â€¢ Designing for different user groups</s></p><p xml:id="_WJc8h8J"><s xml:id="_gzynQ9d">We have placed a particular focus in our review on user groups beyond the typical.</s></p><p xml:id="_WP34ZFH"><s xml:id="_5dH5v3Q">Designing for users who are less able to self-regulate naturally leads to the idea that the technology has to constrain in order to ensure, e.g. that users behave equitably, take turns and focus on the information that is most important.</s><s xml:id="_Bg4nFCB">However, there may be cases, particularly in pedagogical design, when designers may want to relax constraints, perhaps gradually, so that users develop the ability to self-regulate, either through their own behaviour or through altering the way that the technology operates throughout an interaction session.</s><s xml:id="_rrAqkmU">This gives technology an important role in constrain control, which might help focus attention but prompts a need to negotiate turn-taking.</s><s xml:id="_z88DxPu">If this negotiation is difficult, the designer could choose to constrain control by using identification of users to enforce turn-taking.</s><s xml:id="_JRkRgJ5">In multi-touch, all can act simultaneously, so several events can occur simultaneously in users' peripheral field of attention, reducing awareness of what others are doing.</s><s xml:id="_9ryvTMw">Control is less constrained than in single-touch and users might find this liberating, if actions are not very interdependent, or frustrating, if one user's action is contingent on another's.</s></p><p xml:id="_Kfh2B3u"><s xml:id="_7PpjGJg">Multi-touch can work well when seeking to support serendipitous effects and creative solutions.</s></p><p xml:id="_rv4SnKR"><s xml:id="_urTv7Gg">â€¢ The value of availability of background information and making norms explicit Ambient displays have great potential for conveying background information in real time, e.g. on contribution, previous actions, use of space.</s><s xml:id="_b6F4Jvz">However, making such information transparent is not enough: designers have to consider how this information is to be used.</s><s xml:id="_ZAvhfzn">Such displays rely on the group accepting and abiding by the social norm that underlies the design.</s><s xml:id="_Yp9MDvE">In this sense it is a low constraint, since people can simply choose to ignore the display.</s><s xml:id="_g8TkjfF">When there is little mutuality about the background assumptions and no easy way to step outside the task to discuss them, this sort of approach seems doomed to failure.</s><s xml:id="_DdWhZHm">Previous research largely ignores the norms that prevail in multi-user settings, in part because studies are often carried out in relatively artificial lab settings.</s><s xml:id="_njbdvu4">The potentially important but hidden effects of availability suggest the need to consider users' underlying assumptions.</s><s xml:id="_qB4Gq9X">Providing such background information could be used as an opportunity for focusing users' awareness on group processes, allowing them to reflect as a group on how they might be guided by this information.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_R6A8tXQ">â€¢ Low versus high constraints?</head><p xml:id="_dzkaHqv"><s xml:id="_YEf75ra">There are some situations where low constraint can be better for collaboration, for example, if people are conducting an activity on which they can each work independently, and need little awareness while doing so of other people's activity.</s></p><p xml:id="_eFtApqt"><s xml:id="_8hpDr6a">Examples include solving puzzles and games.</s><s xml:id="_d5RzXPH">Towards the end of a puzzle, where only one or two pieces need to be fitted or clues to be solved, one person's actions may then constrain another's more closely, so it is easier if they are constrained to slow down, e.g. by switching the software into single touch mode.</s></p><p xml:id="_bZCqgJ2"><s xml:id="_8XFPZNs">In a task with sustained periods of relatively independent or parallel working, it would be frustrating to have only a single entry point such as single-touch, mouse or tangible.</s><s xml:id="_qe5mNuD">If participants do not need to follow everything that their partners are doing, and if tasks are relatively independent, as in division of labour, or in free play, multiple control and multiple entry points can work well.</s></p><p xml:id="_9YGwCPA"><s xml:id="_dYjy6KW">By explicating the mechanisms of awareness, control and availability, and examining interaction closely to see how design can support these mechanisms in collaborative interaction, we want to encourage designers to consider each mechanism in terms of how the particular technology supports it and to decide whether each needs constraint or relaxation to support the desired form of interaction.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6." xml:id="_AJgjerM">Conclusions</head><p xml:id="_8RZhR2y"><s xml:id="_e8UQnMq">The mechanisms and constraints framework is intended to support the design and evaluation of multi-user interfaces to support collaboration across a range of devices, users and settings.</s><s xml:id="_EStNEQ9">We proposed three mechanisms of behaviour that can support or obstruct collaborative working: awareness of one's own and others' gestures, actions, movements and mental states, control over interactions with the interface and availability of the background information and expectations that users bring with them.</s><s xml:id="_DVDhupj">All of these involve mutuality: not just an individual's awareness, or control, but each person's recognition of the other's beliefs and intentions.</s><s xml:id="_CUvEa9V">Each of the mechanisms can be subject to higher or lower levels of constraint, and these constraints can arise from three different sources: the constraints imposed by physical capabilities, by what is allowed in the technology and by the social rules, often implicit, that underpin users' approaches to the technology.</s><s xml:id="_wsnxP3Q">We presented three case studies to illustrate the ways in which constraints on these mechanisms can work for or against better collaboration.</s><s xml:id="_5hZ9v36">In each case, varying the technological constraints in these mechanisms provides hard evidence of how collaboration is affected.</s><s xml:id="_Q9DubGG">There is no single ideal level of constraint: it depends on the aims of the designers, the interactions of the three mechanisms and the composition of the group.</s><s xml:id="_wAHHDyt">We offer the framework to designers and evaluators as a way of generating ideas, codifying observations and reflecting on how to support collaborative work and play.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc><div><p xml:id="_vdkHTRV"><s xml:id="_e9jfvnJ">Figure 1: Mutual awareness (from Kozima, 2010)</s></p></div></figDesc><graphic coords="14,90.00,237.60,143.40,67.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc><div><p xml:id="_fGzAKrx"><s xml:id="_fN53jxh">Figure 2. Typical layout for non-SCoSS (left) and SCoSS (right)</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>4. 3</head><label>3</label><figDesc><div><p xml:id="_6pJsv6u"><s xml:id="_scpcAzQ">Case Study 3: Tangible interfaces (Augmented Knights' Castle)Our third example shows how the framework can be applied beyond shared surfaces, to understand the design of tangibles and digitally-augmented objects in supporting collaborative interaction.</s><s xml:id="_HEnvv4m">Tangibles offer immediate opportunities for high levels of awareness, control and the application of background knowledge based on the norms that apply to physical objects.The Augmented Knights' Castle (AKC: Figure4;Hinske et al., 2008) is a PlaymobilÂ® medieval castle playset containing figures fitted with RFID tags, such that the figures 'speak' specified sounds when they are in particular locations of the set -for example, the Red Knight says 'Let us attack!' when in the castle courtyard, or the dragon roars when encountering the princess.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc><div><p xml:id="_pYeXAJ4"><s xml:id="_qKmyY2J">Figure 4: The Augmented Knights' Castle in play</s></p></div></figDesc><graphic coords="28,90.00,465.24,260.88,195.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc><div><p xml:id="_kqCFhtC"><s xml:id="_3bYPHW7">figure-location:more exploration</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="1,52.20,28.26,524.88,144.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="26,90.00,548.04,279.24,208.92" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xml:id="_H3smrvf"><p xml:id="_BNafQKG"><s xml:id="_gTrqrRJ">Acknowledgements.</s><s xml:id="_ZayNJyJ">The work for this paper was supported by a grant from the <rs type="funder">Engineering and Physical Sciences Research Council</rs> for the <rs type="projectName">ShareIT</rs> project (<rs type="grantNumber">EP/F017324/1</rs>).</s><s xml:id="_hQcHf9T">We thank all members of the <rs type="institution">ShareIT project</rs> for their contributions, our many research participants and the Riddles project team.</s><s xml:id="_SRcgjs3">We benefitted from insightful comments on the paper from many colleagues and in particular from the 3 anonymous reviewers, and from <rs type="person">Sam Holt</rs>, <rs type="person">Paul Marshall</rs> and <rs type="person">Julie Coultas</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_KBeBM8k">
					<idno type="grant-number">EP/F017324/1</idno>
					<orgName type="project" subtype="full">ShareIT</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_qWHSuSW"><p xml:id="_rVbrTEh"><s xml:id="_5Z2duA4">enabling groups to gain greater control over their collaborative work.</s><s xml:id="_rsFh6Jk">Designers need to be aware of the cultural practices that users associate with the multi-user interface, and these may be particularly rich for tangibles, e.g. in assumptions about what actions the objects afford and how they are to be shared.</s><s xml:id="_Va8hQTY">For older children, the issue of social control over the interface appears particularly important, so for example control through software might be more acceptable than control by an authority figure.</s><s xml:id="_e4uMsAV">We might expect adult users to abide more closely by social norms, but these will vary by social context, for example a game presented in a work or play setting.</s></p><p xml:id="_Q4YcvKe"><s xml:id="_QWCk28R">Users in mixed groups, such as families or serendipitous groups of people in public spaces, raise different considerations, and could perhaps benefit from tailored userspecific constraints.</s><s xml:id="_aPEPhTA">The constraints and mechanisms framework also invites reflection on how design might use different ways of supporting awareness, control and information availability in groups where there might be restrictions, e.g. in children with autism who will have difficulty with awareness of others, or those with sensory impairments.</s><s xml:id="_bFeE9KW">Here, considering how awareness might be enhanced, e.g. by sound, could both enhance the ability of such users to collaborate with others, and also supports our understanding of the nature of such impairments and how they compromise non-augmented interaction.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_tbRtKZM">â€¢ Beyond the tabletop</head><p xml:id="_p5B9v3u"><s xml:id="_AEQfNZq">We have focused mainly on interactive surfaces, but the framework can be applied to other multi-user technologies such as networked tablets, tangibles and combinations of personal and shared technologies.</s><s xml:id="_fX8srVW">All these provide wider scope for manipulating awareness, control and availability, as shown in our case study of a tangible, since these can be shared or asymmetrical, as in the case of a group using a shared surface along with individual devices, or a group each with individual tablets that are networked with each other and a shared display.</s><s xml:id="_era3pRn">Where there are individuallycontrollable devices, we need to consider what triggers users to share information rather than keeping it to themselves.</s></p><p xml:id="_AcqKqHG"><s xml:id="_cZBBGck">â€¢ Multi-touch or single touch?</s></p><p xml:id="_7nqhJ9Y"><s xml:id="_H2gR46m">Varying how many people can act on a multi-user interface affects awareness and control.</s><s xml:id="_eK3ugEt">Single-touch surfaces constrain awareness by heightening shared attentional focus, useful for tasks where users' actions are highly interdependent.</s><s xml:id="_HcrCpTk">They also Statement re prior publication: This document has not been published or submitted in this or any similar form to any prior publication.</s><s xml:id="_R2qQvKr">It includes summary description and analysis of other work the authors have published, and these papers are clearly referenced as appropriate.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_G9pudaw">On Privileging the Role of Gaze in Infant Social Cognition</title>
		<author>
			<persName><forename type="first">N</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gernsbacher</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1750-8606.2008.00044.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_K7aC5s6">Child Development Perspectives</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="59" to="65" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">AKHTAR, N., AND GERNSBACHER, M. 2008. On Privileging the Role of Gaze in Infant Social Cognition. Child Development Perspectives, 2, 59-65.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_wSmFXvX">Reflect: An Interactive Table for Regulating Face-to-Face Collaborative Learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bachour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dillenbourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_CUqs5Tg">Times of Convergence. Technologies Across Learning Contexts</title>
		<title level="s" xml:id="_kfmGTD3">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
	<note type="raw_reference">BACHOUR, K., KAPLAN, F., AND DILLENBOURG, P. 2008. Reflect: An Interactive Table for Regulating Face-to-Face Collaborative Learning. In Times of Convergence. Technologies Across Learning Contexts. Lecture Notes in Computer Science, 39-48. Springer.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_9DTCwc2">Designing storytelling technologies to encourage collaboration between young children</title>
		<author>
			<persName><forename type="first">S</forename><surname>Benford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Akesson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bayon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Druin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hourcade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>O'malley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Simsarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sundblad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Taxen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_7DVEWxK">Proc. CHI&apos;</title>
		<meeting>CHI&apos;</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000. 2000</date>
			<biblScope unit="page" from="556" to="563" />
		</imprint>
	</monogr>
	<note type="raw_reference">BENFORD, S., BEDERSON, B. B., AKESSON, K., BAYON, V., DRUIN, A., HANSSON, P., HOURCADE, J. P., INGRAM, R., NEALE, H., O&apos;MALLEY, C., SIMSARIAN, K. T., STANTON, D., SUNDBLAD, Y., AND TAXEN, G. 2000. Designing storytelling technologies to encourage collaboration between young children. Proc. CHI&apos;2000. ACM, 556-563.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_Uzfdnau">Low-Fi Skin Vision: A Case Study in Rapid Prototyping a Sensory Substitution System</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.14236/ewic/hci2009.7</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_xUNjcfc">Proc. BCS-HCI&apos;09</title>
		<meeting>BCS-HCI&apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
	<note type="raw_reference">BIRD, J., MARSHALL, P., AND ROGERS, Y. 2009. Low-Fi Skin Vision: A Case Study in Rapid Prototyping a Sensory Substitution System. Proc. BCS-HCI&apos;09. 55-64.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_BNt2Pjf">An observational study of how objects support engineering design thinking and communication: implications for the design of tangible media</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brereton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcgarry</surname></persName>
		</author>
		<idno type="DOI">10.1145/332040.332434</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sQdDatK">CHI Letters</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="17" to="224" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">BRERETON, M., AND MCGARRY, B. 2000. An observational study of how objects support engineering design thinking and communication: implications for the design of tangible media. CHI Letters 22, 17-224.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_dN7rJSK">Joint Visual Attention in Infancy</title>
		<author>
			<persName><forename type="first">G</forename><surname>Butterworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_SXWKUQ2">Theories of Infant Development</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Bremner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Slater</surname></persName>
		</editor>
		<meeting><address><addrLine>Malden, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Blackwell Publishing Ltd</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="317" to="354" />
		</imprint>
	</monogr>
	<note type="raw_reference">BUTTERWORTH, G. 2008. Joint Visual Attention in Infancy. In Theories of Infant Development, G. Bremner and A. Slater, Eds. Blackwell Publishing Ltd, Malden, MA, USA., 317-354.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_Yxa4Pus">Telling the whole story: Anticipation, inspiration and reputation in a field deployment of TellTable</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lindley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Helmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sellen</surname></persName>
		</author>
		<idno type="DOI">10.1145/1718918.1718967</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_EWYDERR">Proceedings of CSCW 2010, Computer Supported Cooperative Work (CSCW&apos;10)</title>
		<meeting>CSCW 2010, Computer Supported Cooperative Work (CSCW&apos;10)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
	<note type="raw_reference">CAO, X., LINDLEY, S., HELMES, J. AND SELLEN, A. 2010. Telling the whole story: Anticipation, inspiration and reputation in a field deployment of TellTable. Proceedings of CSCW 2010, Computer Supported Cooperative Work (CSCW&apos;10), ACM, 251-260.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_uvVAyEH">Enforcing Cooperative Storytelling: First Studies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cappelletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gelmini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pianesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zancanaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_AweyKUe">Proc. ICALT, Fourth IEEE International Conference on Advanced Learning Technologies (ICALT&apos;04)</title>
		<meeting>ICALT, Fourth IEEE International Conference on Advanced Learning Technologies (ICALT&apos;04)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="281" to="285" />
		</imprint>
	</monogr>
	<note type="raw_reference">CAPPELLETTI, A., GELMINI, G., PIANESI, F., ROSSI, F. AND ZANCANARO, M. 2004. Enforcing Cooperative Storytelling: First Studies, Proc. ICALT, Fourth IEEE International Conference on Advanced Learning Technologies (ICALT&apos;04), 281-285.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_AHe6Kxm">Social Cognition, Joint Attention, and Communicative Competence from 9 to 15 Months of Age</title>
		<author>
			<persName><forename type="first">C</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nagell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tomasello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Butterworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EN2n5uS">Monographs of the Society for Research in Child Development</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note type="raw_reference">CARPENTER, C., NAGELL, K., TOMASELLO, M., BUTTERWORTH, G. AND MOORE, C. 1998. Social Cognition, Joint Attention, and Communicative Competence from 9 to 15 Months of Age. Monographs of the Society for Research in Child Development 63, 4.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_Czs6bTF">Activity awareness and teamwork in CSCW</title>
		<author>
			<persName><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rosson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Convertino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ganoe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.intcom.2005.05.005</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Xz6PD6T">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="46" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">CARROLL, J., ROSSON, M, CONVERTINO, G. AND GANOE, C. 2006. Activity awareness and teamwork in CSCW. Interacting with Computers, 18, 1, 21-46.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_6kkjGqw">Grounding in Communication</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_DZYTT6V">Perspectives on socially shared cognition</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Resnick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Levine</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Teasley</surname></persName>
		</editor>
		<imprint>
			<publisher>APA Books</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="127" to="149" />
		</imprint>
	</monogr>
	<note type="raw_reference">CLARK, H. H., AND BRENNAN, S. E. 1991. Grounding in Communication. In Perspectives on socially shared cognition, L. B. Resnick, J. Levine, and S. D. Teasley, Eds. APA Books, 127-149.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Csikszentmihalyi</surname></persName>
		</author>
		<title level="m" xml:id="_DEnWdrR">Beyond Boredom and Anxiety: Experiencing Flow in Work and Play</title>
		<imprint>
			<publisher>Jossey-Bass</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">CSIKSZENTMIHALYI, M. 2000. Beyond Boredom and Anxiety: Experiencing Flow in Work and Play. Jossey-Bass.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_uNnjcpR">The impact of increased awareness while face-to-face</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Di Micco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hollenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pandolfo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YTWxMEd">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="47" to="96" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">DI MICCO, J. M, HOLLENBACH, K., PANDOLFO, A. AND BENDER, W. 2007. The impact of increased awareness while face-to-face. Human-Computer Interaction 22, 47-96.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_eHKUEYc">DiamondTouch: A multi-user touch technology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ZEhSyTr">Proc. UIST&apos;01</title>
		<meeting>UIST&apos;01</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
	<note type="raw_reference">DIETZ, P., AND LEIGH, D. 2001. DiamondTouch: A multi-user touch technology. Proc. UIST&apos;01, ACM, 219-226.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_w9bWy27">Coordination Breakdowns: How flexible is collaborative work</title>
		<author>
			<persName><forename type="first">S</forename><surname>Easterbrook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_fvWebxm">CSCW: Requirements and Evaluation</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Thomas</surname></persName>
		</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="91" to="106" />
		</imprint>
	</monogr>
	<note type="raw_reference">EASTERBROOK, S. 1996. Coordination Breakdowns: How flexible is collaborative work? In P. Thomas. Ed. CSCW: Requirements and Evaluation, 91-106. London: Springer-Verlag.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_m7qsEgf">What have you done! The role of &apos;interference&apos; in tangible environments for supporting collaborative learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Falcao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_wtwP482">Proc. of the 9th international conference on Computer supported collaborative learning</title>
		<meeting>of the 9th international conference on Computer supported collaborative learning</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
	<note>CSCL&apos;09)</note>
	<note type="raw_reference">FALCAO, T.P. AND PRICE, S. 2009. What have you done! The role of &apos;interference&apos; in tangible environments for supporting collaborative learning. Proc. of the 9th international conference on Computer supported collaborative learning, (CSCL&apos;09) 325-334.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_Zf2jaPY">The Augmented Knights Castle and Social Interaction in Children with Autism</title>
		<author>
			<persName><forename type="first">W</forename><surname>Farr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hinske</surname></persName>
		</author>
		<idno type="DOI">10.1145/1810543.1810548</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_bwCAe7Q">Proc. of the 9th International ACM SIGCHI Conference on Interaction Design and Children (IDC&apos;10)</title>
		<meeting>of the 9th International ACM SIGCHI Conference on Interaction Design and Children (IDC&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">FARR, W., YUILL, N., AND HINSKE, S. 2010. The Augmented Knights Castle and Social Interaction in Children with Autism. Proc. of the 9th International ACM SIGCHI Conference on Interaction Design and Children (IDC&apos;10).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_6rdvVEB">Finding design qualities in a tangible programming space</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fernaeus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tholander</surname></persName>
		</author>
		<idno type="DOI">10.1145/1124772.1124839</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_WB6rTEb">Proc. CHI&apos;06</title>
		<meeting>CHI&apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
	<note type="raw_reference">FERNAEUS, Y., AND THOLANDER, J. 2006. Finding design qualities in a tangible programming space. Proc. CHI&apos;06, ACM, 447-456.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_9FdvZe8">Bricks: Laying the foundations for graspable user interfaces</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fitzmaurice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ywdsWtG">Proc. CHI &apos;95</title>
		<meeting>CHI &apos;95</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="442" to="449" />
		</imprint>
	</monogr>
	<note type="raw_reference">FITZMAURICE, G., ISHII, H., AND BUXTON, W. 1995. Bricks: Laying the foundations for graspable user interfaces. Proc. CHI &apos;95, ACM, 442-449.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_d8JMbGG">Physical and virtual tools: Activity theory applied to the design of groupware</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fjeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gpDE9FA">CSCW</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="153" to="180" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">FJELD, M. 2002. Physical and virtual tools: Activity theory applied to the design of groupware. CSCW, 11, 153-180.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_aZjecgs">Unpacking collaboration around the tabletop: implications for collaborative learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bonnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_KgFCT5V">Proc. of Interactive Tabletops and Surfaces (ITS&apos;09)</title>
		<meeting>of Interactive Tabletops and Surfaces (ITS&apos;09)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
	<note type="raw_reference">FLECK, R., ROGERS, Y., YUILL, N., MARSHALL, P., CARR, A., RICK, J., AND BONNETT, V. 2009. Unpacking collaboration around the tabletop: implications for collaborative learning. Proc. of Interactive Tabletops and Surfaces (ITS&apos;09). 189-196.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_FWwKB3t">Co-located Sharing in a Multi-Device Environment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garrod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ScC2B6p">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="8" to="11" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Why is Conversation So Easy?</note>
	<note type="raw_reference">FLECK, R., YUILL, N. AND RICK, J. (submitted). Co-located Sharing in a Multi- Device Environment. GARROD, S., AND PICKERING, M. J. 2004. Why is Conversation So Easy? Trends in Cognitive Sciences 8, 8-11.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_ypqpzhE">The Ontogeny of Triadic Cooperative Interactions with Humans in an Infant Gorilla</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gomez</surname></persName>
		</author>
		<idno type="DOI">10.1075/is.11.3.02gom</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4jvfKfQ">Interaction Studies</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="353" to="379" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">GOMEZ, J. 2010. The Ontogeny of Triadic Cooperative Interactions with Humans in an Infant Gorilla. Interaction Studies 11, 353-379.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_j5fYDAA">A Descriptive Framework of Workspace Awareness for Real-Time Groupware</title>
		<author>
			<persName><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<idno type="DOI">10.1023/a:1021271517844</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_t4ZRsDz">CSCW</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="411" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">GUTWIN, C., AND GREENBERG, S. 2002. A Descriptive Framework of Workspace Awareness for Real-Time Groupware. CSCW 11, 411-446.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_T5hux8E">Direct Intentions: The Effects of Input Devices on Collaboration around a Tabletop Display</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mandryk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PmeckK4">IEEE Tabletop</title>
		<imprint>
			<biblScope unit="volume">06</biblScope>
			<biblScope unit="page" from="177" to="184" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">HA, V., INKPEN, K., WHALEN, T., AND MANDRYK, R. 2006. Direct Intentions: The Effects of Input Devices on Collaboration around a Tabletop Display. IEEE Tabletop &apos;06, 177-184.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_Y7xMWG2">Mobile (Cellular) use and driving: A critical review of research methodology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Haigney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Westerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WkXbXDr">Ergonomics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="132" to="143" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">HAIGNEY, D., AND WESTERMAN, S. 2001. Mobile (Cellular) use and driving: A critical review of research methodology. Ergonomics 44, 132-143.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_RauH9m6">Around the table: Are multiple-touch surfaces better than single-touch for children&apos;s collaborative interactions?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bonnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.3115/1600053.1600104</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CzpBFVF">Proc. CSCL&apos;</title>
		<imprint>
			<biblScope unit="volume">09</biblScope>
			<biblScope unit="page" from="335" to="344" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">HARRIS, A., RICK, J., BONNETT, V., YUILL, N., FLECK, R., MARSHALL, P., AND ROGERS, Y. 2009. Around the table: Are multiple-touch surfaces better than single-touch for children&apos;s collaborative interactions? Proc. CSCL&apos;09, 335-344.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_388Qa6V">Collaboration and Control: Crisis Management and Multimedia Technology in London Underground Line Control Rooms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qkUsD4v">CSCW</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="94" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
	<note type="raw_reference">HEATH, C., AND LUFF, P. 1992. Collaboration and Control: Crisis Management and Multimedia Technology in London Underground Line Control Rooms. CSCW 1, 69-94.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_JUVEknZ">Kingdom of the Knights: evaluation of a seamlessly augmented toy environment for playful learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hinske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lampe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Labngheinrich</surname></persName>
		</author>
		<idno type="DOI">10.1145/1551788.1551829</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_pC2YGY5">Proc. of the 8th International Conference on Interaction Design and Children</title>
		<meeting>of the 8th International Conference on Interaction Design and Children</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="202" to="205" />
		</imprint>
	</monogr>
	<note type="raw_reference">HINSKE, S., LAMPE, M., YUILL, N., PRICE, S., AND LABNGHEINRICH, M. 2009. Kingdom of the Knights: evaluation of a seamlessly augmented toy environment for playful learning. Proc. of the 8th International Conference on Interaction Design and Children. 202-205.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main" xml:id="_bzmBq9H">Facilitating classroom interaction and awareness of a partner in children with autism and typical development: effects of a dual control computer paradigm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10803-013-1868-x</idno>
		<imprint/>
	</monogr>
	<note>submitted</note>
	<note type="raw_reference">HOLT, S., AND YUILL, N. (submitted). Facilitating classroom interaction and awareness of a partner in children with autism and typical development: effects of a dual control computer paradigm.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_8baNnfZ">A Design Theme for Tangible Interaction: Embodied Facilitation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hornecker</surname></persName>
		</author>
		<idno type="DOI">10.1007/1-4020-4023-7_2</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_sdGT45W">Proc. ECSCW&apos;05</title>
		<meeting>ECSCW&apos;05</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="23" to="43" />
		</imprint>
	</monogr>
	<note type="raw_reference">HORNECKER, E. 2005. A Design Theme for Tangible Interaction: Embodied Facilitation. Proc. ECSCW&apos;05. 23-43.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_q6vGn77">Getting a Grip on Tangible Interaction: A Framework on Physical Space and Social Interaction</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hornecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buur</surname></persName>
		</author>
		<idno type="DOI">10.1145/1124772.1124838</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_nJrGTMB">Proc. CHI&apos;06</title>
		<meeting>CHI&apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="437" to="446" />
		</imprint>
	</monogr>
	<note type="raw_reference">HORNECKER, E., AND BUUR, J. 2006. Getting a Grip on Tangible Interaction: A Framework on Physical Space and Social Interaction. Proc. CHI&apos;06, ACM, 437- 446.</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_Qns43Dj">Collaboration and interference: Awareness with mice or touch input</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hornecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.1145/1460563.1460589</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_jrgAVHb">Proc. CSCW&apos;08</title>
		<meeting>CSCW&apos;08</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="67" to="176" />
		</imprint>
	</monogr>
	<note type="raw_reference">HORNECKER, E., MARSHALL, P., DALTON, N., AND ROGERS, Y. 2008. Collaboration and interference: Awareness with mice or touch input. Proc. CSCW&apos;08. ACM, 67-176.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_KYydMkD">Semi-Public Displays for Small, Co-located Groups</title>
		<author>
			<persName><forename type="first">E</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mynatt</surname></persName>
		</author>
		<idno type="DOI">10.1145/642611.642622</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bgD3QEg">CHI Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="49" to="56" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">HUANG, E., AND MYNATT, E. 2003,.Semi-Public Displays for Small, Co-located Groups. CHI Letters, 5, 49-56.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_q7F7pVa">Sonigraphical Instruments: From FMOL to the reacTable</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jorda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_nhZr5qC">Proc. of the 3 rd Conference on New Interfaces for Musical Expression (NIME&apos;03)</title>
		<meeting>of the 3 rd Conference on New Interfaces for Musical Expression (NIME&apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">JORDA, S. 2003, Sonigraphical Instruments: From FMOL to the reacTable. Proc. of the 3 rd Conference on New Interfaces for Musical Expression (NIME&apos;03).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_AVR9WtC">Visualizing Audio in Group Table Conversation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Karahalios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bergstrom</surname></persName>
		</author>
		<idno type="DOI">10.1109/tabletop.2006.37</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nAMqewC">IEEE Proc. TableTop</title>
		<imprint>
			<biblScope unit="page" from="131" to="134" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KARAHALIOS, K., AND BERGSTROM, T. 2006. Visualizing Audio in Group Table Conversation. IEEE Proc. TableTop, 131-134.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_JWRHMJf">I&apos;m keeping those there, are you?&apos;&apos; The role of a new user interface paradigm -Separate Control of Shared Space (SCOSS) -in the collaborative decision-making process</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kerawalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luckin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sgdwWqc">Computers and Education</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KERAWALLA, L., PEARCE, D., YUILL, N., LUCKIN, R., AND HARRIS, A. 2008. &apos;&apos;I&apos;m keeping those there, are you?&apos;&apos; The role of a new user interface paradigm -Separate Control of Shared Space (SCOSS) -in the collaborative decision-making process. Computers and Education, 50, 193-206.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main" xml:id="_TgzvXbs">Digital Mysteries: Designing for Learning at the Tabletop</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Kharuffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Leat</surname></persName>
		</author>
		<idno type="DOI">10.1145/1936652.1936689</idno>
		<idno>CS-TR-1171</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Newcastle University Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note type="raw_reference">KHARUFFA, A.S., OLIVIER, P. AND LEAT, D. 2009. Digital Mysteries: Designing for Learning at the Tabletop. Newcastle University Computer Science Technical Report CS-TR-1171.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_Ns2zHQ5">Children&apos;s use of gesture to resolve lexical ambiguity</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kidd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Holler</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-7687.2009.00830.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7tPnrHJ">Developmental Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="903" to="913" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KIDD, E., AND HOLLER, J. 2009. Children&apos;s use of gesture to resolve lexical ambiguity. Developmental Science 12, 6, 903-913.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_rR5sNkz">Meeting Mediator: Enhancing group collaboration and leadership with sociometric feedback</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
		<idno type="DOI">10.1145/1460563.1460636</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ntXetYr">CSCW</title>
		<imprint>
			<biblScope unit="page" from="457" to="466" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KIM, T., CHANG, HOLLAND AND PENTLAND, A. 2008. Meeting Mediator: Enhancing group collaboration and leadership with sociometric feedback. CSCW, 457-466.</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">H</forename><surname>Kozima</surname></persName>
		</author>
		<ptr target="http://www.myu.ac.jp/~xkozima/carebots/index-eng.html" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">KOZIMA, H. 2010. http://www.myu.ac.jp/~xkozima/carebots/index-eng.html</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_tCh463E">The Fantasy Table</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mansor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>De Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>De Bruijn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_JkTbEWE">Proc.of the 8th International Conference on Interaction Design and Children (IDC&apos;08)</title>
		<meeting>.of the 8th International Conference on Interaction Design and Children (IDC&apos;08)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
	<note type="raw_reference">MANSOR, E., DE ANGELI, A., AND DE BRUIJN, O. 2009. The Fantasy Table. Proc.of the 8th International Conference on Interaction Design and Children (IDC&apos;08), 70-79.</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_NfXggqE">Rethinking &apos;multi-user&apos;: an in-the-wild study of how groups approach a walk-up-and-use tabletop interface</title>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kreitmayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<idno type="DOI">10.1145/1978942.1979392</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_vSq63Zc">Proc. CHI&apos;11</title>
		<meeting>CHI&apos;11</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3033" to="3042" />
		</imprint>
	</monogr>
	<note type="raw_reference">MARSHALL, P., MORRIS, R., ROGERS, Y., KREITMAYER, S., AND DAVIES, M. 2011. Rethinking &apos;multi-user&apos;: an in-the-wild study of how groups approach a walk-up-and-use tabletop interface, Proc. CHI&apos;11, ACM, 3033-3042.</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_PhJzV4b">Behavioral analysis of asymmetric information sharing on Lumisight table</title>
		<author>
			<persName><forename type="first">M</forename><surname>Matsuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Namemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tWcxEjg">TableTop. First IEEE International Workshop</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">MATSUDA, M, MATSUSHITA, M., YAMADA, T., AND NAMEMURA, T.2006. Behavioral analysis of asymmetric information sharing on Lumisight table, TableTop. First IEEE International Workshop, 7.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_AFBAFnd">The development of children&apos;s knowledge of self-control strategies</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mischel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mischel</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8624.1983.tb00485.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nwJWwxr">Child Development</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
	<note type="raw_reference">MISCHEL, H., AND MISCHEL, W. 1983. The development of children&apos;s knowledge of self-control strategies. Child Development 54, 603-619.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_N3wgE7B">Fourteen-month-olds know what others experience only in joint engagement</title>
		<author>
			<persName><forename type="first">H</forename><surname>Moll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tomasello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8SuRevR">Developmental Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="826" to="835" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">MOLL, H., CARPENTER, M. AND TOMASELLO, M. 2007. Fourteen-month-olds know what others experience only in joint engagement. Developmental Science, 10, 826-835.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_mBTuFyZ">The role of familiarity among group members in collaborative inhibition and social contagion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mujde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Teckan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_W69qHnw">Social Psychology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="111" to="118" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">MUJDE, P. AND TECKAN, A. 2009. The role of familiarity among group members in collaborative inhibition and social contagion. Social Psychology, 40, 3, 111- 118.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_wfqCEJZ">Control of Permission</title>
		<author>
			<persName><forename type="first">K</forename><surname>Neary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burnstein</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0014088</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qUtvFZJ">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="873" to="876" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">NEARY, K., FRIEDMAN, O. AND BURNSTEIN, C. 2009. Control of Permission. Developmental Psychology, 45, 3, 873-876.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_Qf7X4RG">Natural user interfaces are not natural</title>
		<author>
			<persName><forename type="first">D</forename><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_73sFkcB">Interactions</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="6" to="10" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">NORMAN, D. 2010. Natural user interfaces are not natural. Interactions 17, 3, 6-10.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_Jkq8xcm">I&apos;ll walk this way: Eyes reveal the direction of locomotion and make passersby look and go the other way</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nummenmaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>HyÃ¶nÃ¤</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hietanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Z6765sV">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1454" to="1458" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">NUMMENMAA, L., HYÃ–NÃ„, J., AND HIETANEN, J. K., 2009. I&apos;ll walk this way: Eyes reveal the direction of locomotion and make passersby look and go the other way. Psychological Science, 20, 1454-1458.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_xP5XhWx">The task-sharing framework: A generic approach to scaffolding collaboration and meta-collaboration in educational software</title>
		<author>
			<persName><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kerawalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luckin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_KqN4ZK2">Towards sustainable and scalable educational innovations informed by the learning sciences</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Looi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Jonassen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ikeda</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">PEARCE, D., KERAWALLA, L., LUCKIN, R., YUILL, N., AND HARRIS, A. 2005. The task-sharing framework: A generic approach to scaffolding collaboration and meta-collaboration in educational software. In Towards sustainable and scalable educational innovations informed by the learning sciences, C. Looi, D. Jonassen, and M. Ikeda, Eds. IOS Press, Singapore.</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_wRwUEUN">SIDES: a cooperative tabletop computer game for social skills development</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Piper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_P94kt6k">Proc. CSCW&apos;06</title>
		<meeting>CSCW&apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note type="raw_reference">PIPER, A. M., O&apos;BRIEN, E., MORRIS, M. R., AND WINOGRAD, T. 2006. SIDES: a cooperative tabletop computer game for social skills development. Proc. CSCW&apos;06. ACM,1-10.</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_uTgKktz">Learning by doing with shareable interfaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Haig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vxGeCdA">Children, Youth and Environments</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="321" to="342" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">RICK, J., ROGERS, Y., HAIG, C. AND YUILL, N. 2009. Learning by doing with shareable interfaces. Children, Youth and Environments, 19 (1) 321-342.</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_6BXkZdZ">Extending Tabletops to Support Flexible Collaborative Interactions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Hazlewood</surname></persName>
		</author>
		<idno type="DOI">10.1109/tabletop.2006.13</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_AF27q73">Proc. of Tabletop</title>
		<meeting>of Tabletop</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
	<note type="raw_reference">ROGERS, Y., LIM, K., AND HAZLEWOOD, W. R. 2006. Extending Tabletops to Support Flexible Collaborative Interactions. Proc. of Tabletop, 71-78.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_RYM6hsP">Equal Opportunities: Do shareable interfaces promote more group participation than single user displays?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hazelwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
		</author>
		<idno type="DOI">10.1080/07370020902739379</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_u86WvnM">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="116" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">ROGERS, Y., LIM, Y., HAZELWOOD, W., AND MARSHALL, P. 2009. Equal Opportunities: Do shareable interfaces promote more group participation than single user displays? Human-Computer Interaction 24 (2) 79-116.</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_nFnN6Hg">Collaborating around vertical and horizontal large interactive displays: Which way is best?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lindley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YCBpm4R">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1133" to="1152" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">ROGERS, Y., AND LINDLEY, S. 2004. Collaborating around vertical and horizontal large interactive displays: Which way is best? Interacting with Computers, 16, 1133-1152.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main" xml:id="_68utQ7h">Configuring spaces and surfaces to support collaborative interaction. In Public and situated displays: social and interactional aspects of shared display technologies</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rodden</surname></persName>
		</author>
		<editor>K. O&apos;Hara</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="45" to="79" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">ROGERS, Y. AND RODDEN, T. 2003. Configuring spaces and surfaces to support collaborative interaction. In Public and situated displays: social and interactional aspects of shared display technologies, K. O&apos;Hara, Ed. Springer, Berlin, 45-79.</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Rogoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lave</surname></persName>
		</author>
		<title level="m" xml:id="_J8Gn25b">Everyday Cognition: Its development in social context</title>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
	<note type="raw_reference">ROGOFF, B., AND LAVE, J. 1984. Everyday Cognition: Its development in social context. Harvard University Press.</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_cjN5PEF">Constructing a joint problem space: the computer as a tool for sharing knowledge</title>
		<author>
			<persName><forename type="first">S</forename><surname>Teasley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roschelle</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203052594-14</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_THbj7mG">Computers as cognitive tools</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Lajoie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Derry</surname></persName>
		</editor>
		<meeting><address><addrLine>Hillsdale</addrLine></address></meeting>
		<imprint>
			<publisher>LEA</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note type="raw_reference">TEASLEY, S. AND ROSCHELLE, S. 1993. Constructing a joint problem space: the computer as a tool for sharing knowledge, in S. Lajoie and S. Derry, Computers as cognitive tools, Hillsdale: LEA.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main" xml:id="_vMjZsMm">Exploring the Effects of Group Size and Table Size on Interactions with Tabletop Shared-Display Groupware</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_V2VAXNx">CSCW</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="284" to="293" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">RYALL, K., FORLINES, C., SHEN, C., AND MORRIS, M. 2004. Exploring the Effects of Group Size and Table Size on Interactions with Tabletop Shared- Display Groupware. CSCW, 6, 284-293.</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_FfERxZP">iDwidgets: Parameterizing Widgets by User Identity</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esenther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vernier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_WrvvApe">Proc. of Human-Computer Interaction -INTERACT 2005: IFIP TC13 International Conference</title>
		<meeting>of Human-Computer Interaction -INTERACT 2005: IFIP TC13 International Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1124" to="1128" />
		</imprint>
	</monogr>
	<note type="raw_reference">RYALL, K., ESENTHER, A., EVERITT, K., FORLINES, C., MORRIS, M.R., SHEN, C., SHIPMAN, S. AND VERNIER, F. 2005. iDwidgets: Parameterizing Widgets by User Identity. Proc. of Human-Computer Interaction -INTERACT 2005: IFIP TC13 International Conference, 1124-1128.</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_8bNnZPB">The problem with &quot;awareness</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sAUGB82">CSCW</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="285" to="298" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">SCHMIDT, K. 2002. The problem with &quot;awareness&quot;. CSCW 11 (3-4) 285-98.</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main" xml:id="_pUwjRxN">System guidelines for colocated, collaborative work on a tabletop display</title>
		<author>
			<persName><forename type="first">S</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mandryk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_bxJe9Cj">Proc. ECSCW</title>
		<meeting>ECSCW</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="159" to="178" />
		</imprint>
	</monogr>
	<note type="raw_reference">SCOTT, S., GRANT, K., AND MANDRYK, R. 2003a. System guidelines for co- located, collaborative work on a tabletop display. Proc. ECSCW, 159-178.</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main" xml:id="_Uu5SfuN">Understanding children&apos;s collaborative interactions in shared environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mandryk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ARJMAcw">JCAL</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="220" to="228" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">SCOTT, S., MANDRYK, R., AND INKPEN, K. 2003b. Understanding children&apos;s collaborative interactions in shared environments. JCAL 19,(2), 220-228.</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_Pa579NM">Representing others&apos; actions: just like one&apos;s own?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sebanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Knoblich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wVdvQrF">Cognition</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="11" to="B21" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">SEBANZ, N., AND KNOBLICH, G. 2003. Representing others&apos; actions: just like one&apos;s own? Cognition 88, 3, B11-B21.</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main" xml:id="_YrTRbZX">Sharing and building digital group histories</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vernier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forlines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hmy8yyk">CSCW</title>
		<imprint>
			<biblScope unit="page" from="324" to="333" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">SHEN, C., LESH, N., VERNIER, F., FORLINES, C., AND FROST, J. 2002. Sharing and building digital group histories. CSCW, 324-333.</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main" xml:id="_mKHJdeC">Single Display Groupware: A Model for Co-present Collaboration</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Druin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_zETdP3N">Proc. CHI&apos;99</title>
		<meeting>CHI&apos;99</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="286" to="293" />
		</imprint>
	</monogr>
	<note type="raw_reference">STEWART, J., BEDERSON, B., AND DRUIN, A. 1999. Single Display Groupware: A Model for Co-present Collaboration. Proc. CHI&apos;99, ACM, 286-293.</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main" xml:id="_mTSCQaT">Creativity From Constraints: The Psychology of Breakthrough</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Stokes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">STOKES, P.D. 2005. Creativity From Constraints: The Psychology of Breakthrough. Springer.</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_khWdWCj">Technology affordances for intersubjective meaning-making: a research agenda for CSCL</title>
		<author>
			<persName><forename type="first">D</forename><surname>Suthers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZGbBK87">International Journal of Computer Supported Collaborative Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="315" to="337" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">SUTHERS, D. 2006. Technology affordances for intersubjective meaning-making: a research agenda for CSCL. International Journal of Computer Supported Collaborative Learning 1, 315-337.</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main" xml:id="_xBCzyqg">Mother and infant talk about mental states relates to desire language and emotion understanding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Taumoepeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ruffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tbACBu7">Child Development</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="465" to="481" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">TAUMOEPEAU, M. AND RUFFMAN, T. 2006. Mother and infant talk about mental states relates to desire language and emotion understanding. Child Development, 77, 2, 465-481.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Tomasello</surname></persName>
		</author>
		<title level="m" xml:id="_6bRm3Zk">Why We Cooperate</title>
		<meeting><address><addrLine>Boston, Mass</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">TOMASELLO, M. 2009. Why We Cooperate. MIT Press, Boston, Mass.</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main" xml:id="_64mX5Ek">The concept and foundations of infant intersubjectivity</title>
		<author>
			<persName><forename type="first">C</forename><surname>Trevarthen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Y9qJRbM">Intersubjective Communication and Emotion in Early Ontogeny</title>
		<editor>
			<persName><forename type="first">S</forename><surname>BrÃ¥ten</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="15" to="46" />
		</imprint>
	</monogr>
	<note type="raw_reference">TREVARTHEN, C. 1978. The concept and foundations of infant intersubjectivity. In S. BrÃ¥ten (Ed.) Intersubjective Communication and Emotion in Early Ontogeny, (pp. 15-46). Cambridge: Cambridge University Press.</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main" xml:id="_ngjhhrk">How technology for comprehension training can support conversation towards the joint construction of meaning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kerawalla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luckin</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9817.2008.01384.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6uU67nb">Journal of Research in Reading</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="125" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">YUILL, N., PEARCE, D., KERAWALLA, L., HARRIS, A., AND LUCKIN, R. 2009. How technology for comprehension training can support conversation towards the joint construction of meaning. Journal of Research in Reading 32, 1, 109-125.</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main" xml:id="_gxY5g3f">Using an augmented toy to demonstrate the role of joint attention in children&apos;s cooperative play and narrative</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hinske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00418</idno>
		<imprint/>
	</monogr>
	<note>submitted</note>
	<note type="raw_reference">YUILL, N., HINSKE, S. AND WILLIAMS, S. (submitted). Using an augmented toy to demonstrate the role of joint attention in children&apos;s cooperative play and narrative.</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main" xml:id="_69txWJC">Designing a Playground for Children with Autistic Spectrum Disorders -Effects on Playful Peer Interactions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yuill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Strieth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Roake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Aspden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Todd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XFnFJcn">Journal of Autism and Developmental Disorders</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1192" to="1196" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">YUILL, N., STRIETH, S., ROAKE, C., ASPDEN, R., AND TODD, B. 2007. Designing a Playground for Children with Autistic Spectrum Disorders -Effects on Playful Peer Interactions. Journal of Autism and Developmental Disorders 37, 6, 1192-1196.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
