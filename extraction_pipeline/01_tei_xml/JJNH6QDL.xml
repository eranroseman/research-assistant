<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_ygE4zUy">Detecting Eating Episodes by Tracking Jawbone Movements with a Non-Contact Wearable Sensor</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">San</forename><surname>Keum</surname></persName>
						</author>
						<author>
							<persName><surname>Chun</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Sarnab</forename><surname>Bhattacharya</surname></persName>
							<email>sarnab2008@gmail.com</email>
						</author>
						<author>
							<persName><surname>Bhattacharya</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<note type="raw_affiliation">University of Texas at Austin , USA</note>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<note type="raw_affiliation">University of Texas at Austin , USA EDISON THOMAZ ,</note>
								<orgName type="department">EDISON THOMAZ</orgName>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<note type="raw_affiliation">University of Texas at Austin , USA</note>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<note type="raw_affiliation">University of Texas at Austin , 2501 Speedway , Austin , Texas , 78712 , USA ,</note>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<addrLine>2501 Speedway</addrLine>
									<postCode>78712</postCode>
									<settlement>Austin</settlement>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<note type="raw_affiliation">University of Texas at Austin , 2501 Speedway , Austin , Texas , 78712 , USA , Edison Thomaz ,</note>
								<orgName type="department">Edison Thomaz</orgName>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<addrLine>2501 Speedway</addrLine>
									<postCode>78712</postCode>
									<settlement>Austin</settlement>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<note type="raw_affiliation">University of Texas at Austin , 2501 Speedway , Austin , Texas , 78712 , USA ,</note>
								<orgName type="institution">University of Texas at Austin</orgName>
								<address>
									<addrLine>2501 Speedway</addrLine>
									<postCode>78712</postCode>
									<settlement>Austin</settlement>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_qZvkmba">Detecting Eating Episodes by Tracking Jawbone Movements with a Non-Contact Wearable Sensor</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">16B93162829613581C2CB025AAD68157</idno>
					<idno type="DOI">10.1145/3191736</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T10:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_n48MCzs">CCS Concepts:</term>
					<term xml:id="_8scZ5R5">Human-centered computing → Empirical studies in ubiquitous and mobile computing</term>
					<term xml:id="_s5pftPp">• Applied computing → Health informatics</term>
					<term xml:id="_nxH9kcF">automated dietary monitoring, eating detection, food intake, gesture recognition, commodity sensing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_MJc25cg"><p xml:id="_e8dZKGn"><s xml:id="_BQZh6gF">Eating is one of the most fundamental human activities, and because of the important role it plays in our lives, it has been extensively studied.</s><s xml:id="_mvRhMwb">However, an objective and usable method for dietary intake tracking remains unrealized despite numerous efforts by researchers over the last decade.</s><s xml:id="_j46MU7q">In this work, we present a new wearable computing approach for detecting eating episodes.</s><s xml:id="_YK56uST">Using a novel multimodal sensing strategy combining accelerometer and range sensing, the approach centers on a discreet and lightweight instrumented necklace that captures head and jawbone movements without direct contact with the skin.</s><s xml:id="_zR9tbWt">An evaluation of the system with 32 participants comprised of three phases resulted in eating episodes detected with 95.2% precision and 81.9% recall in controlled studies and 78.2% precision and 72.5% recall in the free-living study.</s><s xml:id="_uU4arxR">This research add technical contributions to the fields of wearable computing, human activity recognition, and mobile health.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" xml:id="_S53TPvT">INTRODUCTION</head><p xml:id="_6wb22WV"><s xml:id="_SjJ67eB">Good nutrition is vital for optimal growth, development, and prevention of disease <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b26">27]</ref>.</s><s xml:id="_AYaCU3C">In particular, poor eating habits are strongly tied to obesity, a major public health problem <ref type="bibr" target="#b27">[28]</ref>.</s><s xml:id="_MZH9sTb">The World Health Organization estimates that more than 1.9 billion adults, 18 and older, were overweight in 2014 <ref type="bibr" target="#b0">[1]</ref>.</s><s xml:id="_bVhFBEM">Of these, over 600 million were obese <ref type="bibr" target="#b0">[1]</ref>.</s><s xml:id="_VQsk9Ng">Due to the importance of diet in human life, health researchers have been interested in understanding the science of measuring dietary intake for decades <ref type="bibr" target="#b39">[40]</ref>, often relying on self-report-based instruments such as food frequency questionnaires (FFQ), <ref type="bibr" target="#b23">24</ref>-hour recalls, and food diaries.</s><s xml:id="_37upphE">Unfortunately, these methods have been widely recognized to have serious shortcomings such as biases, which increase the risk of false characterization of dietary habits.</s></p><p xml:id="_2yk6NRW"><s xml:id="_bz3yUks">To circumvent the weaknesses observed in self-report-based methods, and by leveraging advances in mobile and sensing technologies, a large body of research work around automatic dietary monitoring has emerged 4:2 • K. Chun et al.</s></p><p xml:id="_fvj5HK6"><s xml:id="_j4qRQxZ">over the last decade.</s><s xml:id="_h6Sjfpv">Automatic eating detection has grown to become a key area of interest since it captures the temporal dynamics of eating behaviors and can trigger processes such as behavioral interventions <ref type="bibr" target="#b40">[41]</ref>.</s><s xml:id="_K7cB7pH">Although steady progress has been made in the field, many proposed systems for eating detection have required individuals to wear obtrusive devices.</s><s xml:id="_qD6EwfU">These systems, exemplified by neck collars for swallow detection <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26]</ref> or microphones inside the ear canal to detect chewing <ref type="bibr" target="#b29">[30]</ref> proved to be largely impractical and unpopular for everyday usage.</s><s xml:id="_urY4udJ">Consequently, few human subject experiments targeting automated dietary monitoring have been conducted in naturalistic settings for an extended period of time.</s><s xml:id="_NU27SKK">In the last couple of years, techniques based on off-the-shelf consumer devices such as mobile phones, smart watches, and wearables (e.g., Google Glass) have been developed.</s><s xml:id="_M4mpHX3">However, despite their practicality, these methods have not yet demonstrated performance results that meet application requirements.</s><s xml:id="_CzPA6mJ">These limitations have prevented eating detection, and thus automatic dietary monitoring, from having significant real-world impact.</s></p><p xml:id="_mSpBb4N"><s xml:id="_fjbxhKk">In this paper, we present a wearable device in the form factor of an instrumented necklace that can detect eating episodes, a keystone towards implementing a fully autonomous dietary monitoring system.</s><s xml:id="_cQtKP69">The device operates by capturing jawbone movements through a distance measure obtained with a proximity sensor and using this signal to distinguish eating versus non-eating activities.</s><s xml:id="_uq4J9Vm">Even though it is a neck-mounted device, the sensor does not need to be in direct contact with skin, allowing for a lightweight design and form-factor if compared to previous systems.</s><s xml:id="_9nEjAPS">The contributions of this work are:</s></p><p xml:id="_zrz6ntC"><s xml:id="_bZyGBtG">• The design and implementation of the wearable system alongside a computational approach for analyzing and classifying proximity sensor data as eating or non-eating.</s><s xml:id="_PYkGfTP">• An evaluation of the system with 32 participants comprised of three phases, a controlled laboratory study, a controlled-field study, and an in-the-wild study.</s><s xml:id="_xK4nfSs">Eating episodes were detected with 95.2% precision and 81.9% recall in the controlled studies and 78.2% precision and 72.5% recall in the free-living study.</s><s xml:id="_TbAZuyJ">• An annotated dataset of proximity sensor data collected in the user studies that we share with the community to encourage other researchers to expand upon our work.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" xml:id="_MeUbepT">THE NEED FOR OBJECTIVE DIETARY MONITORING</head><p xml:id="_7JujRfq"><s xml:id="_YBY5Xau">Due to the importance of diet in human life, health researchers have been interested in understanding the science of measuring dietary intake for decades <ref type="bibr" target="#b39">[40]</ref>.</s><s xml:id="_7k2e5x5">Bingham traced the first attempts to perform this measurement outside of a controlled setting to the 1930s and 1940s <ref type="bibr" target="#b8">[9]</ref>.</s><s xml:id="_m83Q4z7">Widdoson et al., for instance, presented an examination of English diets using the weighted food record in 1936 <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49]</ref>; the process involved recording the weight of each item of food and beverage consumed.</s><s xml:id="_ZbzWZfx">Soon thereafter, Wiehl, Turner and Reed pioneered interview-based dietary recall and food frequency methods, with the goal of estimating energy intake <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52]</ref>.</s><s xml:id="_jYyx9Hj">Dietary recalls, food records and food frequency questionnaires (FFQ) remain the primary dietary assessment mechanisms in use today, and are considered to be the gold-standard by nutritional epidemiologists.</s><s xml:id="_K3AFyvh">In dietary recall, an interviewer assists an individual in remembering what was eaten over a period of time, typically 24 hours.</s><s xml:id="_4rVRVVZ">Dietary records are different in that participants are asked to write down what is consumed shortly after the eating moment.</s><s xml:id="_tPVSjfm">Jacobs observed that in practice people often wait until the end of the day to record what they ate <ref type="bibr" target="#b22">[23]</ref>.</s><s xml:id="_MFWh878">In this case, the dietary record becomes a self-administered recall.</s><s xml:id="_6nDw3yp">With food frequency questionnaires (FFQ), which come in many flavors in terms of the number and specificity of questions, the objective is to obtain more general dietary knowledge and habits.</s><s xml:id="_WZWQXeQ">For instance, a question in a FFQ might be "How often do you eat pizza, and if so, how often and how many slices do you typically consume?".</s><s xml:id="_7nsabmu">More detailed questions might be asked, such as "When you drink milk, is it typically fat free, 1%, or whole-milk?" or "Do you prefer white or whole-wheat bread?".</s><s xml:id="_Un3KUyZ">Despite the use of these self-report methods, observations have shown that people tend to forget items that were eaten, underestimate large portion sizes, over-estimate small ones and, in general, are susceptible to a large variety of errors and biases <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b32">33]</ref>.</s><s xml:id="_rYkfCp7">Recently it has become possible to measure the accuracy of these gold-standard dietary assessment instruments thanks to the doubly-labeled water technique <ref type="bibr" target="#b28">[29]</ref>.</s><s xml:id="_WS2DegB">Findings confirmed their weaknesses.</s><s xml:id="_aCK4D63">In light of these limitations, researchers have begun to question the validity of nutritional data collected by self-report methods.</s></p><p xml:id="_pw58v2g"><s xml:id="_R89T8Gq">Archer et al. focused on the National Health and Nutrition Examination Survey (NHANES), stating that "methodological limitations compromise the validity of U.S. nutritional surveillance data and the empirical foundation for formulating dietary guidelines and public health policies" [4].</s><s xml:id="_4HbygC9">Dhurandhar et al. believe traditional instruments like dietary recalls and records should not be used at all for energy intake (EI) and physical activity energy expenditure (PAEE) assessment.</s><s xml:id="_WySdxnM">In their own words, "...it is time to move from the common view that self-reports of EI and PAEE are imperfect, but nevertheless deserving of use, to a view commensurate with the evidence that self-reports of EI and PAEE are so poor that they are wholly unacceptable for scientific research on EI and PAEE." [13].</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3" xml:id="_BFTNSCP">RELATED WORK</head><p xml:id="_xMCz5rZ"><s xml:id="_H56afMq">Dietary assessment challenges and limitations have fueled interest in automated processes starting in the 1980s.</s><s xml:id="_pNVGZfJ">At the time, researchers tried to detect chews and swallows using oral sensors in order to measure the palatability and satiating value of foods <ref type="bibr" target="#b41">[42]</ref>.</s><s xml:id="_wTB54kB">Today, most of the work in dietary assessment involves mobile and wearable devices and the utilization of various forms of sensing modalities such as acoustic, inertial, physiological, visual, capacitive, and piezoelectric sensing.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1" xml:id="_vqPQWdk">Acoustic Sensing</head><p xml:id="_9VzPpms"><s xml:id="_ewmFf2u">Wearable-based acoustic sensing has been widely explored in dietary monitoring.</s><s xml:id="_HB3rDxQ">Sazonov et al. proposed a system for monitoring swallowing and chewing that included a small microphone located over the laryngopharynx <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b38">39]</ref>.</s><s xml:id="_nS9mFpf">Similarly, Olubanjo and Ghovanloo tracked swallowing events from tracheal acoustics <ref type="bibr" target="#b33">[34]</ref>.</s><s xml:id="_rUAQbzH">Passler investigated the problem of intake monitoring using microphones in the outer ear canal <ref type="bibr" target="#b34">[35]</ref>.</s><s xml:id="_XdWCFEz">Bodyscope explored how accurately a large number of activities, including eating and drinking, could be recognized with a single acoustic sensor attached to the user's neck <ref type="bibr" target="#b52">[53]</ref>.</s><s xml:id="_7SvEhVv">In 2012, Liu et al. developed a food logging application based on the capture of audio and first-person point-of-view images <ref type="bibr" target="#b29">[30]</ref>.</s><s xml:id="_NNqU5e7">The system processed incoming sounds through a head-mounted microphone and a classifier identified when chewing was taking place, prompting a wearable camera to capture a video of the eating activity.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2" xml:id="_73T7mtd">Inertial Sensing</head><p xml:id="_7CFht2m"><s xml:id="_Nvjjvtn">The widespread availability of small wearable accelerometers and gyroscopes has opened up a new avenue for detecting eating activities through on-body inertial sensing.</s><s xml:id="_R4BvNBr">Almost a decade ago, Amft et al. detected eating gestures with a measurement system comprised of five inertial sensors placed on the body (wrists, upper arms and on the upper torso) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b24">25]</ref>.</s><s xml:id="_ZTStGwg">In 2013, Dong at al. put forth a method for detecting intake gestures in real-world settings based on a wrist-motion energy heuristic <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>.</s><s xml:id="_uAeaFqq">The authors evaluated the approach by having participants wear a smartphone on the wrist collecting continuous inertial sensor data.</s><s xml:id="_6YWvjqk">As a follow up to Fig. <ref type="figure">1</ref>.</s><s xml:id="_acgwFFk">Several instrumented neckbands aimed at chewing and swallowing detection have been developed over the years but their size, form factor, and aesthetic have limited their mainstream adoption.</s><s xml:id="_raQGm2u"><ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b25">26]</ref> this work, Thomaz evaluated an approach for inferring eating moments based on 3-axis accelerometry collected with a popular smartwatch, the Pebble watch <ref type="bibr" target="#b43">[44]</ref>.</s><s xml:id="_6cknH5R">Trained with data collected in a semi-controlled laboratory setting with 20 subjects, the system recognized eating moments in two free-living condition studies with F1 scores of 76.1% and 71.3%.</s><s xml:id="_AzV52wR">These results were highly encouraging since one of the field experiments was conducted over 30 days, longer than previous ecologically-valid automated dietary monitoring studies.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3" xml:id="_S9hksVh">Physiological Sensing</head><p xml:id="_qU38eKX"><s xml:id="_eYetPqX">Electroglottography (EGG) and electromyography (EMG) have been used to detect chewing and swallowing activities.</s><s xml:id="_nsvaWnv">EGG uses two electrodes placed on the neck to measure the impedance changes induced by the movements of larynx during eating <ref type="bibr" target="#b5">[6]</ref>.</s><s xml:id="_DAfVSXN">Farooq et al. evaluated the approach of using EGG on 25 participants (12 male and 13 female) and compared the performance with that of acoustic sensing <ref type="bibr" target="#b16">[17]</ref>.</s><s xml:id="_eCBwG6U">The EGG approach resulted in better performance than acoustic sensing approach on both male and female participants.</s><s xml:id="_xPAFCbS">While EMG also uses two electrodes like EGG, the measurement made for EMG is the activation of mandibular muscles as opposed to the impedance change in EGG.</s><s xml:id="_YWQ3NEv">Since EMG focuses on detecting action potentials associated with the contraction of mandibular muscles, EMG is more often used for characterizing chewing behavior while EGG is more focused on characterizing swallowing behavior.</s><s xml:id="_9ffYDrJ">While both EMG and EGG can accurately monitor eating activities, both EMG and EGG necessitate that the sensors be attached to the skin.</s><s xml:id="_ANthCrq">In addition, the attachment of electrodes often leads to larger form factors.</s><s xml:id="_e9T93h8">As all the previous studies involving EGG and EMG took place in laboratory settings, and the wearability and the practical application of physiological sensing in the real world need to be further investigated.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4" xml:id="_dX6nDjA">Camera Based Dietary Monitoring</head><p xml:id="_NvHRS7s"><s xml:id="_mnHtUch">Camera-based approach provides an effective means of monitoring eating activities using images captured in intervals.</s><s xml:id="_NZqD9jb">Unlike other methods which leverage swallowing or chewing as proxy for eating detection, camerabased approach relies on the visual information from photos or videos that are captured either continuously or at a regular interval <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b42">43]</ref>.</s><s xml:id="_mMfC878">The camera-based approach has been successfully employed in many applications, and proven to be useful for recording the ground truth <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7]</ref>.</s><s xml:id="_jrSKJ4X">In addition, with image processing, the method has demonstrated that the amount of food consumption can be accurately estimated <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b23">24]</ref>.</s><s xml:id="_CfDnaYK">Despite its strength, the camera-based approach presents a privacy concern as the camera would capture other people's images as well as their daily activities <ref type="bibr" target="#b42">[43]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5" xml:id="_sfjXjgZ">Capacitive Sensing</head><p xml:id="_VgzK8zs"><s xml:id="_mMsnZUW">In 2010, Cheng et al. proposed a new sensing approach that leverages capacitance change induced by contraction of muscles or movements of body.</s><s xml:id="_Kne7mXY"><ref type="bibr" target="#b10">[11]</ref>.</s><s xml:id="_T2rKgJB">Cheng et al. demonstrated that the conductive textile can be incorporated in a neckband for eating detection.</s><s xml:id="_fF2w8dF"><ref type="bibr" target="#b11">[12]</ref> The application of capacitive sensor in neckband resulted in 84.4% accuracy.</s><s xml:id="_yYfGN2E">While Cheng et al. proposed that neckband can be useful for elderly care or cognitive disease monitoring, the neckband presents a significant challenge for mainstream adoption for dietary monitoring in real world situations due to its large form factor. (Shown in the fourth image on Figure <ref type="figure">1</ref>).</s><s xml:id="_7QbCkyR"><ref type="bibr" target="#b11">[12]</ref> 3.6 Piezoelectric Sensing</s></p><p xml:id="_QrQkZ5D"><s xml:id="_6hX334P">Piezoelectric sensors generate electric signal in response to mechanical changes.</s><s xml:id="_CmgtepU"><ref type="bibr" target="#b37">[38]</ref> This principle has been leveraged in multiple applications of dietary monitoring, specifically for chewing detection and swallowing detection.</s><s xml:id="_dGQPEDg"><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b25">26]</ref> In 2016 Farooq and Sazonov demonstrated that eyeglasses that leverages piezoelectric sensor and an accelerometer for dietary monitoring resulted in the F1 score of 99.85% <ref type="bibr" target="#b18">[19]</ref> for sedantary eatig, and 94.16% for eating while walking.</s><s xml:id="_jbqXSdt"><ref type="bibr" target="#b18">[19]</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7" xml:id="_fx7ruSy">Multimodal Sensing</head><p xml:id="_pJ34pVr"><s xml:id="_Qe4Jrty">In the last two years, the utilization of multiple sensing modalities to infer eating activity has gained momentum.</s><s xml:id="_YM3X3jE">Recently, Rahman et al. and Merck et al. have merged multiple sensing modalities in eating recognition and prediction with promising results.</s><s xml:id="_VRw4Ed6">Rahman et al. built a wearable sensing framework consisting of an array of sensors that captured physical activity, location, heart rate, electrodermal activity, skin temperature and caloric expenditure [37].</s><s xml:id="_tvMSZaG">Merck et al. combined head and wrist motion (Google Glass, smartwatches on each wrist), with audio (custom earbud microphone) totaling 72 hours of data from 6 participants [32].</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8" xml:id="_5af5uJr">Challenges and Opportunities</head><p xml:id="_UjanasH"><s xml:id="_BF3Y2Gd">As these examples of prior work make evident, acoustic and inertial sensing have been extensively used in dietary monitoring with promising results.</s><s xml:id="_CSp8pDa">However, adoption of these approaches has been hampered by shortcomings.</s></p><p xml:id="_wK4QtXU"><s xml:id="_Udfn8Sr">A major reason why inertial sensing is appealing is that accelerometers and gyroscopes have been widely incorporated into commodity devices such as smartwatches and activity tracking bands, making it easy to collect data without specialized and custom-built systems.</s><s xml:id="_3Y6Xw4S">Unfortunately, the rate of food intake gesture misclassification (i.e., false positives) from inertial measurements has remained high in naturalistic settings despite many years of research in the field.</s></p><p xml:id="_jf2w7XN"><s xml:id="_n4kyzFQ">A similar functional tradeoff also affects acoustic sensing.</s><s xml:id="_ustVXTQ">Although audio is a very rich signal reflecting dietary markers such as chewing and swallowing, audio processing is computationally intensive.</s><s xml:id="_z7j4kkg">This is a particular problem for wearable devices powered by small batteries and even more so when real-time activity classification is required.</s><s xml:id="_TwQprgf">Another issue of audio sensing, which also applies to inertial and muscle activity sensing, is that the sensors must be in direct contact with the body so that the acoustic signatures of eating can be properly captured.</s><s xml:id="_WNraXaG">Due to this requirement, researchers have developed instrumented neckbands to keep sensors compressed against the skin <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26]</ref>; some of these neckbands are shown in Figure <ref type="figure">1</ref>.</s><s xml:id="_39DE9yR">While effective for data capture, neckbands are largely impractical for everyday use; its design form factor and aesthetic are considered unappealing, limiting mainstream adoption of these devices.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" xml:id="_chgCYbq">APPROACH: MASTICATION AS EATING PROXY</head><p xml:id="_D59HpuA"><s xml:id="_wj463Wq">A distinctive behavioral marker of eating is mastication, the process by which food is cut and crushed by teeth so that it can be more easily broken down by enzymes.</s><s xml:id="_usTHYKN">During mastication, the jaw moves up and down by four muscles in the mouth (i.e., masseter, temporalis, medial and lateral pterygoids) in a mostly deterministic pattern that varies depending on what is being consumed (i.e., food type).</s><s xml:id="_MWtfAmd">The hypothesis behind the proposed work is that it is possible to infer the presence of dietary activity by continuously measuring the distance between the jaw and the base of the neck, as shown in Figure <ref type="figure" target="#fig_2">4</ref>.</s><s xml:id="_ys5ZyGj">In principle, this distance signal should be indicative of whether an individual is eating, be predictive of what is being eaten, and capable of discriminating dietary behaviors from other activities such as talking.</s><s xml:id="_kP5YMxs">In contrast to previous efforts that measured markers of mastication with devices in contact with the skin (e.g., acoustic, inertial, electromyography), the jawbone-neckbase distance can be captured with a small, inexpensive and non-contact proximity sensor mounted either on a specialized necklace or adapted to be outfitted into existing clothing or jewelry.</s></p><p xml:id="_Jd8rYy9"><s xml:id="_GPfNkwv">In order to use mastication as a proxy for detecting eating episodes, we take a bottom-up hierarchical approach.</s><s xml:id="_mGzAwsm">The first step involves detecting chewing.</s><s xml:id="_rmU2DUq">Once chewing has been identified, we group periods of semi-continuous chewing as a chewing bout.</s><s xml:id="_mPXaH3y">Finally, multiple chewing bouts comprise an eating episode.</s><s xml:id="_4KfdxHB">We utilize the following operational definitions for these terms:</s></p><p xml:id="_fvPGfNv"><s xml:id="_whbQ76R">• Chewing: We define chewing as an non-interrupted sequence of chews lasting 5 seconds or longer.</s><s xml:id="_pFQbgKK">It is considered the smallest detectable unit in the context of this study.</s><s xml:id="_4t2bGcN">The rationale for choosing 5 seconds as the minimum duration of chewing stems from the desire to reduce the rate of false positives.</s><s xml:id="_Vh5kmjq">In preliminary experiments, we found that a temporal window shorter than 5 seconds resulted in yawning or nodding being incorrectly detected as chewing, for instance.</s><s xml:id="_gjdJKdX">On the other hand, if longer windows are used, the system might miss actual chews.</s><s xml:id="_q9e28H9">A 5-second chewing window proved to be a good compromise between these edge cases.</s><s xml:id="_muGgsKc">• Chewing Bout: While chewing is a marker and proxy for eating, individuals do not typically chew continuously throughout an entire meal.</s><s xml:id="_eA7ASxV">Small breaks are common while reaching out for food, during intake gestures, or even if just for breathing.</s><s xml:id="_Denb8EY">These pauses represent gaps in-between chewing, and as they do not mark the beginning or end of eating episodes, they should be ignored.</s><s xml:id="_JrSyErj">To abstract these pauses away, we introduce the notion of chewing bout, a group of consecutive chewing periods that are within 30 seconds of each other.</s><s xml:id="_yqzdw5t">In effect, a chewing bout can be conceptualized as an entity that chains chewing periods together as a single-unit.</s><s xml:id="_HNDzwBu">• Eating Episode: Recognizing chewing bouts is critical but not sufficient to identify eating episodes.</s><s xml:id="_63Hfkn8">This is because an eating episode such as breakfast, lunch, dinner is often characterized by chewing bouts interspersed with other activities and interruptions, such as chatting with friends, assisting children with their meals, and going to the restroom.</s><s xml:id="_CaE2MBQ">When eating alone, it is also common to take pauses during eating, especially when multi-tasking, e.g., eating while browsing the web on a mobile device, reading a magazine, or watching TV.</s><s xml:id="_RxrnYJG">Having the flexibility to consider longer breaks as part of eating episodes is important because it accounts for naturalistic behaviors and enhances the practicality of the approach.</s><s xml:id="_8cU6XMJ">Within our inferential framework, we define an eating episode as a sequence of one of more chewing bouts that are no more than 5 minutes apart from each other.</s><s xml:id="_bqU68CZ">More than 5 minutes without chewing and there is a good chance that the eating episode has ended.</s><s xml:id="_72D2med">While we experimented with different durations, we found that 5 minutes led to a good balance in terms of performance.</s><s xml:id="_Bkg7cqZ">We also feel that this parameter can be fine-tuned depending on individual characteristics.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" xml:id="_7yupEG2">SYSTEM DESIGN</head><p xml:id="_6tq5aC5"><s xml:id="_9sBJze3">To realize our approach, we designed and implemented a wearable necklace system consisting of a proximity sensor, a 3D printed sensor mount, a microcontroller, and a bluetooth module.</s><s xml:id="_dbJA75P">The components are compactly packaged as shown in Figure <ref type="figure" target="#fig_1">3</ref>.</s><s xml:id="_Vxxfz36">The system was powered by a 400 mAh LiPo battery, and we were able to reliably use the device for more than 18 hours.</s><s xml:id="_B2DpD33">For data collection, annotation and visualization, an Android phone was also used.</s><s xml:id="_Z9MCJv3">In the first and the second talk sessions, there are some false positives detected at chewing level.</s><s xml:id="_mqUfVhH">However, they fail to be grouped at chewing bout level.</s><s xml:id="_TZYR9FP">During the restroom visit, there was one false positive eating episode.</s><s xml:id="_TQacgyU">However, it is discarded in our algorithm since the duration of detected eating episode (red diagonal block) is too short to be considered an eating episode.</s><s xml:id="_Cuydaxx">5.1 Hardware 5.1.1</s><s xml:id="_DJ3qVyS">Proximity Sensor.</s></p><p xml:id="_ZuTYNea"><s xml:id="_U4Gfh9q">The keystone of the proposed wearable platform is the VL6180X sensor by STMicroelectronics.</s><s xml:id="_XFb2zfv">It is a proximity sensor that measures absolute distance between itself and a target.</s><s xml:id="_GHEaFR7">The distance is calculated by measuring the time emitted light takes to travel to the nearest object and reflect back to the sensor (i.e., time-of-flight).</s><s xml:id="_fmEkkas">In the system, the sensor sits on a board attached to a necklace and the measurement corresponds to the distance between the sensor and the wearer's jawbone.</s><s xml:id="_FMEXhuv">As the jawbone moves up and down due to mastication, these rhythmic patterns are captured as a distance measure (see Figure <ref type="figure" target="#fig_2">4</ref>).</s><s xml:id="_Tk8ZF2j">In principle, eating patterns should have a distinctive pattern signature if compared to non-eating patterns.</s><s xml:id="_3UWDNNB">The proximity sensor draws 1.7 on average, making this component suitable for low-power applications.</s><s xml:id="_pQ6aabv">The maximum distance the sensor can measure is 25.</s><s xml:id="_ye4zpjp">The distance between the sensor and the jaw was maintained below 20 across the entire study.</s><s xml:id="_7YdxS7G">The sensor was placed at the center of the necklace such that it was possible to measure the vertical movement of the jaw.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2" xml:id="_5e3WmV3">3D</head><p xml:id="_FkxSn6Z"><s xml:id="_G45qqDG">Printed Sensor Mount.</s><s xml:id="_U4zYSBX">The sensor mount was designed to provide a consistent positioning of the sensor.</s><s xml:id="_wpsDX2u">To account for the variations of neck shapes and posture, three sensor mount with different angles (0, 30, and 45) were designed (see Figure <ref type="figure" target="#fig_1">3</ref>).</s><s xml:id="_Bve3f3f">The mount contains two larger holes through which a rubber band can pass and two smaller holes for fixing the sensor.</s><s xml:id="_Vk299Br">The sensor mount is used to hold a proximity sensor in place as well as to connect it to the rubber band that goes around the neck.</s><s xml:id="_CFqWqTY">On one side of the rubber band goes the wires that carry signal collected from the sensor to the micro-controller.</s><s xml:id="_ByhT98a">The necklace is shown in the right-most image of the Figure <ref type="figure" target="#fig_1">3</ref>.</s><s xml:id="_UbdhYVY">The eating signal features the participant chewing celery given as an appetizer.</s><s xml:id="_k2drQRt">The sitting signal was captured while the participant was watching a movie clip.</s><s xml:id="_EeuYb9Y">For note-taking task, the participant copied a short paragraph written on the board.</s><s xml:id="_JYWMZwf">During the note-taking, the participants had to look up on the board periodically, and this is reflected in the periodic rise in amplitude in the second plot from the bottom.</s><s xml:id="_cH7MVtC">In the eating signal, visually distinctive periodic changes in amplitude are observed whereas for the other non-eating activities, no such characteristic is noticeable.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3" xml:id="_458h4g5">Bluetooth LE Module.</head><p xml:id="_tNPD9XQ"><s xml:id="_bnDVUc6">In wearable computing, size, weight and heat are critical design factors.</s><s xml:id="_DJrWUv8">To minimize the hardware footprint of the device, only the minimum components necessary for data collection were instrumented in the necklace itself.</s><s xml:id="_FH6fXuw">The sensor data was collected and transmitted to a smartphone in real-time using the Bluetooth LE (i.e., Low Energy) communication protocol.</s><s xml:id="_gmRWjZf">This module relies on the nRF51822 system-on-a-chip (SoC) by Nordic Semiconductor.</s><s xml:id="_eXFtk4m">It is built around the 32-bit ARM Cortex M0 CPU and supports the Bluetooth LE protocol stacks.</s><s xml:id="_n7yFMY6">Unlike other Bluetooth modules which consume approximately 50 during data transmission, BLE consumes approximately 8.5.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_3KQzXtc">5.1.4</head><p xml:id="_NKc5mFa"><s xml:id="_pXwhbEs">Microcontroller.</s><s xml:id="_BGJWwMu">The Arduino Pro Mini was chosen to control the proximity sensor and the Bluetooth module.</s><s xml:id="_2TMn7vZ">To reduce the amount of energy consumed by the microcontroller, the 3.3V/8MHz version was used.</s><s xml:id="_BVCYtv6">With its default settings, the Arduino alone consumes approximately 13 when in regular operation.</s><s xml:id="_DytV3wU">To reduce battery consumption (we used a 400h battery), the Arduino was programmed to remain in sleep-mode for 15 prior to sampling data.</s><s xml:id="_Qb5NAKU">Through this modification, we were able to reduce the microcontroller's current draw down to approximately 200.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2" xml:id="_3Sc6Pya">Software</head><p xml:id="_r2yYbfY"><s xml:id="_tSmsey5">5.2.1 Android Application.</s><s xml:id="_C2HTGV6">One of the components of the wearable system is an Android smartphone running an application with Bluetooth LE support.</s><s xml:id="_SQvENKZ">This application serves three important roles.</s><s xml:id="_mgWuFmd">Firstly, it receives and stores the sensor data collected by the wearable necklace.</s><s xml:id="_8eer2ES">Secondly, its interface is designed to assist with the annotation of the sensor data.</s><s xml:id="_eap2aRQ">And thirdly, the application leverages the smartphone's accelerometer and a simple heuristic to determine whether the individual carrying the phone is walking.</s><s xml:id="_vgBz68N">This measure is used to help discriminate walking from eating.</s><s xml:id="_nnMNNWx">The Android application receives the acceleration with respect to x, y, and z axis in real time.</s><s xml:id="_cagADcx">The magnitude of the acceleration vector is calculated using the euclidean norm, and if the magnitude is greater than 1 m/s 2 , it is assumed that the individual is in motion.</s><s xml:id="_XWMu3dq">In that case, the distance measure obtained with the proximity sensor is discarded (i.e., no eating is taking place).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3" xml:id="_hmKs6my">Data Analysis and Modeling</head><p xml:id="_bd76SfA"><s xml:id="_XXCdvWk">At the heart of the method is a proposed four-phase pipeline for analyzing the data collected by the VL6180X sensor.</s><s xml:id="_9mY22Gy">To reiterate, the goal of the wearable device is to identify episodes of eating from a distance signal measured between the jawbone and the base of the neck.</s><s xml:id="_j6RvMnm">In the first phase of the pipeline, the signal is pre-processed and conditioned.</s><s xml:id="_trgXHNr">In the second and third phases, chewing and chewing bouts are identified.</s><s xml:id="_QpVTSSd">Lastly, in the fourth phase, eating episodes are inferred from chewing bouts using a clustering algorithm.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_fYRfd4g">5.</head><p xml:id="_Vpqd88n"><s xml:id="_5heeJCP">3.1 Preprocessing.</s><s xml:id="_ysU3fHg">: The VL6180X sensor produces a time series signal with distance measures at a rate of 20Hz.</s><s xml:id="_YutMWaD">The signal is first pre-processed using a median filter for smoothing.</s><s xml:id="_MEXenx2">Next, frames are extracted using a 5-second, point-by-point sliding window across the time series (See Figure <ref type="figure" target="#fig_3">5</ref>).</s><s xml:id="_uXQSaHQ">The window size was determined empirically with the goal of optimizing the balance between inference resolution and rate of false positives.</s></p><p xml:id="_3BvTwD2"><s xml:id="_fUUm7yk">In preliminary experiments, we found that a temporal window shorter than 5 seconds resulted in yawning or nodding being incorrectly detected as chewing, for instance.</s><s xml:id="_N8qpcqe">On the other hand, if longer windows were used, the system could miss actual chews.</s><s xml:id="_m9WPwRK">A 5-second chewing window proved to be a good compromise between these edge cases.</s><s xml:id="_bNjyeY3">Each extracted frame was baseline shifted to eliminate patterns and trends that are not intrinsic to the data.</s><s xml:id="_NDBtubQ">The baseline shift was achieved by subtracting the root-mean-square (RMS) of each frame.</s><s xml:id="_aZSeNsQ">Next, each frame was bandpass-filtered to remove artifacts that do not represent dietary activity.</s><s xml:id="_yRXyhuC">The majority of chewing happens in frequencies between 0.94 Hz and 2.17 Hz <ref type="bibr" target="#b35">[36]</ref>; therefore a pass band around this frequency range was used (See Figure <ref type="figure" target="#fig_3">5</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2" xml:id="_qn6PBHP">Chewing Detection.</head><p xml:id="_YnfQHBD"><s xml:id="_UgMHk8c">: Chewing is a distinctive mechanical movement that distinguishes eating from other activities such as talking, yawning, singing or drinking.</s><s xml:id="_8CJEwdg">When captured with a sensor such as the one we propose, this distinction becomes clear in terms of the regularity, frequency and amplitude of the signal.</s><s xml:id="_pHMk5ne">In the chewing detection step, non-eating signals are filtered out using a method called level-crossing.</s><s xml:id="_pRYF6tv">With this technique, we define an amplitude and count the number of crossing over the threshold, as shown in figure <ref type="figure" target="#fig_3">5</ref>.</s><s xml:id="_HdbvVTj">If the number of amplitude thresholds crossings are aligned with the chewing frequency reported by Po et al., the frame is labeled as chewing <ref type="bibr" target="#b35">[36]</ref>.</s><s xml:id="_T53qvcj">Otherwise, it is labeled as non-chewing.</s><s xml:id="_asqTbyD">Based on our analysis, we found that the best results are obtained with amplitude thresholds between 1 and 2, as shown in figure <ref type="figure" target="#fig_5">8</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3" xml:id="_QxhE8et">Chewing Bouts. :</head><p xml:id="_yBzmTNB"><s xml:id="_s8hpgZe">To eliminate small pauses in-between chewing, we group chewing periods over time into clusters using the DBSCAN clustering algorithm <ref type="bibr" target="#b15">[16]</ref>, and call these clusters chewing bouts.</s><s xml:id="_98ksbHb">In prior work, DBSCAN has been identified as appropriate for this task since it does not require the specification of a pre-defined number of clusters prior to analysis; this is not possible with other clustering techniques such as K-Means).</s><s xml:id="_7D3hvBX">Furthermore, this algorithm allows for the parametrization of important settings such as the minimum number of chewing periods per cluster <ref type="bibr" target="#b45">[46]</ref>.</s><s xml:id="_7q7U3Nn">Parametrization also makes DBSCAN amenable to fine-tuning for detecting snacking behavior, when shorter chewing windows might be needed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4" xml:id="_UnT6HjY">Eating Episode Detection. :</head><p xml:id="_5rzCymS"><s xml:id="_K3Z2knh">To identify eating episodes, the beginning and end of each chewing bout are obtained.</s><s xml:id="_7t2wREv">Then, the duration between each consecutive pair of chewing bouts is calculated.</s><s xml:id="_qZFM2P7">If this duration does not exceed a certain amount (we experimented with duration values between 1 and 10 minutes), the chewing bouts are combined to represent an eating episode.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5" xml:id="_JE3Za9y">Evaluation Metric. :</head><p xml:id="_N5X4JGz"><s xml:id="_nKJR6xs">To evaluate the eating episode detector, we perform a comparison between the output of the detector and our acquired ground truth on a segment-by-segment basis, where a segment corresponds to a specified time period (e.g., 5 minutes).</s><s xml:id="_bs9pyyp">We assign true positives, true negatives, false positives and false negatives accordingly.</s><s xml:id="_HqXXdqa">Given a particular segment, it is common for a partial match between inference and ground truth; for example, the detector might output that an eating episode took place for only half of a 5-minute segment (i.e., for 50% of the segment), whereas study participants ate during the entire 5-minute period.</s><s xml:id="_WjBeJCR">To avoid missing eating episodes (but at a risk of more false positives), we marked segments as "eating" under these partial match cases and tested for different amounts of overlap (i.e., 10%, 20% and 30%).</s><s xml:id="_bE7rfS5">We found that the system performs best with overlaps between 10% and 20%.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6" xml:id="_nqw3faj">EXPERIMENTS</head><p xml:id="_XKyFH4B"><s xml:id="_BJ8wzAG">Our system and approach were evaluated in three experiments.</s><s xml:id="_a7Eg4sf">The first experiment was run in controlled laboratory settings; the second experiment was conducted in controlled field settings, a hybrid experimental format that combines the benefits of a free living study with the controlled characteristics of a lab study.</s><s xml:id="_cDJZhbJ">Finally, the third experiment was an in-the-wild study in completely naturalistic settings.</s><s xml:id="_8S6ss8q">For each study, precision and recall measures were calculated at the eating episode level to assess the performance of the system.</s></p><p xml:id="_MDEAaWJ"><s xml:id="_t29TvKG">The food types offered in the studies were chosen to reflect the diverse selection of foods available in the real world (see Figure <ref type="figure" target="#fig_4">7</ref>).</s><s xml:id="_hVfZvtZ">In particular, food groups were picked to include foods with crunchy textures (e.g.</s><s xml:id="_t6XDvEb">nuts, tacos), soft textures (e.g.</s><s xml:id="_Mtak3cZ">ice cream, yogurt), and wet crisp textures (e.g.</s><s xml:id="_zd2PWGb">celery, fruits).</s><s xml:id="_g2Mmsba">A wide array of food types allowed us to examine the performance of the system under different conditions (e.g., soft vs. crunchy foods) and eating styles (e.g., eating with utensils vs. grabbing and holding food with hands).</s></p><p xml:id="_8yUrRx3"><s xml:id="_mVYyShD">At the start of each study, it was made sure that the sensor was pointing at the jaw of the participant.</s><s xml:id="_4ZkzbFh">In laboratory study, the sensor position was adjusted based on visual examination by the lab staff.</s><s xml:id="_sbZU6MF">In controlled field study and wild study, the distance measure was visualized on Android phone in real-time.</s><s xml:id="_kHTXEfA">Thus, participants were asked to move their jaws for a few seconds as if they would when chewing food, and if the signal captured the vertical movement of the jaw, the study began.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1" xml:id="_p8btp9B">Laboratory Study</head><p xml:id="_YrAHxjf"><s xml:id="_QY2VyDF">The goal of the lab study was to validate the feasibility of the proposed approach by obtaining examples of dietary and non-dietary behaviors in a controlled setting where participants could be closely monitored.</s><s xml:id="_aeGAJag">Twenty participants were asked to come to our laboratory and were offered lunch.</s><s xml:id="_asUvcBJ">After check-in, the study staff helped participants put on the necklace device, and adjust the sensor such that it was pointing in the direction of the participant's jawbone and chin.</s><s xml:id="_r4WXJHv">Over the course of each session, which lasted for approximately 40 minutes on average, participants were offered a variety of foods with different characteristics, such as celery, nuts, soup, lasagna, fried rice, burrito, yogurt and chocolate stick.</s><s xml:id="_Nrdb29x">Each participant was provided with a three-course meal that consisted of an appetizer, a main dish and a dessert (see Figure <ref type="figure" target="#fig_4">7</ref>).</s><s xml:id="_wSsmZaF">For each food served, participants were provided with proper utensils (e.g.</s><s xml:id="_HsfmdZb">fork and knife for lasagna, spoon for soup and fried rice).</s><s xml:id="_dse7MKA">While they were encouraged to use the provided utensils, they were not required to use them.</s><s xml:id="_yjnhhdH">A common challenge with current eating detection systems is their high rate of false positives.</s><s xml:id="_xcBfNbn">Therefore, participants were also asked to perform common, non-dietary everyday tasks, such as walking, note-taking, talking and brushing teeth.</s><s xml:id="_VsyjJDq">Eating and non-eating activities were inter-weaved (see Table <ref type="table" target="#tab_3">2</ref>).</s><s xml:id="_tHmfTBB">To obtain ground truth labels, participants were observed by study staff and captured by video cameras throughout the study.</s><s xml:id="_DuamR2W">The study sessions were then annotated for chewing, eating episodes, and non-eating activities.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2" xml:id="_VeTFfCe">Controlled Field Study</head><p xml:id="_XTyDkj2"><s xml:id="_JRQnaMj">While useful, controlled laboratory studies rarely replicate truly naturalistic experiences and settings.</s><s xml:id="_cCdz6h5">Consequently, results obtained in the lab often lack external validity, and thus do not generalize well to real-world conditions.</s><s xml:id="_fgCnzR6">On the other hand, free living studies place participants in their natural everyday environments, but collecting data, and ground truth data in particular, is a significant hurdle.</s><s xml:id="_kmHCPSF">Other than experience sampling techniques using paper diaries or mobile phones, an increasingly popular method for recording ground truth in-the-wild include collecting photos or videos using wearable cameras.</s><s xml:id="_NY2asTg">However, annotating thousands of photos and hours of videos is a time-consuming and burdensome process.</s><s xml:id="_PB6K5Rt">Moreover, continuously capturing media in real-world settings results in a wide range of privacy challenges that cannot be easily overcome.</s></p><p xml:id="_4SmBb9j"><s xml:id="_eb8Gcn5">As an attempt to benefit from the advantages of both laboratory and in-the-wild studies while sidestepping their shortcomings, we explored a hybrid study design that we call controlled field study.</s><s xml:id="_FAhr2ve">In our controlled field study, participants met the experimenter in a public place or commercial establishment instead of in the laboratory.</s><s xml:id="_d6Wgecj">All the experimental tasks took place in real-world environments such as cafes, ice-cream shops and restaurants.</s><s xml:id="_z5yXTrC">The experimenter followed and monitored each and every participant throughout the study, and participants were allowed to interact with the experimenter as if he or she were a friend.</s><s xml:id="_AecVySB">The advantage of this approach is that all activities take place in the wild, and since the experimenter is together with the participants, ground truth can be reliably recorded.</s></p><p xml:id="_tUytmjM"><s xml:id="_32pAnv7">Fifteen participants were recruited in our controlled field study, which began at a university library.</s><s xml:id="_eCw8Zs8">After putting on and having the necklace device adjusted for comfort and fit, participants were asked to perform an initial baseline of activities that included drawing on a tablet device and performing a simple web search on a computer.</s><s xml:id="_DtfQ4N7">Immediately afterwards, they were offered a small snack of either nuts or fruits and were asked where they wanted to go for lunch.</s><s xml:id="_a8Dg9ZS">Lunch options were determined by the availability of restaurants around our university campus and included Chipotle, Panda Express, Shake Shack, Wendy's, Chick-Fil-A and Taco Bell.</s><s xml:id="_RNAV7uw">After lunch at one of these establishments, participants were offered to walk to an ice-cream or frozen yogurt Fig. <ref type="figure">6</ref>.</s><s xml:id="_cQbCrZK">The average duration of lab study was 37.8 minutes, and 20 minutes (52.9% of total duration) were spent on eating.</s><s xml:id="_nHBJbs8">For the lab study, the average time spent on appetizer, main dish, and dessert were 4.6 minutes (12.2%), 9.4 minutes (24.9%), and 6 minutes (15.9%), respectively.</s><s xml:id="_9P9WdYd">In controlled field study, the duration information for P5 was failed to be saved, and for P4 the duration information for walk-2 and dessert was missing.</s><s xml:id="_ajeydk7">P3 refused to get dessert.</s><s xml:id="_NCvhEFP">For the controlled field study, the average duration of total activities was 59.5 minutes, and 26.4 minutes (44.5% of total duration) were spent on eating.</s><s xml:id="_AGNKSTw">The average time spent on appetizer, main dish, and dessert were 3.4 minutes (5.8%), 15.1 minutes (25.4%), and 7.9 minutes (13.3%), respectively.</s></p><p xml:id="_PyUj2Nk"><s xml:id="_VcwMdMS">place and have dessert.</s><s xml:id="_3ehSuTE">Throughout the study, the experimenter accompanied participants and made annotations of all activities in real-time.</s></p><p xml:id="_TKzrCBX"><s xml:id="_Bjc6KQW">The controlled field study was a pseudo-wild study in the sense that every activity took place in the wild.</s><s xml:id="_PpYEFyx">However, due to the natural context provided in the controlled field study, some participants (e.g.</s><s xml:id="_9uuyZpH">P7) initiated and engaged in a long conversation with the researcher after having only a few bites of food (see Figure <ref type="figure">6</ref>).</s><s xml:id="_X8r839x">Whenever participants attempted to get involved in a long conversation longer than 5 minutes without eating, they were reminded of the study and asked to focus on eating.</s><s xml:id="_xGD4JWj">The number of servings is shown in the y-axis of the bar chart.</s><s xml:id="_Y5Rr52p">The served food is written in each segment of bar along with the number of servings for each food.</s><s xml:id="_ZSzxnVC">The bar height for dessert from controlled field study is shorter since two participants (P3 and P4) refused to have desserts.</s><s xml:id="_2rXyb2M">In controlled field study, the menus for appetizer and main dish were prepared such that eating would require significant amount of chewing while the menus for desserts were prepared with those that require minimal chewing.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3" xml:id="_q3YpexW">In-the-Wild Study</head><p xml:id="_VAGUp8A"><s xml:id="_Qru88pP">To evaluate our system and approach in real-world settings, we conducted a 1-day in-the-wild study with 19 participants.</s><s xml:id="_qqUdrbA">While wearing the eating detection device, which was given to them in the morning, participants were free to perform their normal everyday activities for the rest of the day.</s><s xml:id="_8yvuzbR">Each participant was given an Android phone and asked to annotate the beginning and end of any eating activities.</s><s xml:id="_MQWcRzb">Additionally, they were instructed to make a note of what they ate.</s><s xml:id="_Ttaa6er">Two participants (P1 and P11) reported that they failed to eat a meal during the study and thus their data was excluded from the analysis.</s><s xml:id="_vzwrc4f">The remaining seventeen participants reported that they had at least one meal.</s><s xml:id="_QPruxzK">The average duration of the in-wild study was 4 hours and 38 minutes per participant; the shortest duration was 2 hours and the longest was 8 hours and 48 minutes.</s><s xml:id="_MgAj6Pj">The types of food consumed in this study can be seen in Table <ref type="table" target="#tab_4">3</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7" xml:id="_TGSsSWd">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1" xml:id="_hbfMUAT">Laboratory Study Results</head><p xml:id="_mfjj5Zx"><s xml:id="_eYA26fy">Of the twenty participants recruited in the lab study, three participants were excluded from the analysis due to sensor misalignment.</s><s xml:id="_WecSMyV">A 10-minute evaluation segment with 10% overlap and an amplitude threshold of 1.0 resulted in precision of 91.2% and recall of 92.6%.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2" xml:id="_VXcDnWx">Controlled Field Study Results</head><p xml:id="_PBAvzaM"><s xml:id="_Nn2vuRa">For the controlled field study, fifteen participants were recruited.</s><s xml:id="_tvCh4qf">The best result was obtained with precision of 95.2% and recall of 81.9% when the evaluation segment was 10 minutes long with overlap set to 10% and amplitude threshold set to 1.5.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3" xml:id="_SWbSRQ5">In-the-Wild Study Results</head><p xml:id="_rycrB6G"><s xml:id="_RVfc9Db">The fifteen participants from the controlled field study participated in the in-the-wild study.</s><s xml:id="_XD6VEPH">In this study, eating episode detection was achieved with a precision of 78.2% and a recall of 72.5% with the evaluation segment set to 10 minutes.</s><s xml:id="_g7hn8Be">The amplitude threshold of 1.5 and 10% overlap were used for the analysis.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8" xml:id="_VbYD8gf">DISCUSSION</head><p xml:id="_3SPPme7"><s xml:id="_NKfKKGU">As expected, the results demonstrated that eating episode detection performance drops as the duration of the evaluation segment decreases.</s><s xml:id="_RWHkDRq">This is because there are fewer instances of chewing behavior in shorter segments, which reduces the ability of the classifier to discriminate eating from non-eating activities.</s><s xml:id="_gnvhX43">Figure <ref type="figure" target="#fig_5">8</ref> illustrates the effect of evaluation segment on eating episode detection performance and also the amplitude threshold setting.</s></p><p xml:id="_6ytPrEt"><s xml:id="_8KYTeKP">For the lab study, the average F1 score was consistently greater than 0.8 for amplitude thresholds 0.1, 0.5 and 1.0 and started to decrease after 1.0.</s><s xml:id="_KzUzw9p">We set the amplitude threshold of 1.0 for the lab study analysis.</s><s xml:id="_zbdVbgH">The amplitude threshold was varied from 0.1 to 4.0 for the fifteen participants from the controlled field study and wild study, and for the seventeen participants from the lab study.</s><s xml:id="_V6jryKE">For the controlled field study, the average F1 score increased Fig. <ref type="figure">9</ref>. F1 scores for all participants from the controlled field study and the wild study.</s><s xml:id="_fvpY5TM">The evaluation segment was 5 minutes, the amplitude threshold was 1.5, and the minimum required proportion of eating in each evaluation segment duration was 20%.</s><s xml:id="_FQPMGQm">P1 and P11 failed to have meal in the wild and their wild F1 score was calculated as 1.</s><s xml:id="_9WBGgpD">For P10 and P15, the system failed to capture the eating event in the wild.</s><s xml:id="_NdC2ScZ">The average F1 score of controlled field study was 0.83 (0.88 precision and 0.79 recall) and the average F1 score of wild study was 0.76 (0.83 precision and 0.70 recall).</s><s xml:id="_pvnT94c">The average F1 score of wild study without P1 and P11 was 0.72 (0.80 precision and 0.65 recall).</s></p><p xml:id="_B27qYPV"><s xml:id="_s4YnuSs">as the amplitude threshold was increased from 0.1 to 1.5.</s><s xml:id="_B8jzRpH">However, as the amplitude threshold was increased beyond 1.5, the average F1 score began to drop.</s><s xml:id="_3kxVQHm">Based on this result, we set the amplitude threshold at 1.5 for the analysis of data for the controlled field study and the wild study.</s><s xml:id="_TqmZj9f">This difference in optimal amplitude thresholds between lab study and controlled field study is due to the different mechanical designs of the necklaces employed in the studies; after the lab study, sensor mount and rubber band were introduced to the design for ease of use and consistent positioning of the necklace.</s><s xml:id="_uDCmTvW">In the earlier version of the necklace where the proximity sensor was solely suspended by the tension of electrical wires without any support of rubber band and sensor mount, the proximity sensor was consistently placed closer to the chin than that of the second version of the necklace.</s><s xml:id="_SSS7bxn">This resulted in smaller amplitudes in signals, which led to smaller optimal amplitude threshold value in laboratory study than that of the controlled field study.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1" xml:id="_D6qQucz">Food Type and Drinking Episodes</head><p xml:id="_Cn8tpu7"><s xml:id="_DMFMDVn">Our approach to eating episode detection hinges on the identification of chewing, first and foremost.</s><s xml:id="_x3dDc69">However, some legitimate food types such as ice cream, soup, and yogurt are perceived to require very little chewing.</s><s xml:id="_D8BEFhk">To understand how our system performed with these so-called soft-textured foods, we compared the recognition performance of eating episodes of the controlled field study where participants ate soft-textured foods against the one that involved all the other foods.</s></p><p xml:id="_jz66NTm"><s xml:id="_2QRjQ3C">For the analysis, the evaluation segment was set to 1 minute to account for the short duration of dessert eating episodes, whose average length was 7.9 minutes.</s><s xml:id="_5sxHykm">The same setting was applied for the non-soft textured food episodes.</s><s xml:id="_j2qsAN6">Additionally, an amplitude threshold of 1.5 and 70% overlap in eating segment were applied.</s><s xml:id="_nuRuaXu">To restate, this overlap meant that for every non-overlapping sequence of 1-minute evaluation segments, if each segment contained more than 42 seconds of eating (i.e., 70% of 1 minute), the system inferred that eating occurred in the segment.</s></p><p xml:id="_rXjdh5P"><s xml:id="_SYGWFfA">The average F1 score for soft textured food was 67% (sd=34%), and the average F1 score for non-soft textured food was 73% (sd=28%).</s><s xml:id="_v693s7e">As expected, the lower F1 score for soft textured food suggests that it is indeed harder to identify eating when less chewing occurs.</s><s xml:id="_phRW6VF">But the of only 6% in F1 score between these two conditions is encouraging.</s><s xml:id="_FAGGkJh">Another measure of interest is the standard deviation of the F1 scores across participants.</s><s xml:id="_8EMNKTp">Its high values shine light on the amount of intra-class variability in eating episode detection when data from multiple individuals is considered.</s></p><p xml:id="_HKNxqyk"><s xml:id="_EunC9xq">When it comes to understanding the extent to which our wearable system performs across a variety of dietary intake scenarios, it is also natural to question whether our approach is effective for drinking detection.</s><s xml:id="_hePGGKc">This is important because there has been growing interest in the health research community over the last few years in passively monitoring hydration patterns.</s><s xml:id="_x6WR292">While not a focus of this study, we were able to observe characteristic signals that may be used to identify drinking moments.</s><s xml:id="_tmNtTMb">Drinking gave rise to a significant increase in the sensor distance reading as the head is tilted backward and the jawbone is moved further away from the sensor.</s><s xml:id="_G8RJQjC">This increased distance was observed for a short period of time before it rapidly fell back to the baseline.</s><s xml:id="_aahnH8e">However, we also notice that the duration of this effect was different from occasion to occasion as drinking patterns varied.</s><s xml:id="_MANDUNx">Furthermore, the degree of tilting was different from person to person.</s><s xml:id="_MPAnm6c">We are currently developing a study design and methodology so that we can investigate the problem of drinking episode detection systematically and rigorously in the future.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2" xml:id="_xRNS69P">Effect of Light Intensity on Sensor Data</head><p xml:id="_TRgMSQ8"><s xml:id="_cYqA6YX">A core component of our wearable necklace system is the VL6180X sensor.</s><s xml:id="_U42vzxE">To reiterate, this device is a proximity sensor that calculates distance by measuring the time-of-flight of emitted light.</s><s xml:id="_xEbtF3f">Therefore, when used for eating episode detection, a reasonable question to ask is how much the sensor data is affected by the lighting conditions where the device is likely to be used.</s><s xml:id="_zeTRjPQ">To answer this question, we conducted a focused study where we tested our system while varying the light intensity the proximity sensor was exposed to and measuring the intensity of light, as seen in Figure <ref type="figure" target="#fig_6">10</ref>.</s><s xml:id="_B3HdwZU">For this study, we used a stand-alone digital lux meter to accurately measure the ambient light intensity.</s><s xml:id="_NmPJ2Z5">The signal at 2.2 lux was collected in our lab with all the lights turned off.</s><s xml:id="_JZYYCGh">The signal at 23.8 lux was obtained at a different location in the lab where it was slightly brighter due to the light from the outside.</s><s xml:id="_zvQ4gtf">The signal at 256 lux was measured with one light switch on, and the signal at 530 lux was measured with two light switches on.</s><s xml:id="_e3VgVJA">The brightness measurement rapidly increased when the measurement was made outside the building where our laboratory is located, under sunny and cloudy conditions: 27300 lux and 37000 lux.</s><s xml:id="_BEACaAE">In the signals collected outside, it is possible to see that the sensor saturates at times; the flat lines represent that the sensor value reached its maximum.</s><s xml:id="_B5KSQ64">Nonetheless, the sensor was still capable of detecting eating activity, as evidenced by the rhythmic patterns that are also captured.</s><s xml:id="_8us6KEb">This was due to the fact that during eating, even under high light intensity overhead, the sensor is often shaded from light by the head.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3" xml:id="_SdVWKRC">Mechanical Challenges</head><p xml:id="_cSfs8a4"><s xml:id="_37MrGUp">Our intention with the wearable system was to make it practical for everyday use and highly wearable.</s><s xml:id="_9huttjR">By and large we succeeded at this goal; the device we built is lightweight, requires only a small proximity sensor, and does not require contact with the skin.</s><s xml:id="_J9v4AhG">It is attached to a necklace but otherwise it can move freely around the neck.</s><s xml:id="_pttBeG8">However, these design requirements resulted in unanticipated challenges when it came to sensing.</s><s xml:id="_fgMPNu3">An important finding from the studies was that the performance of the device is dependent on the orientation of the sensor, since there is only one and it is so small.</s><s xml:id="_2mEY3G6">As expected, if the sensor was not pointing straight at the jawbone, it was not able to collect any data corresponding to jaw movement.</s><s xml:id="_8nfBhAr">This was relatively common in the studies as the sensor moved slightly as participants performed various activities.</s><s xml:id="_xp6KbmP">This was the case with P11 in the controlled field study; chewing was not captured because the sensor was pointing towards the neck more often than the jawbone.</s><s xml:id="_hzYsfJC">In addition, three participants from the wild study who reported to have engaged in sport activities (i.e., badminton and skateboarding) mentioned that the sensor was rotated around the neck after these activities, and they had to re-position the necklace.</s><s xml:id="_qEmBgWt">We plan to address these issues in a future iteration of the device in two ways.</s><s xml:id="_afAvY6s">First, we will incorporate additional proximity sensors to the system in an array configuration such that a wider sensing area can be explored and the device is not so sensitive to misalignment due to motion.</s><s xml:id="_yRNZ9wU">Secondly, we will explore methods and materials to prevent excessive movement of the sensor and facilitate custom fitting even as individuals are performing highly active physical activities.</s><s xml:id="_zhFXyHX">Ultimately, our goal is to reduce the size of the device further so that it can be integrated into existing jewelry and other wearables.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4" xml:id="_TS55cwZ">Mobility Confounds</head><p xml:id="_4mEcHQB"><s xml:id="_gNJZV5A">A limitation we identified in our preliminary studies is that walking can be confused with chewing.</s><s xml:id="_KxnvmJM">This is highlighted further if a person walks in a straight line without turning their head.</s><s xml:id="_UVnwyXa">In other words, walking can give rise to a signal that has the similar characteristic frequency and amplitude as eating, which can result in a high false-positive rate.</s><s xml:id="_s7JHEPB">To circumvent this problem, the accelerometer from the accompanying smartphone was used.</s><s xml:id="_waDXFVA">Given a certain amount of energy in the acceleration vector, it is assumed the individual is walking and not eating.</s><s xml:id="_ZrGc6Sd">In this case, the sensor data is discarded before it reaches the processing pipeline for efficiency reasons.</s><s xml:id="_ZBnCCmY">This approach is simple and performed well in our studies, reducing the rate false positives, but its limitations are clear.</s><s xml:id="_QHhr4eQ">For one, it does not account for scenarios where eating takes place while walking.</s><s xml:id="_3wyXHuf">And more importantly, it also fails to consider when a person is eating inside of a moving vehicle, which is a common Table <ref type="table">4</ref>.</s><s xml:id="_j5BHk2E">The survey questions asked at the end of the wild study.</s></p><p xml:id="_rNbTyQx"><s xml:id="_kPQ4rB2">User Survey Questions Q1.</s><s xml:id="_Gww22YN">How comfortable was the device in scale from 1-5 with 5 being the most comfortable?</s><s xml:id="_e6uMhmz">Q2.</s><s xml:id="_NpRybET">Were you aware of the device?</s><s xml:id="_upr6DVh">Q3.</s><s xml:id="_MKdCQZK">Will you attend a social event with the device on?</s><s xml:id="_EVWDMDG">occurrence.</s><s xml:id="_t8yc4ys">Thankfully, there is significant prior work focused on the identification of transportation modes with smart phones sensors <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b49">50]</ref>.</s><s xml:id="_PQvzAH5">In the future, we plan to incorporate these approaches into the system so that it can detect eating episodes even when acceleration is observed; the individual might be inside of a car or public transportation and having a snack.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5" xml:id="_maYhEHs">Wearability and Comfort</head><p xml:id="_Wzuc8pc"><s xml:id="_DAZWMYT">The fifteen participants from the controlled field study and wild study were asked about their experience with the device at the conclusion of the experiments.</s><s xml:id="_MAanTXr">The questions asked are shown in the Table <ref type="table">4</ref>.</s><s xml:id="_CvPcmAq">The comfort of the device was asked in scale from 1 to 5 with 5 being the most comfortable.</s><s xml:id="_dG4FS4F">The average comfort score from the fifteen participants was 3.6 and the standard deviation was 0.91 (See Figure <ref type="figure" target="#fig_7">11</ref>).</s><s xml:id="_jXJwffY">The maximum comfort value was 5 and the minimum comfort score was 2. The second question about whether the participants were aware of the device during the study.</s><s xml:id="_JdXuQtM">86.7% of the fifteen participants responded that they were aware of the device throughout the study.</s><s xml:id="_xcnjEvw">The third question was about whether the participants were willing to attend a social event with the device on.</s><s xml:id="_PzAKEPx">73.3% of the fifteen participants responded that they would not mind attending a social event with the device on.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc><div><p xml:id="_xKs3hgU"><s xml:id="_5uDqgD8">Fig.2.</s><s xml:id="_zQDmjQv">The figure shows a hypothetical data set for demonstrating the hierarchical classification levels employed in our detection algorithm.</s><s xml:id="_C2EN6CH">False positives are indicated in red color.</s><s xml:id="_QTQGJgK">In the first and the second talk sessions, there are some false positives detected at chewing level.</s><s xml:id="_eQxGaWB">However, they fail to be grouped at chewing bout level.</s><s xml:id="_WGdAUnF">During the restroom visit, there was one false positive eating episode.</s><s xml:id="_SKCv4GS">However, it is discarded in our algorithm since the duration of detected eating episode (red diagonal block) is too short to be considered an eating episode.</s></p></div></figDesc><graphic coords="7,80.70,106.70,450.60,71.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc><div><p xml:id="_n6q3kY9"><s xml:id="_sNbvya8">Fig. 3.</s><s xml:id="_MN6XMMt">The three sensor mounts at different angles (0, 30, and 45) were prepared to account for the differences in neck postures among individuals.</s><s xml:id="_V5jhaCT">The second and third image show the front and the side view of the sensor on a subject.</s><s xml:id="_fNc5vJt">In our application, the distance d between the proximity sensor and jaw is measured as shown in the third image.</s></p></div></figDesc><graphic coords="7,80.70,266.34,450.61,81.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc><div><p xml:id="_pt7zsqp"><s xml:id="_3vVaTmW">Fig.4.</s><s xml:id="_ZNawexA">Six plots featuring different activities a participant was involved in during lab study are shown.</s><s xml:id="_zrHd433">The eating signal features the participant chewing celery given as an appetizer.</s><s xml:id="_uy8ucD6">The sitting signal was captured while the participant was watching a movie clip.</s><s xml:id="_zRxctdt">For note-taking task, the participant copied a short paragraph written on the board.</s><s xml:id="_hXppzvN">During the note-taking, the participants had to look up on the board periodically, and this is reflected in the periodic rise in amplitude in the second plot from the bottom.</s><s xml:id="_kAyX5fj">In the eating signal, visually distinctive periodic changes in amplitude are observed whereas for the other non-eating activities, no such characteristic is noticeable.</s></p></div></figDesc><graphic coords="8,80.70,106.70,450.60,150.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc><div><p xml:id="_8Kq4rCZ"><s xml:id="_DwQBhQN">Fig. 5.</s><s xml:id="_urZv8tW">The first plot shows the median filtered signal.</s><s xml:id="_b3DMv9w">In the first plot, y-axis shows the distance in millimeter and x-axis shows time in second.</s><s xml:id="_bf34kQx">The second plot shows signals in each frame with baseline adjusted.</s><s xml:id="_KRyb8tz">And the third plot shows the signal after band pass filter (BPF).</s><s xml:id="_47H8GXw">In the second and third plot, x-axis represents data points and y-axis represents amplitude of filtered signal.</s><s xml:id="_mkmrVPQ">Then, the number of crossing about the amplitude thresholds indicated by dotted lines is used to classify if the given frame represents eating or not (fourth plot).</s><s xml:id="_n5RZ2dK">DBSCAN clusters the classification output to form clusters as shown in the fifth plot.</s><s xml:id="_rjwATrn">Finally, eating episode is detected by segmenting the DBSCAN result into non-overlapping time frames and evaluating if each frame contains more than the minimum required proportion of eating (shown in the last plot).</s></p></div></figDesc><graphic coords="10,80.70,106.70,450.61,121.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc><div><p xml:id="_eq2BxWJ"><s xml:id="_AvzbmT2">Fig. 7.</s><s xml:id="_RFqNzXF">The composition of foods served for lab study and controlled field study is shown in the figure.The number of servings is shown in the y-axis of the bar chart.</s><s xml:id="_9SxNPeA">The served food is written in each segment of bar along with the number of servings for each food.</s><s xml:id="_rmTzSXW">The bar height for dessert from controlled field study is shorter since two participants (P3 and P4) refused to have desserts.</s><s xml:id="_sUBDzNr">In controlled field study, the menus for appetizer and main dish were prepared such that eating would require significant amount of chewing while the menus for desserts were prepared with those that require minimal chewing.</s></p></div></figDesc><graphic coords="13,80.70,106.70,450.61,215.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc><div><p xml:id="_set9yU7"><s xml:id="_jhpdUf3">Fig.8.</s><s xml:id="_3FzJ8QK">The difference in plots for the lab study and the controlled field study is due to the difference in necklace design, which resulted the necklace for the lab study being placed consistently closer to the chin.</s><s xml:id="_WBKCbkr">The figure on the right shows the average F1 score as evaluation segment duration varied from 1 to 10 minutes.</s><s xml:id="_n7jnWhm">The amplitude threshold used for this analysis was 1.5 for controlled field and wild study, and 1.0 for lab study.</s><s xml:id="_a3Gt8Qw">For each evaluation segment duration, the minimum proportion of eating required within each evaluation segment duration for eating detection was 10%.</s></p></div></figDesc><graphic coords="14,80.70,106.70,450.61,152.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 .</head><label>10</label><figDesc><div><p xml:id="_bT3JnP6"><s xml:id="_ESgRhNy">Fig. 10.</s><s xml:id="_GctSF2a">The bottom four plots were collected inside a building.</s><s xml:id="_pM77CxH">The two plots from the top were collected outside.</s></p></div></figDesc><graphic coords="17,80.70,106.70,450.61,218.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc><div><p xml:id="_pvjnSJQ"><s xml:id="_fxkMHYf">Fig.11.</s><s xml:id="_PzhVvsr">One individual responded that the device was uncomfortable and two individuals responded that the device was very comfortable.</s><s xml:id="_MdwpmEG">The average score for comfort was 3.6 and it was considered moderately comfortable.</s></p></div></figDesc><graphic coords="18,80.70,213.27,450.59,172.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="12,80.70,106.70,450.62,318.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="15,80.70,106.70,450.60,218.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc><div><p xml:id="_G6bEWVG"><s xml:id="_9ZdRJ4T">A summary of different dietary monitoring approaches.</s></p></div></figDesc><table><row><cell>Sensing Modality</cell><cell>Proxy</cell><cell>Sensor</cell><cell>Sensor Location</cell><cell>Performance</cell><cell></cell></row><row><cell>Inertial</cell><cell>Bite</cell><cell>Accelerometer</cell><cell>Wrist</cell><cell>F-scores of 76.1%</cell><cell>[45]</cell></row><row><cell>Inertial</cell><cell>Bite</cell><cell>Gyroscope</cell><cell>Wrist</cell><cell>81% Accuracy at 1-sec resolution</cell><cell>[15]</cell></row><row><cell>Acoustic</cell><cell>Mastication</cell><cell>Microphone</cell><cell>Neck/Ear</cell><cell>detection accuracy of 83%</cell><cell>[35]</cell></row><row><cell>Physiological</cell><cell>Mastication</cell><cell>EMG Sensor</cell><cell>Neck</cell><cell>80% classification accuracy</cell><cell>[3]</cell></row><row><cell>Piezoelectric</cell><cell cols="2">Swallowing Piezoelectric Sensor</cell><cell>Neck</cell><cell cols="2">F1-score of 85% on solid foods, 86% on liquid [26]</cell></row><row><cell>Proximity</cell><cell>Mastication</cell><cell>Proximity Sensor</cell><cell>Ear</cell><cell>95.3% Accuracy</cell><cell>[8]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc><div><p xml:id="_kb3RhHw"><s xml:id="_HbNZebG">The study design of lab study, controlled field study and wild study.</s><s xml:id="_5YudbUC">The average time for each activity is indicated below the corresponding activity.</s></p></div></figDesc><table><row><cell>2*Lab</cell><cell>Check-in</cell><cell>Video</cell><cell>Video/Snack</cell><cell>Talk</cell><cell cols="2">Walk/Talk Walk</cell><cell>Meal</cell><cell cols="3">Note-taking Dessert Brushing Teeth</cell><cell>Total Time</cell></row><row><cell></cell><cell>5 min</cell><cell>3 min</cell><cell>4.6 min</cell><cell>3.8 min</cell><cell>2 min</cell><cell>2 min</cell><cell>9.4 min</cell><cell>1 min</cell><cell>6 min</cell><cell>1 min</cell><cell>37.8 min</cell></row><row><cell>2Controlled</cell><cell cols="2">Check-in Appetizer</cell><cell>Drawing</cell><cell>Browsing</cell><cell>Walk</cell><cell>Talk</cell><cell>Meal</cell><cell>Walk</cell><cell></cell><cell>Dessert</cell><cell>Total Time</cell></row><row><cell>Field</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>5 min</cell><cell>3.4 min</cell><cell>4.2 min</cell><cell>2.9 min</cell><cell>7 min</cell><cell cols="2">2.5 min 15.1 min</cell><cell>11.5 min</cell><cell></cell><cell>7.8 min</cell><cell>59.6 min</cell></row><row><cell>2*Wild</cell><cell></cell><cell></cell><cell></cell><cell cols="5">Various activities with at least one eating episode</cell><cell></cell><cell></cell><cell>Average Time</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">2 -8 hours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4.6 hours</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc><div><p xml:id="_mKWevRZ"><s xml:id="_aMWmURD">A variety of foods were consumed in the wild.</s><s xml:id="_pjCmk3b">P1 and P11 failed to have a meal session in the wild, and thus, were excluded from the table.</s></p></div></figDesc><table><row><cell>Participant</cell><cell>P2</cell><cell>P3</cell><cell>P4</cell><cell>P5</cell><cell>P6</cell><cell>P7</cell><cell>P8</cell><cell>P9</cell><cell>P10</cell><cell>P12</cell><cell>P13</cell><cell>P14</cell><cell>P15</cell></row><row><cell>2Food</cell><cell cols="4">Pasta Burger Sandwich Bread</cell><cell>Fried Rice</cell><cell>Pasta</cell><cell cols="7">Chicken Salad Salad Rice Rice Bowl Rice Pasta Salad</cell></row><row><cell></cell><cell></cell><cell>Cookies</cell><cell></cell><cell></cell><cell cols="2">Stir Fried Tofu Cookies</cell><cell></cell><cell cols="2">Apple Curry</cell><cell></cell><cell>Soup</cell><cell></cell><cell>Apple</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_Qrht2Km"><s xml:id="_3R4tWgw">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 2, No. 1, Article 4. Publication date: March 2018.</s></p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main" xml:id="_HWYVfub">Obesity and overweight</title>
		<idno type="DOI">10.1097/grh.0000000000000052</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>World Health Organization</publisher>
			<biblScope unit="volume">311</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Fact Sheet</note>
	<note type="raw_reference">2014. Obesity and overweight. Technical Report. World Health Organization. Fact Sheet 311.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_mBrM9QX">Recognition of dietary activity events using on-body sensors</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Amft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Tröster</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artmed.2007.11.007</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_j22Sg8h">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="136" />
			<date type="published" when="2008-02">2008. Feb. 2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Oliver Amft and Gerhard Tröster. 2008. Recognition of dietary activity events using on-body sensors. Artificial Intelligence in Medicine 42, 2 (Feb. 2008), 121-136.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_enPzy23">On-Body Sensing Solutions for Automatic Dietary Monitoring</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Amft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Tröster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YNH7AmH">IEEE pervasive computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009-04">2009. April 2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Oliver Amft and Gerhard Tröster. 2009. On-Body Sensing Solutions for Automatic Dietary Monitoring. IEEE pervasive computing 8, 2 (April 2009).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_TRDrGrz">Validity of U.S. Nutritional Surveillance: National Health and Nutrition Examination Survey Caloric Energy Intake Data, 1971-2010</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">A</forename><surname>Hand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">N</forename><surname>Blair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PUv5Kq2">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">76632</biblScope>
			<date type="published" when="2013-10">2013. Oct. 2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Edward Archer, Gregory A Hand, and Steven N Blair. 2013. Validity of U.S. Nutritional Surveillance: National Health and Nutrition Examination Survey Caloric Energy Intake Data, 1971-2010. PLoS ONE 8, 10 (Oct. 2013), 76632.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_qThDe5x">Automatic eating detection using a proximity sensor</title>
		<author>
			<persName><forename type="first">Yicheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Hong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingui</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/nebec.2014.6972716</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ydYwbEC">Bioengineering Conference (NEBEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
	<note>40th Annual Northeast</note>
	<note type="raw_reference">Yicheng Bai, Wenyan Jia, Zhi-Hong Mao, and Mingui Sun. 2014. Automatic eating detection using a proximity sensor. In Bioengineering Conference (NEBEC), 2014 40th Annual Northeast. IEEE, 1-2.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_n5TgR6K">Electroglottography</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName><surname>Baken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RAJtyNK">Journal of Voice</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="98" to="110" />
			<date type="published" when="1992">1992. 1992</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ronald J Baken. 1992. Electroglottography. Journal of Voice 6, 2 (1992), 98-110.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_qTt4uQD">EarBit: Using Wearable Sensors to Detect Eating Episodes in Unconstrained Environments</title>
		<author>
			<persName><forename type="first">Abdelkareem</forename><surname>Bedri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malcolm</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Temiloluwa</forename><surname>Prioleau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><forename type="middle">Yan</forename><surname>Beh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mayank</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thad</forename><surname>Starner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Abowd</surname></persName>
		</author>
		<idno type="DOI">10.1145/3130902</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_j2E2Ppk">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Abdelkareem Bedri, Richard Li, Malcolm Haynes, Raj Prateek Kosaraju, Ishaan Grover, Temiloluwa Prioleau, Min Yan Beh, Mayank Goel, Thad Starner, and Gregory Abowd. 2017. EarBit: Using Wearable Sensors to Detect Eating Episodes in Unconstrained Environments. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 1, 3 (2017), 37.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_vxaMqYK">A wearable system for detecting eating activities with proximity sensors in the outer ear</title>
		<author>
			<persName><forename type="first">Abdelkareem</forename><surname>Bedri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorva</forename><surname>Verlekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edison</forename><surname>Thomaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerie</forename><surname>Avva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thad</forename><surname>Starner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_T3tt45J">Proceedings of the 2015 ACM International Symposium on Wearable Computers</title>
		<meeting>the 2015 ACM International Symposium on Wearable Computers</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="91" to="92" />
		</imprint>
	</monogr>
	<note type="raw_reference">Abdelkareem Bedri, Apoorva Verlekar, Edison Thomaz, Valerie Avva, and Thad Starner. 2015. A wearable system for detecting eating activities with proximity sensors in the outer ear. In Proceedings of the 2015 ACM International Symposium on Wearable Computers. ACM, 91-92.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main" xml:id="_BB9Fjcg">The dietary assessment of individuals; methods, accuracy, new techniques and recommendations</title>
		<author>
			<persName><forename type="first">Sheila</forename><forename type="middle">A</forename><surname>Bingham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sheila A Bingham. 1987. The dietary assessment of individuals; methods, accuracy, new techniques and recommendations.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_M9MRPRs">Model-based measurement of food portion size for image-based dietary assessment using 3D/2D registration</title>
		<author>
			<persName><forename type="first">Wenyan</forename><surname>Hsin-Chen Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaofeng</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoxin</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yung-Nien</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingui</forename><surname>Fernstrom</surname></persName>
		</author>
		<author>
			<persName><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_25sGRsg">Measurement Science and Technology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">105701</biblScope>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hsin-Chen Chen, Wenyan Jia, Yaofeng Yue, Zhaoxin Li, Yung-Nien Sun, John D Fernstrom, and Mingui Sun. 2013. Model-based measurement of food portion size for image-based dietary assessment using 3D/2D registration. Measurement Science and Technology 24, 10 (2013), 105701.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_uMdHsTV">Active capacitive sensing: Exploring a new wearable sensing modality for activity recognition</title>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Amft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lukowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_7hVq9Qv">International Conference on Pervasive Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="319" to="336" />
		</imprint>
	</monogr>
	<note type="raw_reference">Jingyuan Cheng, Oliver Amft, and Paul Lukowicz. 2010. Active capacitive sensing: Exploring a new wearable sensing modality for activity recognition. In International Conference on Pervasive Computing. Springer, 319-336.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_ax2zEcC">Activity recognition and nutrition monitoring in every day situations with a textile capacitive neckband</title>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Kunze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Christian Rheinländer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Wille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norbert</forename><surname>Wehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Weppner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lukowicz</surname></persName>
		</author>
		<idno type="DOI">10.1145/2494091.2494143</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_bXAKNQV">Proceedings of the ACM conference on Pervasive and ubiquitous computing adjunct publication</title>
		<meeting>the ACM conference on Pervasive and ubiquitous computing adjunct publication<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">155</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Jingyuan Cheng, Bo Zhou, Kai Kunze, Carl Christian Rheinländer, Sebastian Wille, Norbert Wehn, Jens Weppner, and Paul Lukowicz. 2013. Activity recognition and nutrition monitoring in every day situations with a textile capacitive neckband. In Proceedings of the ACM conference on Pervasive and ubiquitous computing adjunct publication. ACM Press, New York, New York, USA, 155.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_Z85c2b9">Energy balance measurement: when something is not better than nothing</title>
		<author>
			<persName><forename type="first">D</forename><surname>N V Dhurandhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A W</forename><surname>Schoeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heymsfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T I A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>R Speakman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D B</forename><surname>Jeansonne</surname></persName>
		</author>
		<author>
			<persName><surname>Allison</surname></persName>
		</author>
		<idno type="DOI">10.1038/ijo.2014.199</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_X2RsDQc">International Journal of Obesity</title>
		<imprint>
			<date type="published" when="2014-11">2014. Nov. 2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">N V Dhurandhar, D Schoeller, A W Brown, S B Heymsfield, D Thomas, T I A Sorensen, J R Speakman, M Jeansonne, and D B Allison. 2014. Energy balance measurement: when something is not better than nothing. International Journal of Obesity (Nov. 2014).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Dong</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10484-012-9194-1</idno>
		<title level="m" xml:id="_nHyr9rC">Tracking Wrist Motion to Detect and Measure the Eating Intake of Free-Living Humans</title>
		<imprint>
			<date type="published" when="2012-05">2012. May 2012</date>
			<biblScope unit="page" from="1" to="106" />
		</imprint>
		<respStmt>
			<orgName>.) Clemson University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Thesis</note>
	<note>Ph. D</note>
	<note type="raw_reference">Yujie Dong. 2012. Tracking Wrist Motion to Detect and Measure the Eating Intake of Free-Living Humans. Thesis (Ph. D.) Clemson University (May 2012), 1-106.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_gGJUkmY">Detecting periods of eating during free living by tracking wrist motion</title>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Scisco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName><surname>Hoover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uCChwkZ">IEEE Journal of Biomedical Health Informatics</title>
		<imprint>
			<date type="published" when="2013-09">2013. Sept. 2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yujie Dong, Jenna Scisco, Mike Wilson, E Muth, and A Hoover. 2013. Detecting periods of eating during free living by tracking wrist motion. IEEE Journal of Biomedical Health Informatics (Sept. 2013).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_YE6B8RM">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><surname>Others</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dRhyuS5">Kdd</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="226" to="231" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Martin Ester, Hans-Peter Kriegel, Jörg Sander, Xiaowei Xu, and others. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise.. In Kdd, Vol. 96. 226-231.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_YEaCEua">A novel approach for food intake detection using electroglottography</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">M</forename><surname>Fontana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Sazonov</surname></persName>
		</author>
		<idno type="DOI">10.1088/0967-3334/35/5/739</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EzneTJ2">Physiological measurement</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">739</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Muhammad Farooq, Juan M Fontana, and Edward Sazonov. 2014. A novel approach for food intake detection using electroglottography. Physiological measurement 35, 5 (2014), 739.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_6YHtKcu">Comparative testing of piezoelectric and printed strain sensors in characterization of chewing</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Sazonov</surname></persName>
		</author>
		<idno type="DOI">10.1109/embc.2015.7320136</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_DN2nNzg">Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="7538" to="7541" />
		</imprint>
	</monogr>
	<note>Annual International Conference of the IEEE</note>
	<note type="raw_reference">Muhammad Farooq and Edward Sazonov. 2015. Comparative testing of piezoelectric and printed strain sensors in characterization of chewing. In Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual International Conference of the IEEE. IEEE, 7538-7541.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_NHq7CzR">Detection of chewing from piezoelectric film sensor signals using ensemble classifiers</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Sazonov</surname></persName>
		</author>
		<idno type="DOI">10.1109/embc.2016.7591833</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_zmpfJgk">Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="4929" to="4932" />
		</imprint>
	</monogr>
	<note>IEEE 38th Annual International Conference of the</note>
	<note type="raw_reference">Muhammad Farooq and Edward Sazonov. 2016. Detection of chewing from piezoelectric film sensor signals using ensemble classifiers. In Engineering in Medicine and Biology Society (EMBC), 2016 IEEE 38th Annual International Conference of the. IEEE, 4929-4932.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_bDfgDPP">A novel wearable device for food intake and physical activity recognition</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Sazonov</surname></persName>
		</author>
		<idno type="DOI">10.3390/s16071067</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kszVhWZ">Sensors</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">1067</biblScope>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Muhammad Farooq and Edward Sazonov. 2016. A novel wearable device for food intake and physical activity recognition. Sensors 16, 7 (2016), 1067.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_znqSp7e">Nutrient-gene interaction: metabolic genotypephenotype relationship</title>
		<author>
			<persName><forename type="first">Vay</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename></persName>
		</author>
		<author>
			<persName><forename type="first">T H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diane</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai-Nang Paul</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wVdampb">The Journal of nutrition</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3016S" to="3020S" />
			<date type="published" when="2005-12">2005. Dec. 2005</date>
		</imprint>
	</monogr>
	<note>Suppl</note>
	<note type="raw_reference">Vay Liang W Go, Christine T H Nguyen, Diane M Harris, and Wai-Nang Paul Lee. 2005. Nutrient-gene interaction: metabolic genotype- phenotype relationship. The Journal of nutrition 135, 12 Suppl (Dec. 2005), 3016S-3020S.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_pNqujvF">Accelerometer-based Transportation Mode Detection on Smartphones</title>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Hemminki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petteri</forename><surname>Nurmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasu</forename><surname>Tarkoma</surname></persName>
		</author>
		<idno type="DOI">10.1145/2517351.2517367</idno>
		<ptr target="http://dx.doi.org/10.1145/2517351.2517367" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_7RFFrrd">Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems (SenSys &apos;13)</title>
		<meeting>the 11th ACM Conference on Embedded Networked Sensor Systems (SenSys &apos;13)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Samuli Hemminki, Petteri Nurmi, and Sasu Tarkoma. 2013. Accelerometer-based Transportation Mode Detection on Smartphones. In Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems (SenSys &apos;13). ACM, New York, NY, USA, Article 13, 14 pages. DOI:http://dx.doi.org/10.1145/2517351.2517367</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_EbWMQG7">Challenges in research in nutritional epidemiology</title>
		<author>
			<persName><forename type="first">D R</forename><surname>Jacobs</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-61779-894-8_2</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DS6fCAJ">Nutritional Health</title>
		<imprint>
			<biblScope unit="page" from="29" to="42" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D R Jacobs. 2012. Challenges in research in nutritional epidemiology. Nutritional Health (2012), 29-42.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_gv2wsph">3D localization of circular feature in 2D image and application to food volume estimation</title>
		<author>
			<persName><forename type="first">Wenyan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaofeng</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">D</forename><surname>Fernstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengnan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongquan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingui</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Gz2zrUF">Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="4545" to="4548" />
		</imprint>
	</monogr>
	<note>Annual International Conference of the IEEE</note>
	<note type="raw_reference">Wenyan Jia, Yaofeng Yue, John D Fernstrom, Zhengnan Zhang, Yongquan Yang, and Mingui Sun. 2012. 3D localization of circular feature in 2D image and application to food volume estimation. In Engineering in Medicine and Biology Society (EMBC), 2012 Annual International Conference of the IEEE. IEEE, 4545-4548.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_aREnZrd">Gesture spotting with body-worn inertial sensors to detect user activities</title>
		<author>
			<persName><forename type="first">Holger</forename><surname>Junker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Amft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Lukowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Tröster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RSFUDAM">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2010" to="2024" />
			<date type="published" when="2008-06">2008. June 2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Holger Junker, Oliver Amft, Paul Lukowicz, and Gerhard Tröster. 2008. Gesture spotting with body-worn inertial sensors to detect user activities. Pattern Recognition 41, 6 (June 2008), 2010-2024.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_NKPMkkF">A Wearable Nutrition Monitoring System</title>
		<author>
			<persName><surname>Kalantarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alshurafa</surname></persName>
		</author>
		<author>
			<persName><surname>Sarrafzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_e8QWHbb">Wearable and Implantable Body Sensor Networks (BSN)</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
	<note>11th International Conference</note>
	<note type="raw_reference">H Kalantarian, N Alshurafa, and M Sarrafzadeh. 2014. A Wearable Nutrition Monitoring System. In Wearable and Implantable Body Sensor Networks (BSN), 2014 11th International Conference on. 75-80.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Nathaniel</forename><surname>Kleitman</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejm194001182220320</idno>
		<title level="m" xml:id="_q9yfCye">Sleep and wakefulness</title>
		<meeting><address><addrLine>Chicago</addrLine></address></meeting>
		<imprint>
			<publisher>The University of Chicago Press</publisher>
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nathaniel Kleitman. 1963. Sleep and wakefulness. The University of Chicago Press, Chicago.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_mJnwXvy">Excess deaths associated with underweight, overweight, and obesity</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Flegal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">I</forename><surname>Graubard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gail</forename><surname>Mh</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.293.15.1861</idno>
		<ptr target="http://dx.doi.org/10.1001/jama.293.15.1861arXiv:/data/Journals/JAMA/4972/JOC50018.pdf" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Q9DdsY9">JAMA</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page" from="1861" to="1867" />
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Flegal KM, Graubard BI, Williamson DF, and Gail MH. 2005. Excess deaths associated with underweight, overweight, and obesity. JAMA 293, 15 (2005), 1861-1867. DOI:http://dx.doi.org/10.1001/jama.293.15.1861 arXiv:/data/Journals/JAMA/4972/JOC50018.pdf</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_CpG7ypZ">Theory of use of the turnover rates of body water for measuring energy and material balance</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lifson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruth</forename><surname>Mcclintock</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-5193(66)90185-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_sFrtp3K">Journal of theoretical biology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="74" />
			<date type="published" when="1966">1966. 1966</date>
		</imprint>
	</monogr>
	<note type="raw_reference">N Lifson and Ruth McClintock. 1966. Theory of use of the turnover rates of body water for measuring energy and material balance. Journal of theoretical biology 12, 1 (1966), 46-74.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_H9kHj5c">An Intelligent Food-Intake Monitoring System Using Wearable Sensors</title>
		<author>
			<persName><forename type="first">Jindong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Atallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pettitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Frost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guang-Zhong</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1109/bsn.2012.11</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_2yrpYct">Wearable and Implantable Body Sensor Networks (BSN)</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="154" to="160" />
		</imprint>
	</monogr>
	<note>Ninth International Conference on</note>
	<note type="raw_reference">Jindong Liu, E Johns, L Atallah, C Pettitt, B Lo, G Frost, and Guang-Zhong Yang. 2012. An Intelligent Food-Intake Monitoring System Using Wearable Sensors. In Wearable and Implantable Body Sensor Networks (BSN), 2012 Ninth International Conference on. IEEE Computer Society, 154-160.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_58gY4bx">Biomedical Signal Processing and Control</title>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Makeyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Lopez-Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Schuckers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Besio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Sazonov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WZufEm9">Biomedical Signal Processing and Control</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="649" to="656" />
			<date type="published" when="2012-11">2012. Nov. 2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Oleksandr Makeyev, Paulo Lopez-Meyer, Stephanie Schuckers, Walter Besio, and Edward Sazonov. 2012. Biomedical Signal Processing and Control. Biomedical Signal Processing and Control 7, 6 (Nov. 2012), 649-656.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_aqMDU6S">Multimodality Sensing for Eating Recognition</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Merck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Maher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Mirtchouk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samantha</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_G3MDWW8">Proceedings of PervasiveHealth</title>
		<meeting>PervasiveHealth</meeting>
		<imprint>
			<date type="published" when="2016-03">2016. March 2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note type="raw_reference">Christopher Merck, Christina Maher, Mark Mirtchouk, Min Zheng, Yuxiao Huang, and Samantha Kleinberg. 2016. Multimodality Sensing for Eating Recognition. Proceedings of PervasiveHealth (March 2016), 1-8.</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_NUh65cE">A renaissance for measurement error</title>
		<author>
			<persName><forename type="first">K B</forename><surname>Michels</surname></persName>
		</author>
		<idno type="DOI">10.1093/ije/30.3.421</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eUg7Vbp">International journal of epidemiology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="421" to="422" />
			<date type="published" when="2001-06">2001. June 2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">K B Michels. 2001. A renaissance for measurement error. International journal of epidemiology 30, 3 (June 2001), 421-422.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_Bh3yjat">Real-time swallowing detection based on tracheal acoustics</title>
		<author>
			<persName><forename type="first">Temiloluwa</forename><surname>Olubanjo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maysam</forename><surname>Ghovanloo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_CmPNArJ">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="4384" to="4388" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
	<note type="raw_reference">Temiloluwa Olubanjo and Maysam Ghovanloo. 2014. Real-time swallowing detection based on tracheal acoustics. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on. IEEE, 4384-4388.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_JtZHgjF">Food intake monitoring: an acoustical approach to automated food intake activity detection and classification of consumed food</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Päßler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolf-Joachim</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cb4zPQX">Physiological Measurement</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1073" to="1093" />
			<date type="published" when="2012-05">2012. May 2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sebastian Päßler, Matthias Wolff, and Wolf-Joachim Fischer. 2012. Food intake monitoring: an acoustical approach to automated food intake activity detection and classification of consumed food. Physiological Measurement 33, 6 (May 2012), 1073-1093.</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_xPjy5R5">Time-frequency analysis of chewing activity in the natural environment</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Jmc Po</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Kieser</surname></persName>
		</author>
		<author>
			<persName><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tésenyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herbison</surname></persName>
		</author>
		<author>
			<persName><surname>Farella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_W2vXGP5">Journal of dental research</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="1206" to="1210" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">JMC Po, JA Kieser, LM Gallo, AJ Tésenyi, P Herbison, and M Farella. 2011. Time-frequency analysis of chewing activity in the natural environment. Journal of dental research 90, 10 (2011), 1206-1210.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_U2uWrju">Predicting &quot;About-to-Eat&quot; Moments for Just-in-Time Eating Intervention</title>
		<author>
			<persName><forename type="first">Tauhidur</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Czerwinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Gilad-Bachrach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Johns</surname></persName>
		</author>
		<idno type="DOI">10.1145/2896338.2896359</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_S7w7tGd">DH &apos;16: Proceedings of the 6th International Conference on Digital Health Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Tauhidur Rahman, Mary Czerwinski, Ran Gilad-Bachrach, and Paul Johns. 2016. Predicting &quot;About-to-Eat&quot; Moments for Just-in-Time Eating Intervention. In DH &apos;16: Proceedings of the 6th International Conference on Digital Health Conference. Cornell University, ACM.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main" xml:id="_hHQeBfJ">Piezoelectric and acoustic materials for transducer applications</title>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Safari</surname></persName>
		</author>
		<author>
			<persName><surname>Koray Akdogan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Ahmad Safari and E Koray Akdogan. 2008. Piezoelectric and acoustic materials for transducer applications. Springer Science &amp; Business Media.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_n8nAxDh">Non-invasive monitoring of chewing and swallowing for objective quantification of ingestive behavior</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Sazonov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Schuckers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Lopez-Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksandr</forename><surname>Makeyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadezhda</forename><surname>Sazonova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">L</forename><surname>Melanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Neuman</surname></persName>
		</author>
		<idno type="DOI">10.1088/0967-3334/29/5/001</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rZH5ty9">Physiological Measurement</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="525" to="541" />
			<date type="published" when="2008-04">2008. April 2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Edward Sazonov, Stephanie Schuckers, Paulo Lopez-Meyer, Oleksandr Makeyev, Nadezhda Sazonova, Edward L Melanson, and Michael Neuman. 2008. Non-invasive monitoring of chewing and swallowing for objective quantification of ingestive behavior. Physiological Measurement 29, 5 (April 2008), 525-541.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_WqPXGZD">Limitations in the assessment of dietary energy intake by self-report</title>
		<author>
			<persName><surname>Schoeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tfGyDhU">Metabolism</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="5" to="5" />
			<date type="published" when="1995-02">1995. Feb. 1995</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Schoeller. 1995. Limitations in the assessment of dietary energy intake by self-report. Metabolism 44 (Feb. 1995), 5-5.</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_xHEmHNG">Dynamic models of behavior for just-in-time adaptive interventions</title>
		<author>
			<persName><forename type="first">Donna</forename><surname>Spruijt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Nilsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rqBBnHn">IEEE Pervasive Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="13" to="17" />
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Donna Spruijt-Metz and Wendy Nilsen. 2014. Dynamic models of behavior for just-in-time adaptive interventions. IEEE Pervasive Computing 3, 13 (2014), 13-17.</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_BHXhz9T">Chews and swallows and the microstructure of eating</title>
		<author>
			<persName><forename type="first">E</forename><surname>Stellar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E E</forename><surname>Shrager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MCUe3Db">The American journal of clinical nutrition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="973" to="982" />
			<date type="published" when="1985">1985. 1985</date>
		</imprint>
	</monogr>
	<note type="raw_reference">E Stellar and E E Shrager. 1985. Chews and swallows and the microstructure of eating. The American journal of clinical nutrition 42, 5 (1985), 973-982.</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_wmMSvn3">eButton: a wearable computer for health monitoring and personal assistance</title>
		<author>
			<persName><forename type="first">Mingui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lora</forename><forename type="middle">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Hong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hsin-Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yicheng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuecheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengliu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyan</forename><surname>Jia</surname></persName>
		</author>
		<idno type="DOI">10.1145/2593069.2596678</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_97av6zH">Design Automation Conference (DAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>ACM/EDAC/IEEE</note>
	<note type="raw_reference">Mingui Sun, Lora E Burke, Zhi-Hong Mao, Yiran Chen, Hsin-Chen Chen, Yicheng Bai, Yuecheng Li, Chengliu Li, and Wenyan Jia. 2014. eButton: a wearable computer for health monitoring and personal assistance. In Design Automation Conference (DAC), 2014 51st ACM/EDAC/IEEE. IEEE, 1-6.</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_5tKeuCt">A Practical Approach for Recognizing Eating Moments with Wrist-Mounted Inertial Sensing</title>
		<author>
			<persName><forename type="first">Edison</forename><surname>Thomaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irfan</forename><surname>Abowd</surname></persName>
		</author>
		<author>
			<persName><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Vm9Mc2D">UbiComp &apos;15: Proceedings of the 2015 ACM international joint conference on Pervasive and ubiquitous computing</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note type="raw_reference">Edison Thomaz, GD Abowd, and Irfan Essa. 2015. A Practical Approach for Recognizing Eating Moments with Wrist-Mounted Inertial Sensing. In UbiComp &apos;15: Proceedings of the 2015 ACM international joint conference on Pervasive and ubiquitous computing. 1-12.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_qMQ8UVt">A practical approach for recognizing eating moments with wrist-mounted inertial sensing</title>
		<author>
			<persName><forename type="first">Edison</forename><surname>Thomaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irfan</forename><surname>Essa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">D</forename><surname>Abowd</surname></persName>
		</author>
		<idno type="DOI">10.1145/2750858.2807545</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Q2zJnHu">Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1029" to="1040" />
		</imprint>
	</monogr>
	<note type="raw_reference">Edison Thomaz, Irfan Essa, and Gregory D Abowd. 2015. A practical approach for recognizing eating moments with wrist-mounted inertial sensing. In Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 1029-1040.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_US7uWbb">Inferring Meal Eating Activities in Real World Settings from Ambient Sounds</title>
		<author>
			<persName><forename type="first">Edison</forename><surname>Thomaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irfan</forename><surname>Essa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">D</forename><surname>Abowd</surname></persName>
		</author>
		<idno type="DOI">10.1145/2678025.2701405</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_XpMmyEk">the 20th Intelligent User Interfaces Conference (IUI)</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="427" to="431" />
		</imprint>
	</monogr>
	<note type="raw_reference">Edison Thomaz, Cheng Zhang, Irfan Essa, and Gregory D Abowd. 2015. Inferring Meal Eating Activities in Real World Settings from Ambient Sounds. In the 20th Intelligent User Interfaces Conference (IUI). ACM Press, New York, New York, USA, 427-431.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_YNgm7pA">The estimation of the patient&apos;s home dietary intake</title>
		<author>
			<persName><forename type="first">D</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><surname>Others</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QuFRuTt">Journal of the American Dietetic Association</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="875" to="881" />
			<date type="published" when="1940">1940. 1940</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D Turner and others. 1940. The estimation of the patient&apos;s home dietary intake. Journal of the American Dietetic Association 16 (1940), 875-881.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_znw9p4g">A study of English diets by the individual method: Part I. Men</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Widdowson</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0022172400043643</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cDuPGn5">Journal of Hygiene</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">03</biblScope>
			<biblScope unit="page" from="269" to="290" />
			<date type="published" when="1936">1936. 1936</date>
		</imprint>
	</monogr>
	<note type="raw_reference">EM Widdowson. 1936. A study of English diets by the individual method: Part I. Men. Journal of Hygiene 36, 03 (1936), 269-290.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_VAhXTmc">A study of English diets by the individual method: Part II</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Widdowson</surname></persName>
		</author>
		<author>
			<persName><surname>Mccance</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0022172400043655</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yyS8y42">Women. Journal of Hygiene</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">03</biblScope>
			<biblScope unit="page" from="293" to="307" />
			<date type="published" when="1936">1936. 1936</date>
		</imprint>
	</monogr>
	<note type="raw_reference">EM Widdowson and RA McCance. 1936. A study of English diets by the individual method: Part II. Women. Journal of Hygiene 36, 03 (1936), 293-307.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_5daACVf">Transport mode detection with realistic smartphone sensor data</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Widhalm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Nitsche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norbert</forename><surname>Brändie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_7VAzBKG">21st International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="573" to="576" />
		</imprint>
	</monogr>
	<note>Pattern Recognition (ICPR)</note>
	<note type="raw_reference">Peter Widhalm, Philippe Nitsche, and Norbert Brändie. 2012. Transport mode detection with realistic smartphone sensor data. In Pattern Recognition (ICPR), 2012 21st International Conference on. IEEE, 573-576.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_68RxvVu">Diets of a group of aircraft workers in Southern California</title>
		<author>
			<persName><forename type="first">Dorothy</forename><forename type="middle">G</forename><surname>Wiehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vuKTD3Q">The Milbank Memorial Fund Quarterly</title>
		<imprint>
			<biblScope unit="page" from="329" to="366" />
			<date type="published" when="1942">1942. 1942</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dorothy G Wiehl. 1942. Diets of a group of aircraft workers in Southern California. The Milbank Memorial Fund Quarterly (1942), 329-366.</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_GY5DnrG">Development of new or improved dietary methods for epidemiological investigations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dorothy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Wiehl</surname></persName>
		</author>
		<author>
			<persName><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eXMCUZy">American Journal of Public Health and the Nations Health</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6_Pt_1</biblScope>
			<biblScope unit="page" from="824" to="828" />
			<date type="published" when="1960">1960. 1960</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dorothy G Wiehl and Robert Reed. 1960. Development of new or improved dietary methods for epidemiological investigations. American Journal of Public Health and the Nations Health 50, 6_Pt_1 (1960), 824-828.</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_YheEcwq">BodyScope: a wearable acoustic sensor for activity recognition</title>
		<author>
			<persName><forename type="first">Koji</forename><surname>Yatani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Khai</surname></persName>
		</author>
		<author>
			<persName><surname>Truong</surname></persName>
		</author>
		<idno type="DOI">10.1145/2370216.2370269</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_hDSTMQr">UbiComp &apos;12: Proceedings of the 2012 ACM Conference on Ubiquitous Computing</title>
		<imprint>
			<date type="published" when="2012-08">2012. 2012. Received August 2017. November 2017. January 2018</date>
			<biblScope unit="page" from="341" to="350" />
		</imprint>
	</monogr>
	<note type="raw_reference">Koji Yatani and Khai N Truong. 2012. BodyScope: a wearable acoustic sensor for activity recognition. UbiComp &apos;12: Proceedings of the 2012 ACM Conference on Ubiquitous Computing (2012), 341-350. Received August 2017; revised November 2017; accepted January 2018</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
