<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_3Mg4mAv">Ethical and regulatory challenges of large language models in medicine</title>
				<funder ref="#_E3NEgh9">
					<orgName type="full">National University of Singapore</orgName>
					<orgName type="abbreviated">NUS</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100001352</idno>
				</funder>
				<funder ref="#_WVdjMq9">
					<orgName type="full">Wellcome Trust</orgName>
					<orgName type="abbreviated">WT</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100010269</idno>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>PharmD</roleName><forename type="first">J</forename><forename type="middle">C L</forename><surname>Ong</surname></persName>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Nan</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">S</forename><forename type="middle">W</forename><surname>Ting</surname></persName>
						</author>
						<author>
							<persName><forename type="first">S Y-H</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName><roleName>Prof</roleName><forename type="first">Finale</forename><surname>Doshi-Velez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jasmine</forename><surname>Chiat</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ling</forename><surname>Ong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yin-Hsi</forename><surname>Shelley</surname></persName>
						</author>
						<author>
							<persName><surname>Chang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wasswa</forename><surname>William</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Atul</forename><forename type="middle">J</forename><surname>Butte</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nigam</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lita</forename><surname>Sui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tjien</forename><surname>Chew</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName><roleName>Prof</roleName><forename type="first">Julian</forename><surname>Savulescu</surname></persName>
						</author>
						<author>
							<persName><roleName>Prof</roleName><forename type="first">Daniel</forename><surname>Shu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Ting</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<note type="raw_affiliation">Division of Pharmacy , Singapore General Hospital , Singapore</note>
								<orgName type="department">Division of Pharmacy</orgName>
								<orgName type="institution">Singapore General Hospital</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<note type="raw_affiliation">Duke-NUS Medical School Department of Pharmacy (L S T Chew MMedSc) , National University of Singapore , Singapore ;</note>
								<orgName type="department">Department of Pharmacy (L S T Chew MMedSc)</orgName>
								<orgName type="institution" key="instit1">Duke-NUS Medical School</orgName>
								<orgName type="institution" key="instit2">National University of Singapore</orgName>
								<address>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<note type="raw_affiliation">Department of Ophthalmology , Chang Gung Memorial Hospital , Linkou Medical Center , Taoyuan , Taiwan (S Y-H</note>
								<orgName type="department" key="dep1">Department of Ophthalmology</orgName>
								<orgName type="department" key="dep2">Linkou Medical Center</orgName>
								<orgName type="institution">Chang Gung Memorial Hospital</orgName>
								<address>
									<settlement>Taoyuan</settlement>
									<region>Y-H</region>
									<country>Taiwan (S</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<note type="raw_affiliation">Chang MD) ; College of Medicine , Chang Gung University , Taoyuan , Taiwan</note>
								<orgName type="department" key="dep1">Chang MD)</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution">Chang Gung University</orgName>
								<address>
									<settlement>Taoyuan</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<note type="raw_affiliation">Department of Biomedical Sciences and Engineering , Mbarara University of Science and Technology , Mbarara , Uganda (</note>
								<orgName type="department">Department of Biomedical Sciences and Engineering</orgName>
								<orgName type="institution">Mbarara University of Science and Technology</orgName>
								<address>
									<settlement>Mbarara</settlement>
									<country key="UG">Uganda</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<note type="raw_affiliation">W William PhD) ; Bakar Computational Health Sciences Institute , and Department of Pediatrics , University of California , San Francisco , San Francisco , CA , USA (</note>
								<orgName type="department" key="dep1">W William PhD)</orgName>
								<orgName type="department" key="dep2">Department of Pediatrics</orgName>
								<orgName type="institution" key="instit1">Bakar Computational Health Sciences Institute</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<addrLine>San Francisco</addrLine>
									<settlement>San Francisco</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<note type="raw_affiliation"><label>A</label> Prof A J Butte PhD) ; Center for Data-Driven Insights and Innovation , University of California Health , Oakland , CA , USA (</note>
								<orgName type="department" key="dep1">Prof A J Butte PhD)</orgName>
								<orgName type="department" key="dep2">Center for Data-Driven Insights and Innovation</orgName>
								<orgName type="institution">University of California Health</orgName>
								<address>
									<settlement>Oakland</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<note type="raw_affiliation">J Butte) ; Stanford Health Care , Palo Alto , CA , USA (</note>
								<orgName type="department">J Butte)</orgName>
								<orgName type="institution">Stanford Health Care</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<note type="raw_affiliation">Prof N H Shah PhD) ; Department of Medicine , and Clinical Excellence Research Center , School of Medicine , Stanford University , Stanford , CA , USA (</note>
								<orgName type="department" key="dep1">Department of Medicine</orgName>
								<orgName type="department" key="dep2">and Clinical Excellence Research Center</orgName>
								<orgName type="department" key="dep3">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Prof N H Shah PhD)</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<note type="raw_affiliation">Prof N H Shah) ; Singapore Health Services , Pharmacy and Therapeutics Council Office , Singapore (L S T Chew) ; Department of Pharmacy , National Cancer Centre Singapore , Singapore (</note>
								<orgName type="department" key="dep1">Pharmacy and Therapeutics Council Office</orgName>
								<orgName type="department" key="dep2">Department of Pharmacy</orgName>
								<orgName type="institution" key="instit1">Prof N H Shah)</orgName>
								<orgName type="institution" key="instit2">Singapore Health Services</orgName>
								<orgName type="institution" key="instit3">Singapore (L S T Chew)</orgName>
								<orgName type="institution" key="instit4">National Cancer Centre Singapore</orgName>
								<address>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<note type="raw_affiliation">L S T Chew) ; Harvard Paulson School of Engineering and Applied Sciences , Harvard University , Cambridge , MA , USA StatNLP Research Group ,</note>
								<orgName type="department" key="dep1">L S T Chew)</orgName>
								<orgName type="department" key="dep2">Harvard Paulson School of Engineering and Applied Sciences</orgName>
								<orgName type="laboratory">StatNLP Research Group</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<note type="raw_affiliation">Singapore University of Technology and Design , Singpore</note>
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<settlement>Singpore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<note type="raw_affiliation">Viewpoint Children&apos;s Research Institute , Melbourne , VIC , Australia Centre for Biomedical Ethics ,</note>
								<orgName type="department">Centre for Biomedical Ethics</orgName>
								<orgName type="institution">Viewpoint Children&apos;s Research Institute</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<region>VIC</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff13">
								<note type="raw_affiliation">Yong Loo Lin School of Medicine , National University of Singapore , Singapore (</note>
								<orgName type="department">Yong Loo Lin School of Medicine</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff14">
								<note type="raw_affiliation">Prof J Savulescu) ; Oxford Uehiro Centre for Practical Ethics , Faculty of Philosophy , University of Oxford , Oxford , UK Artificial Intelligence and Digital Innovation ,</note>
								<orgName type="department" key="dep1">Prof J Savulescu)</orgName>
								<orgName type="department" key="dep2">Oxford Uehiro Centre for Practical Ethics</orgName>
								<orgName type="department" key="dep3">Faculty of Philosophy</orgName>
								<orgName type="laboratory">Artificial Intelligence and Digital Innovation</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff15">
								<note type="raw_affiliation">Singapore Eye Research Institute , Singapore National Eye Center , Singapore Health Service , Singapore ( D S W Ting) ;</note>
								<orgName type="department">D S W Ting)</orgName>
								<orgName type="institution" key="instit1">Singapore Eye Research Institute</orgName>
								<orgName type="institution" key="instit2">Singapore National Eye Center</orgName>
								<orgName type="institution" key="instit3">Singapore Health Service</orgName>
								<address>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff16">
								<note type="raw_affiliation">Byers Eye Institute , Stanford University , Palo Alto , CA , USA Artificial Intelligence and Digital Innovation ,</note>
								<orgName type="laboratory">Artificial Intelligence and Digital Innovation</orgName>
								<orgName type="institution" key="instit1">Byers Eye Institute</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff17">
								<note type="raw_affiliation">Singapore Eye Research Institute , Singapore National Eye Center , Singapore Health Service , Singapore 168751</note>
								<orgName type="institution" key="instit1">Singapore Eye Research Institute</orgName>
								<orgName type="institution" key="instit2">Singapore National Eye Center</orgName>
								<orgName type="institution" key="instit3">Singapore Health Service</orgName>
								<address>
									<postCode>168751</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_KM7XXjM">Ethical and regulatory challenges of large language models in medicine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">75E736C35DD4DDFF0E13148A1CE1BEED</idno>
					<idno type="DOI">10.1016/s2589-7500(24)00061-x</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T13:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_v9w77dx"><p xml:id="_SbbAKTa"><s xml:id="_gn27uXq">With the rapid growth of interest in and use of large language models (LLMs) across various industries, we are facing some crucial and profound ethical concerns, especially in the medical field.</s><s xml:id="_GJ8gSfr">The unique technical architecture and purported emergent abilities of LLMs differentiate them substantially from other artificial intelligence (AI) models and natural language processing techniques used, necessitating a nuanced understanding of LLM ethics.</s><s xml:id="_MBFQWzn">In this Viewpoint, we highlight ethical concerns stemming from the perspectives of users, developers, and regulators, notably focusing on data privacy and rights of use, data provenance, intellectual property contamination, and broad applications and plasticity of LLMs.</s><s xml:id="_psUytvy">A comprehensive framework and mitigating strategies will be imperative for the responsible integration of LLMs into medical practice, ensuring alignment with ethical principles and safeguarding against potential societal risks.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="799.37"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="799.37"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="799.37"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="799.37"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="799.37"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_g9GUzUe">Introduction</head><p xml:id="_EngH4D9"><s xml:id="_8ev4MCd">In the wake of ChatGPT's public release, over a thousand prominent computer scientists and technology industry experts, including Elon Musk and Steve Wozniak, took the unprecedented step of signing a letter calling for an immediate 6-month pause on AI.</s><s xml:id="_VWw5PXR">They argued that the current trajectory of generative AI development had spiralled "out-of-control", posing "profound risks to society". <ref type="bibr" target="#b0">1</ref> Despite objections, the medical fraternity continued the pursuit of scaling-up generative AI research and integration into medicine.</s><s xml:id="_V5CsPXS">Archetypal discussions on AI ethics in medicine revolves around poor model accuracy for users not represented in the training data, transparency of models and model-building, accountability for model output, potential model bias, and risk for privacy and confidentiality breaches. <ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3</ref></s><s xml:id="_Nhqap5d">owever, these concerns fail to fully capture distinctive concerns posed by LLMs.</s></p><p xml:id="_gYD58Wt"><s xml:id="_6BHt2Xa">In this context, we find ourselves in a situation that mirrors the classic Collingridge dilemma: "Attempting to control a technology is difficult…because during its early stages, when it can be controlled, not enough can be known about its harmful social consequences to warrant controlling its development; but by the time these consequences are apparent, control has become costly and slow." <ref type="bibr" target="#b3">4</ref> This dilemma can be viewed as a problem of pacing-although technology development advances rapidly, governance and regulation lags behind.</s><s xml:id="_N5y74A9">To effectively regulate LLMs, grasping the fundamental ethical issues inherent in their design and use is crucial. 1 year after the release of ChatGPT, we now have a better understanding of the limitations and risks the technology poses.</s><s xml:id="_k3jVxwY">LLMs differ substantially from AI-based technologies that are already regulated, creating unique regulatory hurdles: (1) data privacy and rights of use associated with training on massive datasets sourced from the internet; <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6</ref> (2) data provenance, intellectual property contamination, and the uncertainty about the data derivatives that could hamper the accuracy of output; and (3) the so-called plastic nature of LLMs that allows for dynamic learning and evolution of LLM applications based on user inputs and changing clinical contexts (table).</s><s xml:id="_CPqvSBW">The broad use of LLM-based models across different industries limit the utility of a single governing framework.</s><s xml:id="_HQkbkPv">Identification and audit of the societal risks posed by LLM-based models becomes challenging because the precise mechanisms of their tuning or modifications remain opaque. <ref type="bibr" target="#b6">7</ref></s><s xml:id="_593zuQp">In this Viewpoint, we discuss these important peculiarities to position LLMs in the large literature on the ethics of AI.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_dAdG68b">Data privacy and data rights of use</head><p xml:id="_veVBM7T"><s xml:id="_RfDm47a">The development and deployment of LLM models challenge the boundaries of data privacy regulations.</s><s xml:id="_76fXsUg">When identifiable patient data are used during training, there is potential risk that these models inadvertently memorise and disclose sensitive information in the absence of proper security measures.</s><s xml:id="_MU8nHvs">The use of patient information for LLM pre-training without obtaining explicit informed consent contravenes rights-of-data policies. <ref type="bibr" target="#b7">8</ref></s><s xml:id="_62c6Hnx">In addition, data breach of sensitive patient information can occur after adversarial attacks, <ref type="bibr" target="#b6">7</ref> and the re-identification of even anonymised medical data is now possible with few spatiotemporal datapoints. <ref type="bibr" target="#b8">9</ref></s><s xml:id="_NdgvDNu"> greater effort is needed to enhance data privacy and security of LLM-based models.</s><s xml:id="_87btcvm">Clinical LLM models trained with patient information should undergo rigorous cross-examination before implementation 10 as a form of penetration test.</s><s xml:id="_etUTxD2">Cybersecurity measures, such as the use of pseudonyms implementing differential privacy techniques, could be used to counteract the risks of malicious attacks and data poisoning through deliberate adversarial prompting.</s><s xml:id="_wgfqsQv">Preliminary studies have suggested that LLMs can be taught to shield or protect specific categories of personal information under simulated scenarios. <ref type="bibr" target="#b10">11</ref></s><s xml:id="_APVBXVu">What is currently absent are benchmark approaches that effectively measure the balance between privacy and the utility of LLMs.</s><s xml:id="_sqahPVT">This benchmarking would help in evaluating the models' ability to maintain confidentiality while still delivering valuable outputs in a controlled environment.</s><s xml:id="_C29NnvC">In addition, such benchmarking and evaluation tools will need to take on a multimodal approach, given that a multimodal LLM capable of integrating different inputs of text, images, and audio is fast gaining traction in medical applications. <ref type="bibr" target="#b11">12</ref></s><s xml:id="_P4vns5s">oving forward, data protection regulations and guidance will need to take on a more pragmatic approach to avoid placing a hard stop on LLM development and implementation.</s><s xml:id="_5GKhU9F">For example, the use of a tiered approach based on classification of training and input data: public, internal (eg, non-patient data, information, or intellectual property for which there are proprietary interest or contractual obligations), confidential (eg, deidentified or anonymised patient data), and restricted data (eg, identifiable patient data).</s><s xml:id="_sQS6MUw">Data security and information technology infrastructural requirements will differ between different data risk categories (eg, airgap environment for high-risk tiers).</s><s xml:id="_xqHqwRA">Patients should provide broad informed consent to share data, and should be proactively educated on rights of data, such as right to access, right to erasure, and right to limit data processing.</s><s xml:id="_vreqRMq">However, in the event whereby the classification of training data is unclear because of an absence of transparency, regulators will need to weigh between the potential risks of data breach and the benefits that the LLM-based model can bring to the general population.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7ebqMmH">Data provenance and intellectual property contamination</head><p xml:id="_5k992JZ"><s xml:id="_DSh4f6e">The provenance of data refers to the origins, custody, and ownership of the information used to train these models.</s><s xml:id="_Qhh4Ers">When LLMs ingest massive amounts of data from various sources, some of this content might be used without proper licensing despite being protected by intellectual property laws.</s><s xml:id="_YMjmkqt">Additionally, users might inadvertently prompt these models with references to copyrighted or trademarked works, raising questions about the legality and ethics of generating outputs derived from copyrighted or patented inputs.</s><s xml:id="_HEmuqH3">Regulatory rules can be implemented to restrict LLM training on appropriately licensed datasets, but this poses risk to the development, refinement, and maturation of technical standards.</s></p><p xml:id="_GGztavK"><s xml:id="_V6m688S">We encourage developers to maintain transparency when describing the training datasets used in developing LLM-based models when possible, including the source, quantity, and diversity of data. <ref type="bibr" target="#b12">13</ref></s><s xml:id="_DeQ6kkQ">One of the key factors contributing to the accuracy of LLMs is their large-scale pre-training on vast amounts of text data from diverse sources.</s><s xml:id="_wcujquk">However, the accuracy can also be influenced by biases present in the training data, the quality of the input data, and the inherent limitations of the model architecture.</s><s xml:id="_GBx8Can">Unlike other AI models, common techniques used to mitigate AI model bias, such as data resampling, prejudice removal, or subgroup modelling, cannot be easily adopted for LLM-based models.</s><s xml:id="_h4CZCvc">There is an absence of robust quantification on the amplification effect of model bias when building fine-tuned models on general-purpose ones.</s><s xml:id="_c2NtMRW">Water marking techniques seek to address concerns over originality and ownership through embedding a mark into AI-generated content before its release, <ref type="bibr" target="#b13">14</ref> albeit the robustness of such techniques has been challenged.</s><s xml:id="_PSMPe3N">Work is underway to evaluate feasibility of unlearning in LLMs <ref type="bibr" target="#b14">15</ref> to enable models to be updated to comply with updated legislation and data protection standards.</s><s xml:id="_gewU3vb">The techniques present as potential stop-gap measures.</s><s xml:id="_rQjHhhP">However, to comprehensively address this issue, we will most likely need a paradigm shift in current market structures, incentivisation, and reimbursement strategies for LLM-based models or LLM-incorporated medical devices.</s><s xml:id="_sfAjaCM">Segal and colleagues <ref type="bibr" target="#b15">16</ref> proposed a decentralised or blockchainbased, token economy-based market for medical research and publishing.</s><s xml:id="_SnwmkA8">Purported benefits of this blockchain-based platform include data and workflow transparency, immutability of original work, the minimisation of fraud, and incentivisation of reviewers through token payments.</s><s xml:id="_UnW45vQ">Such endeavours need prospective research and review to evaluate the feasibility of scaling.</s></p><p xml:id="_tkGxKXf"><s xml:id="_JfXNdxt">Developers and LLM researchers Regulators and governance bodies Data privacy and data rights of use Have a greater focus on: the cross examination of LLM-based models for risk of data breach; penetration tests for adversarial attacks; the development of benchmarks to evaluate the privacy vs utility trade-off; and validation frameworks for multimodal LLM evaluation Use a pragmatic, tiered approach to regulation based on the sensitivity of data used in training and inputs into LLM; evaluate data security measures required in accordance with data risk category Data provenance and contamination of intellectual property Promote transparency in training datasets used, including source, quality, and quantity; conduct conceptualisation, testbed, and prospective reviews of new market structures A generative AI take on fair use doctrine Broad applications and plasticity of LLMs Develop benchmarking frameworks and risk-assessment methodologies (eg, quality improvement and failure modes and effects analysis): highlight high-risk areas of harm, including quantification of hallucinations, reproducibility of output, and bias; enforce prospective and continuous stewardship Create sandbox environments, taking on an iterative approach to the development of regulatory guidance on the basis of new knowledge</s></p><p xml:id="_FvayxvP"><s xml:id="_5j9jcmf">Users and consumers (ie, the clinicians and their patients) must be familiarised with the rights of data (ie, right of access, right to rectification, right to erasure, right to restrict processing, right to data portability, right to object, right to not be subject to decisions based solely on automated processing).</s><s xml:id="_8qSAYWb">LLM=large language model.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gtcubC3">Table: Ethical concerns relating to framework and mitigating strategies for responsible development and use of LLMs in medicine</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_wd7ZCHZ">Viewpoint</head><p xml:id="_tTEyK5K"><s xml:id="_8dVVTrh">The fair use doctrine is a legal framework promoting freedom of expression through permitting unlicensed use of copyright-protected works under specific circumstances. <ref type="bibr">17</ref></s><s xml:id="_HGwS2Ph">Regulators can apply principles of the fair use doctrine for generative AI-based models developed for medical uses (panel).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cPs4BuF">Broad applications and plasticity of LLMs</head><p xml:id="_xrUB42f"><s xml:id="_bwZsvMd">The potential applications of LLMs in medicine can be broad ranging and heterogeneous.</s><s xml:id="_EPUZySp">LLMs facilitate research by summarising texts and extracting key points from published literature, enhance medical education through data synthesis and interactive learning, and improve clinical tasks by streamlining administrative efforts and supporting decision making. <ref type="bibr" target="#b1">2</ref> The industry is exploring the performance of medical chatbots in assisting patient care, counselling, expressing empathy, and providing information about health recommendations.</s><s xml:id="_feKYuj5">These broad and varied applications of LLMs in medicine mean that a single governing framework for their use is impractical.</s><s xml:id="_XtBM5Wp">In addition, the plastic nature of LLMs allows for dynamic learning and continuous evolution based on user inputs and changing clinical contexts.</s><s xml:id="_fX5ZNSy">Much like neuroplasticity of the human brain, <ref type="bibr" target="#b19">21</ref> LLMs are capable of changing characteristics of its response to stimuli, such as different prompting strategies or different fine-tuning data inputs.</s><s xml:id="_Sd2hNEA">Drawing parallels to human neuroplasticity, structural or functional changes to LLMs can be positive (eg, enhanced personalisation of response through active reinforcement learning) or negative (eg, through propagation of inherent bias and so-called AI hallucinations).</s><s xml:id="_drxaEHp">The identification and audit of the societal risks posed by LLM-based models becomes challenging as the precise mechanisms of their tuning or modifications remain opaque-known as the black-box nature of LLMs. <ref type="bibr" target="#b20">22</ref></s><s xml:id="_enKFCNh">here is an urgent need to develop robust frameworks for evaluating LLM-based models for medicine to mitigate the risks discussed in this Viewpoint.</s><s xml:id="_UezEadw">Such a framework can incorporate clear assessment methodologies before implementation, such as quality improvement <ref type="bibr" target="#b21">23</ref> and failure modes and effects analysis, <ref type="bibr" target="#b22">24</ref> to identify and mitigate potential risks and harms.</s><s xml:id="_R9dxpNZ">The evaluation of LLM-based models for medicine in areas of high risk is of utmost importance: the propagation of bias or discrimination, the quantification and reduction of AI hallucinations, and the reproducibility of the model outputs.</s><s xml:id="_phbFXEg">Tech niques such as retrieval-augmented generation can help in minimising harm and bolstering the self-consistency of responses by cross-referencing with reliable data sources. <ref type="bibr" target="#b23">25</ref></s><s xml:id="_mcsXN3u">Bias evaluation is another crucial aspect, whereby assessment checklists and benchmarking frameworks are applicable.</s><s xml:id="_XM8SwAF">In one study, published as a preprint, authors developed a generative AI assessment checklist specific to models developed for medical indications. <ref type="bibr" target="#b24">26</ref></s><s xml:id="_g2T5jFK">Continuous stewardship after deployment is essential to address any emergent biases or model drifts. <ref type="bibr" target="#b25">27</ref></s><s xml:id="_UFbScBg">Regulatory bodies can take on a proactive role through the creation of sandbox environments to allow exploration, inte raction, and evaluation of LLM-based applications without compromising on security and can mitigate risks to patient safety. <ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b27">29</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_J8KujFh">Conclusion</head><p xml:id="_VpCcQR5"><s xml:id="_Fc7jubp">The rapid advancement of LLMs in the medical field has ushered in a new era of technological capabilities alongside complex ethical and regulatory considerations.</s><s xml:id="_fTJTzyd">Such challenges are unique to LLM-based models as opposed to conventional machine-learning or deep-learning-based models.</s><s xml:id="_uQeEv4t">Developers and regulatory bodies need to work in tandem to encompass the multifaceted nature of LLMs, ensuring data protection without stifling innovation.</s><s xml:id="_5XY5qzh">As we navigate these challenges, a balanced</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rTrPQdx">Panel: Fair use doctrine principles</head><p xml:id="_HXeBt3j"><s xml:id="_497A94r">When evaluating fair use, the fair use doctrine calls for:</s></p><p xml:id="_FVswAPt"><s xml:id="_2BXBd3N">(1) Purpose and character of use Describes the intended use of original material, whether for commercial or not-for-profit use.</s><s xml:id="_fb3kz9r">Highly transformative applications that repurpose the use of the material and cannot be substituted by the original work.</s><s xml:id="_XftckJ7">Generalist LLMs, such as ChatGPT, are trained on highly diverse datasets, <ref type="bibr" target="#b16">18</ref> much of which is probably for non-medical intents.</s><s xml:id="_9rHpxU4">LLMbased medical applications with clearly defined attributes might hence be considered as transformative solutions, work that is largely repurposed from its original material.</s></p><p xml:id="_jnfzabT"><s xml:id="_CAyV8TE">(2) Nature of the original work The use of a creative or imaginative work, such as novels or movies, is less likely to support a claim of fair use than the use of factual work.</s><s xml:id="_KyFPmrP">Although creative industries such as art and music encourage imagination and originality, the practice of medicine thrives upon an evidence-based approach grounded on factual information that is more likely to be considered fair use.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_F5ftnh9">(3) Amount and substantiality of original material used</head><p xml:id="_nmWUjP3"><s xml:id="_KR3q5gF">The black-box nature of LLMs (ie, the input and output is known to users, but the internal mechanisms remain unknown) render this evaluation highly challenging.</s><s xml:id="_w9hRShg">Uncertainty over data derivatives and data provenance pose a barrier to accurate quantification of original material used.</s><s xml:id="_VBAaxgB">Foundation models pre-trained on clinical information <ref type="bibr" target="#b17">19</ref> present with a clearer definition on data lineage.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_bpFnMQ5">(4) Effect of use upon the potential market for, or value of, copyrighted work</head><p xml:id="_RSSJ2ss"><s xml:id="_qvnvGPK">The extent to which unlicensed use of the original work harms the existing or future market for copyrighted owners' original work.</s><s xml:id="_y2xmKcm">LLM-based applications that are developed for specific medical purposes might be regulated as medical devices. <ref type="bibr" target="#b18">20</ref></s><s xml:id="_xNWPRwa">iewpoint approach that fosters innovation while upholding ethical standards will be essential for the responsible integration of LLMs into medical practice.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_yBn2phN">Contributors</head><p xml:id="_X8BahCu"><s xml:id="_D7UTj76">DSWT formulated the direction of the article.</s><s xml:id="_m3kreMm">JCLO and SY-HC led the literature search and manuscript writing.</s><s xml:id="_PuQ4jV6">The manuscript was revised and finetuned by WW, AJB, NHS, LSTC, NL, FD-V, WL, JS, DSWT, and finalised by JCLO and SY-HC.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_SRWvqCT">Declaration of interests</head><p xml:id="_yGFtG3Q"><s xml:id="_R3PNszF">DSWT holds patents on a deep-learning system for the detection of retinal diseases.</s><s xml:id="_JVeGbXZ">AJB is a cofounder and consultant for Personalis and NuMedii; is a consultant to Mango Tree Corporation; has previously been a consultant for Samsung, 10x Genomics, Helix, Pathway Genomics, and Verinata (Illumina); has served on paid advisory panels or boards for Geisinger Health, Regenstrief Institute, Gerson Lehman Group, AlphaSights, Covance, Novartis, Genentech, and Merck, and Roche; is a shareholder in Personalis and NuMedii; is a minor shareholder in Apple, Meta (Facebook), Alphabet (Google), Microsoft, Amazon, Snap, 10x Genomics, Illumina, Regeneron, Sanofi, Pfizer, Royalty Pharma, Moderna, Sutro, Doximity, BioNtech, Invitae, Pacific Biosciences, Editas Medicine, Nuna Health, Assay Depot, and Vet24seven, and several other non-health related companies and mutual funds; has received honoraria and travel reimbursement for invited talks from Johnson and Johnson, Roche, Genentech, Pfizer, Merck, Lilly, Takeda, Varian, Mars, Siemens, Optum, Abbott, Celgene, AstraZeneca, AbbVie, Westat, and many academic institutions, medical-specific or disease-specific foundations and associations, and health systems; receives royalty payments through Stanford University for several patents and other disclosures licensed to NuMedii and Personalis; has done research funded by NIH, Peraton (as the prime on an NIH contract), Genentech, Johnson and Johnson, FDA, Robert Wood Johnson Foundation, Leon Lowenstein Foundation, Intervalien Foundation, Priscilla Chan and Mark Zuckerberg, and the Barbara and Gerson Bakar Foundation; and has previously done research funded by the March of Dimes, Juvenile Diabetes Research Foundation, California Governor's Office of Planning and Research, California Institute for Regenerative Medicine, L'Oreal, and Progenity.</s><s xml:id="_yRQDDbN">NL is a scientific advisor to TIIM SG.</s><s xml:id="_khu84bq">NHS is a cofounder of Prealize Health (a predictive analytics company) and Atropos Health (an on-demand evidence generation company);</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_6Fyauku">Search strategy and selection criteria</head><p xml:id="_vwjGvjq"><s xml:id="_UkkvMmT">We included original papers, reviews, narratives, correspondences, perspectives, and viewpoints identified through searches of PubMed and arXiv from Jan 1, 2020, to Aug 10, 2023, using the search terms ("natural language processing" OR "generative adversarial network" OR "generative model" OR "generative artificial intelligence" OR "generative AI" OR "transformer model" OR "reinforcement learning" OR "large language model" OR "LLM" OR "foundation model" OR "recurrent neural network" OR "RNN" OR "bidirectional encoder representations from transformers" OR "generative pretrained transformer" OR "ChatGPT" OR "Chat Generative Pre-training Transformer" OR "LLaMA" OR "Large Language Model Meta AI" OR "Pathways Language Model") AND ("ethics" OR "bioethics" OR "medical ethics" OR "regulation" OR "regulatory").</s><s xml:id="_RyGfEF2">We excluded publications that did not mention or discuss ethical issues.</s><s xml:id="_4jHcVp2">37 of 998 articles from the search on PubMed and 21 of 668 articles on arXiv were relevant to the topics and eligible for our study.</s><s xml:id="_QVE7MDQ">Only papers published in English were reviewed.</s></p><p xml:id="_e59SCe9"><s xml:id="_x4xPPST">receives funding from the Gordon and Betty Moore Foundation for developing virtual model deployments; and is a member of working groups of the Coalition for Health AI (CHAI), a consensus-building organisation providing guidelines for the responsible use of artificial intelligence in health care.</s><s xml:id="_c7SxSg7">JS, through his involvement with the Murdoch Children's Research Institute, receives funding from the Victorian State Government through the Operational Infrastructure Support (OIS) programme.</s><s xml:id="_hS42kQU">JCLO is supported by grants from the National Medical Research Council Singapore (MOH-CIAINV21nov-001) and AI Singapore OTTIC (AISG2-TC-2022-006).</s><s xml:id="_UFAjAFX">All other authors declare no competing interests.</s></p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_qUUevBr"><s xml:id="_BdJGVS8">www.thelancet.com/digital-health</s><s xml:id="_dAUWVj2">Vol 6 June 2024</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_vmtdR2H">Acknowledgments</head><p xml:id="_F3hTrVw"><s xml:id="_WZ6wJYr">This research project is supported by <rs type="funder">National University of Singapore</rs> under the <rs type="grantName">NUS Start-Up grant</rs>; <rs type="grantNumber">NUHSRO/2022/078/Startup/13</rs>.</s><s xml:id="_aFpJKau">This research was funded in part by the <rs type="funder">Wellcome Trust</rs> (<rs type="grantNumber">WT203132/Z/16/Z</rs>).</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_E3NEgh9">
					<idno type="grant-number">NUHSRO/2022/078/Startup/13</idno>
					<orgName type="grant-name">NUS Start-Up grant</orgName>
				</org>
				<org type="funding" xml:id="_WVdjMq9">
					<idno type="grant-number">WT203132/Z/16/Z</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main" xml:id="_rjAtb7k">Elon Musk and others call for pause on AI, citing profound risks to society</title>
		<author>
			<persName><forename type="first">C</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schmidt</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html" />
		<imprint>
			<date type="published" when="2023-03-29">March 29, 2023. July 25, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Metz C, Schmidt G. Elon Musk and others call for pause on AI, citing profound risks to society. March 29, 2023. https://www. nytimes.com/2023/03/29/technology/ai-artificial-intelligence- musk-risks.html (accessed July 25, 2023).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_mCuxH49">Large language models in medicine</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Thirunavukarasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dsj</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Elangovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dsw</forename><surname>Ting</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-023-02448-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_p6aJRJb">Nat Med</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1930" to="1940" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med 2023; 29: 1930-40.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_uZFvZAt">ChatGPT in society: emerging issues</title>
		<author>
			<persName><forename type="first">M</forename><surname>Farina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lavazza</surname></persName>
		</author>
		<idno type="DOI">10.3389/frai.2023.1130913</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Pb4eq5g">Front Artif Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1130913</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Farina M, Lavazza A. ChatGPT in society: emerging issues. Front Artif Intell 2023; 6: 1130913.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_w6YfaZY">Collingridge and the dilemma of control: towards responsible and accountable innovation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Genus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stirling</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.respol.2017.09.012</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gDgEqmC">Res Policy</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="61" to="69" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Genus A, Stirling A. Collingridge and the dilemma of control: towards responsible and accountable innovation. Res Policy 2018; 47: 61-69.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_9yGjxa9">The imperative for regulatory oversight of large language models (or generative AI) in healthcare</title>
		<author>
			<persName><forename type="first">B</forename><surname>Meskó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-023-00873-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HgV5gcN">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meskó B, Topol EJ. The imperative for regulatory oversight of large language models (or generative AI) in healthcare. NPJ Digit Med 2023; 6: 120.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_MwvKgt7">The challenges for regulating medical use of ChatGPT and other large language models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vayena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2023.9651</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Wy7PavR">JAMA</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="page" from="315" to="316" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Minssen T, Vayena E, Cohen IG. The challenges for regulating medical use of ChatGPT and other large language models. JAMA 2023; 330: 315-16.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_bUEJxZn">Auditing large language models: a three-layered approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mökander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schuett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-023-00289-2</idno>
		<ptr target="https://doi.org/10.1007/s43681-023-00289-2" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_fgJtynn">AI Ethics</title>
		<imprint>
			<date type="published" when="2023-05-30">2023. May 30</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mökander J, Schuett J, Kirk HR, Floridi L. Auditing large language models: a three-layered approach. AI Ethics 2023; published online May 30. https://doi.org/10.1007/s43681-023-00289-2.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<idno type="DOI">10.1201/9781138069848-14</idno>
		<ptr target="https://edps.europa.eu/data-protection/our-work/subjects/rights-individual_en" />
		<title level="m" xml:id="_YPUe62p">Rights of the individual</title>
		<imprint>
			<publisher>European Data Protection Supervisor</publisher>
			<date type="published" when="2023-10-26">2023. Oct 26, 2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">European Data Protection Supervisor. Rights of the individual. 2023. https://edps.europa.eu/data-protection/our-work/subjects/ rights-individual_en (accessed Oct 26, 2023).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_QpzhaBs">A governance model for the application of AI in health care</title>
		<author>
			<persName><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Coghlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cooper</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocz192</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TqAJsY7">J Am Med Inform Assoc</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="491" to="497" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Reddy S, Allan S, Coghlan S, Cooper P. A governance model for the application of AI in health care. J Am Med Inform Assoc 2020; 27: 491-97.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_FXbxgWx">Artificial intelligence-based ethical hacking for health information systems: simulation study</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yevseyeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nkKcgmB">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">41748</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">He Y, Zamani E, Yevseyeva I, Luo C. Artificial intelligence-based ethical hacking for health information systems: simulation study. J Med Internet Res 2023; 25: e41748.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_AwbUf2F">Can language models be instructed to protect personal information?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2310.02224</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2310.02224" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_pzjfByz">arXiv</title>
		<imprint>
			<date type="published" when="2023-10-03">2023. Oct 3</date>
		</imprint>
	</monogr>
	<note>preprint</note>
	<note type="raw_reference">Chen Y, Mendes E, Das S, Xu W, Ritter A. Can language models be instructed to protect personal information? arXiv 2023; published online Oct 3. https://doi.org/10.48550/arXiv.2310.02224 (preprint).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_W8jJCXd">The impact of multimodal large language models on health care&apos;s future</title>
		<author>
			<persName><forename type="first">B</forename><surname>Meskó</surname></persName>
		</author>
		<idno type="DOI">10.2196/52865</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZCvW4zF">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">52865</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meskó B. The impact of multimodal large language models on health care&apos;s future. J Med Internet Res 2023; 25: e52865.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_D24rFCZ">Minimum information about clinical artificial intelligence modeling: the MI-CLAIM checklist</title>
		<author>
			<persName><forename type="first">B</forename><surname>Norgeot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Beaulieu-Jones</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-020-1041-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KCBfyEU">Nat Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1320" to="1324" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Norgeot B, Quer G, Beaulieu-Jones BK, et al. Minimum information about clinical artificial intelligence modeling: the MI-CLAIM checklist. Nat Med 2020; 26: 1320-24.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_USVcWnr">A novel model watermarking for protecting generative adversarial network</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yuyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cose.2023.103102</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zRWvysE">Comput Secur</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page">103102</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Qiao T, Yuyan M, Ning Z, et al. A novel model watermarking for protecting generative adversarial network. Comput Secur 2023; 127: 103102.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_kqpcHBy">Machine unlearning for generative AI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Viswanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jamthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lokiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bianchini</surname></persName>
		</author>
		<idno type="DOI">10.69554/kzrs2422</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_j6pzjMw">Journal of AI, Robotics &amp; Workplace Automation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Viswanath Y, Jamthe S, Lokiah S, Bianchini E. Machine unlearning for generative AI. Journal of AI, Robotics &amp; Workplace Automation 2024; 10: 37-46.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_n8vmy9T">A blockchain-based computerized network infrastructure for the transparent, immutable calculation and dissemination of quantitative, measurable parameters of academic and medical research publications</title>
		<author>
			<persName><forename type="first">G</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Martisiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Markinzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Halperin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zimlichman</surname></persName>
		</author>
		<idno type="DOI">10.1177/20552076231194851</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NFzjrca">Digit Health</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">20552076231194851</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Segal G, Martisiano Y, Markinzon A, Mayer A, Halperin A, Zimlichman E. A blockchain-based computerized network infrastructure for the transparent, immutable calculation and dissemination of quantitative, measurable parameters of academic and medical research publications. Digit Health 2023; 9: 20552076231194851.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_ufDGeg2">Peer review of GPT-4 technical report and systems card</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gallifant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fiske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Levites</forename><surname>Strekalova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000417</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GsNHkXD">PLOS Digit Health</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">e0000417</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>Viewpoint</note>
	<note type="raw_reference">Gallifant J, Fiske A, Levites Strekalova YA, et al. Peer review of GPT-4 technical report and systems card. PLOS Digit Health 2024; 3: e0000417. Viewpoint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_GcQayxv">Foundation models for generalist medical artificial intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Abad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">S</forename></persName>
		</author>
		<idno type="DOI">10.1038/s41586-023-05881-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ButFJa9">Nature</title>
		<imprint>
			<biblScope unit="volume">616</biblScope>
			<biblScope unit="page" from="259" to="265" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moor M, Banerjee O, Hossein Abad ZS, et al. Foundation models for generalist medical artificial intelligence. Nature 2023; 616: 259-65.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_s9QCe59">Regulatory responses to medical machine learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aboy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1093/jlb/lsaa002</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_drq3F8D">J Law Biosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Minssen T, Gerke S, Aboy M, Price N, Cohen G. Regulatory responses to medical machine learning. J Law Biosci 2020; 7: lsaa002.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Puderbaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Emmady</surname></persName>
		</author>
		<idno type="DOI">10.3998/mpub.11373292.cmp.2587</idno>
		<title level="m" xml:id="_4KfQHtq">Neuroplasticity</title>
		<meeting><address><addrLine>Treasure Island, FL</addrLine></address></meeting>
		<imprint>
			<publisher>StatPearls Publishing</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Puderbaugh M, Emmady PD. Neuroplasticity. Treasure Island, FL: StatPearls Publishing, 2023.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_S6YBrTk">ChatGPT is a black box: how AI research can break it open</title>
		<author>
			<persName><surname>Nature</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wJQN5fc">Nature</title>
		<imprint>
			<biblScope unit="volume">619</biblScope>
			<biblScope unit="page" from="671" to="672" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nature. ChatGPT is a black box: how AI research can break it open. Nature 2023; 619: 671-72.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_4ktjwsD">Clinical artificial intelligence quality improvement: towards continual monitoring and updating of AI algorithms in healthcare</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Malenica</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-022-00611-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_46sq6C9">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">66</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Feng J, Phillips RV, Malenica I, et al. Clinical artificial intelligence quality improvement: towards continual monitoring and updating of AI algorithms in healthcare. NPJ Digit Med 2022; 5: 66.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_QnG5rJ3">The medical algorithmic audit</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mccradden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Denniston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Oakden-Rayner</surname></persName>
		</author>
		<idno type="DOI">10.1016/s2589-7500(22)00003-6</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kSQytP9">Lancet Digit Health</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="384" to="397" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu X, Glocker B, McCradden MM, Ghassemi M, Denniston AK, Oakden-Rayner L. The medical algorithmic audit. Lancet Digit Health 2022; 4: e384-97.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_f4C9p2E">Development of a liver disease-specific large language model chat interface using retrieval augmented generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Owens</surname></persName>
		</author>
		<idno type="DOI">10.1097/hep.0000000000000834</idno>
		<ptr target="https://doi.org/10.1097/HEP.0000000000000834" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_USku76f">Hepatology</title>
		<imprint>
			<date type="published" when="2024-03-07">2024. March 7</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ge J, Sun S, Owens J, et al. Development of a liver disease-specific large language model chat interface using retrieval augmented generation. Hepatology 2024; published online March 7. https://doi. org/10.1097/HEP.0000000000000834.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main" xml:id="_3Vwk4kn">Generative artificial intelligence in healthcare: ethical considerations and assessment checklist</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teixayavong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2311.02107</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2311.02107" />
		<imprint>
			<date type="published" when="2023-11-02">2023. Nov 2</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
	<note>preprint</note>
	<note type="raw_reference">Ning Y, Teixayavong S, Shang Y, et al. Generative artificial intelligence in healthcare: ethical considerations and assessment checklist. arXiv 2023; published online Nov 2. https://doi. org/10.48550/arXiv.2311.02107 (preprint).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_nm8uGA2">The case for algorithmic stewardship for artificial intelligence and machine learning technologies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Eaneff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Butte</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2020.9371</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YRuvDHk">JAMA</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="1397" to="1398" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Eaneff S, Obermeyer Z, Butte AJ. The case for algorithmic stewardship for artificial intelligence and machine learning technologies. JAMA 2020; 324: 1397-98.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main" xml:id="_NN49MrJ">Harvard designs AI sandbox that enables exploration, interaction without compromising security</title>
		<idno type="DOI">10.1093/ww/9780199540884.013.u242658</idno>
		<ptr target="https://news.harvard.edu/gazette/story/newsplus/harvard-designs-ai-sandbox-that-enables-exploration-interaction-without-compromising-security/" />
		<imprint>
			<date type="published" when="2023-09-26">Sept 26, 2023. Sept 26, 2023</date>
			<publisher>Harvard Gazette</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Harvard Gazette. Harvard designs AI sandbox that enables exploration, interaction without compromising security. Sept 26, 2023. https://news.harvard.edu/gazette/story/newsplus/ harvard-designs-ai-sandbox-that-enables-exploration-interaction- without-compromising-security/ (accessed Sept 26, 2023).</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main" xml:id="_rN83vBp">First of its kind generative AI evaluation sandbox for trusted AI by AI Verify Foundation and IMDA</title>
		<idno type="DOI">10.1007/978-1-4842-9367-6_6</idno>
		<ptr target="https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/press-releases/2023/generative-ai-evaluation-sandbox" />
		<imprint>
			<date type="published" when="2023-10-31">Oct 31, 2023. Nov 1, 2023</date>
		</imprint>
		<respStmt>
			<orgName>Infocomm Media Development Authority</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Infocomm Media Development Authority. First of its kind generative AI evaluation sandbox for trusted AI by AI Verify Foundation and IMDA. Oct 31, 2023. https://www.imda.gov.sg/ resources/press-releases-factsheets-and-speeches/press- releases/2023/generative-ai-evaluation-sandbox (accessed Nov 1, 2023).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
