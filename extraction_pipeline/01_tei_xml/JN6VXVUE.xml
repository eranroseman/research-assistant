<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_bdRD4Tr">A new method for computing the projection median, its influence curve and techniques for the production of projected quantile plots</title>
				<funder ref="#_9wu3zVJ">
					<orgName type="full">Engineering and Physical Sciences Research Council</orgName>
					<orgName type="abbreviated">EPSRC</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100000266</idno>
				</funder>
				<funder>
					<orgName type="full">University of Bristol/China Scholarship Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
					<p type="raw">© 2020 Chen, Nason. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
				</availability>
				<date type="published" when="2020-05-07">May 7, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fan</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> School of Mathematics , University of Bristol , Fry Building , Woodland Road , Bristol , England , United Kingdom ,</note>
								<orgName type="department">School of Mathematics</orgName>
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<addrLine>Fry Building Woodland Road</addrLine>
									<settlement>Bristol</settlement>
									<country>England United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Guy</forename><surname>Nason</surname></persName>
							<email>g.nason@imperial.ac.uk</email>
							<idno type="ORCID">0000-0002-4664-3154</idno>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Dept. Mathematics , Imperial College , London , England , United Kingdom</note>
								<orgName type="department">Dept. Mathematics</orgName>
								<orgName type="institution">Imperial College</orgName>
								<address>
									<settlement>London</settlement>
									<country>England United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<note type="raw_affiliation">Huazhong University of Science and Technology , CHINA</note>
								<orgName type="institution">Huazhong University of Science and Technology</orgName>
								<address>
									<country key="CN">CHINA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_KQd2buT">A new method for computing the projection median, its influence curve and techniques for the production of projected quantile plots</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-05-07">May 7, 2020</date>
						</imprint>
					</monogr>
					<idno type="MD5">A6627B860A96181D83670988050E19DC</idno>
					<idno type="DOI">10.1371/journal.pone.0229845</idno>
					<note type="submission">Received: August 6, 2019 Accepted: February 15, 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T10:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_9SMbf9r"><p xml:id="_EGYXrqE"><s xml:id="_9dk6TMs">This article introduces a new formulation of, and method of computation for, the projection median.</s><s xml:id="_PJfcSf8">Additionally, we explore its behaviour on a specific bivariate set up, providing the first theoretical result on form of the influence curve for the projection median, accompanied by numerical simulations.</s><s xml:id="_RP2BUWY">Via new simulations we comprehensively compare our performance with an established method for computing the projection median, as well as other existing multivariate medians.</s><s xml:id="_2ySEAH2">We focus on answering questions about accuracy and computational speed, whilst taking into account the underlying dimensionality.</s><s xml:id="_6hDxZ6Q">Such considerations are vitally important in situations where the data set is large, or where the operations have to be repeated many times and some well-known techniques are extremely computationally expensive.</s><s xml:id="_2Y7uDdX">We briefly describe our associated R package that includes our new methods and novel functionality to produce animated multidimensional projection quantile plots, and also exhibit its use on some high-dimensional data examples.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" xml:id="_9dSuTw6">Introduction: Overview of multivariate medians</head><p xml:id="_Sq8nFyK"><s xml:id="_fgYw3sk">The median is an estimator of location that is robust, i.e. not heavily influenced by outlying values, which are, loosely speaking, points that are far from the main body of the data.</s><s xml:id="_FKnxbk9">Let x = (x 1 , . .</s><s xml:id="_6azTVJr">., x k ) T be a mutually independent and identically distributed (i.i.d.) sample of length k 2 N from a univariate distribution with distribution function F. The univariate population median functional M(F) is</s></p><formula xml:id="formula_0">MðFÞ ¼ inf fx : FðxÞ � 1=2g ¼ sup fx : FðxÞ � 1=2g:<label>ð1Þ</label></formula><p xml:id="_SSEUhcJ"><s xml:id="_y466jMd">There are several equivalent definitions of the univariate median that all yield same unique value of true median μ for a distribution F with a bounded and continuous density f(μ) at μ.</s></p><p xml:id="_VfEX3j5"><s xml:id="_Npyf92U">For multivariate data there is no natural ordering of the data to enable the choice of the middle observation in the same way as for one-dimensional data.</s><s xml:id="_zUCPFkN">However, several different multivariate median concepts have been developed that retain some characteristics of the univariate median.</s><s xml:id="_h5C8UMC">For example, an early extension of the multivariate median was suggested by Hayford <ref type="bibr" target="#b0">[1]</ref>, which is simply the component-wise median, also known as the vector of marginal medians.</s><s xml:id="_xmJjtpV">The spatial median, also known as the L 1 median <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, and Tukey's median <ref type="bibr" target="#b3">[4]</ref> are two other popular variants.</s><s xml:id="_aMpPjgK">Oja's median <ref type="bibr" target="#b4">[5]</ref> provides an alternative to the spatial median, but it is known to be more computationally expensive than other choices.</s><s xml:id="_uDSHpNa">These, and others, are reviewed in <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>.</s><s xml:id="_ncpejfB">We briefly review some of them here next, not least as we use them later in our simulation study.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1" xml:id="_g932F4H">Component-wise median</head><p xml:id="_CjmrZA2"><s xml:id="_djfwXJb">Let X = (x 1 , . .</s><s xml:id="_NxktvxJ">., x k ) T be an n-dimensional i.i.d.</s><s xml:id="_dgEF39c">sample with distribution function F : R n !</s><s xml:id="_6TJ9f3H">R. We assume that the n marginal distributions have bounded densities f 1 (μ 1 ), . .</s><s xml:id="_eCw6fpQ">., f n (μ n ) at the uniquely defined marginal medians μ = (μ 1 , . .</s><s xml:id="_yq7gNZS">., μ n ).</s><s xml:id="_QjuNJ9A">The component-wise median, also known as the marginal sample median, M C ðXÞ 2 R n minimises</s></p><formula xml:id="formula_1">k À 1 X k i¼1 fðjx i1 À m 1 j þ � � � þ jx in À m n jÞ À ðjx i1 j þ � � � þ jx in jÞg;<label>ð2Þ</label></formula><p xml:id="_tzaQBrd"><s xml:id="_W4xGAvx">the sum of component-wise distances over m 2 R n , where m = (m 1 , . .</s><s xml:id="_ezAmC6j">., m n ).</s><s xml:id="_eem7gaw">The corresponding population functional, M C (F), for the vector of population medians minimises</s></p><formula xml:id="formula_2">Efðjx 1 À m 1 j þ � � � þ jx n À m n jÞ À ðjx 1 j þ � � � þ jx n jÞg:<label>ð3Þ</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2" xml:id="_Qw2fz9e">Spatial median</head><p xml:id="_C7PbrUV"><s xml:id="_8SMq83e">The spatial median M S (X), also known as the L 1 median, minimises</s></p><formula xml:id="formula_3">k À 1 X k i¼1 fjjx i À mjj À jjx i jjg;<label>ð4Þ</label></formula><p xml:id="_DFExkPT"><s xml:id="_hCqtjp7">over m 2 R n , where jjmjj 2 ¼ P n i¼1 m 2 i is the (squared) Euclidean norm.</s><s xml:id="_BSEBz43">The corresponding functional spatial median, M S (F), minimises E F fjjx À mjj À jjxjjg: ð5Þ</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3" xml:id="_WmWpBm7">Oja's median</head><p xml:id="_9PakUs2"><s xml:id="_VgZBUWe">Let X = (x 1 , . .</s><s xml:id="_tyBRtbC">., x k ) T be an i.i.d.</s><s xml:id="_yVhZjM7">sample in R n with distribution function F : R n !</s><s xml:id="_vHPnzkw">R. The volume of the n-variate simplex determined by the n + 1 vertices (m 1 , . .</s><s xml:id="_cQfa6uR">., m n+1 ) is</s></p><formula xml:id="formula_4">Vðm 1 ; . . . ; m nþ1 Þ ¼ 1 p! det 1 � � � 1 m 1 � � � m nþ1 ! � � � � � � � � � � :<label>ð6Þ</label></formula><p xml:id="_vGSvNDC"><s xml:id="_a6ueMGF">The Oja median, M O (X), minimises</s></p><formula xml:id="formula_5">k n � � À 1 X i 1 &lt;���&lt;i</formula><p xml:id="_Cj4J89g"><s xml:id="_y7uy8ed">n Vðx i 1 ; . . .</s><s xml:id="_twbVPE9">; x i n ; mÞ; ð7Þ over m 2 R n .</s><s xml:id="_Uk859vc">The corresponding functional M O (F) minimises E F fVðx i 1 ; . . .</s><s xml:id="_Pn2SbbC">; x i n ; mÞg:</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4" xml:id="_TfhrEVV">Tukey's median</head><p xml:id="_Ghznnnb"><s xml:id="_nzek4wf">Let X = (x 1 , . .</s><s xml:id="_dRu5rWU">., x k ) T be an i.i.d.</s><s xml:id="_29QwZ8T">sample of size k in R n with distribution function F : R n !</s><s xml:id="_mJrjyV8">R.</s></p><p xml:id="_ZF5dER2"><s xml:id="_rmhK3Xr">Let H be the class of all closed half spaces in R n .</s><s xml:id="_YCM9Jbd">For each H 2 H, define the empirical distribution</s></p><formula xml:id="formula_7">F ðHÞ ¼ n À 1 X k i¼1 Iðx i 2 HÞ;<label>ð9Þ</label></formula><p xml:id="_F2KZqyV"><s xml:id="_fnPuMSt">where I is the usual indicator function.</s><s xml:id="_kZApAEP">Then, define the depth, D(μ), of a point μ 2 R n within the dataset, to be the infinum of FðHÞ, that is taken over all closed half spaces H for which μ 2 H. Tukey's median is defined as the set of points μ of maximal depth.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" xml:id="_684PKH4">The projection median</head><p xml:id="_THSSgBY"><s xml:id="_jye38ry">This section introduces our new method for computing the projection median, yamm.</s><s xml:id="_U54WyQs">We prove that yamm is equivalent to the projection median, as defined by Durocher and Kirkpatrick <ref type="bibr" target="#b8">[9]</ref> in R 2 and then generalised to higher dimensions by Basu et al. <ref type="bibr" target="#b9">[10]</ref>.</s><s xml:id="_3JSZhpu">We also explore, theoretically and numerically, the statistical behaviour of yamm using a mixture of two bivariate normal distributions.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1" xml:id="_tDsDGN2">Review of the projection median</head><p xml:id="_Sw3Uhwu"><s xml:id="_NxFQ9Px">2.1.1</s><s xml:id="_pQbaCkC">Projection median in R 2 .</s><s xml:id="_wxAZfF7">Let X be a multiset of points in R 2 and θ 2 [0, 2π) be an angle.</s><s xml:id="_aGWNznR">Let X θ denote the multiset defined by the projection of X onto the unit vector u θ = (cos θ, sin θ), so</s></p><formula xml:id="formula_8">X y ¼ fu y hx; u y i j x 2 Xg;<label>ð10Þ</label></formula><p xml:id="_mV79WNq"><s xml:id="_gENck7c">where h�i denotes the usual inner product.</s></p><p xml:id="_ENsdbHv"><s xml:id="_eKP4bu6">The projection median of a non-empty finite set X with points in R 2 is</s></p><formula xml:id="formula_9">M P ðXÞ ¼ p À 1 R 2p 0 medðX y Þ dy;<label>ð11Þ</label></formula><p xml:id="_ykHNUhX"><s xml:id="_stdARXY">where medðX y Þ 2 R 2 is the median of the projection of X onto the line through the origin, parallel to u θ .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2" xml:id="_UzBST3t">Generalisation of the projection median.</head><p xml:id="_Xbfu9qr"><s xml:id="_vyPKQpA">Given a fixed positive integer, n � 2, and a finite set of points X in R n , the n-dimensional projection median of X is</s></p><formula xml:id="formula_10">M P ðXÞ ¼ n R X nÀ 1 medðX a Þda R X nÀ 1 da ¼ n Z X nÀ 1 medðX a Þdf ðaÞ;<label>ð12Þ</label></formula><p xml:id="_EE4vDbS"><s xml:id="_yn8Fjw7">where X nÀ 1 ¼ fx 2 R n : jjxjj ¼ 1g is the unit n-dimensional hypersphere, med(X a) is the median of the projection of X onto the line through the origin parallel to a, and f is the normalised uniform measure over X n-1 .</s><s xml:id="_rYUFc7T">Hence, for a point x = (x 1 , x 2 , . .</s><s xml:id="_Xrksqjm">., x n )2X n-1 , the n-dimensional spherical coordinates are given by</s></p><formula xml:id="formula_11">x 1 ¼ cos y 1 x 2 ¼ sin y 1 cos y 2 x 3 ¼ sin y 1 sin y 2 cos � 3 � � � x nÀ 1 ¼ sin y 1 � � � sin y nÀ 2 cos y nÀ 1 x n ¼ sin y 1 � � � sin y nÀ 2 sin y nÀ 1 ;<label>ð13Þ</label></formula><p xml:id="_ykpe7tc"><s xml:id="_X3HNebd">where each angle θ 1 , θ 2 , . .</s><s xml:id="_3AuCDD8">., θ n-2 has a range of π and θ n-1 has range of 2π.</s><s xml:id="_chRAFsZ">Also, the normalised uniform measure f over X n-1 is given by</s></p><formula xml:id="formula_12">df ¼ d X nÀ 1 V R p 0 R p 0 � � � R 2p 0 d X nÀ 1 V ;<label>ð14Þ</label></formula><p xml:id="_ZnT9SCb"><s xml:id="_ah696um">where d X nÀ 1 V ¼ sin nÀ 2 y 1 sin nÀ 3 y 2 . . .</s><s xml:id="_HkyVGk9">sin y nÀ 2 dy 1 dy 2 . . .</s><s xml:id="_KYqagDM">dy nÀ 1 is the volume element of the (n -1)-sphere.</s><s xml:id="_8DuScka">Basu et al. <ref type="bibr" target="#b9">[10]</ref> proved that the projection median has a breakdown point of 1/2 for all n � 2.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2" xml:id="_ND8nqwv">Yet another multivariate median (Yamm)</head><formula xml:id="formula_13">Let X ¼ ðx 1 ; . . . ; x k Þ T 2 R k�n be a random sample of size k 2 N, x i 2 R n .</formula><p xml:id="_Y3txJ2f"><s xml:id="_jmCad3C">Let a be a n × 1 projection vector of unit length, 1 k be the k × 1 vector of ones and μ a shift vector of length n.</s><s xml:id="_EqXGEAu">Let y be the projection of X onto a after X has been shifted by μ:</s></p><formula xml:id="formula_14">y ¼ ðX À 1 k μ T Þ a;<label>ð15Þ</label></formula><p xml:id="_k2FMVwM"><s xml:id="_WtgYDnt">where y 2 R k .</s><s xml:id="_4ndvaAw">The univariate median m of the projected points y is m X ðμ; aÞ ¼ mðyÞ: ð16Þ</s></p><p xml:id="_TEaUMZd"><s xml:id="_kTrvwPv">Now define the integral</s></p><formula xml:id="formula_15">M X;m ðμÞ ¼ R fa:a T a¼1g m X ðμ; aÞ 2 da:<label>ð17Þ</label></formula><p xml:id="_9FGQzJG"><s xml:id="_Z3KxsKc">The yamm estimator of location for X is</s></p><formula xml:id="formula_16">μ ¼ yammðXÞ ¼ argmin μ M X;m ðμÞ:<label>ð18Þ</label></formula><p xml:id="_9GVnn9b"><s xml:id="_JqMxeE8">Eqs ( <ref type="formula" target="#formula_15">17</ref>) and ( <ref type="formula" target="#formula_16">18</ref>) illustrate the rationale behind yamm.</s><s xml:id="_8r6Njcb">Intuitively, if the shift vector μ is far away from the true 'middle' of the dataset, then the magnitude of m X (μ, a), as well as the integral M X, m (μ), will be large.</s><s xml:id="_GwdttAt">By contrast, a smaller m X (μ, a) can be obtained when the μ is moving closer to the true 'middle' of the data set.</s></p><p xml:id="_qKcnB9y"><s xml:id="_tC6S69H">Instead of computing the squared value of m X (μ, a) for the integral, we also considered the absolute value as an alternative.</s><s xml:id="_ARVskkZ">However, this leads to similar numerical results.</s></p><p xml:id="_TpHapmX"><s xml:id="_wuEt37T">Example.</s><s xml:id="_2nGu4mX">We now generate two polar plots of the absolute value of m X (μ, a), when μ is both close to, and far away, from the true median, respectively.</s><s xml:id="_9HEhEfn">A random two-dimensional dataset with k = 100 points was generated, whose Tukey's median computed as <ref type="bibr">(2.78, 8.16</ref>).</s><s xml:id="_UBpJq9c">Here, the Tukey median is to be interpreted as a 'sensible' middle of the data set.</s><s xml:id="_3FZWTck">The shift vector μ is set to be (2.2, 8) and (2, 7.5) respectively, and for each plot, two thousand random projections were used to calculate the univariate median m X (μ, a), using methods to be explained in Section 2.4.</s><s xml:id="_QdyMNja">Fig <ref type="figure" target="#fig_0">1</ref> shows that when μ is near the Tukey's median, the magnitude of each m X (μ, a) is less than 0.65, while a larger value, ranging from 0 to 1.2, is shown in the figure when μ is far away from the median.</s><s xml:id="_B3Mk9uv">Overall, when integrated the quantity involving the μ is closer to the Tukey median it gives a smaller result.</s></p><p xml:id="_VRCj9Qj"><s xml:id="_CEHMkcY">The projection median and yamm definitions seem similar, as both project the multiset onto the line passing through the origin, and then take the median.</s><s xml:id="_aGNjFkb">However, the projection median integrates med(X a ) directly over the unit hypersphere in R n , whereas yamm minimises the objective function M X;m ðμÞ 2 R over the shift vector μ.</s><s xml:id="_BBmHJgg">Despite these differences, the following theorem shows that the projection median and yamm are identical.</s><s xml:id="_EdNTj5T">Theorem.</s><s xml:id="_E5zvb4q">For any finite multiset X � R n with n � 2, yamm is equivalent to the projection median.</s></p><p xml:id="_KaktFzs"><s xml:id="_esSbP6j">For the proof of the theorem, see S1 Appendix.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3" xml:id="_Wdbh8TU">Yamm behaviour on a bivariate normal mixture</head><p xml:id="_CjX9BVE"><s xml:id="_TBDf3dF">To gain insight about the theoretical behaviour of yamm we study the case of yamm applied to a mixture of two bivariate normals, where one is thought of as the bulk and the other as the outlier of the distribution.</s><s xml:id="_CRUXENz">Such a setup enables us to evaluate the robustness of yamm.</s><s xml:id="_7SwwrAV">We numerically and theoretically assess the influence curve when moving the outlier far from the bulk.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1" xml:id="_RMguxnN">Bivariate mixture setup.</head><p xml:id="_B2r3RZj"><s xml:id="_zRZTf6s">Let X 1 � N 2 ðn 1 ; S 1 Þ and X 2 � N 2 ðn 2 ; S 2 Þ be independent bivariate normal random variables, where X 1 = (X 11 , X 12 ) T , X 2 = (X 21 , X 22 ) T with mean vector ν 1 = (ν 11 , ν 12 ) T and ν 2 = (ν 21 , ν 22 ) T .</s><s xml:id="_h84KsFs">Let R(θ) be a rotation matrix with angle θ given by</s></p><formula xml:id="formula_17">RðyÞ ¼ cos y À sin y sin y cos y ! :<label>ð19Þ</label></formula><p xml:id="_Pjf68PV"><s xml:id="_qdYz5Xf">We are interested in the first row of this matrix, which describes the projection onto direction θ.</s></p><formula xml:id="formula_18">Let Y i = (Y i1 , Y i2 ) T = R(X i -μ) for i = 1, 2 respectively, where μ = (μ 1 , μ 2 )</formula><p xml:id="_sc97umw"><s xml:id="_Asy3AA9">T is a shift vector mentioned in <ref type="bibr" target="#b14">(15)</ref>.</s><s xml:id="_FAkeQTv">Basic multivariate theory shows that</s></p><formula xml:id="formula_19">Y i � N 2 fRðν i À μÞ; RS i R T g; for i ¼ 1; 2:<label>ð20Þ</label></formula><formula xml:id="formula_20">Denote Y i = (Y i1 , Y i2 ) T , Y i1 is the first entry of Y i for i = 1, 2. Then, it is immediate that Y i1 � N ðs i ; s 2 i Þ, where s 1 ¼ ðn 11 À m 1 Þ cos y À ðn 12 À m 2 Þ sin y and s 2 1 ¼ ðRS 1 R T Þ 1;1 ;<label>ð21Þ</label></formula><formula xml:id="formula_21">s 2 ¼ ðn 21 À m 1 Þ cos y À ðn 22 À m 2 Þ sin y and s 2 2 ¼ ðRS 2 R T Þ 1;1 :<label>ð22Þ</label></formula><p xml:id="_cKpHYqB"><s xml:id="_d3MXC2N">The mixture distribution that we study is</s></p><formula xml:id="formula_22">f W ðw 1 ; w 2 Þ ¼ ð1 À �Þf X 1 ðw 1 ; w 2 Þ þ �f X 2 ðw 1 ; w 2 Þ;<label>ð23Þ</label></formula><p xml:id="_BXuuwkP"><s xml:id="_jAynX4p">where f X i is the density of X i , and � 2 [0, 1], is typically small.</s><s xml:id="_SjxuHYH">Here, f X 1 is considered to be the bulk of the distribution and f X 2 the outlier.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2" xml:id="_dYMZSW8">Projected distribution.</head><p xml:id="_KvcY4F9"><s xml:id="_2DtGpwR">Based on the bivariate setup above, the projected distribution is</s></p><formula xml:id="formula_23">f Y ðyÞ ¼ ð1 À �Þ� s 1 ;s 2 1 ðyÞ þ �� s 2 ;s 2 2 ðyÞ;<label>ð24Þ</label></formula><p xml:id="_W46UJuM"><s xml:id="_vV62kmQ">where s 1 ; s 2 ; s 2 1 ; s 2 2 are as above and ϕ is the standard normal density.</s><s xml:id="_AcfgCss">The distribution function of the projected Y(θ) is</s></p><formula xml:id="formula_24">F Y ðyÞ ¼ ð1 À �ÞF s 1 ;s 2 1 ðyÞ þ �F s 2 ;s 2 2 ðyÞ;<label>ð25Þ</label></formula><p xml:id="_ygtPuMj"><s xml:id="_cxV5gNz">where F is the standard normal distribution function.</s><s xml:id="_bpfhCS3">We require the median of the projected distribution, i.e. find y m ð�; y; s 1 ; s</s></p><formula xml:id="formula_25">2 ; S 1 ; S 2 Þ such that F Y ðy m Þ ¼ 1=2:<label>ð26Þ</label></formula><p xml:id="_B7fDe84"><s xml:id="_rUJNFxu">Finding an analytic exact solution for y m is difficult.</s><s xml:id="_FHbqm7R">Hence, we will simplify the problem and assume that S 1 = S 2 = I 2 , the identity matrix.</s><s xml:id="_ZkDhgpe">Since R(θ) is an orthogonal matrix, this means that s 2 1 ¼ s 2 2 ¼ 1 and Eq <ref type="bibr" target="#b24">(25)</ref> becomes</s></p><formula xml:id="formula_26">F Y ðyÞ ¼ ð1 À �ÞFðy À s 1 Þ þ �Fðy À s 2 Þ:<label>ð27Þ</label></formula><p xml:id="_WHUeRQY"><s xml:id="_4X8JUfE">For small �, we know that the median should be close to the median of the bulk, so the median of F Y should be close to s 1 , the median of the first component of the mixture in Eq <ref type="bibr" target="#b26">(27)</ref>.</s></p><p xml:id="_hqhQ6nt"><s xml:id="_Y5rCS8b">2.3.3</s><s xml:id="_JpGW9k5">Theoretical approximation of yamm on the mixture.</s><s xml:id="_pDaNHV6">We derive a theoretically based approximation to the empirical influence function.</s><s xml:id="_qcbg8Bf">We proceed by using a Taylor series expansion of F Y (y) around s 1 , the quantity we know is close to our median:</s></p><formula xml:id="formula_27">F Y ðyÞ � ½1 þ � À � Erfc fðs 1 À s 2 Þ= ffi ffi ffi 2 p g�=2 þð2pÞ À 1=2 ½1 À � þ � exp fÀ ðs 1 À s 2 Þ 2 =2g�ðy À s 1 Þ þOfðy À s 1 Þ 2 g;<label>ð28Þ</label></formula><p xml:id="_n6SYYsP"><s xml:id="_DrFQvD6">where Erfc ðyÞ ¼ 2p À 1=2 R 1 y e À t 2 dt: When y is close to s 1 , Eq ( <ref type="formula" target="#formula_27">28</ref>) is approximately equal to 1/2 when � is small, which is the behaviour we expect.</s></p><p xml:id="_Y9YfTa4"><s xml:id="_5VnhBNz">To find an approximation to the median we solve F Y {y m (θ)} = 1/2.</s><s xml:id="_wKPUxvW">Ignoring remainders, subtracting 1/2 off both sides of Eq <ref type="bibr" target="#b27">(28)</ref> gives</s></p><formula xml:id="formula_28">� 2 Erfc ( ðs 1 À s 2 Þ= ffi ffi ffi 2 p " ) À 1 # ¼ ½1 À � þ � exp fÀ ðs 1 À s 2 Þ 2 =2g�ðy m À s 1 Þ ffi ffi ffi ffi ffiffi 2p p ;<label>ð29Þ</label></formula><p xml:id="_q6HZhY9"><s xml:id="_Zxt6cSA">and then</s></p><formula xml:id="formula_29">y m ðyÞ � s 1 þ � ffi ffi ffi ffi ffi ffi ffi ffi p=2 p ½ Erfc fðs 1 À s 2 Þ= ffi ffi ffi 2 p g À 1� ½1 À � þ � exp fÀ ðs 1 À s 2 Þ 2 =2g� :<label>ð30Þ</label></formula><p xml:id="_xaKgn2z"><s xml:id="_hsZxfPE">Now using</s></p><formula xml:id="formula_30">Erfc fðs 1 À s 2 Þ= ffi ffi ffi 2 p g ¼ 2Ffðs 2 À s 1 Þ= ffi ffi ffi 2 p g;<label>ð31Þ</label></formula><formula xml:id="formula_31">and exp fÀ ðs 1 À s 2 Þ 2 =2g ¼ ffi ffi ffi ffi ffiffi 2p p �ðs 1 À s 2 Þ, we can write y m ðyÞ � s 1 þ � ffi ffi ffi ffi ffi ffi ffi ffi p=2 p ð2Ffðs 2 À s 1 Þ= ffi ffi ffi 2 p g À 1Þ 1 À � À ffi ffi ffi ffi ffiffi 2p p ��ðs 2 À s 1 Þ :<label>ð32Þ</label></formula><p xml:id="_YZhNA8k"><s xml:id="_Djv4nqJ">For small � the denominator is close to 1. From Eqs ( <ref type="formula" target="#formula_20">21</ref>) and ( <ref type="formula" target="#formula_21">22</ref>), we can write:</s></p><formula xml:id="formula_32">s 2 À s 1 ¼ ðn 21 À n 11 Þ cos y À ðn 22 À n 12 Þ sin y ¼ d 1 cos y À d 2 sin y;<label>ð33Þ</label></formula><p xml:id="_RmjyM8B"><s xml:id="_FXXd2dr">where δ 1 = ν 21 -ν 11 and δ 2 = ν 22 -ν 12 .</s><s xml:id="_fzX4vtq">Thus</s></p><formula xml:id="formula_33">y m ðyÞ � fðn 11 À m 1 Þ cos y À ðn 12 À m 2 Þ sin yg þ � ffi ffi ffi ffi ffi ffi ffi ffi p=2 p ½2Ffðd 1 cos y À d 2 sin yÞ= ffi ffi ffi 2 p g À 1� 1 À � À ffi ffi ffi ffi ffiffi 2p p ��ðd 1 cos y À d 2 sin yÞ :<label>ð34Þ</label></formula><p xml:id="_3aMNsUF"><s xml:id="_GGNna9B">According to Eq <ref type="bibr" target="#b16">(17)</ref>, our job is to find the optimal μ</s></p><formula xml:id="formula_34">� ¼ ðm � 1 ; m � 2 Þ T , which minimises M ¼ R 2p 0 y 2 m ðyÞ dy:<label>ð35Þ</label></formula><p xml:id="_va8ACUr"><s xml:id="_2hrDy3h">The integrand involves the standard normal distribution function, which is tricky to handle analytically.</s><s xml:id="_dvfg2js">Hence, we use the approximation, ϕ(z)�(1 + cos z)/2π, for -π &lt; z &lt; π, for the standard normal density <ref type="bibr" target="#b10">[11]</ref>, which enables the following proposition.</s></p><p xml:id="_ckx7Bjz"><s xml:id="_K392rx9">Proposition.</s><s xml:id="_hTxF7VQ">Let X 1 = (X 11 , X 12 ) T and X 2 = (X 21 , X 22 ) T .</s><s xml:id="_qspuzun">Suppose that X 1 � N 2 ðν 1 ; S 1 Þ and X 2 � N 2 ðν 2 ; S 2 Þ independently, where ν 1 = (ν 11 , ν 12 ) T and ν 2 = (ν 21 , ν 22 ) T , respectively.</s><s xml:id="_x5n9DRw">Let the mixture, W, of X 1 and X 2 be</s></p><formula xml:id="formula_35">f W ðw 1 ; w 2 Þ ¼ ð1 À �Þf X 1 ðw 1 ; w 2 Þ þ �f X 2 ðw 1 ; w 2 Þ; where � 2 [0, 1] is considered small.</formula><p xml:id="_2PdrbWk"><s xml:id="_m4BsmSA">An approximation of the yamm estimator,</s></p><formula xml:id="formula_36">μ � ¼ ðm � 1 ; m � 2 Þ, is m � 1 ¼ n 11 þ p À 1=2 R�ð1 À R 2 =32 þ R 4 =1536Þ cos a; m � 2 ¼ n 12 þ p À 1=2 R�ð1 À R 2 =32 þ R 4 =1536Þ sin a;<label>ð36Þ</label></formula><formula xml:id="formula_37">where R 2 ¼ ðd 2 1 þ d 2 2 Þ, δ 1 = ν 21 -ν 11 , δ 2 = ν 22 -ν 12 and α = arctan(δ 2 /δ 1 )</formula><p xml:id="_sXvuqXV"><s xml:id="_XKYNTNv">. The approximation we use is valid whenever jR cos ðy þ aÞj &lt; ffi ffi ffi 2 p p, where θ is the projection direction when computing yamm.</s><s xml:id="_nUeRr2A">This inequality is true for all θ whenever R &lt; ffi ffi ffi 2 p p. Intuitively, the approximation in the Proposition works whenever the two cluster means are close enough together, i.e. when R 2</s></p><formula xml:id="formula_38">¼ d 2 1 þ d 2 2 &lt; 2p 2 .</formula><p xml:id="_GW84myF"><s xml:id="_NVkC3zE">In particular, when ν 11 = ν 21 or ν 12 = ν 22 (i.e. when one of the δ i = 0, i = 1, 2), we can form a more accurate approximation.</s><s xml:id="_BsCCFRP">This is because the approximation for the standard normal distribution function, ϕ(z)�(1 + cos z)/2π, is no longer required to find the optimal μ</s></p><formula xml:id="formula_39">� ¼ ðm � 1 ; m � 2 Þ</formula><p xml:id="_XyU3M7v"><s xml:id="_gdtTgV6">T minimising Eq <ref type="bibr" target="#b34">(35)</ref>.</s><s xml:id="_pUa52PY">Without loss of generality, let ν 1 = (ν 11 , ν 12 ) T = (0, 0) T and ν 2 = (ν 21 , ν 22 ) T = (0, d) T , we obtain the yamm estimator as follows</s></p><formula xml:id="formula_40">m � 1 ¼ 0; m � 2 ¼ 2 À 1=2 �d e À d 2 8 BesselI 0; d 2 =8 ½ � þ BesselI 1; d 2 =8 ½ � ð Þ;<label>ð37Þ</label></formula><p xml:id="_qEJNxms"><s xml:id="_8pSN9dW">where BesselI[n, z] is the modified Bessel function of the first kind, sometimes denoted I n (z).</s></p><p xml:id="_ughJxMd"><s xml:id="_FxaM6Yk">For the proof of the proposition, see S2 Appendix.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_madFtkS">2.3.4</head><p xml:id="_vJGfrmy"><s xml:id="_nn4mn9C">The yamm influence curve on the mixture.</s><s xml:id="_B2dXERj">This section numerically computes and plots yamm for the case where � = 0.05, T for d 2 R. We explore how yamm varies as d increases from 0 to 10 in steps of 0.2.</s><s xml:id="_9hn6T3X">If yamm is robust, then it should increase with d, but plateau beyond a certain point.</s></p><formula xml:id="formula_41">X 1 � N 2 ðν 1 ; I 2 Þ and X 2 � N 2 ðν 2 ; I 2 Þ, with ν 1 = (0, 0) T and ν 2 = (0, d)</formula><p xml:id="_Wt2UYqs"><s xml:id="_Bu4KM5D">For each value d we estimate yamm as the mean over five hundred bivariate mixture realizations, with two thousand projections involved for each yamm computation, using methods described below in Section 2. The solid red line in Fig <ref type="figure" target="#fig_2">2</ref> shows our theoretical approximation of the yamm influence curve with the more specific setup, where μ � follows Eq (37).</s><s xml:id="_wwDzyKt">Under this approximation, the influence curve closely follows the numerically computed crosses.</s><s xml:id="_cXvz3jB">On the other hand, the solid blue line is the approximation of the yamm under the more general setting of Eq (36), which exhibits poor approximation after d &gt; 4.5, although it performs reasonably well when the inter-cluster mean distance 0 &lt; d &lt; 4.5, and does not plateau.</s><s xml:id="_tQMFdN7">This is because, in the setup, δ 1 = d, δ 2 = 0, and</s></p><formula xml:id="formula_42">d &gt; 4.5 implies R 2 ¼ d 2 1 ¼ d 2 &gt; 2p 2</formula><p xml:id="_bt2CM7v"><s xml:id="_mwzSywf">. However, the specific setup approximation of yamm obviously does not work for arbitrary values of ν 1 and ν 2 , whereas the general approximation gives a good theoretical idea of the yamm influence curve when the two means of the clusters are close enough together.</s><s xml:id="_eQt9xkx"><ref type="bibr" target="#b11">[12]</ref> can be used to compute an approximation of the projection median by</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4" xml:id="_Jm35xBv">Projection median and yamm computation 2.4.1 Projection median computation. A simple Monte Carlo integration</head><formula xml:id="formula_43">M P ðXÞ ¼ nJ À 1 X J j¼1 medðX a j Þ;<label>ð38Þ</label></formula><p xml:id="_fvzCGCU"><s xml:id="_RsCm5Pk">where J represents the number of projections used, and fa j g J j¼1 is a set of random, independently-drawn, unit length n-vectors over X n-1 .</s></p><p xml:id="_SB69kuX"><s xml:id="_rDXrp6W">Calculating approximation of Eq (38) is relatively straightforward, but a large value of J is required to ensure accuracy.</s><s xml:id="_NjMxHZM">Another approach computes the projection median directly from the definition in Eq <ref type="bibr" target="#b11">(12)</ref>, using the spherical coordinates illustrated in Eq <ref type="bibr" target="#b12">(13)</ref>, where the integral can be obtained by the trapezoidal rule.</s><s xml:id="_enE6U8n">For example, in the two-dimensional case, we apply the trapezoidal rule once on Eq <ref type="bibr" target="#b10">(11)</ref>.</s><s xml:id="_bScHCQ2">In the three-dimensional case, we have to apply the trapezoidal rule twice for the double integral, and so on.</s><s xml:id="_H7SqYVk">This direct approach is easy to implement when our dataset has a low dimension, but excessive work is required in not that many higher dimensions, even with, e.g.</s><s xml:id="_RpDJCfw">n = 10.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2" xml:id="_dMSpYvz">Computing yamm.</head><p xml:id="_3DnEKgF"><s xml:id="_cpEgjaj">To compute an approximation to yamm, we can also use Monte Carlo integration together with an optimiser.</s><s xml:id="_26AaDKU">Let J 2 N be the number of projections, fa j g J j¼1 be a set of independent random unit length n-vectors, an estimator for M X, m (μ) is given by</s></p><formula xml:id="formula_44">M X;m ðμÞ ¼ J À 1 X J j¼1 m X ðμ; a j Þ 2 :<label>ð39Þ</label></formula><p xml:id="_5Uc5JqK"><s xml:id="_YN94q2b">We then numerically minimise MX;m ðμÞ over μ to obtain our estimated location measure, using the BFGS optimization method <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>.</s><s xml:id="_3BxAbH7">BFGS is a quasi-Newton algorithm searching for a stationary point of a function via local quadratic approximation.</s><s xml:id="_mJwpJMM">Parallel versions such as optimParallel exist as easy to use packages in R.</s></p><p xml:id="_NyW4x8h"><s xml:id="_pxDyxK3">With reasonable starting values, such as the mean or other multivariate medians, yamm typically provides accurate results with a considerably smaller number of projections than used by the Monte Carlo projection median method mentioned above.</s></p><p xml:id="_XyR9KrS"><s xml:id="_xtdsXbB">In conclusion, projection median computation via the trapezoidal rule is fast and accurate in low dimensions, but increasingly onerous in higher dimensions, as progressively more multidimensional integration is required.</s><s xml:id="_VhFRW25">For higher dimensions, we prefer the Monte Carlo method and prefer yamm over the projection median as it does not require such a large number of projections, particularly if the optimiser is given a good starting solution.</s></p><p xml:id="_XYeKERX"><s xml:id="_TYb9MQF">Overall, approximating the projection median by the trapezoidal rule is a good choice in R 2 and R 3 , and either of the other two methods can be used in higher dimensions.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3" xml:id="_aAPCHtz">Empirical performance for different medians</head><p xml:id="_PbsGWRm"><s xml:id="_yWrcPRd">This section reviews the theoretical computational complexity for a variety of medians and computes some running times for real implementations of several medians computed in R. We then present some results for accuracy of estimation for these medians.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1" xml:id="_zyzFNAX">Computational complexity and empirical speed</head><p xml:id="_pkCAPM8"><s xml:id="_KX52C94">For a dataset in R n with k observations, the computational complexity for the Spatial median is O(nk) <ref type="bibr" target="#b16">[17]</ref>, which is the same for the exact computation of the component-wise median.</s><s xml:id="_EZUqha5">The projection median can be obtained in O(k 4/3 log 1+� k) time in R 2 <ref type="bibr" target="#b8">[9]</ref>, and O(k</s></p><formula xml:id="formula_45">5/2+� ) time in R 3 [10]. In R n , with n &gt; 3, Basu et al. showed that O[k n{1-δ</formula><p xml:id="_9B9bd7A"><s xml:id="_x2pappB">n /(n+1)}+�] time is required to compute the projection median, where δ n = (4n -3) -n and � is a fixed small constant.</s><s xml:id="_f6WC5Tf">Several algorithms for other multivariate medians have been developed or the bivariate case.</s><s xml:id="_WKV8kZb">The current best algorithms for Oja's and Liu's medians require O(k log 3 k) and O(k 4 ) time, respectively <ref type="bibr" target="#b17">[18]</ref>, whereas that for the fastest bivariate Tukey median is O(k log 3 k) <ref type="bibr" target="#b18">[19]</ref>.</s><s xml:id="_ee9Pnxx">The calculation of these three multivariate medians in higher dimensions is more complicated and approximate computation is often preferred/required.</s></p><p xml:id="_E78UWRh"><s xml:id="_fyS3Ek2">To provide empirical assessment of the real computation speed, we apply several R software medians to simulated data.</s><s xml:id="_D5FAZc5">There are several R functions using different algorithms to compute one median.</s><s xml:id="_jFkfqsA">For example, spatial.median from the library ICSNP estimates the median with the algorithm developed by Vardi and Zhang <ref type="bibr" target="#b19">[20]</ref>, while Gmedian developed by Cardot et al. <ref type="bibr" target="#b20">[21]</ref> is faster but, perhaps, less accurate.</s><s xml:id="_J3ujeaN">In addition, l1median <ref type="bibr" target="#b21">[22]</ref> from library pcaPP and med from depth also provide opportunities to compute the spatial median.</s></p><p xml:id="_AxJqQqH"><s xml:id="_Y9XPvE5">Hence, after some experiments, we choose the best function (evaluated in terms of speed and accuracy) for each multivariate median in R 2 and R 3 shown in Table <ref type="table">1</ref>.</s><s xml:id="_Kdht3V9">Much of the software for multivariate medians in R only works in low numbers of dimensions.</s></p><p xml:id="_KNgga95"><s xml:id="_HGxFE8t">The med function can only calculate the bivariate Liu's median, which is considerably more challenging in higher dimensions.</s><s xml:id="_xhBkyau">The calculation of Tukey's median is exact in one and two dimensions, and approximate in higher dimensions.</s><s xml:id="_gG6eB6D">We use the approximate Tukey's median computation in the med function, due to numerical errors that sometimes surface when using the exact algorithm.</s><s xml:id="_29GyfZV">For Oja's median, the approximate method (evolutionary algorithm) is used instead of the exact one, as it is faster and can deal with high dimensions.</s></p><p xml:id="_CB5Urku"><s xml:id="_ed5X7he">Table <ref type="table">2</ref> displays mean computation times and their standard deviations across 1000 simulated datasets from the two-dimensional Laplace distribution with different numbers of observations (k) for each set.</s><s xml:id="_p8dsuY2">The results are produced by running R on a single core of an Intel i7-8750h processor with 2.20 GHz base clock using 16Gb RAM.</s><s xml:id="_vjWrsng">For small k, Liu's median is fastest, but its speed is not as fast as others for higher k.</s><s xml:id="_hY7uBqf">In this experiment, Oja's median is the slowest for small k values, but its speed does not appear to be particularly sensitive to k.</s><s xml:id="_H4dN7U3">Hence, its speed is faster than Tukey's median when k = 200.</s><s xml:id="_tT5HpEX">The projection median is one of the quickest when k is below 100, while for large k values, the component-wise median and the Spatial median are faster.</s></p><p xml:id="_BHhtXFF"><s xml:id="_XdFvZzH">The results in Table <ref type="table">2</ref> are produced by only one possible R function for one median.</s><s xml:id="_Cs7GJhV">However, other functions can be used.</s><s xml:id="_ehrFN2N">For example, the med function from the depth package can also be used to calculate the spatial median and provides accurate answers.</s><s xml:id="_nGMhf6T">It is extremely</s></p><p xml:id="_p5Taqhh"><s xml:id="_5Em5Hvt">Table 1.</s><s xml:id="_wUWztT8">R functions used for analysing different multivariate medians.</s><s xml:id="_2fv9yEN">Median Function Package Source Spatial l1median pcaPP [22] CWmed med depth -Liu's med depth [23] Tukey's med depth [24] [25] Oja's ojaMedianEvo OjaNP [26] Projection PmedTrapz Yamm Ours <ref type="url" target="https://doi.org/10.1371/journal.pone.0229845.t001">https://doi.org/10.1371/journal.pone.0229845.t001</ref></s><s xml:id="_nWawQWa">Table 2. Mean and standard deviation (s.d.) of the operation time (×10 -5 ) in seconds for data in R 2 .</s><s xml:id="_Baa2BKS">Median k = 10 k = 25 k = 50 k = 100 k = 200 Spatial mean 27 28 30 29 28 s.d.</s><s xml:id="_UV3N8wY">44 45 57 45 45 Component-wise mean 24 21 25 25 24 s.d.</s><s xml:id="_qvfcXBf">42 41 43 43 43 Liu's mean 3 6 14 49 190 s.d.</s><s xml:id="_bQTpekm">18 24 35 66 250 Tukey's mean 67 210 510 970 1890 s.d.</s><s xml:id="_GeXq3GG">47 28 40 56 100 Oja's mean 1430 1400 1460 1410 1410 s.d.</s><s xml:id="_hy59DXH">410 190 270 190 160 Projection mean 7 12 18 31 60 s.d.</s><s xml:id="_Jt5zmSH">26 32 39 46 49 <ref type="url" target="https://doi.org/10.1371/journal.pone.0229845.t002">https://doi.org/10.1371/journal.pone.0229845.t002</ref></s></p><p xml:id="_53HdqUb"><s xml:id="_26dEMhc">fast for small k and lower dimensions, but it becomes slower than l1median for larger k.</s></p><p xml:id="_3fqKE5a"><s xml:id="_dPjGDE2">Hence, we use l1median to compute the spatial median, whose performance for small k is also good.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2" xml:id="_FQ4byZG">Mean squared error for some medians</head><p xml:id="_TZu8tst"><s xml:id="_ZhtpDC3">We assess the accuracy of some of the medians via empirical mean squared error.</s><s xml:id="_EXVwYwh">If X is an estimator in R n with respect to the unknown parameter μ 2 R n , then the mean squared error is</s></p><formula xml:id="formula_46">MSE ð X Þ ¼ n À 1 Eðjj X À μjj 2 2 Þ;<label>ð40Þ</label></formula><p xml:id="_RE7ZBNy"><s xml:id="_5v3B3mk">where n À 1 jj X À μjj 2 2 represents the squared Euclidean distance between X and μ, normalized by the vector length.</s><s xml:id="_8YvV3Fa">Smaller MSE ð XÞ values are better.</s></p><p xml:id="_g8qjMRZ"><s xml:id="_uNzQPhc">Table <ref type="table">3</ref> shows MSE results based on the same simulations as used for Table <ref type="table">2</ref>.</s><s xml:id="_DNk3SMh">Not surprisingly, for this long-tailed data, all medians perform better than the sample mean.</s><s xml:id="_3J8wMAx">The spatial median and the projection median have smaller mean squared error, the latter performing better for small k values.</s><s xml:id="_V8nXsxQ">On the other hand, Liu's median always produces a very high mean squared error.</s></p><p xml:id="_8KaKk28"><s xml:id="_DUkxNdw">Conclusion.</s><s xml:id="_rdmahZN">Based on these simulations, for the R functions listed in Table <ref type="table">1</ref>, the spatial and projection medians always have the lowest mean squared error, but also fast running speeds.</s><s xml:id="_dGAFfmA">Although Liu's median has the shortest computation time, for small k, it is the most inaccurate, and its computation time becomes long for large datasets.</s><s xml:id="_rUXafwW">Similarly, the component-wise median is fast, even when k increases, but it has a large mean squared error.</s><s xml:id="_mdk2k6k">Hence, the spatial and projection medians are good choices when computing two-dimensional robust measures of location in this case, and the latter is preferred for small datasets.</s><s xml:id="_xn3prk3">The computational results for high-dimensional simulations (n = 3, 5, 10) can be found in S1 Table.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3" xml:id="_pFWAC7m">2D projection median computation functions</head><p xml:id="_nNhwTUd"><s xml:id="_9zczwnW">The R package DurocherProjectionMedian can be downloaded from Github at <ref type="url" target="https://github.com/12ramsake/DurocherProjectionMedian">https://github.com/12ramsake/DurocherProjectionMedian</ref>.</s></p><p xml:id="_kYQW3N6"><s xml:id="_Nkb6nBM">The DurocherProjectionMedian package provides functions to compute the projection median via the Monte Carlo integration method using projectionMedianMC) <ref type="bibr" target="#b26">[27]</ref> and an exact method for two dimensions proposed by Ramsay <ref type="bibr" target="#b27">[28]</ref> using projection-Median2D.</s><s xml:id="_9kyYpHC">Tables <ref type="table">4</ref> and <ref type="table">5</ref> show the performance of the different functions computing the two-dimensional projection median of 1000 simulated datasets from the Laplace distribution with different k.</s></p><p xml:id="_wz3MtzU"><s xml:id="_cnSgPyT">Table 3. Mean squared error (×10 -2 ) for data as in Table 2. Location Estimator k = 10 k = 25 k = 50 k = 100 k = 200 Spatial 67 21 9.7 4.6 2.3 Component-wise 74 26 12.0 5.7 2.9 Liu's 110 31 14.0 6.3 3.2 Tukey's 73 21 10.0 4.8 2.3 Oja's 75 22 11.0 5.6 3.2 Projection 66 21 9.8 4.7 2.3 Mean 110 39 20.0 9.9 5.0 <ref type="url" target="https://doi.org/10.1371/journal.pone.0229845.t003">https://doi.org/10.1371/journal.pone.0229845.t003</ref></s></p><p xml:id="_ky624jP"><s xml:id="_utejw5d">For the Monte Carlo Integration method, when k is small (e.g.</s><s xml:id="_7BgK9bJ">under 150 in R 2 ), the computation time of projectionMedianMC is longer than our PmedMCInt under the same number of projections in both R 2 and high dimensions, whereas both implementations have almost the same MSE.</s></p><p xml:id="_CmbAXb2"><s xml:id="_vgVvK5t">Although the projectionMedian2D provides a slightly smaller MSE, its running time is slow.</s><s xml:id="_45eHDvt">Our PmedTrapz is faster and its MSE performance is comparable to projection-Median2D, and, hence, the former might be recommended as the best choice for R 2 .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" xml:id="_VXqDZKc">The yamm R package</head><p xml:id="_cEvAqD6"><s xml:id="_RU67TR4">Our Yamm R package provides users with functions to compute the projection median according to the different methods mentioned in section 2.4.</s><s xml:id="_s3QEbbj">PmedMCInt computes the projection median using the Monte Carlo approximation; PmedTrapz uses the trapezoidal rule and currently, it is only valid in two and three dimensions; yamm computes the projection median using the Monte Carlo approximation to find the shift vector μ minimising our objective function yamm.obj.</s><s xml:id="_cMQpxzz">The package also includes functions Plot2dMedian and Plot2dMedian to plot different multivariate medians for data in both R 2 and R 3 .</s><s xml:id="_GZWm6vE">Most functions in our package are implemented internally using C code.</s><s xml:id="_XMux55Y">This section provides some brief illustrations of the use of Yamm.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1" xml:id="_cw27u6Q">Yamm projection medians</head><p xml:id="_PqcHgUh"><s xml:id="_hrKA95n">The function PmedMCInt computes the projection median for any multivariate data, x, by invoking PmedMCInt(x, nprojs = 20000) Since this function uses Monte Carlo integration, we need to choose the number of projections J, which has a default value of 20000.</s><s xml:id="_gSHkJac">Typically, a large J is required to obtain a stable</s></p><p xml:id="_eKwt7X4"><s xml:id="_U7VdB4F">Table 4. Mean and standard deviation (s.d.) of the operation time (×10 -5 ) in seconds for different R functions to produce the projection median.</s><s xml:id="_sQqh7ye">k R Function 10 25 50 100 200 PmedTrapz mean 7 12 18 31 60 s.d.</s><s xml:id="_hpk24ay">26 32 39 46 49 projectionMedian2D mean 320 1020 3930 11640 44830 s.d.</s><s xml:id="_dj4XaPm">50 99 420 970 2690 PmedMCInt mean 250 320 490 870 1670 s.d.</s><s xml:id="_9GmZtjc">40 39 33 50 58 projectionMedianMC mean 930 970 1010 1130 1280 s.d.</s><s xml:id="_6JBtDDF">49 57 65 60 55 <ref type="url" target="https://doi.org/10.1371/journal.pone.0229845.t004">https://doi.org/10.1371/journal.pone.0229845.t004</ref></s><s xml:id="_AFKGsAP">Table 5. Mean squared error (×10 -3 ) for 1000 sets of data in R 2 generated from Laplace distribution.</s><s xml:id="_4Q9D8xG">k R Function 10 25 50 100 200 PmedTrapz 656 207 98.2 47.1 23.2 projectionMedian2D 656 206 97.4 46.9 22.9 PmedMCInt 659 205 97.8 47.0 23.0 projectionMedianMC 659 205 97.6 47.0 23.0 <ref type="url" target="https://doi.org/10.1371/journal.pone.0229845.t005">https://doi.org/10.1371/journal.pone.0229845.t005</ref></s></p><p xml:id="_CTDqDGX"><s xml:id="_kz8hHdm">answer, which means the result will not change much if recomputed under the same conditions.</s><s xml:id="_wwGhqvQ">This function returns the projection median estimate vector.</s><s xml:id="_3mUmDSj">The function PmedTrapz computes the projection median in R 2 and R 3 and is invoked by PmedTrapz(x, no.subinterval) PmedTrapz applies the trapezoidal rule once in R 2 and twice in R 3 on each entry of the vector medðX a Þ, mentioned in section 2.1.2,</s><s xml:id="_xTneeVC">and returns a vector of the projection median estimate.</s></p><p xml:id="_A7p5vQ6"><s xml:id="_CPDTpfw">The argument no.subinterval determines the number of subintervals for the trapezoidal rule.</s><s xml:id="_GNDJkfD">For the bivariate case the no.subinterval argument is a single number that controls the number of subdivisions for the one-dimensional integration; for the trivariate case the argument is a vector of length two that controls the number of subdivisions for the two integrals.</s><s xml:id="_5zEJXFq">In general, it is better to use at least 36 subintervals, which typically produces accurate results without excessive running time.</s></p><p xml:id="_Pg7KMKM"><s xml:id="_AN3m5ez">More subintervals may be appropriate for more complex datasets.</s><s xml:id="_rPnNfqr">For some unusual data sets it would be ideal to have a high resolution of the interval of integration in one particular region, and a relatively low resolution elsewhere, but this is beyond the scope of the current research.</s><s xml:id="_TVCjN3X">A small number of partitions, e.g.</s><s xml:id="_RpDFRgA">below 15, is not recommended for reasons of accuracy.</s></p><p xml:id="_bF2bskP"><s xml:id="_X5pwJQK">The yamm function is valid for data of any dimension.</s><s xml:id="_FPefb5b">It uses an optimiser to provide another method to compute the projection median.</s><s xml:id="_ne5qsNU">The arguments are yamm(x, nprojs = 2000, reltol = 1e-06, xstart = l1median(x), opt.method = "BFGS", doabs = 0, full.results</s><s xml:id="_hqJfHnR">= FALSE).</s></p><p xml:id="_3cd8un4"><s xml:id="_BazYUNv">The yamm function is a wrapper to minimise the the objective function yamm.obj, which uses the Monte Carlo method to approximate the squared or absolute value of the univariate median of the projection of the shifted data matrix.</s><s xml:id="_jPzECCq">The nprojs argument controls the number of projections in the Monte Carlo approximation and doabs is an indicator, where 1 uses the absolute value of the univariate median and 0 forces the use of the squared value.</s><s xml:id="_fDhYtSM">The arguments reltol, xstart, opt.method are supplied directly to the R optimisation function optim: reltol is the tolerance for the optimiser, with default value of 10 -6 .</s><s xml:id="_bpwzFUk">Usually, we set a larger value (e.g. 10 -3 ) to this argument, which will reduce the running time, whilst maintaining accuracy.</s><s xml:id="_VXBeV7M">The argument opt.method controls the selection of optimisation methods, which can be chosen from any of the four options, "BFGS", "Nelder-Mead" <ref type="bibr" target="#b28">[29]</ref>, "CG" <ref type="bibr" target="#b29">[30]</ref>, "L-BFGS-B" <ref type="bibr" target="#b30">[31]</ref>, and "SANN" <ref type="bibr" target="#b31">[32]</ref>.</s><s xml:id="_ub6Q8jU">The default choice "BFGS" is relatively fast and stable in our case.</s><s xml:id="_9XeTsAs">See the help page of the function optim in R for further details about the different optimisation methods.</s><s xml:id="_Rj37d8D">The xstart argument provides the initial value for the parameters to optimise over, which plays an important role in the function yamm.</s><s xml:id="_JRZ3Hvn">A good starting point will reduce the running time and provide a more accurate result, so we use the spatial median as the default value.</s><s xml:id="_hsD6ay6">Other multivariate medians could be used, but they need to be fast.</s><s xml:id="_ez93AMp">If full.</s><s xml:id="_8BkS35R">results = TRUE, the output of this function involves a list with components obtained from the optim function, otherwise, it returns a vector containing the multivariate median estimate.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2" xml:id="_KTQ6snG">Some real examples</head><p xml:id="_d4cKYeS"><s xml:id="_TXg6x9T">We now exhibit results for the projection medians applied to some real datasets.</s><s xml:id="_PwEpZdR">Our plots show different multivariate medians and the sample mean value for two simulated datasets in R 2 and R 3 , respectively, allowing the methods to be compared.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1" xml:id="_jCVUHtz">Beetle data.</head><p xml:id="_6Qsbhd7"><s xml:id="_24pRYJ5">The famous beetle data <ref type="bibr" target="#b32">[33]</ref> takes six measurements on 74 flea-beetles, with each belonging to one of three different species.</s><s xml:id="_mzkqbpV">We apply yamm and obtain the following output: yamm(beetle, nprojs = 1000, reltol = 1e-3, doabs = 0, full.results</s><s xml:id="_YMBV6AH">= TRUE) <ref type="bibr" target="#b0">[1]</ref> 180.19194 123.73920 49.97819 135.87913 13.62603 95.49062 $value [1] 5.585139 $counts function gradient 90 4 $convergence [1] 0 $message NULL The yamm results show that the optimiser executed 90 calls to the objective function yamm.obj and constructed 4 gradients.</s><s xml:id="_5vKEuN3">The par component contains the estimate of the yamm for the beetle data.</s><s xml:id="_yngQj9h">These results are not that different from the output generated by PmedMCInt, which is PmedMCInt(beetle, nprojs = 100000) [1] 179.54428 124.72128 50.56934 137.47363 13.23372 94.80188</s></p><p xml:id="_u3WH7Dn"><s xml:id="_DD7tXM5">For the beetle data, we chose the number of projections in yamm to be 1000, while many more projections were required (e.g.</s><s xml:id="_h27mM5R">100000) in PmedMCInt to obtain a similar and consistent result; although yamm requires optimisation.</s><s xml:id="_H5ebDC8">Fewer projections for the function PmedM-CInt may lead inaccurate results for some components of the multivariate median.</s><s xml:id="_GjpTDQY">PmedTrapz is not valid in this six-dimensional case, but we will show that it has a similar output when computing projection median in two-and three-dimensions.</s></p><p xml:id="_ZhMWh57"><s xml:id="_qAHbp4m">4.2.2</s><s xml:id="_bCPqVhs">Simulated Data in R 2 with three clusters.</s><s xml:id="_AvrkGDm">We now use the function Plot2dMedian in the package Yamm to generate and display different multivariate medians for the simulated data set clusters2d.</s><s xml:id="_3J5b5MP">This set contains three clusters, which are generated randomly from different independent normal distributions, and two outliers.</s></p><p xml:id="_cz3hBHt"><s xml:id="_rZVEEeA">Here, we display the three different estimates of the projection median.</s><s xml:id="_dzsh9rx">When computing other multivariate medians, we use functions from R packages listed in section 3.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3" xml:id="_Eesu28t">The muqie plot and some examples</head><p xml:id="_B3yNenv"><s xml:id="_TwuwMrg">As well as obtaining a robust location measure, we can use projections to provide information on the spread and configuration of the data.</s><s xml:id="_VC5PBbV">Obtaining true multivariate quantiles can be computationally challenging, and what we produce are not true multivariate quantiles, but they do enable us to gain useful understanding about multivariate data.</s><s xml:id="_3a3Pjmt">The muqie (MUltivariate QuantIlE) plots are constructed as follows.</s></p><p xml:id="_g4gVw5Z"><s xml:id="_zKFa8xm">First choose a unit-length direction vector, u.</s><s xml:id="_ETaUNPP">Then project our yamm-centred multivariate data onto u to obtain a univariate set.</s><s xml:id="_EZuDHP8">The muqie point, Q(α, u), is merely the vector u rescaled to have length equal to the α-quantile of the univariate set.</s><s xml:id="_d3vpZWQ">A muqie plot is the collection of all muqie points, Q(α, u) over all unit-length direction vectors u.</s><s xml:id="_G64Sd7q">In practice, we construct our plot by choosing a number of directions and joining the points.</s><s xml:id="_94bGcpN">The basic concept, and plots, are not new, Section 2 of Fraiman and Pateiro-Lopez <ref type="bibr" target="#b33">[34]</ref> introduces the concept based on mean-centred data and is related to ideas in <ref type="bibr" target="#b34">[35]</ref>.</s><s xml:id="_84qWPVK">Our main addition to this body of work is to (i) centre using yamm, or other robust median and (ii) presenting the muqie plots as dynamic videos of increasing α.</s><s xml:id="_74Yrydq">Fig 5. Muqie plot for the three cluster two-dimensional data set without outliers.</s><s xml:id="_VdVVb9w">The figures are produced for different values of pseudo-quantile α.</s><s xml:id="_2CsDghJ">The centre point (in blue) in each plot is the yamm median.</s><s xml:id="_SgPtkN4">Left: α = 0.4, Right: α = 0.8.</s><s xml:id="_9pe7cdS">These plots were produced by the muqie() function in the Yamm package.</s><s xml:id="_g4453z5">For the animated plot, the package includes the makeplot() function, which calls muqie() for multiple values of α.</s><s xml:id="_PJa6v89">Then we use the CRAN package animation to produce an animated GIF using saveGIF(makeplot(clusters2d[,-c(102,103)], nprojs = 4000), diff.col</s><s xml:id="_7Tvb5fr">= 3, interval = 0.1, width = 500, height = 500).</s></p><p xml:id="_WrbSXF6"><s xml:id="_VRp5Xqg">The movie beetle shows a three-dimensional Muqie plot using three variables from the beetle data.</s><s xml:id="_EKV7xZU">The R commands used were: saveGIF(makeplot3D(beetle, dm = c(1,3,6)), diff.col</s><s xml:id="_aSbjVQB">= 3, interval = 0.2, width = 500, height = 500)</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" xml:id="_nY2Tnb3">Conclusions and discussions</head><p xml:id="_aU2duhE"><s xml:id="_EsajwGW">We have introduced a new method, yamm, to compute the projection median, for data in R n with n � 2. We have proved the theoretical equivalence of yamm and the projection median.</s><s xml:id="_FvMPUC6">Through theoretical and numerical investigations we demonstrate the robustness of yamm on a simple, but illuminating, bivariate setup.</s><s xml:id="_MEnH7pn">Then, we illustrated three computation methods for the projection median, which can be best deployed in different situations.</s><s xml:id="_7UXE8ZX">Approximating the projection median by the Monte Carlo method is valid in any dimensions but requires a large number of projections to ensure accuracy, while using the trapezoidal rule is computationally fast and accurate in two and three dimensions, but requires more integration on the projection vector in the higher dimensions, which becomes rapidly more complex.</s><s xml:id="_7KhjzYe">The yamm approximation can also compute the median in any dimensions.</s><s xml:id="_dD5Ebn8">Its computational speed is not as quick as the other two, under the same conditions (e.g. the number of projections).</s><s xml:id="_UkPed8Z">However, thanks to the optimiser, a small number of the projections can be chosen to obtain an accurate median with a reasonable starting point (e.g.</s><s xml:id="_HQkYqKR">other multivartiate medians or mean value), which can be a distinct advantage.</s></p><p xml:id="_78rcrQN"><s xml:id="_vh7S5aR">Our research also documents the simulated empirical performance for different medians in terms of the computation time and the mean squared error.</s><s xml:id="_YtmZfTE">Using different R functions to calculate different multivariate medians, we find that the spatial median and the projection median are always accurate with relatively fast speed using the existing R functions.</s><s xml:id="_UUz33ZR">The performance of other multivariate medians either exhibits slow speed or large mean squared error.</s></p><p xml:id="_jvSKhPW"><s xml:id="_HbywU8s">Finally, we introduce our R package, Yamm, that contains our three methods to compute the projection median.</s><s xml:id="_cX4H8kS">We show that our methods coincide with each other in R 2 and R 3 , and all multivariate medians are not affected by the outliers in the dataset, but the location of the mean value varies a lot.</s><s xml:id="_hXqnhpq">Currently, the function PmedTrapz in the R package is only valid in R 2 and R 3 , further investment can be conducted on extending this function to higher dimensions.</s></p><p xml:id="_tdbm2uw"><s xml:id="_77KSJZn">The Yamm package also introduces our Muqie plots, which are capable of producing animated plots of two-and three-dimensional sets' projected quantiles.</s><s xml:id="_nHAyW4T">The animated 'growth' of these "quantile" plots give a vivid picture of the extent, spread and configuration of data in the sets.</s></p><p xml:id="_sJ4NJ2Z"><s xml:id="_9qkZ6Z8">The Yamm package is available on the CRAN archive.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig 1 .</head><label>1</label><figDesc><div><p xml:id="_H7Ky6zy"><s xml:id="_469TH4J">Fig 1. Polar plot (in radians) of the magnitude of m X (μ, a).</s><s xml:id="_XvdGE67">Grey line: μ = (2.2,</s><s xml:id="_azXX38N">8) and Blue line: μ = (2, 7.5).</s><s xml:id="_HvNtbDc">https://doi.org/10.1371/journal.pone.0229845.g001</s></p></div></figDesc><graphic coords="5,119.51,78.01,456.44,451.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4 .</head><label>4</label><figDesc><div><p xml:id="_mRcSweN"><s xml:id="_cHseXTs">The numerically computed crosses inFig 2 show that, for this setup, yamm plateaus somewhere between d = 2 and d = 4.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig 2 .</head><label>2</label><figDesc><div><p xml:id="_AJQ4pkz"><s xml:id="_gVyE8vg">Fig 2. Yamm computed on simulated setup, increasing the distance between two bivariate normals.</s><s xml:id="_Q9Kw9Xy">Crosses: numerically computed values; Solid blue line: approximation computed for general ν 1 and ν 2 ; Solid red line: approximation computed when ν 1 = (0, 0) T and ν 2 = (0, d) T .</s><s xml:id="_vJmBjRU">https://doi.org/10.1371/journal.pone.0229845.g002</s></p></div></figDesc><graphic coords="9,95.98,78.01,479.96,315.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>4 . 2 . 3</head><label>423</label><figDesc><div><p xml:id="_aSHr4ej"><s xml:id="_t269wNS">1.</s><s xml:id="_gu6hBnd">The actual data points is plotted with grey dots.</s><s xml:id="_CNtyXZm">The first plot in Fig 3 is producing excluding the two outliers, whilst the second one includes them.</s><s xml:id="_rNXR3Pd">The projection medians produced with different estimators are very close to each other, and not far from the other median estimators also.</s><s xml:id="_P9hTAGY">Fig 3 also shows that the multivariate medians are not particularly affect by the outliers, whilst the mean value is.</s><s xml:id="_VRDtH3y">Simulated data in R 3 with four clusters.</s><s xml:id="_B3rtasy">The function Plot3dMedian in Yamm plots the three-dimensional medians.</s><s xml:id="_KVFNJYr">The dataset clusters3d has four clusters, each generated from different independent normal distributions, as well as five outliers.</s><s xml:id="_qhWBCkh">Fig 4 is produced with the dataset clusters3d, whose outliers have been removed.</s><s xml:id="_xgNmDqg">It shows that apart from the Oja's median, the other medians are located close to each other.</s><s xml:id="_p8JtXWQ">Again, the three approximations of the projection median almost coincide in every component.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig 3 .</head><label>3</label><figDesc><div><p xml:id="_Pn6NZdg"><s xml:id="_k7rBqVa">Fig 3. Bivariate medians and mean for three cluster two-dimensional set.</s><s xml:id="_yCFckM5">Top: without outliers; Bottom: with outliers (out of plot area).</s><s xml:id="_gKTvBxF">https://doi.org/10.1371/journal.pone.0229845.g003</s></p></div></figDesc><graphic coords="16,200.01,78.01,357.62,576.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig 5</head><label>5</label><figDesc><div><p xml:id="_CSqQXmz"><s xml:id="_RWFN5xP">shows two muqie plots for α = 0.4 and α = 0.8.</s><s xml:id="_HESyDqF">The latter indicates the three cluster nature.</s><s xml:id="_DhyUFft">Surprisingly, this also shows up clearly in the α = 0.4 plot with the 0.4 quantile for, e.g.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig 4 .Fig 5 .</head><label>45</label><figDesc><div><p xml:id="_AqkXKdU"><s xml:id="_mCUbXFX">Fig 4. Trivariate medians &amp; mean for four cluster three-dimensional set.</s><s xml:id="_kCYWbZf">https://doi.org/10.1371/journal.pone.0229845.g004</s></p></div></figDesc><graphic coords="17,95.98,78.01,479.96,407.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="18,200.01,78.01,302.57,542.32" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_advFpe7"><s xml:id="_jYDW9JA">PLOS ONE | https://doi.org/10.1371/journal.pone.0229845May</s><s xml:id="_spE9vsc">7, 2020</s></p></note>
		</body>
		<back>

			<div type="funding">
<div xml:id="_jcUmuhD"><p xml:id="_xD8FkZS"><s xml:id="_ZUZJHjq">GN:supported by <rs type="funder">UK Engineering and Physical Sciences Research Council</rs> <rs type="grantNumber">EP/K020951/1</rs> <ref type="url" target="http://www.epsrc.ac.uk">http://www.epsrc.ac.uk</ref></s><s xml:id="_WyrB4gb">FC: supported by a <rs type="funder">University of Bristol/China Scholarship Council</rs> batch award.</s><s xml:id="_a6gkSeN">There is no specific grant number <ref type="url" target="https://www.chinesescholarshipcouncil.com">https://www.chinesescholarshipcouncil.com</ref></s><s xml:id="_eAgv8Qq"><ref type="url" target="http://www.bristol.ac.uk">http://  www.bristol.ac.uk</ref></s><s xml:id="_uCCeXcR">The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_9wu3zVJ">
					<idno type="grant-number">EP/K020951/1</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_gs8fUvg"><p xml:id="_Fjt6XKH"><s xml:id="_HGFw3ny">All relevant beetle data is already published and available in the article "Lubischew, 455-477."</s><s xml:id="_4YqSh7f">All other data is available in an R package via CRAN at <ref type="url" target="https://cran.r-project.org/package=Yamm">https://cran.r-project.org/  package=Yamm</ref> and also available as a Supporting Information file.</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_3cE3r3C" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_8PsYJpx">What is the center of an area or the center of a population</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Hayford</surname></persName>
		</author>
		<idno type="DOI">10.2307/2276137</idno>
		<ptr target="https://doi.org/10.2307/2276137" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Qe4qvf3">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">58</biblScope>
			<biblScope unit="page" from="47" to="58" />
			<date type="published" when="1902">1902</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hayford J. W. (1902). What is the center of an area or the center of a population. Journal of the Ameri- can Statistical Association, 8(58):47-58. https://doi.org/10.2307/2276137</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<title level="m" xml:id="_JbZEQnm">U ¨ber den Standort der Industrien</title>
		<imprint>
			<publisher>Mohr</publisher>
			<date type="published" when="1909">1909</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Weber A. (1909). U ¨ber den Standort der Industrien. Mohr.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<title level="m" xml:id="_chj5GnM">Theory of the Location of Industries</title>
		<imprint>
			<publisher>The University of Chicago Press</publisher>
			<date type="published" when="1929">1929</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Weber A. (1929). Theory of the Location of Industries. The University of Chicago Press.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_bzuzg3T">Mathematics and the picturing of data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<idno type="DOI">10.1090/amsip/042.2/08</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_guPAdkZ">Proceedings of the International Congress of Mathematicians</title>
		<meeting>the International Congress of Mathematicians</meeting>
		<imprint>
			<date type="published" when="1975">1975</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="523" to="531" />
		</imprint>
	</monogr>
	<note type="raw_reference">Tukey J. W. (1975). Mathematics and the picturing of data. In Proceedings of the International Congress of Mathematicians, 2:523-531.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_JK6REZr">Descriptive statistics for multivariate distributions</title>
		<author>
			<persName><forename type="first">H</forename><surname>Oja</surname></persName>
		</author>
		<idno type="DOI">10.1016/0167-7152(83)90054-8</idno>
		<ptr target="https://doi.org/10.1016/0167-7152(83)90054-8" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_DK4fqGg">Statistics &amp; Probability Letters</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="327" to="332" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Oja H. (1983). Descriptive statistics for multivariate distributions. Statistics &amp; Probability Letters, 1:327- 332. https://doi.org/10.1016/0167-7152(83)90054-8</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_YfaEhyB">A survey of multidimensional medians</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Small</surname></persName>
		</author>
		<idno type="DOI">10.2307/1403809</idno>
		<ptr target="https://doi.org/10.2307/1403809" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_NP57XcU">International Statistical Review</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="277" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Small C. G. (1990). A survey of multidimensional medians. International Statistical Review, 58(3):263- 277. https://doi.org/10.2307/1403809</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_QzJ6DpW">Sign tests in multidimension: Inference based on the geometry of data cloud</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sengupta</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1993.10476419</idno>
		<ptr target="https://doi.org/10.1080/01621459.1993.10476419" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Yh5GTjm">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1363" to="1370" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chaudhuri P. and Sengupta D. (1993). Sign tests in multidimension: Inference based on the geometry of data cloud. Journal of the American Statistical Association, 88:1363-1370. https://doi.org/10.1080/ 01621459.1993.10476419</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_RrjQ9ey">Multivariate median</title>
		<author>
			<persName><forename type="first">H</forename><surname>Oja</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-35494-6</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_TMG2Nfd">Robustness and Complex Data Structures, chapter 1</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Becker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fried</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kuhnt</forename><forename type="middle">S</forename></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
	<note type="raw_reference">Oja H. (2013). Multivariate median. In Becker C., Fried R., and Kuhnt S., editors, Robustness and Com- plex Data Structures, chapter 1, pages 3-16. Springer, Berlin.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_pHq4MSu">The projection median of a set of points in R 2</title>
		<author>
			<persName><forename type="first">S</forename><surname>Durocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.comgeo.2008.06.006</idno>
		<ptr target="https://doi.org/10.1016/j.comgeo.2008.06.006" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_JeS3WdR">Journal of Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="364" to="375" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Durocher S. and Kirkpatrick D. G. (2005). The projection median of a set of points in R 2 . Journal of Computational Geometry, 42:364-375. https://doi.org/10.1016/j.comgeo.2008.06.006</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_GHYc9Sy">The projection median of a set of points in R d</title>
		<author>
			<persName><forename type="first">R</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00454-011-9380-6</idno>
		<ptr target="https://doi.org/10.1007/s00454-011-9380-6" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZeGavRF">Discrete and Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="329" to="346" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Basu R., Bhattacharya B. B., and Talukdar T. (2012). The projection median of a set of points in R d . Dis- crete and Computational Geometry, 47(2):329-346. https://doi.org/10.1007/s00454-011-9380-6</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_QqCxJdj">Continuous univariate distributions</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_QbpwCwa">Wiley series in probability and mathematical statistics: Applied probability and statistics</title>
		<imprint>
			<publisher>Wiley &amp; Sons</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note>Number v.2</note>
	<note type="raw_reference">Johnson N. L., Kotz S., and Balakrishnan N. (1995). Continuous univariate distributions. Number v.2 in Wiley series in probability and mathematical statistics: Applied probability and statistics. Wiley &amp; Sons.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_3KVzA7J">Monte Carlo Statistical Methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" xml:id="_8eggYWm">Springer Texts in Statistics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Robert C. P. and Casella G. (2005). Monte Carlo Statistical Methods (Springer Texts in Statistics). Springer-Verlag, Berlin, Heidelberg.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_mTvxB5G">The convergence of a class of double-rank minimization algorithms</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Broyden</surname></persName>
		</author>
		<idno type="DOI">10.1093/imamat/6.1.76</idno>
		<ptr target="https://doi.org/10.1093/imamat/6.1.76" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ApFKNuj">The Institute of Mathematics and Its Applications</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="76" to="90" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Broyden C. G. (1970). The convergence of a class of double-rank minimization algorithms. The Institute of Mathematics and Its Applications, 6:76-90. https://doi.org/10.1093/imamat/6.1.76</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_7dThTTq">A new approach to variable metric algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<idno type="DOI">10.1093/comjnl/13.3.317</idno>
		<ptr target="https://doi.org/10.1093/comjnl/13.3.317" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Sm54M5W">Computer Journal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="322" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fletcher R. (1970). A new approach to variable metric algorithms. Computer Journal, 13(3):317-322. https://doi.org/10.1093/comjnl/13.3.317</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_neN2N4m">A family of variable metric updates derived by variational means</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<idno type="DOI">10.2307/2004873</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pTuHch2">Journal of the Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">109</biblScope>
			<biblScope unit="page" from="123" to="126" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Goldfarb D. (1970). A family of variable metric updates derived by variational means. Journal of the Mathematics of Computation, 24(109):123-126.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_7Mr6PyS">Conditioning of quasi-newton methods for function minimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Shanno</surname></persName>
		</author>
		<idno type="DOI">10.1090/s0025-5718-1970-0274029-x</idno>
		<ptr target="https://doi.org/10.1090/S0025-5718-1970-0274029-X" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_mfWAzGd">Journal of the Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">111</biblScope>
			<biblScope unit="page" from="647" to="656" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shanno D. F. (1970). Conditioning of quasi-newton methods for function minimization. Journal of the Mathematics of Computation, 24(111):647-656. https://doi.org/10.1090/S0025-5718-1970-0274029-X</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_btwGTuV">Fast approximations for sums of distances, clustering and the Fermat-Weber problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Morin</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0925-7721(02)00102-5</idno>
		<ptr target="https://doi.org/10.1016/S0925-7721(02)00102-5" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_hGsFpvW">Computational Geometry: Theory and Applications</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bose P., Maheshwari A., and Morin P. (2003). Fast approximations for sums of distances, clustering and the Fermat-Weber problem. Computational Geometry: Theory and Applications, 24(3):135-146. https://doi.org/10.1016/S0925-7721(02)00102-5</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_nDSWtPz">Algorithms for bivariate medians and a Fermat-Torricelli problem for lines</title>
		<author>
			<persName><forename type="first">G</forename><surname>Aloupis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Langerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Soss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Toussaint</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0925-7721(02)00173-6</idno>
		<ptr target="https://doi.org/10.1016/S0925-7721(02)00173-6" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_rrarTYT">Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Aloupis G., Langerman S., Soss M., and Toussaint G. T. (2003). Algorithms for bivariate medians and a Fermat-Torricelli problem for lines. Computational Geometry, 26:69-79. https://doi.org/10.1016/ S0925-7721(02)00173-6</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main" xml:id="_mWZVMFx">Optimization in Arrangements</title>
		<author>
			<persName><forename type="first">S</forename><surname>Langerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Steiger</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-36494-3_6</idno>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg, Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Langerman S. and Steiger W. (2003). Optimization in Arrangements. Springer Berlin Heidelberg, Ber- lin, Heidelberg.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_DHBZpu9">The multivariate l1-median and associated data depth</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Vardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.97.4.1423</idno>
		<ptr target="https://doi.org/10.1073/pnas.97.4.1423" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_V2YsBDJ">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1423" to="1426" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vardi Y. and Zhang C. (2000). The multivariate l1-median and associated data depth. Proceedings of the National Academy of Sciences, 97(4):1423-1426. https://doi.org/10.1073/pnas.97.4.1423</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_eeRAQMK">Efficient and fast estimation of the geometric median in Hilbert spaces with an averaged stochastic gradient algorithm</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cardot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Zitt</surname></persName>
		</author>
		<idno type="DOI">10.3150/11-bej390</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gdUTRHb">Bernoulli Society for Mathematical Statistics and Probability</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="43" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cardot H., Ce ´nac P., and Zitt P. A. (2013). Efficient and fast estimation of the geometric median in Hil- bert spaces with an averaged stochastic gradient algorithm. Bernoulli Society for Mathematical Statis- tics and Probability, 19(1):18-43.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_GSgD9PU">Algorithms for projection-pursuit robust principal component analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Croux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Filzmoser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Oliveira</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.968376</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tSdSTzU">KU Leuven Working Paper No. KBI</title>
		<imprint>
			<biblScope unit="volume">0624</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="43" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Croux C., Filzmoser P., and Oliveira M. R. (2006). Algorithms for projection-pursuit robust principal component analysis. KU Leuven Working Paper No. KBI 0624, 19(1):18-43.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_scYzq3Y">Algorithm AS 307: Bivariate location depth</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ruts</surname></persName>
		</author>
		<idno type="DOI">10.2307/2986073</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4BxnHvS">Journal of the Royal Statistical Society. Series C (Applied Statistics)</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="516" to="526" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rousseeuw P. J. and Ruts I. (1996). Algorithm AS 307: Bivariate location depth. Journal of the Royal Statistical Society. Series C (Applied Statistics), 45(4):516-526.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_sD3jKJ4">The bagplot: A bivariate boxplot</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ruts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<idno type="DOI">10.2307/2686061</idno>
		<ptr target="https://doi.org/10.2307/2686061" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_PkPbGzm">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="382" to="387" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rousseeuw P. J., Ruts I., and Tukey J. W. (1999). The bagplot: A bivariate boxplot. The American Stat- istician, 53(4):382-387. https://doi.org/10.2307/2686061</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_JhyVRsu">High-dimensional computation of the deepest location</title>
		<author>
			<persName><forename type="first">A</forename><surname>Struyf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0167-9473(99)00112-7</idno>
		<ptr target="https://doi.org/10.1016/S0167-9473(99)00112-7" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZEugjvu">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="415" to="426" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Struyf A. and Rousseeuw P. J. (2000). High-dimensional computation of the deepest location. Compu- tational Statistics &amp; Data Analysis, 34(4):415-426. https://doi.org/10.1016/S0167-9473(99)00112-7</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_22h4ECc">Computing the Oja median in R: The package OjaNP</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mosler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mo ¨tto ¨nen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nordhausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pokotylo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v092.i08</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JvMQWcF">ArXiv</title>
		<imprint>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fischer D., Mosler K., Mo ¨tto ¨nen J., Nordhausen K., Pokotylo O., and Vogel D. (2016). Computing the Oja median in R: The package OjaNP. ArXiv, pages 1-36.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_MdsQnt9">The projection median as a weighted average</title>
		<author>
			<persName><forename type="first">S</forename><surname>Durocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leblanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Skala</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.comgeo.2008.06.006</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6XPaVf3">Journal of Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="78" to="104" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Durocher S., Leblanc A., and Skala M. (2017). The projection median as a weighted average. Journal of Computational Geometry, 8:78-104.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main" xml:id="_gXEph2r">Computable, robust multivariate location using integrated univariate ranks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ramsay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ramsay K. (2017). Computable, robust multivariate location using integrated univariate ranks.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_cr2XNmF">A simplex algorithm for function minimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mead</surname></persName>
		</author>
		<idno type="DOI">10.1093/comjnl/7.4.308</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_htaxFtr">Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="308" to="313" />
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nelder J. A. and Mead R. (1965). A simplex algorithm for function minimization. Computer Journal, 7:308-313.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_nxzP7vG">Function minimization by conjugate gradients</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Reeves</surname></persName>
		</author>
		<idno type="DOI">10.1093/comjnl/7.2.149</idno>
		<ptr target="https://doi.org/10.1093/comjnl/7.2.149" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_nwq6dHQ">Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="148" to="154" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fletcher R. and Reeves C. M. (1964). Function minimization by conjugate gradients. Computer Journal, 7:148-154. https://doi.org/10.1093/comjnl/7.2.149</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main" xml:id="_F5FFMSg">Numerical Optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<idno type="DOI">10.1007/b98874</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>first edition</note>
	<note type="raw_reference">Nocedal J. and Wright S. J. (1999). Numerical Optimization. Springer, first edition.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_Ys6BGdq">A limited memory algorithm for bound constrained optimization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1137/0916069</idno>
		<ptr target="https://doi.org/10.1137/0916069" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_z3denKr">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1190" to="1208" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Byrd R. H., Lu P., Nocedal J., and Zhu C. (1995). A limited memory algorithm for bound constrained optimization. SIAM Journal on Scientific Computing, 16:1190-1208. https://doi.org/10.1137/0916069</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_aZYD5f6">On the use of discriminant functions in taxonomy</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Lubischew</surname></persName>
		</author>
		<idno type="DOI">10.2307/2527894</idno>
		<ptr target="https://doi.org/10.2307/2527894" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_kjfhfrh">Biometrics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="455" to="477" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lubischew A. A. (1962). On the use of discriminant functions in taxonomy. Biometrics, 18:455-477. https://doi.org/10.2307/2527894</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_2efh9MB">Quantiles for finite and infinite dimensional data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fraiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pateiro-Lopez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmva.2012.01.016</idno>
		<ptr target="https://doi.org/10.1016/j.jmva.2012.01.016" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_DxaReZj">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fraiman R. and Pateiro-Lopez B. (2012). Quantiles for finite and infinite dimensional data. Journal of Multivariate Analysis, 108:1-14. https://doi.org/10.1016/j.jmva.2012.01.016</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_5neksqm">Quantile tomography: using quantiles with multivariate data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mizera</surname></persName>
		</author>
		<idno type="DOI">10.5705/ss.2010.224</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rChqcFn">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1589" to="1610" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kong L. and Mizera I. (2012). Quantile tomography: using quantiles with multivariate data. Statistica Sinica, 22:1589-1610.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
