<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_VkfcZXV">Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review</title>
				<funder ref="#_jzgBQt8">
					<orgName type="full">National Research Foundation Singapore</orgName>
					<orgName type="abbreviated">NRF</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/501100001381</idno>
				</funder>
				<funder ref="#_aEw3NKR">
					<orgName type="full">National Medical Research Council health</orgName>
				</funder>
				<funder>
					<orgName type="full">National University of Singapore Graduate School for Integrative Sciences and Engineering Scholarship</orgName>
				</funder>
				<funder ref="#_25fWjNB">
					<orgName type="full">National University Health System joint</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Siqi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> NUS Graduate School for Integrative Science and Engineering , National University of Singapore , Singapore , Singapore</note>
								<orgName type="department">NUS Graduate School for Integrative Science and Engineering</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Saw Swee Hock School of Public Health , National University of Singapore , Singapore , Singapore</note>
								<orgName type="department">Saw Swee Hock School of Public Health</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kay</forename><surname>Choong See</surname></persName>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Division of Respiratory &amp; Critical Care Medicine , National University Hospital , Singapore , Singapore</note>
								<orgName type="department">Division of Respiratory &amp; Critical Care Medicine</orgName>
								<orgName type="institution">National University Hospital</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MBBS</roleName><forename type="first">;</forename><surname>Kee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Ngiam</surname></persName>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Group Chief Technology Office , National University Health System , Singapore , Singapore</note>
								<orgName type="department">Group Chief Technology Office</orgName>
								<orgName type="institution">National University Health System</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MBBS, MRCS, MMed</roleName><forename type="first">Frcs</forename><forename type="middle">;</forename><surname>Leo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anthony</forename><surname>Celi</surname></persName>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Institute for Medical Engineering and Science , Massachusetts Institute of Technology , Cambridge , MA , United States</note>
								<orgName type="department">Institute for Medical Engineering and Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Division of Pulmonary , Critical Care and Sleep Medicine , Beth Israel Deaconess Medical Center , Boston , MA , United States</note>
								<orgName type="department" key="dep1">Division of Pulmonary</orgName>
								<orgName type="department" key="dep2">Critical Care and Sleep Medicine</orgName>
								<orgName type="institution">Beth Israel Deaconess Medical Center</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>MA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MD, MS, MPH</roleName><forename type="first">Xingzhi</forename><surname>Sun</surname></persName>
							<affiliation key="aff6">
								<note type="raw_affiliation"><label>7</label> Ping An Health Technology , Beijing , China School of Public Health</note>
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">Ping An Health Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Mengling</forename><surname>Feng</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Saw Swee Hock School of Public Health , National University of Singapore , Singapore , Singapore</note>
								<orgName type="department">Saw Swee Hock School of Public Health</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Saw</forename><forename type="middle">Swee</forename><surname>Hock</surname></persName>
						</author>
						<author>
							<affiliation key="aff7">
								<note type="raw_affiliation">National University of Singapore 12 Science Drive 2 , #10 -01 Singapore , 117549 Singapore</note>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<addrLine>12 Science Drive 2 #10</addrLine>
									<postCode>-01 117549</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_qHYPEUC">Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F2D7539640781E414FBDA9BE6BBBE9E9</idno>
					<idno type="DOI">10.2196/18477</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T10:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_WacWjfk">artificial intelligence</term>
					<term xml:id="_GetGugm">reinforcement learning</term>
					<term xml:id="_gXa3Ahr">critical care</term>
					<term xml:id="_mauDuHw">decision support systems, clinical</term>
					<term xml:id="_bnnDc7U">intensive care unit</term>
					<term xml:id="_YgP3Mdr">machine learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_4JRdUpx"><p xml:id="_pyPyYED"><s xml:id="_YmqW28S">Background: Decision support systems based on reinforcement learning (RL) have been implemented to facilitate the delivery of personalized care.</s><s xml:id="_WYPtNYH">This paper aimed to provide a comprehensive review of RL applications in the critical care setting.</s></p><p xml:id="_qSxJtZw"><s xml:id="_BKgXYsP">Objective: This review aimed to survey the literature on RL applications for clinical decision support in critical care and to provide insight into the challenges of applying various RL models.</s><s xml:id="_jWgPDpB">Methods: We performed an extensive search of the following databases: PubMed, Google Scholar, Institute of Electrical and Electronics Engineers (IEEE), ScienceDirect, Web of Science, Medical Literature Analysis and Retrieval System Online (MEDLINE), and Excerpta Medica Database (EMBASE).</s><s xml:id="_MrSCjZs">Studies published over the past 10 years (2010-2019) that have applied RL for critical care were included.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7g23PHa">Results:</head><p xml:id="_J3ukrHT"><s xml:id="_hzCTrqt">We included 21 papers and found that RL has been used to optimize the choice of medications, drug dosing, and timing of interventions and to target personalized laboratory values.</s><s xml:id="_J3CV4EW">We further compared and contrasted the design of the RL models and the evaluation metrics for each application.</s></p><p xml:id="_gp9ASbV"><s xml:id="_S6EDbrQ">Conclusions: RL has great potential for enhancing decision making in critical care.</s><s xml:id="_6MnPQm7">Challenges regarding RL system design, evaluation metrics, and model choice exist.</s><s xml:id="_Z4mYJt5">More importantly, further work is required to validate RL in authentic clinical environments.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Za4s9Y4">Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gNHcZKn">Background</head><p xml:id="_tnftk5F"><s xml:id="_aN4tVjW">In the health care domain, clinical processes are dynamic because of the high prevalence of complex diseases and dynamic changes in the clinical conditions of patients.</s><s xml:id="_yjQJQAB">Existing treatment recommendation systems are mainly implemented using rule-based protocols defined by physicians based on evidence-based clinical guidelines or best practices <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>.</s><s xml:id="_K4k7sfy">In addition, these protocols and guidelines may not consider multiple comorbid conditions <ref type="bibr" target="#b3">[4]</ref>.</s><s xml:id="_hXG8pU4">In an intensive care unit (ICU), critically ill patients may benefit from deviation from established treatment protocols and from personalizing patient care using means not based on rules <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>.</s></p><p xml:id="_NHV97xG"><s xml:id="_PuJ6Ek9">When physicians need to adapt treatment for individual patients, they may take reference from randomized controlled trials (RCTs), systemic reviews, and meta-analyses.</s><s xml:id="_NZK2vhc">However, RCTs may not be available or definitive for many ICU conditions.</s><s xml:id="_PAybPsQ">Many patients admitted to ICUs might also be too ill for inclusion in clinical trials <ref type="bibr" target="#b5">[6]</ref>.</s><s xml:id="_zV6YHTB">Furthermore, only 9% of treatment recommendations in the ICU are based on RCTs <ref type="bibr" target="#b6">[7]</ref>, and the vast majority of RCTs in critical care have negative findings <ref type="bibr" target="#b7">[8]</ref>.</s><s xml:id="_WHjgWtK">To aid clinical decisions in ICUs, we need other methods, including the use of large observational data sets.</s><s xml:id="_WnygAS5">ICU data can be useful for learning about patients as they were collected in a data-rich environment.</s><s xml:id="_8jawhAX">A large amount of data can then be fed into artificial intelligence (AI) systems (using computers to mimic human cognitive functions) and machine learning methods (using computer algorithms to perform clinical tasks without the need for explicit instructions).</s><s xml:id="_EZY2jhz">AI and machine learning can then help with diagnosis <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, treatment <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, and resource management <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref> in the ICU.</s><s xml:id="_JTJ33Cv">Given the dynamic nature of critically ill patients, one machine learning method called reinforcement learning (RL) is particularly suitable for ICU settings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ezvB6r7">Fundamentals of Reinforcement Learning</head><p xml:id="_8SXrX4a"><s xml:id="_G4RX28u">RL is a goal-oriented learning tool where a computer agent, acting as a decision maker, analyzes available data within its defined environment <ref type="bibr" target="#b14">[15]</ref>, derives a rule for taking actions, and optimizes long-term rewards.</s><s xml:id="_ZEn3wYk">The agent is the RL model that we wish to develop.</s><s xml:id="_rMCbQyA">In general, an RL agent receives evaluative feedback about the performance of its action in each time step, allowing it to improve the performance of subsequent actions by trial and error <ref type="bibr" target="#b15">[16]</ref>.</s><s xml:id="_BXHg48c">Mathematically, this sequential decision-making process is called the Markov decision process (MDP) <ref type="bibr" target="#b16">[17]</ref>.</s><s xml:id="_x27wG8q">An MDP is defined by 4 major components: (1) a state that represents the environment at each time; <ref type="bibr" target="#b1">(2)</ref> an action the agent takes at each time that influences the next state; (3) a transition probability that provides an estimate for reaching different subsequent states, which reflects the environment for an agent to interact with; (4) a reward function is the observed feedback given a state-action pair.</s><s xml:id="_QcvYEaE">The solution of the MDP is an optimized set of rules and is termed the policy.</s><s xml:id="_BK7Ksm2">RL has already emerged as an effective tool to solve complicated control problems with large-scale, high-dimensional data in some application domains, including video games, board games, and autonomous control <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref>.</s><s xml:id="_GR6cDxx">In these domains, RL has been proven to achieve human-level capacity for learning complex sequential decisions.</s><s xml:id="_DxjzFet">For instance, Alpha Go is an RL agent for playing the strategy board game Go.</s><s xml:id="_YBS6xJj">On the basis of Alpha Go's learned policy, and given the current position of the Go stones, it is possible to decide where the next white/black stone should be placed on the board to maximize its chance of winning.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_4CU7tSd">Analogies to Critical Care</head><p xml:id="_35kmT2Y"><s xml:id="_VdRvgu7">For critical care, given the large amount and granular nature of recorded data, RL is well suited for providing sequential treatment suggestions, optimizing treatments, and improving outcomes for new ICU patients.</s><s xml:id="_SUEugAq">RL also has the potential to expand our understanding of existing clinical protocols by automatically exploring various treatment options.</s><s xml:id="_gtXjRkj">The RL agent analyzes the patient trajectories, and through trial and error, derives a policy, a personalized treatment protocol that optimizes the probability of favorable clinical outcomes (eg, survival).</s><s xml:id="_JabrJX3">As this computerized process is an attempt to mimic the human clinician's thought process, RL has also been called the AI clinician <ref type="bibr" target="#b20">[21]</ref>.</s></p><p xml:id="_m99BR5H"><s xml:id="_jkAX2Dq">We can consider the state as the well-being/condition of a patient.</s><s xml:id="_Pp9wszt">The state of the patients could depend on static traits (eg, patient demographics including age, gender, ethnicity, pre-existing comorbidity) and longitudinal measurements (eg, vital signs, laboratory test results).</s><s xml:id="_VcAduQ6">An action is a treatment or an intervention that physicians do for patients (eg, prescription of medications and ordering of laboratory tests).</s><s xml:id="_SfStGbP">The transition probability is the likelihood of state transitions, and it is viewed as a prognosis.</s><s xml:id="_gDSx6q3">If the well-being in the new state is improved, we assign a reward to the RL agent, but we penalize the agent if the patient's condition worsens or stays stagnant after the intervention.</s></p><p xml:id="_3pAfqna"><s xml:id="_3kcNy8Z">As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, if we take a snapshot of the current well-being of a patient as his/her state, the physician would provide a treatment or an intervention (an action) to the patient.</s><s xml:id="_Tvy73Jf">This action would lead the patient to the next state depending on his/her current state and the action performed on him/her.</s><s xml:id="_Mkf8BzP">While knowing the next state of the patient, the physician would need to take another action according to the new state.</s><s xml:id="_2gVwxS3">These state-action pairs would continue to rollout over time, and the resultant trajectory of state-action pairs could represent the changes in the patients' conditions and the sequential treatment decisions that were performed by the physicians.</s><s xml:id="_R6JXY28">We can define the length of the trajectory for each patient as fixed (eg, during the first 24 hours of the ICUs stay) or as dynamic (eg, different patients could be discharged from the ICUs at different times).</s><s xml:id="_ZWq3Eek">The main objective of the RL algorithm is to train an agent that can maximize the cumulative future reward from the state-action pairs given the patients' state-action trajectories.</s><s xml:id="_3PbJVAU">When a new state is observed, the agent is able to perform an action, which could choose the action for the greatest long-term outcome (eg, survival).</s><s xml:id="_rgrzwqd">When the RL agent is well-trained, it is possible to pick the best action given the state of a patient, and we describe this process as acting according to an optimal policy.</s></p><p xml:id="_dvd5Nmd"><s xml:id="_bgdCBde">A policy is analogous to a clinical protocol.</s><s xml:id="_67kaWFa">Nonetheless, a policy has advantages over a clinical protocol because it is capable of capturing more personalized details of individual patients.</s><s xml:id="_4DjyJw2">A policy can be represented by a table where it maps all possible states with actions.</s><s xml:id="_vP6HBCZ">Alternatively, a policy could also be represented by a deep neural network (DNN) where given the input of a patient's state, the DNN model outputs the highest probability of an action.</s><s xml:id="_FgbGUgG">An optimal policy can be trained using various RL algorithms.</s><s xml:id="_TWHcJTt">Some widely applied RL algorithms include the fitted-Q-iteration (FQI) <ref type="bibr" target="#b21">[22]</ref>, deep Q network (DQN) <ref type="bibr" target="#b22">[23]</ref>, actor-critic network <ref type="bibr" target="#b23">[24]</ref>, and model-based RL <ref type="bibr" target="#b24">[25]</ref>.</s><s xml:id="_xsFXrvz">More technical details about various RL models have been explained <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>.</s></p><p xml:id="_KCEsgCC"><s xml:id="_pnMGD9b">As RL in critical care is a relatively nascent field, we therefore aimed to review all the existing clinical applications that applied RL in the ICU setting for decision support over the past 10 years (2010-2019).</s><s xml:id="_jUW7UAr">Specifically, we aimed to categorize RL applications and summarize and compare different RL designs.</s><s xml:id="_7EbzxGG">We hope that our overview of RL applications in critical care can help reveal both the advances and gaps for future clinical development of RL.</s><s xml:id="_wZ2Sja9">A detailed explanation of the concept of RL and its algorithms is available in Multimedia Appendix 1 <ref type="bibr" target="#b27">[28]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XKTfFQb">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_KFdMEgz">Search Strategy</head><p xml:id="_UHrDafC"><s xml:id="_7mGJDZQ">A review of the literature was conducted using the following 7 databases: PubMed, Institute of Electrical and Electronics Engineers (IEEE), Google Scholar, Medical Literature Analysis and Retrieval System Online (MEDLINE), Excerpta Medica Database (EMBASE), ScienceDirect, and Web of Science.</s><s xml:id="_6KCUvRc">The search terms reinforcement learning, critical care, intensive care, intensive care units, and ICUs were combined.</s><s xml:id="_nQJ2a95">The search phrases listed in Textbox 1 were used to identify articles in each database.</s></p><p xml:id="_YVxQVnM"><s xml:id="_823xnKk">Textbox 1. Queries used to retrieve records.</s><s xml:id="_Em586AS">EMBASE (Excerpta Medica Database) • #1 'reinforcement learning' • #2 'intensive care unit' OR 'critical care' OR 'ICU' • #1 AND #2 Google Scholar • (conference OR journal) AND ("intensive care unit" OR "critical care" OR ICU) AND "reinforcement learning" -survey -reviews -reviewed -news IEEE (Institute of Electrical and Electronics Engineers) • (("Full Text Only": "reinforcement learning") AND "Full Text Only": "intensive care units") OR (("Full Text Only": "reinforcement learning") AND "Full Text Only": "critical care") MEDLINE (Medical Literature Analysis and Retrieval System Online) • multifield search=reinforcement learning, critical care, intensive care PubMed • ("reinforcement learning") AND (("ICU") OR ("critical care") OR ("intensive care unit") OR ("intensive care")) ScienceDirect • "reinforcement learning" AND ("critical care" OR "intensive care" OR "ICU") Web of Science • ALL=(intensive care unit OR "critical care" OR "ICU") AND ((ALL=("reinforcement learning")) AND LANGUAGE: (English))</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_sHSGbkj">Inclusion Criteria</head><p xml:id="_FsZstYk"><s xml:id="_gTM2xHJ">To be eligible for inclusion in this review, the primary requirement was that the article needed to focus on the implementation, evaluation, or use of an RL algorithm to process or analyze patient information (including simulated data) in an ICU setting.</s><s xml:id="_ZVDkrXu">Papers published from January 1, 2010, to October 19, 2019 were selected.</s><s xml:id="_6DUe3aP">General review articles and articles not published in English were excluded.</s><s xml:id="_85f2SZ2">Only papers that discussed sufficient details on the data, method, and results were included in this review.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_b9BXwSe">Data Synthesis</head><p xml:id="_Rbqph2e"><s xml:id="_4K6KAS8">Data were manually extracted from the articles included in the review.</s><s xml:id="_QVeBV8h">A formal quality assessment was not conducted, as relevant reporting standards have not been established for articles on RL.</s><s xml:id="_RZ632Vr">Instead, we extracted the following characteristics from each study: the purpose of the study, data source, number of patients included, main method, evaluation metrics, and related outcomes.</s><s xml:id="_deWZnYw">The final collection of articles was divided into categories to assist reading according to their application type in the ICUs.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cYgRQs7">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Uz54Zbq">Selection Process and Results Overview</head><p xml:id="_JJCH2pr"><s xml:id="_3fdRNVJ">The selection process of this review was demonstrated using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses flow diagram (Figure <ref type="figure" target="#fig_1">2</ref>).</s><s xml:id="_eEFEdHq">From the full text of 269 distinct articles, an independent assessment for eligibility was performed by 2 authors (SL and MF).</s><s xml:id="_8kKSKrt">Disagreements were discussed to reach consensus.</s><s xml:id="_Z7DqyP2">During the full-text review, 249 articles were excluded, and 21 articles were eventually included.</s></p><p xml:id="_UTptGMz"><s xml:id="_WC443Yn">The reasons for exclusion during the review process are outlined in Table <ref type="table" target="#tab_1">1</ref>.</s><s xml:id="_jxyQwMR">The papers discussed issues in the critical care setting, but not using RL as an approach Not using RL a as the approach in critical care 6 1</s></p><p xml:id="_VmFZEFP"><s xml:id="_f4Rspg9">The methods and results were not clearly described and thus not qualified for this review No clear description of the method and result 7 a RL: reinforcement learning.</s></p><p xml:id="_rjkfgQn"><s xml:id="_ukvu4YP">In this section, we organized the reviewed articles into 4 categories, which reflect clinically relevant domains: (1) optimal individualized target laboratory value; (2) optimal choice of medication; (3) optimal timing of an intervention; and (4) optimal dosing of medication.</s></p><p xml:id="_mTEHjU5"><s xml:id="_btccZ9H">We plotted the number of articles reviewed by their category and year of publication in Figure <ref type="figure" target="#fig_2">3</ref>.</s><s xml:id="_aHVG3Kq">We found that the majority of the papers were published in the past 3 years (n=17), indicating an increasing trend of applying RL-based approaches to assist physicians in decision making in critical care.</s><s xml:id="_vavCxzw">In each of the 4 categories, we further organized the articles into subgroups based on their clinical questions (Figure <ref type="figure" target="#fig_2">3</ref>).</s><s xml:id="_KxN6fMx">The figure shows that most of the applications used RL to find optimal drug dosing (n=16) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref>, followed by the timing of an intervention (n=3) <ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref>.</s><s xml:id="_rph3vxS">Only a few applications were looking at the individualized laboratory value (n=1) <ref type="bibr" target="#b45">[46]</ref> and the optimal choice of medication (n=1) <ref type="bibr" target="#b46">[47]</ref>.</s><s xml:id="_FepUzke">Next, we discuss the details for each category with the methods and outcomes for each application.</s><s xml:id="_aXqG9B7">In particular, we further grouped the studies based on specific medication or treatment type in categories 3 and 4 to assist readers.</s><s xml:id="_r8RwupS">A summary of all study details is found in Multimedia Appendix 2.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NJUhQ25">Optimal Individualized Target Laboratory Value</head><p xml:id="_mUEdSKa"><s xml:id="_RfffGyB">Even after decades of routine use of laboratory value ranges, reference standards may need to be reconsidered, especially for individual patients <ref type="bibr" target="#b47">[48]</ref>.</s><s xml:id="_AcdmCxP">Personalized targets for laboratory values in ICU patients could account for disease severity, comorbidities, and other patient-specific differences.</s><s xml:id="_pCsqArt">Weng et al <ref type="bibr" target="#b45">[46]</ref> tried to identify individualized targeted blood glucose levels as a reference for physicians.</s><s xml:id="_D35brSa">They applied an RL-based approach, policy iteration, to learn the target glycemic range at an hourly interval for severely ill patients with sepsis using real ICU data.</s><s xml:id="_d6FmqM3">Their approach was tested using the Medical Information Mart for Intensive Care III (MIMIC III), a large, publicly available ICU database <ref type="bibr" target="#b48">[49]</ref>.</s><s xml:id="_wC5qnZk">MIMIC III contains information for hospital admissions of 43,000 patients in critical care units during 2001 and 2012, from which the authors extracted hourly data for 5565 patients with sepsis.</s></p><p xml:id="_dwZgJee"><s xml:id="_RVJK4v8">Weng et al <ref type="bibr" target="#b45">[46]</ref> constructed their RL model as follows: First, they represented the patients' states from 128 variables.</s><s xml:id="_xNyazjf">These variables included patient demographics, comorbid conditions, vital sign changes, and laboratory value changes.</s><s xml:id="_tKBrJbm">They used a spare autoencoder <ref type="bibr" target="#b49">[50]</ref> to reduce the high dimensionality of the raw features (128 dimensions) to only 32 dimensions so that the RL model could be trained more efficiently with limited observational data.</s><s xml:id="_cuJkWCS">Second, they chose to act upon 1 of 11 discrete ranges of serum glucose at each time step.</s><s xml:id="_DdJJVS4">Third, they designed the reward function so that the RL agent could recommend an hourly target glucose level to optimize long-term survival.</s><s xml:id="_J2apsh5">A positive 100 was assigned to the end state if patients survived 90 days after admission, and a negative 100 was assigned if the patients died.</s><s xml:id="_XgRUYMP">For each state-action pair, the value of the pair was iteratively estimated using the reward from the training data.</s></p><p xml:id="_QXekUWP"><s xml:id="_4YaHm9Z">To understand how the reward value was related to mortality, the authors assigned values to discrete buckets using separate test data.</s><s xml:id="_ZtShzrX">In each value bucket, if the state-action pair is part of a trajectory where a patient died, a label of 1 was assigned to that bucket; otherwise, a label of 0 was assigned.</s><s xml:id="_dwZVHVd">After assigning all the state-action pairs from the test data with the labels in the corresponding value bucket, the mortality rate could be estimated for each value bucket.</s><s xml:id="_Qb2RWsA">The authors plotted the estimated mortality rate with respect to the value-buckets and found an inverse relationship between them, where the highest value was associated with the lowest mortality.</s><s xml:id="_DNvcKdv">This result suggested that the learnt value represented the relationship between the state-action pair and mortality and that the learnt value of the state-action pairs from training data was validated on the test data.</s></p><p xml:id="_AtShVYt"><s xml:id="_K2PqaWf">To validate the RL policy, the author calculated the frequency of state transitions from the training data and generated new trajectories.</s><s xml:id="_5KvmnWq">Starting from the observed state in the test data, the RL policy would recommend an action with the highest value, and the subsequent state was estimated with the transition probability.</s><s xml:id="_hHaAa6c">By averaging the value for all state-action pairs in the simulated trajectory, the mortality for simulated trajectories could be estimated by mapping this value in the mortality-value plot.</s><s xml:id="_v67Dfwc">Compared with the actual mortality rate in the test data, the author claimed that if physicians could control patients' hourly blood glucose levels within the range recommended by the RL model, the estimated 90-day mortality would be lowered by 6.3% (from 31% to 24.7%).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_YjgeR58">Optimal Timing of Intervention</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_zCNEt77">Weaning of Mechanical Ventilation</head><p xml:id="_shcjdEx"><s xml:id="_yZyGU5h">Mechanical ventilation (MV) is a life-saving treatment applied in approximately a third of all critically ill patients <ref type="bibr" target="#b52">[53]</ref>.</s></p><p xml:id="_fts2ACW"><s xml:id="_AmEqSh2">Prematurely discontinuing MV (premature weaning) and excessively prolonged MV (late weaning) are both associated with higher mortality <ref type="bibr" target="#b53">[54]</ref>.</s><s xml:id="_QcTYWh2">The best time to wean may be uncertain <ref type="bibr" target="#b54">[55]</ref>.</s></p><p xml:id="_kQ9TRx5"><s xml:id="_CcvCdHZ">To optimize the timing of ventilation discontinuation, Prasad et al <ref type="bibr" target="#b42">[43]</ref> applied the RL-based FQI (the details of the FQI algorithm are explained in Multimedia Appendix 1 <ref type="bibr" target="#b27">[28]</ref>) on the MIMIC III database for all patients who were kept under ventilator support for more than 24 hours and extracted their records every 10 min from ICU admission to discharge.</s><s xml:id="_S3bzyN5">Patient states included a number of factors that could affect extubation, such as demographics, pre-existing conditions, comorbidities, and time-varying vital signs.</s><s xml:id="_aV84cpe">The action for the ventilation setting was binary, that is, for each 10-min time step, the RL agent needed to decide whether the ventilation should be set on (continued MV) or off (weaned from MV).</s><s xml:id="_ADNGKjs">For reward design, Prasad et al <ref type="bibr" target="#b42">[43]</ref> followed an existing weaning protocol from the Hospital of University of Pennsylvania.</s><s xml:id="_erTekAz">They assigned reward values to the RL agent at each time step according to 3 major considerations: (1) the RL agent should penalize each additional hour spent on the ventilator, (2) the RL agent should be assigned a positive reward value to a weaning action if the patient's vital signs and laboratory results were steady and within normal ranges after extubation, and (3) there was no reward value for failed spontaneous breathing trial or for reintubation after the first extubation.</s><s xml:id="_4AYvspT">For RL policy evaluation, the authors calculated the proportion of weaning actions from the RL policy, referencing the total number of weaning actions from the clinician's policy at each time step, and calculated the overall consistency of weaning transitions.</s><s xml:id="_eFsnr8U">The recommend actions from the RL agent could match 85% of those from clinicians.</s><s xml:id="_HhEJT8u">The authors categorized the degree of consistency into 5 bins, and plotted the distribution of the number of reintubations with respect to the discrete consistency levels.</s><s xml:id="_ayGqfaR">Their results showed that when the consistency was high, vital sign fluctuations were fewer, laboratory results were more in-range, and reintubations were minimized.</s></p><p xml:id="_YfaezKG"><s xml:id="_UwPq4Xh">Yu et al <ref type="bibr" target="#b44">[45]</ref> studied the same clinical issue as Prasad et al <ref type="bibr" target="#b42">[43]</ref> and used the same data set, but designed a different reward function using inverse RL.</s><s xml:id="_pnzm7jv">The inverse RL model directly learnt reward mapping from data for each state-action pair and inferred what clinicians would wish to achieve as a reward.</s><s xml:id="_DCqKEm2">Similar to Prasad et al <ref type="bibr" target="#b42">[43]</ref>, the RL recommendations by Yu et al <ref type="bibr" target="#b44">[45]</ref> were associated with shorter weaning times and fewer reintubations compared with clinician decision making.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_sfX3gHG">Timing to Order Laboratory Tests</head><p xml:id="_4zMQgVj"><s xml:id="_kp5RHyw">The timing of ordering a laboratory test can be challenging.</s><s xml:id="_tYPaQaE">Delayed testing would lead to continued uncertainty over the patient's condition and possible late treatment <ref type="bibr" target="#b55">[56]</ref>.</s><s xml:id="_JrSb5E7">However, excessively early ordering of laboratory tests can cause unnecessary discomfort to the patient, increase the risk of anemia, and increase health care cost.</s></p><p xml:id="_nxdp4t9"><s xml:id="_gAanx5Q">Cheng et al <ref type="bibr" target="#b43">[44]</ref> applied the FQI method to find the optimal timing for ordering laboratory tests among patients with sepsis in the MIMIC III data set.</s><s xml:id="_z5SXGAs">They examined the timing of 4 types of laboratory tests: white blood cell count (WBC), creatinine, blood urea nitrogen (BUN), and lactate.</s><s xml:id="_mwsUezW">They sampled the patients' data at hourly intervals and constructed the state of a patient by considering the predictive variables of severe sepsis or acute kidney failure, including respiratory rate, heart rate, mean blood pressure, temperature, creatinine, BUN, WBC, and lactate.</s><s xml:id="_TjRQCGR">The missing values were predicted by a multioutput Gaussian process <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b57">58]</ref>.</s><s xml:id="_HGwaKtW">In their RL model, they chose to design the reward function with the combination of 4 factors:</s></p><p xml:id="_JfSf8Mf"><s xml:id="_8xW3sku">(1) a positive reward should be given only if the ordering of test was necessary, while penalizing over or under ordering; <ref type="bibr" target="#b1">(2)</ref> the RL agent should be encouraged to order laboratory tests when there was a sudden change in laboratory results or vital signs; (3) negative reward should be given if the laboratory results were similar to the last measurements (no information gain); (4) a penalty would be added to a reward whenever a test was ordered, to reflect the testing cost.</s><s xml:id="_hnDssGC">Their RL agent, compared with clinicians, was able to reduce the number of laboratory tests by 27% for lactate and 44% for WBC, while maintaining high information gain.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_KhvNURx">Optimal Dosing of a Drug</head><p xml:id="_AXQdkjw"><s xml:id="_uDjKTan">Recommendations for dosing regimens in ICU patients are often extrapolated from clinical trials in healthy volunteers or noncritically ill patients.</s><s xml:id="_VMcGEV2">This extrapolation assumes similar drug behavior (pharmacokinetics and pharmacodynamics) in the ICU and other patients or healthy volunteers.</s><s xml:id="_V5TbnME">However, it is well known that many drugs used in critically ill patients may have alterations in pharmacokinetic and pharmacodynamic properties because of pathophysiological changes or drug interactions <ref type="bibr" target="#b58">[59]</ref>.</s><s xml:id="_zHXbsyG">Therefore, critically ill patients bring unique challenges in drug dosing.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_xbWaVng">Dosing of Propofol</head><p xml:id="_z2tC2dN"><s xml:id="_N4u2QPh">Critically ill patients in ICUs often require sedation to facilitate various clinical procedures and to comfort patients during treatment.</s><s xml:id="_jG8N563">Propofol is a widely used sedative medication <ref type="bibr" target="#b59">[60]</ref>, but titration of propofol is challenging, and both over sedation and under sedation can have adverse effects <ref type="bibr" target="#b31">[32]</ref>.</s><s xml:id="_EThvuWQ">Of the studies reviewed, 6 studies have focused on applying RL to determine the optimal dosage for propofol while maintaining the physiological stability of the patient.</s><s xml:id="_FGc5xAa">The bispectral index (BIS) was used to monitor sedation level and to determine the effect of propofol.</s></p><p xml:id="_EQckJy3"><s xml:id="_qPKJ2tp">Borera et al <ref type="bibr" target="#b28">[29]</ref> was the first to apply RL to a pharmacokinetic model <ref type="bibr" target="#b60">[61]</ref> to describe the time-dependent distribution of propofol in human surgical patients.</s><s xml:id="_GDafDjm">The RL agent was a neural network aimed at optimizing the propofol dose to achieve the target BIS value.</s><s xml:id="_eY925PS">The patient's state and state transition were modeled using a mathematical pharmacokinetic model with predefined parameters such as the concentration at half maximal effect of BIS, degree of nonlinearity of BIS, and time-lag coefficient to estimate the BIS value for simulated patients.</s><s xml:id="_2H6vJPn">The action was a discrete range of propofol infusion rate.</s><s xml:id="_ArAYjQb">The reward function was the error rate between the target BIS value and the current simulated BIS value, where a larger negative reward was given when the current simulated BIS value was further away from the predefined target value.</s><s xml:id="_gyzk4pe">They measured the performance of the RL agent by looking at the time to reach the target BIS value (steady time).</s><s xml:id="_qZwG2fa">The evaluation was conducted on 1000 simulated patients.</s><s xml:id="_eJ2Bwnz">On average, the steady time was 3.25 min for the BIS value to reach target.</s></p><p xml:id="_4YKmU7T"><s xml:id="_WcqXXfQ">To ensure patient safety, propofol dosing should consider the concurrent stability of vital parameters.</s><s xml:id="_7AmFde3">For instance, Padmanabhan et al <ref type="bibr" target="#b29">[30]</ref> chose mean arterial pressure (MAP) as the secondary control variable.</s><s xml:id="_MAGQWUM">The authors combined the error rates for both BIS and MAP when designing the reward.</s><s xml:id="_z2hpZag">The target for the RL agent was to infuse propofol so that the target BIS would be reached in a short time, whereas MAP was kept within a desired range.</s><s xml:id="_2K4fjfS">In subsequent studies, Padmanabhan et al <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> modified their methods with different RL training algorithms (Q-learning and policy iteration).</s><s xml:id="_s3SqKqH">In all their studies, the RL agent was able to suggest accurate propofol doses and achieve target BIS values within a few minutes.</s></p><p xml:id="_B6GtDMv"><s xml:id="_DrD3jY7">In contrast to fixed pharmacokinetic models in the RL model environment, Yu et al <ref type="bibr" target="#b44">[45]</ref> applied FQI and Bayesian inverse RL on the MIMIC III database.</s><s xml:id="_jP65WgG">They considered patients' demographic characteristics, pre-existing conditions, comorbidities, and time-varying vital signs to construct the state of the patient.</s><s xml:id="_cUZVGNj">Their inverse RL model interpreted clinician preference as a reward for different patient states.</s><s xml:id="_cUzrJ6Y">The learned reward function from the inverse RL model suggested that clinicians may pay more attention to patients' cardiorespiratory stability rather than oxygenation when making decisions about propofol dosage.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NcTHugK">Dosing of Intravenous Heparin</head><p xml:id="_G3pJ47H"><s xml:id="_WRN5nPE">Anticoagulant agents are often used to prevent and treat a wide range of cardiovascular diseases.</s><s xml:id="_jn4Awwf">Heparin is commonly used in critical care <ref type="bibr" target="#b61">[62]</ref>, yet its precise dosing is complicated by a narrow therapeutic window.</s><s xml:id="_xDubf6J">Overdosing of heparin results in bleeding whereas under dosing risks clotting.</s><s xml:id="_SNre68M">To guide heparin dosing, activated partial thromboplastin time (aPTT) is often used as a measure of the anticoagulant effect of heparin.</s></p><p xml:id="_zsGcJrc"><s xml:id="_5GCSwqm">Nemati et al <ref type="bibr" target="#b5">[6]</ref> applied FQI with a neural network to optimize and individualize heparin dosing.</s><s xml:id="_3FvbDMz">Their study was conducted on the MIMIC II database, with the reward function based on aPTT levels following heparin dosing <ref type="bibr" target="#b62">[63]</ref>.</s><s xml:id="_Mzfamn5">The reward to the RL agent will be high if the aPTT value is between 60 and 100 seconds.</s><s xml:id="_5mmeuUE">After training, they plot the state-action value with respect to the level of consistency between the RL policy and clinician practice.</s><s xml:id="_9DA6KEY">Their results showed that, on average, following the recommendations of the RL agent resulted in higher state-action values.</s></p><p xml:id="_wr3h8Hw"><s xml:id="_3ZeXwMK">Ghassemi et al <ref type="bibr" target="#b32">[33]</ref> and Lin et al <ref type="bibr" target="#b33">[34]</ref> focused on a personalized optimal heparin dosing using different RL algorithms.</s><s xml:id="_hnk8Q2d">In addition to the MIMIC III data set, Lin et al <ref type="bibr" target="#b33">[34]</ref> applied an actor-critic network on the Emory Healthcare data set from Emory University.</s><s xml:id="_rq5wDFa">For RL policy evaluation, Lin et al <ref type="bibr" target="#b33">[34]</ref> regressed the discordance between RL policy and physician practice over the number of clotting and bleeding complications, adjusting for covariates such as history of clot or bleed, weight, age, and sequential organ failure assessment score.</s><s xml:id="_ygQY6N5">The regression coefficient suggested that following the RL agent's recommendations would have likely resulted in improved clinical outcomes with a reduced number of clotting and bleeding complications.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_nuWBf27">Intravenous Fluids, Vasopressors, and Cytokine Therapy for Treating Sepsis</head><p xml:id="_yWxcRWu"><s xml:id="_6gqV57E">Sepsis is the third leading cause of death and is expensive to treat <ref type="bibr" target="#b63">[64]</ref>.</s><s xml:id="_jBQej4X">Besides antibiotics and source control, challenges remain with the use of intravenous (IV) fluids to correct hypovolemia and administration of vasopressors to counteract sepsis-induced vasodilation.</s><s xml:id="_wjvyzG6">Raghu et al <ref type="bibr" target="#b35">[36]</ref> suggested a data-driven RL approach to recommend personalized optimal dosage for IV fluids and vasopressors to improve hospital mortality.</s><s xml:id="_D323ZgU">Their RL model was double DQN with dueling, which can minimize the overestimation problem of previous Q-learning models.</s><s xml:id="_QPe3ken">The details of the Q-learning and double DQN algorithms are explained in Multimedia Appendix 1 <ref type="bibr" target="#b27">[28]</ref>.</s><s xml:id="_YCFr8z5">The authors considered patients' demographics, laboratory values, vital signs, and intake/output events as state features in the RL model.</s><s xml:id="_ZyEDyZG">Action was designed as a combination of 5 discrete bins for IV fluid dosing and 5 bins for vasopressor dosing to treat patients with sepsis.</s><s xml:id="_sUegjYM">The reward was issued at the terminal time step of the patient's trajectory, with a positive reward if the patient survived.</s><s xml:id="_HtY4sYZ">Data were extracted from the MIMIC III database for all patients who fulfilled sepsis-3 criteria <ref type="bibr" target="#b64">[65]</ref>.</s><s xml:id="_JFMvN73">For policy evaluation, Raghu et al <ref type="bibr" target="#b35">[36]</ref> plotted the estimated hospital mortality with respect to the difference between dosages recommended by the RL agent and by clinicians.</s><s xml:id="_s99pCRB">The plot showed that the mortality was lowest when there was no discrepancy between RL policy and physician decision making.</s><s xml:id="_Pf934uP">Six other groups of researchers also focused on the same research question and applied various RL algorithms with slightly different designs of the state space, reward function, and evaluation metrics <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref>.</s><s xml:id="_VKGxe4H">The findings from these studies all suggest that the RL agent would be able to learn from the data and if physicians followed the RL policy, the estimated hospital mortality could be improved.</s></p><p xml:id="_GR8pecU"><s xml:id="_48tZ7gj">Among the aforementioned studies, Komorowski et al <ref type="bibr" target="#b20">[21]</ref> were the pioneers of applying RL in the ICU, using data from patients with sepsis in the MIMIC III database.</s><s xml:id="_Ahv7YCs">They inferred a patient's health status using an array of inputs, which included demographics, vital signs, laboratory tests, illness severity scores, medications, procedures, fluid intake and output, physician notes, and diagnostic coding.</s><s xml:id="_uF7cnhH">Patient data were aggregated and averaged every 4 hours to represent patient states.</s><s xml:id="_aVggRD5">Using a k-means algorithm, these patient states were then simplified into 750 discrete mutually exclusive clusters.</s><s xml:id="_tD6DsFu">A sequence of these clustered states would describe a particular patient's trajectory.</s><s xml:id="_9hygU6x">The authors estimated the state transition probability by counting how many times each transition was observed and converted the counts to a stochastic matrix.</s><s xml:id="_NepZyuW">This transition matrix contained the probability for each patient going to a new state, given a previous action taken in the current state.</s><s xml:id="_BGKSnEW">The entire trajectory of a patient's state can be estimated using the transition matrix.</s><s xml:id="_3bSr88E">The authors applied a policy iteration RL algorithm that learnt the optimal dosing policy for IV fluids and vasopressors to maximize the probability of 90-day survival.</s></p><p xml:id="_d4NH8Uk"><s xml:id="_7Fphxd9">Nevertheless, the study by Komorowski et al <ref type="bibr" target="#b20">[21]</ref>.</s><s xml:id="_auQxvNe">had several limitations.</s><s xml:id="_UZyD4D5">First, their study only considered fluid and vasopressor management, ignoring other important treatments such as source control, correction of hypovolemia, and management of secondary organ failures <ref type="bibr" target="#b20">[21]</ref>.</s><s xml:id="_czvejDf">Second, 90-day mortality is affected by factors outside of the ICU, which the study did not take into account.</s><s xml:id="_8GTv7aR">Third, clinical decision making considers both short-term outcomes (eg, physiological stability) and long-term outcomes (eg, kidney failure or mortality), but the study only considered mortality as the single goal for training the RL algorithm <ref type="bibr" target="#b65">[66]</ref>.</s><s xml:id="_F8eduZS">Fourth, discretizing patient health status into discrete clusters loses data granularity and may limit the ability to detect changes in patient status.</s><s xml:id="_gsXrZyf">These limitations also occur in other studies, which we will elaborate in the Discussion section.</s></p><p xml:id="_zvY3QEp"><s xml:id="_cAYEraC">Other than using IV fluids and vasopressors for treating sepsis.</s><s xml:id="_DqEZp4h">Petersen et al <ref type="bibr" target="#b41">[42]</ref> investigated cytokine therapy using the deep deterministic policy gradient <ref type="bibr" target="#b66">[67]</ref> method.</s><s xml:id="_FkWwjny">The details of the policy gradient RL algorithm are explained in Multimedia Appendix 1 <ref type="bibr" target="#b27">[28]</ref>.</s><s xml:id="_neHnAWV">They evaluated the RL model by using an agent-based model, the innate immune response agent-based model <ref type="bibr" target="#b67">[68]</ref>, that simulated the immune response to infection.</s><s xml:id="_EaPku2n">The RL policy was able to achieve a very low mortality rate of 0.8% over 500 simulated patients, and suggested that personalized multicytokine treatment could be promising for patients with sepsis.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9xZdjCm">Dosing of Morphine</head><p xml:id="_vWYknjW"><s xml:id="_k5MyhKx">Critically ill patients may experience pain as a result of disease or certain invasive interventions.</s><s xml:id="_QY6hfSm">Morphine is one of the most commonly used opioids for analgesia <ref type="bibr" target="#b68">[69]</ref>.</s><s xml:id="_ZTz4agx">Similar to sedation, the dosing of analgesia is subject to uncertainty.</s><s xml:id="_4R2FKj3">Lopez-Martinez et al <ref type="bibr" target="#b40">[41]</ref> collected data for patients who had at least one pain intensity score and at least one dose of IV morphine in the MIMIC III database.</s><s xml:id="_CYfaEgZ">They applied double DQN with dueling as their RL model and constructed the state space to be continuous with features including the patient's self-reported pain intensity and their measured physiological status.</s><s xml:id="_JQrMd44">The action was a choice of 14 discrete dosing ranges of IV morphine.</s><s xml:id="_mAcrhUV">The reward was determined by considering both the patients' cardiorespiratory stability and their pain intensity.</s><s xml:id="_vHgf5Td">The highest reward was given when pain was absent and both heart rate and respiration rate were within the acceptable range.</s><s xml:id="_PzyxRQk">By comparing the RL policy with physicians' choices, Lopez-Martinez et al <ref type="bibr" target="#b40">[41]</ref> found that RL policy tended to prescribe higher doses of morphine.</s><s xml:id="_r3MpXN9">This result was consistent with previous studies: continuous dosing provided similar or even better pain relief with no increase in acute adverse effects <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b70">71]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ZPpF7qV">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9dc2bRP">Principal Findings</head><p xml:id="_W8jz6ma"><s xml:id="_uexbYJM">Our comprehensive review of the literature demonstrates that RL has the potential to be a clinical decision support tool in the ICU.</s><s xml:id="_eSxcjW4">As the RL algorithm is well aligned with sequential decision making in ICUs, RL consistently outperformed physicians in simulated studies.</s><s xml:id="_JDc89Yv">Nonetheless, challenges regarding RL system design, evaluation metrics, and model choice exist.</s><s xml:id="_aYyVUSW">In addition, all current applications have focused on using retrospective data sets to derive treatment algorithms and require prospective validation in authentic clinical settings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ZKDugnu">RL System Design</head><p xml:id="_Dwg8HX2"><s xml:id="_btAQvqE">The majority of applications were similar in their formulation of the RL system design.</s><s xml:id="_WCACSMe">The state space is usually constructed by features including patient demographics, laboratory test values, and vital signs, whereas some studies applied encoding methods to represent the state of the patients instead of using raw features.</s><s xml:id="_894k3jZ">The action space was very specific to each application.</s><s xml:id="_NspqZDf">For instance, in terms of the dosing category, the action space would be discretized ranges of medication dosage.</s><s xml:id="_jb6wEQr">For other categories, such as timing of an intervention, the action space would be the binary indicator of an intervention for each time step.</s><s xml:id="_eyWBCx2">The number of action levels differed among the studies.</s><s xml:id="_RCjqjJB">For some studies, the action levels could be as many as a dozen or a hundred (eg, optimal medication combination), whereas for other studies, the action levels were limited to only 2 (eg, on/off MV).</s><s xml:id="_y8N3EJ9">The design of the reward function is central to successful RL learning.</s><s xml:id="_SSkuF7p">Most of the reward functions were designed a priori with guidance from clinical practice and protocols, but 2 studies <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b44">45]</ref> managed to directly learn the reward function from the data using inverse RL.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_tpKp2c2">Evaluation Metrics</head><p xml:id="_685pRJu"><s xml:id="_UsK2tpQ">The only metric that matters is if the adoption of an RL algorithm leads to improvement in some clinical outcomes.</s><s xml:id="_tauHcmP">Most studies calculated the estimated mortality as the long-term outcome and drew plots to show the relationship between the estimated mortality versus the learnt value of patients' state-action trajectories, where the higher value function was associated with lower mortality.</s><s xml:id="_jnHWX2b">The RL agent would provide treatment suggestions for those actions with higher values, thus leading to a lower estimated mortality.</s><s xml:id="_3X56x9D">Estimated mortality is a popular metric for RL policy evaluation.</s><s xml:id="_AHccy5R">However, the problem with the estimated mortality is that it is calculated from simulated trajectories with observational data, and may not be the actual mortality.</s></p><p xml:id="_xpd9YgW"><s xml:id="_vNt6DfP">Mortality is not always the most relevant and appropriate outcome measure.</s><s xml:id="_a7rMDWf">For instance, in the study by Weng et al <ref type="bibr" target="#b45">[46]</ref>, they tried to identify individualized targeted blood glucose levels as a reference for physicians.</s><s xml:id="_Tpb4fq7">In their study, 90-day mortality was used to evaluate the RL policy.</s><s xml:id="_vXYj8et">However, a more relevant measure could be considered, such as short-term changes in the blood glucose level, physiological stability, and development of complications.</s></p><p xml:id="_HWQM6Wn"><s xml:id="_PEq5jWb">Several studies that focused on propofol titration have considered BIS as the evaluation metric to monitor the sedation level and hence to determine the effect of propofol.</s><s xml:id="_sut6VCt">Although BIS monitoring is fairly objective, assessing sedation is usually performed by health care providers with clinically validated behavioral assessment scales such as the Richmond Agitation-Sedation Scale score <ref type="bibr" target="#b71">[72]</ref>.</s><s xml:id="_CmCJ2mH">In addition, EEG-based technologies, such as BIS and M-entropy, have been validated more in the operating room than in the ICU <ref type="bibr" target="#b72">[73]</ref>.</s><s xml:id="_EMjjNRQ">Furthermore, BIS cannot be used as the sole monitoring parameter for sedation, as it is affected by several other factors, including the anesthetic drugs used, muscle movement, or artifacts from surgical equipments <ref type="bibr" target="#b73">[74]</ref>.</s></p><p xml:id="_Kjwwqzd"><s xml:id="_QrJF7fY">To date, there has been no prospective evaluation of an RL algorithm.</s><s xml:id="_86jE8PZ">Moreover, the observational data itself may not truly reflect the underlying condition of patients.</s><s xml:id="_NjMYHDs">This is known as the partially observable MDP <ref type="bibr" target="#b74">[75]</ref> problem, where we are only able to represent a patient's state by the observed physiological features, which are solved by mathematical approximation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_PCmcYDG">Model Choice</head><p xml:id="_bxaxgz7"><s xml:id="_mXA4fqU">FQI and DQN seem to be the top RL approaches among the reviewed studies.</s><s xml:id="_HvrahWG">FQI is not a deep learning-based RL model, which guarantees convergence for many commonly used regressors, including kernel-based methods and decision trees.</s><s xml:id="_wph5WGx">On the other hand, DQN leverages the representational power of DNNs to learn optimal treatment recommendations, mapping the patient state-action pair to the value function.</s><s xml:id="_PdyvFTJ">Neural networks hold an advantage over tree-based methods in iterative settings in that it is possible to simply update the network weights at each iteration, rather than rebuilding the trees entirely.</s></p><p xml:id="_8PQ5DPn"><s xml:id="_eDSwkzk">Both FQI and DQN are off-policy RL models.</s><s xml:id="_qgaqP3x">Off-policy refers to learning about one way of behaving from the data generated by another way of selecting actions <ref type="bibr" target="#b75">[76]</ref>.</s><s xml:id="_mEzURJB">For instance, an off-policy RL model tries to train a policy X to select actions in each step, but it estimates the Q-values from state-action pairs where the action was chosen by following another policy Y.</s><s xml:id="_WZqb2Cj">In contrast to off-policy learning, on-policy learning uses the same policy X to choose actions and to evaluate the returns in each step during training.</s><s xml:id="_HTuprCr">Most of the included studies adopted off-policy RL models because the RL models aim to learn policy X from the data, which was generated by following real actions of physicians (policy Y).</s><s xml:id="_mSsmVDM">The data generated by policy Y is the actual physicians' policy, where the RL models try to learn and improve from.</s><s xml:id="_YZC6Wp2">This is the fundamental idea of applying off-policy RL models.</s></p><p xml:id="_RvQ5eMg"><s xml:id="_BFtKsqc">In addition, both FQI and DQN are value-based RL models that aim to learn the value functions.</s><s xml:id="_CK9D3B3">In value-based RL, a policy can be derived by following the action with the highest value at each time step.</s><s xml:id="_PqfJ32Q">Another type of RL is called policy-based RL, which aims to learn the policy directly without worrying about the value function.</s><s xml:id="_SFVcrvs">Policy-based methods are more useful in continuous space.</s><s xml:id="_hZ7ehTT">When the data volume is insufficient to train a DQN model, the DQN is not guaranteed to achieve a stable RL policy.</s><s xml:id="_gg473gj">As there is an infinite number of actions or states to estimate the values for, value-based RL models are too computationally expensive in the continuous space.</s><s xml:id="_p2BzYXf">However, policy-based RL models demand more data samples for training.</s><s xml:id="_7NmcXFe">Otherwise, the learned policy is not guaranteed to converge to an optimal one.</s><s xml:id="_xy6yvAK">Both value-based and policy-based RL models can be grouped in a more general way as model-free RL.</s><s xml:id="_NFWRBAS">Here the word model-free means the environment is unknown to an agent.</s><s xml:id="_na6SbVw">The RL agent makes use of the trajectories generated from the environment, rather than explicitly knowing the rule or the transition probability.</s><s xml:id="_9dHVeCp">In contrast to model-free RL, model-based RL requires the agent to know the transition probability for all the state-action combinations explicitly and hence impractical as the state space and action space grow.</s><s xml:id="_vAzbKqD">In the critical care context, patients' conditions and prognosis are very complex to apply model-based RL because we are not exactly sure about the probability of all state transitions.</s><s xml:id="_TRUUcSq">In addition, most studies in critical care could only use limited retrospective data to train the model offline.</s><s xml:id="_xzxSUv5">Therefore, we found that most of the studies have applied a value-based RL model to utilize the available observational data.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_APUCEuH">Common Data Sets</head><p xml:id="_32BZHdj"><s xml:id="_NCq5p49">We found that 71% (15/21) of applications utilized the MIMIC II or MIMIC III database to conduct their experiments.</s><s xml:id="_2nkkaYP">We conjecture that such popularity might be due to public availability and high quality of MIMIC data.</s><s xml:id="_xeCmdP7">However, data collected from a single source may introduce potential bias to the research findings.</s><s xml:id="_jETMfdC">There are inherent biases in the medical data sets obtained at various institutions due to multiple factors, including operation strategy, hospital protocol, instrument difference, and patient preference.</s><s xml:id="_JvGhKGT">Therefore, the RL models trained on a single data set, regardless of the data volume, cannot be confidently applied to another data set.</s><s xml:id="_AsFkNdX">The findings from the reviewed articles may not be generalizable to other institutions and populations.</s><s xml:id="_aa7Vx48">In addition to the MIMIC database, one of the studies also utilized the eICU Research Institute (eRI) database to test their RL model <ref type="bibr" target="#b76">[77]</ref>.</s><s xml:id="_j4XbxFC">The eRI database has a larger volume of data compared with the MIMIC database, and it is also publicly available.</s><s xml:id="_Yc25z3T">We suggest that future applications could cross-validate their models on both the MIMIC and eRI databases.</s><s xml:id="_UCQByjq">In addition, all current applications have focused on using retrospective data sets to derive treatment algorithms and require prospective validation in authentic clinical settings.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9ZHCg6n">Strengths and Limitations of This Study</head><p xml:id="_cZkejtX"><s xml:id="_BwtzscH">The strengths of this paper include the comprehensive and extensive search for all available publications that applied RL as an approach in the critical care context.</s><s xml:id="_j26nJZS">Nonetheless, we acknowledge the limitations.</s><s xml:id="_c8PHGSW">We included papers (eg, those on arXiv) that have not been peer-reviewed before publication but these papers have undergone a postpublication peer review.</s><s xml:id="_eGZrNH8">According to the search phrases applied in this review, we may miss out certain papers that applied RL in critical care, but did not specify the phrase intensive care nor ICU in their full text papers.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GhYq7ZK">Challenges and Future Directions</head><p xml:id="_xGU5yhs"><s xml:id="_vJJDex8">A number of challenges must be overcome before RL can be implemented in a clinical setting.</s><s xml:id="_aHHdPhe">First, it is important to have a meaningful reward design.</s><s xml:id="_AsYMwP3">The RL agent would be vulnerable in case of reward misspecification, and might not be able to produce any meaningful treatment suggestion.</s><s xml:id="_uaZa9Jc">Inverse RL can be an alternative to a priori-specified reward functions.</s><s xml:id="_5rzQ4D9">However, inverse RL assumes that the given data represent the experts' demonstrations and the recommendations from the data were already optimal; these may not be true.</s></p><p xml:id="_uzQtUKa"><s xml:id="_5SvMEEs">Second, medical domains present special challenges with respect to data acquisition, analysis, interpretation, and presentation of these data in a clinically relevant and usable format.</s><s xml:id="_HzJBcWs">Addressing the question of censoring in suboptimal historical data and explicitly correcting for the bias that arises from the timing of interventions or dosing of medication is crucial to fair evaluation of learnt policies.</s><s xml:id="_xb8J8vH">Third, another challenge for applying the RL model in the clinical setting is exploration.</s><s xml:id="_sRQY5nV">Unlike other domains such as game playing, where one can repeat the experiments as many times, in the clinical setting, the RL agent has to learn from a limited set of data and intervention variations that were collected offline.</s><s xml:id="_3T8gd2S">Using trial and error to explore all possible scenarios may conflict with medical ethics, thereby limiting the ability of the RL agent to attempt new behaviors to discover ones with higher rewards and better long-term outcomes.</s></p><p xml:id="_a254sUj"><s xml:id="_2PhjbpS">In comparison with other machine learning approaches, there is an absence of acceptable performance standards in RL.</s><s xml:id="_cYFuCJk">This problem is not unique to RL but seems harder to address in RL compared with other machine learning approaches, such as prediction and classification algorithms, where accuracy and precision recall are more straightforward to implement.</s><s xml:id="_fMxfzdg">However, it is worth noting that RL has a distinct advantage over other machine learning approaches, that one can choose which outcome to optimize by specifying the reward function.</s><s xml:id="_Mywpp84">This provides an opportunity to involve patient preferences and shared decision making.</s><s xml:id="_xgCzu2P">This becomes more relevant when learned policies change depending on the reward function.</s><s xml:id="_JrxMBa3">For example, an RL algorithm that optimizes survival may recommend a different set of treatments versus an RL algorithm that optimizes neurologic outcome.</s><s xml:id="_pxvDdFG">In such situations, patient preference is elicited to guide the choice of the RL algorithm.</s></p><p xml:id="_YShHHJy"><s xml:id="_JK7PFbn">RL has the potential to offer considerable advantages in supporting the decision making of physicians.</s><s xml:id="_WBwNESj">However, certain key issues need to be addressed, such as clinical implementation, ethics, and medico-legal limitations in health care delivery <ref type="bibr" target="#b77">[78]</ref>.</s><s xml:id="_pkX2BcY">In fact, any machine learning model would need to address these limitations carefully to serve as truly effective tools.</s><s xml:id="_yxENADs">In clinical practice, the RL models need to be refined iteratively throughout the time to include newly generated data from electronic health systems in hospitals, and the model must produce robust results for physicians to interpret and understand.</s><s xml:id="_my4J8EU">Besides, patients' understanding and willingness to use the RL model as a supporting tool in their care would be another important consideration.</s><s xml:id="_xYXhmpy">Another important ethical consideration would be the liability in case of medical error when the RL model recommendation differs from the physician.</s><s xml:id="_y7QgdSj">It has an impact on the autonomy of both the physician and patient.</s><s xml:id="_7ba7DSe">The problem of medical error works in both ways when there is a poor outcome: (1) if the physician follows the RL model recommendation, can the clinician then blame the model and the personnel who maintain the model; (2) if the clinician does not follow the RL model recommendation, can the clinician then be said to have made the wrong decision and be penalized.</s></p><p xml:id="_s9EYm5V"><s xml:id="_YChHdxH">Possible directions for future work include (1) modeling the RL environment as a partially observable MDP, in which observations from the data are mapped to some state space that truly represents patients' underlying well-being; (2) extending the action space to be continuous, suggesting more precise and practical treatment recommendations to physicians; and (3) improving the interpretability of the RL models so that physicians can have more confidence in accepting the model results.</s><s xml:id="_p7K7tPm">With further efforts to tackle these challenges, RL methods could play a crucial role in helping to inform patient-specific decisions in critical care.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc><div><p xml:id="_qYzpp5c"><s xml:id="_afa2h7Z">Figure 1.</s><s xml:id="_zRshfaf">Illustration of reinforcement learning in critical care.</s></p></div></figDesc><graphic coords="3,56.69,82.34,481.90,148.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc><div><p xml:id="_Qk93vjC"><s xml:id="_vPFmtV8">Figure 2. Preferred Reporting Items for Systematic Reviews and Meta-Analyses flow diagram of the search strategy.</s></p></div></figDesc><graphic coords="5,56.69,82.34,481.90,309.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc><div><p xml:id="_wfPuDJA"><s xml:id="_YUkxqHM">Figure 3. Mapping of reinforcement learning studies in critical care by application type.</s></p></div></figDesc><graphic coords="6,56.69,82.38,481.84,346.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc><div><p xml:id="_gKfDt3U"><s xml:id="_Dk4Jykx">Exclusion criteria used to exclude papers.</s></p></div></figDesc><table><row><cell>Criterion number</cell><cell>Exclusion criteria</cell><cell>Justification</cell><cell>Excluded articles, n</cell></row><row><cell>1</cell><cell>Duplicates</cell><cell>The papers have duplicate titles</cell><cell>39</cell></row><row><cell>2</cell><cell>Not a research article</cell><cell>The papers were blog articles, reports, comments, or views</cell><cell>23</cell></row><row><cell>3</cell><cell>Not written in English</cell><cell>The papers were not written in English</cell><cell>6</cell></row><row><cell>4</cell><cell>Review</cell><cell>The papers were review articles regarding general methods on big</cell><cell>12</cell></row><row><cell></cell><cell></cell><cell>data, deep learning, and clinical applications</cell><cell></cell></row><row><cell>5</cell><cell>Not applied in the field of</cell><cell>The papers did not focus on applications in critical care or intensive</cell><cell>92</cell></row><row><cell></cell><cell>critical care</cell><cell>care</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>115</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_xmxZVXy"><s xml:id="_5rxvaxw">J Med Internet Res 2020 | vol.</s><s xml:id="_5CtDRrg">22 | iss.</s><s xml:id="_Sah9gPd">7 | e18477 | p. 2 https://www.jmir.org/2020/7/e18477</s><s xml:id="_Wezk6TX">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_cAEFMjK"><s xml:id="_nHu9NvY">J Med Internet Res 2020 | vol.</s><s xml:id="_2aTqRz6">22 | iss.</s><s xml:id="_tynUkx5">7 | e18477 | p. 3 https://www.jmir.org/2020/7/e18477</s><s xml:id="_Xf5Q5yG">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_uKUMXjc"><s xml:id="_HHuBX5n">J Med Internet Res 2020 | vol.</s><s xml:id="_eukUccu">22 | iss.</s><s xml:id="_ZGbnK2G">7 | e18477 | p. 4 https://www.jmir.org/2020/7/e18477</s><s xml:id="_smZ7QUn">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p xml:id="_dg5kUyD"><s xml:id="_599vtXP">J Med Internet Res 2020 | vol.</s><s xml:id="_QXjy3cm">22 | iss.</s><s xml:id="_6GTfSNn">7 | e18477 | p. 5 https://www.jmir.org/2020/7/e18477</s><s xml:id="_XFE9u54">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p xml:id="_havtZkX"><s xml:id="_KW9MhQR">J Med Internet Res 2020 | vol.</s><s xml:id="_nSPREFc">22 | iss.</s><s xml:id="_pvQDdVH">7 | e18477 | p. 6 https://www.jmir.org/2020/7/e18477</s><s xml:id="_XeKFk8P">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p xml:id="_W3wTQ6X"><s xml:id="_aWUtdzr">J Med Internet Res 2020 | vol.</s><s xml:id="_hNPeTbA">22 | iss.</s><s xml:id="_9psPgVn">7 | e18477 | p. 7 https://www.jmir.org/2020/7/e18477</s><s xml:id="_ZHfmhUx">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p xml:id="_tAEnRqQ"><s xml:id="_6hWMrvn">J Med Internet Res 2020 | vol.</s><s xml:id="_qgQVCCm">22 | iss.</s><s xml:id="_uUCHRA6">7 | e18477 | p. 8 https://www.jmir.org/2020/7/e18477</s><s xml:id="_Z4KwHU8">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p xml:id="_7jv4V4b"><s xml:id="_bEDwCqF">J Med Internet Res 2020 | vol.</s><s xml:id="_bWhGxjy">22 | iss.</s><s xml:id="_W2MtyNR">7 | e18477 | p. 9 https://www.jmir.org/2020/7/e18477</s><s xml:id="_Y5kMkP8">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_8"><p xml:id="_F3aWY2P"><s xml:id="_mfpZN3E">J Med Internet Res 2020 | vol.</s><s xml:id="_TKVWPHw">22 | iss.</s><s xml:id="_3tkpxVJ">7 | e18477 | p. 10 https://www.jmir.org/2020/7/e18477</s><s xml:id="_GuE6QEB">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_9"><p xml:id="_FM4h8sX"><s xml:id="_5ceGWAy">J Med Internet Res 2020 | vol.</s><s xml:id="_Bx85gqq">22 | iss.</s><s xml:id="_5eAehDu">7 | e18477 | p. 11 https://www.jmir.org/2020/7/e18477</s><s xml:id="_ATYgUTm">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_10"><p xml:id="_peWnSEu"><s xml:id="_uk7dvsg">J Med Internet Res 2020 | vol.</s><s xml:id="_KrkgWTY">22 | iss.</s><s xml:id="_KaaGXTn">7 | e18477 | p. 12 https://www.jmir.org/2020/7/e18477</s><s xml:id="_ZbBEue9">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_11"><p xml:id="_a2JNeAt"><s xml:id="_x8GdBvv">J Med Internet Res 2020 | vol.</s><s xml:id="_VfaDFKc">22 | iss.</s><s xml:id="_NvuxpZQ">7 | e18477 | p. 13 https://www.jmir.org/2020/7/e18477</s><s xml:id="_GgpDrzf">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_12"><p xml:id="_fWvAHP8"><s xml:id="_QaaZBpg">J Med Internet Res 2020 | vol.</s><s xml:id="_QUQzxjt">22 | iss.</s><s xml:id="_NApTZdg">7 | e18477 | p. 14 https://www.jmir.org/2020/7/e18477</s><s xml:id="_83aPjEp">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_13"><p xml:id="_Mz3vwVE"><s xml:id="_7vZt2rt">J Med Internet Res 2020 | vol.</s><s xml:id="_9BPRMBG">22 | iss.</s><s xml:id="_7C5V66t">7 | e18477 | p. 15 https://www.jmir.org/2020/7/e18477</s><s xml:id="_aq64xUF">(page number not for citation purposes)</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_14"><p xml:id="_h7wF9qv"><s xml:id="_d98TKzF">J Med Internet Res 2020 | vol.</s><s xml:id="_RuGrWkE">22 | iss.</s><s xml:id="_nvc9fWJ">7 | e18477 | p. 16 https://www.jmir.org/2020/7/e18477</s><s xml:id="_dCYtdEm">(page number not for citation purposes)</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_bmPzqB6">Acknowledgments</head><p xml:id="_AxUEQuR"><s xml:id="_KuBKGSw">SL was funded by the <rs type="funder">National University of Singapore Graduate School for Integrative Sciences and Engineering Scholarship</rs>.</s><s xml:id="_wBfawj2">This research was supported by the <rs type="funder">National Research Foundation Singapore</rs> under its <rs type="programName">AI Singapore Programme</rs> (award no.</s><s xml:id="_XNpGHjf"><rs type="grantNumber">AISG-GC-2019-002</rs>), the <rs type="funder">National University Health System joint</rs> grant (<rs type="grantNumber">WBS R-608-000-199-733</rs>), and the <rs type="funder">National Medical Research Council health</rs> service research grant (<rs type="grantNumber">HSRG-OC17nov004</rs>).</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_jzgBQt8">
					<idno type="grant-number">AISG-GC-2019-002</idno>
					<orgName type="program" subtype="full">AI Singapore Programme</orgName>
				</org>
				<org type="funding" xml:id="_25fWjNB">
					<idno type="grant-number">WBS R-608-000-199-733</idno>
				</org>
				<org type="funding" xml:id="_aEw3NKR">
					<idno type="grant-number">HSRG-OC17nov004</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_HeYJSxS">Optimal Choice of Medications</head><p xml:id="_EZVPFTJ"><s xml:id="_DYRuW8Y">Apart from some clinical decision support systems, commonly used systems such as computerized prescriber order entry and bar-coded medication administration lack personalized recommendations to optimize medication effectiveness and minimize side effects <ref type="bibr" target="#b50">[51]</ref>.</s><s xml:id="_UBVkVZt">Wang et al <ref type="bibr" target="#b46">[47]</ref> applied a deep learning network based on RL to exploit medication recommendations with a data-driven strategy.</s><s xml:id="_TwP8bW4">Their approach accounted for individual patient demographics, laboratory values, vital signs, and diagnoses from the MIMIC III database.</s><s xml:id="_2NgxVvv">They selected the top 1000 out of 4127 medications and the top 2000 out of 6695 diseases (represented by the International Classification of Diseases, Ninth Revision codes), which covered 85.4% of all medication records and 95.3% of all diagnosis records, respectively.</s><s xml:id="_NyqruwB">To reduce the problem complexity, the authors further categorized the 1000 medications into 180 drug categories using anatomical therapeutic chemical codes and aggregated patients' drug prescriptions into 24-hour windows.</s></p><p xml:id="_pRw6uH3"><s xml:id="_4BCSg6b">The authors defined RL action as the medication combinations from the 180 drug categories.</s><s xml:id="_NCgZp8M">They adopted an actor-critic RL agent that suggested a daily medication prescription set, and aimed to improve patients' hospital survival.</s><s xml:id="_jqYzPYU">The details of the actor-critic RL algorithm are explained in Multimedia Appendix 1 <ref type="bibr" target="#b27">[28]</ref>.</s><s xml:id="_ezZu6FW">For each patient's ICU day, the actor network would recommend one medication combination by considering state variables such as demographics, laboratory results, and vital signs.</s><s xml:id="_hxNG5NX">A reward value of positive 15 would be given to the end state if a patient survived until hospital discharge and negative 15 if the patient died.</s><s xml:id="_FESgZeM">The reward was designated as 0 for all other time steps.</s><s xml:id="_SZRuS5V">To counterbalance the actor network, the critic network was applied to evaluate the consistency of actual physician prescriptions and the RL agent's recommendations.</s><s xml:id="_3Kc8CWh">The net effect of the actor-critic RL agent was to optimize the long-term outcomes of patients (hospital mortality) while minimizing deviations of RL-recommended actions from actual prescription patterns.</s><s xml:id="_PxscHhf">In addition to the actor-critic network, the authors also applied long short-term memory <ref type="bibr" target="#b51">[52]</ref> to represent a patient's current state by incorporating the long sequence of all historical states.</s><s xml:id="_EMSpnGP">Wang et al <ref type="bibr" target="#b46">[47]</ref> suggested that hospital mortality would be reduced by 4.4% if clinicians adhered to the RL agent's recommendations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_xQ5mUjB">Conflicts of Interest</head><p xml:id="_7Fj9NaA"><s xml:id="_T3BR32H">None declared.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7REqvHx">Multimedia Appendix 1</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_nzqekPf">Designing a pilot sequential multiple assignment randomized trial for developing an adaptive treatment strategy</title>
		<author>
			<persName><forename type="first">D</forename><surname>Almirall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Compton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gunlicks-Stoessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="DOI">10.1002/sim.4512</idno>
		<idno>Medline: 22438190</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_c6FwfAE">Stat Med</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="1887" to="1902" />
			<date type="published" when="2012-07-30">2012 Jul 30</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Almirall D, Compton SN, Gunlicks-Stoessel M, Duan N, Murphy SA. Designing a pilot sequential multiple assignment randomized trial for developing an adaptive treatment strategy. Stat Med 2012 Jul 30;31(17):1887-1902 [FREE Full text] [doi: 10.1002/sim.4512] [Medline: 22438190]</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_pEbDkCa">A physician advisory system for chronic heart failure management based on knowledge patterns</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marple</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Salazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tamil</surname></persName>
		</author>
		<idno type="DOI">10.1017/s1471068416000429</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_E3CYDwx">Theor Pract Log Prog</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="604" to="618" />
			<date type="published" when="2016-10-14">2016 Oct 14</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen Z, Marple K, Salazar E, Gupta G, Tamil L. A physician advisory system for chronic heart failure management based on knowledge patterns. Theor Pract Log Prog 2016 Oct 14;16(5-6):604-618. [doi: 10.1017/S1471068416000429]</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_XxGkmUR">Implementing evidence-based medicine in general practice: a focus group based study</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hannes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vermeire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aertgeerts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Buntinx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Depoorter</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2296-6-37</idno>
		<idno>Medline: 16153300</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_V3D6EkD">BMC Fam Pract</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2005-09-09">2005 Sep 9</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Hannes K, Leys M, Vermeire E, Aertgeerts B, Buntinx F, Depoorter A. Implementing evidence-based medicine in general practice: a focus group based study. BMC Fam Pract 2005 Sep 9;6:37 [FREE Full text] [doi: 10.1186/1471-2296-6-37] [Medline: 16153300]</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_wZcdVDq">Making use of guidelines in clinical practice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baker</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.319.7216.1078</idno>
		<idno>Medline: 10521225</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pEJp95N">Br Med J</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="issue">7216</biblScope>
			<biblScope unit="page">1078</biblScope>
			<date type="published" when="1999-10-16">1999 Oct 16</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Hutchinson A, Baker R. Making use of guidelines in clinical practice. Br Med J 1999 Oct 16;319(7216):1078 [FREE Full text] [doi: 10.1136/bmj.319.7216.1078] [Medline: 10521225]</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_fthKhtX">A new, evidence-based estimate of patient harms associated with hospital care</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>James</surname></persName>
		</author>
		<idno type="DOI">10.1097/pts.0b013e3182948a69</idno>
		<idno>Medline: 23860193</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PWe73Jv">J Patient Saf</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="122" to="128" />
			<date type="published" when="2013-09">2013 Sep</date>
		</imprint>
	</monogr>
	<note type="raw_reference">James JT. A new, evidence-based estimate of patient harms associated with hospital care. J Patient Saf 2013 Sep;9(3):122-128. [doi: 10.1097/PTS.0b013e3182948a69] [Medline: 23860193]</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_Tuv2bWZ">Optimal medication dosing from suboptimal clinical examples: a deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nemati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Clifford</surname></persName>
		</author>
		<idno type="DOI">10.1109/embc.2016.7591355</idno>
		<idno>Medline: 28268938</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tFYXbHh">Conf Proc IEEE Eng Med Biol Soc</title>
		<imprint>
			<biblScope unit="volume">2016</biblScope>
			<biblScope unit="page" from="2978" to="2981" />
			<date type="published" when="2016-08">2016 Aug</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nemati S, Ghassemi MM, Clifford GD. Optimal medication dosing from suboptimal clinical examples: a deep reinforcement learning approach. Conf Proc IEEE Eng Med Biol Soc 2016 Aug;2016:2978-2981. [doi: 10.1109/EMBC.2016.7591355] [Medline: 28268938]</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_zKYDrC3">Scientific evidence underlying the recommendations of critical care clinical practice guidelines: a lack of high level evidence</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00134-018-5142-8</idno>
		<idno>Medline: 29564478</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DKKUh9x">Intensive Care Med</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1189" to="1191" />
			<date type="published" when="2018-07">2018 Jul</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhang Z, Hong Y, Liu N. Scientific evidence underlying the recommendations of critical care clinical practice guidelines: a lack of high level evidence. Intensive Care Med 2018 Jul;44(7):1189-1191. [doi: 10.1007/s00134-018-5142-8] [Medline: 29564478]</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_ZU53vRW">Negative trials in critical care: why most research is probably wrong</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Laffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Kavanagh</surname></persName>
		</author>
		<idno type="DOI">10.1016/s2213-2600(18)30279-0</idno>
		<idno>Medline: 30061048</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_T57SxYH">Lancet Respir Med</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="659" to="660" />
			<date type="published" when="2018-09">2018 Sep</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Laffey JG, Kavanagh BP. Negative trials in critical care: why most research is probably wrong. Lancet Respir Med 2018 Sep;6(9):659-660. [doi: 10.1016/S2213-2600(18)30279-0] [Medline: 30061048]</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_4wWMADT">Feasibility and acceptability of home use of a smartphone-based urine testing application among women in prenatal care</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Thaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Adiri</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ajog.2019.06.015</idno>
		<idno>Medline: 31300161</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hSMe8VA">Am J Obstet Gynecol</title>
		<imprint>
			<biblScope unit="volume">221</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="527" to="528" />
			<date type="published" when="2019-11">2019 Nov</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Burke AE, Thaler KM, Geva M, Adiri Y. Feasibility and acceptability of home use of a smartphone-based urine testing application among women in prenatal care. Am J Obstet Gynecol 2019 Nov;221(5):527-528. [doi: 10.1016/j.ajog.2019.06.015] [Medline: 31300161]</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_74Zpbsc">TextRay: Mining Clinical Reports to Gain a Broad Understanding of Chest X-Rays</title>
		<author>
			<persName><forename type="first">J</forename><surname>Laserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Lantsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cohen-Sfady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Goz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brestel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-00934-2_62</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_JmpnB8K">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<meeting><address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09-16">2018. September 16-20, 2018</date>
		</imprint>
	</monogr>
	<note>MICCAI&apos;18</note>
	<note type="raw_reference">Laserson J, Lantsman CD, Cohen-Sfady M, Tamir I, Goz E, Brestel C, et al. TextRay: Mining Clinical Reports to Gain a Broad Understanding of Chest X-Rays. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. 2018 Presented at: MICCAI&apos;18; September 16-20, 2018; Granada, Spain. [doi: 10.1007/978-3-030-00934-2_62]</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_GZn6DDr">Doctor AI: predicting clinical events via recurrent neural networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocw112</idno>
		<idno>Medline: 28286600</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MujVXXq">JMLR Workshop Conf Proc</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="301" to="318" />
			<date type="published" when="2016-08">2016 Aug</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Choi E, Bahadori MT, Schuetz A, Stewart WF, Sun J. Doctor AI: predicting clinical events via recurrent neural networks. JMLR Workshop Conf Proc 2016 Aug;56:301-318 [FREE Full text] [Medline: 28286600]</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_FnzPzpC">Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.1002/mp.13271</idno>
		<idno>Medline: 30383300</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xTk7FZ7">Med Phys</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="370" to="381" />
			<date type="published" when="2019-01">2019 Jan</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fan J, Wang J, Chen Z, Hu C, Zhang Z, Hu W. Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique. Med Phys 2019 Jan;46(1):370-381. [doi: 10.1002/mp.13271] [Medline: 30383300]</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_23YnTqM">Automated opportunistic osteoporotic fracture risk assessment using computed tomography scans to aid in FRAX underutilization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elnekave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Barda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bregman-Amitai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Orlovsky</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-019-0720-z</idno>
		<idno>Medline: 31932801</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rHPztxW">Nat Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="82" />
			<date type="published" when="2020-01">2020 Jan</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dagan N, Elnekave E, Barda N, Bregman-Amitai O, Bar A, Orlovsky M, et al. Automated opportunistic osteoporotic fracture risk assessment using computed tomography scans to aid in FRAX underutilization. Nat Med 2020 Jan;26(1):77-82. [doi: 10.1038/s41591-019-0720-z] [Medline: 31932801]</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_kNjPwJs">Improved cancer detection using artificial intelligence: a retrospective evaluation of missed cancers on mammography</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">X</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10278-019-00192-5</idno>
		<idno>Medline: 31011956</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gSBJS5S">J Digit Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="625" to="637" />
			<date type="published" when="2019-08">2019 Aug</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Watanabe AT, Lim V, Vu HX, Chim R, Weise E, Liu J, et al. Improved cancer detection using artificial intelligence: a retrospective evaluation of missed cancers on mammography. J Digit Imaging 2019 Aug;32(4):625-637 [FREE Full text] [doi: 10.1007/s10278-019-00192-5] [Medline: 31011956]</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_PVTD8hb">Reinforcement learning: an introduction</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Montague</surname></persName>
		</author>
		<author>
			<persName><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<idno type="DOI">10.1016/s1364-6613(99)01331-5</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fAS6kqa">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">360</biblScope>
			<date type="published" when="1999-09">1999 Sep</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Montague PR. Reinforcement learning: an introduction, by Sutton, RS and Barto, AG. Trends Cogn Sci 1999 Sep;3(9):360. [doi: 10.1016/S1364-6613(99)01331-5]</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_mS9VK7N">Optimal and autonomous control using reinforcement learning: a survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kiumarsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vamvoudakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Modares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="DOI">10.1109/tnnls.2017.2773458</idno>
		<idno>Medline: 29771662</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mJeNrSG">IEEE Trans Neural Netw Learn Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2042" to="2062" />
			<date type="published" when="2018-06">2018 Jun</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kiumarsi B, Vamvoudakis KG, Modares H, Lewis FL. Optimal and autonomous control using reinforcement learning: a survey. IEEE Trans Neural Netw Learn Syst 2018 Jun;29(6):2042-2062. [doi: 10.1109/TNNLS.2017.2773458] [Medline: 29771662]</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main" xml:id="_uwT4JCn">Dynamic Programming and Markov Process</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960">1960</date>
			<publisher>MIT Press and Wiley</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Howard RA. Dynamic Programming and Markov Process. New York, USA: MIT Press and Wiley; 1960.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main" xml:id="_gqP9AD2">Playing atari with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno>arXiv preprint 2013:-epub ahead of print(1312.5602</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Mnih V, Kavukcuoglu K, Silver D, Graves A, Antonoglou I, Wierstra D, et al. Playing atari with deep reinforcement learning. arXiv preprint 2013:-epub ahead of print(1312.5602) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_aNHz3Mv">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Van Den Driessche</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature16961</idno>
		<idno>Medline: 26819042</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nXpBF6J">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016-01-28">2016 Jan 28</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Silver D, Huang A, Maddison CJ, Guez A, Sifre L, van den Driessche G, et al. Mastering the game of Go with deep neural networks and tree search. Nature 2016 Jan 28;529(7587):484-489. [doi: 10.1038/nature16961] [Medline: 26819042]</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_YfZ4MQv">Autonomous inverted autonomous helicopter flight via reinforcement learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Diel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ganapathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_NtbngE7">Experimental Robotics IX</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="363" to="372" />
		</imprint>
	</monogr>
	<note type="raw_reference">Ng A, Coates A, Diel M, Ganapathi V, Schulte J, Tse B, et al. Autonomous inverted autonomous helicopter flight via reinforcement learning. In: Experimental Robotics IX. New York, USA: Springer; 2006:363-372.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_UUkehxb">The artificial intelligence clinician learns optimal treatment strategies for sepsis in intensive care</title>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Badawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Faisal</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0213-5</idno>
		<idno>Medline: 30349085</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JfdQDqP">Nat Med</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1716" to="1720" />
			<date type="published" when="2018-11">2018 Nov</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Komorowski M, Celi LA, Badawi O, Gordon AC, Faisal AA. The artificial intelligence clinician learns optimal treatment strategies for sepsis in intensive care. Nat Med 2018 Nov;24(11):1716-1720. [doi: 10.1038/s41591-018-0213-5] [Medline: 30349085]</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_hwDej7w">Neural Fitted Q Iteration -First Experiences with a Data Efficient Neural Reinforcement Learning Method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="DOI">10.1007/11564096_32</idno>
		<ptr target="https://doi.org/10.1007/11564096_32[doi:10.1007/11564096_32" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_WD2YYkm">Proceedings of the European Conference on Machine Learning</title>
		<meeting>the European Conference on Machine Learning<address><addrLine>Porto, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10-03">2005. October 3-7, 2005</date>
		</imprint>
	</monogr>
	<note>ECML&apos;05</note>
	<note type="raw_reference">Riedmiller M. Neural Fitted Q Iteration -First Experiences with a Data Efficient Neural Reinforcement Learning Method. In: Proceedings of the European Conference on Machine Learning. 2005 Presented at: ECML&apos;05; October 3-7, 2005; Porto, Portugal URL: https://doi.org/10.1007/11564096_32 [doi: 10.1007/11564096_32]</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_2MQgh8Z">Deep Reinforcement Learning With Double Q-learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<idno type="DOI">10.5555/3016100.3016191</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_kbkrufX">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-02-12">2016. February 12-17, 2016</date>
		</imprint>
	</monogr>
	<note>Presented at: AAAI&apos;16</note>
	<note type="raw_reference">van Hasselt H, Guez A, Silver D. Deep Reinforcement Learning With Double Q-learning. In: Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. 2016 Presented at: AAAI&apos;16; February 12-17, 2016; Phoenix, Arizona, USA. [doi: 10.5555/3016100.3016191]</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main" xml:id="_KZHUWj4">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Puigdomenech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<idno>Arxiv 2016:-epub ahead of print(1602.01783</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Mnih V, Puigdomenech A, Mirza M, Graves A, Lillicrap T, Harley T, et al. Asynchronous methods for deep reinforcement learning. Arxiv 2016:-epub ahead of print(1602.01783) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_SX9CByJ">Multiple model-based reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Doya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Samejima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Katagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawato</surname></persName>
		</author>
		<idno type="DOI">10.1162/089976602753712972</idno>
		<idno>Medline: 12020450</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_egbsN4n">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1347" to="1369" />
			<date type="published" when="2002-06">2002 Jun</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Doya K, Samejima K, Katagiri K, Kawato M. Multiple model-based reinforcement learning. Neural Comput 2002 Jun;14(6):1347-1369. [doi: 10.1162/089976602753712972] [Medline: 12020450]</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_Mqteyw6">Deep reinforcement learning: a brief survey</title>
		<author>
			<persName><forename type="first">K</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Deisenroth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Bharath</surname></persName>
		</author>
		<idno type="DOI">10.1109/MSP.2017.2743240</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Q9axxQD">IEEE Signal Process Mag</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="26" to="38" />
			<date type="published" when="2017-11">2017 Nov</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Arulkumaran K, Deisenroth MP, Brundage M, Bharath AA. Deep reinforcement learning: a brief survey. IEEE Signal Process Mag 2017 Nov;34(6):26-38. [doi: 10.1109/MSP.2017.2743240]</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Wiering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Otterlo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-27645-3</idno>
		<title level="m" xml:id="_thRytFS">Reinforcement Learning: State-of-the-Art</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wiering M, van Otterlo M, editors. Reinforcement Learning: State-of-the-Art. Berlin, Heidelberg: Springer-Verlag; 2012.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main" xml:id="_Tyew9yQ">Reinforcement-Learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Siqi</surname></persName>
		</author>
		<ptr target="https://github.com/nus-mornin-lab/Reinforcement-Learning" />
		<imprint>
			<date type="published" when="2020-01-01">2020-01-01</date>
		</imprint>
	</monogr>
	<note type="report_type">GitHub</note>
	<note type="raw_reference">Siqi L. Reinforcement-Learning. GitHub. URL: https://github.com/nus-mornin-lab/Reinforcement-Learning [accessed 2020-01-01]</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_GuVH5VR">An Adaptive Neural Network Filter for Improved Patient State Estimation in Closed-Loop Anesthesia Control</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Borera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Doufas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Pyeatt</surname></persName>
		</author>
		<idno type="DOI">10.1109/ictai.2011.15</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_SffUQEe">23rd International Conference on Tools with Artificial Intelligence</title>
		<meeting><address><addrLine>Boca Raton, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">2011. November 7-9, 2011</date>
		</imprint>
	</monogr>
	<note>ICTAI&apos;11</note>
	<note type="raw_reference">Borera EC, Moore BL, Doufas AG, Pyeatt LD. An Adaptive Neural Network Filter for Improved Patient State Estimation in Closed-Loop Anesthesia Control. In: 23rd International Conference on Tools with Artificial Intelligence. 2011 Presented at: ICTAI&apos;11; November 7-9, 2011; Boca Raton, FL, USA. [doi: 10.1109/ictai.2011.15]</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_4kwFDsJ">Closed-loop Control of Anesthesia and Mean Arterial Pressure Using Reinforcement Learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Meskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Haddad</surname></persName>
		</author>
		<idno type="DOI">10.1109/adprl.2014.7010644</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_n4tydRN">Symposium on Adaptive Dynamic Programming and Reinforcement Learning</title>
		<meeting><address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-09">2014. December 9-12, 2014</date>
		</imprint>
	</monogr>
	<note>ADPRL&apos;14</note>
	<note type="raw_reference">Padmanabhan R, Meskin N, Haddad WM. Closed-loop Control of Anesthesia and Mean Arterial Pressure Using Reinforcement Learning. In: Symposium on Adaptive Dynamic Programming and Reinforcement Learning. 2014 Presented at: ADPRL&apos;14; December 9-12, 2014; Orlando, FL, USA. [doi: 10.1109/ADPRL.2014.7010644]</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_adZNEQy">Reinforcement Learning-Based Control for Combined Infusion of Sedatives and Analgesics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Meskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Haddad</surname></persName>
		</author>
		<idno type="DOI">10.1109/codit.2017.8102643</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_SDkFpFw">4th International Conference on Control, Decision and Information Technologies</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-05">2017. April 5-7, 2017</date>
		</imprint>
	</monogr>
	<note>Presented at: CoDIT&apos;17</note>
	<note type="raw_reference">Padmanabhan R, Meskin N, Haddad WM. Reinforcement Learning-Based Control for Combined Infusion of Sedatives and Analgesics. In: 4th International Conference on Control, Decision and Information Technologies. 2017 Presented at: CoDIT&apos;17; April 5-7, 2017; Barcelona, Spain. [doi: 10.1109/codit.2017.8102643]</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_ZKdVmAx">Optimal adaptive control of drug dosing using integral reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Meskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Haddad</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.mbs.2019.01.012</idno>
		<idno>Medline: 30735696</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XbaEmYa">Math Biosci</title>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="page" from="131" to="142" />
			<date type="published" when="2019-03">2019 Mar</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Padmanabhan R, Meskin N, Haddad WM. Optimal adaptive control of drug dosing using integral reinforcement learning. Math Biosci 2019 Mar;309:131-142. [doi: 10.1016/j.mbs.2019.01.012] [Medline: 30735696]</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_CqsG69c">Personalized Medication Dosing Using Volatile Data Streams</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Alhanai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Westover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nemati</surname></persName>
		</author>
		<ptr target="https://aaai.org/ocs/index.php/WS/AAAIW18/paper/view/17234" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_53xG5QD">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-02-02">2018. February 2-7, 2018</date>
		</imprint>
	</monogr>
	<note>Presented at: AAAI&apos;18</note>
	<note type="raw_reference">Ghassemi MM, Alhanai T, Westover MB, Mark TG, Nemati S. Personalized Medication Dosing Using Volatile Data Streams. In: Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence. 2018 Presented at: AAAI&apos;18; February 2-7, 2018; New Orleans, Louisiana, USA URL: https://aaai.org/ocs/index.php/WS/AAAIW18/paper/view/17234</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_SGjXWGB">A deep deterministic policy gradient approach to medication dosing and surveillance in the ICU</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nemati</surname></persName>
		</author>
		<idno type="DOI">10.1109/embc.2018.8513203</idno>
		<idno>Medline: 30441448</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_e4DPRBp">Conf Proc IEEE Eng Med Biol Soc</title>
		<imprint>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page" from="4927" to="4931" />
			<date type="published" when="2018-07">2018 Jul</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Lin R, Stanley MD, Ghassemi MM, Nemati S. A deep deterministic policy gradient approach to medication dosing and surveillance in the ICU. Conf Proc IEEE Eng Med Biol Soc 2018 Jul;2018:4927-4931 [FREE Full text] [doi: 10.1109/EMBC.2018.8513203] [Medline: 30441448]</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main" xml:id="_8n5d9a4">Deep reinforcement learning for sepsis treatment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<idno type="DOI">10.5173/ceju.2017.1595</idno>
		<idno>arXiv 2017:-epub ahead of print(1711.09602</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Raghu A, Komorowski M, Ahmed I, Celi L, Szolovits P, Ghassemi M. Deep reinforcement learning for sepsis treatment. arXiv 2017:-epub ahead of print(1711.09602) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main" xml:id="_3tnRE8e">Continuous state-space models for optimal sepsis treatment-a deep reinforcement learning approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<idno type="DOI">10.2514/6.2020-2909.vid</idno>
		<idno>arXiv 2017:-epub ahead of print(1705.08422</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Raghu A, Komorowski M, Celi L, Szolovits P, Ghassemi M. Continuous state-space models for optimal sepsis treatment-a deep reinforcement learning approach. arXiv 2017:-epub ahead of print(1705.08422) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main" xml:id="_NUNrtUG">Model-based reinforcement learning for sepsis treatment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<idno>arXiv 2018:-epub ahead of print-1811.09602</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Raghu A, Komorowski M, Singh S. Model-based reinforcement learning for sepsis treatment. arXiv 2018:-epub ahead of print-1811.09602 [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main" xml:id="_AnBaA4D">Learning to Treat Sepsis with Multi-Output Gaussian Process Deep Recurrent Q-Networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Futoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sendak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bedoya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SyxCqGbRZ" />
		<imprint>
			<date type="published" when="2018">2018. 2020-06-10</date>
			<publisher>OpenReview</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Futoma J, Lin A, Sendak M, Bedoya A, Clement M, O&apos;Brien C, et al. Learning to Treat Sepsis with Multi-Output Gaussian Process Deep Recurrent Q-Networks. OpenReview. 2018. URL: https://openreview.net/forum?id=SyxCqGbRZ [accessed 2020-06-10]</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_kWGQxHs">Improving sepsis treatment strategies by combining deep and kernel-based reinforcement learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wihl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gottesman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Komorowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<idno>Medline: 30815131</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9cSPmZY">AMIA Annu Symp Proc</title>
		<imprint>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page" from="887" to="896" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Peng X, Ding Y, Wihl D, Gottesman O, Komorowski M, Lehman LH, et al. Improving sepsis treatment strategies by combining deep and kernel-based reinforcement learning. AMIA Annu Symp Proc 2018;2018:887-896 [FREE Full text] [Medline: 30815131]</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_unbedTq">Truly Batch Apprenticeship Learning with Deep Successor Features</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/819</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_fCV7GrH">International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting><address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10">2019. August 10-16, 2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lee D, Srinivasan S, Doshi-Velez F. Truly Batch Apprenticeship Learning with Deep Successor Features. 2019 Presented at: International Joint Conferences on Artificial Intelligence Organization; August 10-16, 2019; Macao, China. [doi: 10.24963/ijcai.2019/819]</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_Y9b92z9">Deep reinforcement learning for optimal critical care pain management with morphine using dueling double-deep Q networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lopez-Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Eschenfeldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ostvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
		<idno type="DOI">10.1109/EMBC.2019.8857295</idno>
		<idno>Medline: 31946739</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tK7CxZk">Conf Proc IEEE Eng Med Biol Soc</title>
		<imprint>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="3960" to="3963" />
			<date type="published" when="2019-07">2019 Jul</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lopez-Martinez D, Eschenfeldt P, Ostvar S, Ingram M, Hur C, Picard R. Deep reinforcement learning for optimal critical care pain management with morphine using dueling double-deep Q networks. Conf Proc IEEE Eng Med Biol Soc 2019 Jul;2019:3960-3963. [doi: 10.1109/EMBC.2019.8857295] [Medline: 31946739]</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main" xml:id="_bw7zH8P">Precision medicine as a control problem: Using simulation and deep reinforcement learning to discover adaptive, personalized multi-cytokine therapy for sepsis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cockrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Santiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>An</surname></persName>
		</author>
		<idno type="DOI">10.1089/cmb.2018.0168</idno>
		<idno type="arXiv">arXiv:1802.104402018</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>FREE Full text</note>
	<note type="raw_reference">Petersen B, Yang J, Grathwohl WS, Cockrell C, Santiago C, An G, et al. Precision medicine as a control problem: Using simulation and deep reinforcement learning to discover adaptive, personalized multi-cytokine therapy for sepsis. arXiv preprint. arXiv:1802.10440 2018 [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main" xml:id="_HgEW6Hy">A reinforcement learning approach to weaning of mechanical ventilation in intensive care units</title>
		<author>
			<persName><forename type="first">N</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Draugelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Engelhardt</surname></persName>
		</author>
		<idno type="DOI">10.3390/jpm12050661</idno>
		<idno>Arxiv 2017:-epub ahead of print(1704.06300</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Prasad N, Cheng LF, Chivers C, Draugelis M, Engelhardt B. A reinforcement learning approach to weaning of mechanical ventilation in intensive care units. Arxiv 2017:-epub ahead of print(1704.06300) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_X2ShtAv">An optimal policy for patient laboratory tests in intensive care units</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Engelhardt</surname></persName>
		</author>
		<idno>Medline: 30864333</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4YnvCMR">Pac Symp Biocomput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="320" to="331" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Cheng L, Prasad N, Engelhardt BE. An optimal policy for patient laboratory tests in intensive care units. Pac Symp Biocomput 2019;24:320-331 [FREE Full text] [Medline: 30864333]</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_6ajbq9g">Inverse reinforcement learning for intelligent mechanical ventilation and sedative dosing in intensive care units</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12911-019-0763-6</idno>
		<idno>Medline: 30961594</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zUFbBFT">BMC Med Inform Decis Mak</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">Suppl 2</biblScope>
			<biblScope unit="page">57</biblScope>
			<date type="published" when="2019-04-09">2019 Apr 9</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Yu C, Liu J, Zhao H. Inverse reinforcement learning for intelligent mechanical ventilation and sedative dosing in intensive care units. BMC Med Inform Decis Mak 2019 Apr 9;19(Suppl 2):57 [FREE Full text] [doi: 10.1186/s12911-019-0763-6] [Medline: 30961594]</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main" xml:id="_uBqEyms">Representation and reinforcement learning for personalized glycemic control in septic patients</title>
		<author>
			<persName><forename type="first">W</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<idno>arXiv 2017:-epub ahead of print(1712.00654</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Weng W, Gao M, He Z, Yan S, Szolovits P. Representation and reinforcement learning for personalized glycemic control in septic patients. arXiv 2017:-epub ahead of print(1712.00654) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_7M5GC6n">Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<idno type="DOI">10.1145/3219819.3219961</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_SnRGZqb">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-08-19">2018. August 19-23, 2018</date>
		</imprint>
	</monogr>
	<note>KDD&apos;18</note>
	<note type="raw_reference">Wang L, Zhang W, He X, Zha H. Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2018 Presented at: KDD&apos;18; August 19-23, 2018; London, UK. [doi: 10.1145/3219819.3219961]</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_PDeeWwD">In the era of precision medicine and big data, who is normal?</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Manrai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Ioannidis</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2018.2009</idno>
		<idno>Medline: 29710130</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rB425ER">J Am Med Assoc</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="1981" to="1982" />
			<date type="published" when="2018-05-15">2018 May 15</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Manrai AK, Patel CJ, Ioannidis JP. In the era of precision medicine and big data, who is normal? J Am Med Assoc 2018 May 15;319(19):1981-1982. [doi: 10.1001/jama.2018.2009] [Medline: 29710130]</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_EHRRmHk">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2016.35</idno>
		<idno>Medline: 27219127</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3DGeYak">Sci Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">160035</biblScope>
			<date type="published" when="2016-05-24">2016 May 24</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Johnson AE, Pollard TJ, Shen L, Lehman LH, Feng M, Ghassemi M, et al. MIMIC-III, a freely accessible critical care database. Sci Data 2016 May 24;3:160035 [FREE Full text] [doi: 10.1038/sdata.2016.35] [Medline: 27219127]</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><surname>Cs</surname></persName>
		</author>
		<ptr target="https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf" />
		<title level="m" xml:id="_5CUVJH5">A Lecture Notes: Sparse Autoencoder</title>
		<imprint>
			<date type="published" when="2011">294. 2011. 2020-06-09</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Ng A. CS294A Lecture Notes: Sparse Autoencoder. Stanford University. 2011. URL: https://web.stanford.edu/class/cs294a/ sparseAutoencoder.pdf [accessed 2020-06-09]</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_nzGTYHX">Clinical practice guideline: safe medication use in the ICU</title>
		<author>
			<persName><forename type="first">Kane-Gill</forename><surname>Sl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Dasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Devabhakthuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1097/CCM.0000000000002533</idno>
		<idno>Medline: 28816851</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DVS4reP">Crit Care Med</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="877" to="e915" />
			<date type="published" when="2017-09">2017 Sep</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kane-Gill SL, Dasta JF, Buckley MS, Devabhakthuni S, Liu M, Cohen H, et al. Clinical practice guideline: safe medication use in the ICU. Crit Care Med 2017 Sep;45(9):e877-e915. [doi: 10.1097/CCM.0000000000002533] [Medline: 28816851]</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_yUrJYF5">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<idno>Medline: 9377276</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_x2t8Q8T">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997-11-15">1997 Nov 15</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hochreiter S, Schmidhuber J. Long short-term memory. Neural Comput 1997 Nov 15;9(8):1735-1780. [doi: 10.1162/neco.1997.9.8.1735] [Medline: 9377276]</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_AFt4eEP">Bedside monitoring of diaphragm electrical activity during mechanical ventilation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sinderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brander</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-92276-6_37</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_XfArAsQ">Yearbook of Intensive Care and Emergency Medicine</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Vincent</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
	<note type="raw_reference">Sinderby C, Breck J, Brander L. Bedside monitoring of diaphragm electrical activity during mechanical ventilation. In: Vincent JL, editor. Yearbook of Intensive Care and Emergency Medicine. New York, NY: Springer; 2009:385-393.</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_pRzCNUb">Sedation and analgesia in the mechanically ventilated patient</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kress</surname></persName>
		</author>
		<idno type="DOI">10.1164/rccm.201102-0273ci</idno>
		<idno>Medline: 22016443</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AZqVyUR">Am J Respir Crit Care Med</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="486" to="497" />
			<date type="published" when="2012-03-01">2012 Mar 1</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Patel SB, Kress JP. Sedation and analgesia in the mechanically ventilated patient. Am J Respir Crit Care Med 2012 Mar 1;185(5):486-497. [doi: 10.1164/rccm.201102-0273CI] [Medline: 22016443]</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_bHeZHWH">Automatic tube compensation-assisted respiratory rate to tidal volume ratio improves the prediction of weaning outcome</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grozovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singer</surname></persName>
		</author>
		<idno type="DOI">10.1378/chest.122.3.980</idno>
		<idno>Medline: 12226043</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_k9JnVrv">Chest</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="980" to="984" />
			<date type="published" when="2002-09">2002 Sep</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cohen J, Shapiro M, Grozovski E, Singer P. Automatic tube compensation-assisted respiratory rate to tidal volume ratio improves the prediction of weaning outcome. Chest 2002 Sep;122(3):980-984. [doi: 10.1378/chest.122.3.980] [Medline: 12226043]</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_xfGMshZ">Clinicians role in reducing lab order frequency in ICU settings</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Loftsgard</surname></persName>
		</author>
		<idno type="DOI">10.4172/jpcic.1000112</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BBtbDEz">J Perioper Crit Intens Care Nurs</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="320" to="331" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Kashyap R, Loftsgard TO. Clinicians role in reducing lab order frequency in ICU settings. J Perioper Crit Intens Care Nurs 2015;2(1):320-331 [FREE Full text] [doi: 10.4172/jpcic.1000112]</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_QKvnu5J">Towards Real-Time Information Processing of Sensor Network Data Using Computationally Efficient Multi-output Gaussian Processes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Ramchurn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
		<idno type="DOI">10.1109/ipsn.2008.25</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_KWPMRhw">International Conference on Information Processing in Sensor Networks</title>
		<meeting><address><addrLine>St Louis, MO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-04-22">2008. April 22-24, 2008</date>
		</imprint>
	</monogr>
	<note>Presented at: IPSN&apos;08</note>
	<note type="raw_reference">Osborne MA, Roberts SJ, Rogers A, Ramchurn SD, Jennings NR. Towards Real-Time Information Processing of Sensor Network Data Using Computationally Efficient Multi-output Gaussian Processes. In: International Conference on Information Processing in Sensor Networks. 2008 Presented at: IPSN&apos;08; April 22-24, 2008; St Louis, MO, USA. [doi: 10.1109/ipsn.2008.25]</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main" xml:id="_WNvBMag">Information gain and a general measure of correlation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kent</surname></persName>
		</author>
		<idno type="DOI">10.2307/2335954</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6TgAPNJ">Biometrika</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="173" />
			<date type="published" when="1983-04">1983 Apr</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kent JT. Information gain and a general measure of correlation. Biometrika 1983 Apr;70(1):163-173. [doi: 10.2307/2335954]</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_Cmb9ubj">Optimizing drug dosing in the ICU</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_zNYHbbV">Yearbook of Intensive Care and Emergency Medicine</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liu X, Kruger P, Roberts MS. Optimizing drug dosing in the ICU. In: Yearbook of Intensive Care and Emergency Medicine. New York, USA: Springer; 2009.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main" xml:id="_m7g42WH">Monitoring and managing raised intracranial pressure after traumatic brain injury</title>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-0-387-92278-2_73</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dv6Adqn">Intensive Care Medicine</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Vincent</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="801" to="808" />
		</imprint>
	</monogr>
	<note type="raw_reference">Smith M. Monitoring and managing raised intracranial pressure after traumatic brain injury. In: Vincent JL, editor. Intensive Care Medicine. New York, NY: Springer; 2009:801-808.</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_Crnxcbm">BIS -AAI and clinical measures during propofol target controlled infusion with Schnider&apos;s pharmacokinetic model</title>
		<author>
			<persName><forename type="first">E</forename><surname>Iannuzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iannuzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sidro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cardinale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiefari</surname></persName>
		</author>
		<idno type="DOI">10.1093/bja/ael296</idno>
		<idno>Medline: 17115013</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pUCfKuv">Minerva Anestesiol</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Iannuzzi E, Iannuzzi M, Viola G, Sidro L, Cardinale A, Chiefari M. BIS -AAI and clinical measures during propofol target controlled infusion with Schnider&apos;s pharmacokinetic model. Minerva Anestesiol 2007;73(1-2):23-31 [FREE Full text] [Medline: 17115013]</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_RxnrU2v">Emergency reversal of antithrombotic treatment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Levi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11739-008-0201-8</idno>
		<idno>Medline: 19002653</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Z3sUFu7">Intern Emerg Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="145" />
			<date type="published" when="2009-04">2009 Apr</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Levi M. Emergency reversal of antithrombotic treatment. Intern Emerg Med 2009 Apr;4(2):137-145. [doi: 10.1007/s11739-008-0201-8] [Medline: 19002653]</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main" xml:id="_dTtBka3">Multiparameter intelligent monitoring in intensive care II: a public-access intensive care unit database</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Villarroel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Reisner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Moody</surname></persName>
		</author>
		<idno type="DOI">10.1097/ccm.0b013e31820a92c6</idno>
		<idno>Medline: 21283005</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JRqpzHZ">Crit Care Med</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="952" to="960" />
			<date type="published" when="2011-05">2011 May</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Saeed M, Villarroel M, Reisner AT, Clifford G, Lehman L, Moody G, et al. Multiparameter intelligent monitoring in intensive care II: a public-access intensive care unit database. Crit Care Med 2011 May;39(5):952-960 [FREE Full text] [doi: 10.1097/CCM.0b013e31820a92c6] [Medline: 21283005]</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main" xml:id="_fqwHbu9">Sepsis: a roadmap for future research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Adhikari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Angus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Calandra</surname></persName>
		</author>
		<idno type="DOI">10.1016/s1473-3099(15)70112-x</idno>
		<idno>Medline: 25932591</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dE63Wmu">Lancet Infect Dis</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="581" to="614" />
			<date type="published" when="2015-05">2015 May</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cohen J, Vincent J, Adhikari NK, Machado FR, Angus DC, Calandra T, et al. Sepsis: a roadmap for future research. Lancet Infect Dis 2015 May;15(5):581-614. [doi: 10.1016/S1473-3099(15)70112-X] [Medline: 25932591]</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_EY3esXK">The third international consensus definitions for sepsis and septic shock (sepsis-3)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Deutschman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shankar-Hari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Annane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2016.0287</idno>
		<idno>Medline: 26903338</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BbbAKqt">J Am Med Assoc</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="801" to="810" />
			<date type="published" when="2016-02-23">2016 Feb 23</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Singer M, Deutschman CS, Seymour CW, Shankar-Hari M, Annane D, Bauer M, et al. The third international consensus definitions for sepsis and septic shock (sepsis-3). J Am Med Assoc 2016 Feb 23;315(8):801-810 [FREE Full text] [doi: 10.1001/jama.2016.0287] [Medline: 26903338]</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main" xml:id="_AcCwcCz">Does the artificial intelligence clinician learn optimal treatment strategies for sepsis in intensive care?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Josef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shashikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nemati</surname></persName>
		</author>
		<idno type="DOI">10.1101/2021.03.03.21252863</idno>
		<idno>arXiv 2019:-epub ahead of print(1902.03271</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Jeter R, Josef C, Shashikumar S, Nemati S. Does the artificial intelligence clinician learn optimal treatment strategies for sepsis in intensive care? arXiv 2019:-epub ahead of print(1902.03271) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main" xml:id="_G9rZu26">Continuous control with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
		<idno>arXiv 2015:-epub ahead of print(1509.02971</idno>
		<imprint/>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Lillicrap T, Hunt J, Pritzel A, Heess N, Erez T, Tassa Y, et al. Continuous control with deep reinforcement learning. arXiv 2015:-epub ahead of print(1509.02971) [FREE Full text]</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main" xml:id="_cXECmRK">In silico experiments of existing and hypothetical cytokine-directed clinical trials using agent-based modeling</title>
		<author>
			<persName><forename type="first">An</forename><forename type="middle">G</forename></persName>
		</author>
		<idno type="DOI">10.1097/01.ccm.0000139707.13729.7d</idno>
		<idno>Medline: 15483414</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qvbnnM7">Crit Care Med</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2050" to="2060" />
			<date type="published" when="2004-10">2004 Oct</date>
		</imprint>
	</monogr>
	<note type="raw_reference">An G. In silico experiments of existing and hypothetical cytokine-directed clinical trials using agent-based modeling. Crit Care Med 2004 Oct;32(10):2050-2060. [doi: 10.1097/01.ccm.0000139707.13729.7d] [Medline: 15483414]</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_Mgj33Ua">Clinical practice guidelines for the management of pain, agitation, and delirium in adult patients in the intensive care unit</title>
		<author>
			<persName><forename type="first">J</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Puntillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Ely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gélinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Dasta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">American</forename><surname>College</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Care</forename><surname>Critical</surname></persName>
		</author>
		<author>
			<persName><surname>Medicine</surname></persName>
		</author>
		<idno type="DOI">10.1097/ccm.0b013e3182783b72</idno>
		<idno>Medline: 23269131</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WQUBP4C">Crit Care Med</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="263" to="306" />
			<date type="published" when="2013-01">2013 Jan</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barr J, Fraser GL, Puntillo K, Ely EW, Gélinas C, Dasta JF, American College of Critical Care Medicine. Clinical practice guidelines for the management of pain, agitation, and delirium in adult patients in the intensive care unit. Crit Care Med 2013 Jan;41(1):263-306. [doi: 10.1097/CCM.0b013e3182783b72] [Medline: 23269131]</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main" xml:id="_4wCgtKm">Continuous infusion versus intermittent bolus dosing of morphine: a comparison of analgesia, tolerance, and subsequent voluntary morphine intake</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gong</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jpsychires.2014.08.009</idno>
		<idno>Medline: 25193460</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_K2abX9d">J Psychiatr Res</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="161" to="166" />
			<date type="published" when="2014-12">2014 Dec</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yu G, Zhang F, Tang S, Lai M, Su R, Gong Z. Continuous infusion versus intermittent bolus dosing of morphine: a comparison of analgesia, tolerance, and subsequent voluntary morphine intake. J Psychiatr Res 2014 Dec;59:161-166. [doi: 10.1016/j.jpsychires.2014.08.009] [Medline: 25193460]</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main" xml:id="_PqpGE3d">Morphine: controlled trial of different methods of administration for postoperative pain relief</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Rutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Dudley</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.280.6206.12</idno>
		<idno>Medline: 6986940</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PFv2cYs">Br Med J</title>
		<imprint>
			<biblScope unit="volume">280</biblScope>
			<biblScope unit="issue">6206</biblScope>
			<biblScope unit="page" from="12" to="13" />
			<date type="published" when="1980-01-05">1980 Jan 5</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Rutter PC, Murphy F, Dudley HA. Morphine: controlled trial of different methods of administration for postoperative pain relief. Br Med J 1980 Jan 5;280(6206):12-13 [FREE Full text] [doi: 10.1136/bmj.280.6206.12] [Medline: 6986940]</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main" xml:id="_nnkPUEy">Automatic classification of sedation levels in ICU patients using heart rate variability</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Nagaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Mcclain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Biswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Purdon</surname></persName>
		</author>
		<idno type="DOI">10.1097/ccm.0000000000001708</idno>
		<idno>Medline: 27035240</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6595yTg">Critical Care Medicine</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="782" to="e789" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nagaraj SB, McClain LM, Zhou DW, Biswal S, Rosenthal ES, Purdon PL, et al. Automatic classification of sedation levels in ICU patients using heart rate variability. Critical Care Medicine 2016;44(9):e782-e789. [doi: 10.1097/ccm.0000000000001708] [Medline: 27035240]</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main" xml:id="_QPSWMpY">Instruments for monitoring intensive care unit sedation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Carrasco</surname></persName>
		</author>
		<idno type="DOI">10.1186/cc697</idno>
		<idno>Medline: 11094504</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9Xc929A">Crit Care</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="217" to="225" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Carrasco G. Instruments for monitoring intensive care unit sedation. Crit Care 2000;4(4):217-225 [FREE Full text] [doi: 10.1186/cc697] [Medline: 11094504]</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main" xml:id="_W8ujZPd">Bispectral index for improving intraoperative awareness and early postoperative recovery in adults</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Pritchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fawcett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Punjasawadwong</surname></persName>
		</author>
		<idno type="DOI">10.1002/14651858.CD003843.pub4</idno>
		<idno>Medline: 31557307</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4dQW4WC">Cochrane Database Syst Rev</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3843</biblScope>
			<date type="published" when="2019-09-26">2019 Sep 26</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
	<note type="raw_reference">Lewis SR, Pritchard MW, Fawcett LJ, Punjasawadwong Y. Bispectral index for improving intraoperative awareness and early postoperative recovery in adults. Cochrane Database Syst Rev 2019 Sep 26;9(6):CD003843 [FREE Full text] [doi: 10.1002/14651858.CD003843.pub4] [Medline: 31557307]</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main" xml:id="_sPd2bq6">Partially observable Markov decision processes for spoken dialog systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csl.2006.06.008</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_qq4PZ7W">Comput Speech Lang</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="422" />
			<date type="published" when="2007-04">2007 Apr</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Williams JD, Young S. Partially observable Markov decision processes for spoken dialog systems. Comput Speech Lang 2007 Apr;21(2):393-422. [doi: 10.1016/j.csl.2006.06.008]</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main" xml:id="_E3MrDsE">Toward Off-Policy Learning Control with Function Approximation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Maei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesv´ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatnagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sutton</surname></persName>
		</author>
		<ptr target="https://icml.cc/Conferences/2010/papers/627.pdf" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_wPUpw5b">The 27th International Conference on Machine Learning</title>
		<meeting><address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06-21">2010. June 21-24, 2010</date>
		</imprint>
	</monogr>
	<note>ICML&apos;10</note>
	<note type="raw_reference">Maei H, Szepesv´ari C, Bhatnagar S, Sutton R. Toward Off-Policy Learning Control with Function Approximation. In: The 27th International Conference on Machine Learning. 2010 Presented at: ICML&apos;10; June 21-24, 2010; Haifa, Israel URL: https://icml.cc/Conferences/2010/papers/627.pdf</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main" xml:id="_YSJmBmf">The eICU research institute -a collaboration between industry, health-care providers, and academia</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mcshea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Holl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Badawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Riker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Silfen</surname></persName>
		</author>
		<idno type="DOI">10.1109/memb.2009.935720</idno>
		<idno>Medline: 20659837</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_T7WTYx7">IEEE Eng Med Biol Mag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="18" to="25" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McShea M, Holl R, Badawi O, Riker RR, Silfen E. The eICU research institute -a collaboration between industry, health-care providers, and academia. IEEE Eng Med Biol Mag 2010;29(2):18-25. [doi: 10.1109/MEMB.2009.935720] [Medline: 20659837]</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main" xml:id="_AezjyaH">Sun X, Feng M Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iw ;</forename><surname>Khor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<idno type="DOI">10.2196/18477</idno>
		<ptr target="https://www.jmir.org/2020/7/e18477doi:10.2196/18477PMID:32706670" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_uYyHrWk">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">18477</biblScope>
			<date type="published" when="2019-05">2019 May. 2020</date>
		</imprint>
	</monogr>
	<note>WBC: white blood cell Edited by G Eysenbach; submitted 28.02 comments to author 08.04.20 revised version received 05.05.20; accepted 13.05.20 Big data and machine learning algorithms for health-care delivery Lancet Oncol</note>
	<note type="raw_reference">Ngiam KY, Khor IW. Big data and machine learning algorithms for health-care delivery. Lancet Oncol 2019 May;20(5):e262-e273. [doi: 10.1016/S1470-2045(19)30149-4] WBC: white blood cell Edited by G Eysenbach; submitted 28.02.20; peer-reviewed by A Hallawa, Z Zhang, D Maslove; comments to author 08.04.20; revised version received 05.05.20; accepted 13.05.20; published 20.07.20 Please cite as: Liu S, See KC, Ngiam KY, Celi LA, Sun X, Feng M Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review J Med Internet Res 2020;22(7):e18477 URL: https://www.jmir.org/2020/7/e18477 doi: 10.2196/18477 PMID: 32706670</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Kay</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kee</forename><forename type="middle">Yuan</forename><surname>Choong See</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingzhi</forename><surname>Anthony Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengling</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Feng</surname></persName>
		</author>
		<ptr target="http://www.jmir.org),20.07" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_xtng54D">Originally published in the Journal of Medical Internet Research</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">©Siqi Liu, Kay Choong See, Kee Yuan Ngiam, Leo Anthony Celi, Xingzhi Sun, Mengling Feng. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 20.07</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
