<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_Ce4fqGe">CORE-MD clinical risk score for regulatory evaluation of artificial intelligence-based medical device software Check for updates</title>
				<funder ref="#_eaVMVTR">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Frank</forename><forename type="middle">E</forename><surname>Rademakers</surname></persName>
							<email>frank.rademakers@kuleuven.be</email>
							<idno type="ORCID">0000-0002-7786-4179</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Emeritus Professor of Cardiology , KU Leuven , Leuven , Belgium.</note>
								<orgName type="department">Emeritus Professor of Cardiology</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elisabetta</forename><surname>Biasin</surname></persName>
							<idno type="ORCID">0000-0001-9090-3315</idno>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Researcher in Law , Center for IT &amp; IP Law (CiTiP) , KU Leuven , Leuven , Belgium.</note>
								<orgName type="department" key="dep1">Researcher in Law</orgName>
								<orgName type="department" key="dep2">Center for IT &amp; IP Law (CiTiP)</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nico</forename><surname>Bruining</surname></persName>
							<idno type="ORCID">0000-0002-0272-5617</idno>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Department of Cardiology , Erasmus Medical Center , Thorax Center , Rotterdam , the Netherlands.</note>
								<orgName type="department">Department of Cardiology</orgName>
								<orgName type="institution" key="instit1">Erasmus Medical Center</orgName>
								<orgName type="institution" key="instit2">Thorax Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">the Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enrico</forename><forename type="middle">G</forename><surname>Caiani</surname></persName>
							<idno type="ORCID">0000-0002-1770-6486</idno>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Department of Electronics , Information and Biomedical Engineering , Poli- tecnico di Milano , Milan , Italy.</note>
								<orgName type="department" key="dep1">Department of Electronics</orgName>
								<orgName type="department" key="dep2">Information and Biomedical Engineering</orgName>
								<orgName type="institution">Poli- tecnico di Milano</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> IRCCS Istituto Auxologico Italiano , Milan , Italy.</note>
								<orgName type="institution">IRCCS Istituto Auxologico Italiano</orgName>
								<address>
									<settlement>Milan</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rhodri</forename><forename type="middle">H</forename><surname>Davies</surname></persName>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Institute of Cardiovascular Science , University College London , London , UK.</note>
								<orgName type="department">Institute of Cardiovascular Science</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><forename type="middle">H</forename><surname>Gilbert</surname></persName>
							<affiliation key="aff6">
								<note type="raw_affiliation"><label>7</label> Professor for Medical Device Regulatory Science , Else Kröner Fresenius Center , for Digital Health , TUD Dresden University of Technology , Dresden , Germany.</note>
								<orgName type="department" key="dep1">Professor for Medical Device Regulatory Science</orgName>
								<orgName type="department" key="dep2">Else Kröner Fresenius Center</orgName>
								<orgName type="department" key="dep3">for Digital Health</orgName>
								<orgName type="institution">TUD Dresden University of Technology</orgName>
								<address>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Kamenjasevic</surname></persName>
							<affiliation key="aff7">
								<note type="raw_affiliation"><label>8</label> Doctoral researcher in Law and Ethics , Center for IT &amp; IP Law (CiTiP) , KU Leuven , Leuven , Belgium.</note>
								<orgName type="department" key="dep1">Doctoral researcher in Law and Ethics</orgName>
								<orgName type="department" key="dep2">Center for IT &amp; IP Law (CiTiP)</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gearóid</forename><surname>Mcgauran</surname></persName>
							<idno type="ORCID">0009-0005-3615-1876</idno>
							<affiliation key="aff8">
								<note type="raw_affiliation"><label>9</label> Medical Officer , Medical Devices , Health Products Regulatory Authority , Dublin , Ireland.</note>
								<orgName type="department" key="dep1">Medical Officer</orgName>
								<orgName type="department" key="dep2">Medical Devices</orgName>
								<orgName type="institution">Health Products Regulatory Authority</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gearóid</forename><surname>O'connor</surname></persName>
							<idno type="ORCID">0009-0001-4839-8412</idno>
							<affiliation key="aff8">
								<note type="raw_affiliation"><label>9</label> Medical Officer , Medical Devices , Health Products Regulatory Authority , Dublin , Ireland.</note>
								<orgName type="department" key="dep1">Medical Officer</orgName>
								<orgName type="department" key="dep2">Medical Devices</orgName>
								<orgName type="institution">Health Products Regulatory Authority</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jean-Baptiste</forename><surname>Rouffet</surname></persName>
							<affiliation key="aff9">
								<note type="raw_affiliation"><label>10</label> Policy Advisor , European Affairs , European</note>
								<orgName type="department">Policy Advisor</orgName>
								<orgName type="institution">European Affairs</orgName>
								<address>
									<country>European</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Baptiste</forename><surname>Vasey</surname></persName>
							<affiliation key="aff11">
								<note type="raw_affiliation"><label>11</label> Nuffield Department of Surgical Sciences , University of Oxford , Oxford , UK.</note>
								<orgName type="department">Nuffield Department of Surgical Sciences</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff12">
								<note type="raw_affiliation"><label>12</label> Department of Surgery , Geneva University Hospital , Geneva , Switzerland.</note>
								<orgName type="department">Department of Surgery</orgName>
								<orgName type="institution">Geneva University Hospital</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alan</forename><forename type="middle">G</forename><surname>Fraser</surname></persName>
							<affiliation key="aff13">
								<note type="raw_affiliation"><label>13</label> Consultant Cardiologist , University Hospital of Wales , and Emeritus Professor of Cardiology , School of Medicine , Cardiff University , Heath Park , Cardiff , UK.</note>
								<orgName type="department" key="dep1">Consultant Cardiologist</orgName>
								<orgName type="department" key="dep2">Emeritus Professor of Cardiology</orgName>
								<orgName type="department" key="dep3">School of Medicine</orgName>
								<orgName type="institution" key="instit1">University Hospital of Wales</orgName>
								<orgName type="institution" key="instit2">Cardiff University</orgName>
								<address>
									<addrLine>Heath Park</addrLine>
									<settlement>Cardiff</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff14">
								<note type="raw_affiliation"><label>14</label> Cardiovascular Imaging and Dynamics , KU Leuven , Leuven , Belgium.</note>
								<orgName type="department">Cardiovascular Imaging and Dynamics</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<note type="raw_affiliation">Federation of National Societies of Orthopaedics and Traumatology , Rolle , Switzerland.</note>
								<orgName type="institution">Federation of National Societies of Orthopaedics and Traumatology</orgName>
								<address>
									<settlement>Rolle</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_YHrRqjk">CORE-MD clinical risk score for regulatory evaluation of artificial intelligence-based medical device software Check for updates</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FF117EAA32918BE920376ADD9DF9F5C1</idno>
					<idno type="DOI">10.1038/s41746-025-01459-8</idno>
					<note type="submission">Received: 12 July 2024; Accepted: 15 January 2025;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T09:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_Xxepmsp"><p xml:id="_3UNjB4Q"><s xml:id="_6FQMMba">The European CORE-MD consortium (Coordinating Research and Evidence for Medical Devices) proposes a score for medical devices incorporating artificial intelligence or machine learning algorithms.</s><s xml:id="_ZURhn9u">Its domains are summarised as valid clinical association, technical performance, and clinical performance.</s><s xml:id="_DnDuyUe">High scores indicate that extensive clinical investigations should be undertaken before regulatory approval, whereas lower scores indicate devices for which less pre-market clinical evaluation may be balanced by more post-market evidence.</s></p><p xml:id="_s4WKFbj"><s xml:id="_yx44SRg">Artificial Intelligence (AI) in all its forms is being used increasingly in healthcare and medicine by both caregivers and patients/citizens <ref type="bibr" target="#b0">1</ref> .</s><s xml:id="_DKjp3fc">Until recently most applications were supporting diagnosis (analysing electrocardiograms, imaging, pathological specimens, skin lesions, and retinal pictures, etc.) but now AI methods are being employed in addition to estimating prognosis and predict the effects of treatment (personalisation); to detect and extract health data (using natural language processing); to assist in drug development; to monitor patients remotely; to communicate with patients (chatbots); and to personalise therapy through digital therapeutics and digiceuticals.</s><s xml:id="_x9WnvEJ">Many more uses arrive each day <ref type="bibr" target="#b1">2</ref> .</s><s xml:id="_bD87Ds8">Besides direct medical applications, the roles of AI are expanding into medical research, training (also via extended reality), public health, administration, and logistics.</s><s xml:id="_jF6Qt7s">AI drives robotics and automates procedures and interventions, offering promise for more lean and efficient healthcare <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4</ref> .</s><s xml:id="_5eBWXq2">Early applications of large language models (LLM) and the possibilities of foundation models are being explored and used in clinical contexts, but they are not covered by this document.</s></p><p xml:id="_caqX45R"><s xml:id="_WPYeRe7">Several individuals and institutions have warned of risks associated with the unbridled use of AI <ref type="bibr" target="#b4">5</ref> , or even suggested a temporary ban on further development.</s><s xml:id="_bn9p9B2">The European Union (EU) has developed horizontal laws relevant to healthcare and AI, such as the General Data Protection Regulation (GDPR), the Artificial Intelligence Act, and the European Health Data Space Regulation <ref type="bibr" target="#b5">6</ref> .</s><s xml:id="_Nya5Uaw">More importantly, medical device software (MDSW) that incorporates AI algorithms, whether it is standalone or integrated within a diagnostic or high-risk therapeutic device, requires conformity assessment for regulatory purposes before it is approved as a medical device for general use in clinical practice.</s><s xml:id="_RVC32Hs">In the EU the principles of device evaluation are prescribed by the Medical Device Regulation (MDR) and the In Vitro Diagnostic Medical Devices Regulation (IVDR), while worldwide most jurisdictions and many standards organisations and expert groups are also developing guidance <ref type="bibr" target="#b5">6</ref> .</s></p><p xml:id="_9UsvSMX"><s xml:id="_Bcy2vHD">European guidance for MDSW <ref type="bibr" target="#b6">7</ref> is based on international recommendations but does not comprehensively describe the specific clinical evidence needed for medical AI software.</s><s xml:id="_DXJUK5y">Thus there is a need for recommendations for the regulatory evaluation of AI MDSW, that could balance its potential for major beneficial impacts in healthcare against the possibility for its misuse and negative effects on individuals and society.</s></p><p xml:id="_E3WDGdR"><s xml:id="_WwquCGs">In the EU, producing guidance is the responsibility of the Medical Device Coordination Group (MDCG) (Article 105 MDR), which is composed of representatives from national regulatory agencies and chaired by the European Commission.</s><s xml:id="_FCXMjqy">A call from the Horizon 2020 programme sought external expert advice on methodologies for the clinical investigation of high-risk medical devices including those incorporating AI.</s><s xml:id="_76PGb5R">The CORE-MD project (Coordinating Research and Evidence for Medical Devices) established a task force for that specific objectivenamely to outline methodological principles for the clinical evaluation of AI MDSW during its full life cycle, applying a risk-benefit approach and focusing on pre-and post-release phases from both regulatory and end-user perspectives <ref type="bibr" target="#b7">8</ref> .</s><s xml:id="_ss9GV4g">This article presents its final recommendations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_w4uwhDK">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gjN9pHV">Membership</head><p xml:id="_pKWaVk4"><s xml:id="_NMS9NQK">The task force was led by KU Leuven and composed of CORE-MD consortium members and others invited because of their complementary expertise.</s><s xml:id="_7eQfM9Z">Backgrounds and relevant experience encompassed clinicians who have used AI to analyse medical images and other data types, clinicians qualified in computer science or as authors of relevant expert consensus statements, biomedical, electronics and informatics engineers, specialists in medical technology and regulatory science, lawyers expert in EU legislation and ethical considerations, and doctors from EU national regulatory agencies for medical devices.</s><s xml:id="_dmfRK4n">Manufacturers were not primary members of the CORE-MD consortium but their trade associations were represented on its international advisory board and so for this task, advisers were included because of their participation in international standards-setting bodies.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XNhmhUx">Review of existing guidance</head><p xml:id="_9NUqvTc"><s xml:id="_azMHmKA">A comprehensive analysis was undertaken of definitions, recommendations, and standards relating to the use of AI in healthcare and medical devices, published by national, European, and global organisations.</s><s xml:id="_z2AWax2">The resulting publication includes details of the search strategies that were used <ref type="bibr" target="#b5">6</ref> .</s><s xml:id="_NZAaURu">It was concluded that the level of clinical evidence should be determined according to each application and should consider factors that contribute to risk, including accountability, transparency, and interpretability.</s><s xml:id="_arAAjEE">Some principles are summarised below as the rationale for developing a risk score to guide proportionate clinical evaluation of AI MDSW.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_twMD4BN">Delphi consensus</head><p xml:id="_mBGNukV"><s xml:id="_GSBkQBW">After a series of strategy meetings among the members of the task force, the first version of the report was drafted in October 2022, and a two-stage Delphi process was organised throughout 2023.</s><s xml:id="_BhBJTuP">The meetings were held online; 33 clinical experts participated in the first session and 26 in the second one.</s><s xml:id="_Hec2dvF">Round 1 consisted of 11 voting statements and one free-text question; each was introduced briefly by the task leader, before independent voting.</s><s xml:id="_VfKtrZb">The threshold for statements to be adopted was 70% of positive responses.</s><s xml:id="_FyfDUUM">During Round 2, six statements that did not achieve 70% positive responses at the first vote, were revised and resubmitted to the experts.</s><s xml:id="_jDuPFxS">Participants were also invited to comment on the draft report.</s><s xml:id="_5yrF2V2">All statements that achieved consensus were integrated into this recommendation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_dtARZdB">Consultations with regulators and notified bodies</head><p xml:id="_WQvpdC8"><s xml:id="_vsVEEJt">The draft proposal was circulated with an explanatory note to members of the Clinical Investigation and Evaluation (CIE) and New Technologies (NT) Working Groups of the MDCG of the European Commission.</s><s xml:id="_F3hP2sW">Its key elements were presented by the task leader and the scientific coordinator of CORE-MD at meetings of CIE in April and November 2023, and at NT in June and December 2023.</s><s xml:id="_rnFCUbG">In parallel, the updated CORE-MD recommendations were sent to regulators and notified bodies, members of the consortium, and a team in the Joint Research Centre (JRC) of the European Commission (in Ispra, Italy) that is studying AI in medical technology <ref type="bibr" target="#b8">9</ref> .</s><s xml:id="_UHkA3dy">Finally, the proposals were presented to a meeting of the CORE-MD Advisory Board, and in a discussion with leadership of the International Medical Device Regulators Forum (IMDRF) Working Group on AI medical devices.</s><s xml:id="_92mGVtH">Account was taken of all comments received.</s><s xml:id="_Qs42GuK">Details of this methodology are provided in Supplementary Information Section 2.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9p5N4bx">Considerations for regulating AI medical devices</head><p xml:id="_KHnNhE4"><s xml:id="_x84yxCv">Quality and transparency of clinical decisions Healthcare providers apply evidence-based guidelines to optimise approaches to specific medical problems <ref type="bibr" target="#b9">10</ref> .</s><s xml:id="_d8tnP7x">Common approaches can help practitioners improve patient-relevant outcomes, maximising the health of individuals and the population <ref type="bibr" target="#b10">11</ref> .</s><s xml:id="_e86qmNQ">Deviation from guidelines may be warranted on the basis of patients' unique backgrounds, needs or expectations, in which case healthcare professionals (HCP) should be able to justify their decisions to the people affected.</s><s xml:id="_KbBjWzw">AI MDSW can be a powerful support tool to minimise unwanted variation, which is inherent in human judgements and decision-making <ref type="bibr" target="#b11">12</ref> .</s><s xml:id="_fn7667D">For it to earn the trust of end-users (citizens, patients, and HCPs) the AI MDSW must have undergone appropriate clinical evaluation and be compliant with the relevant MDR requirements.</s><s xml:id="_J7r3nNV">In many circumstances, the information provided can then enable real informed codecision-making between the patient and HCP, whether for diagnostic or therapeutic options.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_EH2vr4G">Human oversight</head><p xml:id="_UuFYRmU"><s xml:id="_77ew2hb">The autonomy of AI systems and the degree of possible human supervision vary greatly, so most commentators stress the need to integrate AI tools into existing workflow, creating a 'Human-AI team' <ref type="bibr" target="#b12">13</ref> .</s><s xml:id="_kfKUfqF">Interpretation and oversight can become difficult or even impossible when AI systems perform as 'black boxes' <ref type="bibr" target="#b13">14</ref> with their logic remaining obscure even when explainability methods, which often remain inadequate, are applied <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref> .</s><s xml:id="_4SPFKG6">Oversight may be less effective for less experienced users who paradoxically might benefit the most from such tools <ref type="bibr" target="#b23">24</ref> .</s><s xml:id="_kpVVx8S">It is exactly for this reason we have recommended transparency of all input data and continued evaluation of the diagnostic performance of such algorithms.</s></p><p xml:id="_vFerthQ"><s xml:id="_4zB2km4">On the other hand, providing real-time human oversight might reduce safety and decrease the performance of an AI tool <ref type="bibr" target="#b24">25</ref> whose capabilities exceed the human and the human-AI team in terms of speed (faster reaction times), performance (more accurate and precise), being less prone to errors and more consistent.</s><s xml:id="_kNmeb4C">It remains, however, the sole responsibility of the caregiver, together with the patient, to co-decide about preventive, diagnostic or therapeutic measures using AI tools, while taking into account the patient's values, social and lifestyle factors, culture and accessible resources.</s></p><p xml:id="_kpCzBhd"><s xml:id="_SGu2DX5">Some AI tools are available as apps to be used by citizens and patients without any involvement of HCPs, in which case oversight depends on the end-user <ref type="bibr" target="#b25">26</ref> .</s><s xml:id="_TzfY37w">Human oversight can be very effective and appropriate in many circumstances, but that should not be used to shift responsibility and accountability for the output of AI MDSW from the manufacturer solely to the supervising human.</s><s xml:id="_vP35dKV">Decisions mostly depend on the context of use and are made by clinical teams of HCPs so it would be more appropriate to consider liability at the level of the manufacturer and the organisation using the MDSW.</s><s xml:id="_6QkawhH">As with all medical tools, AI MDSW should be evaluated in the intended population for the specific purpose with appropriate clinical investigations before implementation.</s><s xml:id="_6v4VUpk">It is the goal of this article to provide a practical guide as to how and in what phase of the AI life cycle such investigations should be performed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_94gSs8M">On-market adaptive approaches</head><p xml:id="_TTFqufE"><s xml:id="_YR4xYZn">The implementation of the objectives of personalised medicine may be supported by AI tools that adapt to specific use settings and patients' characteristics, after they have been placed on the market, by using a learning approach to adjust their parameters with continuous or intermittent implementation of changes.</s><s xml:id="_HJreEGA">The high complexity of the post-release phase of AI MDSW makes Algorithm Change Protocols challenging <ref type="bibr" target="#b26">27</ref> .</s><s xml:id="_HNq6awR">Any drift in the intended use of an AI algorithm or in the target population where it is applied, perhaps because of evolving clinical practice, could change its risk and performance metrics.</s><s xml:id="_jUnnrbz">Additional data need to be collected and used to adapt the algorithm, which necessitates continuous evaluation after its release.</s><s xml:id="_EqQgaW4">An agile approach to the development, testing, and validation of AI tools <ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29</ref> preferably with a system view rather than a pure device focus <ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref> , should be facilitated by regulatory standards.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_sa8se38">Similarity with clinical judgement</head><p xml:id="_CEVZsgk"><s xml:id="_tGBTd3e">To better understand how an AI decision-support tool could be positioned in the clinical workflow, the tool can be compared to a clinical colleague from whom one receives advice before deciding on a diagnostic or therapeutic action.</s><s xml:id="_NhQA26t">No one is infallible but a clinical colleague is trusted because of their verified licence, education, training, competence, ethical principles, and experience.</s><s xml:id="_qrzSBBP">An AI MDSW developer should provide similar proof, with documentation of safety and performance and verification by a notified body, as required in the EU by the MDR (and by the AI Act), and with clinical evaluation showing a positive balance between predefined benefits and any associated risks.</s><s xml:id="_9YeNDJR">That will not guarantee that the MDSW will function without any errors, but it should support improved outcomes at a reasonable cost compared to other methods, leaving the final co-decision to the patient and the HCP.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_aWu4DGv">Results and recommendations</head><p xml:id="_xUkEHTG"><s xml:id="_PMcRMTN">Process endorsed Almost all experts (90%) consulted in the Delphi process supported the riskbenefit-based approach for evaluating AI medical devices, and 80% supported the concept of a scoring system to guide requirements for clinical evidence (see Supplementary Information Section 2).</s><s xml:id="_7tEnxrM">Most (88%) also concurred with the recommendation that low-risk AI medical devices showing a clear benefit could be brought to the market with graded evidence and formal requirements for post-market follow-up.</s><s xml:id="_eaVXWcQ">There was no consensus among the consortium members to incorporate in this proposed text the alternative approach that has been adopted by some regulators [such as the Food and Drug Administration (FDA)] of certifying software companies on the basis of their quality-control systems and adapting the requirements for specific MDSW release depending on such certification.</s><s xml:id="_JFAT9Ba">Such a mechanism could make it very difficult, if not impossible, for small and medium-sized enterprises and academic institutions to comply with these requirements.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_HxWjFW8">Risk-based approach</head><p xml:id="_eftV2za"><s xml:id="_ErHHndJ">Transparency is key in all healthcare interactions.</s><s xml:id="_sfGsAj5">When using AI MDSW, the HCP should be completely open to the patient about its use and about inherent benefits and disadvantages including explainability or lack thereof, the technical and clinical evidence supporting its use, any alternatives, and the consequences of non-use.</s><s xml:id="_8sSuCsD">For this, of course, the HCP needs access to the evidence supporting the claims for the AI MDSW for its defined purpose.</s></p><p xml:id="_MBRYMRv"><s xml:id="_cMw9bhY">The balance between positive outcomes and possible safety risks or side effects needs to be considered at both the individual and the societal level.</s><s xml:id="_FnfpDk3">When demonstrating clinical benefit and/or improved efficiency in workflow, individual and societal human rights might conflict to a certain degree, so ethical considerations are paramount <ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref> .</s><s xml:id="_XzBYTqW">Medical device legislation requires compliance with safety and performance requirements, with a positive benefit-risk balance taking into account the acknowledged state of the art <ref type="bibr" target="#b36">37</ref> .</s></p><p xml:id="_fDTAwXw"><s xml:id="_q7dm8uj">When evaluating a new AI tool in the context of the present state of the art, the tool must demonstrate an improved benefit-risk ratio, while keeping the absolute risk as low as possible.</s><s xml:id="_hQ3fA2N">Implementing a new tool involves managing both an operational and a cultural change, which may be difficult for the endusers to accept, so a comparison of risks is crucial for reaching a decision.</s></p><p xml:id="_3X7Ze6Q"><s xml:id="_TXcnPnu">Manufacturers are required to justify why the clinical evidence for their AI tool, which they provide, is appropriate and conforms with standards.</s><s xml:id="_JnNjggy">European guidance, in line with recommendations from the IMDRF, considers three aspects to be crucial for the safe and effective use of MDSW (and by implication AI): valid clinical association, technical performance, and clinical performance <ref type="bibr" target="#b6">7</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jmZENRy">Defining risk</head><p xml:id="_ARnRFUY"><s xml:id="_TDZejst">Risk is a composite of the probability of an event and its severity.</s><s xml:id="_mhN5BTZ">Specific challenges for managing risks of AI tools, at every stage in their life cycle, may include:</s></p><p xml:id="_mJUBaX9"><s xml:id="_BQVd8Jx">(1) difficulty in defining and measuring negative impact or magnitude of harm; (2) tolerance of risks due to societal acceptance and preferences;</s></p><p xml:id="_ZMa82Aw"><s xml:id="_h8dHMCG">(3) having to consider not just absolute risk but also the culture about taking and allowing risks in the specific use environment; (4) considering additional factors such as cybersecurity and privacy.</s></p><p xml:id="_WYPwbQX"><s xml:id="_G97q8QF">The goal is to optimise the benefit-risk balance for the end-user(s) by applying the best processes for 'TEVV' (test, evaluation, verification and validation).</s></p><p xml:id="_zCBKsdj"><s xml:id="_WgTJebR">The stages of developing and implementing AI MDSW have been described by the National Institute of Standards and Technology (NIST) in the USA as: Data and Input; AI Model; Task and Output; and Application context <ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref> .</s><s xml:id="_5nQk8GY">These have been adapted into 8 phases as represented by the coloured boxes in Fig. <ref type="figure" target="#fig_0">1</ref>.</s><s xml:id="_dPKJfJH">Ideally, trustworthy AI should be valid and reliable, safe, secure and resilient, accountable and transparent, explainable and interpretable, privacy-enhanced, and fair with harmful biases managed <ref type="bibr" target="#b42">43</ref> .</s></p><p xml:id="_sWfn5uX"><s xml:id="_X5CtmyT">AI tools need to be trained and tested on representative datasets reflecting the context of intended use <ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45</ref> , and certain supervised ML algorithms need good-quality labels determined by human annotators for use as reference (or ground truth).</s><s xml:id="_pNAkGCs">The collection of datasets that contain personal information is subject to the requirements of the EU General Data Protection Regulation <ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47</ref> .</s><s xml:id="_zvCBYdJ">The use of datasets for developing AI tools and their need for curation necessitate extra attention concerning their validity, intrinsic bias (i.e. by ethnicity, sex, age group, etc.), representativeness of patient populations, geographic distribution of data sources, and quality of the labels.</s></p><p xml:id="_yt98Mgb"><s xml:id="_EAQEZyZ">A comprehensive list of factors that can influence risk is given in Supplementary Information Section 1.</s><s xml:id="_qvcqEkj">For a given AI tool, some or all of these factors will be relevant but usually with variable impact on the overall benefit-risk balance, depending on the application domain and the context  <ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63</ref> ) which they have been designed to reflect.</s><s xml:id="_xHTFMAY">The blue vertical lines show the possible timing of CE certification in Europe; depending on the Risk Score, CE certification can be obtained with the pilot (lower risk, certificate with conditions; first line) or with full comparative (higher risk) clinical evaluation (second time-line), always with appropriate post-release evaluation.</s></p><p xml:id="_kp2jUwJ"><s xml:id="_5W7kqVq"><ref type="url" target="https://doi.org/10.1038/s41746-025-01459-8">https://doi.org/10.1038/s41746-025-01459-8</ref> of use.</s><s xml:id="_UTDbsZS">A manufacturer should position its AI tool with respect to all these factors, to specify what evidence will be required before approval and what should be collected after release.</s><s xml:id="_Px8vbJE">This information will also inform the enduser when deciding whether to use the tool in the clinical environment.</s></p><p xml:id="_Yf5RPXP"><s xml:id="_k2YvH2X">Balancing safety with access Individuals and patients should not be exposed to MDSW with unacceptable risks.</s><s xml:id="_jTCZg4b">There have been cases where AI or MDSW applications in healthcare heightened risks for individuals.</s><s xml:id="_wj7EXD9">For example, a US class-action lawsuit against Healthcare United alleged that their AI algorithm ("nH Predict") was issuing wrongful denials of claims for extended care for elderly patients (<ref type="url" target="https://www.forbes.com/sites/douglaslaney/2023/11/16/ai-ethics-essentials-lawsuit-over-ai-denial-of-healthcare/">https://www.forbes.com/sites/douglaslaney/2023/11/16/ai-ethics- essentials-lawsuit-over-ai-denial-of-healthcare/</ref>).</s><s xml:id="_TqnaEAv">In another case, involving IBM Watson for Oncology, possible unacceptable risks for medical device software were caused by AI-based systems providing wrong recommendations to doctors for treating cancer <ref type="bibr" target="#b14">15</ref> .</s><s xml:id="_wzwPseC">Many AI tools, however, could offer a relevant benefit for unmet needs without conveying significant risk.</s><s xml:id="_24Gzu5X">Not offering such MDSW tools, due to excessive regulatory demands, could disadvantage individuals who would have benefited <ref type="bibr" target="#b47">48</ref> .</s><s xml:id="_wtBHeUg">Manufacturers could decide not to market their AI medical device in the EU if it is perceived that the burden for CE-marking is too high.</s></p><p xml:id="_AcrHvEW"><s xml:id="_ZAGQz7y">AI tools with a favourable clinical benefit-risk ratio and a low level of risk to individuals and society, as indicated by the scoring system proposed in this advice, could be approved with appropriate graded or stratified evidence.</s><s xml:id="_FhenmjN">Premarket studies focused mainly on statistical significance and less on clinical relevance, which could be balanced by more emphasis on gathering data in the post-market phase to support the clinical usefulness.</s><s xml:id="_hEaxKVt">Some low-risk tools, or new releases of existing tools providing usability or other improvements, could be approved without additional studies in patients and with only technical and scientific proof of the desired change or outcome.</s></p><p xml:id="_P7wn2eE"><s xml:id="_DWUTpxX">A manufacturer might release a lower-risk AI tool with evidence from a study powered for the general target population but not for subpopulations/ minority groups.</s><s xml:id="_KdZ5FXt">Where the evidence for such groups is limited, patients and users should be made aware of these limitations as appropriate.</s><s xml:id="_YUS385A">In contrast, tools with a high risk to individuals or society should undergo extensive clinical evaluation before release, including clinical investigations or trials.</s><s xml:id="_p2BTCEB">If it is difficult or impossible to show benefit, either directly to patients' outcomes or indirectly by improving efficiency for the interactions between HCPs and patients, then any risk, however small, would be unacceptable.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_KqWMQFh">Surveillance of risk</head><p xml:id="_7zhCWTV"><s xml:id="_qGKEmNv">In either casewhether an AI tool is initially approved with graded or more extensive evidencecontinued evaluation of its benefit-risk ratio is necessary because of potential drifts over time in its intended or actual use, in the target population, and/or in its verifiability by humans.</s><s xml:id="_Bufz6rE">The representativeness and quality of additional real-world data about the accuracy and performance of the tool need to be demonstrated, evaluated and validated.</s><s xml:id="_aqzVRVv">In contrast to hardware devices, it would be an advantage if such evaluation could be built into the MDSW <ref type="bibr" target="#b48">49</ref> although that would require specification of new criteria to be assessed by notified bodies.</s><s xml:id="_mX6sv7M">If post-release evidence (algorithmic vigilance) <ref type="bibr" target="#b49">50</ref> reveals that AI MDSW is negatively influencing the benefit-risk ratio, then stricter regulatory follow-up should ensure that it is withdrawn.</s><s xml:id="_95N64UU">Reimbursement decisions would also require reconsideration of new evidence during the post-release phase.</s></p><p xml:id="_nHksYR3"><s xml:id="_Zyt4SSM">End-users of an AI tool (citizens, patients, and HCPs) should be informed about benefit-risk evaluations and their consequences for certification and access to the market.</s><s xml:id="_W8R634v">Transparency is essential for continued trust in a specific tool and in the process as a whole.</s><s xml:id="_RNUgPpp">The quality of submitted evidence should always be high for both pre-release and post-market requirements, and whether data are acquired retrospectively or prospectively, should be determined by analysis of possible benefits and risks.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ecCwWQz">Estimating riskscoring system</head><p xml:id="_R63nBHt"><s xml:id="_qASQ58V">We propose a simple point-scoring system to estimate the overall risk of an AI tool.</s><s xml:id="_GtxFmPM">It is composed of three parts, that allow assessment of the tool during its whole life cycle.</s><s xml:id="_sJJS22G">Its componentsvalid clinical association score (VCAS), valid technical performance score (VTPS), and clinical performance score (CPS)have been developed using the terms and definitions for categories of evidence given in MDCG guidance 2020-17, which are described in Table <ref type="table" target="#tab_0">1</ref>.</s><s xml:id="_SDAHrSr">Although they are specific to the EU regulatory system, they are well aligned with the IMDRF guidance.</s><s xml:id="_5TXu23g">We propose that the total score (with possible values from 4 to 12) should be linked to requirements for clinical evaluation before and after an AI tool is approved.</s><s xml:id="_QWsCAdE">Lower values are associated with less risk.</s><s xml:id="_2TrqaZg">The relationships of the three risk scores with the life cycle phases, the timing of the pre-and post-release phases, and the possible timings of CE certification (vertical blue lines) are indicated in Fig. <ref type="figure" target="#fig_0">1</ref>.</s><s xml:id="_SGPzzEM">This approach could seem like an oversimplification but it is intended firstly to help manufacturers, notified bodies, and clinicians to prioritise efforts for evaluating new AI MDSW, and secondly to avoid unnecessarily limiting access to potentially helpful AI tools that are low-risk.</s><s xml:id="_GvVARCT">The score does not deflect from the need for regulatory appraisal of the entire AI benefit-risk evaluation during the certification process.</s><s xml:id="_wGybx5J">It does not consider if the manufacturer of an AI tool intends to have its output validated by a 'human-in-the-loop', since that would depend too much on the user's (unknown) expertise and experience.</s><s xml:id="_hcR7uur">In our view, planning output verification by a human, irrespective of the capability of the human to effectively perform such oversight, is not currently sufficient to designate a medical AI tool as low-risk; there are not yet rigorous and repeatable methods to ensure that explainability is delivered to users (either the HCP or patient) in a manner that truly assists them in recognising poor advice from AI systems, or for the prevention of automaton bias.</s><s xml:id="_ebsr9FA">There are also not yet implementable approaches for evaluating the safety of the explainability of AI MDSW.</s><s xml:id="_TnfXXUu">Should such approaches later be developed, the scoring system can be adapted to take appropriate account of these developments.</s><s xml:id="_HJhx4Ge">In all circumstances it should be completely transparent to the end-users, both clinicians and patients, if the AI tool is explainable or not, and how rigorously the validation and testing were performed, in order to support the trust they can put into the results of the tool.</s></p><p xml:id="_6WdGqSh"><s xml:id="_ynWm8Je">Valid clinical association score (VCAS).</s><s xml:id="_2gnPpDp">The valid clinical association is defined as "the extent to which the MDSW's output (e.g.</s><s xml:id="_sZK82aF">concept, conclusion, calculations), based on the inputs and algorithms selected, is associated with the targeted physiological state or clinical condition.</s><s xml:id="_wZhyb6c">This association should be well founded or clinically accepted" <ref type="bibr" target="#b50">51</ref> .</s><s xml:id="_uVUErtF">The clinical association may be characterised by the type of AI model (e.g.</s><s xml:id="_pkYUvDp">supervised or unsupervised), the availability of ground truth to train and test the algorithm, its transparency and explainability, and the possibility for human oversight (see item 4b in the Supplementary Information Section 1).</s></p><p xml:id="_GsEMwFs"><s xml:id="_5wpuytr">As an example, in the case of an unsupervised AI model in which data are clustered to find a possible relationship among the extracted features, but without the presence of ground truth, a subscore in this category of 3 (impossible) would be assigned.</s><s xml:id="_g69hzJr">If following the preliminary association, another and more specific scientific study has been conducted to prove such apparent relationships, then the strength of its results could modulate the relevant VCAS score to being 1 (easy) or 2 (difficult).</s></p><p xml:id="_fFpRxdC"><s xml:id="_fMSgQM9">An example of effective oversight for a deep learning algorithm that is a 'black box' would be when the output of a diagnostic imaging segmentation tool is verified by a clinician seeing the contour made by the tool, overlaid onto the image that it has analysed; that would merit a subscore in this category of 1 (easy) despite the algorithm itself being uninterpretable.</s></p><p xml:id="_46xqWFz"><s xml:id="_vhbVdnp">Valid technical performance score (VTPS).</s><s xml:id="_YE3UdtD">Technical performance is defined as the "Capability of an MDSW to accurately and reliably generate the intended technical/analytical output from the input data".</s><s xml:id="_SKpQGhn">Verification of technical performance is thus by demonstrating that the AI tool accurately, reliably and precisely generates the intended output from the input data, when it is used in the real world in its intended computing and use environments.</s><s xml:id="_kHChdRz">Technical performance can be documented by standard measures for assessing AI tools, such as accuracy, specificity, sensitivity, area under the receiver-operating characteristic curve, and F1 score, in the presence of a ground truth.</s><s xml:id="_KSzYpqA">Caution is needed with imbalanced datasets, where these standard metrics are overly optimistic and can miss poor performance in low-prevalence conditions <ref type="bibr" target="#b51">52</ref> .</s><s xml:id="_Am2eTCD">In such cases, measures such as the area under the precision-recall curve provide greater robustness to class imbalance and should be considered instead <ref type="bibr" target="#b52">53</ref> .</s><s xml:id="_FzZ963S">Input characteristics are listed in item 4a in Supplementary Information Section 1, and features related to output are given in items 4c-f.</s></p><p xml:id="_HNmbtBy"><s xml:id="_EUaBShr">In addition to any metrics, we propose that the grades in the VTPS should reflect the degree of independence between the training data and the data used for testing an AI tool, and the breadth of external testing performed.</s><s xml:id="_vAkFyKd">(see Table <ref type="table" target="#tab_0">1</ref>).</s><s xml:id="_RscuX26">Machine learning methods are susceptible to identifying spurious relationships that exist in the training data but are not present in real-world settings <ref type="bibr" target="#b53">54</ref> , resulting in reduced model performance on new data from different settings.</s><s xml:id="_7CBSuvf">Good model performance can be assured only through testing on data acquired from a range of real-world settings <ref type="bibr" target="#b54">55</ref> , which are truly representative of the settings of intended use, and this is reflected by the VTPS (Table <ref type="table" target="#tab_0">1</ref>).</s></p><p xml:id="_vb2yFvH"><s xml:id="_tUxJApA">'Internal Validation' means that the performance of the tool has been tested only on data acquired with the same settings (same institution, using the same equipment, interpreted by the same observer as the training group, in the same group of patients, perhaps with bootstrapping) as the training data.</s><s xml:id="_ZJ8BX6D">This would produce a VTPS of 3. 'Narrow External Validation' implies that the training and testing data were partially differentiated for some of these factors (VTPS = 2), while 'Broad External Validation' signifies that the performance of the AI tool was evaluated using separate training and (re) testing datasets (i.e.</s><s xml:id="_7HPtxZh">acquired using different equipment, from different centres, at different times, interpreted by different observers, in different patient groups, etc).</s><s xml:id="_KjWF9sX">This would generate a VTPS of 1. Thus the VTPS also reflects the risk of bias in the performance of an AI model.</s></p><p xml:id="_yF7PMwe"><s xml:id="_8gxEKnp">Notwithstanding efforts to validate AI tools before approval, unintended generalisation, shortcut learning <ref type="bibr" target="#b53">54</ref> , biases in the function of the algorithm <ref type="bibr" target="#b55">56</ref> , and other errors in performance often become apparent only when the MDSW is used in the real world for its intended indication but in an unselected population.</s><s xml:id="_8bgwkrF">Drift in the intended purpose and population may occur more easily with MDSW than with other devices, so it is imperative that proper post-release surveillance is conducted.</s><s xml:id="_E67WG5B">It should document the context of use, the indication for use, and relevant outcomes, at predefined time-points after release.</s><s xml:id="_56D4sZZ">Feedback to regulatory authorities and Notified Bodies should verify the continued performance of the MDSW, and when it becomes necessary to address problems, then interventions should limit use, lead to a recall, or in the EU suspend the certificate of conformity.</s><s xml:id="_GQRTfTt">Such postrelease surveillance could also include notifications to end-users to alert them in individual cases if they are using the MDSW outside the validated indication and context.</s></p><p xml:id="_YUkpzRT"><s xml:id="_KHUBbxe">Clinical performance score (CPS).</s><s xml:id="_Q9A7rFy">Clinical performance is the "ability of a device, resulting from any direct or indirect medical effects which stem from its technical or functional characteristics, including diagnostic characteristics, to achieve its intended purpose as claimed by the manufacturer, thereby leading to a clinical benefit for patients, when used as intended by the manufacturer" <ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b50">51</ref> .</s></p><p xml:id="_kJzpWQf"><s xml:id="_et4hK6k">A clinical benefit is always required for unrestricted release to the market; the timing for establishing such benefit, however, depends on the risk involved in exposing patients to the device.</s><s xml:id="_G6cjkxJ">The CPS is used to determine such timing, either before or after release.</s></p><p xml:id="_A6VQQF9"><s xml:id="_axqKKVH">In 2017, IMDRF guidance recommended that the need for an independent review of clinical investigations and evidence of the benefit of MDSW, before regulatory approval, should be determined firstly according to the function of the software (ranging from informing for a non-serious condition to treating or diagnosing in a critical condition) and secondly to its significance <ref type="bibr" target="#b56">57</ref> .</s><s xml:id="_mMPwdYA">These features were summarised in two scales ("Definition Statement" and "Impact") but they conflate three characteristics, which are the function of the MDSW (informs/drives/treats), the stage of the clinical condition (non-serious/serious/critical), and its potential impact (none/ low/medium/high/catastrophic).</s><s xml:id="_qT34qSA">Also, the classification system proposed by the IMDRF <ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref> is very context-dependent.</s><s xml:id="_sXDvN39">The same disease or condition may be acute or chronic, with various levels of severity, and influenced by <ref type="url" target="https://doi.org/10.1038/s41746-025-01459-8">https://doi.org/10.1038/s41746-025-01459-8</ref></s><s xml:id="_KqJ9hVt">comorbidities.</s><s xml:id="_7RVmhfn">A diagnostic tool could be critical when its result determines treatment for a life-threatening disease, while the same tool would be nonserious if used for a chronic non-life-threatening illness or with extensive human oversight.</s><s xml:id="_cDQCyZG">In practice, the application of an AI tool may drift from its original intended purpose ("off-label" use), so it is best from the outset to consider its most critical possible use when determining the risk score.</s></p><p xml:id="_bfshYBR"><s xml:id="_zfUAMTE">The CPS consists of two criteria that should be scored separately and then combined (see Table <ref type="table" target="#tab_0">1</ref>); they assess the criticality of the healthcare situation for which the AI tool is intended, and the expected impact of its output.</s><s xml:id="_raGY87b">Together they reflect if the AI tool, when used for its recommended indication, achieves the clinical benefit that was claimed as its purpose.</s><s xml:id="_MYRz7Ka">The CPS relates to items listed in paragraphs 1-3 and 5-6 in Supplementary Information Section 1.</s><s xml:id="_6P2H6uM">The relevance of human factors is underscored by the emphasis on human oversight (Supplementary Information Section 1, 4b), explainability (Supplementary Information Section 1, 4d), and the evaluation of proper integration in the clinical workflow (Supplementary Information Section 1, 4e).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rVAA8Xx">Discussion</head><p xml:id="_baAjRzq"><s xml:id="_yFDESBV">The overall score, which is the sum of the CPS, VTPS and VCAS (Fig. <ref type="figure" target="#fig_1">2</ref>), indicates when an extended evaluation and a higher level of clinical evidence would be appropriate before approval, or when a less rigorous assessment Values falling within the range indicated in the green box will apply to AI medical devices that could be approved for market access after less extensive, appropriate evaluation.</s><s xml:id="_kdcz75E">Fig. <ref type="figure">3</ref> | Recommended items to be evaluated and documented for AI medical device software, before regulatory review, approval, and releaseaccording to the level of the CORE-MD AI Risk Score.</s><s xml:id="_HZfEVuA">Sections 1-8, and the corresponding items, are developed from NIST recommendations <ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63</ref> .</s><s xml:id="_h4gfySn">The green and orange columns correspond respectively to AI medical devices with lower values of the risk score, and those with higher values (see Fig. <ref type="figure" target="#fig_1">2</ref>).</s><s xml:id="_C9m4zy4">+ indicates an item that should be evaluated during the pre-market stage;indicates an item that does not need to be evaluated at this stage.</s></p><p xml:id="_grw7maG"><s xml:id="_w5aapHA"><ref type="url" target="https://doi.org/10.1038/s41746-025-01459-8">https://doi.org/10.1038/s41746-025-01459-8</ref></s><s xml:id="_BUed4ez">would be proportionate before market release (but perhaps with conditions for collecting more evidence during post-market clinical follow-up). Th</s><s xml:id="_fSdy5pp"> 10 principles of Good Machine Learning Practices 60 pertain to both circumstances.</s></p><p xml:id="_VsXkVcg"><s xml:id="_vZKWARH">A minimum score of 4 would be awarded to an AI tool that has been trained and retested using independent datasets from different populations, gives diagnostic information about a non-serious disease, is fully transparent, completely interpretable and explainable, and is capable of comprehensive human oversight.</s><s xml:id="_wd5AVrr">A low-risk tool with such features can be safely approved with a basic level of pre-market clinical evidence.</s><s xml:id="_R8ZW8AS">On the other hand, an autonomous AI system which recommends treatment for a critical condition based on the output of a deep learning algorithm that has not been validated in an independent population and that allows no possibility for human oversight (earning a maximum score of 12), would clearly be very high risk.</s><s xml:id="_mVpaHS9">An AI device of that type cannot be approved safely for market access until it has undergone thorough clinical evaluation, probably including a randomised trial.</s></p><p xml:id="_GFjvEca"><s xml:id="_gd2x5Cy">Most AI medical devices will fall between these extreme examples.</s><s xml:id="_wTVejph">To avoid inappropriately early release of an AI tool with a low overall score but a high score on one of the subsets, extended pre-market evaluation is advised if the CPS score is 5 or more, or if the sum of the CPS and VTPS is 6 or more (see Fig. <ref type="figure" target="#fig_1">2</ref>).</s><s xml:id="_9WbDcpC">Thus an AI tool used in a critical situation could fall into the lower-risk category if its function is only to inform (subtotal for CPS = 4); any other function would make it higher risk (≥5).</s><s xml:id="_R996dxv">Similarly, an AI decisionsupport system that suggests a diagnosis or treatment would be lower risk only if its use is restricted to non-serious conditions (CPS = 4).</s><s xml:id="_wwuD7ex">If the technical validation of an AI algorithm has been weak (VTPS = 3) then initial regulatory approval with less extensive pre-market clinical evidence could be considered only if its function claimed by the manufacturer is to inform in a non-serious condition (CPS + VTPS = 5).</s></p><p xml:id="_ayTRFBV"><s xml:id="_6gjnhPC">Beyond this focus on the CPS and clinical implementation of an AI medical device, the cumulative risk score described in Fig. <ref type="figure" target="#fig_1">2</ref> can also indicate requirements for evaluation across all life cycle stages.</s><s xml:id="_5WQsSjG">These are listed in Figs. <ref type="figure">3</ref>, <ref type="figure">4</ref>, opposite eight categories adapted from NIST <ref type="bibr" target="#b29">30</ref> .</s><s xml:id="_D6HN53c">The last two columns show items that should be evaluated for lower-and higher-risk AI MDSW, respectively, either before market access (Fig. <ref type="figure">3</ref>) or after market access (Fig. <ref type="figure">4</ref>).</s></p><p xml:id="_Egh5qtx"><s xml:id="_kERfPNa">Many official bodies, including the Chinese Authority for Medical Device Evaluation (the National Medical Products Administration, NMPA <ref type="url" target="https://www.cmde.org.cn/xwdt/shpgzgg/gztg/20231107153309174.html">https://www.cmde.org.cn/xwdt/shpgzgg/gztg/20231107153309174.html</ref>), are now engaged in preparing guidelines and recommendations for the use of AI and ML in medical applications; the main sources of documents relevant to the EU system are illustrated in Fig. <ref type="figure" target="#fig_2">5</ref>. Within this framework, the CORE-MD project has no official status, but it was funded by the EU with the remit to advise on the clinical evaluation of high-risk medical devices.</s><s xml:id="_qzceE8T">Representatives from CORE-MD have presented the recommendations in this paper to both the CIE and NT working groups (see Supplementary Information Section 2), with a view to advising on the development of MDCG guidance on the clinical evaluation of AI/ML-enabled medical devices.</s><s xml:id="_nKdCCUp">The scoring system proposed by this paper will be discussed as part of a dedicated work package of CIE aimed at integrating CORE-MD outputs into the European regulatory system.</s><s xml:id="_uwsuHAX">The recommendations have also been presented to one of the chairs of the IMDRF AI/ML working group.</s><s xml:id="_CeHRMp6">A more detailed account of regulatory initiatives relating to AI and MLenabled medical devices is given in an earlier report from the CORE-MD project <ref type="bibr" target="#b5">6</ref> .</s></p><p xml:id="_n22xyae"><s xml:id="_uvqNmtJ">Guidance will need to be developed concerning the methodologies of studies required for each phase.</s><s xml:id="_gVZmcYs">Studies of AI MDSW early in its life cycle aim at showing the stability of the product, while demonstrating safety may be difficult if cohorts are small.</s><s xml:id="_kuhpJq9">Later, comparative studies could make use of Fig. <ref type="figure">4</ref> | Recommended items to be evaluated and documented for AI medical device software, after regulatory approval and release and according to the level of the CORE-MD AI Risk Score.</s><s xml:id="_hsPfY2V">Sections 1-8, and the corresponding items, are developed from NIST recommendations <ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63</ref> .</s><s xml:id="_etvRKan">The green and orange columns correspond respectively to AI medical devices with lower values of the risk score, and those with higher values (see Fig. <ref type="figure" target="#fig_1">2</ref>).</s><s xml:id="_68uy4hy">+ indicates an item that should be evaluated during the post-market stage;indicates an item that does not need to be evaluated at this stage.</s></p><p xml:id="_jN5ccBw"><s xml:id="_PNbKPkb"><ref type="url" target="https://doi.org/10.1038/s41746-025-01459-8">https://doi.org/10.1038/s41746-025-01459-8</ref> re</s><s xml:id="_er4Hd6W">l-world approaches, large simple trials, and adaptive designs <ref type="bibr" target="#b60">61</ref> .</s><s xml:id="_meRzafQ">Retrospective data can be used for the initial training, testing, and validation of an AI tool, but prospective clinical investigations will always be required in the appropriate phases.</s><s xml:id="_HHmRQNf">Medical device Expert Panels could play a crucial role in establishing guidance for clinical evaluation, with participation from patients and citizens especially when rules for the clinical evaluation of MDSW in lower-risk classes are being considered; these CORE-MD recommendations are relevant especially to high-risk AI MDSW.</s></p><p xml:id="_WxnUHye"><s xml:id="_DH3VuGF">Evaluation of the potential clinical utility of the CORE-MD AI Risk Score will need to assess if it is equally applicable to different AI/ML devices used in different contexts and populations.</s><s xml:id="_6j2mMXK">The use of a new tool may drift, and it may be used 'off-label'.</s><s xml:id="_ZCegPAH">All AI/ML devices need to be evaluated to determine their generalisability; a similar consideration may be important for this score.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XnvpruH">Conclusions</head><p xml:id="_sPrPaQm"><s xml:id="_BTXrdpg">Using a new and simple scoring system for the assessment of risk, we propose a benefit-risk approach to guide requirements for the clinical evaluation of AI Medical Device Software, taking into account the entire life cycle of the MDSW and addressing regulatory requirements and the clinical evidence needed for trusted use of these devices by patients and caregivers.</s></p><p xml:id="_EnfMHKn"><s xml:id="_vJqc6Tf">By combining regulatory and clinical requirements into one workflow, and by focusing on the need for real-world evidence for AI MDSW, including an analysis of the risks involved in human-machine interactions, we offer a more streamlined approach which can lead to a proportionate implementation of the MDR requirements, alleviating some of the concerns about limiting innovation.</s><s xml:id="_bRaR2hC">By emphasising the post-release phase, any changes or drift in AI MDSW in the clinical environment can be addressed when and where they occur.</s></p><p xml:id="_CG9yHch"><s xml:id="_383thyg">The approach that we recommend should now be evaluated scientifically, and if its utility is confirmed then it could serve as a valuable contributary resource for future EU regulatory guidance.</s><s xml:id="_rdbqmEJ">The recommendations have been developed robustly, in consultation with regulatory authorities, and further discussions are planned.</s><s xml:id="_rRm2Nct"><ref type="url" target="https://doi.org/10.1038/s41746-025-01459-8">https://doi.org/10.1038/s41746-025-01459-8</ref></s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 |</head><label>1</label><figDesc><div><p xml:id="_Vkb26rv"><s xml:id="_MrqzxBC">Fig. 1 | Relationship between components of the CORE-MD Risk Score and the stages of development and implementation of AI MDSW.</s><s xml:id="_Ccak2DM">The relationship between components of the CORE-MD Risk Score [CPS Clinical performance score; VTPS Valid Technical performance score; and VCAS Valid clinical performance score] and the stages of development and implementation of AI MDSW (adapted from NIST<ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63</ref> ) which they have been designed to reflect.</s><s xml:id="_AhnBRxp">The blue vertical lines show the possible timing of CE certification in Europe; depending on the Risk Score, CE certification can be obtained with the pilot (lower risk, certificate with conditions; first line) or with full comparative (higher risk) clinical evaluation (second time-line), always with appropriate post-release evaluation.</s></p></div></figDesc><graphic coords="3,213.28,566.14,347.98,156.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 |</head><label>2</label><figDesc><div><p xml:id="_H2B3QZY"><s xml:id="_Qv4V3js">Fig. 2 | Relationships between subtotals and a total of the CORE-MD AI Risk Score and the extent of clinical evaluation recommended before regulatory approval.</s><s xml:id="_4Fg7TQ5">The CPS score should be estimated first since high scores in both of its parts would mandate more extensive clinical evaluation.</s><s xml:id="_8YJ79s3">Any subtotals or total scores that have values as indicated in the orange box, indicate AI medical devices that merit extensive clinical evaluation before approval.</s><s xml:id="_339wdEr">Values falling within the range indicated in the green box will apply to AI medical devices that could be approved for market access after less extensive, appropriate evaluation.</s></p></div></figDesc><graphic coords="6,237.26,186.75,324.00,175.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 |</head><label>5</label><figDesc><div><p xml:id="_gGrm7eq"><s xml:id="_T4HEXHb">Fig. 5 | Schematic representation of major bodies involved in producing guidance relevant to the EU for approving AI medical device software.</s><s xml:id="_k8Xw5pd">In the European Union (EU), the European Commission is responsible for proposing legislation; its Directorate General for Health and Food Safety (DG SANTE) is responsible for the harmonised implementation of the Medical Device Regulation (MDR) and the In Vitro Diagnostic Medical Device Regulation (IVDR) in consultation with member states at the Medical Device Coordination Group (MDCG).</s><s xml:id="_wDnYbGe">The MDR authorises the MDCG to develop device standards, common specifications, and product-specific guidance.</s><s xml:id="_mwVu5vx">Its working groups on Clinical Investigation and Evaluation (CIE) and New Technologies (NT) share interests in the clinical evaluation of medical device software and AI/ML-enabled medical devices.</s><s xml:id="_FEfqEwW">The AI Office established within DG CNECT (Communications Networks, Content and Technology) will manage the implementation of the AI Act, with member states at the AI Board and with advice from both a Scientific Panel and an Advisory Forum.</s><s xml:id="_hNKG6au">The AI Act provides authority for the production of codes of practice, guidance documents, and specifications, within particular fields.</s><s xml:id="_cWKKeCW">Member states of the EU -independently from their device regulatorsare members of the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC), through their national standards bodies.</s><s xml:id="_HrmunG5">The ISO and IEC have a joint technical committee (JTC 1) on Information Technology; its sub-committee (SC) 42 has the responsibility to prepare guidance on Artificial Intelligence.</s><s xml:id="_AgMaCFb">ISO/IEC standards may be harmonised with EU legislation by their European counterpart organisations CEN (the European Committee for Standardization) and CENELEC (the European Electrotechnical Committee for Standardization), on request from the European Commission.</s><s xml:id="_sxGv8WS">The EU is a member of the International Medical Device Regulators Forum (IMDRF) where it collaborates with other regulatory jurisdictions to prepare joint recommendations.</s><s xml:id="_Xt3QtjC">The IMDRF has established working groups for Software as a Medical Device (SaMD) and for AI and ML.</s><s xml:id="_WndWA8r">Finally, within the World Health Organization (WHO), which has official observer status at the IMDRF, there is a unit concerned with the regulation and safety of medical devices; it collaborates with the International Telecommunication Union (ITU) in a Global Initiative on AI for Health (GI-AI4H) that has also produced guidance on regulatory standards.</s></p></div></figDesc><graphic coords="8,138.44,49.72,324.00,216.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="7,90.48,49.72,419.98,301.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 |</head><label>1</label><figDesc><div><p xml:id="_kAabH4h"><s xml:id="_WvSPM2z">Components of the CORE-MD AI Risk Score</s></p></div></figDesc><table><row><cell>Criterion and explanation</cell></row></table><note xml:id="_X9WFfhP"><p><s xml:id="_nfAqv7k">MDSW medical device software.</s><s xml:id="_8mTQDK5">The definitions of 'valid clinical association' and 'valid technical performance' were adapted with minor modifications from the IMDRF guidance on Software as a Medical Device (SaMD): Clinical Evaluation (2017).</s><s xml:id="_m4Srjsm">[IMDRF/SaMD WG/N41FINAL:2017] 57 , and from MDCG 2020-1: Guidance on Clinical Evaluation (MDR) [‥] of Medical Device Software 7 .</s><s xml:id="_3QreY9A">Definitions of the criteria in the clinical performance score were derived from the IMDRF guidance on Software as a Medical Device (SaMD): Clinical Evaluation (2017).</s><s xml:id="_3pNV2q4">[IMDRF/SaMD WG/N41FINAL:2017].</s><s xml:id="_8QtUqTb">https://doi.org/10.1038/s41746-025-01459-8</s></p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_GyzUBxr"><s xml:id="_wRmXVY7">https://doi.org/10.1038/s41746-025-01459-8</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_mkjEUEt"><s xml:id="_NeRVRFb">npj Digital Medicine | (2025) 8:90</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_8DDNyU3"><s xml:id="_7XQ7eGr">© The Author(s) 2025 https://doi.org/10.1038/s41746-025-01459-8</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_wJD3aSx">Acknowledgements</head><p xml:id="_6crNnWh"><s xml:id="_FZb3MdM">The <rs type="projectName">CORE-MD</rs> project received funding from the <rs type="funder">European Union</rs> <rs type="programName">Horizon 2020 Research and Innovation programme, for a Coordination &amp; Support Action</rs>, under grant agreement No. <rs type="grantNumber">945260</rs>.</s><s xml:id="_XGTUs23">We thank all the colleagues who took part in the Delphi project and consultations.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_eaVMVTR">
					<idno type="grant-number">945260</idno>
					<orgName type="project" subtype="full">CORE-MD</orgName>
					<orgName type="program" subtype="full">Horizon 2020 Research and Innovation programme, for a Coordination &amp; Support Action</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_u3acgcR">Author contributions</head><p xml:id="_3Rb76cu"><s xml:id="_5upKbs2">F.R. co-designed the AI MDSW work package in the CORE-MD programme; led the online and on-site meetings; drafted and revised the deliverables and publications output of the work package, including this manuscript.</s><s xml:id="_SnGGU75">E.B. contributed legal expertise to the work package discussions; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_k4htc9s">N.B. contributed to the discussions leading to this manuscript; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_z4XA638">E.C. contributed to the concepts and deliverables of the work package; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_eb46Dut">R.D. contributed to the concepts and deliverables of the work package; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_evzu35a">S.G. contributed to the concepts and deliverables of the work package; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_meA3ghv">E.K. contributed legal expertise to the work package discussions; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_CM89mrt">G.M. contributed to the concepts and deliverables of the work package; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_XaWQBbC">G.O. contributed to the concepts and deliverables of the work package; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_xuHphxT">J.B.R. organised the Delphi-like procedure reported in this manuscript; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_xJpbU8f">B.V. contributed to the concepts and deliverables of the work package; drafted and revised parts of the text outputs of the work package, including this manuscript.</s><s xml:id="_Q4VXuMw">A.G.F.</s><s xml:id="_TukWUdD">led the CORE-MD consortium; obtained the EU funding; co-designed the AI MDSW work package in the CORE-MD programme; drafted and revised the deliverables and publications of the work package, including this manuscript.</s><s xml:id="_Ebjfd5u">All authors have read the paper, approved the submission of the paper and agreed to be responsible for their own contribution and subscribe to the ethics guidelines to ensure compliance with the accuracy and integrity of the work.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_FgbV78B">Competing interests</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mzfm9Mr">Additional information</head><p xml:id="_gZYJm2N"><s xml:id="_yAP2hcY">Supplementary information The online version contains supplementary material available at <ref type="url" target="https://doi.org/10.1038/s41746-025-01459-8">https://doi.org/10.1038/s41746-025-01459-8</ref>.</s></p><p xml:id="_9hdjnhu"><s xml:id="_GYp9EXX">Correspondence and requests for materials should be addressed to Frank E. Rademakers.</s></p><p xml:id="_WTaPNZ9"><s xml:id="_Fseb89G">Reprints and permissions information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/reprints</ref></s><s xml:id="_hMRNuaN">Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p><p xml:id="_XEMPQnh"><s xml:id="_RCBhmtH">Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material.</s><s xml:id="_47CZhJa">You do not have permission under this licence to share adapted material derived from this article or parts of it.</s><s xml:id="_ApxGKe7">The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material.</s><s xml:id="_eY5cZAg">If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</s><s xml:id="_aVJUPa8">To view a copy of this licence, visit <ref type="url" target="http://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by- nc-nd/4.0/</ref>.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_jQubcpV">AI in health and medicine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nPaV83e">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="31" to="38" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rajpurkar, P., Chen, E., Banerjee, O. &amp; Topol, E. J. AI in health and medicine. Nat. Med. 28, 31-38 (2022).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_NPECX6e">Where medical statistics meets artificial intelligence</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Holmes</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejmra2212850</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fm2vgMd">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="page" from="1211" to="1219" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hunter, D. J. &amp; Holmes, C. Where medical statistics meets artificial intelligence. N. Engl. J. Med. 389, 1211-1219 (2023).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<idno type="DOI">10.1787/8e65efc1-en</idno>
		<ptr target="https://www.who.int/publications/i/item/9789240078871" />
		<title level="m" xml:id="_d4VqBEK">Regulatory considerations on artificial intelligence for health</title>
		<imprint>
			<publisher>World Health Organization</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">World Health Organization. Regulatory considerations on artificial intelligence for health. https://www.who.int/publications/i/item/ 9789240078871 (2023).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_F2MVc9a">Application of artificial intelligence in medical technologies: a systematic review of main trends</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">V</forename><surname>Bitkina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1177/20552076231189331</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8TZK6fN">Digit. Health</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">20552076231189331</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bitkina, O. V., Park, J. &amp; Kim, H. K. Application of artificial intelligence in medical technologies: a systematic review of main trends. Digit. Health 9, 20552076231189331 (2023).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_FjdCkF2">Application of artificial intelligence in the health care safety context: opportunities and challenges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ellahham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ellahham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C E</forename><surname>Simsekler</surname></persName>
		</author>
		<idno type="DOI">10.1177/1062860619878515</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DqJ5bTx">Am. J. Med. Qual</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="341" to="348" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ellahham, S., Ellahham, N. &amp; Simsekler, M. C. E. Application of artificial intelligence in the health care safety context: opportunities and challenges. Am. J. Med. Qual. 35, 341-348 (2020).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_8dbxn5G">Artificial intelligence in medical device software and high-risk medical devicesa review of definitions, expert recommendations and regulatory initiatives</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Fraser</surname></persName>
		</author>
		<idno type="DOI">10.1080/17434440.2023.2184685</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FvFau7h">Expert Rev. Med. Devices</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="467" to="491" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fraser, A. G. et al. Artificial intelligence in medical device software and high-risk medical devices -a review of definitions, expert recommendations and regulatory initiatives. Expert Rev. Med. Devices 20, 467-491 (2023).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<idno type="DOI">10.1016/b978-0-443-22063-0.00017-1</idno>
		<ptr target="https://health.ec.europa.eu/system/files/2020-09/md_mdcg_2020_1_guidance_clinic_eva_md_software_en_0.pdf" />
		<title level="m" xml:id="_FhUtYCp">Medical Devices Coordination Group Document MDCG 2020-1. Guidance on Clinical Evaluation (MDR) / Performance Evaluation (IVDR) of Medical Device Software</title>
		<imprint>
			<publisher>European Commission</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">European Commission. Medical Devices Coordination Group Document MDCG 2020-1. Guidance on Clinical Evaluation (MDR) / Performance Evaluation (IVDR) of Medical Device Software. https:// health.ec.europa.eu/system/files/2020-09/md_mdcg_2020_1_ guidance_clinic_eva_md_software_en_0.pdf (2020).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_H49Fdzz">Improved clinical investigation and evaluation of high-risk medical devices: the rationale and objectives of CORE-MD (Coordinating Research and Evidence for Medical Devices)</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Fraser</surname></persName>
		</author>
		<idno type="DOI">10.1302/2058-5241.6.210081</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7t6MCHm">Eur. Heart J. Qual. Care Clin. Outcomes</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="249" to="258" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fraser, A. G. et al. Improved clinical investigation and evaluation of high-risk medical devices: the rationale and objectives of CORE-MD (Coordinating Research and Evidence for Medical Devices). Eur. Heart J. Qual. Care Clin. Outcomes 8, 249-258 (2022).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_cqGaNQs">Data quality requirements for inclusive, non-biased and trustworthy AI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Balahur-Dobrescu</surname></persName>
		</author>
		<idno type="DOI">10.2760/365479</idno>
		<ptr target="131097" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_g6qFq3H">JRC</title>
		<meeting><address><addrLine>Luxembourg</addrLine></address></meeting>
		<imprint>
			<publisher>Publications Office of the European Union</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Balahur-Dobrescu, A. et al. Data quality requirements for inclusive, non-biased and trustworthy AI. https://doi.org/10.2760/365479, JRC131097 (Publications Office of the European Union, Luxembourg, 2022).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_UUkzdJb">Evidence based medicine: what it is and what it isn&apos;t</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Sackett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Haynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rbQjp7h">BMJ</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="page" from="71" to="72" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sackett, D. L., Rosenberg, W. M., Gray, J. A., Haynes, R. B. &amp; Richardson, W. S. Evidence based medicine: what it is and what it isn&apos;t. BMJ 312, 71-72 (1996).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_8AQaHxY">Standardization as a mechanism to improve safety in health care</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Rozich</surname></persName>
		</author>
		<idno type="DOI">10.1016/s1549-3741(04)30001-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PJ9ucVk">Jt. Comm. J. Qual. Saf</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5" to="14" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rozich, J. D. et al. Standardization as a mechanism to improve safety in health care. Jt. Comm. J. Qual. Saf. 30, 5-14 (2004).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sibony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Sunstein</surname></persName>
		</author>
		<title level="m" xml:id="_CKzHFzv">Noise: a Flaw in Human Judgment</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Brown Spark</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kahneman, D., Sibony, O. &amp; Sunstein, C. R. Noise: a Flaw in Human Judgment (Little, Brown Spark, New York, 2021).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_bZaCYEA">Teaming with a synthetic teammate: insights into human-autonomy teaming</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mcneese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Cooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">10.1177/0018720817743223</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wczGDjs">Hum. Factors</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="262" to="273" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McNeese, N. J., Demir, M., Cooke, N. J. &amp; Myers, C. Teaming with a synthetic teammate: insights into human-autonomy teaming. Hum. Factors 60, 262-273 (2018).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_Jbw7DbW">Through a glass, darkly: artificial intelligence and the problem of opacity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chesterman</surname></persName>
		</author>
		<idno type="DOI">10.1093/ajcl/avab012</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8WRThJ9">Am. J. Comp. Law</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="271" to="294" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chesterman, S. Through a glass, darkly: artificial intelligence and the problem of opacity. Am. J. Comp. Law 69, 271-294 (2021).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main" xml:id="_NZux22J">Towards a rigorous science of interpretable machine learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-98131-4_1</idno>
		<ptr target="http://arxiv.org/abs/1702.08608" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
	<note type="raw_reference">Doshi-Velez, F. &amp; Kim, B. Towards a rigorous science of interpretable machine learning. Preprint at http://arxiv.org/abs/1702.08608 (2017).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_DUhgYzM">The false hope of current approaches to explainable artificial intelligence in health care</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Oakden-Rayner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DJNCPDd">Lancet Digit. Health</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="745" to="e750" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ghassemi, M., Oakden-Rayner, L. &amp; Beam, A. L. The false hope of current approaches to explainable artificial intelligence in health care. Lancet Digit. Health 3, e745-e750 (2021).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_7D6xmV9">Big data and black-box medical algorithms</title>
		<author>
			<persName><forename type="first">W</forename><surname>Nicholson Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_8AAmPHP">Sci. Transl. Med</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">5333</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Nicholson Price, W. Big data and black-box medical algorithms. Sci. Transl. Med. 10, eaao5333 (2018).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_xj2VrZG">Expert-level diagnosis of nonpigmented skin cancer by combined convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamadermatol.2018.4378</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tbprWBg">JAMA Dermatol</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="58" to="65" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tschandl, P. et al. Expert-level diagnosis of nonpigmented skin cancer by combined convolutional neural networks. JAMA Dermatol. 155, 58-65 (2019).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_B62p65A">Risk of bias and error from data sets used for dermatologic artificial intelligence</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ravFvmW">JAMA Dermatol</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="page" from="1271" to="1273" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tschandl, P. Risk of bias and error from data sets used for dermatologic artificial intelligence. JAMA Dermatol. 157, 1271-1273 (2021).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_KEFrHMU">Do as AI say: susceptibility in deployment of clinical decision-aids</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gaube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2AZPg2V">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gaube, S. et al. Do as AI say: susceptibility in deployment of clinical decision-aids. NPJ Digit. Med. 4, 31 (2021).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_9SUDDbM">Human-computer collaboration for skin cancer recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-020-0942-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NQB4hUb">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1229" to="1234" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Tschandl, P. et al. Human-computer collaboration for skin cancer recognition. Nat. Med. 26, 1229-1234 (2020).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main" xml:id="_44G99EY">Combining Human Expertise with Artificial Intelligence: Experimental Evidence from Radiology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salz</surname></persName>
		</author>
		<idno type="DOI">10.3386/w31422</idno>
		<ptr target="https://doi.org/10.3386/w31422" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>National Bureau of Economic Research</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Working paper 31422</note>
	<note type="raw_reference">Agarwal, N., Moehring, A., Rajpurkar, P. &amp; Salz, T. Combining Human Expertise with Artificial Intelligence: Experimental Evidence from Radiology. Working paper 31422 https://doi.org/10.3386/w31422 (National Bureau of Economic Research, 2023).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_xk5DQYt">Heterogeneity and predictors of the effects of AI assistance on radiologists</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-024-02850-w</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6ZCwH36">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="837" to="849" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yu, F. et al. Heterogeneity and predictors of the effects of AI assistance on radiologists. Nat. Med. 30, 837-849 (2024).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_84BfmZd">Association of clinician diagnostic performance with machine learning-based decision support systems: A systematic review</title>
		<author>
			<persName><forename type="first">B</forename><surname>Vasey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_362ANEm">JAMA Netw. Open</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">211276</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vasey, B. et al. Association of clinician diagnostic performance with machine learning-based decision support systems: A systematic review. JAMA Netw. Open 4, e211276 (2021).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_R7FYe2P">Human-centered artificial intelligence: reliable, safe &amp; trustworthy</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gD9Tyyy">Int. J. Hum. Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="495" to="504" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shneiderman, B. Human-centered artificial intelligence: reliable, safe &amp; trustworthy. Int. J. Hum. Comput. Interact. 36, 495-504 (2020).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_G5wKvDQ">Proceedings of the NHLBI workshop on artificial intelligence in cardiovascular imaging: translation patient care</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kgWdyMd">JACC Cardiovasc. Imaging</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1209" to="1223" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dey, D. et al. Proceedings of the NHLBI workshop on artificial intelligence in cardiovascular imaging: translation patient care. JACC Cardiovasc. Imaging 16, 1209-1223 (2023).</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_sPg5qXv">Algorithm change protocols in the regulation of adaptive machine learning-based medical devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7zPVpfC">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">30545</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gilbert, S. et al. Algorithm change protocols in the regulation of adaptive machine learning-based medical devices. J. Med. Internet Res. 23, e30545 (2021).</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_8Sy9gtD">The last mile: where artificial intelligence meets reality</title>
		<author>
			<persName><forename type="first">E</forename><surname>Coiera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uEgaASr">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">16323</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Coiera, E. The last mile: where artificial intelligence meets reality. J. Med. Internet Res. 21, e16323 (2019).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_w89SvqT">How machine learning is embedded to support clinician decision making: an analysis of FDA-approved medical devices</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lyell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Coier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Magrabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WAYKE9q">BMJ Health Care Inform</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">100301</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lyell, D., Coier, A. E., Chen, J., Shah, P. &amp; Magrabi, F. How machine learning is embedded to support clinician decision making: an analysis of FDA-approved medical devices. BMJ Health Care Inform. 28, e100301 (2021).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main" xml:id="_HJWQv3P">Regulatory guidelines for software medical devices -A lifecycle approach</title>
		<idno type="DOI">10.1017/9781009091725.013</idno>
		<ptr target=")-pub.pdf" />
		<imprint>
			<date type="published" when="2022-04">2022-apr. 2022</date>
		</imprint>
		<respStmt>
			<orgName>Health Sciences Authority (Singapore</orgName>
		</respStmt>
	</monogr>
	<note>Revision 2.0</note>
	<note type="raw_reference">Health Sciences Authority (Singapore). Regulatory guidelines for software medical devices -A lifecycle approach. Revision 2.0 https:// www.hsa.gov.sg/docs/default-source/hprg-mdb/guidance- documents-for-medical-devices/regulatory-guidelines-for-software- medical-devices---a-life-cycle-approach_r2-(2022-apr)-pub.pdf (2022).</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_sJBYgeS">Moving towards vertically integrated artificial intelligence development</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-022-00690-x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_73wpjjS">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">143</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhang, J. et al. Moving towards vertically integrated artificial intelligence development. NPJ Digit. Med. 5, 143 (2022).</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_4BN5f7R">The need for a system view to regulate artificial intelligence/machine learning-based software as medical device</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Babic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rma9Rpr">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">53</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gerke, S., Babic, B., Evgeniou, T. &amp; Cohen, I. G. The need for a system view to regulate artificial intelligence/machine learning-based software as medical device. NPJ Digit. Med. 3, 53 (2020).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main" xml:id="_5JnE2hw">Artificial Intelligence, Governance and Ethics: Global Perspectives</title>
		<author>
			<persName><forename type="first">A</forename><surname>Daly</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.3414805</idno>
		<idno>Paper No. 2019/033</idno>
		<ptr target="https://doi.org/10.2139/ssrn.3414805" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>University of Hong Kong Faculty of Law Research</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Daly, A. et al. Artificial Intelligence, Governance and Ethics: Global Perspectives. Paper No. 2019/033. https://doi.org/10.2139/ssrn. 3414805 (Chinese University of Hong Kong Faculty of Law Research, 2019).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Biasin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brešić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kamenjašević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Notermans</surname></persName>
		</author>
		<ptr target="https://www.safecare-project.eu/wp-content/uploads/2020/02/Analysis-of-Ethics-Privacy-and-Confidentiality-Restraints.pdf" />
		<title level="m" xml:id="_Q7mMpwm">Analysis of ethics, privacy, and confidentiality constraints</title>
		<imprint>
			<publisher>KUL</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>SAFECARE project deliverable 3.9 Lead Author</note>
	<note type="raw_reference">Biasin, E., Brešić, D., Kamenjašević, E. &amp; Notermans, P. Analysis of ethics, privacy, and confidentiality constraints. SAFECARE project deliverable 3.9. Lead Author: KUL. https://www.safecare-project.eu/ wp-content/uploads/2020/02/Analysis-of-Ethics-Privacy-and- Confidentiality-Restraints.pdf (2018).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_GbwZqzu">An ethics framework for a learning health care system: a departure from traditional research ethics and clinical ethics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Faden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZrBcByr">Hastings Cent. Rep</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="16" to="27" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Faden, R. R. et al. An ethics framework for a learning health care system: a departure from traditional research ethics and clinical ethics. Hastings Cent. Rep. 43, Spec No:S16-27 (2013).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<ptr target="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai" />
		<title level="m" xml:id="_pEbsARp">High-Level Expert Group on Artificial Intelligence set up by the European Commission. Ethics guidelines for trustworthy AI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">High-Level Expert Group on Artificial Intelligence set up by the European Commission. Ethics guidelines for trustworthy AI. https:// digital-strategy.ec.europa.eu/en/library/ethics-guidelines- trustworthy-ai (2019).</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_EQ38FVH">Regulate artificial intelligence in health care by prioritizing patient outcomes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2JT9TkV">JAMA</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="page" from="639" to="640" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ayers, J. W., Desai, N. &amp; Smith, D. M. Regulate artificial intelligence in health care by prioritizing patient outcomes. JAMA 331, 639-640 (2024).</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<ptr target="https://www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf-playbook" />
		<title level="m" xml:id="_2VqANuV">AI Risk Management Framework Playbook-MAP</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">NIST. AI Risk Management Framework Playbook-MAP https://www. nist.gov/itl/ai-risk-management-framework/nist-ai-rmf-playbook (2023).</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<idno type="DOI">10.6028/nist.ai.100-1.jpn</idno>
		<ptr target="https://www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf-playbook" />
		<title level="m" xml:id="_xhKekDX">AI Risk Management Framework Playbook-MEASURE</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">NIST. AI Risk Management Framework Playbook-MEASURE https:// www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf- playbook (2023).</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<idno type="DOI">10.6028/nist.ai.100-1.jpn</idno>
		<ptr target="https://www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf-playbook" />
		<title level="m" xml:id="_GaaMu4F">AI Risk Management Framework Playbook-MANAGE</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">NIST. AI Risk Management Framework Playbook-MANAGE https:// www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf- playbook (2023).</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<idno type="DOI">10.6028/nist.ai.100-1.jpn</idno>
		<ptr target="https://www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf-playbook" />
		<title level="m" xml:id="_Ef9VwB2">AI Risk Management Framework Playbook-GOVERN</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">NIST. AI Risk Management Framework Playbook-GOVERN https:// www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf- playbook (2023).</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<idno type="DOI">10.6028/nist.sp.1314</idno>
		<ptr target="https://nist.gov/rmf" />
		<title level="m" xml:id="_ZHs8V2A">Risk Management Framework Quick Start Guide. Roles and Responsibilities Crosswalk</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">NIST. Risk Management Framework Quick Start Guide. Roles and Responsibilities Crosswalk https://nist.gov/rmf (2021).</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<idno type="DOI">10.6028/nist.cswp.40.ipd</idno>
		<ptr target="https://www.nist.gov/privacy-framework" />
		<title level="m" xml:id="_Nf5M567">Privacy Framework Core</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">NIST. Privacy Framework Core https://www.nist.gov/privacy- framework (2020).</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Bernal-Delgado</surname></persName>
		</author>
		<idno type="DOI">10.3030/101131118</idno>
		<ptr target="https://tehdas.eu/app/uploads/2023/03/tehdas-report-on-architecture-and-infrastructure-options-to-support-ehds-services.pdf" />
		<title level="m" xml:id="_kWttvWg">Report on architecture and infrastructure options to support EHDS services for secondary use of data</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bernal-Delgado, E. et al. Report on architecture and infrastructure options to support EHDS services for secondary use of data. https:// tehdas.eu/app/uploads/2023/03/tehdas-report-on-architecture- and-infrastructure-options-to-support-ehds-services.pdf (2023).</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_QJjk88e">Trading on the unknown: scenarios for the future value of data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Newlands</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fieseler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FbVBAgA">Law Ethics Hum. Rights</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="97" to="114" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Newlands, G., Lutz, C. &amp; Fieseler, C. Trading on the unknown: scenarios for the future value of data. Law Ethics Hum. Rights 13, 97-114 (2019).</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_f3fJppZ">Towards a paradigm shift in governing data access and related intellectual property rights in big data and health-related research</title>
		<author>
			<persName><forename type="first">P</forename><surname>Andanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dYDAd38">IIC Int. Rev. Intellect. Prop. Compet. Law</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1052" to="1081" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Andanda, P. Towards a paradigm shift in governing data access and related intellectual property rights in big data and health-related research. IIC Int. Rev. Intellect. Prop. Compet. Law 50, 1052-1081 (2019).</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_66PSppP">Negotiating the reuse of health-data: Research, Big Data, and the European General Data Protection Regulation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Starkbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Felt</surname></persName>
		</author>
		<idno type="DOI">10.1177/2053951719862594</idno>
		<ptr target="https://doi.org/10.1177/2053951719862594" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_YAX2wje">Big Data Soc</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Starkbaum, J. &amp; Felt, U. Negotiating the reuse of health-data: Research, Big Data, and the European General Data Protection Regulation. Big Data Soc. https://doi.org/10.1177/ 2053951719862594 (2019).</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_MnkrqNn">Coverage for emerging technologiesbridging regulatory approval and patient access</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Kadakia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Yeh</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-025-01459-8</idno>
		<ptr target="https://doi.org/10.1038/s41746-025-01459-8" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_R5m6Rkb">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">389</biblScope>
			<biblScope unit="page" from="2021" to="2024" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kadakia, K. T., Kramer, D. B. &amp; Yeh, R. W. Coverage for emerging technologies -bridging regulatory approval and patient access. N. Engl. J. Med. 389, 2021-2024 (2023). https://doi.org/10.1038/s41746-025-01459-8</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_PpXPbuw">Holistic human-serving digitization of health care needs integrated automated system-level assessment tools</title>
		<author>
			<persName><forename type="first">C</forename><surname>Welzel</surname></persName>
		</author>
		<idno type="DOI">10.2196/50158</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_fwEr2SD">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">50158</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Welzel, C. et al. Holistic human-serving digitization of health care needs integrated automated system-level assessment tools. J. Med. Internet Res. 25, e50158 (2023).</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_rUXx6sf">Algorithmovigilance, lessons from pharmacovigilance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Balendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Benchoufi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ravaud</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-024-01237-y</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xbMy3EH">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">270</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Balendran, A., Benchoufi, M., Evgeniou, T. &amp; Ravaud, P. Algorithmovigilance, lessons from pharmacovigilance. NPJ Digit. Med. 7, 270 (2024).</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_2fEutDz">Guidelines on the qualification and classification of stand alone software used in healthcare within the regulatory framework of medical devices</title>
		<idno type="DOI">10.1016/b978-0-12-804179-6.00003-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SMPh5rV">Medical Devices Guidance Document MEDDEV</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2016">2016. 2016</date>
			<publisher>European Commission</publisher>
		</imprint>
	</monogr>
	<note>European Commission. Guidelines on the qualification and classification of stand alone software used in healthcare within the regulatory framework of medical devices Medical Devices Guidance Document MEDDEV 2.1/6</note>
	<note type="raw_reference">European Commission. Guidelines on the qualification and classification of stand alone software used in healthcare within the regulatory framework of medical devices. Medical Devices Guidance Document MEDDEV 2.1/6 (2016)European Commission. Guidelines on the qualification and classification of stand alone software used in healthcare within the regulatory framework of medical devices. Medical Devices Guidance Document MEDDEV 2.1/6 (2016).</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_yQmj6gx">Survey on deep learning with class imbalance</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_M3WPCr5">J. Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson, J. M. &amp; Khoshgoftaar, T. M. Survey on deep learning with class imbalance. J. Big Data 6, 27 (2019).</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_gMYQ2Dw">Class imbalance on medical image classification: towards better evaluation practices for discrimination and calibration performance</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mosquera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Milone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00330-024-10834-0</idno>
		<ptr target="https://doi.org/10.1007/s00330-024-10834-0" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_fbN6QYg">Eur. Radiol</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mosquera, C., Ferrer, L., Milone, D. H., Luna, D. &amp; Ferrante, E. Class imbalance on medical image classification: towards better evaluation practices for discrimination and calibration performance. Eur. Radiol. https://doi.org/10.1007/s00330-024-10834-0 (2024).</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_tWaGxea">Shortcut learning in deep neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Geirhos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KvgSe2R">Nat. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="665" to="673" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Geirhos, R. et al. Shortcut learning in deep neural networks. Nat. Mach. Intell. 2, 665-673 (2020).</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_QG2qe3C">Key challenges for delivering clinical impact with artificial intelligence</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karthikesalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pEpryD4">BMC Med</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">195</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kelly, C. J., Karthikesalingam, A., Suleyman, M., Corrado, G. &amp; King, D. Key challenges for delivering clinical impact with artificial intelligence. BMC Med. 17, 195 (2019).</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_UD22f8k">Dissecting racial bias in an algorithm used to manage the health of populations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vogeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wbUZnwZ">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="page" from="447" to="453" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Obermeyer, Z., Powers, B., Vogeli, C. &amp; Mullainathan, S. Dissecting racial bias in an algorithm used to manage the health of populations. Science 366, 447-453 (2019).</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_jeSAwuJ">Software as a Medical Device Working Group. Software as a Medical Device (SaMD): Clinical Evaluation</title>
		<idno>WG/N41FINAL:2017</idno>
		<ptr target="https://www.imdrf.org/sites/default/files/docs/imdrf/final/technical/imdrf-tech-170921-samd-n41-clinical-evaluation_1.pdf" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_tYy24MB">IMDRF/SaMD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>International Medical Device Regulators Forum</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">International Medical Device Regulators Forum. Software as a Medical Device Working Group. Software as a Medical Device (SaMD): Clinical Evaluation. IMDRF/SaMD WG/N41FINAL:2017. https://www.imdrf.org/sites/default/files/docs/imdrf/final/technical/ imdrf-tech-170921-samd-n41-clinical-evaluation_1.pdf (2017).</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" xml:id="_4V67TeF">IMDRF/SaMD WG/ N23 FINAL: 2015 -Software as a Medical Device (SaMD): Application of Quality Management System</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>International Medical Device Regulators Forum</note>
	<note type="raw_reference">International Medical Device Regulators Forum. IMDRF/SaMD WG/ N23 FINAL: 2015 -Software as a Medical Device (SaMD): Application of Quality Management System. (2015).</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main" xml:id="_7jtbaGu">Machine Learningenabled medical devices-a subset of artificial intelligence-enabled medical devices: key terms and definitions</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>IMDRF AIMD Working Group</publisher>
		</imprint>
		<respStmt>
			<orgName>International Medical Device Regulators Forum</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">International Medical Device Regulators Forum. Machine Learning- enabled medical devices-a subset of artificial intelligence-enabled medical devices: key terms and definitions. IMDRF AIMD Working Group. (2021).</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<ptr target="https://www.fda.gov/media/153486/download" />
		<title level="m" xml:id="_qrZTWgC">Good machine learning practice for medical device development: guiding principles</title>
		<imprint>
			<publisher>US Food and Drug Adminstration, Health Canada, and the Medicines &amp; Healthcare Products Regulatory Authority</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">US Food and Drug Adminstration, Health Canada, and the Medicines &amp; Healthcare Products Regulatory Authority. Good machine learning practice for medical device development: guiding principles. https:// www.fda.gov/media/153486/download (2021).</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_pqjag8a">IDEAL as a guide to designing clinical device studies consistent with the new European medical device regulation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fleetcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XeYRwpK">BMJ Surg. Interv. Health Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">66</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fleetcroft, C., McCulloch, P. &amp; Campbell, B. IDEAL as a guide to designing clinical device studies consistent with the new European medical device regulation. BMJ Surg. Interv. Health Technol. 3, e000066 (2021).</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_ReRwC2F">FDA perspective on the regulation of artificial intelligence in health care and biomedicine</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Warraich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tazbaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Califf</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2024.21451</idno>
		<ptr target="https://doi.org/10.1001/jama.2024.21451" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_dPraGJ2">JAMA</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Warraich, H. J., Tazbaz, T. &amp; Califf, R. M. FDA perspective on the regulation of artificial intelligence in health care and biomedicine. JAMA https://doi.org/10.1001/jama.2024.21451 (2024).</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<orgName type="collaboration">FDA</orgName>
		</author>
		<ptr target="https://www.fda.gov/files/medical%20devices/published/USFDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper.pdf" />
		<title level="m" xml:id="_7gTMFx7">Proposed regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD)-discussion paper and request for feedback</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">FDA. Proposed regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD)-discussion paper and request for feedback https:// www.fda.gov/files/medical%20devices/published/USFDA-Artificial- Intelligence-and-Machine-Learning-Discussion-Paper.pdf (2024).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
