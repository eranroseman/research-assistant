<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_xDeSGxs"></title>
				<funder>
					<orgName type="full">George J. Stigler Center for the Study of the Economy and the State</orgName>
				</funder>
				<funder>
					<orgName type="full">James S. Kemper Foundation Faculty Research Fund</orgName>
				</funder>
				<funder>
					<orgName type="full">Neubauer Family Foundation</orgName>
					<orgName type="abbreviated">NFF</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100019099</idno>
				</funder>
				<funder>
					<orgName type="full">Initiative on Global Markets</orgName>
				</funder>
				<funder>
					<orgName type="full">University of Chicago Booth School of Business</orgName>
				</funder>
				<funder>
					<orgName type="full">Centel Foundation/Robert P. Reuss Faculty Research Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">*</forename><surname>Kamenica</surname></persName>
							<email>emir.kamenica@chicagobooth.edu</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">University of Chicago Booth School of Business , 5807 South Woodlawn Avenue , Office 518 , Chicago , IL 60637</note>
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">University of Chicago Booth</orgName>
								<address>
									<addrLine>5807 South Woodlawn Avenue Office 518</addrLine>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Budish</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation">University of Chicago Booth School of Business , 5807 South Woodlawn Avenue , Office 514 , Chicago , IL 60637</note>
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">University of Chicago Booth</orgName>
								<address>
									<addrLine>5807 South Woodlawn Avenue Office 514</addrLine>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wouter</forename><surname>Dessein</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation">University of Chicago Booth School of Business , 5807 South Woodlawn Avenue , Office 514 , Chicago , IL 60637</note>
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">University of Chicago Booth</orgName>
								<address>
									<addrLine>5807 South Woodlawn Avenue Office 514</addrLine>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Navin</forename><surname>Kartik</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation">University of Chicago Booth School of Business , 5807 South Woodlawn Avenue , Office 514 , Chicago , IL 60637</note>
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">University of Chicago Booth</orgName>
								<address>
									<addrLine>5807 South Woodlawn Avenue Office 514</addrLine>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Canice</forename><surname>Prendergast</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation">University of Chicago Booth School of Business , 5807 South Woodlawn Avenue , Office 514 , Chicago , IL 60637</note>
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">University of Chicago Booth</orgName>
								<address>
									<addrLine>5807 South Woodlawn Avenue Office 514</addrLine>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maxwell</forename><surname>Stinchcombe</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation">University of Chicago Booth School of Business , 5807 South Woodlawn Avenue , Office 514 , Chicago , IL 60637</note>
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">University of Chicago Booth</orgName>
								<address>
									<addrLine>5807 South Woodlawn Avenue Office 514</addrLine>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lars</forename><surname>Stole</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation">University of Chicago Booth School of Business , 5807 South Woodlawn Avenue , Office 514 , Chicago , IL 60637</note>
								<orgName type="department">School of Business</orgName>
								<orgName type="institution">University of Chicago Booth</orgName>
								<address>
									<addrLine>5807 South Woodlawn Avenue Office 514</addrLine>
									<postCode>60637</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">24A3038CB72E7A5218ED795DEEB6F96C</idno>
					<idno type="DOI">10.1257/aer.101.6.2590</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T12:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_SSgf458"><p xml:id="_sASzRD9"><s xml:id="_JVYEGVC">Suppose one person, call him Sender, wishes to persuade another, call her Receiver, to change her action.</s><s xml:id="_nebtGWY">If Receiver is a rational Bayesian, can Sender persuade her to take an action he would prefer over the action she was originally going to take?</s><s xml:id="_UUN94Vp">If Receiver understands that Sender chose what information to convey with the intent of manipulating her action for his own benefit, can Sender still gain from persuasion?</s><s xml:id="_TpwcUxV">If so, what is the optimal way to persuade?</s></p><p xml:id="_kp3bVuu"><s xml:id="_KHntC48">These questions are of substantial economic importance.</s><s xml:id="_fub6vx3">As Donald McCloskey and Arjo Klamer (1995) emphasize, attempts at persuasion command a sizable share of our resources.</s><s xml:id="_Fr7pNy7">Persuasion, as we will define it below, plays an important role in advertising, courts, lobbying, financial disclosure, and political campaigns, among many other economic activities.</s></p><p xml:id="_QDMmGns"><s xml:id="_RCJs6jH">Consider the example of a prosecutor trying to convince a judge that a defendant is guilty.</s><s xml:id="_hNSWugY">When the defendant is indeed guilty, revealing the facts of the case will tend to help the prosecutor's case.</s><s xml:id="_n4E2CBg">When the defendant is innocent, revealing facts will tend to hurt the prosecutor's case.</s><s xml:id="_dFSVpxX">Can the prosecutor structure his arguments, selection of evidence, etc. so as to increase the probability of conviction by a rational judge on average?</s><s xml:id="_RPkGesy">Perhaps surprisingly, the answer to this question is yes.</s><s xml:id="_zpxnX55">Bayes's Law restricts the expectation of posterior beliefs but puts no other constraints on</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="504.0" lry="720.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mr6mknh">Bayesian Persuasion †</head><p xml:id="_Qm5B7C5"><s xml:id="_W7fUcsX">By Emir Kamenica and Matthew Gentzkow* When is it possible for one person to persuade another to change her action?</s><s xml:id="_2w2Urjz">We consider a symmetric information model where a sender chooses a signal to reveal to a receiver, who then takes a noncontractible action that affects the welfare of both players.</s><s xml:id="_pUKnYW4">We derive necessary and sufficient conditions for the existence of a signal that strictly benefits the sender.</s><s xml:id="_faJ4WFy">We characterize sender-optimal signals.</s><s xml:id="_VBs8uGq">We examine comparative statics with respect to the alignment of the sender's and the receiver's preferences.</s><s xml:id="_N7nsXd2">Finally, we apply our results to persuasion by litigators, lobbyists, and salespeople.</s><s xml:id="_cUYHX9d">(JEL D72, D82, D83, K40, M31) their distribution.</s><s xml:id="_rV6pZ4s">Therefore, so long as the judge's action is not linear in her beliefs, the prosecutor may benefit from persuasion.</s></p><p xml:id="_csPRWh5"><s xml:id="_arQH8Pa">To make this concrete, suppose the judge (Receiver) must choose one of two actions: to acquit or convict a defendant.</s><s xml:id="_dcpxNmS">There are two states of the world: the defendant is either guilty or innocent.</s><s xml:id="_mcMvBwr">The judge gets utility 1 for choosing the just action (convict when guilty and acquit when innocent) and utility 0 for choosing the unjust action (convict when innocent and acquit when guilty).</s><s xml:id="_ADuYv4h">The prosecutor (Sender) gets utility 1 if the judge convicts and utility 0 if the judge acquits, regardless of the state.</s><s xml:id="_29TDX82">The prosecutor and the judge share a prior belief Pr (guilty) = 0.3.</s></p><p xml:id="_6UFAA96"><s xml:id="_ZMKdQ3q">The prosecutor conducts an investigation and is required by law to report its full outcome.</s><s xml:id="_Yegn4Cg">We can think of the choice of the investigation as consisting of the decisions on whom to subpoena, what forensic tests to conduct, what questions to ask an expert witness, etc.</s><s xml:id="_d4SsMG4">We formalize an investigation as distributions π (⋅ | guilty) and π (⋅ | innocent) on some set of signal realizations.</s><s xml:id="_BjNvCFv">The prosecutor chooses π and must honestly report the signal realization to the judge.</s></p><p xml:id="_BWVZBr4"><s xml:id="_Yu87NsG">If there is no communication (or equivalently, if π is completely uninformative), the judge always acquits because guilt is less likely than innocence under her prior.</s><s xml:id="_Y8tEXT5">If the prosecutor chooses a fully informative investigation, one that leaves no uncertainty about the state, the judge convicts 30 percent of the time.</s><s xml:id="_5TKVVnd">The prosecutor can do better, however.</s><s xml:id="_2aJp5sn">As we show below, his uniquely optimal investigation is a binary signal:</s></p><formula xml:id="formula_0">(1) π (i | innocent) = 4 _ 7 π (i | guilty) = 0 π (g | innocent) = 3 _ 7 π (g | guilty) = 1.</formula><p xml:id="_Pe7WuaP"><s xml:id="_4D2XEKf">This leads the judge to convict with probability 60 percent.</s><s xml:id="_GVprUdT">Note that the judge knows 70 percent of defendants are innocent, yet she convicts 60 percent of them!</s><s xml:id="_nJXywpY">She does so even though she is fully aware that the investigation was designed to maximize the probability of conviction.</s></p><p xml:id="_dE7DydH"><s xml:id="_gzCXdQE">In this paper, we study the general problem of persuading a rational agent by controlling her informational environment.</s><s xml:id="_rMmQpbN">We consider a symmetric information setting with an arbitrary state space and action space, an arbitrary prior, and arbitrary state-dependent preferences for both Sender and Receiver.</s><s xml:id="_Wtr4gbz">Sender chooses an informative signal about the state of the world, Receiver observes a realization from this signal, and then she takes an action.</s><s xml:id="_RK8E5dZ">Throughout the analysis, we prohibit Sender from making transfers or affecting Receiver's payoffs in any way.</s><s xml:id="_GGPFQCn">We focus on two questions: (i) when does there exist a signal that strictly benefits <ref type="bibr">Sender, and (ii)</ref> what is an optimal signal from Sender's perspective?</s></p><p xml:id="_MCPmyf4"><s xml:id="_gYHwtnh">A key assumption of our model is that Sender cannot distort or conceal information once the signal realization is known.</s><s xml:id="_HzUesDH">This allows us to abstract from the incentive compatibility issues that are the focus of much of the previous literature on strategic communication.</s><s xml:id="_MPwK7RE">We discuss the precise meaning of this assumption and the settings where it is likely to apply when we introduce the general model below.</s></p><p xml:id="_7qhgA6c"><s xml:id="_nwfYrW6">We begin by establishing a result that simplifies our analysis.</s><s xml:id="_srffCUJ">We show that we can reexpress the problem of choosing an optimal signal as a search over distributions of posteriors subject to the constraint that the expected posterior is equal to the prior.</s><s xml:id="_zS8prTr">This reformulation of Sender's problem provides a useful geometric approach to deriving the optimal signal.</s></p><p xml:id="_vk4ckRd"><s xml:id="_qaqWHn5">When does there exist a signal that strictly benefits Sender?</s><s xml:id="_GUHBkYx">Consider why the prosecutor in the example benefits from the opportunity to provide information to the judge.</s><s xml:id="_fQfNJun">Since the judge is rational, providing information must sometimes make her more convinced and sometimes less convinced that the defendant is guilty.</s><s xml:id="_8Jd5Ay6">The former will strictly improve the prosecutor's payoff if the information is strong enough to induce conviction.</s><s xml:id="_5xPNEs7">The latter, however, will not reduce the prosecutor's payoff, since the judge already acquits the defendant by default.</s><s xml:id="_N7cufyw">The net effect is to increase the prosecutor's payoff in expectation.</s><s xml:id="_XNqbCu5">We show that in general Sender benefits from persuasion whenever (i) Receiver does not take Sender's preferred action by default (in a sense we make precise below) and (ii) Receiver's action is constant in some neighborhood of beliefs around the prior.</s><s xml:id="_Mu6Mm3V">When these conditions hold, Sender can benefit by sending a signal that induces a better action with positive probability and balances this with a worse belief that leaves Receiver's action unchanged.</s><s xml:id="_vXgBCPe">We also show that whether Sender benefits from persuasion depends in a natural way on the concavity or convexity of Sender's payoff as a function of Receiver's beliefs.</s></p><p xml:id="_mVth4RF"><s xml:id="_PmrKK4Y">We next turn to studying optimal signals.</s><s xml:id="_bvECDBj">We use tools from convex analysis to characterize the optimal signal for any given set of preferences and initial beliefs.</s><s xml:id="_6PZyfns">We show that no disclosure of information is optimal when Sender's payoff is concave in Receiver's beliefs, and full disclosure is optimal when Sender's payoff is convex in Receiver's beliefs.</s></p><p xml:id="_7xKx8Q6"><s xml:id="_BN8fVkY">We then generalize two important properties of the optimal signal in the example above.</s><s xml:id="_FtwcuUg">Notice, first, that when the judge chooses the prosecutor's least-preferred action (acquit), she is certain of the state.</s><s xml:id="_ZFa7xmW">That is, she never acquits guilty defendants.</s><s xml:id="_493wPtx">Otherwise, we would have π (i | guilty) &gt; 0. But then the prosecutor could increase his payoff by decreasing π (i | guilty) and increasing π (g | guilty) ; this would strictly increase the probability of g and would only increase the willingness of the judge to convict when she sees g.</s><s xml:id="_u9JDE35">We establish that, in general, whenever Receiver takes Sender's least-preferred action, she knows with certainty that the state is one where this action is uniquely optimal.</s></p><p xml:id="_tSJqT3T"><s xml:id="_qGA9XTt">Second, notice that when the judge convicts, she is exactly indifferent between convicting and acquitting.</s><s xml:id="_a8Cz64n">If she strictly preferred to convict upon seeing g, the prosecutor could increase his payoff by slightly decreasing π (i | innocent) and increasing π (g | innocent) ; this would increase the probability of g and leave the judge's optimal action given the message unchanged, thus increasing the probability of conviction.</s><s xml:id="_a5BPKkv">We show that, in general, whenever Receiver has an interior posterior, she is effectively indifferent between two actions.</s></p><p xml:id="_eUw2MBS"><s xml:id="_zUZx4js">We also examine how the extent of information transmission and Sender's gain from persuasion depend on the alignment of Sender's and Receiver's preferences.</s><s xml:id="_69uNyXm">In contrast to previous work on strategic communication, we find that making preferences more aligned can reduce the extent of communication in equilibrium.</s></p><p xml:id="_us3P3zG"><s xml:id="_4JdggK5">We next apply our results to two examples.</s><s xml:id="_nEFPNdZ">First, we examine the type of studies that a lobbying group might fund so as to influence a benevolent politician.</s><s xml:id="_CKf5zhB">Then, we analyze a seller's provision of free trials or other information to potential consumers.</s></p><p xml:id="_HAcadXu"><s xml:id="_K6xU47c">In the final section of the paper, we discuss extensions of our results to settings where Receiver has private information and where there are multiple receivers.</s></p><p xml:id="_BRpBrfn"><s xml:id="_ndZVp5E">The observation that Bayesian updating only restricts the expectation of posteriors has been made before and has been utilized in a variety of contexts.</s><s xml:id="_gqKmtte">The work most closely related to our paper is Robert J. <ref type="bibr" target="#b2">Aumann and Michael B. Maschler (1995)</ref> and Isabelle <ref type="bibr" target="#b4">Brocas and Juan D. Carrillo (2007)</ref>.</s><s xml:id="_f5f48WP"><ref type="bibr" target="#b2">Aumann and Maschler (1995)</ref> employ formal methods very similar to ours to analyze repeated games of incomplete information.</s><s xml:id="_Z8GCCSy">They study the value to a player of knowing which game is being played when the other player lacks this knowledge, a fixed zero-sum game is repeated ad infinitum, players maximize their long-run nondiscounted average payoffs, and payoffs are not observed.</s><s xml:id="_8eF5HjA">The fact that the informed player's initial actions have no impact on his long-run average payoffs (and can thus be treated as nothing but a signal) combined with a focus on Nash equilibria (which implicitly allow for commitment) makes Aumann and Maschler's problem mathematically analogous to ours.</s><s xml:id="_epWjkmX"><ref type="bibr" target="#b4">Brocas and Carrillo (2007)</ref> analyze the gain to Sender from controlling the flow of public information in a setting with a binary state space and information that consists of a sequence of symmetric binary signals.</s><s xml:id="_GDRWmcR">Our consideration of a more general environment allows us to provide new intuitions about when Sender benefits from persuasion and about the optimal informational environment from Sender's perspective.</s><s xml:id="_JPSsjvz">For example, we establish that whenever Receiver has finitely many actions and there is some information Sender would share, Sender benefits from persuasion.</s><s xml:id="_R2E6adw">Also, we derive several novel properties that beliefs induced by an optimal signal must satisfy.</s></p><p xml:id="_Bg3yWzv"><s xml:id="_SrUKXBT">This paper also relates to a broader literature on optimal information structures.</s><s xml:id="_cHzAXyg">Luis <ref type="bibr" target="#b25">Rayo and Ilya Segal (2010)</ref> characterize the optimal disclosure policy under specific assumptions about preferences and about Receiver's outside option.</s><s xml:id="_tv56nxW">Michael <ref type="bibr" target="#b24">Ostrovsky and Michael Schwarz (2010)</ref> examine the equilibrium design of grade transcripts and the resulting information about quality of students when schools compete to place their students in good jobs.</s><s xml:id="_B5WftFz">Johannes Hörner and Andrzej Skrzypacz (2005) demonstrate how sequential revelation of partially informative signals can increase payments to a Sender who is trying to sell his information to Receiver.</s><s xml:id="_JztdU8u">Finally, the results in our paper connect to several other strands of research, including work on optimal advertising, self-signalling, and contract theory.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_FdMNvBG">I. A Model of Persuasion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_b7ZrMsm">A. setup</head><p xml:id="_A4ktGM9"><s xml:id="_wDKjUtY">Receiver has a continuous utility function u (a, ω) that depends on her action a ∈ A and the state of the world ω ∈ Ω. Sender has a continuous utility function v (a, ω) that depends on Receiver's action and the state of the world.</s><s xml:id="_GYd2jrn">Sender and Receiver share a prior μ 0 ∈ int (Δ (Ω) ) . <ref type="foot" target="#foot_0">1</ref> The action space A is compact and the state space Ω is finite.</s><s xml:id="_XA8gVha">The latter assumption is mainly for ease of exposition.</s><s xml:id="_7W5kxAy">In the online Appendix, we show that our central characterization result extends to the case where Ω is any compact metric space.</s></p><p xml:id="_8HMx2pH"><s xml:id="_6V6SnAX">A signal π consists of a finite realization space s and a family of distributions {π (⋅ | ω) } ω∈Ω over s.</s><s xml:id="_yaB3EHG">Sender chooses a signal.</s><s xml:id="_2jvy474">Receiver observes Sender's choice of the signal and a signal realization s ∈ s, and then takes her action.</s><s xml:id="_N9DyXUS">Our solution concept is Sender-preferred subgame perfect equilibrium: given Sender's choice of π and a signal realization s, Receiver forms the posterior μ s using Bayes's rule and takes an action from the set a * ( μ s ) = arg ma x a∈A E μ s <ref type="bibr">[u (a, ω)</ref> ] .</s><s xml:id="_9HYR8gX">We assume that there are at least two actions in A and that for any action a there exists a μ such that a ∈ a * (μ) .</s><s xml:id="_WrUNMUr">If Receiver is indifferent between some actions at a given belief, we assume she takes an action that maximizes Sender's expected utility.</s><s xml:id="_czbMcBt">This assumption simplifies notation and provides a useful benchmark in case of multiple equilibria.</s><s xml:id="_sRh8fKq">We let  a (μ) denote Receiver's equilibrium action at belief μ. <ref type="foot" target="#foot_1">2</ref> We refer to  a ( μ 0 ) as the default action.</s><s xml:id="_mxKgt8E">Taking Receiver's behavior as given, Sender chooses a signal π which maximizes his expected utility. <ref type="foot" target="#foot_2">3</ref></s><s xml:id="_G8U6Rza">In the remainder of the paper, we use the term "equilibrium" to mean a Sender-preferred subgame perfect equilibrium.</s></p><p xml:id="_tZWM8X5"><s xml:id="_5eKAmJV">A common special case is where ω is a real-valued random variable, Receiver's action depends only on the expectation E μ [ω] , rather than the entire distribution μ, and Sender's preferences over Receiver's actions do not depend on ω.</s><s xml:id="_jWMZvb8">This holds, for example, if u (a, ω) = -(a -ω) 2 and v (a, ω) = a.</s><s xml:id="_aJcw5Fd">When these conditions are satisfied, we will say that Sender's payoff depends only on the expected state.</s></p><p xml:id="_ew6dXHD"><s xml:id="_FxbCxrK">We define the value of a signal to be the equilibrium expectation of v (a, ω) under that signal.</s><s xml:id="_VhUJAaa">The gain from a signal is the difference between its value and the equilibrium expectation of v (a, ω) when Receiver obtains no information.</s><s xml:id="_SuxJFND">sender benefits from persuasion if there is a signal with a strictly positive gain.</s><s xml:id="_RfTNYCk">A signal is optimal if no other signal has higher value.</s><s xml:id="_GtZkNDU">Clearly, in equilibrium Sender selects an optimal signal.</s></p><p xml:id="_TdNjqEy"><s xml:id="_8KR3mGr">Given a signal, each signal realization s leads to a posterior belief μ s ∈ Δ (Ω) .</s><s xml:id="_6WuvBkz">Accordingly, each signal leads to a distribution over posterior beliefs.</s><s xml:id="_W5aWZW5">We denote a distribution of posteriors by τ ∈ Δ (Δ (Ω) ) .</s><s xml:id="_n7hSQdj">Algebraically, a signal π induces τ if Supp (τ) = { μ s } s∈s and</s></p><formula xml:id="formula_1">μ s (ω) = π (s | ω) μ 0 (ω) __ ∑ ω′ ∈Ω π (s | ω′ ) μ 0 ( ω′ ) for all s and ω τ (μ) = ∑ s: μ s =μ ∑ ω′ ∈Ω π (s | ω′ ) μ 0 ( ω′ ) for all μ.</formula><p xml:id="_nqBCR4n"><s xml:id="_9Wajdd9">We say a belief μ is induced by a signal if τ is induced by that signal and τ (μ) &gt; 0.</s></p><p xml:id="_Est46fP"><s xml:id="_dcfWT7s">A distribution of posteriors is Bayes plausible if the expected posterior probability equals the prior:</s></p><formula xml:id="formula_2">∑ supp(τ)</formula><p xml:id="_zAcHYjD"><s xml:id="_cdJs3gf">μ τ (μ) = μ 0 .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gpcqqmW">B. simplifying the problem</head><p xml:id="_5UZgtKG"><s xml:id="_wTWynKh">A distribution of posteriors induced by a signal determines a distribution of Receiver's actions.</s><s xml:id="_Y5caFZA">From Sender's perspective, any signal that induces the same distribution of actions conditional on the state must have the same value.</s><s xml:id="_hR4cDFj">To determine whether there exists a signal with some given value, therefore, it is sufficient to ask whether there exists a distribution of Receiver's posteriors that can be induced by a signal and that generates expected utility for Sender equal to that value.</s><s xml:id="_TM4KNJN">Hence, we need to know (i) which distributions of posteriors can be induced, and (ii) what is the expected utility generated by each distribution of posteriors?</s></p><p xml:id="_VfkdhFn"><s xml:id="_RAsRfGQ">Bayesian rationality requires that any equilibrium distribution of Receiver's beliefs be Bayes-plausible.</s><s xml:id="_TxBF9XH">Our first proposition below shows that this is the only restriction imposed by Bayesian rationality.</s><s xml:id="_nchTuRv">That is, for any Bayes-plausible distribution of posteriors there is a signal that induces it. <ref type="foot" target="#foot_3">4</ref></s><s xml:id="_NnSEckT">hen both Sender and Receiver hold some belief μ, Sender's expected utility is equal to</s></p><formula xml:id="formula_3"> v (μ) ≡ E μ v (  a (μ) , ω).</formula><p xml:id="_sgEQRaK"><s xml:id="_avZzBWF">Since Sender's and Receiver's beliefs coincide, Sender's utility from any signal which induces a distribution of posteriors τ is simply the expectation of  v under τ, i.e., E τ  v (μ) .</s><s xml:id="_FB7SQ5K">Combining the two observations above allows us to greatly simplify the analysis of our game.</s><s xml:id="_AJwJHCX">We simplify the analysis further by noting that, without loss of generality, we can restrict our attention to a particular class of signals.</s><s xml:id="_XRucV8S">Say that a signal is straightforward if s ⊆ A and Receiver's equilibrium action equals the signal realization.</s><s xml:id="_HUHC2vz">In other words, a straightforward signal produces a "recommended action" and Receiver always follows the recommendation.</s></p><p xml:id="_zhp52ZG"><s xml:id="_FvAyYw7">PROPOSITION 1: the following are equivalent:</s></p><p xml:id="_JfK9pef"><s xml:id="_EQT5WWp">(i) there exists a signal with value v * ;</s></p><p xml:id="_WzXHVJ4"><s xml:id="_WTy32tD">(ii) there exists a straightforward signal with value v * ;</s></p><p xml:id="_dmVZMQC"><s xml:id="_QJTdmtb">(iii) there exists a Bayes-plausible distribution of posteriors τ such that</s></p><formula xml:id="formula_4">E τ  v (μ) = v * .</formula><p xml:id="_HyTMx32"><s xml:id="_auFCXVx">Detailed proofs of all propositions are in Appendix A. The basic idea behind this proposition, however, is simple.</s><s xml:id="_xGcB9rk">The equivalence of (i) and (ii) is closely analogous to the revelation principle (e.g., Roger B. <ref type="bibr" target="#b23">Myerson 1979)</ref>, except that the revelation principle applies to problems where players' information is a given, while our problem is that of designing the informational environment.</s><s xml:id="_8xnt9nr">To see the equivalence between (i) and (iii), given a τ let s index Supp (τ) and consider a signal π (s | ω) = μ s (ω) τ ( μ s ) / μ 0 (ω) .</s><s xml:id="_5aBzjrq">Simple algebra reveals that π induces τ.</s><s xml:id="_Dh5MSZd">As we mentioned earlier, this equivalence shows that Bayes plausibility is the only restriction on the equilibrium distribution of posteriors. 5</s><s xml:id="_kaNUVTF">This fact is closely related to Eran <ref type="bibr" target="#b26">Shmaya and Leeat Yariv's (2009)</ref> concurrent work that identifies which sequences of distributions of posteriors are consistent with Bayesian rationality.</s></p><p xml:id="_mBPCvjh"><s xml:id="_CvK69Aw">The key implication of Proposition 1 is that to evaluate whether Sender benefits from persuasion and to determine the value of an optimal signal we need only ask how E τ  v (μ) varies over the space of Bayes-plausible distributions of posteriors. 6</s></p><p xml:id="_5dTMsDA"><s xml:id="_UGfZPvC">COROLLARY 1: sender benefits from persuasion if and only if there exists a Bayesplausible distribution of posteriors τ such that</s></p><formula xml:id="formula_5">E τ  v (μ) &gt;  v ( μ 0 ) .</formula><p xml:id="_J8uCCZj"><s xml:id="_bGMjZHh">the value of an optimal signal is</s></p><formula xml:id="formula_6">max τ E τ  v (μ) s.t. ∑ supp(τ) μ d τ (μ) = μ 0 .</formula><p xml:id="_tHCTtpN"><s xml:id="_QKCVnch">Note that Corollary 1 does not by itself tell us that an optimal signal exists.</s><s xml:id="_CBpwFuM">Our focus on Sender-preferred equilibria, however, implies that  v is upper semicontinuous which in turn ensures the existence of an optimal signal.</s></p><p xml:id="_M7Z9dhY"><s xml:id="_aGhaVhp">We introduce a final definition that will be useful in the analysis that follows.</s><s xml:id="_a5b5hHU">Let V be the concave closure of  v :</s></p><formula xml:id="formula_7">V (μ) ≡ sup { z | (μ, z) ∈ co(  v )},</formula><p xml:id="_pup4sxm"><s xml:id="_ww27XdK">where co (  v ) denotes the convex hull of the graph of  v .</s><s xml:id="_dVHS8vn">Note that V is concave by construction.</s><s xml:id="_4t4mwJW">In fact, it is the smallest concave function that is everywhere weakly greater than  v . 7</s><s xml:id="_84SFUEU">Figure <ref type="figure" target="#fig_0">1</ref> shows an example of the construction of V.</s><s xml:id="_Q9h9M8J">In this figure, the state space is binary, and we identify a distribution μ with the probability of one of the states.</s><s xml:id="_hY8vK2h">Specifying this probability of course uniquely pins down the entire distribution μ.</s></p><p xml:id="_Bny5QjG"><s xml:id="_yKGfm5Y">To see why</s></p><formula xml:id="formula_8">V is a useful construct, observe that if ( μ′ , z) ∈ co (  v ) , then there exists a distribution of posteriors τ such that E τ μ = μ′ and E τ  v (μ) = z. Thus, by Proposition 1, co (  v )</formula><p xml:id="_rP3UjR5"><s xml:id="_4mKXssm">is the set of (μ, z) such that if the prior is μ, there exists a signal with value z.</s><s xml:id="_3HzY8Xh">Hence, V (μ) is the largest payoff Sender can achieve with any signal when the prior is μ.</s></p><p xml:id="_CRe8jPC"><s xml:id="_Ed7VzHd">5 Juan-Jose <ref type="bibr" target="#b9">Ganuza and Jose Penalva (2010)</ref> utilize this isomorphism between signals and distributions of posteriors to introduce orders on the space of signals based on the dispersion of the distribution of posteriors they induce. 6</s><s xml:id="_aEWQDaF">This observation reveals a strong connection between our setting and the behavioral economics literature where agents are assumed to have explicit preferences over beliefs and choose what information to obtain (e.g., Andrew <ref type="bibr" target="#b5">Caplin and John Leahy 2004;</ref><ref type="bibr" target="#b16">Botond K ˝ o szegi 2006;</ref><ref type="bibr" target="#b8">Kfir Eliaz and Ran Spiegler 2006</ref>). 7</s><s xml:id="_AC52Usg">Our definition of concave closure is closely related to the notion of a biconjugate function in convex analysis (Jean-Baptiste Hiriart-Urruty and Claude Lemaréchal 2004).</s><s xml:id="_V6yRZZF"><ref type="bibr" target="#b2">Aumann and Maschler (1995)</ref> refer to V as the concavification of  v .</s></p><p xml:id="_AAwxC2C"><s xml:id="_d9VgkGk">COROLLARY 2: the value of an optimal signal is V ( μ 0 ) .</s><s xml:id="_qqPGVCR">sender benefits from persuasion if and only if V ( μ 0 ) &gt;  v ( μ 0 ) .</s></p><p xml:id="_D2e3uJt"><s xml:id="_uArbbej">Figure <ref type="figure">2</ref> shows the function  v , the optimal signal, and the concave closure V in the motivating example from the introduction.</s><s xml:id="_V5KBkG3">In the figure, μ denotes the probability that the state is guilty.</s><s xml:id="_pFpKkZB">As panel A shows,  v is a step function: the prosecutor's expected payoff is 0 whenever μ is less than 0.5 (since the judge will choose acquit) and 1 whenever μ is greater than or equal to 0.5 (since the judge will choose convict).</s><s xml:id="_xyhwpUk">As panel B shows, the optimal signal induces two posterior beliefs.</s><s xml:id="_eahsUSw">When the judge observes i, her posterior belief is μ = 0 and  v (0) = 0.</s><s xml:id="_PwB8QdZ">When the judge observes g, her posterior belief is μ = 0.5 and  v (0.5) = 1.</s><s xml:id="_Q9D6wv6">The distribution τ over these beliefs places probability 0.4 on μ = 0 and probability 0.6 on μ = 0.5.</s><s xml:id="_99jP64p">Hence, the prosecutor's expected utility is E τ  v (μ) = 0.6.</s><s xml:id="_pHgEgY4">The distribution τ is Bayes plausible since μ 0 = 0.3 = 0.4 × 0 + 0.6 × 0.5.</s><s xml:id="_Aub5hu5">As panel C shows, the concave closure V is equal to 2μ when μ ≤ 0.5 and constant at 1 when μ &gt; 0.5.</s><s xml:id="_9hjCJPM">It is clear that</s></p><formula xml:id="formula_9">V ( μ 0 ) &gt;  v ( μ 0 )</formula><p xml:id="_A2ZaN42"><s xml:id="_WTQQtXx">and that the value of the optimal signal is V ( μ 0 ) .</s><s xml:id="_R5eVbHM">Finally, following the proof of Proposition 1, it is easy to compute the signal that induces the optimal τ : π (s | ω) = μ s (ω) τ ( μ s ) / μ 0 (ω) .</s><s xml:id="_8ANtYUk">This yields the signal in equation (1) .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_y2r5QmT">C. the commitment Assumption</head><p xml:id="_8JE4n4k"><s xml:id="_fpQX6Bu">Most existing models of strategic communication consider settings where Sender is perfectly informed and has a limited ability to commit to communicate to Receiver</s></p><formula xml:id="formula_10">l h V v co( v )</formula><p xml:id="_4xTQSu7"><s xml:id="_HWjQtVr">what he knows.</s><s xml:id="_mGSPpV8">For example, in Vincent <ref type="bibr" target="#b6">Crawford and Joel Sobel (1982)</ref>, he can costlessly send any message regardless of what he knows.</s><s xml:id="_m458J5M">In Sanford J. <ref type="bibr" target="#b10">Grossman (1981)</ref> and Paul <ref type="bibr" target="#b20">Milgrom (1981)</ref>, he must tell the truth but not necessarily the whole truth.</s><s xml:id="_JvUYRPu">In Navin <ref type="bibr" target="#b15">Kartik (2009)</ref>, he suffers a lying cost for reporting messages that are far from the truth.</s><s xml:id="_eBRfyzX">In A. Michael <ref type="bibr" target="#b27">Spence (1973)</ref>, his cost of sending a high education message is decreasing in his true ability.</s></p><p xml:id="_Ey9RCJX"><s xml:id="_EMvkk7K">Our model gives Sender more commitment power than these papers because it assumes the realization of the signal is truthfully communicated to Receiver.</s><s xml:id="_enpuQta">This makes our environment effectively nonstrategic.</s><s xml:id="_EHWZ9RE">Receiver solves a simple decision problem given the information she receives, and Sender needn't worry about Receiver's interpretation of his actions.</s><s xml:id="_RbEnwvK">In particular, Sender's choice of a signal establishes the meaning of messages and eliminates the possibility of babbling equilibria and related coordination failures that are common in other models of strategic communication.</s></p><p xml:id="_9zH2R2U"><s xml:id="_aUdAwSC">Although this commitment assumption is strong, it is weaker than it may seem at first.</s><s xml:id="_gYBZM6U">For instance, it may seem restrictive to assume that Sender can generate signals that are arbitrarily informative.</s><s xml:id="_xSbgCUz">This assumption, however, is innocuous under an appropriate interpretation of the state ω.</s><s xml:id="_k53PmeR">We can define ω to be the realization of the most informative signal Sender can generate.</s><s xml:id="_xupXFZP">Then, his choice of π is equivalent to a choice of how much to garble information that is potentially available.</s></p><p xml:id="_v96wuhE"><s xml:id="_Fs7aDmF">It may also seem restrictive to assume that Sender can commit to limit the information he gathers.</s><s xml:id="_tyjh6J6">In many situations, we might worry that when Sender chooses a partially informative signal, he may wish to deviate and generate additional information following certain signal realizations.</s><s xml:id="_czZXgab">As we show later, however, under the optimal signal, Sender would never want to generate any further information regardless of the initial signal realization (cf.</s><s xml:id="_Rb7fxTz">Lemma 2 in the Appendix).</s></p><p xml:id="_JHPkuRh"><s xml:id="_sjm6gaG">Finally, we can also weaken the assumption that Sender will truthfully communicate any signal realization, and allow Sender to conceal some or all of his information, so long as the messages he does send are verifiable.</s><s xml:id="_PqnuZGT">Specifically, consider an alternate game where Sender chooses signal π, privately observes its realization s,</s></p><formula xml:id="formula_11">v v v V 1 1 0.5 0.5 1 Panel A. Function Panel B. Optimal signal Panel C. Function V v 0.5 0 0 0 E τ v V 0 ) Figure 2. The Motivating Example</formula><p xml:id="_WAKGtup"><s xml:id="_2wErhz9">and then sends a message m ∈  (s) such that s ∈ m. <ref type="foot" target="#foot_4">8</ref> Receiver knows what signal π Sender chose and observes the message m.<ref type="foot" target="#foot_5">foot_5</ref></s><s xml:id="_HKgA9Sa">Given any preferences and initial beliefs, the set of equilibrium outcomes of this alternate game and the set of equilibrium outcomes of the game we study in this paper coincide.</s><s xml:id="_gzKTmjA">We present a proof of this claim in the online Appendix.</s></p><p xml:id="_mhac5u6"><s xml:id="_RqgPtTU">There are a number of real-world settings in which our commitment assumption is a reasonable approximation.</s><s xml:id="_cMPb7Qh">First, there are contexts where commitment is legally mandated.</s><s xml:id="_Za4Dv4Z">Our motivating example of a prosecutor persuading a judge is a good example of such a context.</s><s xml:id="_tPxjfph">In Brady v. maryland,<ref type="foot" target="#foot_6">foot_6</ref> the Supreme Court of the United States ruled that a prosecutor violates the Due Process Clause of the Fourteenth Amendment when he fails to disclose material evidence favorable to the accused.</s><s xml:id="_HSZBz2H">Since a prosecutor maximizing convictions would always willingly choose to report any evidence unfavorable to the accused, our assumption that he discloses any evidence, i.e., any signal realization, seems justifiable. <ref type="foot" target="#foot_7">11</ref></s><s xml:id="_cDpKfEr">econd, there are settings where Sender cannot avoid learning all the available information but is able to commit to a stochastic disclosure rule π : Ω → Δ (s).</s><s xml:id="_dKC7HYj">Examples include a school choosing a coarse grading policy for students, or a rating agency choosing a scoring procedure for hospitals.</s></p><p xml:id="_4cukerM"><s xml:id="_8UCuFp2">Third, procedures for information gathering in organizations often involve commitment, either formally through contracts, or informally through reputation.</s><s xml:id="_A8G7XMt">Firms commit to the information they will seek out for performance reviews.</s><s xml:id="_a3XSESM">Academic departments follow fixed rules about the information they will solicit for midterm or tenure reviews.</s></p><p xml:id="_xvBR3xd"><s xml:id="_dypajWc">Fourth, there are many settings where the decision to conduct tests or studies is publicly observable, and the results are verifiable ex post.</s><s xml:id="_EG2Jbcd">Tobacco companies, for example, commission third party studies on the health effects of smoking.</s><s xml:id="_jNfa3Ym">They can limit the precision of the information they gather and may find it costly to suppress or distort the results after the fact.</s><s xml:id="_a5qdYDP">Medical research provides another, especially clear example.</s><s xml:id="_CKd7QVs">In order to be eligible for consideration by any major peer-reviewed biomedical journal, a randomized clinical trial must be registered in a publicly accessible trials registry before any subjects are enrolled.<ref type="foot" target="#foot_8">foot_8</ref></s><s xml:id="_QcZGWJx">Similarly, the design of drug trials must be submitted ahead of time to the FDA.</s><s xml:id="_fMtCf5q">In both cases, the design must be registered before any information can be gathered, and deviating from the proposed design renders a study invalid.</s></p><p xml:id="_BqRNGse"><s xml:id="_RGnCYKy">Fifth, in many situations, both Sender's choice of the signal and the signal realization are directly observed by Receiver.</s><s xml:id="_qGXT59F">Examples include a soft drink maker running a public taste test and a software maker providing a limited trial version of its software.</s></p><p xml:id="_gFqqZap"><s xml:id="_hNCNUhX">tHE AmERicAn EcOnOmic REViEW OctOBER 2011</s></p><p xml:id="_K92Gt92"><s xml:id="_k2jssnR">Even in settings where Sender cannot commit, our model may still prove useful.</s><s xml:id="_ymywV4g">In the online Appendix, we show that Sender's gain from persuasion in our model is weakly greater than his gain in any alternative communication game, including all those mentioned in the first paragraph of this subsection.</s><s xml:id="_KKwPc6G">Hence, the results in this paper provide an upper bound on gains from communication that are possible regardless of Sender's commitment power.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NJNZarH">II. When Does Sender Benefit from Persuasion?</head><p xml:id="_qGQpEKf"><s xml:id="_NCtg4u2">Corollary 2 provides a necessary and sufficient condition for Sender to benefit from persuasion in terms of the concave closure V.</s><s xml:id="_PDFaqwV">In any problem where we can graph the function  v , it is straightforward to construct V and determine the prior beliefs, if any, at which V ( μ 0 ) &gt;  v ( μ 0 ) .</s><s xml:id="_YFasn6b">In Figure <ref type="figure" target="#fig_0">1</ref>, Sender benefits from persuasion for any μ 0 ∈ ( μ l , μ h ) , and does not benefit from persuasion for any μ 0 ≤ μ l or μ 0 ≥ μ h .</s><s xml:id="_hvAVB8r">In Figure <ref type="figure">2</ref>, Sender benefits from persuasion for any μ 0 &lt; 0.5 -i.e., at any prior belief at which the judge does not convict by default.</s><s xml:id="_U4eqMCv">In this section, we show ways to determine whether V ( μ 0 ) &gt;  v ( μ 0 ) in cases when the state space is too large to graph  v .</s><s xml:id="_KjGeycj">We first do this in terms of the properties of  v , and then in terms of the primitives of our model, namely Sender and Receiver's preferences and initial beliefs.</s></p><p xml:id="_cyuV4kJ"><s xml:id="_J4P8X6v">Corollaries 1 and 2 tell us that Sender benefits from persuasion if and only if there exists a τ such that</s></p><formula xml:id="formula_12">E τ (  v (μ) ) &gt;  v ( E τ (μ)</formula><p xml:id="_M2aZjTz"><s xml:id="_BSawqq5">).</s><s xml:id="_pzyB3PN">Whether this is the case is naturally tied to the concavity or convexity of  v .</s></p><p xml:id="_7E2VPAj"><s xml:id="_ssrgJWa">REMARK 1: if  v is concave, sender does not benefit from persuasion for any prior.</s><s xml:id="_ZbMKn5s">if  v is convex and not concave, sender benefits from persuasion for every prior.</s></p><p xml:id="_e2jp24J"><s xml:id="_AmBBEEd">Observe that in the simple case where Sender's payoff does not depend on the state,  v (μ) = v (  a (μ) ).</s><s xml:id="_Kbs3d82">The concavity or convexity of  v then depends on just two things: whether Receiver's action  a (μ) is concave or convex in μ, and whether Sender's payoff v (a) is concave or convex in a.</s><s xml:id="_aRZZaGF">If both  a and v are concave, Sender does not benefit from persuasion.</s><s xml:id="_CfpXwZs">If both  a and v are convex and at least one of them is not concave, Sender benefits from persuasion.</s></p><p xml:id="_FhkpEuv"><s xml:id="_GJ7djW2">Often,  v will be neither convex nor concave.</s><s xml:id="_v7Nhaac">This is true, for example, in our motivating example as shown in Figure <ref type="figure">2</ref>. As we discussed earlier, the fact that Sender benefits from persuasion in that example hinges on (i) the fact that Receiver does not take Sender's preferred action by default, and (ii) the fact that Receiver's action is constant in a neighborhood around the prior.</s><s xml:id="_5BYmQwG">We now show that these two conditions, suitably generalized, play a crucial role more broadly.</s></p><p xml:id="_Gy73Z49"><s xml:id="_mkFSjr4">To generalize (i), say there is information sender would share if ∃ μ such that</s></p><formula xml:id="formula_13">(2)  v (μ) &gt; E μ v (  a ( μ 0 ), ω).</formula><p xml:id="_evPN4Jv"><s xml:id="_M6KguN4">In other words, there is a μ such that, if Sender had private information that led him to believe μ, he would prefer to share this information with Receiver rather than have Receiver act based on μ 0 .</s><s xml:id="_htAAfjd">Note that when v does not depend on ω, there is information Sender would share as long the default action is not dominant, i.e., as long as v (  a ( μ 0 )) &lt; v(a) for some a ∈ A. This is the sense in which equation (2) generalizes condition (i).</s></p><p xml:id="_Wmf8j3M"><s xml:id="_tHTAjfM">To generalize (ii), we say Receiver's preference is discrete at belief μ if Receiver's expected utility from her preferred action  a (μ) is bounded away from her expected utility from any other action, i.e., if there is an ε &gt;</s></p><formula xml:id="formula_14">0 s.t. ∀ a ≠  a (μ) , E μ u(  a (μ), ω) &gt; E μ u (a, ω) + ε.</formula><p xml:id="_gKSRfwg"><s xml:id="_v9PuwrM">When A is finite, Receiver's preference is not discrete only if Receiver is exactly indifferent between two distinct actions.</s><s xml:id="_TjB6eW5">Our main result in this section is that the generalization of (i) is necessary, while generalizations of (i) and (ii) are jointly sufficient, for Sender to benefit from persuasion.</s></p><p xml:id="_7vwzWqT"><s xml:id="_kjZJHSA">PROPOSITION 2: if there is no information sender would share, sender does not benefit from persuasion.</s><s xml:id="_XPrWQG9">if there is information sender would share and Receiver's preference is discrete at the prior, sender benefits from persuasion.</s><s xml:id="_sREbRar">if A is finite, Receiver's preference is discrete at the prior generically.</s></p><p xml:id="_PRTqgTy"><s xml:id="_RsBnjg3">The first part of the proposition is easy to see.</s><s xml:id="_JDM3EVA">If there is no information Sender would share, any realization of any signal leads Receiver to take an action Sender weakly dislikes relative to the default action.</s><s xml:id="_wnJQtAU">Hence, a completely noninformative signal is optimal.</s></p><p xml:id="_3bKjxmf"><s xml:id="_dJw98py">The intuition for the second part is as follows.</s><s xml:id="_XWCd8Rs">Because there is information that Sender would share we can find a belief μ h such that </s></p><formula xml:id="formula_15">v ( μ h ) &gt; ∑ ω v (  a ( μ 0 ), ω) μ h (ω) .</formula><p xml:id="_gC8tAeJ"><s xml:id="_k2c5kEf">Moreover, the discreteness of Receiver's preference implies that there is a belief near the prior, say μ l , such that  a ( μ l ) is equal to Receiver's default action and μ 0 is on the segment between μ l and μ h .</s><s xml:id="_YjWYJZ5">That mixing point μ l and μ h produces a strictly positive gain is obvious in a case like the motivating example where Sender's payoff v does not depend on the state.</s><s xml:id="_MxxzqVM">The argument is more subtle when v does depend on the state.</s><s xml:id="_pHdVCDg">The key observation is that for any given action by Receiver, Sender's utility is linear in μ.</s><s xml:id="_CEf9RNJ">In particular, ∑ ω v (  a ( μ 0 ), ω) μ (ω) is linear in μ.</s><s xml:id="_ygen8EQ">This implies that mixing μ l with μ h yields a strictly positive gain.</s></p><p xml:id="_9Wa52ET"><s xml:id="_QBrUVvX">Note that the second part of the proposition is of no use if A is connected.</s><s xml:id="_52CWUQG">In that case, the continuity of u implies that Receiver's preference cannot be discrete at any belief.</s><s xml:id="_sZBBEez">In contrast, as the last part of the proposition establishes, when A is finite, the set of beliefs at which Receiver's preference is not discrete is Lebesgue measure zero in Δ (Ω) .</s><s xml:id="_cYb7G5s">This holds because Receiver is indifferent between two actions only at finitely many beliefs, which means that she is generically not indifferent at the prior.</s><s xml:id="_Yr5AQSZ">The last part of Proposition 2 is not meant to suggest, however, that there is some form of discontinuity in Sender's benefit from persuasion as we move from large finite choice sets to infinite ones.</s><s xml:id="_DMEF4uM">As the action space becomes large, the gain from persuasion may become arbitrarily small.</s><s xml:id="_Yu9JpM7">sender's payoff depends only on the Expected state.-We</s><s xml:id="_YzrGERY">have shown that when  v can be graphed, inspection of the graph can show directly whether Sender benefits from persuasion.</s><s xml:id="_DFhmxT5">The domain of  v , however, is Δ (Ω) .</s><s xml:id="_Ph4pQGE">This means that it is possible to easily depict  v only when there are two or three states.</s><s xml:id="_nX3nvuA">When there are more states, our propositions still apply, but one cannot approach the problem by simply studying the graph of  v .</s><s xml:id="_R3TaGG6">When Sender's payoff depends only on the expected state, however, a natural conjecture is that we could learn about Sender's gain from persuasion by graphing Sender's payoff as a function of the expected state E μ [ω] rather than as a function of μ directly.</s><s xml:id="_XRFdrpW">If so, we would have a simple two-dimensional representation of this subclass of problems regardless of the size of the state space.</s></p><p xml:id="_tk9xvSS"><s xml:id="_AMSdYte">When Sender's payoff depends only on the expected state, there exists a ˜</s></p><formula xml:id="formula_16">v : ℝ → ℝ such that ˜ v ( E μ [ω] ) =  v (μ) . Let ˜ V be the concave closure of ˜ v .</formula><p xml:id="_Df8WdCJ"><s xml:id="_eDQnJdW">The following Proposition shows that the conjecture above is correct: we can determine whether Sender benefits from persuasion simply by inspecting ˜ V and ˜ v .</s><s xml:id="_TTQN9DN">In Section V below, we provide an example of how this result can greatly simplify the analysis of problems with a large state space.</s></p><p xml:id="_h5f3SYj"><s xml:id="_4TzeC2H">PROPOSITION 3: When sender's payoff depends only on the expected state, sender benefits from persuasion if and only if ˜</s></p><formula xml:id="formula_17">V ( E μ 0 [ω] ) &gt; ˜ v ( E μ 0 [ω] ).</formula><p xml:id="_bux8tY9"><s xml:id="_PU9gGNS">To see that ˜</s></p><formula xml:id="formula_18">V ( E μ 0 [ω] ) ≤ ˜ v ( E μ 0 [ω]</formula><p xml:id="_JHBFCbK"><s xml:id="_CDqYcmJ">) implies Sender cannot benefit from persuasion, we need only note that for any Bayes-plausible τ,</s></p><formula xml:id="formula_19">E τ [  v (μ) ] ≤ ˜ V ( E μ 0 [ω] ) ≤ ˜ v ( E μ 0 [ω] ) =  v ( μ 0 ) . The proof of the converse is more involved. If ˜ V ( E μ 0 [ω] ) &gt; ˜ v ( E μ 0 [ω] ), we know there is a τ s.t. E τ [ E μ [ω] ] = E μ 0 [ω] and E τ [  v (μ) ] &gt;  v ( μ 0</formula><p xml:id="_GVJEZWj"><s xml:id="_9r24DyB">) .</s><s xml:id="_ue6Vyyy">If this τ were Bayes-plausible, we could construct a signal that induces it and we would be done.</s><s xml:id="_8pXBzPm">The trouble is that E τ [ E μ <ref type="bibr">[ω]</ref> ] = E μ 0 [ω] does not guarantee that τ is Bayes plausible.</s><s xml:id="_MgkARxx">To construct a signal with a strictly positive gain, we show that it is always possible to find a belief μ′ such that E μ′ [ω] = E μ 0 [ω] and a Bayes-plausible τ ′ that is a mixture of τ and μ′ .</s><s xml:id="_bVcHBG5">Since</s></p><formula xml:id="formula_20">E τ [  v (μ) ] &gt;  v ( μ 0 ) and  v ( μ′ ) =  v ( μ 0 ) , we know that E τ′ [  v (μ) ] &gt;  v ( μ 0 ) . 13</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_BBEtdyV">III. Optimal Signals</head><p xml:id="_ZvxCdE7"><s xml:id="_reqhVD7">Corollary 2 shows that the value of an optimal signal is V ( μ 0 ) .</s><s xml:id="_bR5jSGq">When it is possible to graph  v and V, we can read V ( μ 0 ) and the gain V ( μ 0 ) - v ( μ 0 ) off the graph directly.</s><s xml:id="_ufY5Upc">The graphs of  v and V also identify the beliefs induced by the optimal signal-these are the points on  v whose convex combination yields value V ( μ 0 ) .</s><s xml:id="_gfwcQ9F">In Figure <ref type="figure" target="#fig_0">1</ref>, we see that the optimal signal induces beliefs μ l and μ h .</s><s xml:id="_qEZGQ53">As we explained at the end of Subsection IB, once these beliefs are identified, it easy to compute the optimal signal which generates them.</s></p><p xml:id="_dcsuHFz"><s xml:id="_jtKsfqP">Determining the optimal signal is also easy when  v is convex or concave.</s><s xml:id="_VbjAhTd">Say that no disclosure is optimal if μ s = μ 0 for all s realized with positive probability under the optimal signal.</s><s xml:id="_yVaP5EH">If, at the other extreme, μ s is degenerate<ref type="foot" target="#foot_10">foot_10</ref> for all s realized with positive probability under the optimal signal, say that full disclosure is optimal.</s><s xml:id="_BE6zBwE">Then, if  v is (strictly) concave, no disclosure is (uniquely) optimal, and if  v is (strictly) convex, full disclosure is (uniquely) optimal.</s><s xml:id="_GC7hjcF">This observation follows directly from the definitions of convexity and concavity.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Xm3Rhuj">When </head><p xml:id="_rH4mk69"><s xml:id="_ah4tE8C">v cannot be visualized and is neither convex nor concave, we can still develop insight about optimal signals by noting general properties of beliefs induced by optimal signals.</s><s xml:id="_2KVNYk3">Recall that in the motivating example: (i) whenever the judge chooses the prosecutor's least-preferred action (acquit), she is certain of the state; and (ii) whenever she chooses an action that is not the prosecutor's least-preferred (convict), she is indifferent between that action and a worse one.</s></p><p xml:id="_SP68vS5"><s xml:id="_4ezbbgw">The first of these properties holds in general.</s><s xml:id="_AxJp3TN">Define an action a _ to be a worst action if v ( a _ , ω) &lt; v (a, ω) for all ω and all a ≠ _ a .</s><s xml:id="_2R9pSj4">Say that Receiver is certain of her action at a belief μ if μ (ω) = 0 for all ω s.t.</s><s xml:id="_C32aCUN">{  a (μ) } ≠ arg max u(a, ω).</s><s xml:id="_pGyJgXs">If a =  a (μ) say that μ leads to a.</s><s xml:id="_FRvFs7K">The proof of the following proposition follows the logic we described in the introduction with regard to the motivating example.</s></p><p xml:id="_fgNWdXE"><s xml:id="_5QhAN72">PROPOSITION 4: if an optimal signal induces a belief μ that leads to a worst action, Receiver is certain of her action at μ.</s></p><p xml:id="_QeUsfjf"><s xml:id="_PU6FMhr">The second of the properties above, on the other hand, is not completely general when v depends on ω.</s><s xml:id="_4kjNXDT">Sender's preferences could then take a form such that two actions a 1 and a 2 are both induced by an optimal signal, but at the belief at which Receiver takes a 1 Sender is exactly indifferent between a 1 and a 2 .</s><s xml:id="_u6C4bPF">Then the logic described in the introduction-where Sender could improve his payoff by shifting probability mass away from a belief that induced a strict preference for one action in order to increase the probability of an alternative action-need not hold, since Sender is exactly indifferent to this change.</s><s xml:id="_YWsNxqt">However, if this occurs under a particular utility function v, it will not occur for a slight perturbation of v.</s><s xml:id="_4WC65Uz">The following assumption rules out this pathological case.</s></p><p xml:id="_PBWtdXZ"><s xml:id="_NCqv8Uf">ASSUMPTION 1: there exists no action a s.t.</s></p><formula xml:id="formula_21">(i) ∀μ,  v (μ) ≤ E μ v (a, ω) and (ii) ∃ μ s.t. a ≠  a (μ) and  v (μ) = E μ v (a, ω) .</formula><p xml:id="_P45m2AG"><s xml:id="_4nvKUQn">The intuition that we provided for property (ii) applies to any interior belief.</s><s xml:id="_RfdWM9x">The same intuition, however, also applies to any belief which leads to an action that Sender cannot improve upon.</s><s xml:id="_mT3ADY2">Say an action a is best attainable</s></p><formula xml:id="formula_22">if E μ v (a, ω) &gt;  v (μ) for all μ s.t. a ≠  a (μ).</formula><p xml:id="_WqzcBYq"><s xml:id="_zrrkVJA">PROPOSITION 5: suppose Assumption 1 holds and sender benefits from persuasion.</s><s xml:id="_RkSXdKE">if a belief μ induced by an optimal signal is either (i) interior or (ii) leads to a best-attainable action, then Receiver's preference is not discrete at μ.</s></p><p xml:id="_Ge4YzS6"><s xml:id="_hrtT9Ek">Recall that when the action space is finite, Receiver's preference is not discrete at μ means that she is indifferent between two actions at μ. Hence, in the motivating example, Proposition 5 implies that the judge is indifferent between convicting and acquitting when she convicts.</s></p><p xml:id="_F2hPQnw"><s xml:id="_RRJ45tr">The motivating example suggests an additional property of the optimal signal.</s><s xml:id="_Srsa8m6">Because the prosecutor's payoff is (weakly) increasing in the judge's posterior belief that the state is guilty, it is meaningful to talk about beliefs that place more weight on innocent as being "worse" from the prosecutor's perspective.</s><s xml:id="_mvxrrjS">A different way to look at properties (i) and (ii) is that the prosecutor chooses an investigation that induces the worst possible belief consistent with a given action by the judgecertainty of innocence when the action is acquit, and indifference when the action is convict.</s><s xml:id="_kUrwpKx">In the online Appendix, we show that when Sender's payoffs are monotonic in Receiver's beliefs, there is a general sense in which Sender always induces the worst belief consistent with a given action.</s></p><p xml:id="_95rR533"><s xml:id="_KTzGQBy">sender's payoff depends only on the Expected state.-Recall</s><s xml:id="_wnGwYwg">that we established earlier that when Sender's payoff depends only on the expected state, there is a function ˜</s></p><formula xml:id="formula_23">v s.t. ˜ v ( E μ [ω] ) =  v (μ)</formula><p xml:id="_6j6sFjX"><s xml:id="_24Ga7up">, and Sender benefits from persuasion if and only if ˜</s></p><formula xml:id="formula_24">V ( E μ 0 [ω] ) &gt; ˜ v ( E μ 0 [ω]</formula><p xml:id="_Nnf3xxN"><s xml:id="_UcnXGfg">).</s><s xml:id="_TqRqYUh">We might conjecture that the value of an optimal signal is ˜</s></p><formula xml:id="formula_25">V ( E μ 0 [ω]</formula><p xml:id="_yWq2uSE"><s xml:id="_zPfvhEx">).</s><s xml:id="_VB2zjrU">This conjecture turns out to be false.</s><s xml:id="_q4maFAy">Recall from the discussion of Proposition 3 that even though we know there is always a τ s.</s></p><formula xml:id="formula_26">t. E τ [ E μ [ω] ] = E μ 0 [ω] and E τ [  v (μ) ] = ˜ V ( E μ 0 [ω]</formula><p xml:id="_CUrVm9H"><s xml:id="_TJfY2pg">), such τ need not be Bayes plausible.</s><s xml:id="_eUPZs4X">In order to show that Sender could benefit from persuasion, we had to mix the beliefs in the support of τ with another belief μ′ such that</s></p><formula xml:id="formula_27">E μ′ [ω] = E μ 0 [ω]</formula><p xml:id="_58YhTMV"><s xml:id="_KV9a6ZD">. This reduces the value of the signal strictly below ˜</s></p><formula xml:id="formula_28">V ( E μ 0 [ω]</formula><p xml:id="_RuVMEZu"><s xml:id="_SEXBv5A">).</s></p><p xml:id="_8Zmp2K7"><s xml:id="_wUKRGmK">For a concrete example, suppose that</s></p><formula xml:id="formula_29">A = [0, 1] , Ω = {-1, 0, 1} , u (a, ω) = -(a -ω) 2 , and v (a, ω) = a 2 . In this case,  v (μ) = ˜ v ( E μ 0 [ω] ) = ( E μ [ω] ) 2 .</formula><p xml:id="_NG5vwn9"><s xml:id="_qnPn5VF">Hence, ˜ V is constant at 1 and in particular ˜</s></p><formula xml:id="formula_30">V ( E μ 0 [ω] ) = 1.</formula><p xml:id="_XsN3M3S"><s xml:id="_4XtRen9">Yet, whenever the prior puts any weight on ω = 0, the value of any mechanism is strictly less than 1.</s><s xml:id="_jkcErm9">Hence, when Sender's payoff depends only on the expected state, we can use ˜ v to determine whether Sender benefits from persuasion, but ˜</s></p><formula xml:id="formula_31">V ( E μ 0 [ω]</formula><p xml:id="_2vMXJnh"><s xml:id="_VpDjXPG">) is only an upper bound on the value of an optimal signal.</s><s xml:id="_nkTz7h5">To characterize the optimal signal more precisely, we need to study  v directly or derive its properties from Propositions 4 and 5.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_6zvj684">IV. Preference Alignment</head><p xml:id="_Tj7JKhH"><s xml:id="_vHVCRdG">We say that preferences ( u′ , v′ ) are more aligned than (u, v) if for any a and any μ</s></p><formula xml:id="formula_32">E μ v(  a (μ) , ω) ≥ E μ v(a, ω) ⇒ E μ v′ (  a ′ (μ) , ω) ≥ E μ v′ (a, ω),</formula><p xml:id="_v6FGhye"><s xml:id="_jSSdyjj">where  a ′ (μ) denotes Receiver's equilibrium action when her belief is μ and her utility is u′ .</s><s xml:id="_X45UZpd">Note that the functional form used to index alignment in the main example of <ref type="bibr" target="#b6">Crawford and Sobel (1982)</ref> satisfies this definition.</s></p><p xml:id="_JdMp3Hy"><s xml:id="_EqgQqPp">It is easy to establish that Sender necessarily obtains higher utility if preferences are more aligned.</s><s xml:id="_9TwEapj">Consider moving from (u, v) to a more aligned ( u′ , v) .</s><s xml:id="_Pg8pA9u">We hold v constant so that Sender's utility is measured on a constant scale.</s><s xml:id="_WbctxjB">Plugging in a =  a (μ) to the definition above, it is immediate that</s></p><formula xml:id="formula_33">E μ v(  a ′ (μ) , ω) ≥ E μ v(  a (μ) , ω) for any μ. This means  v ′ (μ) ≥  v (μ)</formula><p xml:id="_PVNM9cz"><s xml:id="_2zHtJnC">for all μ, so the value of the optimal signal is weakly higher under ( u′ , v) than under (u, v) .</s><s xml:id="_6MtDDcc">Note, however, that when greater alignment changes the default action, it is possible for the gain from persuasion to be lower under more aligned preferences.</s></p><p xml:id="_kC5zCke"><s xml:id="_dntCFfJ">The impact of alignment on the amount of information communicated in equilibrium is also ambiguous.</s><s xml:id="_tbqebsM">On the one hand, the more Receiver responds to information in a way consistent with what Sender would do, the more Sender benefits from providing information.</s><s xml:id="_UvM7GRC">On the other hand, when preferences are more aligned Sender can provide less information and still sway Receiver's action in a desirable direction.</s><s xml:id="_4eNfV8A">Hence, making preferences more aligned can make the<ref type="foot" target="#foot_11">foot_11</ref> optimal signal either more or less informative.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rtjhahG">V. Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mvNTgfR">A. Lobbying</head><p xml:id="_hdpaRnP"><s xml:id="_RTqZrvs">Consider a setting where a lobbying group commissions a study with the goal of influencing a benevolent politician.</s><s xml:id="_ktsUCUK">Such studies are common in practice.</s><s xml:id="_mRCRGZz">The tobacco lobby has spent large sums funding studies about the health effects of smoking (Joaquin <ref type="bibr" target="#b3">Barnoya and Stanton A. Glantz 2006)</ref>.</s><s xml:id="_xgR74P4">Drug companies spend over $14 billion a year funding clinical trials of their products (Hamilton <ref type="bibr" target="#b22">Moses III et al. 2005)</ref>.</s><s xml:id="_eUu8eJa">Would it make sense for the lobbyist to commission such studies even if the politician is rational and knows the lobbyist is providing information with the goal of influencing her decision?</s><s xml:id="_yfUQFF4">Would the optimal study in this case be biased toward supporting the lobbyist's position or fully revealing of the true state?</s></p><p xml:id="_8zCMBPX"><s xml:id="_BhbgVa6">Here, our commitment assumption requires that the information the lobbyist gathers is observable to the politician, and that the lobbyist can make verifiable claims about what the information shows.</s><s xml:id="_xrkGmnF">Recall from Section C that it is not necessary to assume the lobbyist truthfully reports everything he knows, so long as any claims he does make are verifiable.</s></p><p xml:id="_cfgEnEd"><s xml:id="_E6XAs3x">We assume that the politician (Receiver) chooses a unidimensional policy a ∈ [0, 1].</s><s xml:id="_HFbj9N9">The state ω ∈ [0, 1] is the socially optimal policy.</s><s xml:id="_kcSmWPz">The lobbyist (Sender) is employed by an interest group whose preferred action a * = αω + (1 -α) ω * , with α ∈ [0, 1], depends on ω but is biased toward a specific policy ω * &gt; 1.</s><s xml:id="_rbqFNxh">The politician's payoff is u = -(a -ω) 2 and the lobbyist's payoff is v = -(aa * ) 2 .</s><s xml:id="_NXdZ2Cr">We are interested in the way the equilibrium depends on the extent of preference disagreement, as captured by α and ω * .</s><s xml:id="_4v3HVsK">It is easy to see that an increase in α or a decrease in ω * makes preferences more aligned according the definition in Section IV.</s></p><p xml:id="_ZMVFXXE"><s xml:id="_hWQ9m56">Since</s></p><formula xml:id="formula_34">u = -(a -ω) 2 we know that  a (μ) = E μ [ω] . Given this  a , simple algebra reveals that  v (μ) = -(1 -α) 2 ω *2 + 2 (1 -α) 2 ω * E μ [ω] -α 2 E μ [ ω 2 ] + (2α -1) ( E μ [ω] ) 2 . The expectation of -(1 -α) 2 ω *2 + 2 (1 -α) 2 ω * E μ [ω] -α 2 E μ [ ω 2 ] is constant across all Bayes-plausible τ 's, so we can treat  v (μ) as a constant plus (2α -1) ( E μ [ω] ) 2 .</formula><p xml:id="_ebEEGn3"><s xml:id="_CYB5mja">We can now easily solve for the optimal signal;  v is linear in μ when α = 1/2, strictly convex when α &gt; 1/2, and strictly concave when α &lt; 1/2.</s><s xml:id="_MhheRp7">From the discussion in Section III, this implies that when α &gt; 1/2, i.e., the lobbyist's preferences are sufficiently aligned with those of the politician, full disclosure is uniquely optimal. 16</s><s xml:id="_YawzJFd"> When α &lt; 1/2, i.e., the lobbyist's and the politician's preferences diverge significantly, no disclosure is uniquely optimal.</s><s xml:id="_J3PSqXU">When α = 1/2 all signals yield the same value.</s><s xml:id="_4BD4sAf">There is thus a natural sense in which some alignment of preferences is necessary for information to be communicated in equilibrium even when Sender has the ability to commit.</s></p><p xml:id="_fSGXsNU"><s xml:id="_RvSKh2K">Note, however, that the optimal signal is independent of ω * .</s><s xml:id="_CeJQb6H">This is important because ω * also captures a form of disagreement between the lobbyist and the politician.</s><s xml:id="_ucBp59W">We might have expected communication to be difficult when ω * is much greater than one.</s><s xml:id="_uJZktpC">Unlike α, however, ω * does not affect the way the lobbyist's payoff varies across realizations of a signal.</s><s xml:id="_Jx6hND7">The loss the lobbyist suffers from high values of ω * is thus a sunk cost and does not affect the decision of how best to persuade.</s><s xml:id="_NhUJZKV">This is another illustration of the ambiguous effect of preference alignment in our setting. 17</s><s xml:id="_FyQvvdS"> An interesting feature of this example is that the lobbyist either commissions a fully revealing study or no study at all.</s><s xml:id="_WWBHBJM">This contrasts with the observation that industry-funded studies often seem to produce results more favorable to the industry than independent studies.</s><s xml:id="_6aDpQ4A">The model suggests that commissioning such biased studies when policymakers are rational may not be optimal from the industry's perspective.</s><s xml:id="_6VkCNs7">If such studies are optimal, it is likely that the intended constituency is not fully rational, the lobbyists cannot commit not to distort study results ex post, or the payoff functions differ from those in this simple example in a way that makes asymmetric signals optimal.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7b9qMd2">B. supplying product information</head><p xml:id="_3DrZM5X"><s xml:id="_t8WRphU">Firms often provide information to consumers to help them learn about the match between their preferences and the characteristics of the firm's products.</s><s xml:id="_gTGxZqK">Car dealers allow consumers to test drive cars.</s><s xml:id="_N7GXR52">Pharmaceutical advertising informs consumers of the conditions for which a particular drug is likely to be effective.</s><s xml:id="_War74nB">Software producers allow consumers to download trial versions of their products.</s><s xml:id="_W9ZdZSY">In each of these cases, firms decide what kind of signal consumers can obtain-the length and frequency of test drives, the details included in ads, the number of features that are available in the free version of software, and so on.</s></p><p xml:id="_MBZCBv5"><s xml:id="_skmjw7X">Our commitment assumption is natural in this setting because the consumer observes the signal and its realization directly.</s><s xml:id="_cFEqHSs">The assumption of common priors is 16 Even if we remove the restriction that α ∈ [0, 1], it remains the case that  v is convex whenever α &gt; 1/2.</s><s xml:id="_vghyvwA">Hence, even if the interest group's preferences differ greatly from socially optimal ones by being overly sensitive to ω, full disclosure remains uniquely optimal. 17</s><s xml:id="_mCfbpKK">This observation also highlights a difference between our setting and delegation models where Receiver has commitment power (e.g., Bengt R. <ref type="bibr" target="#b12">Holmstrom 1984</ref><ref type="bibr" target="#b7">, Wouter Dessein 2002</ref><ref type="bibr" target="#b0">, Ricardo Alonso and Niko Matouschek 2008)</ref>.</s><s xml:id="_gcbEQs7">In those models, Sender has no commitment power, but Receiver commits ex ante how she will respond to messages from Sender.</s><s xml:id="_BwrT8qV">Nahum D. <ref type="bibr" target="#b19">Melumad and Toshiyuki Shibano (1991)</ref> analyze such a game with the same preferences as in this example and show that the amount of information communicated in equilibrium depends on ω * as well as α.</s><s xml:id="_RASPpaP">Hence, the way in which preference disagreement affects communications depends on the nature of commitment.</s><s xml:id="_7j4Cart">Note that when there is a worst action for Sender and both parties have complete commitment, full disclosure is always an equilibrium: Receiver would commit to take that worst action at any nondegenerate belief and thus force Sender to send a fully informative signal.</s><s xml:id="_VMNzKFu">also natural when the state is the match between a particular consumer's preferences and a product rather than the product's overall average quality.</s></p><p xml:id="_SxaRXJ6"><s xml:id="_pdts8v3">Tracy R. Lewis and David E. M. Sappington (1994), Simon P. <ref type="bibr" target="#b1">Anderson and Regis Renault (2006)</ref>, and Justin P. <ref type="bibr" target="#b14">Johnson and David P. Myatt (2006)</ref> study the question of how much information firms should provide to their potential customers.</s><s xml:id="_6JdEQ8f">Here, we derive the optimal signal in a simple version of the <ref type="bibr" target="#b17">Lewis and Sappington (1994)</ref> model. <ref type="foot" target="#foot_12">18</ref></s><s xml:id="_G9WtEAX"> firm (Sender) faces a single consumer (Receiver) who decides whether to buy one unit of the firm's product or not.</s><s xml:id="_sG6WjYY">If the consumer does not purchase, she gets an outside option which yields utility u _ ∈ [0, 1].</s><s xml:id="_SgyuqNH">The consumer gets utility ω ∈ [0, 1] from buying the product.</s><s xml:id="_EYeSxSE">The state ω indexes the match quality between consumer's taste and the product (holding constant the price and other characteristics which we treat as exogenous).</s><s xml:id="_aRVkR95">The firm and the consumer share a prior μ 0 about ω.</s><s xml:id="_xKsUzTP">The consumer is risk neutral and hence will buy the product if and only if E μ [ω] ≥ u _ where μ is her posterior belief about ω.</s><s xml:id="_scmgsvW">To make things interesting, we suppose that the default action is not to buy, i.e., E μ 0 [ω] &lt; u _ .</s><s xml:id="_bX29BC3">The firm chooses the type of interaction that the consumer can have with the product before deciding whether to purchase it.</s><s xml:id="_WQS4wwf">Formally, it chooses a signal π : [0, 1] → Δ (s) that the consumer can observe about ω.</s></p><p xml:id="_5FZQbFg"><s xml:id="_SPbSGYJ">We again begin by computing  v .</s><s xml:id="_c34wRPc">Denoting the decision to buy with 1 and the alternative with 0, we have </s></p><formula xml:id="formula_35">a (μ) = { 0 1 if E μ [ω] &lt; u _ E μ [ω] ≥ u _  v (μ) = { 0 1 if E μ [ω] &lt; u _ E μ [ω] ≥ u _ .</formula><p xml:id="_hUzMeKw"><s xml:id="_cWw3tQG">In this example,  v is difficult to visualize.</s><s xml:id="_mZ8nzxR">However, since Sender's payoff depends only on the expected state, we can depict ˜ v and ˜ V (Figure <ref type="figure">3</ref>).</s><s xml:id="_sT7khVe">Since ˜</s></p><formula xml:id="formula_36">V ( E μ 0 [ω] ) &gt; ˜ v ( E μ 0 [ω]</formula><p xml:id="_Uq3JkvX"><s xml:id="_anc2T37">), Proposition 3 tells us there exists an advertising campaign that increases the firm's revenue.</s><s xml:id="_QUq7ysb">Also, as we discussed at the end of Section III, while we cannot determine the optimal campaign by examining ˜ v , we know that ˜</s></p><formula xml:id="formula_37">V ( E μ 0 [ω]</formula><p xml:id="_wgBnGCn"><s xml:id="_S8yHmYC">) is an upper bound on the market share that can be achieved by any advertising campaign.</s></p><p xml:id="_UGKKXtZ"><s xml:id="_5mKsZCM">Although we cannot easily solve for the optimal signal in this example, the propositions in Section III allow us to characterize it.</s><s xml:id="_7uS9uBF">An optimal signal induces two possible beliefs, whose expectations are illustrated by E μ l [ω] and E μ h [ω] in Figure <ref type="figure">3</ref>. <ref type="foot" target="#foot_13">19</ref> We know that any consumer who buys the product will be just indifferent between buying and not buying (Proposition 5), so that E μ h [ω] = u _ .</s><s xml:id="_wKyJNNU">We also know that any consumer who does not buy will have a posterior that puts zero weight on the possibility that ω ≥ u _ (Proposition 4), so that Supp ( μ l ) ⊆ [0, u _ ).</s><s xml:id="_swUUeHC">Note that, as discussed in the final part of Section III, we cannot simply read the value of E μ l [ω] off the figure and assume E μ l [ω] = 0.</s><s xml:id="_zUGjDCy">For most priors, μ l will have to assign positive weight to ω ∈ (0, u _ ) so that E μ l [ω] &gt; 0. By Bayes plausability, since</s></p><formula xml:id="formula_38">E μ h [ω] = _ u &gt; E μ 0 [ω] , we must have E μ l [ω] &lt; E μ 0 [ω] .</formula><p xml:id="_rRf6GPf"><s xml:id="_5HqX8xw">The firm's optimal strategy is thus to allow a trial which separates consumers into two groups: those who are sure the product is not for them, and those who are just positive enough that they will choose to buy.</s><s xml:id="_EESK3sN">A car salesman, for example, might want to explain frankly that certain classes of buyers should not buy a given car; the credibility that he gains by doing so will then increase the willingness to pay of the remaining customers, ideally just to the point that they will be willing to purchase.</s><s xml:id="_kjF5BqR">Such optimal information provision allows the firm to extract all the consumer surplus.</s><s xml:id="_5E9vXvD">Note that this would not be the case if, in line with previous literature, we had restricted our attention to a parameterized subset of signals.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_uA7pKWC">VI. Extensions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_JqvvMpV">A. Receiver's private information</head><p xml:id="_QD6k8Wy"><s xml:id="_48Y6GSY">Extending our analysis to situations where Receiver has private information is straightforward.</s><s xml:id="_TvvaJUM">Suppose that Sender and Receiver share a prior μ 0 at the outset of the game, and then Receiver privately observes a realization r ∈ R from some signal χ (⋅ | ω) .</s><s xml:id="_6npXFrj">Sender then chooses a signal; Receiver observes its realization and takes her action.</s><s xml:id="_t7kqB9m">We assume that Receiver cannot communicate any of her private information to Sender before Sender selects his signal.</s></p><formula xml:id="formula_39">E h [ω] E h [ω] E [ω] [ω] E 0 [ω] [ω] E E _ u _ u Panel A. Function Panel B. Function E E ˜ v ˜ V ˜ v ˜ v ˜ V ˜ V Figure 3</formula><p xml:id="_z6TNJka"><s xml:id="_8gcKhyq">. Advertising to Increase Sales actions and Sender can send private signals to individual receivers.</s><s xml:id="_nh8Zavz">The crucial problem with this case is that for a given set of beliefs that receivers hold after observing their messages, the receivers' actions may vary as a function of the signal that produced those beliefs.</s><s xml:id="_VK2vaPU">In an auction, for example, a bidder with a given belief may behave differently if she believes that other bidders are receiving highly informative signals than if she believes they are receiving uninformative signals.</s><s xml:id="_fDHzHHf">This means that the key simplifying step in our analysis-reducing the problem of finding an optimal signal to one of maximizing over distributions of posterior beliefs-does not apply.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_RMbEkyT">VII. Conclusion</head><p xml:id="_3KxBhCY"><s xml:id="_Ub4dgqd">There are two ways to induce a person to do something.</s><s xml:id="_3hfbUME">One is to provide incentives, by which we mean anything which changes marginal utility-explicit payments, coercion, or supply of complementary goods.</s><s xml:id="_vTWTPF2">The other is to persuade, by which we mean anything which changes beliefs.</s></p><p xml:id="_D4fhvw7"><s xml:id="_WsA2QnJ">In this paper, we study persuasion in a setting where both Sender and Receiver are rational Bayesians.</s><s xml:id="_9neZzSQ">Perhaps surprisingly, the scope for persuasion under rationality is large.</s><s xml:id="_rDDDvJA">Our results characterize the form persuasion should take in such a setting.</s><s xml:id="_ZBDPwvx">If persuasion in the real world departs from this characterization-for example, if Receivers are systematically harmed by persuasive activity-this suggests that limited rationality may be at play.</s><s xml:id="_PGpFuzT">Appendix: Proofs A. proof of proposition 1 By definition, (ii) implies (i) and (iii).</s><s xml:id="_nhxfZRr">We first show that (i) implies (ii).</s><s xml:id="_2kEYX3S">Given a signal π with value v * , let s a = {s |  a ( μ s ) = a} for each a.</s><s xml:id="_k7fQA6k">Consider a signal with s ′ = A and π ′ (a | ω) = ∑ s∈ s a π (s | ω) .</s><s xml:id="_A7RP6y4">In other words, π′ "replaces" each signal realization with a recommendation of the action that the signal realization induced.</s><s xml:id="_YuS6xGR">Since a was an optimal response to each s ∈ s a , it must also be an optimal response to the realization a from π′ .</s><s xml:id="_k9d4Hkm">Hence, the distribution of Receiver's actions conditional on the state under π′ is the same as under π.</s><s xml:id="_MnfNR58">It remains to show that (iii) implies (i).</s><s xml:id="_AqUPwV5">Consider any v * and any Bayes-plausible τ s.t.</s></p><formula xml:id="formula_40">E τ  v (μ) = v * .</formula><p xml:id="_xqDbC2a"><s xml:id="_TA66NeG">Since Ω is finite, Caratheodory's Theorem implies there exists a Bayes-plausible τ * with finite support such that E τ *  v (μ) = v * .</s><s xml:id="_y37DagX">Now, define s so that Supp( τ * ) = { μ s } s∈s and let π (s | ω) = μ s (ω) τ * ( μ s ) / μ 0 (ω) .</s><s xml:id="_Tf4MWrA">Then simple algebra shows that π is indeed a signal and induces τ * .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_TfYWqUq">B. proof of proposition 2</head><p xml:id="_cnqhzkK"><s xml:id="_y6gZwSd">Suppose there is no information Sender would share:</s></p><formula xml:id="formula_41">∀ μ,  v (μ) ≤ ∑ ω v (  a ( μ 0 ) , ω)μ (ω) . Given a signal π that induces some τ , its value is ∑ s∈s τ s  v ( μ s ) ≤ ∑ s∈s τ s ∑ ω v (  a ( μ 0 ) , ω) μ s (ω) =  v ( μ 0 )</formula><p xml:id="_EXxcSUc"><s xml:id="_K4an3mQ">. Hence, Sender does not benefit from persuasion.</s></p><p xml:id="_dQCHZaz"><s xml:id="_yBgx8gC">Now, suppose there is information Sender would share and Receiver's preference is discrete at the prior.</s><s xml:id="_cCM4zKr">Since u is continuous in ω, ∑ u (  a ( μ 0 ) , ω) μ (ω) is continuous in μ.</s><s xml:id="_qpgWR3h">Therefore, since Receiver's preference is discrete at the prior, ∃ δ &gt; 0 s.t. for all μ in a δ-ball around μ 0 ,  a (μ) =  a ( μ 0 ) .</s><s xml:id="_Bpg95Yp">Denote this ball by B δ .</s><s xml:id="_M5sqNxX">Since there is information Sender would share, ∃ μ h s.t.</s><s xml:id="_fgknNzJ"> v ( μ h ) &gt; ∑ ω v (  a ( μ 0 ) , ω) μ h (ω) .</s><s xml:id="_BxVXycz">Consider a ray from μ h through μ 0 .</s><s xml:id="_9WxXBjf">Since μ 0 is not on the boundary of Δ (Ω) , there exists a belief on that ray, μ l s.t.</s><s xml:id="_KhPhStS">μ l ∈ B δ and μ 0 = γ μ l + (1 -γ) μ h for some γ ∈ (0, 1) .</s><s xml:id="_8sunbH5">Now, consider the Bayes-plausible distribution of posteriors τ ( μ</s></p><formula xml:id="formula_42">l ) = γ, τ ( μ h ) = 1 -γ. Since  a ( μ =  a ( μ l ) ,  v ( μ l ) = ∑ ω v (  a ( μ 0 ) , ω) μ l (ω) . Hence, E τ [  v (μ) ] = γ  v ( μ l ) + (1 -γ)  v ( μ h ) &gt; γ ∑ ω v (  a ( μ 0 ) , ω) μ l (ω) + (1 -γ) ∑ ω v (  a ( μ 0 ) , ω) μ h (ω) =  v ( μ 0 )</formula><p xml:id="_wrqCG23"><s xml:id="_kGZyhas">. Therefore, Sender benefits from persuasion.</s></p><p xml:id="_phsNdMm"><s xml:id="_KvnH9r8">It remains to show that if A is finite, Receiver's preference is discrete at the prior generically.</s><s xml:id="_trvbdGT">Suppose A is finite.</s><s xml:id="_pKgGukC">We begin with the following Lemma: LEMMA 1: if Receiver's preference at a belief μ is not discrete, there must be an action a ≠ </s></p><formula xml:id="formula_43">a (μ) such that ∑ u (  a (μ) , ω) μ (ω) = ∑ u (a, ω) μ (ω) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_QG4BnQy">PROOF:</head><p xml:id="_FHbmB6w"><s xml:id="_DAmhkVX">Suppose there is no such action.</s><s xml:id="_HyNtHyY">Then, we can define an ε &gt; 0 by</s></p><formula xml:id="formula_44">ε = 1 _ 2 min a≠  a (μ) { ∑ u(  a (μ) , ω) μ (ω) -∑ u (a, ω) μ (ω) } . Since A is finite, the minimum is obtained. But then, u (  a (μ) , ω) u (ω) &gt; ∑ u (a, ω) μ (ω) + ε ∀ a ≠  a (μ)</formula><p xml:id="_N3hR26H"><s xml:id="_NyHsVcT">, which means that Receiver's preference is discrete at μ.</s></p><p xml:id="_9BqZjWG"><s xml:id="_bkMEDMN">Given this Lemma, since there are only finitely many pairs of actions a, a′ , and since the union of a finite number of measure-zero sets has measure zero, it will suffice to show that given any distinct a and a′ , the set {μ | ∑ u (a, ω) μ (ω) = ∑ u ( a′ , ω) μ (ω) } has measure zero.</s><s xml:id="_3887S97">Given any distinct a and a′ , index states by i and let β i = u (a, ω i ) -u ( a′ , ω i ) .</s><s xml:id="_JYhGqf4">Let β = [ β 1 , ... , β n ] and μ = [μ ( ω 1 ) , ... , μ ( ω n ) ] .</s><s xml:id="_ZUkJ68y">We need to show that the set {μ | β′μ = 0} has measure zero.</s><s xml:id="_9rt7afH">Recall that for any action a there exists a μ s.t. a * (μ) = {a} .</s><s xml:id="_gDVAkTY">That means that there is necessarily an ω s.t.</s><s xml:id="_hdwmMUU">u (a, ω ≠ u(a′, ω) .</s><s xml:id="_DabUcyF">Hence, there is at least one β i ≠ 0. Therefore, β is a linear transformation of rank 1.</s><s xml:id="_wDTqkzT">Hence, the kernel of β is a vector space of dimension n -1.</s><s xml:id="_ZKMnUh3">Therefore, {μ | β′μ = 0} is measure zero with respect to the Lebesgue measure on ℝ n .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ABA9YYn">C. proof of proposition 3</head><p xml:id="_vzNh6D7"><s xml:id="_B8udHhY">As we mentioned in footnote 13, we will establish a somewhat stronger proposition which implies Proposition 3. Suppose that there exists a linear transformation t</s></p><formula xml:id="formula_45">: Δ (Ω) → ℝ k s.t.  v (μ) = ˜ v (tμ) . Let ˜ V denote the concave closure of ˜ v .</formula><p xml:id="_9zvfn6x"><s xml:id="_nHTDFkk">Then, PROPOSITION 6: sender benefits from persuasion if and only if ˜ V (t μ 0 ) &gt; ˜ v (t μ 0 ) .</s><s xml:id="_2VsV8Ek">PROOF: Suppose ˜ V (t μ 0 ) &gt; ˜ v (t μ 0 ) .</s><s xml:id="_96cVWCr">That implies there exists a z s.t.</s><s xml:id="_kGNENux">z &gt; ˜ v (t μ 0 ) and (t μ 0 , z) ∈ co( ˜ v ).</s><s xml:id="_uwXYrsa">Hence, there exists a set ( t i ) i=1 k+1 w/ t i ∈ Image(t ) and weights γ</s></p><formula xml:id="formula_46">∈ Δ k+1 s.t. ∑ i γ i t i = t μ 0 and ∑ i γ i ˜ v ( t i ) &gt; ˜ v (t μ 0 ) . For each i, select any μ i from t -1 t i . Let μ a = ∑ i=1 k+1 γ i μ i . Since t is linear, t μ a = t ∑ i γ i μ i = ∑ i γ i t μ i = ∑ i γ i t i = t μ 0 .</formula><p xml:id="_TVWkrma"><s xml:id="_ENWK85G">Since μ 0 is not on the boundary of Δ n , there exists a belief μ b and a λ ∈ (0, 1) s.</s></p><formula xml:id="formula_47">t. λ μ a + (1 -λ) μ b = μ 0 . Since t is linear, t μ b = 1/(1 -λ) (t μ 0 -λt μ a ). Therefore, since t μ a = t μ 0 , we have t μ b = t μ 0 . Hence, ˜ v (t μ 0 ) = ˜ v (t μ b )</formula><p xml:id="_HZs7Dnw"><s xml:id="_Hfr3kQw">. Now, consider a signal that induces the distribution of posteriors τ ( μ i ) = λ γ i for i = 1, … , k + 1 and τ ( μ b ) = 1 -λ.</s><s xml:id="_CPp3ESY">Since μ a = ∑ i=1 k+1 γ i μ i and λ μ a +</s></p><p xml:id="_psrxec3"><s xml:id="_kQXUdr8">(1 -λ) μ b = μ 0 , this τ is Bayes-plausible.</s><s xml:id="_FWBymXs">The value of a signal that induces this τ is</s></p><formula xml:id="formula_48">∑ i λ γ i  v ( μ i ) + (1 -λ)  v ( μ b ) = λ ∑ i γ i ˜ v ( t i ) + (1 -λ) ˜ v (t μ 0 ) &gt; λ ˜ v (t μ 0 ) + (1 -λ) ˜ v (t μ 0 ) =  v ( μ 0 ) .</formula><p xml:id="_V3TWcWv"><s xml:id="_DPYsqnZ">Hence, Sender benefits from persuasion.</s><s xml:id="_2GMKpBA">Now suppose ˜</s></p><formula xml:id="formula_49">V (t μ 0 ) ≤ ˜ v (t μ 0 ) . For any Bayes-plausible distribution of posteriors τ, E τ [μ] = μ 0 implies E τ [tμ] = t μ 0 , so E τ [  v (μ) ] = E τ [ ˜ v (tμ) ] ≤ ˜ V (t μ 0 ) ≤ ˜ v (t μ 0 ) =  v ( μ 0 ) . Hence,</formula><formula xml:id="formula_50">(ω) = { μ′ (ω) /(1 -μ′ ( _ ω ) ) 0 if ω ≠ _ ω if ω = _ ω . If we "replace"</formula><p xml:id="_NjAr3sV"><s xml:id="_WbkVGNn">μ′ with a mixture of _ μ and μ _ , this will yield a higher value since Simple algebra reveals that τ * is Bayes plausible and yields a higher value than τ does.</s></p><p xml:id="_nM7MV6V"><s xml:id="_4AVMYag">E. proof of proposition 5 LEMMA 2: if μ′ is induced by an optimal signal, V ( μ′ ) =  v ( μ′ ) .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jW2q9Q6">PROOF:</head><p xml:id="_vSg9rer"><s xml:id="_Uq2WkN3">Suppose that an optimal signal induces τ and there is some μ′ s.t.</s><s xml:id="_TkrS3CM">τ ( μ′ ) &gt; 0 and V ( μ′ ) &gt;  v ( μ′ ) .</s><s xml:id="_yC4G3gY">Since ( μ′ , V ( μ′ ) ) ∈ co (  v ) , there exists a distribution of posteriors τ ′ such that E τ′ μ = μ′ and E τ′  v (μ) = V ( μ′ ) .</s><s xml:id="_uzknubW">But then we can then take all the weight from μ′ and place it on τ ′ which would yield higher value while preserving Bayes plausibility.</s><s xml:id="_Sces237">Formally, consider the distribution of posteriors τ ( μ′ ) τ ′ (μ)</s></p><p xml:id="_tNsrAsn"><s xml:id="_N5YyBux">if μ ∈ Supp ( τ ′ ) \Supp (τ) τ * (μ) = { τ (μ) + τ ( μ′ ) τ ′ (μ) if μ ∈ Supp ( τ ′ ) ∩ Supp (τ) τ (μ)</s></p><p xml:id="_dMKGkj8"><s xml:id="_rMMw3zd">if μ Supp \ (Supp ( τ ′ ) ∪ { μ′ } ) .</s></p><p xml:id="_Bz8RuUw"><s xml:id="_tYgXuxZ">By construction, τ * is Bayes plausible and yields a higher value than τ does.</s></p><p xml:id="_crwjAYr"><s xml:id="_FTbSf79">LEMMA 3: suppose μ l and μ r are induced by an optimal signal and μ m = γ μ l + (1 -γ) μ r for some γ ∈</s></p><formula xml:id="formula_51">[0, 1]. then,  v ( μ m ) ≤ γ  v ( μ l ) + (1 -γ)  v ( μ r ) .</formula><p xml:id="_XEWwVUd"><s xml:id="_qjuUjsQ">PROOF: Suppose to the contrary that τ is induced by an optimal signal, τ ( μ l ) , τ ( μ r ) &gt; 0, and  v ( μ m ) &gt; γ  v ( μ l ) + (1 -γ)  v ( μ r ) .</s><s xml:id="_wDkZNz9">Then we can take some weight from μ l and μ r and place it on μ m which would yield higher value while preserving Bayes plausibility.</s><s xml:id="_QvgvCGX">Formally, pick any ε ∈ (0, 1).</s><s xml:id="_YAKkWsp">Let ε′ = ετ ( μ l ) /τ ( μ r ) .</s><s xml:id="_kkDMhrA">Consider an alternative τ * defined by: τ * ( μ l ) = (1 -γε) τ ( μ l ) τ * ( μ r ) = (1 -(1 -γ) ε′ ) τ ( μ r ) τ * ( μ m ) = τ ( μ m ) + ετ ( μ l ) τ * (μ) = τ (μ) if μ ∉ { μ l , μ m , μ r } .</s></p><p xml:id="_nkfCu3X"><s xml:id="_efCCAZ5">Simple algebra reveals that τ * is Bayes plausible and yields a higher value than τ does.</s></p><p xml:id="_nZW2kcB"><s xml:id="_ReMmDE3">Say that action a is induced dominant if ∀ μ,  v (μ) ≤ ∑ ω v (a, ω) μ (ω) .</s><s xml:id="_EwpSJSM">Say that a is strictly induced dominant if ∀ μ s.t. a ≠  a (μ),  v (μ) &lt; ∑ ω v (a, ω) μ (ω) .</s><s xml:id="_xjumJRA">Say that a is weakly but not strictly dominant (wnsd) if it is induced dominant and ∃ μ s.t. a ≠  a (μ), and  v (μ) = ∑ ω v (a, ω) μ (ω) .</s><s xml:id="_Bqw5yqA">Note that there is information Sender would share if and only if  a ( μ 0 ) is not induced dominant, and that Assumption 1 states that there are no wnsd actions.</s><s xml:id="_BCNG5yB">LEMMA 4: suppose that Assumption 1 holds.</s><s xml:id="_dVc5cAZ">Let μ be an interior belief induced by an optimal signal.</s><s xml:id="_xxu8k2K">then, either: (i) Receiver's preference at μ is not discrete, or (ii)  a (μ) is strictly induced dominant.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_A5ZAz9S">PROOF:</head><p xml:id="_yarAFxU"><s xml:id="_AJhvDxA">Suppose that Assumption 1 holds and μ is an interior belief induced by an optimal signal.</s><s xml:id="_ZdGY5Fr">Now, suppose Receiver's preference at μ is discrete.</s><s xml:id="_WHpMNK9">By Proposition 2, we know that if μ were the prior either: (i) there would be no information Sender would want to share, i.e.,  a (μ) is induced dominant; or (ii) Sender would benefit from persuasion.</s><s xml:id="_GTqmw9j">But, Sender could not benefit from persuasion if μ were the prior because by Lemma 2 we know V (μ) =  v (μ) .</s><s xml:id="_ftK9VHJ">Thus,  a (μ) is induced dominant so by Assumption 1 it is strictly induced dominant.</s></p><p xml:id="_eDdUba6"><s xml:id="_y9DEMXh">LEMMA 5: suppose sender benefits from persuasion, μ is an interior belief induced by an optimal signal, and  a (μ) is strictly induced dominant.</s><s xml:id="_xaNAGmu">then, Receiver's preference at μ is not discrete.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_esWw5Yb">PROOF:</head><p xml:id="_Bpu7GnQ"><s xml:id="_aSwfcYK">Suppose Sender benefits from persuasion, μ is an interior belief induced by an optimal signal, and  a (μ) is strictly induced dominant.</s><s xml:id="_FY7WX88">Since the set of beliefs that induces any particular action is convex, when Sender benefits from persuasion, any optimal signal must induce at least two distinct actions.</s><s xml:id="_djFyYB6">Therefore, there must be a μ′ induced by the signal at which  a (μ) ≠  a (μ′ ).</s><s xml:id="_N8NUeMs">Now, suppose that Receiver's preference at μ is discrete.</s><s xml:id="_j3a8k4B">Then, there is an ε &gt; 0 s.t.</s><s xml:id="_arEWQXx"> a (ε μ′ + (1 -ε)μ) =  a (μ) .</s><s xml:id="_aKjJukD">Let μ m = ε μ′ + (1 -ε) μ.</s><s xml:id="_up5evjw">Since both μ and μ′ are induced by an optimal signal, Lemma 3 tells us that </s></p><formula xml:id="formula_52">v ( μ m ) ≤ ε  v ( μ′ ) + (1 -ε)  v (μ) . But,  v ( μ m ) = ∑ ω v (  a (μ) , ω) μ m (ω) = ε ∑ ω v (  a (μ) , ω) μ′ (ω) + (1 -ε)  v (μ)</formula><p xml:id="_WnKUgQs"><s xml:id="_hnQUrwR">. Hence, the last inequality is equivalent to ∑ ω v (  a (μ) , ω) μ′ (ω) ≤  v ( μ′ ) , which means  a (μ) is not strictly induced dominant.</s><s xml:id="_KKQE46d">Combining Lemma 4 and Lemma 5, we know that if Assumption 1 holds, Sender benefits from persuasion, and μ is an interior belief induced by an optimal signal, Receiver's preference at μ is not discrete.</s><s xml:id="_M9PRTJ9">It remains to show is that if Assumption 1 holds, Sender benefits from persuasion, and a belief μ induced by an optimal signal leads to a best-attainable action, then Receiver's preference at μ is also not discrete.</s><s xml:id="_C5CzCJ9">Suppose to the contrary Assumption 1 holds, Sender benefits from persuasion, an optimal signal π induces μ * which leads to a best-attainable a * , and Receiver's preference is discrete at μ * .</s><s xml:id="_mzJfXSh">Let τ be the distribution of posteriors induced by π.</s><s xml:id="_nnZe9Ft">Since Receiver's preference is discrete at μ * , there is an ε &gt; 0 s.t.</s><s xml:id="_dT7PxCT">μ′ ≡ ε μ 0 + (1 -ε) μ * also leads to a * .</s><s xml:id="_psqSGZG">Moreover, since τ puts positive measure on at most finitely many beliefs, we can select μ′ s.t.</s><s xml:id="_dGd5fd5">τ does not put positive measure on μ′ .</s><s xml:id="_bqZaFAK">Now, let τ ′ be defined as follows:</s></p><formula xml:id="formula_53">τ ′ ( μ′ ) = τ ( μ * ) __ 1 -ε + ε τ ( μ * ) τ ′ (μ) = 1 -ε __ 1 -ε + ε τ ( μ * ) τ (μ) for μ ∉ { μ * , μ′ } τ ′ ( μ * ) = 0.</formula><p xml:id="_sPAUG5N"><s xml:id="_ZC59p6S">Simple algebra shows τ′ is Bayes plausible and has higher value than τ, so we've reached a contradiction.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc><div><p xml:id="_NwtPHCP"><s xml:id="_7aKAcBh">Figure 1.</s><s xml:id="_CDJ9zjq">An Illustration of Concave Closure</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc><div><p xml:id="_Wxq5sEe"><s xml:id="_UraUPxb">by Corollary 1 Sender does not benefit from persuasion.D. proof of proposition 4Suppose that v ( a _ , ω) &lt; v (a, ω) for all ω and all a ≠ a _ .</s><s xml:id="_PDuFW6D">Let Ω _ = {ω |  a ( μ ω ) = a _ } , where μ ω (ω) = 1.</s><s xml:id="_Qm3VkkP">Let _ Ω be the complement of Ω _ .</s><s xml:id="_BemJUVD">Suppose contrary to Proposition 4 that an optimal signal induces τ and there is a belief μ′ s.t.</s><s xml:id="_zKWfpat">τ ( μ′ ) &gt; 0 ,  a ( μ′ ) = a 0. We can express μ′ as a convex combination of</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc><div><p xml:id="_uwsqEq8"><s xml:id="_zzQjfCk">action Sender strictly prefers to a _ while  a ( μ _ ) cannot be any worse for Sender than  a ( μ′ ) = a _ .</s><s xml:id="_rrd2HGV">Formally, consider the following distribution of beliefs:* (μ) = τ (μ) if μ ∉ { μ′ , μ _ , _ μ } .</s></p></div></figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p xml:id="_PzDQenx"><s xml:id="_k66KUQN">int (X) denotes the interior of set X and Δ (X) the set of all probability distributions on X.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p xml:id="_ezmTPeU"><s xml:id="_Yp8yred">If there is more than one action in a * (μ) that maximizes Sender's expected utility, we let  a (μ) denote an arbitrary element of that set.</s><s xml:id="_BzXyHcn">This allows us to use convenient notation such as v (  a (μ) , ω) .</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p xml:id="_xVMtbeh"><s xml:id="_p5ypjFp">Note that Sender cannot benefit by using mixed strategies; for any randomization over signals, there is a single signal that leads to identical outcomes.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p xml:id="_r4auyCm"><s xml:id="_s9CMKdK">Strictly speaking, because s is finite, this is true only for distributions of posteriors with finite support.</s><s xml:id="_s9aWWcN">This, however, is not a substantive restriction, since Ω is also finite.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4"><p xml:id="_ZcjYTAR"><s xml:id="_Ftju5ez"> (X) denotes the set of all subsets of X.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5"><p xml:id="_yjNm3bd"><s xml:id="_GRud9Se">This game is clearly related to persuasion games studied in<ref type="bibr" target="#b21">Milgrom and John Roberts (1986)</ref> with an important difference that Sender can ex ante choose to be imperfectly informed.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6"><p xml:id="_QJfyUnC"><s xml:id="_YRduxUJ">373 US 83, 87 (1963).</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_7"><p xml:id="_pjkMS8t"><s xml:id="_RJckuux">That said, this Supreme Court ruling amplifies the importance of our assumption that the prosecutor fully controls what information is generated.</s><s xml:id="_KnyyV5S">For example, if an unexpected witness comes forward, Brady v. maryland would require the prosecutor to report this even if doing so is suboptimal for him.</s><s xml:id="_gP2BQFv">The extension of the model to cases where Receiver might obtain additional information (Subsection A) allows us to address this issue.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_8"><p xml:id="_MukUDhq"><s xml:id="_r2nhPes">http://www.icmje.org/publishing_10register.html</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_9"><p xml:id="_cZrGGqP"><s xml:id="_PU5e4Dw">As the detailed proof in Appendix A shows, we can also establish a result somewhat stronger than Proposition 3. Suppose there exists a linear t : Δ(Ω) → ℝ k and a ˜ v : ℝ k → ℝ s.t.</s><s xml:id="_vuQXZ3T"> v (μ) = ˜ v (tμ).</s><s xml:id="_fx4g4Tx">Then, Sender benefits from persuasion if and only if ˜ v is below its concave closure at t μ 0 .</s><s xml:id="_pnKWek6">We focus on the case where tμ = E μ [ω] only to simplify the exposition of the result.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_10"><p xml:id="_9rZTuWJ"><s xml:id="_NZ8zYC7">We say μ is degenerate if there is an ω s.t.</s><s xml:id="_jby9N5s">μ (ω) = 1.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_11"><p xml:id="_sNsAzCa"><s xml:id="_m747Hhh">This remark assumes the optimal signal is unique.</s><s xml:id="_nS5v78M">When there are multiple optimal signals, there is an additional complication of comparing the informativeness of sets of signals.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_12"><p xml:id="_aJdM9Wv"><s xml:id="_8rPYKXS">The<ref type="bibr" target="#b17">Lewis and Sappington (1994)</ref> model is more general than the one below because they endogenize prices and allow nonunit demand.</s><s xml:id="_TVWWTZS">However, they allow firms to select from a limited, parameterized set of signals, whereas we study the optimal choice from the set of all possible signals.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_13"><p xml:id="_AbBmtp3"><s xml:id="_XtgGstJ">Recall that an optimal signal need not have more realizations than | A | .</s></p></note>
		</body>
		<back>

			<div type="funding">
<div xml:id="_6sdKqtX"><p xml:id="_UEXDbKX"><s xml:id="_WByK26R">comments.</s><s xml:id="_jhng7Tv">This work is supported by the <rs type="funder">Initiative on Global Markets</rs>, the <rs type="funder">George J. Stigler Center for the Study of the Economy and the State</rs>, the <rs type="funder">James S. Kemper Foundation Faculty Research Fund</rs>, the <rs type="funder">Centel Foundation/Robert P. Reuss Faculty Research Fund</rs>, and the <rs type="funder">Neubauer Family Foundation</rs>, all at the <rs type="funder">University of Chicago Booth School of Business</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_PCt5VmV"><p xml:id="_m2pKPHv"><s xml:id="_8CTBJt2">The only way in which Receiver's private information changes our analysis is that we can no longer construct a deterministic function  a (μ) which specifies Receiver's action at any belief she shares with Sender.</s><s xml:id="_udRFuBg">Rather, for any Sender's belief μ, Receiver's optimal action  a (μ, r) depends on the realization of her private signal and so is stochastic from Sender's perspective.</s><s xml:id="_Vn9SfbG">When his posterior is μ, Sender assigns probability χ (r | ω) μ (ω) to the event that Receiver's signal is r and the state is ω.</s><s xml:id="_WRUEkNZ">Hence, Sender's expected utility when his posterior is μ is:</s></p><p xml:id="_UyR7fkH"><s xml:id="_zhVZsgK">A different situation that involves private information is when Receiver's preferences depend on some parameter θ ∈ Θ which is unrelated to ω.</s><s xml:id="_XR8ZVgb">Again, the impact of private information is that Receiver's optimal action  a (μ, θ) is stochastic from Sender's perspective.</s><s xml:id="_QxR7RHX">We can therefore define  v by integrating over this uncertainty, similarly to equation (3) .</s></p><p xml:id="_ufPZUQp"><s xml:id="_Xt3RZ8a">Finally, suppose that Receiver can gather some additional information following the realization of Sender's signal.</s><s xml:id="_U6mgwYC">For example, in our motivating example, when the judge observes signal realization g, gathering even a small amount of additional information would increase her payoff.</s><s xml:id="_94CE8Zx">In this case  v (μ) will be Sender's expected payoff integrating over the information that Receiver gathers following a signal realization that induces μ.</s></p><p xml:id="_TE33TXR"><s xml:id="_zfQZ4Fy">In all of these cases, our approach applies directly with respect to the reformulated  v .</s><s xml:id="_VqKjATe">In particular, our key simplifying results-Proposition 1, Corollary 1, Corollary 2-still hold.</s><s xml:id="_ZhysyMH">Aside from the fact that constructing  v is slightly more complicated, the analysis of the problem in terms of the properties of  v and its concave closure V proceeds exactly as before.</s><s xml:id="_HGmYqFf">However, because private information will "smooth out"  v , some of our characterization results, such as that Receiver's preference is never discrete at any interior μ induced by an optimal signal, will no longer hold.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jhs2VhV">B. multiple Receivers</head><p xml:id="_VGXpFER"><s xml:id="_bDDjptc">In many settings of interest-politicians persuading voters, firms advertising to consumers, auctions-our assumption that there is a single Receiver is unrealistic.</s><s xml:id="_un2fKUn">Suppose there are n receivers.</s><s xml:id="_e9jdvbu">For ease of exposition we maintain our common prior assumption, which in this setting means that Sender and all receivers share a prior μ 0 over Ω. Sender's utility is now a function of each receiver's action: v ( a 1 , ... , a n , ω) .</s></p><p xml:id="_7aVWk7d"><s xml:id="_P8A43Fg">There are two classes of multiple-receiver models where our results can be extended quite easily.</s><s xml:id="_hmNBmK9">The first is one where Sender sends separate (possibly correlated) messages to each receiver, Sender's utility is separable across receivers' actions, and each receiver cares only about her own action.</s><s xml:id="_AYYa5dH">In this case, we can simply apply our approach separately to Sender's problem vis-à-vis each receiver.</s><s xml:id="_KqectZF">The second class is where Sender can persuade only by revealing public information.</s><s xml:id="_NsAVzcG">In this case, we can compute the outcome following any (common) posterior μ and set  v (μ) to Sender's expected utility from that outcome.</s></p><p xml:id="_RETAUzT"><s xml:id="_Q3mcJpW">There is an important third class of multiple-receiver models, however, where our results do not extend easily: those where the receivers care about each other's</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_bbB8dS7">Optimal Delegation</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niko</forename><surname>Matouschek</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-937x.2007.00471.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SJtayvX">Review of Economic studies</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="293" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alonso, Ricardo, and Niko Matouschek. 2008. &quot;Optimal Delegation.&quot; Review of Economic studies, 75(1): 259-93.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_w4Y67hf">Advertising Content</title>
		<author>
			<persName><forename type="first">Simon</forename><forename type="middle">P</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Regis</forename><surname>Renault</surname></persName>
		</author>
		<idno type="DOI">10.1257/000282806776157632</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Ug7hdhv">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="113" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Anderson, Simon P., and Regis Renault. 2006. &quot;Advertising Content.&quot; American Economic Review, 96(1): 93-113.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Aumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">B</forename><surname>Maschler</surname></persName>
		</author>
		<title level="m" xml:id="_ZhUqHrn">Repeated games with incomplete information</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Aumann, Robert J., and Michael B. Maschler. 1995. Repeated games with incomplete information. Cambridge, MA: MIT Press.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_4KbJNe8">The Tobacco Industry&apos;s Worldwide ETS Consultant&apos;s Project: European and Asian Components</title>
		<author>
			<persName><forename type="first">Joaquin</forename><surname>Barnoya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanton</forename><forename type="middle">A</forename><surname>Glantz</surname></persName>
		</author>
		<idno type="DOI">10.1093/eurpub/cki044</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7anCJTg">European Journal of public Health</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="77" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Barnoya, Joaquin, and Stanton A. Glantz. 2006. &quot;The Tobacco Industry&apos;s Worldwide ETS Consul- tant&apos;s Project: European and Asian Components.&quot; European Journal of public Health, 16(1): 69-77.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_YA5wuZD">Influence through Ignorance</title>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Brocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Carrillo</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0741-6261.2007.00119.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pbVK9C4">RAnd Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="931" to="947" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brocas, Isabelle, and Juan D. Carrillo. 2007. &quot;Influence through Ignorance.&quot; RAnd Journal of Eco- nomics, 38(4): 931-47.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_zTvfaxR">The Supply of Information by a Concerned Expert</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Caplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Leahy</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0013-0133.2004.0228a.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5VPpbeA">Economic Journal</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">497</biblScope>
			<biblScope unit="page" from="487" to="505" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Caplin, Andrew, and John Leahy. 2004. &quot;The Supply of Information by a Concerned Expert.&quot; Eco- nomic Journal, 114(497): 487-505.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_NMZAhF2">Strategic Information Transmission</title>
		<author>
			<persName><forename type="first">Vincent</forename><forename type="middle">P</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joel</forename><surname>Sobel</surname></persName>
		</author>
		<idno type="DOI">10.2307/1913390</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9Z8SyJv">Econometrica</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1431" to="1451" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Crawford, Vincent P., and Joel Sobel. 1982. &quot;Strategic Information Transmission.&quot; Econometrica, 50(6): 1431-51.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_UNSTejw">Authority and Communication in Organizations</title>
		<author>
			<persName><forename type="first">Wouter</forename><surname>Dessein</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-937x.00227</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_82N36ZS">Review of Economic studies</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="811" to="838" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dessein, Wouter. 2002. &quot;Authority and Communication in Organizations.&quot; Review of Economic stud- ies, 69(4): 811-38.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_gVTNhjT">Can Anticipatory Feelings Explain Anomalous Choices of Information Sources?</title>
		<author>
			<persName><forename type="first">Kfir</forename><surname>Eliaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Spiegler</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.geb.2005.06.004</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UrrVPSQ">games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="104" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Eliaz, Kfir, and Ran Spiegler. 2006. &quot;Can Anticipatory Feelings Explain Anomalous Choices of Infor- mation Sources?&quot; games and Economic Behavior, 56(1): 87-104.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_kMUzw9r">Signal Orderings Based on Dispersion and the Supply of Private Information in Auctions</title>
		<author>
			<persName><forename type="first">Juan-Jose</forename><surname>Ganuza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">S</forename><surname>Penalva</surname></persName>
		</author>
		<idno type="DOI">10.3982/ecta6640</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dWC4AyZ">Econometrica</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1007" to="1030" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ganuza, Juan-Jose, and Jose S. Penalva. 2010. &quot;Signal Orderings Based on Dispersion and the Supply of Private Information in Auctions.&quot; Econometrica, 78(3): 1007-30.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_BvtPcYZ">The Informational Role of Warranties and Private Disclosure about Product Quality</title>
		<author>
			<persName><forename type="first">Sanford</forename><forename type="middle">J</forename><surname>Grossman</surname></persName>
		</author>
		<idno type="DOI">10.1086/466995</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EmgQ6Sp">Journal of Law and Economics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="461" to="483" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Grossman, Sanford J. 1981. &quot;The Informational Role of Warranties and Private Disclosure about Prod- uct Quality.&quot; Journal of Law and Economics, 24(3): 461-83.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Jean-Baptiste</forename><surname>Hiriart-Urruty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claude</forename><surname>Lemaréchal</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-56468-0</idno>
		<title level="m" xml:id="_2vt8BQB">Fundamentals of convex Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hiriart-Urruty, Jean-Baptiste, and Claude Lemaréchal. 2004. Fundamentals of convex Analysis. New York: Springer.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_FaeGF42">On the Theory of Delegation</title>
		<author>
			<persName><forename type="first">Bengt</forename><surname>Holmstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_3b2kNpk">Bayesian models in Economic theory</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Boyer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kihlstrom</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Science</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="115" to="141" />
		</imprint>
	</monogr>
	<note type="raw_reference">Holmstrom, Bengt. 1984. &quot;On the Theory of Delegation.&quot; In Bayesian models in Economic theory, ed. M. Boyer and R. E. Kihlstrom, 115-41. New York: Elsevier Science.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main" xml:id="_aP4UQdc">Selling Information</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Horner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrzej</forename><surname>Skrzypacz</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.1526606</idno>
		<idno>Paper 1743</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Yale University Cowles Foun</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">dation Discussion</note>
	<note type="raw_reference">Horner, Johannes, and Andrzej Skrzypacz. 2005. &quot;Selling Information.&quot; Yale University Cowles Foun- dation Discussion Paper 1743.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_CMvf6KG">On the Simple Economics of Advertising, Marketing, and Product Design</title>
		<author>
			<persName><forename type="first">Justin</forename><forename type="middle">P</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">P</forename><surname>Myatt</surname></persName>
		</author>
		<idno type="DOI">10.1257/aer.96.3.756</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_V9yfdue">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="756" to="784" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Johnson, Justin P., and David P. Myatt. 2006. &quot;On the Simple Economics of Advertising, Marketing, and Product Design.&quot; American Economic Review, 96(3): 756-84.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_zCGmnzx">Strategic Communication with Lying Costs</title>
		<author>
			<persName><forename type="first">Navin</forename><surname>Kartik</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-937x.2009.00559.x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HJvT8cy">Review of Economic studies</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1359" to="1395" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kartik, Navin. 2009. &quot;Strategic Communication with Lying Costs.&quot; Review of Economic studies, 76(4): 1359-95.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_UqaJC3x">Emotional Agency</title>
		<author>
			<persName><forename type="first">Botond</forename><surname>K ˝ O Szegi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AMXCHRB">Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="155" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">K ˝ o szegi, Botond. 2006. &quot;Emotional Agency.&quot; Quarterly Journal of Economics, 121(1): 121-55.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_XYV2yjB">Supplying Information to Facilitate Price Discrimination</title>
		<author>
			<persName><forename type="first">Tracy</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">E M</forename><surname>Sappington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DH8fQSx">international Economic Review</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="327" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lewis, Tracy R., and David E. M. Sappington. 1994. &quot;Supplying Information to Facilitate Price Dis- crimination.&quot; international Economic Review, 35(2): 309-27.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_bRbtp2A">One Quarter of GDP Is Persuasion</title>
		<author>
			<persName><forename type="first">Donald</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjo</forename><surname>Klamer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ajEbRhv">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="195" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McCloskey, Donald, and Arjo Klamer. 1995. &quot;One Quarter of GDP Is Persuasion.&quot; American Eco- nomic Review, 85(2): 191-95.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_xvjK6YF">Communication in Settings with No Transfers</title>
		<author>
			<persName><forename type="first">Nahum</forename><forename type="middle">D</forename><surname>Melumad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshiyuki</forename><surname>Shibano</surname></persName>
		</author>
		<idno type="DOI">10.2307/2601016</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_frcuznG">RAnd Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="198" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Melumad, Nahum D., and Toshiyuki Shibano. 1991. &quot;Communication in Settings with No Transfers.&quot; RAnd Journal of Economics, 22(2): 173-98.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_AP7rrps">Good News and Bad News: Representation Theorems and Applications</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Milgrom</surname></persName>
		</author>
		<idno type="DOI">10.2307/3003562</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YSjYBpX">Bell Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="380" to="391" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Milgrom, Paul. 1981. &quot;Good News and Bad News: Representation Theorems and Applications.&quot; Bell Journal of Economics, 12(2): 380-91.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_7BMjAm7">Relying on the Information of Interested Parties</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Milgrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Roberts</surname></persName>
		</author>
		<idno type="DOI">10.2307/2555625</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EvH3yu2">RAnd Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="32" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Milgrom, Paul, and John Roberts. 1986. &quot;Relying on the Information of Interested Parties.&quot; RAnd Journal of Economics, 17(1): 18-32.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_yTva7rq">Financial Anatomy of Biomedical Research</title>
		<author>
			<persName><surname>Moses</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Ray</forename><surname>Dorsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">O</forename><surname>Matheson</surname></persName>
		</author>
		<author>
			<persName><surname>Thier</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.294.11.1333</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5wEMAym">Journal of the American medical Association</title>
		<imprint>
			<biblScope unit="volume">294</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1333" to="1342" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moses, Hamilton III, E. Ray Dorsey, David H. M. Matheson, and Samuel O. Thier. 2005. &quot;Financial Anatomy of Biomedical Research.&quot; Journal of the American medical Association, 294(11): 1333-42.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_ccvVSfd">Incentive Compatibility and the Bargaining Problem</title>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">B</forename><surname>Myerson</surname></persName>
		</author>
		<idno type="DOI">10.2307/1912346</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eCsYrZd">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="73" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Myerson, Roger B. 1979. &quot;Incentive Compatibility and the Bargaining Problem.&quot; Econometrica, 47(1): 61-73.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_ZGvXUSh">Information Disclosure and Unraveling in Matching Markets</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Ostrovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schwarz</surname></persName>
		</author>
		<idno type="DOI">10.1257/mic.2.2.34</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cTzgbS2">American Economic Journal: microeconomics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="34" to="63" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ostrovsky, Michael, and Michael Schwarz. 2010. &quot;Information Disclosure and Unraveling in Matching Markets.&quot; American Economic Journal: microeconomics, 2(2): 34-63.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_t47t7MW">Optimal Information Disclosure</title>
		<author>
			<persName><forename type="first">Luis</forename><surname>Rayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Segal</surname></persName>
		</author>
		<idno type="DOI">10.1086/657922</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YyYUhb2">Journal of political Economy</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="949" to="987" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rayo, Luis, and Ilya Segal. 2010. &quot;Optimal Information Disclosure.&quot; Journal of political Economy, 118(5): 949-87.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main" xml:id="_rXKHGWp">Foundations for Bayesian Updating</title>
		<author>
			<persName><forename type="first">Eran</forename><surname>Shmaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leeat</forename><surname>Yariv</surname></persName>
		</author>
		<idno type="DOI">10.4016/10177.01</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Unpublished</note>
	<note type="raw_reference">Shmaya, Eran, and Leeat Yariv. 2009. &quot;Foundations for Bayesian Updating.&quot; Unpublished.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_unqbgGx">Job Market Signaling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName><surname>Michael</surname></persName>
		</author>
		<idno type="DOI">10.2307/1882010</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bQkjrD8">Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="374" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Spence, A. Michael. 1973. &quot;Job Market Signaling.&quot; Quarterly Journal of Economics, 87(3): 355-74.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
