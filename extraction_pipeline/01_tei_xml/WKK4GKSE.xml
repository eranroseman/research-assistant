<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_WFBF35p">federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data</title>
				<funder>
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000002</idno>
				</funder>
				<funder ref="#_AX4zPzw">
					<orgName type="full">UPMC</orgName>
				</funder>
				<funder ref="#_CVzd3Jq #_aWbrg3N #_3xsQzXd">
					<orgName type="full">NCI</orgName>
				</funder>
				<funder ref="#_ftcwrVQ">
					<orgName type="full">NINDS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Micah</forename><forename type="middle">J</forename><surname>Sheller</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Intel Corporation , 2200 Mission College Blvd. , Santa Clara , CA 95052 , USA.</note>
								<orgName type="institution">Intel Corporation</orgName>
								<address>
									<addrLine>2200 Mission College Blvd.</addrLine>
									<postCode>95052</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brand</forename><surname>Edwards</surname></persName>
							<idno type="ORCID">0000-0002-0433-7159</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Intel Corporation , 2200 Mission College Blvd. , Santa Clara , CA 95052 , USA.</note>
								<orgName type="institution">Intel Corporation</orgName>
								<address>
									<addrLine>2200 Mission College Blvd.</addrLine>
									<postCode>95052</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">G</forename><surname>Anthony</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Intel Corporation , 2200 Mission College Blvd. , Santa Clara , CA 95052 , USA.</note>
								<orgName type="institution">Intel Corporation</orgName>
								<address>
									<addrLine>2200 Mission College Blvd.</addrLine>
									<postCode>95052</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Martin</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Intel Corporation , 2200 Mission College Blvd. , Santa Clara , CA 95052 , USA.</note>
								<orgName type="institution">Intel Corporation</orgName>
								<address>
									<addrLine>2200 Mission College Blvd.</addrLine>
									<postCode>95052</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sarth</forename><surname>Pati</surname></persName>
							<idno type="ORCID">0000-0003-2243-8487</idno>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Center for Biomedical Image Computing and Analytics (CBICA) , University of Pennsylvania , Richards Medical Research Laboratories , Floor 7 , 3700 Hamilton Walk , Philadelphia , PA 19104 , USA.</note>
								<orgName type="department" key="dep1">Center for Biomedical Image Computing and Analytics (CBICA)</orgName>
								<orgName type="department" key="dep2">Richards Medical Research Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<addrLine>Floor 7 3700 Hamilton Walk</addrLine>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Department of Radiology , Perelman School of Medicine , University of Pennsylvania , Richards Medical Research Laboratories , Floor 7 , 3700 Hamilton Walk , Philadelphia , PA 19104 , USA.</note>
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">Perelman School of Medicine</orgName>
								<orgName type="department" key="dep3">Richards Medical Research Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<addrLine>Floor 7 3700 Hamilton Walk</addrLine>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aikaterini</forename><surname>Kotrot</surname></persName>
							<idno type="ORCID">0000-0002-0433-7159</idno>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Department of Diagnostic Radiology , The University of Texas MD Anderson Cancer Center , 1400 Pressler St. , Houston , TX 77030 , USA.</note>
								<orgName type="department">Department of Diagnostic Radiology</orgName>
								<orgName type="institution">The University of Texas MD Anderson Cancer Center</orgName>
								<address>
									<addrLine>1400 Pressler St.</addrLine>
									<postCode>77030</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Department of Cancer Systems Imaging , The University of Texas MD Anderson Cancer Center , 1881 East Rd , 3SCRB4 , Houston , TX 77054 , USA.</note>
								<orgName type="department">Department of Cancer Systems Imaging</orgName>
								<orgName type="institution">The University of Texas MD Anderson Cancer Center</orgName>
								<address>
									<addrLine>1881 East Rd 3SCRB4</addrLine>
									<postCode>77054</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mikhail</forename><surname>Milchen</surname></persName>
							<idno type="ORCID">0000-0001-8734-6482</idno>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Department of Radiology , Washington University School of Medicine , St. Louis , MO 63110 , USA.</note>
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Washington University School of Medicine</orgName>
								<address>
									<postCode>63110</postCode>
									<settlement>St. Louis</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weilin</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> Intel Corporation , 2200 Mission College Blvd. , Santa Clara , CA 95052 , USA.</note>
								<orgName type="institution">Intel Corporation</orgName>
								<address>
									<addrLine>2200 Mission College Blvd.</addrLine>
									<postCode>95052</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Marcus</surname></persName>
							<idno type="ORCID">0000-0001-9501-8104</idno>
							<affiliation key="aff5">
								<note type="raw_affiliation"><label>6</label> Department of Radiology , Washington University School of Medicine , St. Louis , MO 63110 , USA.</note>
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Washington University School of Medicine</orgName>
								<address>
									<postCode>63110</postCode>
									<settlement>St. Louis</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rivka</forename><forename type="middle">R</forename><surname>Colen</surname></persName>
							<idno type="ORCID">0000-0002-0882-0607</idno>
							<affiliation key="aff3">
								<note type="raw_affiliation"><label>4</label> Department of Diagnostic Radiology , The University of Texas MD Anderson Cancer Center , 1400 Pressler St. , Houston , TX 77030 , USA.</note>
								<orgName type="department">Department of Diagnostic Radiology</orgName>
								<orgName type="institution">The University of Texas MD Anderson Cancer Center</orgName>
								<address>
									<addrLine>1400 Pressler St.</addrLine>
									<postCode>77030</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<note type="raw_affiliation"><label>5</label> Department of Cancer Systems Imaging , The University of Texas MD Anderson Cancer Center , 1881 East Rd , 3SCRB4 , Houston , TX 77054 , USA.</note>
								<orgName type="department">Department of Cancer Systems Imaging</orgName>
								<orgName type="institution">The University of Texas MD Anderson Cancer Center</orgName>
								<address>
									<addrLine>1881 East Rd 3SCRB4</addrLine>
									<postCode>77054</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<note type="raw_affiliation"><label>7</label> Hillman Cancer Center , University of Pittsburgh Medical Center , Pittsburgh , PA 15232 , USA.</note>
								<orgName type="department">Hillman Cancer Center</orgName>
								<orgName type="institution">University of Pittsburgh Medical Center</orgName>
								<address>
									<postCode>15232</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<note type="raw_affiliation"><label>8</label> Department of Radiology , University of Pittsburgh , Pittsburgh , PA 15213 , USA.</note>
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">University of Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">&amp;</forename><surname>Spyridon Bakas</surname></persName>
							<idno type="ORCID">0000-0001-8734-6482</idno>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> Center for Biomedical Image Computing and Analytics (CBICA) , University of Pennsylvania , Richards Medical Research Laboratories , Floor 7 , 3700 Hamilton Walk , Philadelphia , PA 19104 , USA.</note>
								<orgName type="department" key="dep1">Center for Biomedical Image Computing and Analytics (CBICA)</orgName>
								<orgName type="department" key="dep2">Richards Medical Research Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<addrLine>Floor 7 3700 Hamilton Walk</addrLine>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<note type="raw_affiliation"><label>3</label> Department of Radiology , Perelman School of Medicine , University of Pennsylvania , Richards Medical Research Laboratories , Floor 7 , 3700 Hamilton Walk , Philadelphia , PA 19104 , USA.</note>
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">Perelman School of Medicine</orgName>
								<orgName type="department" key="dep3">Richards Medical Research Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<addrLine>Floor 7 3700 Hamilton Walk</addrLine>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<note type="raw_affiliation"><label>9</label> Department of Pathology and Laboratory Medicine , Perelman School of Medicine , University of Pennsylvania , Richards Medical Research Laboratories , Floor 7 , 3700 Hamilton Walk , Philadelphia , PA 19104 , USA.</note>
								<orgName type="department" key="dep1">Department of Pathology and Laboratory Medicine</orgName>
								<orgName type="department" key="dep2">Perelman School of Medicine</orgName>
								<orgName type="department" key="dep3">Richards Medical Research Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<addrLine>Floor 7 3700 Hamilton Walk</addrLine>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Leave</surname></persName>
						</author>
						<author>
							<affiliation key="aff9">
								<note type="raw_affiliation">MDACC University of Texas MD Anderson Cancer Center WashU Washington University School of Medicine in St</note>
								<orgName type="department" key="dep1">Anderson Cancer Center</orgName>
								<orgName type="department" key="dep2">School</orgName>
								<orgName type="institution" key="instit1">MDACC University of Texas</orgName>
								<orgName type="institution" key="instit2">WashU</orgName>
								<orgName type="institution" key="instit3">Washington University</orgName>
								<orgName type="institution" key="instit4">of Medicine</orgName>
								<address>
									<settlement>St</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<note type="raw_affiliation">. Louis CNN</note>
								<orgName type="institution">Louis CNN</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_ydjEGhN">federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FCC3C41D1D00B77AC8C4DAD36E593497</idno>
					<idno type="DOI">10.1038/s41598-020-69250-1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T13:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords xml:id="_V2zDnJd">Collaborative data sharing FL Federated learning IIL Institutional incremental learning CIIL Cyclic institutional incremental learning IID Independent</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_UwP9CQW"><p xml:id="_R2rvq8d"><s xml:id="_jJSfekY">Several studies underscore the potential of deep learning in identifying complex patterns, leading to diagnostic and prognostic biomarkers.</s><s xml:id="_cJRsTCw">Identifying sufficiently large and diverse datasets, required for training, is a significant challenge in medicine and can rarely be found in individual institutions.</s><s xml:id="_XvrzrpU">Multi-institutional collaborations based on centrally-shared patient data face privacy and ownership challenges.</s><s xml:id="_ux3EPuv">federated learning is a novel paradigm for data-private multi-institutional collaborations, where model-learning leverages all available data without sharing data between institutions, by distributing the model-training to the data-owners and aggregating their results.</s><s xml:id="_ZScDD5s">We show that federated learning among 10 institutions results in models reaching 99% of the model quality achieved with centralized data, and evaluate generalizability on data from institutions outside the federation.</s><s xml:id="_YqW7wmp">We further investigate the effects of data distribution across collaborating institutions on model quality and learning patterns, indicating that increased access to data through data private multi-institutional collaborations can benefit model quality more than the errors introduced by the collaborative method.</s><s xml:id="_KFHnBpF">finally, we compare with other collaborative-learning approaches demonstrating the superiority of federated learning, and discuss practical implementation considerations.</s><s xml:id="_67kybbE">clinical adoption of federated learning is expected to lead to models trained on datasets of unprecedented size, hence have a catalytic impact towards precision/personalized medicine.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="782.362"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_eWyHCFR"><p xml:id="_8nq7v5Y"><s xml:id="_JVfqJxb">similarly reconstituted the real-world contributions to the BraTS dataset and compared FL model quality under various training conditions.</s><s xml:id="_EnsRCC4">The primary focus was on the performance impact of differentially private training techniques, which may reduce the risk of training data being reverse engineered from model parameters.</s><s xml:id="_Kk8TKfv">Such reverse engineering is one of the many security and privacy concerns that remain for FL, discussed in "Supplementary Information: Security and Privacy".</s></p><p xml:id="_VDNZ55v"><s xml:id="_AF3S4kH">Data private collaborative learning introduces additional restrictions to the training process over that of datasharing (e.g., not shuffling data across participants) as the computational process is not identical (see "Discussion" section).</s><s xml:id="_rMjhS4A">For any given potential collaboration, a crucial question then is whether the increased access to data from data private collaborative learning improves model accuracy more than these restrictions may hamper model accuracy.</s><s xml:id="_mTyVTkp">Here, we take brain cancer as an example, and perform a quantitative evaluation of data-private collaborative learning on the task of distinguishing healthy brain tissue from cancerous tissue, by virtue of their radiographic appearance on clinically-acquired magnetic resonance imaging (MRI).</s><s xml:id="_KnHc8Dw">We reconstitute the original 10 institutional contributions to the data of the largest manually-annotated publicly-available medical imaging dataset (i.e., BraTS <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> ), to form the Original Institution group for our study such that our dataset assignments match the real-world configuration, and further expand our quantitative evaluation to completely independent data from institutions that did not contribute to this dataset. We qu</s><s xml:id="_Yf2tDg8">ntitatively compare models trained by (1)  single institutions, (2) using the data-private collaborative learning methods FL, CIIL, and IIL, and (3) using CDS, by evaluating their performance on both data from institutions within the Original Institution group, and data collected at institutions outside of that group.</s><s xml:id="_baAnz7b">These evaluations reveal that the loss relative to CDS in final model quality for FL is considerably less than the benefits the group's data brings over single institution training.</s><s xml:id="_Fr5nPrY">Though we provide a method for model validation during CIIL that makes it competitive with FL on this group of institutions, the Leave-One-(institution)-Out (LOO) testing on this group highlight the fact that CIIL model quality results are less stable than those of FL (Fig. <ref type="figure" target="#fig_3">4</ref>).</s><s xml:id="_ncNBEsJ">Our findings also indicate that IIL heavily biases the model toward the last model to train, as is discussed in "Supplementary Information: Hyper-Parameter Selection for IIL and CIIL".</s><s xml:id="_anrS2F6">For completeness we discuss practical considerations to be made during implementation, including potential optimizations for training efficiency (see "Supplementary Information: Hyper-Parameter Selection for FL") and ongoing work on mitigations for remaining security and privacy issues (see "Supplementary Information: Security and Privacy"), and also explore more challenging learning environments-both of which further expose the superiority of FL over CIIL (see "Supplementary Information: Further Challenging Model Quality Across Data-Private Collaborative Methods").</s><s xml:id="_quDGNdv">In summary, this present study when compared to our preliminary results <ref type="bibr" target="#b14">15</ref> (i.e., the first evaluation of FL, IIL, and CIIL in the medical domain), provides a far more extensive evaluation and highlights the need and ongoing considerations to address security and privacy issues.</s><s xml:id="_cN9w2kr">Specifically, the extensive evaluation is done through use of additional publicly available data from BraTS <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> and additional private testing data from independent institutions (not included in the BraTS dataset).</s><s xml:id="_BrNybNU">The additional experiments conducted here attempt to evaluate model generalization under various training schemes comprising (1) single institution training, (2) LOO validation, and importantly (3) exhaustively evaluating performance differences between FL, IIL, and CIIL, by exploring convergence, "model selection", and the effect of institutional order for IIL and CIIL.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_66bjAvP">Results</head><p xml:id="_y7qV8G7"><s xml:id="_HpqQnrF">Ample and diverse data are needed.</s><s xml:id="_T4vr9ST">In order to establish the need for more numerous and diverse data at the individual institutions of the Original Institution group, we trained single institution models for each institution in the group, and then evaluated each of these models against held-out validation sets from each of the institutions in the group defined prior to model training (Fig. <ref type="figure" target="#fig_1">2</ref>).</s></p><p xml:id="_JFZQ6tn"><s xml:id="_cZ6PzG3">We note that institutional models perform much lower against data from the other institutions of the group, showing that more ample and diverse data are indeed needed by each institution to train more generalizable models-a fact that is also supported by the results in our next finding.</s><s xml:id="_8AesxuZ">Note also that institution 1 has by far the best generalization performance.</s><s xml:id="_ne4bgUk">Institution 1 also holds the most data in the group (see "Methods: Data" section for more details).</s><s xml:id="_yrE8ghs">The poorest model generalization performances are shown on institutions 2, 3 and 6, which have the smallest data contributions of the group.</s><s xml:id="_FTcNJ9Z">collaborative learning is superior.</s><s xml:id="_WhjSPUd">We evaluate the benefits of collaborative learning with respect to improving both scores on an institution's own data, and the generalization performance to data from unseen institutions.</s><s xml:id="_9Jw6ejQ">In both evaluations, we compare models trained only on data from each single institution against models trained collaboratively using CDS and FL.</s><s xml:id="_KBMNWUD">To evaluate the first goal, we compare models over the single institutions' local held-out validation sets (For more details see " Methods: Data" section) to determine whether a given institution can improve performance on its own data by collaborating.</s><s xml:id="_mnH785g">To evaluate the second goal, we compare models over data from institutions that did not participate in the Original Institution group.</s></p><p xml:id="_vknMye7"><s xml:id="_zhVdCMU">Figure <ref type="figure" target="#fig_2">3</ref> shows the average (over experimental runs) of the model quality (Dice) results for single institution, CDS, and FL models, measured against the local (single institution) validation sets.</s><s xml:id="_wq5SMPc">Notably, averaging over institutions, the CDS model performance is 3.17% greater than the single institution models on their own validation data, and for FL the increase is 2.63% (percent improvements are shown in Table <ref type="table" target="#tab_0">S1</ref>).</s></p><p xml:id="_WpctTct"><s xml:id="_5Durx57">Table <ref type="table" target="#tab_0">1</ref> includes the average mean and standard deviation of test Dice results of models trained using CDS, FL, and data of each single institution, as well as using a LOO schema, where each institution is held out in turn as the test set.</s><s xml:id="_VFfMHYC">Here, test performance exposes an even broader gap in model quality between the single institution and collaborative models (both CDS and FL).</s></p><p xml:id="_zwjAWGt"><s xml:id="_XrHTXGg">We see the benefits of collaboration for the ten institutions in our study, both in terms of their own data and in terms of external test data, as rooted in the inherent diversity that can come from data collection across multiple  <ref type="bibr" target="#b33">34</ref> ) for the Original Institution group (y-axis) measured against all single institution held-out validation sets (x-axis) using multiple runs of five-fold collaborative cross validation.</s><s xml:id="_pSVrbtt">The Y axis represents models trained on a single institutional dataset, and the X axis represents the validation dataset of each independent institution (Local Validation Dataset).</s><s xml:id="_9BNwBzd">"AVG" indicates the average of each institution mean model performance over all institutions in the group other than itself, "W-AVG" denotes the same, but with a weighted average according to each institution's contribution to the validation set size.</s><s xml:id="_kAH6Vrk">The diagonal entries indicate how well each institution's final models scored against their own validation set, and they are represented as the Single Institutional Model (SIM) results reported in Fig. <ref type="figure" target="#fig_2">3</ref>. institutions.</s><s xml:id="_S2dQC64">Collaborative training across multiple institutions is a natural means by which to address the need that deep learning models have for ample and diverse data.</s></p><p xml:id="_vCE9NFs"><s xml:id="_bgWH5wB">fL performs comparably to data-sharing.</s><s xml:id="_u9cxpRr">Table <ref type="table" target="#tab_0">1</ref> shows the mean model test Dice of models trained using FL on the Original Institution group.</s><s xml:id="_FYWcqhy">Specifically, for the LOO results, the collaborative method is carried out with one institution held-out from training, the held-out data to be used as the test set for the resulting models.</s><s xml:id="_Dz7SGCG">The 'LOO Test' results reported in Table <ref type="table" target="#tab_0">1</ref> are the weighted average over institutional LOO tests, weighted by the test institution contribution.</s><s xml:id="_Z37EdMr">These LOO results differentiate FL from IIL and CIIL, and do not include single institution models as these are not trained using data from multiple institutions.</s><s xml:id="_aBDxPNx">The per-institution LOO results  can be found in the Supplementary Information Section "Extended Data".</s><s xml:id="_aEj3WTF">Notably FL performs within 1% Dice of CDS on the three test sets, as well as for the LOO tests (on average).</s><s xml:id="_rbs4jp9">In order to compare the rates of model improvement, we plotted global validation Dice over epoch for all collaborative methods (Fig. <ref type="figure" target="#fig_3">4</ref>) and show that FL training converges relatively quickly to the same performance as CDS training.</s><s xml:id="_tG54GYc">A CDS epoch is defined to be a complete training pass over the shared data, whereas an FL epoch is defined as a parallel pass of all institutions over their own data.</s><s xml:id="_xYpKCFh">Averaging epochs from single institution training updates (i.e., FL) is not as efficient as CDS training, which shuffles the institutions' datasets together, but both approaches eventually converge to the same performance.</s><s xml:id="_sNhVChY">Here we measure that FL final models took on average 2.26 × as many epochs to train when compared to CDS final models (with a stopping criterion of 10 epochs with no improvement in the best validation DC observed).</s><s xml:id="_Y2jNV3v">We also include learning curves for other data-private collaborative methods (Fig. <ref type="figure" target="#fig_3">4</ref>).</s></p><p xml:id="_c4JWRRT"><s xml:id="_sWeZfpW">Model learning during fL is more stable than during incremental methods.</s><s xml:id="_PePbvfm">To identify the superiority of a single data-private collaborative method, we compared the learning performance of FL with IIL and CIIL.</s><s xml:id="_M5rZb2r">FL achieves the best rate of model improvement over epoch of the data-private collaborative learning methods (Fig. <ref type="figure" target="#fig_3">4</ref>).</s><s xml:id="_GzetSFW">In addition, the more erratic nature of the IIL and CIIL curves (compared to both FL and CDS) expose an inefficiency in their training, a topic that we return to in the "Discussion" section.</s><s xml:id="_8WSUmhE">Note that an epoch for IIL and CIIL is defined as a pass of one institution over its training data.</s></p><p xml:id="_vZZaS7Q"><s xml:id="_EUVGrTV">The results in Table <ref type="table" target="#tab_0">1</ref> also show that FL results in better models on average than every other data-private method on the Original Institution group.</s><s xml:id="_WznDASP">For CIIL, "best local" and "random local" are two methods we introduce for final model selection (see "Methods: Final Model Selection" section), as the only such methods considered by Chang et al. <ref type="bibr" target="#b13">14</ref> , was that of keeping the model resulting from the last training cycle of a predetermined number of cycles (see "Discussion" section for more information regarding their final model selection).</s><s xml:id="_HcdvbEu">CIIL "best local" is the best competing data-private method, producing models of quality that is generally less than, but very close to FL (see "Supplementary information: Hyper-Parameter Selection for IIL and CIIL" for results regarding the choice of institutional order used in IIL and CIIL).</s><s xml:id="_yBKvWpn">The experiments on the LOO groups (Table <ref type="table" target="#tab_0">1</ref>) show, however, that CIIL "best local" can be less stable, as the standard deviation of model quality is twice or more that of both CDS and FL.</s><s xml:id="_gJswgmW">See "Supplementary Information: Further Challenging Model Quality Across Data-Private Collaborative Methods", for experiments on a more challenging hypothetical group of institutions for which CIIL "best local" final model quality mean drops further below that of FL, with an even larger standard deviation relative to FL.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_KEg5ssn">Discussion</head><p xml:id="_mcT5me2"><s xml:id="_K2xryY4">This study shows that data-private collaborative learning approaches, and particularly FL, can achieve the full learning capacity of the data while obviating the need to share patient data, and hence facilitate large-scale multiinstitutional collaborations, while overcoming technical and data ownership concerns and assisting towards meeting the requirements of data protection regulations (e.g., the European General Data Protection Regulation (GDPR) <ref type="bibr" target="#b23">24</ref> , and the Health Insurance Portability and Accountability Act (HIPAA) of the United States) <ref type="bibr" target="#b24">25</ref> .</s><s xml:id="_K8j6fQ7">This finding can potentially pave the way towards shifting the paradigm of multi-institutional collaborations.</s><s xml:id="_tX87JN5">Model training using FL across multiple authentic institutional datasets performs comparably to model training using CDS (Table <ref type="table" target="#tab_0">1</ref>, Figs. <ref type="figure" target="#fig_2">3</ref>, <ref type="figure" target="#fig_3">4</ref>).</s><s xml:id="_FU4j2RQ">The use of FL over CDS has the immediate advantage of raw data confidentiality, and current technologies can be incorporated into FL to aid in alleviating additional privacy concerns (discussed below).</s><s xml:id="_wUNBsGm">We expect for domains such as medicine, that the development of such solutions will allow for dataprivate collaborative training over data of unprecedented numbers and diversity.</s><s xml:id="_rmm8uAp">Such collaborations are likely to result in a significant jump in the state of the art performance for these models.</s></p><p xml:id="_XF5UMgg"><s xml:id="_mTJCFva">Previous work on CIIL (Chang, et al. <ref type="bibr" target="#b13">14</ref> ) performs final model selection by keeping the last model trained after a predetermined number of cycles.</s><s xml:id="_9Nsf9WE">Selecting final models from all locally trained models in this way, makes sense provided models can be consistently validated, and scores shown to be (more or less) non-decreasing.</s><s xml:id="_tTrZvu5">Chang et al. <ref type="bibr" target="#b13">14</ref> , held out a global validation set for consistent validation, and their results indeed show a non-decreasing trend.</s><s xml:id="_nuWZm4m">We do not see a non-decreasing trend as something one can rely on in general.</s><s xml:id="_mRaDdSr">We think that Chang et al. <ref type="bibr" target="#b13">14</ref> was an exceptional case driven by some intrinsic characteristic of their data (such as the IID nature of the data at their hypothetical institutions), and indeed our results confirm that on the contrary a quasi-periodic pattern can be observed.</s><s xml:id="_CPWg9gn">Moreover, CIIL in practice does not allow for anything but local validation.</s><s xml:id="_UkWyss6">Though we use global validation results to assess the quality of CIIL models, no such set is available to a collaboration in practice without sharing data.</s><s xml:id="_mEGK5vh">Additionally for CIIL, only two of all collaborators ever see any one given model, preventing the aggregation of local validation on the same model that FL uses to obtain global validation results for its model selection process.</s><s xml:id="_GJnr9zA">As a result, we introduce the "random local" and "best local" model selection methods, and consider "random local" as the method closer to Chang et al. <ref type="bibr" target="#b13">14</ref> as it requires less communication.</s><s xml:id="_e3XKaC3">We find that "best local" significantly outperforms "random local" in our setting.</s></p><p xml:id="_Fc9Z7ve"><s xml:id="_rzP37MC">Following its performance evaluation, we favor FL over IIL and CIIL as a more principled way to perform multi-institutional data-private collaborative learning.</s><s xml:id="_qnRcrKN">The individual institutional training that occurs during all of FL, IIL, and CIIL is biased in as much as that institution's data patterns differ from that of the union of data used for CDS training.</s><s xml:id="_UhuzKXz">In the case of FL however, the results of institutional training are aggregated at the end of each round, mitigating this bias.</s><s xml:id="_FUHSQMG">In IIL, a type of aggregation exists as subsequent institutional training blends knowledge into the models it receives from the previous institution, however this aggregation favors institutions that train later in the cycle, and no mitigation exists for bias introduced by the last institution.</s><s xml:id="_tv8Wycz">See "Supplementary Information: Hyper-Parameter Selection for IIL and CIIL" for further evidence of this bias during IIL.</s><s xml:id="_yxGY3Rq">CIIL further mitigates individual institutional bias, by limiting the number of epochs each institution trains before passing it forward, and by incorporating repeated cycling in an effort to enhance the type of aggregation that occurs during incremental training.</s><s xml:id="_p9GgNcW">The differences in the time-scale and quality of aggregation that occurs during FL versus IIL and CIIL, create qualitative differences in their training curves (Fig. <ref type="figure" target="#fig_3">4</ref>).</s><s xml:id="_2xVc9f3">The short-term performance drops within the IIL training curve in Fig. <ref type="figure" target="#fig_3">4</ref> indicate that when an institution trains, it can significantly reduce previously established performance.</s><s xml:id="_zVMC57y">Likewise, the CIIL curves clearly show a quasiperiodic pattern formed by re-visiting these performance drops while cycling over the institutions.</s><s xml:id="_dDVB5TE">We see this behavior as indicative of catastrophic forgetting <ref type="bibr" target="#b17">18</ref> .</s><s xml:id="_uN5pCuZ">The forgetting is not complete, as is evidenced by the fact that model improvement is still achievable for CIIL over cycles.</s><s xml:id="_HF2eaSG">However, these patterns do expose an inefficiency in the training processes of both IIL and CIIL.</s></p><p xml:id="_QbUZVMs"><s xml:id="_YVvsnG9">Consistent with the findings of Zech et al. <ref type="bibr" target="#b0">1</ref> , the CDS models for the Original Institution group still appear to suffer from a lack of diverse data, scoring an average of 11% and 5% lower Dice on the data from institutions outside of the Original Institution group (Table <ref type="table" target="#tab_0">1</ref>, Fig. <ref type="figure" target="#fig_2">3</ref>).</s><s xml:id="_mYjxWA4">Though our institutional datasets are somewhat limited to be representative of a standard CDS contribution, we expect that data privacy and ownership concerns prevent near-term multi-institutional CDS collaborations large enough to overcome institutional biases and build models that widely generalize.</s><s xml:id="_HBCzWT8">We believe the data privacy that FL enables will be a catalyst for the formation of much larger collaborations, leveraging data throughout the world, since the data will be retained within their acquired institutions.</s><s xml:id="_VkBY4Wf">Hence FL models will substantially benefit by continually learning on new data, compensating for the current relatively inferior performance compared to CDS models.</s><s xml:id="_48F3p6R">Additionally, some settings may allow for this gap to be further closed, as we further describe in the Supplementary Section "Hyper-Parameter Selection for FL".</s></p><p xml:id="_axeDWhh"><s xml:id="_JaeAyzv">Although the data are not centrally shared in FL, sources of variation across equipment configurations and acquisition protocols require careful consideration.</s><s xml:id="_GXzAY86">For example, the highest throughput of medical images is produced during standard clinical practice, where the uncontrolled and varying acquisition protocols make such data of limited use and significance in large-scale analytical studies.</s><s xml:id="_4Gh2TSr">In contrast, data from more controlled environments (such as clinical trials) are more suitable <ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27</ref> .</s><s xml:id="_QRE45xe">To appropriately address this issue, common preprocessing routines should be considered and shared that account for harmonization of heterogeneous data (e.g., image resampling, orientation to a standardized atlas), allowing for integration and facilitating easier multi-institutional collaboration for large-scale analytics (see "Methods: Data" for details).</s></p><p xml:id="_vufFeaN"><s xml:id="_eHXztJJ">This study focused on the evaluation of data-private collaborative methods in radiographic imaging data.</s><s xml:id="_vnvMecp">Specifically, following the performance evaluation presented here, the findings of this study support the superiority of FL when compared with IIL and CIIL, particularly on computational models for distinguishing healthy brain tissue from cancer, by virtue of their radiographic appearance.</s><s xml:id="_NAXPdRc">Technically, one can assume that similar results might be expected for other medical deep learning use cases, since generally FL should be able to approach CDS by increasing the rate of synchronization at the cost of network communication overhead.</s><s xml:id="_AdpwpBk">However, we acknowledge that the synchronization used in this study (1 epoch per synchronization, i.e., federated round) may be insufficient for data such as electronic health records <ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29</ref> and clinical notes, as well as genomics, where more variance might be present across international institutions.</s><s xml:id="_yvVZMZa">Notably, we did not perform hyper-parameter tuning specifically to FL.</s><s xml:id="_HcrBQqw">Further evaluation should be considered for the application and generalizability of data-private collaborative learning in other medical applications, beyond radiographic imaging, including exploration on variations in data sizes, institutional bias, as well as number and sequence of institutions.</s></p><p xml:id="_RQKBX7v"><s xml:id="_Gxt5QeB">While data-private collaborative learning methods keep patient records confidential and allow multi-institutional training without sharing patient data, we caution that privacy risks still exist, since model parameters and the training execution are distributed among the collaborators.</s><s xml:id="_zKR5b8f">Studies have shown that training data may be approximated from the model weights <ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31</ref> .</s><s xml:id="_EVc4cKG">Model parameters necessarily encode information about their training data, which attackers may extract <ref type="bibr" target="#b29">30</ref> .</s><s xml:id="_SBDXdN2">In FL, CIIL, and IIL the training algorithm is shared with multiple parties, each of which can tamper with some portion of the training.</s><s xml:id="_zC6Kn5W">A malicious participant may tamper with training to cause the model to encode more information about others' training data than is necessary for the model task, improving the attacker's ability to approximate training data <ref type="bibr" target="#b31">32</ref> .</s><s xml:id="_E8bGnqd">Thus, while data-private collaborations offer clear privacy advantages over CDS, collaborators must still conduct privacy analyses and consider possible mitigations such as tamper-resistant hardware and proper identity management.</s><s xml:id="_6mNzFxn">See "Supplementary Information: Security and Privacy" for a discussion on such threats and mitigations.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_4jdgdPd">Methods</head><p xml:id="_8sKK3zb"><s xml:id="_VyYvfQR">Data.</s><s xml:id="_Bc5Jp9R">We use the task of distinguishing healthy brain tissue from tissue affected by cancer cells as the case study in evaluation of FL against CDS on a medical imaging task.</s><s xml:id="_CV4aQAG">We used the BraTS 2017 training dataset <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> to form our institutional training and test datasets. We fu</s><s xml:id="_8Q2uaHy">her formed two additional test sets by utilizing independent additional clinically-acquired brain tumor MRI scans from the University of Texas MD Anderson Cancer Center (MDACC) and Washington University School of Medicine in St. Louis (WashU).</s><s xml:id="_57MthWG">The complete BraTS 2017 high grade glioma data were collected from 13 different institutions, and consist of a training set of 210 patient scans, (collected from 10 different institutions), and additional validation and testing sets of 33 and 116 patients, respectively.</s><s xml:id="_NcQxsVM">The WashU and MDACC data consist of 18 and 29 patients, respectively.</s><s xml:id="_hFndWRv">All these data reflect true clinical practice of radiographically scanning patients diagnosed with gliomas, and consist of multimodal magnetic resonance imaging (MRI) comprising pre-and post-contrast T1-weighted, T2-weighted, and T2-weighted Fluid Attenuated Inversion Recovery (T2-FLAIR) scans.</s></p><p xml:id="_ef8fAct"><s xml:id="_bvBHZC6">The radiographically abnormal regions of each image were annotated and approved by multiple clinical experts at each contributing institution following a pre-defined annotation protocol.</s><s xml:id="_444cq9W">The annotated regions included 3 distinct label masks indicating (1) peritumoral edematous/infiltrated tissue, (2) non-enhancing/ solid and necrotic/cystic tumor core, and (3) enhancing tumor regions.</s><s xml:id="_PHuqmb3">The raw brain scans were rigidly coregistered to a common anatomical atlas <ref type="bibr" target="#b32">33</ref> , resampled to an isotropic resolution of 1 mm 3 to make the size of each scan consisting of 155 axial 2D slice images of 240 × 240 resolution, and skull-stripped.</s><s xml:id="_zW3HRc7">The data were further pre-processed to be made suitable for the specific task of our study, where the affected brain tissue is defined as the union of all three labels described above <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> . Furth</s><s xml:id="_3fcn6K3">rmore, following the BraTS annotation protocol we eliminated all but the T2-FLAIR modality.</s></p><p xml:id="_9pjyTfh"><s xml:id="_DMpu9fQ">From the BraTS 2017 training data, we sharded the data across 10 institutions, to match the real-world configuration of the 10 contributing institutions.</s><s xml:id="_YnEtbMp">We call this the Original Institution sharding.</s><s xml:id="_N5MJYWs">The resulting patient counts for each of the shards, which we will refer to as institutions 1-10 are given as 88, 22, 34, 12, 8, 4, 8, 14, 15, and 5 patients respectively.</s><s xml:id="_amubc9v">Additionally, we formed the Original Institution LOO groups from the Original Institution group, by variously holding out each one of the ten original institutions.</s><s xml:id="_fqUn655">The LOO groups represent additional examples of authentic institutional groups.</s></p><p xml:id="_bKanFe7"><s xml:id="_u4MWdeP">Furthermore, for each institution of the collaborative group we hold out a validation set from their data, i.e., local validation set.</s><s xml:id="_VQFjt4w">We call the union of local validation sets the global validation set.</s><s xml:id="_jkghtbT">These validation sets are used for final model selection as described below.</s></p><p xml:id="_pXGT4vd"><s xml:id="_Y2sVgnF">In order to reduce bias due to local validation set selection, we perform what we call "collaborative cross validation".</s><s xml:id="_faXSPMf">In collaborative cross validation, each institution's dataset is partitioned into approximately 5 equal folds (indexed partitions), while ensuring that the 155 2D slices coming from a single patient scan end up in the same fold.</s><s xml:id="_AdJ2mf7">Every experiment with a different model initialization is performed for five runs, each run using a different fold index to determine the validation fold at every institution.</s><s xml:id="_fgvWXBR">The other four fold indices correspond to the folds that form the training set for every institution during that run.</s><s xml:id="_ugkTTXA">Note that institution 6, holding only 4 patients, will have one empty fold.</s><s xml:id="_eVGKmK7">During CDS and FL, the run for which this fold number is selected is run as usual with no local validation step for institution 6, whereas during IIL, CIIL, and single institution 6 training this run is skipped.</s><s xml:id="_maQks27">All experimental results in this work report average results over multiple instances of collaborative cross validation, with each instance using a different model initialization.</s><s xml:id="_KzJzNYs">Note that collaborative cross validation defines multiple iterations of coordinated local training and validation splits.</s><s xml:id="_YGaMB3F">As we specify for each experiment we perform, the validation scores reported may come from validating against the global validation set (union of all local validation sets), or from a local validation set belonging to a particular institution.</s></p><p xml:id="_FAjbKR5"><s xml:id="_6KXkM5D">The BraTS 2017 validation data were combined with 22 cases from the BraTS 2017 test data (moved to the validation set for BraTS 2019) to form one test set for our study, which we call BTEST.</s><s xml:id="_K3mfjye">(These images are now provided to BraTS 2019-2020 participants during the competition for method development and fine-tuning, and not for ranking purposes.</s><s xml:id="_xbcE8FU">Intel possessed the BraTS 2017-2018 training data having been participants in BraTS 2018 (as the training data were the same for 2017 and 2018).</s><s xml:id="_HtY85b2">The binarized whole tumor (WT) labels for the BraTS 2017 validation data and the additional 22 BraTS 2017 test cases that were moved to BraTS 2019 validation set, were provided to the lead author Micah Sheller after the conclusion of the BraTS 2018 competition and under a signed Non-Disclosure Agreement.</s><s xml:id="_jxBWRvB">The data were held for calculation, avoiding exposure to a third party, and will be deleted upon publication of this manuscript.)</s><s xml:id="_Bb8scsm">Both WashU and MDACC did not contribute data to the BraTS 2017 training dataset or in the formulated BTEST data, and as such their data is used to test generalization to data from outside institutions.</s><s xml:id="_YkWBfZm">Models resulting from training on each of the Original Institution LOO groups are tested against the data owned by the institution held out to form the group.</s><s xml:id="_wyKW3uG">final model selection.</s><s xml:id="_7Jr4wpY">Following standard practice, the final model for individual institutional training is taken as the one that achieves the best local validation score over the course of training.</s><s xml:id="_EQVXCVP">For CDS, final model selection can similarly be made using global validation scores.</s><s xml:id="_wGGXuUs">During FL, each institution locally validates any model it receives from the central aggregation server, i.e., at the start of each federated round.</s><s xml:id="_PfNwqAH">These local validation results are then sent to the aggregation server along with the model updates to be aggregated with the other institutional results.</s><s xml:id="_WbSsP6R">In such a way, global validation results can be naturally obtained during FL for final model selection.</s></p><p xml:id="_VTjYzdR"><s xml:id="_QR23Mys">Final model selection is harder for IIL and CIIL, than for FL and CDS, as generally no single model is seen by all institutions.</s><s xml:id="_HHGzsfg">Therefore, a complete set of local validation scores cannot be computed within these methods' natural framework.</s><s xml:id="_f6BW9Tc">For CIIL, previous work <ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15</ref> did not provide any final model selection mechanism.</s><s xml:id="_mEME2sk">Here, we introduce and explore two final model selection methods that keep close to the minimal communication costs of CIIL.</s><s xml:id="_zF9j4XR">For both these methods, each institution saves the best locally validated model.</s><s xml:id="_mGPfakF">After the last training cycle, the final model is either randomly selected from one of the locally best models (which we call "random local") or all locally selected models and corresponding local validation results are passed around in order to select the best local model according to global validation (which we call "best local").</s><s xml:id="_5SsB8Ym">We stress that CIIL "best local" requires more communication between institutions than was originally designed for <ref type="bibr" target="#b13">14</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7ZgNPSr">Model quality metric.</head><p xml:id="_RjgeS3w"><s xml:id="_gPuqbY2">To evaluate model quality on a particular test sample, we use a measure (Dice Similarity Coefficient <ref type="bibr" target="#b33">34</ref> , also known as Dice) in the range [0,1] for the similarity between the model prediction on the test sample features, and the sample's ground truth mask label.</s><s xml:id="_TK2WSCp">If P and T are the prediction and ground truth masks respectively, Dice is defined as: where • is the Hadamard product (component-wise multiplication), and 1 is the L1-norm (sum on the absolute values of all components).</s></p><p xml:id="_eTyP6ds"><s xml:id="_zJTsMRh">For the model training loss, we took the negative log of Dice, and explored multiple values for the Laplace smoothing [s terms in Eq. ( <ref type="formula">2</ref>)].</s><s xml:id="_wUuupzr">After algebraically rearranging this loss function, we obtained:</s></p><formula xml:id="formula_0">(1) Dice = 2�P • T� 1 + 1 �P� 1 + �T� 1 + 1</formula><p xml:id="_BtH8kQa"><s xml:id="_B8QzSTz">the U-net model.</s><s xml:id="_SCA9Ajy">For our analysis, we implemented a U-Net topology of a deep Convolutional Neural Network (CNN) <ref type="bibr" target="#b34">35</ref> , in TensorFlow, and made the source code publicly available at: <ref type="url" target="https://github.com/IntelAI/unet/tree/master/2D">https ://githu b.com/Intel AI/  unet/tree/maste r/2D</ref> (commit: eaeac1fc68aa309feb00d419d1ea3b43b8725773).</s><s xml:id="_TmHKhCH">All experiments use a dropout parameter of 0.2, upsampling set to true, and args.featuremaps</s><s xml:id="_6yzQ28v">set to 32.   training hyper-parameters.</s><s xml:id="_Hc3RwJk">See "Supplementary Information" for a table summarizing all the hyperparameters considered in this study.</s><s xml:id="_2UuUB8V">All institutional training in our experiments use mini-batch stochastic optimization and the Adam optimizer <ref type="bibr" target="#b35">36</ref> , thus require batch size and Adam optimizer hyper-parameters <ref type="bibr" target="#b35">36</ref> (adam learning rate, adam first moment decay parameter, and adam second moment decay parameter).</s><s xml:id="_RB7jUTc">Additionally, our training loss function requires the smoothing parameter (Laplace smoothing) the 's' of Eq. ( <ref type="formula">2</ref>) in "Model Quality Metric".</s><s xml:id="_sgsSSs2">These are the only hyper-parameters required for individual institutional training and CDS, and are shared by FL, IIL and CIIL.</s></p><p xml:id="_eAZEuRh"><s xml:id="_xPHq4fw">When using the Adam optimizer during FL, each institutional training session results in a distinct final state for Adam's first and second moments.</s><s xml:id="_ujvKBhx">A natural question arises as to whether it is best to aggregate these moments to be used by every institution in the next training session, or whether it is better to carry forward the optimizer states in some other way.</s><s xml:id="_nxJrM3n">We considered this choice to be an FL-specific hyper-parameter (optimizer state treatment).</s><s xml:id="_F5ctfQB">In addition, for FL training one needs to determine how many epochs of training to apply at each institution per round (epochs per round), which here we only consider as the same number for all institutions and rounds.</s><s xml:id="_DUGzhxu">One also needs to determine what percentage of institutions to randomly select for participation on each round (institutions per round).</s></p><p xml:id="_XtSMMvA"><s xml:id="_yAYGnSu">Similar to FL, IIL and CIIL also have specific hyper-parameters.</s><s xml:id="_R8ExrZU">No hyper-parameters are associated with the Adam optimizer for institutional training, as for IIL and CIIL we pass the values of the Adam first and second moments along with the model for continued training.</s><s xml:id="_uS6UUt5">Specifically needed for IIL however, is the determination of the number of epochs with no validation improvement (over best so far) before passing the model to the next institution (patience), as well as how to order the institutions for the serial training process (institution order).</s><s xml:id="_3cTeTen">For CIIL training one needs to determine how many epochs of training to apply at each institution (epochs per institution per cycle), as well as how to order the institutions for each training cycle (institution order).</s><s xml:id="_rfrJHQq">We consider only the same patience value for all institutions during IIL, the same institution order to made during every cycle of CIIL, and the same epochs per institution per cycle to be applied at every institution for every cycle of CIIL.</s></p><p xml:id="_GVBURtF"><s xml:id="_FKfFrGK">For all institutional training we chose a batch size of 64, and used the Adam optimizer with adam first moment decay parameter of 0.9 and adam second moment decay parameter of 0.999.</s><s xml:id="_FyKeHVg">In a preliminary experiment, we performed a grid search over the values of the Laplace smoothing, and learning rate used during CDS training, and found the best cross-validation values to be a Laplace smoothing value of 32, and a learning rate of 1 × 10 -4 .</s><s xml:id="_krrGMGZ">We subsequently used these institutional training hyper-parameter values for all experiments.</s><s xml:id="_MFfgQ2e">See "Supplementary Information: Hyper-Parameter Selection for Institutional Training" for further details regarding institutional training hyper-parameter tuning.</s></p><p xml:id="_tJeucDK"><s xml:id="_e4eVWfK">The FL hyper-parameter epochs per round and institutions per round were set to 1 and 100% respectively in all experiments.</s><s xml:id="_2a5XqNa">Additionally, the FL hyper-parameter optimizer state treatment was set to that of aggregating the moments using a weighted average, exactly as the model weights are aggregated during FL.</s><s xml:id="_d3CYTgt">For a discussion of how other values of these hyper-parameters can affect FL training, see "Supplementary Information: Hyper-Parameter Selection for FL".</s></p><p xml:id="_VXttscK"><s xml:id="_pQDGme6">All IIL experiments used a patience value of 10.</s><s xml:id="_nVz9ABE">For epochs per institution per cycle during CIIL, we used 1, as this value produced the best results in previous work <ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15</ref> .</s><s xml:id="_yQhB7JD">For all IIL and CIIL experiments, institutional order was taken as increasing order by institution data size as preferable to decreasing order in initial exploration.</s><s xml:id="_ZW2wQzx">See "Supplementary Information: Hyper-Paramter Selection for IIL and CIIL" for details of this exploration.</s></p><p xml:id="_Khq7aa9"><s xml:id="_N9MTJuF">experiments.</s><s xml:id="_QNBB5zV">Every experiment in this work was repeated over multiple runs: using multiple random initializations of the U-Net model, with multiple choices for the local validation sets (as discussed in "Data" section).</s></p><p xml:id="_42TWcK7"><s xml:id="_3btJfmv">We first trained models for each institution in the Original Institution group using its own training and validation data, training all models to 100 epochs, and evaluating the final model quality Dice against all single institution validation sets, the global validation set, as well as BTest, WashU and MDACC test data.</s></p><p xml:id="_BPrqXwd"><s xml:id="_bpJtK5t">Next, we measure final model quality Dice of FL, CIIL "best local", CIIL "random local", IIL, and CDS models trained on the Original Institution group against the global validation data as well as the BTest, WashU and MDACC test data.</s><s xml:id="_E7KHFFx">Here, all models were trained to 200 epochs.</s></p><p xml:id="_9GwQBfy"><s xml:id="_RWXF5sy">Finally, we train using CDS, FL, CIIL "best local", and CIIL "random local" on each of the LOO groups (described in "Data" section).</s><s xml:id="_y6yEuEX">Here all models are trained for a maximum of 200 epochs, stopping early if the best known model by validation did not change over 90 epochs.</s><s xml:id="_Sy94W6j">The quality of these final models was measured as its Dice value against the entire training/validation dataset belonging to the institution that was held out to form the group.</s><s xml:id="_nzhqsgc">(2) loss = log (�P� 1 + �T� 1 + s) -log (2�P • T� 1 + s)</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc><div><p xml:id="_5FrU5bu"><s xml:id="_nMrjXb3">Figure 1.</s><s xml:id="_Gux8q4b">System architectures of collaborative learning approaches for multi-institutional collaborations.</s><s xml:id="_9qt5HDr">The current paradigm for multi-institutional collaborations, based on Centralized Data Sharing, is shown in (a), whereas in (b) we note the proposed paradigm, based on Federated Learning.</s><s xml:id="_VQBAGtf">Panels (c) and (d) offer schematics for alternative data-private collaborative learning approaches evaluated in this study, namely Institutional Incremental Learning, and Cyclic Institutional Incremental Learning, respectively.</s></p></div></figDesc><graphic coords="3,155.91,50.50,382.68,620.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc><div><p xml:id="_FhwDSxG"><s xml:id="_3PmYk9r">Figure 2. Single Original Institution Validation Results.</s><s xml:id="_7CwMKCK">Single institution mean final model qualities (based on the Dice Similarity Coefficient 34 ) for the Original Institution group (y-axis) measured against all single institution held-out validation sets (x-axis) using multiple runs of five-fold collaborative cross validation.</s><s xml:id="_YxyGM5G">The Y axis represents models trained on a single institutional dataset, and the X axis represents the validation dataset of each independent institution (Local Validation Dataset).</s><s xml:id="_PhTWb4C">"AVG" indicates the average of each institution mean model performance over all institutions in the group other than itself, "W-AVG" denotes the same, but with a weighted average according to each institution's contribution to the validation set size.</s><s xml:id="_fkuFFqJ">The diagonal entries indicate how well each institution's final models scored against their own validation set, and they are represented as the Single Institutional Model (SIM) results reported in Fig.3.</s></p></div></figDesc><graphic coords="5,155.91,50.50,360.00,249.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc><div><p xml:id="_m6ZhHHU"><s xml:id="_gYJvhna">Figure 3. Model quality results from single institution training, CDS, FL, IIL, and CIIL.</s><s xml:id="_swajVSj">CDS, FL, CIIL mean model Dice against the Original Institution group single institution held-out validation data over multiple runs of collaborative cross validation, as well as the average of single institutional results under the same scheme (AVG SIM).</s><s xml:id="_vFyzBUj">The AVG 1-10 column provides the average performance of each collaboration method across single institution validation sets.</s><s xml:id="_u8bXyyt">For CIIL, 'best local' and 'random local' are two methods we introduce for final model selection during CIIL (More details are given in the "Methods: Final Model Selection" section ).</s><s xml:id="_wJr7XmN">Note that the color scale here differs from that used in Fig. 2.</s></p></div></figDesc><graphic coords="5,129.01,441.23,425.16,174.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc><div><p xml:id="_wKdcctX"><s xml:id="_C3VJNve">Figure 4. Learning curves of collaborative learning methods on Original Institution data.</s><s xml:id="_t7Ua7R8">Mean global validation Dice every epoch by collaborative learning method on the Original Institution group over multiple runs of collaborative cross validation.</s><s xml:id="_vdfX4NM">Confidence intervals are min, max.</s><s xml:id="_ZcMGrR3">An epoch for DCS is defined as a single training pass over all of the centralized data.</s><s xml:id="_cVHvrwA">An epoch for FL is defined as a parallel training pass of every institutiuon over their training data, and an epoch during CIIL and IIL is defined as a single insitution training pass over its data.</s></p></div></figDesc><graphic coords="6,155.91,350.71,360.00,183.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Received: 5</head><label>5</label><figDesc><div><p xml:id="_Qv3SquH"><s xml:id="_aJuqQrs">March 2020; Accepted: 23 June 2020</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc><div><p xml:id="_Z7pvG6u"><s xml:id="_npMtMxM">Model quality results from single institution training, CDS, and all data-private methods.</s><s xml:id="_fPJbr4A">Mean ± standard deviation of Dice for all collaboration methods on the Original Institution group under multiple runs of collaborative cross validation, as well as the mean of single institutional results under the same scheme.</s><s xml:id="_x4YmAmw">The LOO results are a weighted average over institutional LOO tests, weighted by test institution contribution.</s><s xml:id="_KwQdEMx">The '-' entries in the LOO column indicate single-institution tests, where the LOO method did not apply.</s></p></div></figDesc><table><row><cell>Model</cell><cell>BTest</cell><cell>WashU</cell><cell>MDACC</cell><cell>Global val</cell><cell>LOO</cell></row><row><cell>Avg single inst</cell><cell cols="4">0.732 ± 0.054 0.666 ± 0.045 0.705 ± 0.033 0.733</cell><cell>-</cell></row><row><cell>CDS</cell><cell cols="5">0.863 ± 0.008 0.782 ± 0.009 0.828 ± 0.007 0.862 ± 0.007 0.84 ± 0.006</cell></row><row><cell>FL</cell><cell cols="3">0.858 ± 0.004 0.771 ± 0.008 0.82 ± 0.003</cell><cell cols="2">0.857 ± 0.007 0.835 ± 0.006</cell></row><row><cell>CIIL "best local"</cell><cell cols="3">0.855 ± 0.007 0.775 ± 0.013 0.82 ± 0.009</cell><cell cols="2">0.853 ± 0.006 0.831 ± 0.012</cell></row><row><cell>CIIL "rand. local"</cell><cell>0.84 ± 0.021</cell><cell cols="4">0.758 ± 0.021 0.808 ± 0.014 0.824 ± 0.035 0.804 ± 0.031</cell></row><row><cell>IIL "smallest first"</cell><cell cols="5">0.833 ± 0.006 0.751 ± 0.007 0.781 ± 0.009 0.825 ± 0.007 0.785 ± 0.023</cell></row><row><cell>Institution 1</cell><cell>0.826</cell><cell>0.731</cell><cell>0.773</cell><cell>0.824</cell><cell>-</cell></row><row><cell>Institution 2</cell><cell>0.614</cell><cell>0.572</cell><cell>0.651</cell><cell>0.628</cell><cell>-</cell></row><row><cell>Institution 3</cell><cell>0.700</cell><cell>0.635</cell><cell>0.718</cell><cell>0.702</cell><cell>-</cell></row><row><cell>Institution 4</cell><cell>0.751</cell><cell>0.680</cell><cell>0.701</cell><cell>0.747</cell><cell>-</cell></row><row><cell>Institution 5</cell><cell>0.753</cell><cell>0.685</cell><cell>0.691</cell><cell>0.733</cell><cell>-</cell></row><row><cell>Institution 6</cell><cell>0.708</cell><cell>0.621</cell><cell>0.668</cell><cell>0.709</cell><cell>-</cell></row><row><cell>Institution 7</cell><cell>0.721</cell><cell>0.674</cell><cell>0.712</cell><cell>0.732</cell><cell>-</cell></row><row><cell>Institution 8</cell><cell>0.755</cell><cell>0.687</cell><cell>0.720</cell><cell>0.755</cell><cell>-</cell></row><row><cell>Institution 9</cell><cell>0.745</cell><cell>0.691</cell><cell>0.715</cell><cell>0.755</cell><cell>-</cell></row><row><cell>Institution 10</cell><cell>0.751</cell><cell>0.687</cell><cell>0.700</cell><cell>0.745</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_5jAzARM"><s xml:id="_dKcwCQQ">Scientific RepoRtS | (2020) 10:12598 | https://doi.org/10.1038/s41598-020-69250-1</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_bxvbB4b"><s xml:id="_WCzybUF">Vol:.(1234567890) Scientific RepoRtS | (2020) 10:12598 | https://doi.org/10.1038/s41598-020-69250-1</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p xml:id="_2nS7sPc"><s xml:id="_YhS5Gkt">Vol.:(0123456789) Scientific RepoRtS | (2020) 10:12598 | https://doi.org/10.1038/s41598-020-69250-1</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_JHGC2YF">Acknowledgements</head><p xml:id="_gaZK7wE"><s xml:id="_JfKzSmE">The authors would like to thank <rs type="person">Dr. Christos Davatzikos</rs> for his insightful comments during writing of this manuscript.</s><s xml:id="_JCAHn5c">Research reported in this publication was partly supported by the <rs type="funder">National Institutes of Health (NIH)</rs> under Award Numbers <rs type="funder">NCI</rs>:<rs type="grantNumber">U01CA242871</rs>, <rs type="funder">NINDS</rs>:<rs type="grantNumber">R01NS042645</rs>, <rs type="funder">NCI</rs>:<rs type="grantNumber">U24CA189523</rs>, <rs type="funder">NCI</rs>:<rs type="grantNumber">U24CA204854</rs>, and <rs type="funder">UPMC</rs> <rs type="grantNumber">CCSG P30CA047904</rs>.</s><s xml:id="_3knN7vN">The content of this publication is solely the responsibility of the authors and does not necessarily represent the official views of the <rs type="institution">NIH</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_CVzd3Jq">
					<idno type="grant-number">U01CA242871</idno>
				</org>
				<org type="funding" xml:id="_ftcwrVQ">
					<idno type="grant-number">R01NS042645</idno>
				</org>
				<org type="funding" xml:id="_aWbrg3N">
					<idno type="grant-number">U24CA189523</idno>
				</org>
				<org type="funding" xml:id="_3xsQzXd">
					<idno type="grant-number">U24CA204854</idno>
				</org>
				<org type="funding" xml:id="_AX4zPzw">
					<idno type="grant-number">CCSG P30CA047904</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cjD9BTG">Author contributions</head><p xml:id="_ayFT5CB"><s xml:id="_ZvFPW7W">M.J.S., B.E., and S.B. conceived and designed the complete study.</s><s xml:id="_vEJdJwe">A.K., M.M., D.M., R.R.C., and S.B. provided the data for the study.</s><s xml:id="_mhbjkEB">M.J.S. and B.E. did the data analysis.</s><s xml:id="_TUjypF4">M.J.S., B.E., and S.B. interpreted the data and wrote the manuscript.</s><s xml:id="_dncjQCS">G.A.R., J.M., S.P., A.K., M.M., W.X., D.M., and R.R.C. reviewed and edited the manuscript.</s><s xml:id="_meFvF6T">M.J.S., B.E., G.A.R., S.P., and S.B. created new software used in the study.</s><s xml:id="_TzpC4DT">Each author has approved the submitted version, and has agreed both to be personally accountable for the author's own contributions and to ensure that questions related to the accuracy or integrity of any part of the work, even ones in which the author was not personally involved, are appropriately investigated, resolved, and the resolution documented in the literature.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_wAmJcVw">competing interests</head><p xml:id="_vKt2AWm"><s xml:id="_mnzuteq">The authors declare no competing interests.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_z3rQ6VQ">Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a crosssectional study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Zech</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pmed.1002683</idno>
		<ptr target="https://doi.org/10.1371/journal.pmed.1002683" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_xQDNF9W">PLOS Med</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1002683</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zech, J. R. et al. Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross- sectional study. PLOS Med. 15, e1002683. https ://doi.org/10.1371/journ al.pmed.10026 83 (2018).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_NZnhFhE">The cancer imaging archive (TCIA): maintaining and operating a public information repository</title>
		<author>
			<persName><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10278-013-9622-7</idno>
		<ptr target="https://doi.org/10.1007/s10278-013-9622-7" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ByUfcsn">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1045" to="1057" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Clark, K. et al. The cancer imaging archive (TCIA): maintaining and operating a public information repository. J. Digit. Imaging 26, 1045-1057. https ://doi.org/10.1007/s1027 8-013-9622-7 (2013).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_MHhZ729">AI-based prognostic imaging biomarkers for precision neurooncology: the ReSPOND consortium</title>
		<author>
			<persName><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
		<idno type="DOI">10.1093/neuonc/noaa045</idno>
		<ptr target="https://doi.org/10.1093/neuonc/noaa045" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_wBgYFeF">Neuro Oncol</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Davatzikos, C. et al. AI-based prognostic imaging biomarkers for precision neurooncology: the ReSPOND consortium. Neuro Oncol. https ://doi.org/10.1093/neuon c/noaa0 45 (2020).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_b5MzEqp">The multimodal brain tumor image segmentation benchmark (BRATS)</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<idno type="DOI">10.1109/tmi.2014.2377694</idno>
		<ptr target="https://doi.org/10.1109/TMI.2014.2377694" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_VZrKz7z">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1993" to="2024" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Menze, B. H. et al. The multimodal brain tumor image segmentation benchmark (BRATS). IEEE Trans. Med. Imaging 34, 1993- 2024. https ://doi.org/10.1109/TMI.2014.23776 94 (2015).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_r8WxBkf">Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<idno type="DOI">10.1038/sdata.2017.117</idno>
		<ptr target="https://doi.org/10.1038/sdata.2017.117" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_q2ZMBYj">Nat. Sci. Data</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">170117</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bakas, S. et al. Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features. Nat. Sci. Data 4, 170117. https ://doi.org/10.1038/sdata .2017.117 (2017).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main" xml:id="_vuKrpbF">Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.02629</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bakas S. et al. Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge. arXiv:1811.02629 (2018).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Bilic</surname></persName>
		</author>
		<idno type="DOI">10.1109/ichi61247.2024.00107</idno>
		<idno type="arXiv">arXiv:1901.04056</idno>
		<ptr target="https://ui.adsabs.harvard.edu/abs/2019arXiv190104056B" />
		<title level="m" xml:id="_5jrs3Ga">The liver tumor segmentation benchmark (LiTS)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bilic P. et al. The liver tumor segmentation benchmark (LiTS). arXiv:1901.04056. https ://ui.adsab s.harva rd.edu/abs/2019a rXiv1 90104 056B (2019).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Heller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.00445</idno>
		<ptr target="https://ui.adsabs.harvard.edu/abs/2019arXiv190400445H" />
		<title level="m" xml:id="_QETa9wP">The challenge data: 300 kidney tumor cases with clinical context, CT semantic segmentations, and surgical outcomes</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Heller N. et al. The challenge data: 300 kidney tumor cases with clinical context, CT semantic segmentations, and surgical outcomes. arXiv:1904.00445. https ://ui.adsab s.harva rd.edu/abs/2019a rXiv1 90400 445H (2019).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main" xml:id="_WNhVUxB">A large annotated medical image dataset for the development and evaluation of segmentation algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Simpson</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerjcs.745/table-17</idno>
		<ptr target="https://ui.adsabs.harvard.edu/abs/2019arXiv190209063S" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Simpson A. L. et al. A large annotated medical image dataset for the development and evaluation of segmentation algorithms. https ://ui.adsab s.harva rd.edu/abs/2019a rXiv1 90209 063S (2019).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_9YRkd8A">ANHIR: automatic non-rigid histological image registration challenge</title>
		<author>
			<persName><forename type="first">J</forename><surname>Borovec</surname></persName>
		</author>
		<idno type="DOI">10.1109/tmi.2020.2986331</idno>
		<ptr target="https://doi.org/10.1109/TMI.2020.2986331" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_rP8WtYf">IEEE Trans. Med. Imaging</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Borovec, J. et al. ANHIR: automatic non-rigid histological image registration challenge. IEEE Trans. Med. Imaging https ://doi. org/10.1109/TMI.2020.29863 31 (2020).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_AnNhyM4">Glioma through the looking GLASS: molecular evolution of diffuse gliomas and the Glioma Longitudinal Analysis Consortium</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Consortium</surname></persName>
		</author>
		<idno type="DOI">10.1093/neuonc/noy020</idno>
		<ptr target="https://doi.org/10.1093/neuonc/noy020" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_yP2KQ4U">Neuro-Oncology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="873" to="884" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Consortium, T. G. Glioma through the looking GLASS: molecular evolution of diffuse gliomas and the Glioma Longitudinal Analysis Consortium. Neuro-Oncology 20, 873-884. https ://doi.org/10.1093/neuon c/noy02 0 (2018).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_sVGJNAa">Going digital: a survey on digitalization and large-scale data analytics in healthcare</title>
		<author>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<idno type="DOI">10.1109/jproc.2016.2615052</idno>
		<ptr target="https://doi.org/10.1109/JPROC.2016.2615052" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_3c3FQXx">Proc. IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="2180" to="2206" />
		</imprint>
	</monogr>
	<note type="raw_reference">Tresp, V. et al. Going digital: a survey on digitalization and large-scale data analytics in healthcare. Proc. IEEE 104, 2180-2206. https ://doi.org/10.1109/JPROC .2016.26150 52 (2016).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_U6dDWqA">Privacy protection and intrusion avoidance for cloudlet-based medical data sharing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/tcc.2016.2617382</idno>
		<ptr target="https://doi.org/10.1109/TCC.2016.2617382" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_XYJTzER">IEEE Trans. Cloud Comput</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen, M. et al. Privacy protection and intrusion avoidance for cloudlet-based medical data sharing. IEEE Trans. Cloud Comput. https ://doi.org/10.1109/TCC.2016.26173 82 (2016).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_JWhSZaG">Distributed deep learning networks among institutions for medical imaging</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocy017</idno>
		<ptr target="https://doi.org/10.1093/jamia/ocy017" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Erm4SZQ">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="945" to="954" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chang, K. et al. Distributed deep learning networks among institutions for medical imaging. J. Am. Med. Inform. Assoc. 25, 945-954. https ://doi.org/10.1093/jamia /ocy01 7 (2018).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_kcWBdxz">Multi-institutional deep learning modeling without sharing patient data: A feasibility study on brain tumor segmentation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Sheller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Reina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-11723-8_9</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-11723-8_9" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_Qn4DVnP">Brainles 2018 -Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11383</biblScope>
			<biblScope unit="page" from="92" to="104" />
		</imprint>
	</monogr>
	<note type="raw_reference">Sheller, M. J., Reina, G. A., Edwards, B., Martin, J. &amp; Bakas, S. Multi-institutional deep learning modeling without sharing patient data: A feasibility study on brain tumor segmentation. In Brainles 2018 -Springer Lecture Notes in Computer Science 11383, 92-104. https ://doi.org/10.1007/978-3-030-11723 -8_9 (2018).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_mpdU4MW">Communication-efficient learning of deep networks from decentralized data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hampson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Arcas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wMWUzjM">Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="1273" to="1282" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McMahan, B., Moore, E., Ramage, D., Hampson, S. &amp; y Arcas, B. A. Communication-efficient learning of deep networks from decentralized data, in Artificial Intelligence and Statistics. 1273-1282 (2017).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_aEqKRAV">Federated learning: collaborative machine learning without centralized training Data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aDujn7a">Google AI Blog</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McMahan, B. &amp; Ramage, D. Federated learning: collaborative machine learning without centralized training Data. Google AI Blog (2017).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_wEW3MVY">Catastrophic forgetting in connectionist networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
		<idno type="DOI">10.1016/s1364-6613(99)01294-2</idno>
		<ptr target="https://doi.org/10.1016/S1364-6613(99)01294-2" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_SBbxbV2">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="raw_reference">French, R. M. Catastrophic forgetting in connectionist networks. Trends Cogn. Sci. 3, 128-135. https ://doi.org/10.1016/S1364 -6613(99)01294 -2 (1999).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00582</idno>
		<title level="m" xml:id="_kxx7f2Z">Federated learning with non-iid data</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zhao Y. et al. Federated learning with non-iid data. arXiv:1806.00582 (2018).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_BKsnAq5">Racial differences in quantitative measures of area and volumetric breast density</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Mccarthy</surname></persName>
		</author>
		<idno type="DOI">10.1093/jnci/djw104</idno>
		<ptr target="https://doi.org/10.1093/jnci/djw104" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_jbFzJJC">JNCI J. Natl. Cancer Inst</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">McCarthy, A. M. et al. Racial differences in quantitative measures of area and volumetric breast density. JNCI J. Natl. Cancer Inst. https ://doi.org/10.1093/jnci/djw10 4 (2016).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_VT4Y8m6">Segmentation labels and radiomic features for the pre-operative scans of the TCGA-GBM collection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<idno type="DOI">10.7937/K9/TCIA.2017.KLXWJJ1Q</idno>
		<ptr target="1Q" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_rqZpQ9F">The Cancer Imaging Archive</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>KLXWJ J</note>
	<note type="raw_reference">Bakas, S. et al. Segmentation labels and radiomic features for the pre-operative scans of the TCGA-GBM collection. The Cancer Imaging Archive. https ://doi.org/10.7937/K9/TCIA.2017.KLXWJ J1Q (2017).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_ujMfJRt">Segmentation labels and radiomic features for the pre-operative scans of the TCGA-LGG collection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bakas</surname></persName>
		</author>
		<idno type="DOI">10.7937/K9/TCIA.2017.GJQ7R0EF</idno>
		<ptr target="https://doi.org/10.7937/K9/TCIA.2017.GJQ7R0EF" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_mkAfJVJ">The Cancer Imaging Archive</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bakas, S. et al. Segmentation labels and radiomic features for the pre-operative scans of the TCGA-LGG collection. The Cancer Imaging Archive. https ://doi.org/10.7937/K9/TCIA.2017.GJQ7R 0EF (2017).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_hgVArsw">Privacy-Preserving Federated Brain Tumour Segmentation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-32692-0_16</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-32692-0_16" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_RHWTgYX">MLMI 2019 -Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11861</biblScope>
			<biblScope unit="page" from="133" to="141" />
		</imprint>
	</monogr>
	<note type="raw_reference">Li, W. et al. Privacy-Preserving Federated Brain Tumour Segmentation, In MLMI 2019 -Springer Lecture Notes in Computer Science 11861, 133-141. https ://doi.org/10.1007/978-3-030-32692 -0_16 (2019).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_9PjYbEM">The eu general data protection regulation (gdpr)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Voigt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Von Dem Bussche</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-62328-8</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_SNuV2AS">A Practical Guide</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>1st edn</note>
	<note type="raw_reference">Voigt, P. &amp; Von dem Bussche, A. The eu general data protection regulation (gdpr). In A Practical Guide, 1st edn (Springer, Cham, 2017).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_KMdY9Jh">HIPAA regulations-a new era of medical-record privacy?</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Annas</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejmlim035027</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wpnM26w">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">348</biblScope>
			<biblScope unit="page" from="1486" to="1490" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Annas, G. J. HIPAA regulations-a new era of medical-record privacy?. N. Engl. J. Med. 348, 1486-1490 (2003).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_uHhSwRZ">Sharing clinical trial data-a proposal from the international committee of medical journal editors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Taichman</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejme1515172</idno>
		<ptr target="https://doi.org/10.1056/NEJMe1515172" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_WJEwvhE">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">374</biblScope>
			<biblScope unit="page" from="384" to="386" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Taichman, D. B. et al. Sharing clinical trial data-a proposal from the international committee of medical journal editors. N. Engl. J. Med. 374, 384-386. https ://doi.org/10.1056/NEJMe 15151 72 (2016).</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_FzAmkpF">Data sharing from clinical trials-a research funder&apos;s perspective</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kiley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Reddington</surname></persName>
		</author>
		<idno type="DOI">10.1056/nejmsb1708278</idno>
		<ptr target="https://doi.org/10.1056/NEJMsb1708278" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_BMqNs4f">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">377</biblScope>
			<biblScope unit="page" from="1990" to="1992" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kiley, R., Peatfield, T., Hansen, J. &amp; Reddington, F. Data sharing from clinical trials-a research funder&apos;s perspective. N. Engl. J. Med. 377, 1990-1992. https ://doi.org/10.1056/NEJMs b1708 278 (2017).</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_eBFCCDR">Distributed learning from multiple EHR databases: contextual embedding models for medical events</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Long</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbi.2019.103138</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Den5WMx">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">103138</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Li, Z., Roberts, K., Jiang, X. &amp; Long, Q. Distributed learning from multiple EHR databases: contextual embedding models for medical events. J. Biomed. Inform. 92, 103138 (2019).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_5dxkYTg">Federated learning of predictive models from federated electronic health records</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Brisimi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijmedinf.2018.01.007</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PBaNjSd">Int. J. Med. Inform</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="59" to="67" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brisimi, T. S. et al. Federated learning of predictive models from federated electronic health records. Int. J. Med. Inform. 112, 59-67 (2018).</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ristenpart</surname></persName>
		</author>
		<idno type="DOI">10.1145/2810103.2813677</idno>
		<title level="m" xml:id="_DJCjk5t">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security 1322-1333</title>
		<meeting>the 22nd ACM SIGSAC Conference on Computer and Communications Security 1322-1333<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fredrikson, M., Jha, S. &amp; Ristenpart, T. in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security 1322-1333 (ACM, Denver, Colorado, USA, 2015).</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main" xml:id="_bBQnVd8">The secret sharer: measuring unintended neural network memorization and extracting secrets</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ú</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1515/9781400863037.49</idno>
		<idno type="arXiv">arXiv:1802.08232</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Carlini, N., Liu, C., Kos, J., Erlingsson, Ú. &amp; Song, D. The secret sharer: measuring unintended neural network memorization and extracting secrets. arXiv:1802.08232 (2018).</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Hitaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ateniese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Perez-Cruz</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133956.3134012</idno>
		<title level="m" xml:id="_CHMGgrv">Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2017 ACM SIGSAC Conference on Computer and Communications Security<address><addrLine>Dallas, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="603" to="618" />
		</imprint>
	</monogr>
	<note type="raw_reference">Hitaj, B., Ateniese, G. &amp; Perez-Cruz, F. in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security 603-618 (ACM, Dallas, Texas, USA, 2017).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_gRQzjQ2">The SRI24 multichannel atlas of normal adult human brain structure</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rohlfing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Zahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pfefferbaum</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.20906</idno>
		<ptr target="https://doi.org/10.1002/hbm.20906" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_36gQDTF">Hum. Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="798" to="819" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rohlfing, T., Zahr, N. M., Sullivan, E. V. &amp; Pfefferbaum, A. The SRI24 multichannel atlas of normal adult human brain structure. Hum. Brain Mapp. 31, 798-819. https ://doi.org/10.1002/hbm.20906 (2010).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_jd7PTMg">Measures of the amount of ecologic association between species</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Dice</surname></persName>
		</author>
		<idno type="DOI">10.2307/1932409</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_49zHEdn">Ecology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="297" to="302" />
			<date type="published" when="1945">1945</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dice, L. R. Measures of the amount of ecologic association between species. Ecology 26, 297-302 (1945).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
		<title level="m" xml:id="_JZ6uCvr">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
	<note type="raw_reference">Ronneberger, O., Fischer, P. &amp; Brox, T. in International Conference on Medical Image Computing and Computer-Assisted Interven- tion. 234-241 (Springer).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m" xml:id="_NTbAs8P">a method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. arXiv:1412.6980 (2014).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
