<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_CE696FP">Deep Learning for Health Informatics</title>
				<funder ref="#_uvpjUHa #_PFrBERN">
					<orgName type="full">EPSRC-NIHR</orgName>
				</funder>
				<funder ref="#_Vp9YTd5">
					<orgName type="full">EPSRC Smart Sensing for Surgery</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniele</forename><surname>Ravì</surname></persName>
							<email>d.ravi@imperial.ac.uk</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">London SW7 2AZ , U.</note>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country>U</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Charence</forename><surname>Wong</surname></persName>
							<email>charence@imperial.ac.uk</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">London SW7 2AZ , U.</note>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country>U</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fani</forename><surname>Deligianni</surname></persName>
							<email>fani.deligianni@imperial.ac.uk</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">London SW7 2AZ , U.</note>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country>U</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Melissa</forename><surname>Berthelot</surname></persName>
							<email>m.berthelot14@imperial.ac.uk</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">London SW7 2AZ , U.</note>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country>U</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Javier</forename><surname>Andreu-Perez</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation">London SW7 2AZ , U.</note>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country>U</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benny</forename><surname>Lo</surname></persName>
							<email>benny.lo@imperial.ac.uk</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">London SW7 2AZ , U.</note>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country>U</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Guang-Zhong</forename><surname>Yang</surname></persName>
							<email>g.z.yang@imperial.ac.uk</email>
							<affiliation key="aff0">
								<note type="raw_affiliation">London SW7 2AZ , U.</note>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country>U</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_wWhqhMA">Deep Learning for Health Informatics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0B3FEA8CB11C879EEB93D0C6C100D291</idno>
					<idno type="DOI">10.1109/jbhi.2016.2636665</idno>
					<note type="submission">Manuscript received October 11, 2016; revised November 28, 2016; accepted December 2, 2016. Date of publication December 29, 2016; date of current version January 31, 2017.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T12:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_EajuuRc">Bioinformatics</term>
					<term xml:id="_sn8Xu2Y">deep learning</term>
					<term xml:id="_2XuKUdh">health informatics</term>
					<term xml:id="_j4ajXVB">machine learning</term>
					<term xml:id="_EK8XQXU">medical imaging</term>
					<term xml:id="_BefVP96">public health</term>
					<term xml:id="_tBDK3N3">wearable devices</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_teVsQyw"><p xml:id="_eRf4VB8"><s xml:id="_M7XFXTJ">With a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade.</s><s xml:id="_yyZHUaY">This has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics.</s><s xml:id="_hRDRZGe">Deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence.</s><s xml:id="_m7zCxSz">Rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data.</s><s xml:id="_8CYrR4T">This article presents a comprehensive up-todate review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook.</s><s xml:id="_ZNnUnsb">The paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="594.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_vZSQJ6C">I. INTRODUCTION</head><p xml:id="_evfy6Xw"><s xml:id="_PWNykbn">D EEP learning has in recent years set an exciting new trend in machine learning.</s><s xml:id="_9zwhGHK">The theoretical foundations of deep learning are well rooted in the classical neural network (NN) literature.</s><s xml:id="_dzrzpfG">But different to more traditional use of NNs, deep learning accounts for the use of many hidden neurons and layers-typically more than two-as an architectural advantage combined with new training paradigms.</s><s xml:id="_ABjnYPZ">While resorting to many neurons allows an extensive coverage of the raw data at hand, the layer-by-layer pipeline of nonlinear combination of their outputs generates a lower dimensional projection of the input space.</s><s xml:id="_6PhNCjw">Every lower-dimensional projection corresponds to a higher perceptual level.</s><s xml:id="_tWD4TRD">Provided that the network is optimally weighted, it results in an effective high-level abstraction of the raw data or images.</s><s xml:id="_d6h45Dn">This high level of abstraction renders Fig. <ref type="figure">1</ref>.</s><s xml:id="_gd6PkQn">Distribution of published papers that use deep learning in subareas of health informatics.</s><s xml:id="_AtJj9bB">Publication statistics are obtained from Google Scholar; the search phrase is defined as the subfield name with the exact phrase deep learning and at least one of medical or health appearing, e.g., "public health" "deep learning" medical OR health.</s></p><p xml:id="_DJHrCZp"><s xml:id="_C87FTw5">an automatic feature set, which otherwise would have required hand-crafted or bespoke features.</s></p><p xml:id="_Vav62TX"><s xml:id="_quT6Px5">In domains such as health informatics, the generation of this automatic feature set without human intervention has many advantages.</s><s xml:id="_fc8VnSw">For instance, in medical imaging, it can generate features that are more sophisticated and difficult to elaborate in descriptive means.</s><s xml:id="_YupFvZB">Implicit features could determine fibroids and polyps <ref type="bibr" target="#b0">[1]</ref>, and characterize irregularities in tissue morphology such as tumors <ref type="bibr" target="#b1">[2]</ref>.</s><s xml:id="_JvtBEb7">In translational bioinformatics, such features may also determine nucleotide sequences that could bind a DNA or RNA strand to a protein <ref type="bibr" target="#b2">[3]</ref>.</s><s xml:id="_mMrSrqC">Fig. <ref type="figure">1</ref> outlines a rapid surge of interest in deep learning in recent years in terms of the number of papers published in sub-fields in health informatics including bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.</s></p><p xml:id="_ZwvYuBd"><s xml:id="_dfjpSjU">Among various methodological variants of deep learning, several architectures stand out in popularity.</s><s xml:id="_AyXGhUs">Fig. <ref type="figure">2</ref> depicts the number of publications by deep learning method since 2010.</s><s xml:id="_pSgYBbh">In particular, Convolutional Neural Networks (CNNs) have had the greatest impact within the field of health informatics.</s><s xml:id="_wCtVUMZ">Its architecture can be defined as an interleaved set of feed-forward layers implementing convolutional filters followed by reduction, rectification or pooling layers.</s><s xml:id="_Y6TA6Hz">Each layer in the network originates a high-level abstract feature.</s><s xml:id="_89kca2t">This biologically-inspired architecture resembles the procedure in which the visual cortex assimilates visual information in the form of receptive fields.</s><s xml:id="_6wANNyc">Other plausible architectures for deep learning include those grounded in compositions of restricted Boltzmann machines (RBMs) such as deep belief networks (DBNs), stacked Autoencoders functioning as deep Autoencoders, extending artificial This work is licensed under a Creative Commons Attribution 3.0 License.</s><s xml:id="_KnTVA4P">For more information, see <ref type="url" target="http://creativecommons.org/licenses/by/3.0/">http://creativecommons.org/licenses/by/3.0/</ref></s><s xml:id="_KBpftag">Fig. <ref type="figure">2</ref>. Percentage of most used deep learning methods in health informatics.</s><s xml:id="_dXWcFuG">Learning method statistics are also obtained from Google Scholar by using the method name with at least one of medical or health as the search phrase.</s></p><p xml:id="_XdMhRas"><s xml:id="_TMZknQA">NNs with many layers as deep neural networks (DNNs), or with directed cycles as recurrent neural networks (RNNs).</s><s xml:id="_nv55k35">Latest advances in Graphics Processing Units (GPUs) have also had a significant impact on the practical uptake and acceleration of deep learning.</s><s xml:id="_RAfg6Du">In fact, many of the theoretical ideas behind deep learning were proposed during the pre-GPU era, although they have started to gain prominence in the last few years.</s><s xml:id="_ATJcds2">Deep learning architectures such as CNNs can be highly parallelized by transferring most common algebraic operations with dense matrices such as matrix products and convolutions to the GPU.</s></p><p xml:id="_zBdM68P"><s xml:id="_FBHRUrw">Thus far, a plethora of experimental works have implemented deep learning models for heath informatics, reaching similar performance or in many cases exceeding that of alternative techniques.</s><s xml:id="_ja8Wm8k">Nevertheless, the application of deep learning to health informatics raises a number of challenges that need to be resolved.</s><s xml:id="_QswDZqt">For example, training a deep architecture requires an extensive amount of labeled data, which in the healthcare domain can be difficult to achieve.</s><s xml:id="_s8tp2Mz">In addition, deep learning requires extensive computational resources, without which training could become excessively time-consuming.</s><s xml:id="_eQksTav">Attaining an optimal definition of the network's free parameters can become a particularly laborious task to solve.</s><s xml:id="_5w5RcGg">Eventually, deep learning models can be affected by convergence issues as well as overfitting, hence supplementary learning strategies are required to address these problems <ref type="bibr" target="#b3">[4]</ref>.</s></p><p xml:id="_eU5hm7c"><s xml:id="_T3552kJ">In the following sections of this review, we examine recent health informatics studies that employ deep learning to discuss its relative strength and potential pitfalls.</s><s xml:id="_W9Dj5cQ">Furthermore, their schemas and operational frameworks are described in detail to elucidate their practical implementations, as well as expected performance.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_8xgM42Q">II. FROM PERCEPTRON TO DEEP LEARNING</head><p xml:id="_DgkR2fj"><s xml:id="_JeQSTW4">Perceptron is a bio-inspired algorithm for binary classification and it is one of the earliest NNs proposed <ref type="bibr" target="#b18">[19]</ref>.</s><s xml:id="_AM832b5">It mathematically formalizes how a biological neuron works.</s><s xml:id="_Gsk7aGM">It has been realized that the brain processes information through billions of these interconnected neurons.</s><s xml:id="_TaERrNh">Each neuron is stimulated by the injection of currents from the interconnected neurons and an action potential is generated when the voltage exceeds a limit.</s><s xml:id="_5vkXVUy">These action potentials allow neurons to excite or inhibit other neurons, and through these networked neural activities, the biological network can encode, process, and transmit information.</s><s xml:id="_Uwt6Qbp">Biological NNs have the capacity to modify themselves, create new neural connections, and learn according to the stimulation characteristics.</s><s xml:id="_XGUtSRr">Perceptrons, which consist of an input layer directly connected to an output node, emulate this biochemical process through an activation function (also referred to as a transfer function) and a few weights.</s><s xml:id="_6GfTjfH">Specifically, it can learn to classify linearly separable patterns by adjusting these weights accordingly.</s></p><p xml:id="_qU5j6bn"><s xml:id="_GHa8T7Z">To solve more complex problems, NNs with one or more hidden layers of Perceptrons have been introduced <ref type="bibr" target="#b19">[20]</ref>.</s><s xml:id="_j97wPfh">To train these NNs, many stages or epochs are usually performed where each time the network is presented with a new input sample and the weights of each neuron are adjusted based on a learning process called delta rule.</s><s xml:id="_7F9eg5E">The delta rule is used by the most common class of supervised NNs during the training and is usually implemented by exploiting the back-propagation routine <ref type="bibr" target="#b20">[21]</ref>.</s><s xml:id="_Uq7Aqt3">Specifically, without any prior knowledge, random values are assigned to the network weights.</s><s xml:id="_2fuSvVr">Through an iterative training process, the network weights are adjusted to minimize the difference between the network outputs and the desired outputs.</s><s xml:id="_cHyy7Pc">The most common iterative training method uses the gradient descent method where the network is optimized to find the minimum along the error surface.</s><s xml:id="_5bJBZcf">The method requires the activation functions to be always differentiable.</s></p><p xml:id="_U77jS5d"><s xml:id="_fT8SMfN">Adding more hidden layers to the network allows a deep architecture to be built that can express more complex hypotheses as the hidden layers capture the nonlinear relationships.</s><s xml:id="_28gxdJU">These NNs are known as DNNs.</s><s xml:id="_sm2gkZZ">Training of DNNs is not trivial because once the errors are back-propagated to the first few layers, they become negligible (vanishing of the gradient), thus failing the learning process.</s><s xml:id="_ptCwM9q">Although more advanced variants of backpropagation <ref type="bibr" target="#b21">[22]</ref> can solve this problem, they still result in a very slow learning process.</s></p><p xml:id="_f9uUMSA"><s xml:id="_tCVZFaK">Deep learning has provided new sophisticated approaches to train DNN architectures.</s><s xml:id="_ZzAUBej">In general, DNNs can be trained with unsupervised and supervised learning methodologies.</s><s xml:id="_PS7EzM6">In supervised learning, labeled data are used to train the DNNs and learn the weights that minimize the error to predict a target value for classification or regression, whereas in unsupervised learning, the training is performed without requiring labeled data.</s><s xml:id="_TuUQFft">Unsupervised learning is usually used for clustering, feature extraction or dimensionality reduction.</s><s xml:id="_sd4Bba2">For some applications it is common to combine an initial training procedure of the DNN with an unsupervised learning step to extract the most relevant features and then use those features for classification by exploiting a supervised learning step.</s><s xml:id="_G39NuDR">For more general background information related to the theory of machine learning, the reader can refer to the works in <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b24">[25]</ref> where common training problems, such as overfitting, model interpretation and generalization, are explained in detail.</s><s xml:id="_3y5ANeH">These considerations must be taken into account when deep learning frameworks are used.</s></p><p xml:id="_kNThQxM"><s xml:id="_QSSJ4B4">For many years, hardware limitations have made DNNs impractical due to high computational demands for both training and processing, especially for applications that require real-time processing.</s><s xml:id="_WrTunAt">Recently, advances in hardware and thanks to the possibility of parallelization through GPU acceleration, cloud computing and multicore processing, these limitations have been partially overcome and have enabled DNNs to be recognized as a significant breakthrough in artificial intelligence.</s><s xml:id="_FGYtnZs">Thus far, several DNNs architectures have been introduced in literature and Table I briefly describes the pros and cons of the commonly used deep learning approaches in the field of health informatics.</s><s xml:id="_gzv5MwR">In Table <ref type="table">II</ref> are instead described the main features of popular software packages that provide deep learning implementation.</s><s xml:id="_kdVF6KE">Finally, Table <ref type="table">III</ref> summarizes the different applications in the five areas of health informatics considered in this paper.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cpqdzRG">A. Autoencoders and Deep Autoencoders</head><p xml:id="_jjM2vBZ"><s xml:id="_BzrGwJU">Recent studies have shown that there are no universally handengineered features that always work on different datasets.</s><s xml:id="_n4C6v8U">Features extracted using data driven learning can generally be more accurate.</s><s xml:id="_xEcXuq6">An Autoencoder is a NN designed exactly for this purpose.</s><s xml:id="_CYtUzjc">Specifically, an Autoencoder has the same number of input and output nodes, as shown in Fig. <ref type="figure" target="#fig_0">3</ref>(a), and it is trained to recreate the input vector rather than to assign a class label to it.</s><s xml:id="_cuvSYM8">The method is therefore unsupervised.</s><s xml:id="_uTcPE39">Usually, the number of hidden units is smaller than the input/output layers, which achieve encoding of the data in a lower dimensional space and extract the most discriminative features.</s><s xml:id="_FuRJ4Fr">If the input data is of high dimensionality, a single hidden layer of an Autoencoder may not be sufficient to represent all the data.</s><s xml:id="_2EVh38D">Alternatively, many Autoencoders can be stacked on top of each other to create a deep Autoencoder architecture <ref type="bibr" target="#b4">[5]</ref>.</s><s xml:id="_h79zmfp">Deep Autoencoder structures also face the problem of vanishing gradients during training.</s><s xml:id="_5h8mxxT">In this case, the network learns to reconstruct the average of all the training data.</s><s xml:id="_FeE8dpT">A common solution to this problem is to initialize the weights so that the network starts with a good approximation of the final configuration.</s><s xml:id="_dkMxqfp">Finding these initial weights is referred to as pretraining and is usually achieved by training each layer separately in a greedy fashion.</s><s xml:id="_jjqUvpK">After pretraining, the standard back-propagation can be used to fine-tune the parameters.</s><s xml:id="_ZbEuz44">Many variations of Autoencoder have been proposed to make the learned representations more robust or stable against small variations of the input pattern.</s><s xml:id="_SyKvv9n">For example, the sparse autoencoder <ref type="bibr" target="#b5">[6]</ref> that forces the representation to be sparse is usually used to make the classes more separable.</s><s xml:id="_pc94AmP">Another variation, called denoising autoencoder, was proposed by Vincent et al. <ref type="bibr" target="#b6">[7]</ref>, where in order to increase the robustness of the model, the method recreates the input introducing some noise to the patterns, thus, forcing the model to capture just the structure of the input.</s><s xml:id="_2h3xSPe">A similar idea was implemented in contractive autoencoder, proposed by Rifai et al. <ref type="bibr" target="#b7">[8]</ref>, but instead of injecting noise to corrupt the training set, it adds an analytic contractive penalty to the error function.</s><s xml:id="_zwQF2au">Finally, the convolutional autoencoder <ref type="bibr" target="#b8">[9]</ref> shares weights between nodes to preserve spatial locality and process two-dimensional (2-D) patterns (i.e., images) efficiently.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rAaC8Mg">B. Recurrent Neural Network</head><p xml:id="_2qCU9na"><s xml:id="_BprYu5J">RNN <ref type="bibr" target="#b12">[13]</ref> is a NN that contains hidden units capable of analyzing streams of data.</s><s xml:id="_ed7bMrH">This is important in several applications where the output depends on the previous computations, such as the analysis of text, speech, and DNA sequences.</s><s xml:id="_HVQ4aEY">The RNN is usually fed with training samples that have strong inter-dependencies and a meaningful representation to maintain information about what happened in all the previous time steps.</s><s xml:id="_M9TGymB">The outcome obtained by the network at time t -1 affects the choice at time t.</s><s xml:id="_B662Xeh">In this way, RNNs exploit two sources of input, the present and the recent past, to provide the output of the new data.</s><s xml:id="_BABA78t">For this reason, it is often said that RNNs have memory.</s><s xml:id="_nm3aqTV">Although the RNN is a simple and powerful model, it also suffers from the vanishing gradient and exploding gradient problems as described in Bengio et al. <ref type="bibr" target="#b25">[26]</ref>.</s><s xml:id="_FHNHtsr">A variation of RNN called long short-term memory units (LSTMs), was proposed in <ref type="bibr" target="#b26">[27]</ref> to solve the problem of the vanishing gradient generated by long input sequences.</s><s xml:id="_HJD8ycu">Specifically, LSTM is particularly suitable for applications where there are very long time lags of unknown sizes between important events.</s><s xml:id="_p2ANBss">To do so, LSTMs exploit new sources of information so that data can be stored in, written to, or read from a node at each step.</s><s xml:id="_ckFtmYk">During the training, the network learns what to store and when to allow reading/writing in order to minimize the classification errors.</s></p><p xml:id="_SWKzNSk"><s xml:id="_d2mT5Wb">Unlike other types of DNNs, which uses different weights at each layer, a RNN or a LSTM shares the same weights across all steps.</s><s xml:id="_CZFjgdH">This greatly reduces the total number of parameters that the network needs to learn.</s><s xml:id="_zPAqsfD">RNNs have shown great successes in many natural language processing tasks such as language modeling, bioinformatics, speech recognition, and generating image description.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_qGxdKYU">C. RBM-Based Technique</head><p xml:id="_8VC6ttn"><s xml:id="_bmAna26">A RBM was first proposed in <ref type="bibr" target="#b36">[37]</ref> and is a variant of the Boltzmann machine, which is a type of stochastic NN.</s><s xml:id="_eA2vuvR">These networks are modeled by using stochastic units with a specific distribution (for example Gaussian).</s><s xml:id="_bNbK68m">Learning procedure involves several steps called Gibbs sampling, which gradually adjust the weights to minimize the reconstruction error.</s><s xml:id="_anSUFx8">Such NNs are useful if it is required to model probabilistic relationships between variables.</s></p><p xml:id="_ExBnmjn"><s xml:id="_7mzNsda">Bayesian networks <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref> are a particular case of network with stochastic unit referred as probabilistic graphical model that characterizes the conditional independence between variables in the form of a directed acyclic graph.</s><s xml:id="_Xtea5Sg">In an RBM, the visible</s></p><p xml:id="_V56N53Y"><s xml:id="_Z8QE4zy">TABLE I DIFFERENT DEEP LEARNING ARCHITECTURES TABLE II POPULAR SOFTWARE PACKAGES THAT PROVIDE DNNS IMPLEMENTATION Name Creator License Platform Interface OpenMP Supported techniques Cloud support RNN CNN DBN computing Caffe [28] Berkeley Center FreeBSD Linux, Win, OSX, Andr.</s><s xml:id="_F3yCbCX">C++, Python, MATLAB ✗ √ √ ✗ ✗ CNTK [29] Microsoft MIT Linux, Win Command line √ √ √ ✗ ✗ Deeplearning4jK [30] Skymind Apache 2.0 Linux, Win, OSX, Andr.</s><s xml:id="_tX7HnW9">Java, Scala, Clojure √ √ √ √ ✗ Wolfram Math.</s><s xml:id="_emB3T3k">[31] Wolfram Research Proprietary Linux, Win, OSX, Cloud Java, C++ ✗ ✗ √ √ √ TensorFlow [32] Google Apache 2.0 Linux, OSX Python ✗ √ √ √ ✗ Theano [33] Université de Montréal BSD Cross-platform Python √ √ √ √ ✗ Torch [34] Ronan Collobert et al.</s><s xml:id="_Y286QrB">BSD Linux, Win, OSX, Andr., iOS Lua, LuaJIT, C √ √ √ √ ✗ Keras [35] Franois Chollet MIT license Linux, Win, OSX Python ✗ √ √ √ ✗ Neon [36] Nervana Systems Apache 2.0 OSX, Linux Python √ √ √ √ √</s></p><p xml:id="_C7JVy32"><s xml:id="_zJUVH6Q">TABLE III SUMMARY OF THE DIFFERENT DEEP LEARNING METHODS BY AREAS AND APPLICATIONS IN HEALTH INFORMATICS</s></p><p xml:id="_7tKcxTW"><s xml:id="_yjQjjxH">and hidden units are restricted to form a bipartite graph that allows implementation of more efficient training algorithms.</s><s xml:id="_fGrwQjb">Another important characteristics is that RBMs have undirected nodes, which implies that values can be propagated in both the directions as shown in Fig. <ref type="figure" target="#fig_0">3(b)</ref>.</s></p><p xml:id="_PB4Sbwm"><s xml:id="_pRk2PNe">Contrastive divergence <ref type="bibr" target="#b39">[40]</ref> (CD) algorithm is a common method used to train an RBM.</s><s xml:id="_qAdT8mj">CD is an unsupervised learning algorithm, which consists of two phases that can be referred to as positive and negative phases.</s><s xml:id="_u77PrkS">During the positive phase the network configuration is modified to replicate the training set, whereas during the negative phase it attempts to recreate the data based on the current network configuration.</s></p><p xml:id="_kaZ6pqz"><s xml:id="_3j2taAs">A beneficial property of RBM is that the conditional distribution over the hidden units factorizes given the visible units.</s><s xml:id="_bpWCpY5">This makes inferences tractable since the RBM feature representation is taken to be a set of posterior marginal obtained by directly maximizing the likelihood.</s><s xml:id="_mfZY3yS">Utilizing RBM as learning modules, two main deep learning frameworks have been proposed in literature: the DBN and the deep Boltzmann machine (DBM).</s></p><p xml:id="_QdwM2Gb"><s xml:id="_QGcvPGd">1) Deep Belief Network: Proposed in <ref type="bibr" target="#b9">[10]</ref>, a DBN can be viewed as a composition of RBMs where each subnetwork's hidden layer is connected to the visible layer of the next RBM.</s><s xml:id="_HSZusPA">DBNs have undirected connections only at the top two layers and directed connections to the lower layers.</s><s xml:id="_vgntBCW">The initialization of a DBN is obtained through an efficient layer-by-layer greedy learning strategy using unsupervised learning and is then finetuned based on the target outputs.</s></p><p xml:id="_K7rbg4X"><s xml:id="_Cu8vngA">2) Deep Boltzmann Machines: Proposed in <ref type="bibr" target="#b10">[11]</ref>, a DBM is another DNN variant based on the Boltzmann family.</s><s xml:id="_UUnmmRT">The main difference with DBN is that the former possesses undirected connections (conditionally independent) between all layers of the network.</s><s xml:id="_PdPybdb">In this case, calculating the posterior distribution over the hidden units given the visible units cannot be achieved by directly maximizing the likelihood due to interactions between the hidden units.</s><s xml:id="_YJtRsgg">For this reason, to train a DBM, a stochastic maximum likelihood <ref type="bibr" target="#b11">[12]</ref> based algorithm is usually used to maximize the lower bound of the likelihood.</s><s xml:id="_rDMkdsJ">Same as for DBNs, a greedy layer-wise training strategy is also performed when pretraining the DBM network.</s><s xml:id="_MAkjxdj">The main disadvantage of a DBM is the time complexity required for the inference that is considerably higher with respect to the DBN, and that makes the optimization of the parameters not practical for big training set <ref type="bibr" target="#b40">[41]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ReSxXAz">D. Convolutional Neural Networks</head><p xml:id="_wXvbFjN"><s xml:id="_uKgF2pN">In general, all the DNNs presented so far cannot scale well with multidimensional input that has locally correlated data, such as an image.</s><s xml:id="_344EVQy">The main problem is that the number of nodes and the number of parameters that they have to train could be huge, and therefore, they are not practical.</s><s xml:id="_ptc4HEh">CNNs have been proposed in <ref type="bibr" target="#b13">[14]</ref> to analyze imagery data.</s><s xml:id="_aNDx875">The name of these networks comes from the convolution operator that is an easy way to perform complex operations using convolution filter.</s><s xml:id="_wbnwsZh">CNN does not use predefined kernels, but instead learns locally connected neurons that represent data-specific kernels.</s><s xml:id="_pWSVrKh">Since these filters are applied repeatedly to the entire image, the resulting connectivity looks like a series of overlapping receptive fields.</s><s xml:id="_8SP8Er3">The main advantage of a CNN is that during back-propagation, the network has to adjust a number of parameters equal to a single instance of the filter which drastically reduces the connections from the typical NN architecture.</s><s xml:id="_MnzbsJ4">The concept of CNN is largely inspired by the neurobiological model of the visual cortex <ref type="bibr" target="#b14">[15]</ref>.</s><s xml:id="_Wuzw9Bb">The visual cortex is known to consist of maps of local receptive fields that decrease in granularity as the cortex moves anteriorly.</s><s xml:id="_BvwxN3r">This process can be briefly summarized as follows:  1) The input image is convolved using several small filters.</s></p><p xml:id="_t4ZMBev"><s xml:id="_dfctU4R">2) The output at Step 1 is subsampled.</s></p><p xml:id="_PpgVKCU"><s xml:id="_JysxQmt">3) The output at Step 2 is considered the new input and the convolution and subsampling processes are repeated until high level features can be extracted.</s><s xml:id="_VsDbwcY">According to the aforementioned schema, a typical CNN configuration consists of a sequence of convolution and subsample layers as illustrated in Fig. <ref type="figure" target="#fig_1">4</ref>.</s><s xml:id="_NTBKXh8">After the last subsampling layer, a CNN usually adopts several fully-connected layers with the aim of converting the 2-D feature maps into a 1-D vector to allow final classification.</s><s xml:id="_uTvE6Dg">Fully-connected layers can be considered like traditional NNs and they contain about 90% of the parameters of the entire CNN, which increases the effort required for training considerably.</s><s xml:id="_AQTJu7c">A common solution for solving this problem is to decrease the connections in these layers with a sparsely connected architecture.</s><s xml:id="_UxnYSKe">To this end, many configurations and variants have been proposed in literature and some of the most popular CNNs at the moment are: AlexNet <ref type="bibr" target="#b15">[16]</ref>, Clarifai <ref type="bibr" target="#b16">[17]</ref>, VGG <ref type="bibr" target="#b41">[42]</ref>, and GoogLeNet <ref type="bibr" target="#b17">[18]</ref>.</s></p><p xml:id="_FFzTwHq"><s xml:id="_TvH2JGv">A more recent deep learning approach is known as convolutional deep belief networks (CDBN) <ref type="bibr" target="#b42">[43]</ref>.</s><s xml:id="_SyCxMmF">CDBN maintains structures that are very similar to a CNN, but is trained similarly to a DBN.</s><s xml:id="_fk9reXm">Therefore, it exploits the advantages of CNN whilst making use of pretraining to initialize efficiently the network as a DBN does.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Guh9AZG">E. Software/Hardware Implementations</head><p xml:id="_v6R8qUk"><s xml:id="_Vt3BnKN">Table II lists the most popular software packages that allow implementation of customized deep learning methodologies based on the approaches described so far.</s><s xml:id="_FMe9ruC">All the software listed in the table can exploit CUDA/Nvidia support to improve performance using GPU acceleration.</s><s xml:id="_Kb2yQKJ">Adding to the growing trend of proprietary deep learning frameworks being turned into open source projects, some companies, such as Wolfram Mathematica <ref type="bibr" target="#b30">[31]</ref> and Nervana Systems <ref type="bibr" target="#b35">[36]</ref>, have decided to provide a cloud based services that allow researchers to speedup the training process.</s><s xml:id="_rsYE4CX">New GPU acceleration hardware includes purpose-built microprocessors for deep learning, such as the Nvidia DGX-1 <ref type="bibr" target="#b43">[44]</ref>.</s><s xml:id="_mZybBDC">Other possible future solutions are neuromorphic electronic systems that are usually used in computational neuroscience simulations.</s><s xml:id="_VphE2qG">These later hardware architectures intend to implement artificial neurons and synapses in a chip.</s><s xml:id="_YUvCkxC">Some current hardware designs are IBM TrueNorth, SpiNNaker <ref type="bibr" target="#b44">[45]</ref>, NuPIC, and Intel Curie.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_YBKdT9G">III. APPLICATIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_fqJKaCR">A. Translational Bioinformatics</head><p xml:id="_qpt8QmS"><s xml:id="_eYU4hjX">Bioinformatics aims to investigate and understand biological processes at a molecular level.</s><s xml:id="_fYbD6GW">The human genome project has made available a vast amount of unexplored data and allowed the development of new hypotheses of how genes and environmental factors interact together to create proteins <ref type="bibr" target="#b117">[118]</ref>, <ref type="bibr" target="#b118">[119]</ref>.</s><s xml:id="_vySfkMQ">Further advances in biotechnology have helped reduce the cost of genome sequencing and steered the focus on prognostic, diagnostic and treatment of diseases by analyzing genes and proteins.</s><s xml:id="_rnKV4FF">This can be illustrated by the fact that sequencing the first human genome cost billions of dollars, whereas today it is affordable <ref type="bibr" target="#b44">[45]</ref>.</s><s xml:id="_ArhG7Fz">Further motivated by P4 (predictive, personalized, preventive, participatory) medicine <ref type="bibr" target="#b119">[120]</ref>, bioinformatics aims to predict and prevent diseases by involving patients in the development of more efficient and personalized treatments.</s></p><p xml:id="_QrcZePM"><s xml:id="_V5d7Z28">The application of machine learning in bioinformatics (Fig. <ref type="figure" target="#fig_2">5</ref>) can be divided into three areas: prediction of biological processes, prevention of diseases and personalized treatment.</s><s xml:id="_CezgstC">These areas are found in genomics, pharmacogenomics and epigenomics.</s><s xml:id="_sbV5SAG">Genomics explores the function and information structures encoded in the DNA sequences of a living cell <ref type="bibr" target="#b120">[121]</ref>: it analyzes genes or alleles responsible for the creation of protein sequences and the expression of phenotypes.</s><s xml:id="_YHXVFmE">A goal of genomics is to identify gene alleles and environmental factors that contribute to diseases such as cancer.</s><s xml:id="_QDjjX3T">Identification of these genes can enable the design of targeted therapies <ref type="bibr" target="#b120">[121]</ref>.</s><s xml:id="_uZusDBf">Pharmacogenomics evaluates variations in an individual's drug response to treatment brought about by differences in genes.</s><s xml:id="_PDZd89H">It aims to design more efficient drugs for personalized treatment whilst reducing side effects.</s><s xml:id="_BKqcUF8">Finally, epigenomics aims to investigate protein interactions and understand higher level processes, such as transcriptome (mRNA count), proteome, and metabolome, which lead to modification in the gene's expression.</s><s xml:id="_2XKT3xU">Understanding how environmental factors affect protein formation and their interactions is a goal of epigenomics.</s></p><p xml:id="_5Uscfrk"><s xml:id="_4CTdA3q">1) Genetic Variants: splicing and alternative splicing code.</s><s xml:id="_FJAaeP8">Genetic variant aims to predict human splicing code in different tissues and understand how gene expression changes according to genetic variations.</s><s xml:id="_K79vYdc">Alternative splicing code is the process from which different transcripts are generated from one gene.</s><s xml:id="_fN2MQyv">Prediction of splicing patterns is crucial to better understand genes variations, phenotypes consequences and possible drug effect variations.</s><s xml:id="_965NNqR">Genetic variances play a significant role in the expression of several diseases and disorders, such as autism, spinal muscular atrophy, and hereditary colorectal cancer.</s><s xml:id="_phcf84F">Therefore, understanding genetic variants can be a key to provide early diagnosis.</s></p><p xml:id="_g6aeqFF"><s xml:id="_2Ga6ytX">2) Protein-Protein and Compound-Protein Interactions (CPI): Quantitative structure activity relationship (QSAR) aims to predict the protein-protein interaction normally based on structural molecular information.</s><s xml:id="_mew2gGX">CPI aims to predict the interaction between a given compound and protein.</s><s xml:id="_5D4zUyU">Protein-protein and protein-compound interactions are important in virtual screening for drug discovery: they help identifying new compounds, toxic substances, and provide significant interpretation on how a drug will affect any type of cell, targeted or not.</s><s xml:id="_u5EWxzM">Specifically to epigenomics, QSAR and CPI help modeling the RNA protein binding.</s></p><p xml:id="_gDTXMVk"><s xml:id="_Tg57Nkf">3) DNA Methylation: DNA methylation states are part of a process that changes the DNA expression without changing the DNA sequence itself.</s><s xml:id="_VKdBnRM">This can be brought about by a wide range of reasons, such as chromosome instability, transcription or translation errors, cell differentiation or cancer progression.</s></p><p xml:id="_Sb2SsTP"><s xml:id="_ABxUHme">The datasets are usually high dimensional, heterogeneous, and sometimes unbalanced.</s><s xml:id="_mG9WvP8">The conventional workflow includes data preprocessing/cleaning, feature extraction, model fitting, and evaluation <ref type="bibr" target="#b121">[122]</ref>.</s><s xml:id="_8xBSqFs">These methods do not operate on the sequence data directly but they require domain knowledge.</s><s xml:id="_p8WZwjf">For example, the ChEMBL database, used in pharmacogenomics, has millions of compounds and compound descriptors associated with a large database of drug targets <ref type="bibr" target="#b44">[45]</ref>.</s><s xml:id="_rGAEEew">Such databases encode molecular "fingerprints" and are major sources of information in drug discovery applications.</s><s xml:id="_qU2NxBk">Traditional machine learning approaches have been successful, mostly because the complexity of molecular interactions was reduced by only investigating one or two dimension of the molecule structure in the feature descriptors.</s><s xml:id="_7xKdy2v">Reducing design complexity inevitably leads to ignore some relevant but uncaptured aspects of the molecular structures <ref type="bibr" target="#b122">[123]</ref>, <ref type="bibr" target="#b123">[124]</ref>.</s><s xml:id="_GGVkuVe">However, Zhang et al. <ref type="bibr" target="#b49">[50]</ref> used deep learning to model structural features for RNA binding protein prediction and showed that using the RNA tertiary structural profile can improve outcomes.</s></p><p xml:id="_CYerygY"><s xml:id="_k8MtQdB">Extracting biomarkers or alleles of genes responsible for a specific disorder is very challenging as it requires a great amount of data from a large diversified cohort.</s><s xml:id="_uZceSKs">The markers should be present-if possible at different concentration levels throughout the disorder's evolution and patient's treatment-with a direct explanation on the phenotype changes due to the disease <ref type="bibr" target="#b124">[125]</ref>.</s><s xml:id="_svAgsxr">One approach accounting for sequence variation which limits the number of required subjects is to split the sequence into windows centered on the investigated trait.</s><s xml:id="_34rc7gf">Although this results in thousands of training examples of molecular traits even from just one genome, a large scale of DNA sequences and interactions mediated by various distant regulatory factors should be used <ref type="bibr" target="#b121">[122]</ref>.</s></p><p xml:id="_HgcCfQ6"><s xml:id="_kRNAa6t">The ability of deep learning to abstract large, complex, and unstructured data offers a powerful way of analyzing heterogeneous data such as gene alleles, proteins occurrences, and environmental factors <ref type="bibr" target="#b125">[126]</ref>.</s><s xml:id="_Mzj4wa5">Their contribution to bioinformatics has been reviewed in several related areas <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b120">[121]</ref>, <ref type="bibr" target="#b121">[122]</ref>, <ref type="bibr" target="#b123">[124]</ref>, <ref type="bibr" target="#b125">[126]</ref>- <ref type="bibr" target="#b128">[129]</ref>.</s><s xml:id="_trXQpux">In deep learning approaches, feature extraction and model fitting takes place in a unified step.</s><s xml:id="_CDjTAX6">Multilayer feature representation can capture nonlinear dependencies at multiple scales of transcriptional and epigenetic interactions and can model molecular structure and properties in a datadriven way.</s><s xml:id="_upWpWaN">These nonlinear features are invariant to small input changes which results in eliminating noise and increasing the robustness of the technique.</s></p><p xml:id="_QmEMPvh"><s xml:id="_CaK87t6">Several works have demonstrated that deep learning features outperformed methods relying on visual descriptors in the recognition and classification of cancer cells.</s><s xml:id="_35aSbPd">For example, Fakoor et al. <ref type="bibr" target="#b1">[2]</ref> proposed an autoencoder architecture based on gene expression data from different types of cancer and the same microarray dataset to detect and classify cancer.</s><s xml:id="_8Sw9u4p">Ibrahim et al. <ref type="bibr" target="#b45">[46]</ref> proposed a DBN with an active learning approach to find features in genes and microRNA that resulted in the best classification performance of various cancer diseases such as hepatocellular carcinoma, lung cancer and breast cancer.</s><s xml:id="_BkffuFQ">For breast cancer genetic detection, Khademi et al. <ref type="bibr" target="#b46">[47]</ref> overcame missing attributes and noise by combining a DBN and Bayesian network to extract features from microarray data.</s><s xml:id="_wg5jTGq">Deep learning approaches have also outperformed SVM in predicting splicing code and understanding how gene expression changes by genetic variants <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b129">[130]</ref>.</s><s xml:id="_NjHFbkQ">Angermueller et al. <ref type="bibr" target="#b51">[52]</ref> used DNN to predict DNA methylation states from DNA sequences and incomplete methylation profiles.</s><s xml:id="_b4p4Vbc">After applying to 32 embryonic mice stem cells, the baseline model was compared with the results.</s><s xml:id="_CcVCz4M">This method can be used for genome-wide downstream analyses.</s></p><p xml:id="_qnKxv7j"><s xml:id="_Wa6v4zF">Deep learning not only outperforms conventional approaches but also opens the door to more efficient methods to be developed.</s><s xml:id="_cyKu9WQ">Kearnes et al. <ref type="bibr" target="#b122">[123]</ref> described how deep learning based on graph convolutions can encode molecular structural features, physical properties, and activities in other assays.</s><s xml:id="_23gZsvf">This allows a rich representation of possible interactions beyond the molecular structural information encoded in standard databases.</s><s xml:id="_z2Da3FK">Similarly, multitask DNNs provides an intuitive model of correlation between molecule compounds and targets because information can be shared among different nodes.</s><s xml:id="_8BQWmyh">This increases robustness, reduces chances to miss information, and usually outperforms other methods that process large datasets <ref type="bibr" target="#b48">[49]</ref>.</s></p><p xml:id="_ghcWGh9"><s xml:id="_QHyuxVg">Deep learning has rapidly been adopted in the field of bioinformatics due to several open source packages.</s><s xml:id="_qAz3WNG">However, there are no standard methods of choosing model architectures and their use require expertise in computer science and biology.</s><s xml:id="_k9KmTjv">Therefore, the question of integrating the software development and the data has been raised <ref type="bibr" target="#b126">[127]</ref>.</s><s xml:id="_gFqt3du">Also, deep learning approaches do not include a standard way of establishing statistical significance, which is a limitation for future result comparisons.</s><s xml:id="_KR36hUJ">Therefore, conventional methods offer some advantages, especially in the case of small datasets.</s><s xml:id="_cUqJg7t">Although DNNs scale better to large datasets, the computational cost is high, resulting in the specific necessity of chips for massive parallel processing in order to deal with the increased complexity <ref type="bibr" target="#b44">[45]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_5TzFBrs">B. Deep Learning for Medical Imaging</head><p xml:id="_jHqZN72"><s xml:id="_eaKkSfx">Automatic medical imaging analysis is crucial to modern medicine.</s><s xml:id="_CFVE6fs">Diagnosis based on the interpretation of images can be highly subjective.</s><s xml:id="_dKY3axE">Computer-aided diagnosis (CAD) can provide an objective assessment of the underlying disease processes.</s><s xml:id="_xD2R8kX">Modeling of disease progression, common in several neurological conditions, such as Alzheimer's, multiple sclerosis, and stroke, requires analysis of brain scans based on multimodal data and detailed maps of brain regions.</s></p><p xml:id="_zyRSVbJ"><s xml:id="_sJw7ZUS">In recent years, CNNs have been adapted rapidly by the medical imaging research community because of their outstanding performance demonstrated in computer vision and their ability to be parallelized with GPUs.</s><s xml:id="_P6PspZ4">The fact that CNNs in medical imaging have yielded promising results have also been highlighted in a recent survey of CNN approaches in brain pathology segmentation <ref type="bibr" target="#b57">[58]</ref> and in an editorial of deep learning techniques in computer aided detection, segmentation, and shape analysis <ref type="bibr" target="#b75">[76]</ref>.</s></p><p xml:id="_mcESYes"><s xml:id="_nTsHM7v">Among the biggest challenges in CAD are the differences in shape and intensity of tumors/lesions and the variations in imaging protocol even within the same imaging modality.</s><s xml:id="_7w9Gg9K">In several cases, the intensity range of pathological tissue may overlap with that of healthy samples.</s><s xml:id="_rP8nXeP">Furthermore, Rician noise, nonisotropic resolution, and bias field effects in magnetic resonance images (MRI) cannot be handled automatically using simpler machine learning approaches.</s><s xml:id="_9WQf2zh">To deal with this data complexity, hand-designed features are extracted and conventional machine learning approaches are trained to classify them in a completely separate step.</s></p><p xml:id="_3y3suES"><s xml:id="_edQRCAt">Deep learning provides the possibility to automate and merge the extraction of relevant features with the classification procedure <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b64">[65]</ref>.</s><s xml:id="_SktRvMH">CNNs inherently learn a hierarchy of increasingly more complex features and, thus, they can operate directly on a patch of images centered on the abnormal tissue.</s><s xml:id="_8MufVgT">Example applications of CNNs in medical imaging include the classification of interstitial lung diseases based on computed tomography (CT) images <ref type="bibr" target="#b69">[70]</ref>, the classification of tuberculosis manifestation based on X-ray images <ref type="bibr" target="#b70">[71]</ref>, the classification of neural progenitor cells from somatic cell source <ref type="bibr" target="#b56">[57]</ref>, the detection of haemorrhages in color fundus images <ref type="bibr" target="#b68">[69]</ref> and the organ or body-part-specific anatomical classification of CT images <ref type="bibr" target="#b67">[68]</ref>.</s><s xml:id="_GmFDqtF">A body-part recognition system is also presented in Yan et al. <ref type="bibr" target="#b74">[75]</ref>.</s><s xml:id="_dTbvyJk">A multistage deep learning framework based on CNNs extracts both the patches with the most as well as least discriminative local patches in the pretraining stage.</s><s xml:id="_cRnnjGC">Subsequently, a boosting stage exploits this local information to improve performance.</s><s xml:id="_HEmVaPm">The authors point out that training based on discriminative local appearances are more accurate compared to the usage of global image context.</s><s xml:id="_HcY5yR9">CNNs have also been proposed for the segmentation of isointense stage brain tissues <ref type="bibr" target="#b130">[131]</ref> and brain extraction from multimodality MR images <ref type="bibr" target="#b55">[56]</ref>.</s></p><p xml:id="_yyjHY8a"><s xml:id="_bXENpmU">Hybrid approaches that combine CNNs with other architectures are also proposed.</s><s xml:id="_UUxDFRU">In <ref type="bibr" target="#b65">[66]</ref>, a deep learning algorithm is employed to encode the parameters of a deformable model and thus facilitate the segmentation of the left ventricle (LV) from short-axis cardiac MRI.</s><s xml:id="_qmaq9cx">CNNs are employed to automatically detect the LV, whereas deep Autoencoders are utilized to infer its shape.</s><s xml:id="_7hpxPJ6">Yu et al. <ref type="bibr" target="#b66">[67]</ref> designed a wireless capsule endoscopy classification system based on a hybrid CNN with extreme learning machine (ELM).</s><s xml:id="_jwpabVZ">The CNN constitutes a data-driven feature extractor, whereas the cascaded ELM acts as a strong classifier.</s></p><p xml:id="_qepvtN7"><s xml:id="_F9DGu9u">A comparison between different CNNs architectures concluded that deep CNNs of up to 22 layers can be useful even with limited training datasets <ref type="bibr" target="#b72">[73]</ref>.</s><s xml:id="_jep4rz5">More detailed description of various CNNs architectures proposed in medical imaging analysis is presented in previous survey <ref type="bibr" target="#b57">[58]</ref>.</s><s xml:id="_xBmA6yF">The key challenges and limitations are:</s></p><p xml:id="_DuyvgUM"><s xml:id="_PyynNcZ">1) CNNs are designed for 2-D images whereas segmentation problems in MRI and CT are inherently 3-D.</s><s xml:id="_P6JQUFd">This problem is further complicated by the anisotropic voxel size.</s><s xml:id="_vDTznyX">Although the creation of isotropic images by interpolating the data is a possibility, it can result in severely blurred images.</s><s xml:id="_7FGXf44">Another solution is to train the CNNs on orthogonal patches extracted from axial, sagittal and coronal views <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b131">[132]</ref>.</s><s xml:id="_AZTQAqF">This approach also drastically reduces the time complexity required to process 3-D information and thus alleviates the problem of overfitting.</s><s xml:id="_EuAf7Hh">2) CNNs do not model spatial dependencies.</s><s xml:id="_ByTw7Jq">Therefore, several approaches have incorporated voxel neighboring information either implicitly or by adding a pairwise term in the cost function, which is referred as conditional random field <ref type="bibr" target="#b84">[85]</ref>.</s><s xml:id="_8AZBaTQ">3) Preprocessing to bring all subjects and imaging modalities to similar distribution is still a crucial step that affects the classification performance.</s><s xml:id="_VqXnpFx">Similarly to conventional machine learning approaches, balancing the datasets with bootstrapping and selecting samples with high entropy is advantageous.</s><s xml:id="_UEQ7VaX">Perhaps, all of these limitations result from or are exacerbated by small and incomplete training datasets.</s><s xml:id="_UwaYY6U">Furthermore, there is limited availability of ground-truth/annotated data, since the cost and time to collect and manually annotate medical images is prohibitively large.</s><s xml:id="_J7SwXw7">Manual annotations are subjective and highly variable across medical experts.</s><s xml:id="_q8KyEUY">Although, it is thought that the manual annotation would require highly specialized knowledge in medicine and medical imaging physics, recent studies suggest that nonprofessional users could perform similarly <ref type="bibr" target="#b75">[76]</ref>.</s><s xml:id="_gxRfhc6">Therefore, crowdsourcing is suggested as a viable alternative to create low-cost, big ground-truth medical imaging datasets.</s><s xml:id="_yeh5Ym5">Moreover, the normal class is often over represented since the healthy tissue usually dominates and forms highly repetitive pat-terns.</s><s xml:id="_QpXdj4v">These issues result in slow convergence and overfitting.</s><s xml:id="_DcFUGAB">To alleviate the lack of training samples, transfer learning via fine tuning have been suggested in medical imaging applications <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b71">[72]</ref>, <ref type="bibr" target="#b73">[74]</ref>, <ref type="bibr" target="#b75">[76]</ref>.</s><s xml:id="_32b5DA6">In transfer learning via fine-tuning, a CNN is pretrained using a database of labeled natural images.</s><s xml:id="_ZMVQY52">The use of natural images to train CNNs in medical imaging is controversial because of the profound difference between natural and medical images.</s><s xml:id="_AAKcW3u">Nevertheless, Tajbakhsh et al. <ref type="bibr" target="#b73">[74]</ref> showed that fine-tuned CNNs based on natural images are less prone to overfitting due to the limited size training medical imaging sets and perform similarly or better than CNNs trained from scratch.</s><s xml:id="_aTF6GuG">Shin et al. <ref type="bibr" target="#b72">[73]</ref> has applied transfer learning from natural images in thoraco-abdominal lymph node detection and interstitial lung disease classification.</s><s xml:id="_m3HR3Tc">They also reported better results than training the CNNs from scratch with more consistent performances of validation loss and accuracy traces.</s><s xml:id="_J8J8CzR">Chen et al. <ref type="bibr" target="#b71">[72]</ref> applied successfully a transfer learning strategy to identify the fetal abdominal standard plane.</s><s xml:id="_cAgNHKq">The lower layers of a CNN are pretrained based on natural images.</s><s xml:id="_SeU7xm8">The approach shows improved capability of the algorithm to encode the complicated appearance of the abdominal plane.</s><s xml:id="_gBbMqnE">Multitask training has also been suggested to handle the class imbalance common in CAD applications.</s><s xml:id="_4BeeG2A">Multitasking refers to the idea of solving different classification problems simultaneously and it results in a drastic reduction of free parameters <ref type="bibr" target="#b132">[133]</ref>.</s></p><p xml:id="_bjqbHYC"><s xml:id="_fcGTcn2">Although CNNs have dominated medical image analysis applications, other deep learning approaches/architectures have also been applied successfully.</s><s xml:id="_4c4pkwp">In a recent paper, a stacked denoising autoencoder was proposed for the diagnosis of benign malignant breast lesions in ultrasound images and pulmonary nodules in CT scans <ref type="bibr" target="#b76">[77]</ref>.</s><s xml:id="_TedHsva">The method outperforms classical CAD approaches, largely due to the automatic feature extraction and noise tolerance.</s><s xml:id="_cF64bQS">Furthermore, it eliminates the image segmentation process to obtain a lesion boundary.</s><s xml:id="_HnpGN26">Shan et al. <ref type="bibr" target="#b52">[53]</ref> presented a stacked sparse autoencoder for microaneurysms detection in fundus images as an instance of a diabetic retinopathy strategy.</s><s xml:id="_YR6R94s">The proposed method learns high-level distinguishing features based only on pixel intensities.</s></p><p xml:id="_YV7EYnv"><s xml:id="_grewfMe">Various autoencoder-based learning approaches have also been applied to the automatic extraction of biomarkers from brain images and the diagnosis of neurological diseases.</s><s xml:id="_DgQTHaZ">These methods often use available public domain brain image databases such as the Alzheimer's disease neuroimaging initiative database.</s><s xml:id="_NyGuq2k">For example, a deep Autoencoder combined with a softmax output layer for regression is proposed for the diagnosis of Alzheimer's disease.</s><s xml:id="_WB47WHk">Hu et al. <ref type="bibr" target="#b133">[134]</ref> also used autoencoders for Alzheimer's disease prediction based on Functional Magnetic Resonance Images (fMRI).</s><s xml:id="_CD934cy">The results show that the proposed method achieves much better classification than the traditional means.</s><s xml:id="_DMUpMfH">On the other hand, Li et al. <ref type="bibr" target="#b60">[61]</ref> proposed an RBM approach that identifies biomarkers from MRI and positron emission tomography (PET) scans.</s><s xml:id="_h9ehbnp">They obtained an improvement of about 6% in classification accuracy compared to the standard approaches.</s><s xml:id="_NGaKCf2">Kuang et al. <ref type="bibr" target="#b59">[60]</ref> proposed an RBM approach for fMRI data to discriminate attention deficit hyperactivity disorder.</s><s xml:id="_gxdhfgJ">The system is capable of predicting the subjects as control, combined, inattentive or hyperactive through their frequency features.</s><s xml:id="_m6vMMvD">Suk et al. <ref type="bibr" target="#b58">[59]</ref> proposed a DBM to extract a latent hierarchical feature representation from 3-D patches of brain images.</s></p><p xml:id="_MwYST7R"><s xml:id="_8btCRnV">Low level image processing, such as image segmentation and registration can also benefit from deep learning models.</s><s xml:id="_DUrMAYd">Brosch et al. <ref type="bibr" target="#b63">[64]</ref> described a manifold learning approach of 3-D brain images based on DBN.</s><s xml:id="_tzGmRpA">It is different than other methods because it does not require a locally linear manifold space.</s><s xml:id="_wnHtXAq">Mansoor et al. <ref type="bibr" target="#b53">[54]</ref> developed a fully automated shape model segmentation mechanism for the analysis of cranial nerve systems.</s><s xml:id="_8y9g5j3">The deep learning approach outperforms conventional methods particularly in regions with low contrast, such as optic tracts and areas with pathology.</s><s xml:id="_eQYxt5K">In <ref type="bibr" target="#b134">[135]</ref>, a pipeline is proposed for object detection and segmentation in the context of automatically processing volumetric images.</s><s xml:id="_pqqwuGp">A novel framework called marginal space deep learning implements an object parameterization in hierarchical marginal spaces combined with automatic feature detection based on deep learning.</s><s xml:id="_Z4eXnRz">In <ref type="bibr" target="#b83">[84]</ref>, a DNN architecture called input-output deep architecture is described to solve the image labelling problem.</s><s xml:id="_6v9Z5Zn">A single NN forward step is used to assign a label to each pixel.</s><s xml:id="_zDpGud4">This method avoids the handcrafted subjective design of a model with a deep learning mechanism, which automatically extracts the dependencies between labels.</s><s xml:id="_kQspuyr">Deep learning is also used for processing hyperspectral images <ref type="bibr" target="#b82">[83]</ref>.</s><s xml:id="_XubrHpV">Spectral and spatial learned features are combined together in a hierarchical model to characterize tissues or materials.</s></p><p xml:id="_urM63sY"><s xml:id="_X4Mkv8q">In <ref type="bibr" target="#b77">[78]</ref>, a hybrid multilayered group method of data handling, which is a special NN with polynomial activation functions, has been used together with a principal component-regression analysis to recognize the liver and spleen.</s><s xml:id="_Gf6nm8r">A similar approach is used for the identification of the myocardium <ref type="bibr" target="#b78">[79]</ref> as well as the right and left kidney regions <ref type="bibr" target="#b79">[80]</ref>.</s><s xml:id="_4uJXfWv">The authors extend the method to analyze brain or lung CT images to detect cancer <ref type="bibr" target="#b80">[81]</ref>.</s><s xml:id="_caFKnCS">Zhen et al. <ref type="bibr" target="#b62">[63]</ref> presents a framework for direct biventricular volume estimation, which avoids the need of user inputs and over simplification assumptions.</s><s xml:id="_mAaBfvy">The learning process involves unsupervised cardiac image representation with multiscale deep networks and direct biventricular volume estimation with RF. Rose et al. <ref type="bibr" target="#b81">[82]</ref> propose a methodology for hierarchical clustering in application to mammographic image data.</s><s xml:id="_58CXDuf">Classification is performed based on a deep learning architecture along with a standard NN.</s></p><p xml:id="_Yfrkbx9"><s xml:id="_seeKBfy">In general, deep learning in medical imaging provides automatic discovery of object features and automatic exploration of feature hierarch and interaction.</s><s xml:id="_9pufeNS">In this way, a relatively simple training process and a systematic performance tuning can be used, making deep learning approaches improve over the state-of-the art.</s><s xml:id="_hz53X4F">However, in medical imaging analysis, their potentials have not been unfolded fully.</s><s xml:id="_PbKzR7A">To be successful in disease detection and classification approaches, deep learning requires the availability of large labeled datasets.</s><s xml:id="_DfNg6Tb">Annotating imaging datasets is an extremely time-consuming and costly process that is normally undertaken by medical doctors.</s><s xml:id="_Y77wzsH">Currently, there is a lot of debate on whether to increase the number of annotated datasets with the help of non-experts (crowd-sourcing) and how to standardize the available images to allow objective assessment of the deep learning approaches.</s><s xml:id="_FXkDhvF">Fig. <ref type="figure">6</ref>.</s><s xml:id="_PNeV6Z7">Data for health monitoring applications can be captured using a wide array of pervasive sensors that are worn on the body, implanted, or captured through ambient sensors, e.g., inertial motion sensors, ECG patches, smart-watches, EEG, and prosthetics.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7gPAxNN">C. Pervasive Sensing for Health and Wellbeing</head><p xml:id="_eR3YRPn"><s xml:id="_M9AxcaT">Pervasive sensors, such as wearable, implantable, and ambient sensors <ref type="bibr" target="#b135">[136]</ref> allow continuous monitoring of health and wellbeing, Fig. <ref type="figure">6</ref>.</s><s xml:id="_szHX4na">An accurate estimation of food intake and energy expenditure throughout the day, for example, can help tackle obesity and improve personal wellbeing.</s><s xml:id="_hqnttWQ">For elderly patients with chronic diseases, wearable and ambient sensors can be utilized to improve quality of care by enabling patients to continue living independently in their own homes.</s><s xml:id="_pNHZg3U">The care of patients with disabilities and patients undergoing rehabilitation can also be improved through the use of wearable and implantable assistive devices and human activity recognition.</s><s xml:id="_z2rheWV">For patients in critical care, continuous monitoring of vital signs, such as blood pressure, respiration rate, and body temperature, are important for improving treatment outcomes by closely analyzing the patient's condition <ref type="bibr" target="#b136">[137]</ref>.</s></p><p xml:id="_CJBhznJ"><s xml:id="_rqhxRYJ">1) Energy Expenditure and Activity Recognition: Obesity has been identified as an escalating global epidemic health problem and is found to be associated with many chronic diseases, including type 2 diabetes and cardiovascular diseases.</s><s xml:id="_hyK9sZy">Dietitian recommend that only a standard amount of calories should be consumed to maintain a healthy balance within the body.</s><s xml:id="_yDkkNtN">Accurately recording the foods consumed and physical activities performed can help to improve health and manage diseases; however, selecting features that can generalize across the wide variety of food and daily activities is a major challenge.</s><s xml:id="_wbDUxrx">A number of solutions that use smartphones or wearable devices have been proposed for managing food intake and monitoring energy expenditure.</s></p><p xml:id="_5n2j3Mz"><s xml:id="_syzpbsc">In <ref type="bibr" target="#b98">[99]</ref>, an assistive calorie measurement system is proposed to help patients and doctors to control diet-related health conditions.</s><s xml:id="_tRknvHY">The proposed smartphone-based system estimates the calories contained in pictures of food taken by the user.</s><s xml:id="_XmqBeph">In order to recognize food accurately in the system, a CNN is used.</s><s xml:id="_dHJFJ7q">In <ref type="bibr" target="#b99">[100]</ref>, deep learning, mobile cloud computing, distance estimation, and size calibration tools are implemented on a mobile device for food calorie estimation.</s></p><p xml:id="_RRxzj6G"><s xml:id="_CCqtrEA">To identify different activities, <ref type="bibr" target="#b89">[90]</ref> proposes to combine deep learning techniques with invariant and slowly varying features for the purpose of learning hierarchical representations from video.</s><s xml:id="_8KHGFGK">Specifically, it uses a two-layered structure with 3-D convolution and max pooling to make the method scalable to large inputs.</s><s xml:id="_PJQK2F5">In <ref type="bibr" target="#b93">[94]</ref>, a deep learning based algorithm is developed for human activity recognition using RGB-D video sequences.</s><s xml:id="_pnAacfd">A temporal structure is learnt in order to improve the classification of human activities.</s><s xml:id="_yWMZsHH"><ref type="bibr" target="#b90">[91]</ref> proposed an elderly and child care intelligent surveillance system where a three stream CNN is proposed for recognizing particular human actions such as fall and baby crawl.</s><s xml:id="_QkqDAr8">If the system detects abnormal activities, it will raise an alarm and notify family members.</s></p><p xml:id="_ufMSX7K"><s xml:id="_PMfq6sr">Zeng et al. <ref type="bibr" target="#b91">[92]</ref> compared the performance of a CNN based method on three public human activity recognition datasets and found that their deep learning approach can obtain better overall classification accuracy across different human activities as the method is more generalizable.</s><s xml:id="_qXQhctC">Ha et al. <ref type="bibr" target="#b92">[93]</ref> also used a CNN for human activity recognition.</s><s xml:id="_tJmDfsM">CNNs can capture local relationships from data as well as provide invariance against distortion, which makes it popular for learning features from images and speech.</s><s xml:id="_NWe6F35">Choi et al. <ref type="bibr" target="#b94">[95]</ref> employed RBMs to learn activities using data from smart watches and home activity datasets, respectively, with improvements shown over baseline methods.</s><s xml:id="_nzXfSTp">However, for low-power devices such as smart-watches and sensor nodes, efficiency is often a concern, especially when a deep learning method with high computational complexity is needed for learning.</s><s xml:id="_2eCNNKk">To overcome this, Ravì et al. <ref type="bibr" target="#b95">[96]</ref> proposed data preprocessing techniques to standardize and reduce variations in the input data caused by differences in sensor properties, such as placement and orientation.</s></p><p xml:id="_HkbqVsR"><s xml:id="_QJtb5kZ">2) Assistive Devices: Recognizing generic objects from the 3-D world, understanding shape and volume or classification of scene are important features required for assistive devices.</s><s xml:id="_h8hX9g5">These applications are mainly developed to guide users and provide audio or tactile feedback, for example, in the case of impaired patients that need a system to avoid obstacles along the path or receive information concerned with the surrounding environment.</s><s xml:id="_HbkZxNG">For example, Poggi et al. <ref type="bibr" target="#b96">[97]</ref> proposed a robust obstacle detection system for people suffering from visual impairments.</s><s xml:id="_zXqCFbs">Here a wearable device based on CNN is designed.</s></p><p xml:id="_6qUJzDB"><s xml:id="_FnddPBa">Assistive devices that can recognize hand gestures have also been proposed for patients with disabilities-for applications such as sign language interpretation-and sterile environments in the surgical setting-to allow for touch less human-computerinteraction (HRI).</s><s xml:id="_kkAMxBp">However, gesture recognition is a very challenging task due to the complexity and large variations in hand postures.</s><s xml:id="_zyHBBuQ">Huang et al. <ref type="bibr" target="#b97">[98]</ref> proposes a method for sign language recognition which involves the use of a DNN fed with real-sense data.</s><s xml:id="_KxBa2hz">The DNN takes the 3-D coordinates of finger joints as inputs directly with no handcrafted features used.</s></p><p xml:id="_ekhKxUa"><s xml:id="_kda9jJh">3) Detection of Abnormalities in Vital Signs: For critically ill patients, identifying abnormalities in their vital signs is important.</s><s xml:id="_jMdRsu3">These episodes, however, are rare, vary between patients, and susceptible to noise and artifacts.</s><s xml:id="_FGBEsQv">Machine learning approaches have been proposed for detecting abnormalities under a varying set of condition and thus their application in a clinical setting is limited.</s><s xml:id="_C68WqrZ">Furthermore, with continuous sensing, large volumes of data can be generated, such as electroencephalography (EEG) record signal from a large number of input channels with a high temporal resolution (several kHz).</s><s xml:id="_spdXkxr">Managing this amount of time-series data requires the development of online algorithms that could process the varying types of data.</s></p><p xml:id="_hEvm9SE"><s xml:id="_K6R9fkA">Wulsin et al. <ref type="bibr" target="#b88">[89]</ref> proposed a DBN approach to detect anomalies in EEG waveforms.</s><s xml:id="_JkdaNSC">EEG is used to record electrical activity of the brain.</s><s xml:id="_qcEvs9U">Interpreting the waveforms from brain activity is challenging due to the high dimensionality of the input signal and the limited understanding of the intrinsic brain operations.</s><s xml:id="_A88YRCx">Using a large set of training data, DBNs outperform SVM and have a faster query time of around 10s for 50 000 samples.</s><s xml:id="_B4kPNtf">Jia et al. <ref type="bibr" target="#b85">[86]</ref> used a deep learning method based on RBMs to recognize affective state of EEG.</s><s xml:id="_eCEbaVe">Although the sample sets are small and noisy, the proposed method achieves greater accuracy.</s><s xml:id="_gfmuTbm">A DBN was also used for detecting arrhythmias from electrocardiography (ECG) signals.</s><s xml:id="_KWMQsPe">A DBN was also used in monitoring heart rhythm based on ECG data <ref type="bibr" target="#b86">[87]</ref>.</s><s xml:id="_hscnEgm">The main purpose of the system is identifying arrhythmias which are a complex pattern recognition problem.</s><s xml:id="_8YtfARU">Yan et al. attained classification accuracies of 98% using a two-lead ECG dataset.</s><s xml:id="_vJXFP4Y">For low-power wearable and implantable EEG sensors, where energy consumption and efficiency are major concerns, Wang et al. <ref type="bibr" target="#b87">[88]</ref> designed a DBN to compress the signal.</s><s xml:id="_49tngBb">This results in more than 50% of energy savings while retaining accuracy for neural decoding.</s></p><p xml:id="_XDHRVP9"><s xml:id="_FsVHwpB">The introduction of deep learning has increased the utility of pervasive sensing across a range of health applications by improving the accuracy of sensors that measure food calorie intake, energy expenditure, activity recognition, sign language interpretation, and detection of anomalous events in vital signs.</s><s xml:id="_CBGQXzB">Many applications use deep learning to achieve greater efficiency and performance for real-time processing on low-power devices; however, a greater focus should be placed upon implementations on neuromorphic hardware platforms designed for low-power parallel processing.</s><s xml:id="_gKg5B7Q">The most significant improvements in performance have been achieved where the data has high dimensionality-as seen in the EEG datasets-or high variability-due to changes in sensor placement, activity, and subject.</s><s xml:id="_v5GZqQJ">Most current research has focused on the recognition of activities of daily living and brain activity.</s><s xml:id="_3tbMARQ">Many opportunities for other applications and diseases remain, and many currently studies still rely upon relatively small datasets that may not fully capture the variability of the real world.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_eZYy9Df">D. Medical Informatics</head><p xml:id="_2esQRWN"><s xml:id="_ZcGZx28">Medical Informatics focuses on the analysis of large, aggregated data in health-care settings with the aim to enhance and develop clinical decision support systems or assess medical data both for quality assurance and accessibility of health care services.</s><s xml:id="_CTFHhxu">Electronic health records (EHR) are an extremely rich source of patient information, which include medical history details such as diagnoses, diagnostic exams, medications and treatment plans, immunization records, allergies, radiology images, sensors multivariate times series (such as EEG from intensive care units), laboratory, and test results.</s><s xml:id="_yVryrWC">Efficient mining of this big data would provide valuable insight into disease management <ref type="bibr" target="#b137">[138]</ref>, <ref type="bibr" target="#b138">[139]</ref>.</s><s xml:id="_xrYrs6F">Nevertheless, this is not trivial because of several reasons:</s></p><p xml:id="_gdYZsy4"><s xml:id="_nBu2MT9">1) Data complexity owing to varying length, irregular sampling, lack of structured reporting and missing data.</s><s xml:id="_UnHvy4B">The quality of reporting varies considerably among institutions and persons.</s><s xml:id="_FkaG4m5">2) Multimodal datasets of several petabytes that includes medical images, sensors data, lab results, and unstructured text reports.</s><s xml:id="_qDh9jdV">3) Long-term time dependencies between clinical events and disease diagnosis and treatment that complicates learning.</s><s xml:id="_aGT6ZRq">For example, long and varying delays often separate the onset of disease from the appearance of symptoms.</s><s xml:id="_mnMw3Dd">4) Inability of traditional machine learning approaches to scale up to large and unstructured datasets.</s><s xml:id="_W2jCudA">5) Lack of interpretability of results hinders adaptation of the methods in the clinical setting.</s><s xml:id="_y7VBWUj">Deep learning approaches have been designed to scale up well with big and distributed datasets.</s><s xml:id="_xXQKWvM">The success of DNNs is largely due to their ability to learn novel features/patterns and understand data representation in both an unsupervised and supervised hierarchical manners.</s><s xml:id="_caQKesF">DNNs have also proven to be efficient in handling multimodal information since they can combine several DNN architectural components.</s><s xml:id="_WCzzqq2">Therefore, it is unsurprising that deep learning has quickly been adopted in medical informatics research.</s><s xml:id="_wQS8Z5j">For example, Shin et al. <ref type="bibr" target="#b104">[105]</ref> presented a combined text-image CNN to identify semantic information that links radiology images and reports from a typical picture archiving and communication system hospital system.</s><s xml:id="_5zZvAXD">Liang et al. <ref type="bibr" target="#b106">[107]</ref> used a modified version of CDBN as an effective training method for large-scale datasets on hypertension, and Chinese medical diagnosis from a manually converted EHR database.</s><s xml:id="_tGv3cBn">Putin et al. <ref type="bibr" target="#b107">[108]</ref> applied DNNs for identifying markers that predict human chronological age based on simple blood tests.</s><s xml:id="_kh7bC2y">Nie et al. <ref type="bibr" target="#b102">[103]</ref> proposed a deep learning network for automatic disease inference, which requires manual gathering the key symptoms or questions related to the disease.</s></p><p xml:id="_GXhTbMt"><s xml:id="_sFrApYA">In another study, Mioto et al. <ref type="bibr" target="#b101">[102]</ref> showed that a stack of denoising autoencoders can be used to automatically infer features from a large-scale EHR database and represent patients without requiring additional human effort.</s><s xml:id="_H7958vs">These general features can be used in several scenarios.</s><s xml:id="_j8u3Hba">The authors demonstrated the ability of their system to predict the probability of a patient developing specific diseases, such as diabetes, schizophrenia and cancer.</s><s xml:id="_xH3jNbB">Furthermore, Futoma et al. <ref type="bibr" target="#b108">[109]</ref> compared different models in their ability to predict hospital readmissions based on a large EHR database.</s><s xml:id="_XU49ujn">DNNs have significantly higher prediction accuracies than conventional approaches, such as penalized logistic regression, though training of the DNN models were not straightforward.</s></p><p xml:id="_5uhb5GR"><s xml:id="_muG6rDX">To tackle time dependencies in EHR with multivariate time series from intensive care monitoring systems, <ref type="bibr">Lipton et al. [106]</ref> employed a LSTM RNN.</s><s xml:id="_wckXXcE">The reason for using RNNs is that their ability to memorize sequential events could improve the modeling of the varying time delays between the onsets of emergency clinical events, such as respiratory distress and asthma attack and the appearance of symptoms.</s><s xml:id="_smVf7Jp">In a related study, Mehrabi et al. <ref type="bibr" target="#b103">[104]</ref> proposed the use DBN to discover common temporal patterns and characterize disease progression.</s><s xml:id="_2EnpSxj">The authors highlighted that the ability to discern and interpret the newly discovered patterns requires further investigation.</s></p><p xml:id="_u9pRctJ"><s xml:id="_HN6mjNH">The motivations behind these studies are to develop general purpose systems to accurately predict length of stay, future illness, readmission, and mortality with the view to improve clinical decision making and optimize clinical pathways.</s><s xml:id="_PVExDXJ">Early prediction in health care is directly related to saving patients' lives.</s><s xml:id="_tN5eGb6">Furthermore, the discovery of novel patterns can result in new hypotheses and research questions.</s><s xml:id="_Xa4xCpT">In computational phenotyping research, the goal is to discover meaningful data-driven features and disease characteristics.</s></p><p xml:id="_Yzq6Sxn"><s xml:id="_6CxgMKM">For example, Che et al. <ref type="bibr" target="#b100">[101]</ref> highlighted that although DNNs outperform conventional machine learning approaches in their ability to predict and classify clinical events, they suffer from the issue of model interpretability, which is important for clinical adaptation.</s><s xml:id="_RZ3mxKh">They pointed out that interpreting individual units can be misleading and the behavior of DNNs are more complex than originally thought.</s><s xml:id="_d6a4C9S">They suggested that once a DNN is trained with big data, a simpler model can be used to distil knowledge and mimic the prediction performance of the DNN.</s><s xml:id="_eQyJ475">To interpret features from deep learning models such as stacked denoising autoencoder and LSTM RNNs, they use gradient boosting decision trees (GBDT).</s><s xml:id="_aSmPsnm">GBDT are an ensemble of weak prediction models and in this work they represent a linear combination of functions.</s></p><p xml:id="_y99mfje"><s xml:id="_BH9Ujam">Deep learning has paved the way for personalized health care by offering an unprecedented power and efficiency in mining large multimodal unstructured information stored in hospitals, cloud providers and research organization.</s><s xml:id="_jeqrWnY">Although, it has the potential to outperform traditional machine learning approaches, appropriate initialization and tuning is important to avoid overfitting.</s><s xml:id="_c9HuTCz">Noisy and sparse datasets result in considerable fall of performance indicating that there are several challenges to be addressed.</s><s xml:id="_bQAhr4W">Furthermore, adopting these systems into clinical practice requires the ability to track and interpret the extracted features and patterns.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_R34WwBn">E. Public Health</head><p xml:id="_QzbBHZv"><s xml:id="_gbhZcm5">Public health aims to prevent disease, prolong life, and promote healthcare by analyzing the spread of disease and social behaviors in relation to environmental factors.</s><s xml:id="_pJMPgYT">Public health studies consider small localized populations to large populations that encompass several continents such as in the case of epidemics and pandemics.</s><s xml:id="_vPwCj3D">Applications involve epidemic surveillance, modeling lifestyle diseases, such as obesity, with relation to geographical areas, monitoring and predicting air quality, drug safety surveillance, etc.</s><s xml:id="_78TWAZf">The conventional predic-tive models scale exponentially with the size of the data and use complex models derived from physics, chemistry, and biology.</s><s xml:id="_zX5J4bx">Therefore, tuning these systems depend on parameterizations and ad hoc twists that only experts can provide.</s><s xml:id="_QPBC3dJ">Nevertheless, existing computational methods are able to accurately model several phenomena, including the progression of diseases or the spread of air pollution.</s><s xml:id="_heYCE9r">However, they have limited abilities in incorporating real time information, which could be crucial in controlling an epidemic or the adverse effects of a newly approved medicine.</s><s xml:id="_GAFkeNe">In contrast, deep learning approaches have a powerful generalization ability.</s><s xml:id="_rgBaVDP">They are data-driven methods that automatically build a hierarchical model and encode the information within their structure.</s><s xml:id="_J7mjzuf">Most deep learning algorithm designs are based on online machine learning and, thus, optimization of the cost function takes place sequentially as new training datasets become available.</s><s xml:id="_ZWZ64fZ">One of the simplest online optimization algorithms applied in DNNs is stochastic gradient descent.</s><s xml:id="_cDkgw7c">For these reasons, deep learning, along with recommendation systems and network analysis, are suggested as the key analysis methods for public health studies <ref type="bibr" target="#b139">[140]</ref>.</s></p><p xml:id="_QC9DtqF"><s xml:id="_t6wREB7">For example, monitoring and forecasting the concentration of air pollutants represents an area where deep learning has been successful.</s><s xml:id="_xHtwZpF">Ong et al. <ref type="bibr" target="#b109">[110]</ref> reports that poor air quality is responsible for around 60 000 annual deaths and it is the leading cause for a number of chronic obstructive pulmonary diseases.</s><s xml:id="_fptPeGe">They describe a system to predict the concentration of major air pollutant substances in Japan based on sensor data captured from over 52 cities.</s><s xml:id="_xHgVBty">The proposed DNN consists of stacked Autoencoders and is trained in an online fashion.</s><s xml:id="_hjFFNp9">This deep architecture differs from the standard deep Autoencoders in that the output components are added gradually during training.</s><s xml:id="_qcBMWtX">To allow tracking of the large number of sensors and interpret the results, the authors exploited the sparsity in the data and they fine-tuned the DNN based on regularization approaches.</s><s xml:id="_mxDt5H8">Nevertheless, the authors pointed out that deep learning approaches as data-driven methods are affected by the inaccuracies and incompleteness of real-world data.</s></p><p xml:id="_YqxTmGS"><s xml:id="_Q5Qb5vQ">Another interesting application is tracking outbreaks with social media for epidemiology and lifestyle diseases.</s><s xml:id="_XgXkUSE">Social media can provide rich information about the progression of diseases, such as Influenza and Ebola, in real time.</s><s xml:id="_gjeUsNG">Zhao et al. <ref type="bibr" target="#b115">[116]</ref> used the microblogging social media service, Twitter, to continuously track health states from the public.</s><s xml:id="_V7pMvkz">DNN is used to mine epidemic features that are then combined into a simulated environment to model the progression of disease.</s><s xml:id="_9dMtjgn">Text from Twitter messages can also be used to gain insight into antibiotics and infectious intestinal diseases.</s><s xml:id="_HHCMwrj">In <ref type="bibr" target="#b111">[112]</ref>, DBN is used to categorize antibiotic-related Twitter posts into nine classes (side effects, wanting/needing, advertisement, advice/information, animals, general use, resistance, misuse, and other).</s><s xml:id="_JERGs2w">To obtain the classifier, Twitter messages were randomly selected for manual labeling and categorization.</s><s xml:id="_2NF6bqS">They used a training set of 412 manually labeled and 150 000 unlabeled examples.</s><s xml:id="_eATbaee">A deep learning approach based on RBMs was pretrained in a layerby-layer procedure.</s><s xml:id="_X8ZCrvG">Fine-tuning was based on standard back propagation and the labeled data.</s><s xml:id="_REBwfKC">In <ref type="bibr" target="#b113">[114]</ref>, deep learning is used to create a topical vocabulary of keywords related to three types of infectious intestinal disease-campylobacter, norovirus, and food poisoning.</s><s xml:id="_TCgCZpA">When compared to officially documented cases, their results show that social media can be a good predictor of intestinal diseases.</s></p><p xml:id="_asQxySg"><s xml:id="_rvPJ3MH">For tracking certain stigmatized behaviors, social media can also provide information that is often undocumented; Garimella et al. <ref type="bibr" target="#b114">[115]</ref> used geographically-tagged images from Instagram to track lifestyle diseases, such as obesity, drinking, and smoking, and compare the self-categorization of images from the user against annotations obtained using a deep learning algorithm.</s><s xml:id="_Zst3hx2">The study found that while self-annotation generally provides useful demographic information, machine generated annotations were more useful for behaviors such as excessive drinking and substance abuse.</s><s xml:id="_XrVKjR4">In <ref type="bibr" target="#b110">[111]</ref>, a deep learning approach based on RBMs is designed to model and predict activity level and prevent obesity by taking into account self-motivation, social influences and environment events.</s></p><p xml:id="_QsvaHew"><s xml:id="_JbZtXTr">There is a growing interest in using mobile phone metadata to characterize and track human behavior.</s><s xml:id="_RmmUdGh">Metadata normally includes the duration and the location of the phone call or text message and it can provide valuable demographic information.</s><s xml:id="_zhkZEkj">A CNN was applied in predicting demographic information from mobile phone metadata, which was represented as temporal 2-D matrices.</s><s xml:id="_6nCxYRC">The CNN is comprised of a series of five horizontal convolution layers followed by a vertical convolution filter and two dense layers.</s><s xml:id="_cjsK5cg">The method provides high accuracy for age and gender prediction, whereas it eliminates the need for handcrafted features <ref type="bibr" target="#b112">[113]</ref>.</s></p><p xml:id="_UPDzyj9"><s xml:id="_TtSPcVU">Mining the online data and metadata about individuals and large-scale populations via EHRs, mobile networks and social media is a means to inform public health and policy.</s><s xml:id="_HB6Cs7v">Furthermore, mining food and drug records to identify adverse events could provide vital large scale alert mechanisms.</s><s xml:id="_d3A5ezu">We have presented a few examples that use deep learning for early identification and modeling the spread of epidemics and public health risks.</s><s xml:id="_8JSMdah">However, strict regulation that protects data privacy limits the access and aggregation of the relevant information.</s><s xml:id="_myrvFTq">For example, Twitter messages or Facebook posts could be used to identify new mothers at risk from postpartum depression.</s><s xml:id="_t5tzVD9">Although, this is positive, there is controversy associated of whether this information should become available, since it stigmatizes specific individuals.</s><s xml:id="_YNbNS5E">Therefore, it has become evident that we need to strike a balance between ensuring individuals can control access to their private medical information and providing pathways on how to make information available for public health studies <ref type="bibr" target="#b116">[117]</ref>.</s><s xml:id="_s6kWneB">The complexity and limited interpretability of deep learning models constitute an obstacle in allowing an informed decision about the precise operation of a DNN, which may limit its application in sensitive data.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jxTBfqh">IV. DEEP LEARNING IN HEALTHCARE: LIMITATIONS AND CHALLENGES</head><p xml:id="_yrxgSBH"><s xml:id="_nQ25C5z">Although for different artificial intelligence tasks, deep learning techniques can deliver substantial improvements in comparison to traditional machine learning approaches, many researchers and scientists remain sceptical of their use where medical applications are involved.</s><s xml:id="_kUNtnTT">These scepticisms arise since deep learning theories have not yet provided complete solutions and many questions remain unanswered.</s><s xml:id="_rPfC8D4">The following four aspects summarize some of the potential issues associated with deep learning:</s></p><p xml:id="_H8dWeTE"><s xml:id="_ctu7RG6">1) Despite some recent work on visualizing high level features by using the weight filters in a CNN <ref type="bibr" target="#b140">[141]</ref>, <ref type="bibr" target="#b141">[142]</ref>, the entire deep learning model is often not interpretable.</s><s xml:id="_2fMKAuM">Consequently, most researchers use deep learning approaches as a black box without the possibility to explain why it provides good results or without the ability to apply modifications in the case of misclassification issues.</s><s xml:id="_Ht4R3tV">2) As we have already highlighted in the previous sections, to train a reliable and effective model, large sets of training data are required for the expression of new concepts.</s></p><p xml:id="_fnQMb3M"><s xml:id="_ud5vtUn">Although recently we have witnessed an explosion of available healthcare data with many organizations starting to effectively transform medical records from paper to electronic records, disease specific data is often limited.</s><s xml:id="_rraQUew">Therefore, not all applications-particularly rare diseases or events-are well suited to deep learning.</s><s xml:id="_KHE7KhA">A common problem that can arise during the training of a DNN (especially in the case of small datasets) is overfitting, which may occur when the number of parameters in the network is proportional to the total number of samples in the training set.</s><s xml:id="_nu6G2MR">In this case, the network is able to memorize the training examples, but cannot generalize to new samples that it has not already observed.</s><s xml:id="_7pzwwYk">Therefore, although the error on the training set is driven to a very small value, the errors for new data will be high.</s><s xml:id="_YmZfjwx">To avoid the overfitting problem and improve generalization, regularization methods, such as the dropout <ref type="bibr" target="#b142">[143]</ref>, are usually exploited during training.</s><s xml:id="_mxs9yxR">3) Another important aspect to take into account when deep learning tools are employed, is that for many applications the raw data cannot be directly used as input for the DNN.</s><s xml:id="_pgKrWj4">Thus, preprocessing, normalization or change of input domain is often required before the training.</s><s xml:id="_D93dXVy">Moreover, the setup of many hyperparameters that control the architecture of a DNN, such as the size and the number of filter in a CNN, or its depth, is still a blind exploration process that usually requires accurate validation.</s><s xml:id="_PwJjFtF">Finding the correct preprocessing of the data and the optimal set of hyperparameters can be challenging, since it makes the training process even longer, requiring significant training resources and human expertise, without which is not possible to obtain an effective classification model.</s><s xml:id="_gF4wBkZ">4) The last aspect that we would like to underline is that many DNNs can be easily fooled.</s><s xml:id="_ZthfRtB">For example, <ref type="bibr" target="#b143">[144]</ref> shows that it is possible to add small changes to the input samples (such as imperceptible noise in an image) to cause samples to be misclassified.</s><s xml:id="_keXC8jJ">However, it is important to note that almost all machine learning algorithms are susceptible to such issues.</s><s xml:id="_WMrXBZM">Values of particular features can be deliberately set very high or very low to induce misclassification in logistic regression.</s><s xml:id="_3zH7ZjJ">Simi-larly, for decision tress, a single binary feature can be used to direct a sample along the wrong partition by simply switching it at the final layer.</s><s xml:id="_xhpXnXM">Hence in general, any machine learning models are susceptible to such manipulations.</s><s xml:id="_2J4c4pq">On the other hand, the work in <ref type="bibr" target="#b144">[145]</ref> discusses the opposite problem.</s><s xml:id="_7EZxyn5">The author shows that it is possible to obtain meaningless synthetic samples that are strongly classified into classes even though they should not have been classified.</s><s xml:id="_nc97Zdz">This is also a genuine limitation of the deep learning paradigm, but it is a drawback for other machine learning algorithms as well.</s><s xml:id="_ukczUVk">To conclude, we believe that healthcare informatics today is a human-machine collaboration that may ultimately become a symbiosis in the future.</s><s xml:id="_zRxdVve">As more data becomes available, deep learning systems can evolve and deliver where human interpretation is difficult.</s><s xml:id="_Vk2dSSC">This can make diagnoses of diseases faster and smarter and reduce uncertainty in the decision making process.</s><s xml:id="_e76XZXt">Finally, the last boundary of deep learning could be the feasibility of integrating data across disciplines of health informatics to support the future of precision medicine.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_MgJRT89">V. CONCLUSION</head><p xml:id="_MR5XXQ7"><s xml:id="_5g24vM5">Deep learning has gained a central position in recent years in machine learning and pattern recognition.</s><s xml:id="_38FcGcS">In this paper, we have outlined how deep learning has enabled the development of more data-driven solutions in health informatics by allowing automatic generation of features that reduce the amount of human intervention in this process.</s><s xml:id="_F7DR4Xs">This is advantageous for many problems in health informatics and has eventually supported a great leap forward for unstructured data such as those arising from medical imaging, medical informatics, and bioinformatics.</s><s xml:id="_pnq3e6b">Until now, most applications of deep learning to health informatics have involved processing health data as an unstructured source.</s><s xml:id="_8AUxKPD">Nonetheless, a significant amount of information is equally encoded in structured data such as EHRs, which provide a detailed picture of the patient's history, pathology, treatment, diagnosis, outcome, and the like.</s><s xml:id="_hfTRKAQ">In the case of medical imaging, the cytological notes of a tumor diagnosis may include compelling information like its stage and spread.</s><s xml:id="_aPXev49">This information is beneficial to acquire a holistic view of a patient condition or disease and then be able to improve the quality of the obtained inference.</s><s xml:id="_P58Hywx">In fact, robust inference through deep learning combined with artificial intelligence could ameliorate the reliability of clinical decision support systems.</s><s xml:id="_ynvDff7">However, several technical challenges remain to be solved.</s><s xml:id="_48ncz7V">Patient and clinical data is costly to obtain and healthy control individuals represent a large fraction of a standard health dataset.</s><s xml:id="_Hd643e8">Deep learning algorithms have mostly been employed in applications where the datasets were balanced, or, as a work-around, in which synthetic data was added to achieve equity.</s><s xml:id="_7yarQcA">The later solution entails a further issue as regards the reliance of the fabricated biological data samples.</s><s xml:id="_GURmEAm">Therefore, methodological aspects of NNs need to be revisited in this regard.</s><s xml:id="_THE6Xfu">Another concern is that deep learning predominantly depends on large amounts of training data.</s><s xml:id="_v8Mbrcr">Such requirements make more critical the classical entry barriers of machine learning, i.e., data availability and privacy.</s><s xml:id="_HshEPAY">Consequently, advances in the development of seamless and fast equipment for health monitoring and diagnoses will play a prominent role in future research.</s><s xml:id="_m7kQVqg">Reference to the issue of computational power, we envisage that for the years to come, further ad hoc hardware platforms for neural networks and deep learning processing will be announced and made commercially available.</s><s xml:id="_sh9xfrS">It is worth noting that the rise of deep learning has been mightily supported by major IT companies (e.g., Google, Facebook, and Baidu) which hold a large extent of patents in the field and core businesses are substantially supported by data gathering, enormous storehouses and processing machines.</s><s xml:id="_yqvHa9f">Many researchers have been encouraged to apply deep learning to any data-mining and pattern recognition problem related to health informatics in light of the wide availability of free packages to support this research.</s><s xml:id="_mT2mynP">Looking at it from the bright side, it has fostered an interesting trend and boosted the expectations of what machine learning could achieve on its own.</s><s xml:id="_4MgzFWc">Nevertheless, we should not consider deep learning as a silver bullet for every single challenge set by health informatics.</s><s xml:id="_QPayky2">In practice, it is still questionable whether the large amount of training data and computational resources needed to run deep learning at full performance is worthwhile, considering other fast learning algorithms that may produce close performance with fewer resources, less parameterization, tuning, and higher interpretability.</s><s xml:id="_AN5zFUm">Therefore, we conclude that deep learning has provided a positive revival of NNs and connectionism from the genuine integration of the latest advances in parallel processing enabled by coprocessors.</s><s xml:id="_FYTpBwE">Nevertheless, a sustained concentration of health informatics research exclusively around deep learning could slow down the development of new machine learning algorithms with a more conscious use of computational resources and interpretability.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc><div><p xml:id="_2bA3UFW"><s xml:id="_NKnkXeV">Fig. 3. Schematic illustration of simple NNs without deep structures.</s><s xml:id="_JTKDQ3N">(a) Autoencoder.</s><s xml:id="_6kAXT3Z">(b) Restricted Boltzmann machine.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc><div><p xml:id="_9vB7HPZ"><s xml:id="_5TCd7Nd">Fig. 4. Basic architecture of CNN which consists in several layers of convolution and subsampling to efficiently process images.</s></p></div></figDesc><graphic coords="6,306.45,66.40,240.00,186.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc><div><p xml:id="_VUW5SUt"><s xml:id="_Z7RhjjS">Fig. 5. Overview of the different inputs and applications in biomedical and health informatics.</s></p></div></figDesc><graphic coords="6,303.83,302.21,244.34,173.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="10,302.87,66.65,246.14,229.94" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div xml:id="_bpRAyvA"><p xml:id="_TEJ6WYV"><s xml:id="_FQmTDrY">This work was supported by the <rs type="funder">EPSRC Smart Sensing for Surgery</rs> (<rs type="grantNumber">EP/L014149/1</rs>) and in part by the <rs type="funder">EPSRC-NIHR</rs> <rs type="grantName">HTC Partnership Award</rs> (<rs type="grantNumber">EP/M000257/1</rs> and <rs type="grantNumber">EP/N027132/1</rs>).</s></p><p xml:id="_WXXvvnC"><s xml:id="_JSRdRn6">The authors are with the <rs type="institution">Hamlyn Centre, Imperial College London</rs>,</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Vp9YTd5">
					<idno type="grant-number">EP/L014149/1</idno>
				</org>
				<org type="funding" xml:id="_uvpjUHa">
					<idno type="grant-number">EP/M000257/1</idno>
					<orgName type="grant-name">HTC Partnership Award</orgName>
				</org>
				<org type="funding" xml:id="_PFrBERN">
					<idno type="grant-number">EP/N027132/1</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_25QGhqm"><p xml:id="_YfypwpD"><s xml:id="_UzHdaEw">Authors' photographs and biographies not available at the time of publication.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_KSzhc2T">Improving computer-aided detection using convolutional neural networks and random view aggregation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GGc8Tcn">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1170" to="1181" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H. R. Roth et al., &quot;Improving computer-aided detection using convolu- tional neural networks and random view aggregation,&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1170-1181, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_8rXU96G">Using deep learning to enhance cancer diagnosis and classification</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fakoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_e34qqKM">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note type="raw_reference">R. Fakoor, F. Ladhak, A. Nazi, and M. Huber, &quot;Using deep learning to enhance cancer diagnosis and classification,&quot; in Proc. Int. Conf. Mach. Learn., 2013, pp. 1-7.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_UbSpSSD">Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Delong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Weirauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2Qphycw">Nature Biotechnol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="831" to="838" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">B. Alipanahi, A. Delong, M. T. Weirauch, and B. J. Frey, &quot;Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning,&quot; Nature Biotechnol., vol. 33, pp. 831-838, 2015.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_kpf3dMw">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature14539</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6majDfA">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Y. LeCun, Y. Bengio, and G. Hinton, &quot;Deep learning,&quot; Nature, vol. 521, no. 7553, pp. 436-444, 2015.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_Uqkk6D2">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Ua5RYyJ">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">G. E. Hinton and R. R. Salakhutdinov, &quot;Reducing the dimensionality of data with neural networks,&quot; Science, vol. 313, no. 5786, pp. 504-507, 2006.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_uVG4utM">Efficient learning of sparse representations with an energy-based model</title>
		<author>
			<persName><forename type="first">C</forename><surname>Poultney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_9JyDF6G">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1137" to="1144" />
		</imprint>
	</monogr>
	<note type="raw_reference">C. Poultney et al., &quot;Efficient learning of sparse representations with an energy-based model,&quot; in Proc. Adv. Neural Inf. Process. Syst., 2006, pp. 1137-1144.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_XXenjqU">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<idno type="DOI">10.1145/1390156.1390294</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_a3Deu5q">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
	<note type="raw_reference">P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, &quot;Extracting and composing robust features with denoising autoencoders,&quot; in Proc. Int. Conf. Mach. Learn., 2008, pp. 1096-1103.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_8mQWwXn">Contractive auto-encoders: Explicit invariance during feature extraction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-23783-6_41</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_HUmjvD6">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Rifai, P. Vincent, X. Muller, X. Glorot, and Y. Bengio, &quot;Contractive auto-encoders: Explicit invariance during feature extraction,&quot; in Proc. Int. Conf. Mach. Learn., 2011, pp. 833-840.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_xy9gZNX">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cires ¸an</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-21735-7_7</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_YDwp4R2">Proc. Int. Conf. Artif. Neural Netw</title>
		<meeting>Int. Conf. Artif. Neural Netw</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Masci, U. Meier, D. Cires ¸an, and J. Schmidhuber, &quot;Stacked convo- lutional auto-encoders for hierarchical feature extraction,&quot; in Proc. Int. Conf. Artif. Neural Netw., 2011, pp. 52-59.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_rN5ykXA">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.2006.18.7.1527</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZhyeHTv">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">G. E. Hinton, S. Osindero, and Y.-W. Teh, &quot;A fast learning algorithm for deep belief nets,&quot; Neural Comput., vol. 18, no. 7, pp. 1527-1554, 2006.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_nW7VHmV">Deep boltzmann machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco_a_00311</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_j8X3GKF">Proc. Int. Conf. Artif. Intell. Stat</title>
		<meeting>Int. Conf. Artif. Intell. Stat</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">R. Salakhutdinov and G. E. Hinton, &quot;Deep boltzmann machines.&quot; in Proc. Int. Conf. Artif. Intell. Stat., 2009, vol. 1, Art. no. 3.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_kwa2G2h">On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates</title>
		<author>
			<persName><forename type="first">L</forename><surname>Younes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_N6Ggc8T">Stochastics: An Int. J. Probab. Stochastic Process</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="177" to="228" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="raw_reference">L. Younes, &quot;On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates,&quot; Stochastics: An Int. J. Probab. Stochastic Process., vol. 65, no. 3/4, pp. 177-228, 1999.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_yNUunje">A learning algorithm for continually running fully recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zipser</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1989.1.2.270</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uT6QDqS">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="280" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R. J. Williams and D. Zipser, &quot;A learning algorithm for continually running fully recurrent neural networks,&quot; Neural Comput., vol. 1, no. 2, pp. 270-280, 1989.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_RMwyKmE">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VzfvK27">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998-11">Nov. 1998</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, &quot;Gradient-based learn- ing applied to document recognition,&quot; Proc. IEEE, vol. 86, no. 11, pp. 2278-2324, Nov. 1998.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_YErFrNb">Receptive fields, binocular interaction and functional architecture in the cat&apos;s visual cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eEHHWU6">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="106" to="154" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D. H. Hubel and T. N. Wiesel, &quot;Receptive fields, binocular interaction and functional architecture in the cat&apos;s visual cortex,&quot; J. Physiol., vol. 160, no. 1, pp. 106-154, 1962.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_2dDxtnv">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_HmRVBJf">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Krizhevsky, I. Sutskever, and G. E. Hinton, &quot;Imagenet classifica- tion with deep convolutional neural networks,&quot; in Proc. Adv. Neural Inf. Process. Syst., 2012, pp. 1097-1105.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_RgHSP3m">Visualizing and understanding convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dKPk6zp">Proc. Eur. Conf. Comput. Vision</title>
		<meeting>Eur. Conf. Comput. Vision</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. D. Zeiler and R. Fergus, &quot;Visualizing and understanding convolu- tional networks,&quot; in Proc. Eur. Conf. Comput. Vision, 2014, pp. 818-833.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_UgMNm4H">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_hWjdVD5">Proc. Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note type="raw_reference">C. Szegedy et al., &quot;Going deeper with convolutions,&quot; in Proc. Conf. Comput. Vis. Pattern Recognit., 2015, pp. 1-9.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_9XagX3u">The perceptron a perceiving and recognizing automaton</title>
		<author>
			<persName><forename type="first">R</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.21926/obm.geriatr.2001099</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6QqgDFM">Cornell Aeronautical Laboratory</title>
		<imprint>
			<biblScope unit="page" from="85" to="460" />
			<date type="published" when="1957">1957</date>
			<pubPlace>Buffalo, NY, USA, Tech. Rep</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">R. Frank, &quot;The perceptron a perceiving and recognizing automaton,&quot; Cor- nell Aeronautical Laboratory, Buffalo, NY, USA, Tech. Rep. 85-460-1, 1957.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main" xml:id="_RUrChXD">Parallel distributed processing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">J. L. McClelland et al., Parallel distributed processing. Cambridge, MA, USA: MIT Press, vol. 2, 1987.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_GzfWqTE">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=65669.104451" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_6qcaUHn">Neurocomputing: Foundations of Research</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Anderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Rosenfeld</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="696" to="699" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. E. Rumelhart, G. E. Hinton, and R. J. Williams, &quot;Learning represen- tations by back-propagating errors,&quot; in Neurocomputing: Foundations of Research, J. A. Anderson and E. Rosenfeld, Eds. Cambridge, MA, USA: MIT Press, 1988, pp. 696-699. [Online]. Available: http://dl.acm.org/ citation.cfm?id=65669.104451</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_T25c7bq">On optimization methods for deep learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Prochnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_QZmeNnd">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Ngiam, A. Coates, A. Lahiri, B. Prochnow, Q. V. Le, and A. Y. Ng, &quot;On optimization methods for deep learning,&quot; in Proc. Int. Conf. Mach. Learn., 2011, pp. 265-272.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_f3M3EkH">A few useful things to know about machine learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Mre9MDq">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="87" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">P. Domingos, &quot;A few useful things to know about machine learning,&quot; Commun. ACM, vol. 55, no. 10, pp. 78-87, 2012.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_gatG7yH">An overview of statistical learning theory</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<idno type="DOI">10.1109/72.788640</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3TWGrQR">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="988" to="999" />
			<date type="published" when="1999-09">Sep. 1999</date>
		</imprint>
	</monogr>
	<note type="raw_reference">V. N. Vapnik, &quot;An overview of statistical learning theory,&quot; IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 988-999, Sep. 1999.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_58EGyFt">Pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dCnFsgG">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="1" to="737" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">C. M. Bishop, &quot;Pattern recognition,&quot; Mach. Learn., vol. 128, pp. 1-737, 2006.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_c7BUWUn">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<idno type="DOI">10.1109/72.279181</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Wqc927t">IEEE Trans. Neural Netw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994-03">Mar. 1994</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Bengio, P. Simard, and P. Frasconi, &quot;Learning long-term dependencies with gradient descent is difficult,&quot; IEEE Trans. Neural Netw., vol. 5, no. 2, pp. 157-166, Mar. 1994.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_7xW4wPv">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WCNxddQ">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Hochreiter and J. Schmidhuber, &quot;Long short-term memory,&quot; Neural Comput., vol. 9, no. 8, pp. 1735-1780, 1997.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main" xml:id="_vuu3Yks">Caffe</title>
		<idno type="DOI">10.1093/benz/9780199773787.article.b00030126</idno>
		<ptr target="http://caffe.berkeleyvision.org/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>Center Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Center Berkeley, &quot;Caffe,&quot; 2016. [Online]. Available: http://caffe.berkeley vision.org/</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main" xml:id="_K5Su3gf">Cntk</title>
		<idno type="DOI">10.1007/978-1-4842-3658-1_17</idno>
		<ptr target="https://github.com/Microsoft/CNTK" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>Microsoft</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Microsoft, &quot;Cntk,&quot; 2016. [Online]. Available: https://github.com/ Microsoft/CNTK.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main" xml:id="_MDP9fhv">Deeplearning4j</title>
		<author>
			<persName><surname>Skymind</surname></persName>
		</author>
		<ptr target="http://deeplearning4j.org/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Skymind, &quot;Deeplearning4j,&quot; 2016.[Online]. Available: http:// deeplearning4j.org/</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main" xml:id="_GupUQ8H">Wolfram math</title>
		<author>
			<persName><forename type="first">Wolfram</forename><surname>Research</surname></persName>
		</author>
		<ptr target="https://www.wolfram.com/mathematica/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wolfram Research, &quot;Wolfram math,&quot; 2016. [Online]. Available: https://www.wolfram.com/mathematica/</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main" xml:id="_NSQsQwY">Tensorflow</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Google, &quot;Tensorflow,&quot; 2016. [Online]. Available: https://www. tensorflow.org/</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<ptr target="http://deeplearning.net/software/theano/" />
		<title level="m" xml:id="_yD8bAZJ">Theano</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>Universite de Montreal</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Universite de Montreal, &quot;Theano,&quot; 2016. [Online]. Available: http://deeplearning.net/software/theano/</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main" xml:id="_cUbY5jz">Torch</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
		<ptr target="http://torch.ch/" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R. Collobert, K. Kavukcuoglu, and C. Farabet, &quot;Torch,&quot; 2016. [Online]. Available: http://http://torch.ch/</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Franois</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io/" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_rYBGJ2T">Keras</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Franois Chollet, &quot;Keras,&quot; 2016. [Online]. Available: https://keras.io/</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<ptr target="https://github.com/NervanaSystems/neon" />
		<title level="m" xml:id="_WYZ4k2q">Nervana Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Neon</note>
	<note type="raw_reference">Nervana Systems, &quot;Neon,&quot; 2016. [Online]. Available: https://github.com/ NervanaSystems/neon</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_7jjZhqT">Learning and relearning in boltzman machines</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ackely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sejnowski</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/5236.003.0018</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_zUMxVMC">Parallel Distributed Processing: Explorations in Microstructure of Cognition</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="282" to="317" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Ackely, G. Hinton, and T. Sejnowski, &quot;Learning and relearning in boltzman machines,&quot; in Parallel Distributed Processing: Explorations in Microstructure of Cognition. Cambridge, MA, USA: MIT Press, pp. 282- 317, 1986.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main" xml:id="_6uhMEBV">Towards Bayesian deep learning: A survey</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-04">Apr. 2016</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
	<note type="raw_reference">H. Wang and D.-Y. Yeung, &quot;Towards Bayesian deep learning: A survey,&quot; ArXiv e-prints, Apr. 2016.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main" xml:id="_2GnEVMA">Probabilistic reasoning in intelligent systems: networks of plausible inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Mateo, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Pearl, Probabilistic reasoning in intelligent systems: networks of plau- sible inference. San Mateo, CA, USA: Morgan Kaufmann, 2014.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_K7KA5TP">On contrastive divergence learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Carreira-Perpinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_2UCFKGN">Proc. Int. Conf. Artif. Intell. Stat</title>
		<meeting>Int. Conf. Artif. Intell. Stat</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. A. Carreira-Perpinan and G. Hinton, &quot;On contrastive divergence learning.&quot; in Proc. Int. Conf. Artif. Intell. Stat., 2005, vol. 10, pp. 33-40.</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_XWwRS7r">Deep learning for visual understanding: A review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oerlemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zDGuvMW">Neurocomput</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="27" to="48" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, and M. S. Lew, &quot;Deep learning for visual understanding: A review,&quot; Neurocomput., vol. 187, pp. 27-48, 2016.</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_xFZYg7m">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<ptr target="http://arxiv.org/abs/1409.1556" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_KvJTJwS">CoRR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">K. Simonyan and A. Zisserman, &quot;Very deep convolutional networks for large-scale image recognition,&quot; CoRR, vol. abs/1409.1556, 2014. [Online]. Available: http://arxiv.org/abs/1409.1556</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_ADWz37A">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<idno type="DOI">10.1145/1553374.1553453</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_nERuZTV">Proc. Int. Conf. Mach. Learn</title>
		<meeting>Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
	<note type="raw_reference">H. Lee, R. Grosse, R. Ranganath, and A. Y. Ng, &quot;Convolutional deep belief networks for scalable unsupervised learning of hierarchical repre- sentations,&quot; in Proc. Int. Conf. Mach. Learn., 2009, pp. 609-616.</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main" xml:id="_HpmVye6">Nvidia dgx-1</title>
		<author>
			<orgName type="collaboration">NVIDIA corp</orgName>
		</author>
		<ptr target="http://www.nvidia.com/object/deep-learning-system.html" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">NVIDIA corp., &quot;Nvidia dgx-1,&quot; 2016. [Online]. Available: http://www. nvidia.com/object/deep-learning-system.html</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_HesnTWn">Deep artificial neural networks and neuromorphic chips for big data analysis: Pharmaceutical and bioinformatics applications</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Pastur-Romay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cedrón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pazos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Porto-Pazos</surname></persName>
		</author>
		<idno type="DOI">10.3390/ijms17081313</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Vb8GhvE">Int. J. Molecular Sci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1313</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">L. A. Pastur-Romay, F. Cedrón, A. Pazos, and A. B. Porto-Pazos, &quot;Deep artificial neural networks and neuromorphic chips for big data analysis: Pharmaceutical and bioinformatics applications,&quot; Int. J. Molecular Sci., vol. 17, no. 8, 2016, Art. no. 1313.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_ekj5X8T">Multi-level gene/mirna feature selection using deep belief nets and active learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Yousri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ismail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>El-Makky</surname></persName>
		</author>
		<idno type="DOI">10.1109/embc.2014.6944490</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_akmXp2y">Proc. Eng. Med. Biol. Soc</title>
		<meeting>Eng. Med. Biol. Soc</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3957" to="3960" />
		</imprint>
	</monogr>
	<note type="raw_reference">R. Ibrahim, N. A. Yousri, M. A. Ismail, and N. M. El-Makky, &quot;Multi-level gene/mirna feature selection using deep belief nets and active learning,&quot; in Proc. Eng. Med. Biol. Soc., 2014, pp. 3957-3960.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_vHgtVdC">Probabilistic graphical models and deep belief networks for prognosis of breast cancer</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khademi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Nedialkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_qFrYkD7">Proc. IEEE 14th Int. Conf. Mach. Learn. Appl</title>
		<meeting>IEEE 14th Int. Conf. Mach. Learn. Appl</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="727" to="732" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Khademi and N. S. Nedialkov, &quot;Probabilistic graphical models and deep belief networks for prognosis of breast cancer,&quot; in Proc. IEEE 14th Int. Conf. Mach. Learn. Appl., 2015, pp. 727-732.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_wbyPDyA">Dann: A deep learning approach for annotating the pathogenicity of genetic variants</title>
		<author>
			<persName><forename type="first">D</forename><surname>Quang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZDwWrkr">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="761" to="763" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D. Quang, Y. Chen, and X. Xie, &quot;Dann: A deep learning approach for annotating the pathogenicity of genetic variants,&quot; Bioinformatics, vol. 31, p. 761-763, 2014.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main" xml:id="_hm53hUh">Massively multitask networks for drug discovery</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Konerding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-02">Feb. 2015</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
	<note type="raw_reference">B. Ramsundar, S. Kearnes, P. Riley, D. Webster, D. Konerding, and V. Pande, &quot;Massively multitask networks for drug discovery,&quot; ArXiv e-prints, Feb. 2015.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_fpxHwZg">A deep learning framework for modeling structural features of rna-binding protein targets</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6ngv6DW">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="32" to="e32" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Zhang et al., &quot;A deep learning framework for modeling structural features of rna-binding protein targets,&quot; Nucleic Acids Res., vol. 44, no. 4, pp. e32-e32, 2016.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_Qgtf3bm">Boosting compound-protein interaction prediction by deep learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_XZdBNrT">Proc. IEEE Int. Conf. Bioinformat. Biomed</title>
		<meeting>IEEE Int. Conf. Bioinformat. Biomed</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="29" to="34" />
		</imprint>
	</monogr>
	<note type="raw_reference">K. Tian, M. Shao, S. Zhou, and J. Guan, &quot;Boosting compound-protein interaction prediction by deep learning,&quot; in Proc. IEEE Int. Conf. Bioin- format. Biomed., 2015, pp. 29-34.</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_zZysrpC">Accurate prediction of single-cell dna methylation states using deep learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Angermueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Reik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Stegle</surname></persName>
		</author>
		<idno type="DOI">10.1101/055715</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GmCjdhC">bioRxiv</title>
		<imprint>
			<biblScope unit="page">55715</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Art</note>
	<note type="raw_reference">C. Angermueller, H. Lee, W. Reik, and O. Stegle, &quot;Accurate prediction of single-cell dna methylation states using deep learning,&quot; bioRxiv, 2016, Art. no. 055715.</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_hjJBn88">A deep learning method for microaneurysm detection in fundus images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/chase.2016.12</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_6M6rkWk">Proc. IEEE Connected Health, Appl., Syst. Eng. Technol</title>
		<meeting>IEEE Connected Health, Appl., Syst. Eng. Technol</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="357" to="358" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Shan and L. Li, &quot;A deep learning method for microaneurysm detection in fundus images,&quot; in Proc. IEEE Connected Health, Appl., Syst. Eng. Technol., 2016, pp. 357-358.</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_nbZtvG4">Deep learning guided partitioned shape model for anterior visual pathway segmentation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mansoor</surname></persName>
		</author>
		<idno type="DOI">10.1109/tmi.2016.2535222</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QWVXS2J">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1856" to="1865" />
			<date type="published" when="2016-08">Aug. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A. Mansoor et al., &quot;Deep learning guided partitioned shape model for anterior visual pathway segmentation,&quot; IEEE Trans. Med. Imag., vol. 35, no. 8, pp. 1856-1865, Aug. 2016.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_n5GUN3P">3d deep learning for multi-modal imaging-guided survival time prediction of brain tumor patients</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_25</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-46723-8_25" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_4FTTh6V">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="212" to="220" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Nie, H. Zhang, E. Adeli, L. Liu, and D. Shen, &quot;3d deep learning for multi-modal imaging-guided survival time prediction of brain tumor patients,&quot; in Proc. MICCAI, 2016, pp. 212-220. [Online]. Available: http://dx.doi.org/10.1007/978-3-319-46723-8_25</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_SUKaFvp">Deep MRI brain extraction: A 3D convolutional neural network for skull stripping</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleesiek</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2016.01.024</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aGAhzX5">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="460" to="469" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Kleesiek et al., &quot;Deep MRI brain extraction: A 3D convolutional neural network for skull stripping,&quot; NeuroImage, vol. 129, pp. 460-469, 2016.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_6kUU4dF">Convolutional neural networks in automatic recognition of trans-differentiated neural progenitor cells under bright-field microscopy</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_rEATW4R">Proc. Instrum. Meas., Comput</title>
		<meeting>Instrum. Meas., Comput</meeting>
		<imprint>
			<publisher>Commun. Control</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="122" to="126" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. Jiang, X. Wang, J. Luo, X. Zhang, Y. Xiong, and H. Pang, &quot;Convo- lutional neural networks in automatic recognition of trans-differentiated neural progenitor cells under bright-field microscopy,&quot; in Proc. Instrum. Meas., Comput., Commun. Control, 2015, pp. 122-126.</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main" xml:id="_NFmK5Vy">Deep learning trends for focal brain pathology segmentation in MRI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Havaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Guizard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jodoin</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-50478-0_6</idno>
		<idno>abs/1607.05258</idno>
		<ptr target="http://arxiv.org/abs/1607.05258" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_zTgmBSS">CoRR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Havaei, N. Guizard, H. Larochelle, and P. Jodoin, &quot;Deep learning trends for focal brain pathology segmentation in MRI,&quot; CoRR, vol. abs/1607.05258, 2016. [Online]. Available: http://arxiv.org/ abs/1607.05258</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_aSBwxdy">Hierarchical feature representation and multimodal fusion with deep learning for ad/mci diagnosis</title>
		<author>
			<persName><forename type="first">H.-I</forename><surname>Suk</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2014.06.077</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HFr5UMY">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="569" to="582" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H.-I. Suk et al., &quot;Hierarchical feature representation and multimodal fusion with deep learning for ad/mci diagnosis,&quot; NeuroImage, vol. 101, pp. 569-582, 2014.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main" xml:id="_FACpHeY">Classification on ADHD with deep learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_HF5e4fn">Proc. Cloud Comput. Big Data</title>
		<meeting>Cloud Comput. Big Data</meeting>
		<imprint>
			<date type="published" when="2014-11">Nov. 2014</date>
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Kuang and L. He, &quot;Classification on ADHD with deep learning,&quot; in Proc. Cloud Comput. Big Data, Nov. 2014, pp. 27-32.</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_VtmgDje">A robust deep model for improved classification of ad/mci patients</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Thung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/jbhi.2015.2429556</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tgFVfQ5">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1610" to="1616" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">F. Li, L. Tran, K. H. Thung, S. Ji, D. Shen, and J. Li, &quot;A robust deep model for improved classification of ad/mci patients,&quot; IEEE J. Biomed. Health Inform., vol. 19, no. 5, pp. 1610-1616, Sep. 2015.</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_KzZSt6a">Deep neural networks for fast segmentation of 3d medical images</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fritscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raudaschl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zaffino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Spadea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schubert</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_19</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-46723-8_19" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_6x8MkDp">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="158" to="165" />
		</imprint>
	</monogr>
	<note type="raw_reference">K. Fritscher, P. Raudaschl, P. Zaffino, M. F. Spadea, G. C. Sharp, and R. Schubert, &quot;Deep neural networks for fast segmentation of 3d medi- cal images,&quot; in Proc. MICCAI, 2016, pp. 158-165. [Online]. Available: http://dx.doi.org/10.1007/978-3-319-46723-8_19</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main" xml:id="_ywREkzY">Multi-scale deep networks and regression forests for direct bi-ventricular volume estimation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bhaduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wThUPwr">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="120" to="129" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">X. Zhen, Z. Wang, A. Islam, M. Bhaduri, I. Chan, and S. Li, &quot;Multi-scale deep networks and regression forests for direct bi-ventricular volume estimation,&quot; Med. Image Anal., vol. 30, pp. 120-129, 2016.</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main" xml:id="_pxqkypk">Manifold learning of brain mris by deep learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_qUbhfb5">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="633" to="640" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Brosch et al., &quot;Manifold learning of brain mris by deep learning,&quot; in Proc. MICCAI, 2013, pp. 633-640.</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_HBBsPjd">Multimodal deep learning for cervical dysplasia diagnosis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_14</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-46723-8_14" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_5dBXhXp">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="115" to="123" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Xu, H. Zhang, X. Huang, S. Zhang, and D. N. Metaxas, &quot;Multimodal deep learning for cervical dysplasia diagnosis,&quot; in Proc. MICCAI, 2016, pp. 115-123. [Online]. Available: http://dx.doi.org/10.1007/978-3-319- 46723-8_14</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main" xml:id="_uenwcBf">A combined deep-learning and deformable-model approach to fully automatic segmentation of the left ventricle in cardiac mri</title>
		<author>
			<persName><forename type="first">M</forename><surname>Avendi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kheradvar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jafarkhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FuX27pk">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="108" to="119" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Avendi, A. Kheradvar, and H. Jafarkhani, &quot;A combined deep-learning and deformable-model approach to fully automatic segmentation of the left ventricle in cardiac mri,&quot; Med. Image Anal., vol. 30, pp. 108-119, 2016.</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main" xml:id="_SuQjJEU">A hybrid convolutional neural networks with extreme learning machine for WCE image classification</title>
		<author>
			<persName><forename type="first">J.-S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-X</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_fqQ2tat">Proc. IEEE Robot. Biomimetics</title>
		<meeting>IEEE Robot. Biomimetics</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1822" to="1827" />
		</imprint>
	</monogr>
	<note type="raw_reference">J.-s. Yu, J. Chen, Z. Xiang, and Y.-X. Zou, &quot;A hybrid convolutional neural networks with extreme learning machine for WCE image classification,&quot; in Proc. IEEE Robot. Biomimetics, 2015, pp. 1822-1827.</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main" xml:id="_BSWj7Cw">Anatomy-specific classification of medical images using deep convolutional nets</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_SCpZncX">Proc. IEEE Int. Symp. Biomed. Imag</title>
		<meeting>IEEE Int. Symp. Biomed. Imag</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="101" to="104" />
		</imprint>
	</monogr>
	<note type="raw_reference">H. R. Roth et al., &quot;Anatomy-specific classification of medical images using deep convolutional nets,&quot; in Proc. IEEE Int. Symp. Biomed. Imag., 2015, pp. 101-104.</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_AgPXjeU">Fast convolutional neural network training using selective data sampling: Application to hemorrhage detection in color fundus images</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Grinsven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Hoyng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Theelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SeswdbR">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1273" to="1284" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. J. van Grinsven, B. van Ginneken, C. B. Hoyng, T. Theelen, and C. I. Sánchez, &quot;Fast convolutional neural network training using selec- tive data sampling: Application to hemorrhage detection in color fun- dus images,&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1273-1284, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main" xml:id="_7fdtA4v">Lung pattern classification for interstitial lung diseases using a deep convolutional neural network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Anthimopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Christodoulidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Christe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mougiakakou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EkWsedV">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1207" to="1216" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Anthimopoulos, S. Christodoulidis, L. Ebner, A. Christe, and S. Mougiakakou, &quot;Lung pattern classification for interstitial lung dis- eases using a deep convolutional neural network,&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1207-1216, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main" xml:id="_NGGhPWD">Improving tuberculosis diagnostics using deep learning and mobile health technologies among resource-poor and marginalized communities</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ekuA6Aa">IEEE Connected Health, Appl., Syst. Eng. Technol</title>
		<imprint>
			<biblScope unit="page" from="274" to="281" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Cao et al., &quot;Improving tuberculosis diagnostics using deep learning and mobile health technologies among resource-poor and marginalized communities,&quot; in IEEE Connected Health, Appl., Syst. Eng. Technol., 2016, pp. 274-281.</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main" xml:id="_wzZU3D5">Standard plane localization in fetal ultrasound via domain transferred deep neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_muRBQZS">IEEE J. Biomed. Health Inform</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1627" to="1636" />
			<date type="published" when="2015-09">Sep. 2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H. Chen et al., &quot;Standard plane localization in fetal ultrasound via do- main transferred deep neural networks,&quot; IEEE J. Biomed. Health Inform., vol. 19, no. 5, pp. 1627-1636, Sep. 2015.</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main" xml:id="_RaP9MqW">Deep convolutional neural networks for computeraided detection: CNN architectures, dataset characteristics and transfer learning</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JpQd6us">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1285" to="1298" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H.-C. Shin et al., &quot;Deep convolutional neural networks for computer- aided detection: CNN architectures, dataset characteristics and transfer learning,&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1285-1298, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main" xml:id="_28WNV9E">Convolutional neural networks for medical image analysis: Full training or fine tuning?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<idno type="DOI">10.1109/tmi.2016.2535302</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Rrqf8Bk">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1299" to="1312" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">N. Tajbakhsh et al., &quot;Convolutional neural networks for medical image analysis: Full training or fine tuning?&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1299-1312, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main" xml:id="_r4E3g9T">Multi-instance deep learning: Discover discriminative local anatomies for bodypart recognition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1109/tmi.2016.2524985</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yT8RBBM">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1332" to="1343" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Z. Yan et al., &quot;Multi-instance deep learning: Discover discriminative local anatomies for bodypart recognition,&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1332-1343, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main" xml:id="_AzapW6D">Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique</title>
		<author>
			<persName><forename type="first">H</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3KSZVNu">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1153" to="1159" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H. Greenspan, B. van Ginneken, and R. M. Summers, &quot;Guest edito- rial deep learning in medical imaging: Overview and future promise of an exciting new technique,&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1153-1159, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main" xml:id="_VKCkEr2">Computer-aided diagnosis with deep learning architecture: Applications to breast lesions in us images and pulmonary nodules in ct scans</title>
		<author>
			<persName><forename type="first">J.-Z</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9Y2FSag">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">24454</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J.-Z. Cheng et al., &quot;Computer-aided diagnosis with deep learning ar- chitecture: Applications to breast lesions in us images and pulmonary nodules in ct scans,&quot; Sci. Rep., vol. 6, 2016, Art. no. 24454.</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main" xml:id="_3wssUmw">Medical image recognition of abdominal multi-organs by hybrid multi-layered GMDH-type neural network using principal component-regression analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ueno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_xEzs6UR">Proc. 2nd Int. Symp. Comput. Netw</title>
		<meeting>2nd Int. Symp. Comput. Netw</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Kondo, J. Ueno, and S. Takao, &quot;Medical image recognition of abdom- inal multi-organs by hybrid multi-layered GMDH-type neural network using principal component-regression analysis,&quot; in Proc. 2nd Int. Symp. Comput. Netw., 2014, pp. 157-163.</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main" xml:id="_qfnchQh">Hybrid feedback GMDH-type neural network using principal component-regression analysis and its application to medical image recognition of heart regions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Junji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_9S7vYaX">Proc. Joint 7th Int. Conf. Adv. Intell. Syst., 15th Int. Symp. Soft Comput. Intell. Syst</title>
		<meeting>Joint 7th Int. Conf. Adv. Intell. Syst., 15th Int. Symp. Soft Comput. Intell. Syst</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1203" to="1208" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Kondo, U. Junji, and S. Takao, &quot;Hybrid feedback GMDH-type neural network using principal component-regression analysis and its applica- tion to medical image recognition of heart regions,&quot; in Proc. Joint 7th Int. Conf. Adv. Intell. Syst., 15th Int. Symp. Soft Comput. Intell. Syst., 2014, pp. 1203-1208.</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main" xml:id="_Mxevx3d">The 3-dimensional medical image recognition of right and left kidneys by deep GMDH-type neural network</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ueno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_93cAERE">Proc. Int. Conf. Intell. Informat. Biomed. Sci</title>
		<meeting>Int. Conf. Intell. Informat. Biomed. Sci</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="313" to="320" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Kondo, S. Takao, and J. Ueno, &quot;The 3-dimensional medical im- age recognition of right and left kidneys by deep GMDH-type neu- ral network,&quot; in Proc. Int. Conf. Intell. Informat. Biomed. Sci., 2015, pp. 313-320.</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main" xml:id="_bAMmph8">Medical image diagnosis of lung cancer by deep feedback GMDH-type neural network</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ueno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takao</surname></persName>
		</author>
		<idno type="DOI">10.2991/jrnal.2016.2.4.11</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3Dw9yPF">Robot. Netw. Artif. Life</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="252" to="257" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">T. Kondo, J. Ueno, and S. Takao, &quot;Medical image diagnosis of lung cancer by deep feedback GMDH-type neural network,&quot; Robot. Netw. Artif. Life, vol. 2, no. 4, pp. 252-257, 2016.</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main" xml:id="_JZU5mJZ">Applying deeplayered clustering to mammography image analytics</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Arel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Karnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Paquit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_8ADxNXQ">Proc. Biomed. Sci. Eng. Conf</title>
		<meeting>Biomed. Sci. Eng. Conf</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. C. Rose, I. Arel, T. P. Karnowski, and V. C. Paquit, &quot;Applying deep- layered clustering to mammography image analytics,&quot; in Proc. Biomed. Sci. Eng. Conf., 2010, pp. 1-4.</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main" xml:id="_35c8WPV">Learning hierarchical spectral-spatial features for hyperspectral image classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ABARS4w">IEEE Trans. Cybern</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1667" to="1678" />
			<date type="published" when="2016-07">Jul. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Zhou and Y. Wei, &quot;Learning hierarchical spectral-spatial features for hyperspectral image classification,&quot; IEEE Trans. Cybern., vol. 46, no. 7, pp. 1667-1678, Jul. 2016.</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main" xml:id="_TwhFsj4">Ioda: an input/output deep architecture for image labeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lerouge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Herault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chatelain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Modzelewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Jpuawh9">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2847" to="2858" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Lerouge, R. Herault, C. Chatelain, F. Jardin, and R. Modzelewski, &quot;Ioda: an input/output deep architecture for image labeling,&quot; Pattern Recognit., vol. 48, no. 9, pp. 2847-2858, 2015.</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main" xml:id="_jsVprPR">A deep learning approach for semantic segmentation in histology tissue images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_21</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-46723-8_21" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_DfecuBZ">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="176" to="184" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Wang, J. D. MacKenzie, R. Ramachandran, and D. Z. Chen, &quot;A deep learning approach for semantic segmentation in histology tissue images,&quot; in Proc. MICCAI, 2016, pp. 176-184. [Online]. Available: http://dx.doi.org/10.1007/978-3-319-46723-8_21</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main" xml:id="_DgR2NKx">A novel semi-supervised deep learning framework for affective state recognition on eeg signals</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/bibe.2014.26</idno>
		<ptr target="http://dx.doi.org/10.1109/BIBE.2014.26" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_kYgVAE9">Proc. Int. Conf. Bioinformat. Bioeng</title>
		<meeting>Int. Conf. Bioinformat. Bioeng</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="30" to="37" />
		</imprint>
	</monogr>
	<note type="raw_reference">X. Jia, K. Li, X. Li, and A. Zhang, &quot;A novel semi-supervised deep learn- ing framework for affective state recognition on eeg signals,&quot; in Proc. Int. Conf. Bioinformat. Bioeng., 2014, pp. 30-37. [Online]. Available: http://dx.doi.org/10.1109/BIBE.2014.26</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main" xml:id="_peEJbwP">A restricted Boltzmann machine based two-lead electrocardiography classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/bsn.2015.7299399</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_YcRaS9j">Proc. 12th Int. Conf. Wearable Implantable Body Sens. Netw</title>
		<meeting>12th Int. Conf. Wearable Implantable Body Sens. Netw</meeting>
		<imprint>
			<date type="published" when="2015-06">Jun. 2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Yan, X. Qin, Y. Wu, N. Zhang, J. Fan, and L. Wang, &quot;A restricted Boltz- mann machine based two-lead electrocardiography classification,&quot; in Proc. 12th Int. Conf. Wearable Implantable Body Sens. Netw., Jun. 2015, pp. 1-9.</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main" xml:id="_nWBeK7E">Selective and compressive sensing for energy-efficient implantable neural decoding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_rP9ayXv">Proc. Biomed. Circuits Syst. Conf</title>
		<meeting>Biomed. Circuits Syst. Conf</meeting>
		<imprint>
			<date type="published" when="2015-10">Oct. 2015</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Wang, C. Song, X. Xu, F. Lin, Z. Jin, and W. Xu, &quot;Selective and compressive sensing for energy-efficient implantable neural decoding,&quot; in Proc. Biomed. Circuits Syst. Conf., Oct. 2015, pp. 1-4.</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main" xml:id="_BChq5Bw">Semi-supervised anomaly detection for eeg waveforms using deep belief nets</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wulsin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Litt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_WcvNauW">Proc. 9th Int. Conf. Mach. Learn. Appl</title>
		<meeting>9th Int. Conf. Mach. Learn. Appl</meeting>
		<imprint>
			<date type="published" when="2010-12">Dec. 2010</date>
			<biblScope unit="page" from="436" to="441" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Wulsin, J. Blanco, R. Mani, and B. Litt, &quot;Semi-supervised anomaly detection for eeg waveforms using deep belief nets,&quot; in Proc. 9th Int. Conf. Mach. Learn. Appl., Dec. 2010, pp. 436-441.</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main" xml:id="_JqGq4Cp">DL-SFA: Deeply-learned slow feature analysis for action recognition</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_bRSmKm7">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2625" to="2632" />
		</imprint>
	</monogr>
	<note type="raw_reference">L. Sun, K. Jia, T.-H. Chan, Y. Fang, G. Wang, and S. Yan, &quot;DL-SFA: Deeply-learned slow feature analysis for action recognition,&quot; in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2014, pp. 2625-2632.</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main" xml:id="_x5tv738">Human action recognition system for elderly and children care using three stream convnet</title>
		<author>
			<persName><forename type="first">C.-D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_U4pxPjd">Proc. Int. Conf. Orange Technol</title>
		<meeting>Int. Conf. Orange Technol</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="5" to="9" />
		</imprint>
	</monogr>
	<note type="raw_reference">C.-D. Huang, C.-Y. Wang, and J.-C. Wang, &quot;Human action recognition system for elderly and children care using three stream convnet,&quot; in Proc. Int. Conf. Orange Technol., 2015, pp. 5-9.</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main" xml:id="_vXKud34">Convolutional neural networks for human activity recognition using mobile sensors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="DOI">10.4108/icst.mobicase.2014.257786</idno>
		<ptr target="http://dx.doi.org/10.4108/icst.mobicase.2014.257786" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_aYvuQF4">Proc. MobiCASE</title>
		<meeting>MobiCASE</meeting>
		<imprint>
			<date type="published" when="2014-11">Nov. 2014</date>
			<biblScope unit="page" from="197" to="205" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Zeng et al., &quot;Convolutional neural networks for human activity recognition using mobile sensors,&quot; in Proc. MobiCASE, Nov. 2014, pp. 197-205. [Online]. Available: http://dx.doi.org/10.4108/icst. mobicase.2014.257786</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main" xml:id="_nStyFwE">Multi-modal convolutional neural networks for activity recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.1109/smc.2015.525</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_4bwz8WS">Proc. Int. Conf. Syst., Man, Cybern</title>
		<meeting>Int. Conf. Syst., Man, Cybern</meeting>
		<imprint>
			<date type="published" when="2015-10">Oct. 2015</date>
			<biblScope unit="page" from="3017" to="3022" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Ha, J. M. Yun, and S. Choi, &quot;Multi-modal convolutional neural net- works for activity recognition,&quot; in Proc. Int. Conf. Syst., Man, Cybern., Oct. 2015, pp. 3017-3022.</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main" xml:id="_cK3cqKa">Human activity recognition using deep belief networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yalc ¸ın</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ZRER8aC">Proc. Signal Process. Commun. Appl. Conf</title>
		<meeting>Signal ess. Commun. Appl. Conf</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1649" to="1652" />
		</imprint>
	</monogr>
	<note type="raw_reference">H. Yalc ¸ın, &quot;Human activity recognition using deep belief networks,&quot; in Proc. Signal Process. Commun. Appl. Conf., 2016, pp. 1649-1652.</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main" xml:id="_XQQjrZN">Human behavior prediction for smart homes using deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_jEZPqkg">Proc. IEEE RO-MAN</title>
		<meeting>IEEE RO-MAN</meeting>
		<imprint>
			<date type="published" when="2013-08">Aug. 2013</date>
			<biblScope unit="page" from="173" to="179" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Choi, E. Kim, and S. Oh, &quot;Human behavior prediction for smart homes using deep learning,&quot; in Proc. IEEE RO-MAN, Aug. 2013, pp. 173-179.</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main" xml:id="_KXBAcav">Deep learning for human activity recognition: A resource efficient implementation on low-power devices</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_UaUKjC5">Proc. 13th Int. Conf. Wearable Implantable Body Sens. Netw</title>
		<meeting>13th Int. Conf. Wearable Implantable Body Sens. Netw</meeting>
		<imprint>
			<date type="published" when="2016-06">Jun. 2016</date>
			<biblScope unit="page" from="71" to="76" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Ravi, C. Wong, B. Lo, and G. Z. Yang, &quot;Deep learning for human activity recognition: A resource efficient implementation on low-power devices,&quot; in Proc. 13th Int. Conf. Wearable Implantable Body Sens. Netw., Jun. 2016, pp. 71-76.</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main" xml:id="_Ss2csWe">A wearable mobility aid for the visually impaired based on embedded 3d vision and deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Poggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mattoccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_z6RF9vn">Proc. IEEE Symp. Comput. Commun</title>
		<meeting>IEEE Symp. Comput. Commun</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="208" to="213" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Poggi and S. Mattoccia, &quot;A wearable mobility aid for the visually impaired based on embedded 3d vision and deep learning,&quot; in Proc. IEEE Symp. Comput. Commun., 2016, pp. 208-213.</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main" xml:id="_7xEDtRR">Sign language recognition using real-sense</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/chinasip.2015.7230384</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ET3kqBt">Proc. IEEE ChinaSIP</title>
		<meeting>IEEE ChinaSIP</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="166" to="170" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Huang, W. Zhou, H. Li, and W. Li, &quot;Sign language recognition using real-sense,&quot; in Proc. IEEE ChinaSIP, 2015, pp. 166-170.</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main" xml:id="_F9XYHjc">Food calorie measurement using deep learning neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pouladzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kuhad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V B</forename><surname>Peddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yassine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shirmohammadi</surname></persName>
		</author>
		<idno type="DOI">10.1109/i2mtc.2016.7520547</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_RDg6Jtm">Proc. IEEE Int. Instrum. Meas. Technol. Conf. Proc</title>
		<meeting>IEEE Int. Instrum. Meas. Technol. Conf</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note type="raw_reference">P. Pouladzadeh, P. Kuhad, S. V. B. Peddi, A. Yassine, and S. Shirmohammadi, &quot;Food calorie measurement using deep learning neural network,&quot; in Proc. IEEE Int. Instrum. Meas. Technol. Conf. Proc., 2016, pp. 1-6.</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main" xml:id="_yEnrDUh">Using distance estimation and deep learning to simplify calibration in food calorie measurement</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kuhad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yassine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shimohammadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_4dNwfC3">Proc. IEEE Int. Conf. Comput. Intell. Virtual Environ. Meas. Syst. Appl</title>
		<meeting>IEEE Int. Conf. Comput. Intell. Virtual Environ. Meas. Syst. Appl</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note type="raw_reference">P. Kuhad, A. Yassine, and S. Shimohammadi, &quot;Using distance estimation and deep learning to simplify calibration in food calorie measurement,&quot; in Proc. IEEE Int. Conf. Comput. Intell. Virtual Environ. Meas. Syst. Appl., 2015, pp. 1-6.</note>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main" xml:id="_aBAQggG">Distilling knowledge from deep networks with applications to healthcare domain</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Purushotham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Khemani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-12">Dec. 2015</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
	<note type="raw_reference">Z. Che, S. Purushotham, R. Khemani, and Y. Liu, &quot;Distilling knowledge from deep networks with applications to healthcare domain,&quot; ArXiv e-prints, Dec. 2015.</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main" xml:id="_xTwgq4r">Deep patient: An unsupervised representation to predict the future of patients from the electronic health records</title>
		<author>
			<persName><forename type="first">R</forename><surname>Miotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kidd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Dudley</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep26094</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EEkGHMS">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R. Miotto, L. Li, B. A. Kidd, and J. T. Dudley, &quot;Deep patient: An unsupervised representation to predict the future of patients from the electronic health records,&quot; Sci. Rep., vol. 6, pp. 1-10, 2016.</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main" xml:id="_E3Dknwy">Disease inference from health-related questions via sparse deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_aRHMcAr">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2107" to="2119" />
			<date type="published" when="2015-08">Aug. 2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">L. Nie, M. Wang, L. Zhang, S. Yan, B. Zhang, and T. S. Chua, &quot;Disease inference from health-related questions via sparse deep learning,&quot; IEEE Trans. Knowl. Data Eng, vol. 27, no. 8, pp. 2107-2119, Aug. 2015.</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main" xml:id="_MQVkqC3">Temporal pattern and association discovery of diagnosis codes using deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mehrabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_WPF3GwH">Proc. Int. Conf. Healthcare Informat</title>
		<meeting>Int. Conf. Healthcare Informat</meeting>
		<imprint>
			<date type="published" when="2015-10">Oct. 2015</date>
			<biblScope unit="page" from="408" to="416" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Mehrabi et al., &quot;Temporal pattern and association discovery of diagno- sis codes using deep learning,&quot; in Proc. Int. Conf. Healthcare Informat., Oct. 2015, pp. 408-416.</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main" xml:id="_9e9mbJy">Interleaved text/image deep mining on a large-scale radiology database for automated image interpretation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<idno>abs/1505.00670</idno>
		<ptr target="http://arxiv.org/abs/1505.00670" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_V8JnQqJ">CoRR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H. Shin, L. Lu, L. Kim, A. Seff, J. Yao, and R. M. Summers, &quot;In- terleaved text/image deep mining on a large-scale radiology database for automated image interpretation,&quot; CoRR, vol. abs/1505.00670, 2015. [Online]. Available: http://arxiv.org/abs/1505.00670</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main" xml:id="_rJXymPc">Learning to diagnose with LSTM recurrent neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Wetzel</surname></persName>
		</author>
		<idno>abs/1511.03677</idno>
		<ptr target="http://arxiv.org/abs/1511.03677" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_566dgEf">CoRR</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Z. C. Lipton, D. C. Kale, C. Elkan, and R. C. Wetzel, &quot;Learning to diag- nose with LSTM recurrent neural networks,&quot; CoRR, vol. abs/1511.03677, 2015. [Online]. Available: http://arxiv.org/abs/1511.03677</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main" xml:id="_zZC5mpk">Deep learning for healthcare decision making with emrs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_eTgT4Vd">Proc. Int. Conf. Bioinformat. Biomed</title>
		<meeting>Int. Conf. Bioinformat. Biomed</meeting>
		<imprint>
			<date type="published" when="2014-11">Nov 2014</date>
			<biblScope unit="page" from="556" to="559" />
		</imprint>
	</monogr>
	<note type="raw_reference">Z. Liang, G. Zhang, J. X. Huang, and Q. V. Hu, &quot;Deep learning for healthcare decision making with emrs,&quot; in Proc. Int. Conf. Bioinformat. Biomed., Nov 2014, pp. 556-559.</note>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main" xml:id="_PeYf7nK">Deep biomarkers of human aging: Application of deep neural networks to biomarker development</title>
		<author>
			<persName><forename type="first">E</forename><surname>Putin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WBuQrma">Aging</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="021" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">E. Putin et al., &quot;Deep biomarkers of human aging: Application of deep neural networks to biomarker development,&quot; Aging, vol. 8, no. 5, pp. 1-021, 2016.</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main" xml:id="_emyghbW">A comparison of models for predicting early hospital readmissions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Futoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lucas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SM3uk4D">J. Biomed. Informat</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="229" to="238" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Futoma, J. Morris, and J. Lucas, &quot;A comparison of models for predicting early hospital readmissions,&quot; J. Biomed. Informat., vol. 56, pp. 229-238, 2015.</note>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main" xml:id="_ndX4X3y">Dynamically pre-trained deep recurrent neural networks using environmental monitoring data for predicting pm2. 5</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sugiura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zettsu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00521-015-1955-3</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NwCeUMR">Neural Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">B. T. Ong, K. Sugiura, and K. Zettsu, &quot;Dynamically pre-trained deep recurrent neural networks using environmental monitoring data for pre- dicting pm2. 5,&quot; Neural Comput. Appl., vol. 27, pp. 1-14, 2015.</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main" xml:id="_hg9m3B9">Social restricted Boltzmann machine: Human behavior prediction in health social networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Piniewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kil</surname></persName>
		</author>
		<idno type="DOI">10.1145/2808797.2809307</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_M73wneX">Proc. IEEE/ACM Int. Conf. Adv. Social Netw. Anal. Mining</title>
		<meeting>IEEE/ACM Int. Conf. Adv. Social Netw. Anal. Mining</meeting>
		<imprint>
			<date type="published" when="2015-08">Aug. 2015</date>
			<biblScope unit="page" from="424" to="431" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Phan, D. Dou, B. Piniewski, and D. Kil, &quot;Social restricted Boltzmann machine: Human behavior prediction in health social net- works,&quot; in Proc. IEEE/ACM Int. Conf. Adv. Social Netw. Anal. Mining, Aug. 2015, pp. 424-431.</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main" xml:id="_BqEbpNG">Characterizing the discussion of antibiotics in the Twittersphere: What is the bigger picture?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Kendra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Eickholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gandy</surname></persName>
		</author>
		<idno type="DOI">10.2196/jmir.4220</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9v5VDGQ">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">154</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R. L. Kendra, S. Karki, J. L. Eickholt, and L. Gandy, &quot;Charac- terizing the discussion of antibiotics in the Twittersphere: What is the bigger picture?&quot; J. Med. Internet Res., vol. 17, no. 6, 2015, Art. no. e154.</note>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main" xml:id="_cr2EwmD">Using deep learning to predict demographics from mobile phone metadata</title>
		<author>
			<persName><forename type="first">B</forename><surname>Felbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sundsøy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>De Montjoye</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1511.06660" />
		<imprint>
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">B. Felbo, P. Sundsøy, A. Pentland, S. Lehmann, and Y.-A. de Montjoye, &quot;Using deep learning to predict demographics from mobile phone meta- data,&quot; Feb. 2016. [Online]. Available: http://arxiv.org/abs/1511.06660</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main" xml:id="_DUagg4g">On infectious intestinal disease surveillance using social media content</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lampos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gorton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_ZP6cEVm">Proc. 6th Int. Conf. Digit. Health Conf</title>
		<meeting>6th Int. Conf. Digit. Health Conf</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="157" to="161" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. Zou, V. Lampos, R. Gorton, and I. J. Cox, &quot;On infectious intestinal disease surveillance using social media content,&quot; in Proc. 6th Int. Conf. Digit. Health Conf., 2016, pp. 157-161.</note>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main" xml:id="_P9FsySB">Social media image analysis for public health</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R K</forename><surname>Garimella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alfayad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858234</idno>
		<ptr target="http://doi.acm.org/10.1145/2858036.2858234" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_MvB7Zen">Proc. CHIConf. Human Factors Comput. Syst</title>
		<meeting>CHIConf. Human Factors Comput. Syst</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="5543" to="5547" />
		</imprint>
	</monogr>
	<note type="raw_reference">V. R. K. Garimella, A. Alfayad, and I. Weber, &quot;Social media image analysis for public health,&quot; in Proc. CHIConf. Human Factors Com- put. Syst., 2016, pp. 5543-5547. [Online]. Available: http://doi.acm. org/10.1145/2858036.2858234</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main" xml:id="_BUu9vsh">Simnest: Social media nested epidemic simulation via online semisupervised deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_uvhHXy6">Proc. IEEE Int. Conf. Data Mining</title>
		<meeting>IEEE Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
	<note type="raw_reference">L. Zhao, J. Chen, F. Chen, W. Wang, C.-T. Lu, and N. Ramakrishnan, &quot;Simnest: Social media nested epidemic simulation via online semi- supervised deep learning,&quot; in Proc. IEEE Int. Conf. Data Mining, 2015, pp. 639-648.</note>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main" xml:id="_RWjxXCH">Data, privacy, and the greater good</title>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mulligan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Rc5yKjq">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="issue">6245</biblScope>
			<biblScope unit="page" from="253" to="255" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">E. Horvitz and D. Mulligan, &quot;Data, privacy, and the greater good,&quot; Sci- ence, vol. 349, no. 6245, pp. 253-255, 2015.</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main" xml:id="_TuyvHe8">The sequence of the human genome</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Venter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cRVsVEe">Science</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="issue">5507</biblScope>
			<biblScope unit="page" from="1304" to="1351" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. C. Venter et al., &quot;The sequence of the human genome,&quot; Science, vol. 291, no. 5507, pp. 1304-1351, 2001.</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main" xml:id="_KqnDnjc">Initial sequencing and analysis of the human genome</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Lander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_N44tuxw">Nature</title>
		<imprint>
			<biblScope unit="volume">409</biblScope>
			<biblScope unit="issue">6822</biblScope>
			<biblScope unit="page" from="860" to="921" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">E. S. Lander et al., &quot;Initial sequencing and analysis of the human genome,&quot; Nature, vol. 409, no. 6822, pp. 860-921, 2001.</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main" xml:id="_WmxvpSq">Predictive, personalized, preventive, participatory (p4) cancer medicine</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Friend</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrclinonc.2010.227</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BywhK3b">Nature Rev. Clin. Oncol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="184" to="187" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">L. Hood and S. H. Friend, &quot;Predictive, personalized, preventive, partic- ipatory (p4) cancer medicine,&quot; Nature Rev. Clin. Oncol., vol. 8, no. 3, pp. 184-187, 2011.</note>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main" xml:id="_QyuxfAW">Machine learning in genomic medicine: A review of computational problems and data sets</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Delong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5CVECFx">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="176" to="197" />
			<date type="published" when="2016-01">Jan. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. K. Leung, A. Delong, B. Alipanahi, and B. J. Frey, &quot;Machine learning in genomic medicine: A review of computational problems and data sets,&quot; Proc. IEEE, vol. 104, no. 1, pp. 176-197, Jan. 2016.</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main" xml:id="_uHWTg3X">Deep learning for computational biology</title>
		<author>
			<persName><forename type="first">C</forename><surname>Angermueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pärnamaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Parts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Stegle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_emQy2nd">Molecular Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">878</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">C. Angermueller, T. Pärnamaa, L. Parts, and O. Stegle, &quot;Deep learning for computational biology,&quot; Molecular Syst. Biol., vol. 12, no. 7, 2016, Art. no. 878.</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main" xml:id="_6K6KbnV">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10822-016-9938-8</idno>
		<ptr target="http://dx.doi.org/10.1007/s10822-016-9938-8" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_SsnWYTG">J. Comput. Aided Mol. Des</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Kearnes, K. McCloskey, M. Berndl, V. Pande, and P. Riley, &quot;Molecu- lar graph convolutions: moving beyond fingerprints,&quot; J. Comput. Aided Mol. Des., vol. 30, no. 8, pp. 595-608, 2016. [Online]. Available: http://dx.doi.org/10.1007/s10822-016-9938-8</note>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main" xml:id="_Vfy95Yg">Deep learning in drug discovery</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gawehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_e4BSATE">Molecular Informat</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">E. Gawehn, J. A. Hiss, and G. Schneider, &quot;Deep learning in drug discov- ery,&quot; Molecular Informat., vol. 35, no. 1, pp. 3-14, 2016.</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main" xml:id="_kYvUm6e">Development of biomarkers to chart all alzheimer?s disease stages: The royal road to cutting the therapeutic gordian knot</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hampel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">S</forename><surname>Khachaturian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CRuYRcE">Alzheimer&apos;s Dementia</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="312" to="336" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H. Hampel, S. Lista, and Z. S. Khachaturian, &quot;Development of biomark- ers to chart all alzheimer?s disease stages: The royal road to cutting the therapeutic gordian knot,&quot; Alzheimer&apos;s Dementia, vol. 8, no. 4, pp. 312-336, 2012.</note>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main" xml:id="_kA6TqGz">Biology: The big challenges of big data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Marx</surname></persName>
		</author>
		<idno type="DOI">10.1038/498255a</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wPzJdem">Nature</title>
		<imprint>
			<biblScope unit="volume">498</biblScope>
			<biblScope unit="issue">7453</biblScope>
			<biblScope unit="page" from="255" to="260" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">V. Marx, &quot;Biology: The big challenges of big data,&quot; Nature, vol. 498, no. 7453, pp. 255-260, 2013.</note>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main" xml:id="_MKAx7Wj">The next era: Deep learning in pharmaceutical research</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ekins</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11095-016-2029-7</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xT83aTX">Pharmaceutical Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2594" to="2603" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Ekins, &quot;The next era: Deep learning in pharmaceutical re- search,&quot; Pharmaceutical Res., vol. 33, no. 11, pp. 2594-2603, 2016.</note>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main" xml:id="_be6uW5Q">Pattern recognition in bioinformatics</title>
		<author>
			<persName><forename type="first">D</forename><surname>De Ridder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>De Ridder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Reinders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RVD9MWv">Briefings Bioinformat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="633" to="647" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D. de Ridder, J. de Ridder, and M. J. Reinders, &quot;Pattern recognition in bioinformatics,&quot; Briefings Bioinformat., vol. 14, no. 5, pp. 633-647, 2013.</note>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main" xml:id="_ycW9acn">Practical recommendations for gradient-based training of deep architectures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-35289-8_26</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_tEv7Tqa">Neural Networks: Tricks of the Trade</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="437" to="478" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Bengio, &quot;Practical recommendations for gradient-based training of deep architectures,&quot; in Neural Networks: Tricks of the Trade. New York, NY, USA: Springer, 2012, pp. 437-478.</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main" xml:id="_nGEXjYB">The human splicing code reveals new insights into the genetic determinants of disease</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PPH2whH">Science</title>
		<imprint>
			<biblScope unit="volume">347</biblScope>
			<biblScope unit="issue">6218</biblScope>
			<biblScope unit="page">1254806</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">H. Y. Xiong et al., &quot;The human splicing code reveals new insights into the genetic determinants of disease,&quot; Science, vol. 347, no. 6218, 2015, Art. no. 1254806.</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main" xml:id="_zzVZ6Af">Deep convolutional neural networks for multi-modality isointense infant brain image segmentation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_z6zGx3d">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="214" to="224" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">W. Zhang et al., &quot;Deep convolutional neural networks for multi-modality isointense infant brain image segmentation,&quot; NeuroImage, vol. 108, pp. 214-224, 2015.</note>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main" xml:id="_d6NTzS8">3d deep learning for efficient and robust landmark detection in volumetric data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_qFgF3g9">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="565" to="572" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Zheng, D. Liu, B. Georgescu, H. Nguyen, and D. Comaniciu, &quot;3d deep learning for efficient and robust landmark detection in volumetric data,&quot; in Proc. MICCAI, 2015, pp. 565-572.</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main" xml:id="_CuabCUb">Spinenet: Automatically pinpointing classification evidence in spinal MRIS</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jamaludin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kadir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-46723-8_20</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-319-46723-8_20" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_ES4cWZA">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="166" to="175" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Jamaludin, T. Kadir, and A. Zisserman, &quot;Spinenet: Automatically pinpointing classification evidence in spinal MRIS,&quot; in Proc. MICCAI, 2016, pp. 166-175. [Online]. Available: http://dx.doi.org/10.1007/978- 3-319-46723-8_20</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main" xml:id="_jPVAq8n">Clinical decision support for alzheimer&apos;s disease based on deep learning and brain network</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/icc.2016.7510831</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_NcnzFxR">Proc. Int. Conf. Commun</title>
		<meeting>Int. Conf. Commun</meeting>
		<imprint>
			<date type="published" when="2016-05">May 2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note type="raw_reference">C. Hu, R. Ju, Y. Shen, P. Zhou, and Q. Li, &quot;Clinical decision support for alzheimer&apos;s disease based on deep learning and brain network,&quot; in Proc. Int. Conf. Commun., May 2016, pp. 1-6.</note>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main" xml:id="_TXQd7zU">Marginal space deep learning: Efficient architecture for volumetric image parsing</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Ghesu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RUmj3Jh">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1217" to="1228" />
			<date type="published" when="2016-05">May 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">F. C. Ghesu et al., &quot;Marginal space deep learning: Efficient architecture for volumetric image parsing,&quot; IEEE Trans. Med. Imag., vol. 35, no. 5, pp. 1217-1228, May 2016.</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<author>
			<persName><forename type="first">G.-Z</forename><surname>Yang</surname></persName>
		</author>
		<title level="m" xml:id="_jhC3Vs8">Body Sensor Networks</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>2nd ed</note>
	<note type="raw_reference">G.-Z. Yang, Body Sensor Networks, 2nd ed. New York, NY, USA: Springer, 2014.</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main" xml:id="_n48mRrQ">Machine learning and decision support in critical care</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E W</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nemati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Niehaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_nj7XU4N">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="444" to="466" />
			<date type="published" when="2016-02">Feb. 2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A. E. W. Johnson, M. M. Ghassemi, S. Nemati, K. E. Niehaus, D. A. Clifton, and G. D. Clifford, &quot;Machine learning and decision support in critical care,&quot; Proc. IEEE, vol. 104, no. 2, pp. 444-466, Feb. 2016.</note>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main" xml:id="_mnK6Epw">Big data for health</title>
		<author>
			<persName><forename type="first">J</forename><surname>Andreu-Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C Y</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Merrifield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Z</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1109/jbhi.2015.2450362</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JE4vHSs">IEEE J. Biomed. Health Informat</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1193" to="1208" />
			<date type="published" when="2015-07">Jul. 2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Andreu-Perez, C. C. Y. Poon, R. D. Merrifield, S. T. C. Wong, and G. Z. Yang, &quot;Big data for health,&quot; IEEE J. Biomed. Health Informat., vol. 19, no. 4, pp. 1193-1208, Jul. 2015.</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main" xml:id="_G8YRAck">Big data for precision medicine</title>
		<author>
			<persName><forename type="first">G.-Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Leff</surname></persName>
		</author>
		<ptr target="http://engineering.org.cn/EN/abstract/article_12197.shtml" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_57G7Auw">Engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">277</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">G.-Z. Yang and D. R. Leff, &quot;Big data for precision medicine,&quot; Engi- neering, vol. 1, no. 3, 2015, Art. no. 277. [Online]. Available: http:// engineering.org.cn/EN/abstract/article_12197.shtml</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main" xml:id="_nBaRqSP">Promises and challenges of big data computing in health sciences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bdr.2015.02.002</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dZCduCy">Big Data Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="11" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">T. Huang, L. Lan, X. Fang, P. An, J. Min, and F. Wang, &quot;Promises and challenges of big data computing in health sciences,&quot; Big Data Res., vol. 2, no. 1, pp. 2-11, 2015.</note>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main" xml:id="_tpkKVFR">Visualizing higherlayer features of a deep network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="DOI">10.5152/dir.2020.19542</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">1341</biblScope>
			<pubPlace>Montreal, QC, Canada, Tech. Rep</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Univ. Montreal</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">D. Erhan, Y. Bengio, A. Courville, and P. Vincent, &quot;Visualizing higher- layer features of a deep network,&quot; Univ. Montreal, Montreal, QC, Canada, Tech. Rep. 1341, 2009.</note>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main" xml:id="_batpeZg">Understanding representations learned in deep architectures</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">1355</biblScope>
			<pubPlace>QC, Canada, Tech. Rep</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department dInformatique et Recherche Operationnelle, University of Montreal</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">D. Erhan, A. Courville, and Y. Bengio, &quot;Understanding representations learned in deep architectures,&quot; Department dInformatique et Recherche Operationnelle, University of Montreal, QC, Canada, Tech. Rep. 1355, 2010.</note>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main" xml:id="_kUx86jA">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Qbq22Gu">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">N. Srivastava, G. E. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, &quot;Dropout: a simple way to prevent neural networks from overfitting.&quot; J. Mach. Learn. Res., vol. 15, no. 1, pp. 1929-1958, 2014.</note>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main" xml:id="_zUC5sTf">Deep neural networks are easily fooled: High confidence predictions for unrecognizable images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr.2015.7298640</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_8F6uYE7">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="427" to="436" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Nguyen, J. Yosinski, and J. Clune, &quot;Deep neural networks are easily fooled: High confidence predictions for unrecognizable images,&quot; in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2015, pp. 427-436.</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main" xml:id="_76Dmhc4">Intriguing properties of neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>abs/1312.6199</idno>
		<ptr target="http://dblp.uni-trier.de/db/journals/corr/corr1312.html#" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_nKhWEHd">CoRR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">C. Szegedy et al., &quot;Intriguing properties of neural networks.&quot; CoRR, vol. abs/1312.6199, 2013. [Online]. Available: http://dblp.uni-trier. de/db/journals/corr/corr1312.html#</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
