<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_JMyVcMJ">Investigating primary school children&apos;s embodied expression of programming Investigating primary school children&apos;s embodied expression of programming concepts concepts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
					<p type="raw">Licence Licence This work is made available under the Copyright not evaluated licence and should only be used in accordance with that licence. For more information on the specific terms, consult the repository record for this item. v1 Published in Published in International Journal of Child-Computer Copyright and reuse: Copyright and reuse: This work was downloaded from Sussex Research Open (SRO). This document is made available in line with publisher policy and may differ from the published version. Please cite the published version where possible. Copyright and all moral rights to the version of the paper presented here belong to the individual author(s) and/or other copyright owners unless otherwise stated. For more information on this work, SRO or to report an issue, you can contact the repository administrators at sro@sussex.ac.uk.</p>
				</availability>
				<date type="published" when="2023-06-01">01-06-2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kate</forename><surname>Howland</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Abrar</forename><surname>Almjally</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benedict</forename><surname>Du Boulay</surname></persName>
						</author>
						<title level="a" type="main" xml:id="_RYgA74H">Investigating primary school children&apos;s embodied expression of programming Investigating primary school children&apos;s embodied expression of programming concepts concepts</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-06-01">01-06-2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">4B22E1656F6678E0905509FDF002BBD9</idno>
					<idno type="DOI">10.1016/j.ijcci.2023.100574</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T12:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_VTvH2Nr">tangible user interface (TUI), graphical user interface (GUI), representational gesture (RG) Computing education</term>
					<term xml:id="_Da88g7h">Embodied cognition</term>
					<term xml:id="_x3Dy8SV">Gesture</term>
					<term xml:id="_VbBbwXj">Metaphor</term>
					<term xml:id="_D9UT9Xt">Abstract, User interfaces</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_Da94JHt"><p xml:id="_XRu8ykJ"><s xml:id="_vnn9Ted">The study of children's gestures has proved useful in understanding learning and conceptual development in subjects such as mathematics but has not yet been carried out in computing education.</s><s xml:id="_e62qGCn">This paper presents an analysis of the way in which children describe programming concepts and their use of spontaneous co-speech gestures.</s><s xml:id="_wEahUNr">We conducted two interviews at two different times (one directly after a programming activity, and one approximately two weeks later) with 45 primary school students in Saudi Arabia (aged 6 to 7).</s><s xml:id="_KGA5ETm">We analysed their responses when asked to explain two programming concepts: program and iteration.</s><s xml:id="_cj5e7mC">Participants using metaphorical gestures drew upon two overarching embodied metaphors in their explanations, namely (i) computing constructs as physical objects (ii) computing processes as a motion along the path.</s><s xml:id="_85pPRM4">Participants moved their hands along one of three bodybased axes (longitudinal, transverse, and frontal) when referring to chronological sequences.</s><s xml:id="_VpdzqvA">These findings were broadly in keeping with those found in previous work on University computing students' gestures.</s><s xml:id="_c6d2DZP">However, our study also showed that gestures used by child learners whose first language is a right-to-left language (i.e., Arabic) had directional differences compared to the gestures used by adult learners whose first language is a left-to-right language (e.g., English).</s><s xml:id="_zVDGrzu">This work is the first step toward understanding young children's embodied descriptions of programming concepts following introductory programming activities, and the potential role of gestures in supporting their learning.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" xml:id="_Bcz2TTC">Introduction</head><p xml:id="_yBMwPMX"><s xml:id="_gptBSdu">There are ongoing calls to enhance computer education in schools <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> and many countries have modified and extended their curricula.</s><s xml:id="_Y5GhDUk">A key challenge is the relative lack of theoretical and empirical evidence about how children learn in computing domains.</s><s xml:id="_VQZ9W5k">One theory of particular relevance is embodied cognition, which has been applied in designing and implementing learning activities and materials for other STEM domains, such as mathematics <ref type="bibr" target="#b2">[3]</ref>.</s></p><p xml:id="_UejGRsf"><s xml:id="_w4aCnmv">In particular, metaphor plays a significant role in the embodied cognition perspective <ref type="bibr" target="#b3">[4]</ref>,and it has substantial implications for computing, especially in teaching <ref type="bibr" target="#b4">[5]</ref>.</s><s xml:id="_QjYpntH">Metaphors can be expressed using different language or gestures, including hand movements produced when talking <ref type="bibr" target="#b5">[6]</ref>.</s><s xml:id="_92hmCZE">Metaphors are important in human communication and reflect human cognition, often being used by people to visualise what they are thinking <ref type="bibr" target="#b6">[7]</ref>.</s><s xml:id="_jCmDp7b">Students and teachers routinely produce gestures to communicate information alongside speech and to enhance their listeners' comprehension <ref type="bibr" target="#b7">[8]</ref>.</s><s xml:id="_wH2BkAN">Furthermore, there is increasing evidence suggesting that gesture plays a vital, potentially fundamental role, in knowledge development and change.</s><s xml:id="_49UQ9yn">Thus, understanding the use of gestures in classrooms is important in developing a deeper understanding of instructional communication and knowledge change <ref type="bibr" target="#b7">[8]</ref>.</s></p><p xml:id="_xFvP2Zn"><s xml:id="_JHbs9nB">To date, there are no published empirical studies with children that focus on gesture and adopt an embodied cognition lens to explore the conceptual development of programming concepts and their retainment of those concepts.</s><s xml:id="_XFHs9bC">In this work, we investigate the following research questions:</s></p><p xml:id="_cFNqftn"><s xml:id="_eucjF2D">• What types of gesture do children use to describe computing concepts following an introductory programming activity?</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" xml:id="_ssGSxV5">Theoretical background</head><p xml:id="_G97WY5B"><s xml:id="_uR2NgtK">Theories of embodied cognition highlight the extent to which the body and the physical world influence cognition, pointing to the coevolution of body and behaviour, emotional states, and culture <ref type="bibr" target="#b12">[13]</ref>.</s><s xml:id="_dXsHCrT">Most embodied cognition theories imply the mind is not the only source of knowledge: instead, people make meaning about their surroundings from their body-based, lived experiences <ref type="bibr" target="#b13">[14]</ref> and image schemas in the body's interaction with the world <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>.</s></p><p xml:id="_tZquu2p"><s xml:id="_FduZgZu">There are many different viewpoints on embodied cognition.</s><s xml:id="_BeEWsP3">Wilson discusses six distinct claims often argued for in theories of embodied cognition, of which the first five are: (1) cognition is situated; (2) cognition is time-pressured;</s></p><p xml:id="_sKYF6Vj"><s xml:id="_YT96Mgs">(3) we offload cognitive work onto the environment; (4) the environment is part of the cognitive system; <ref type="bibr" target="#b4">(5)</ref> cognition is for action <ref type="bibr" target="#b16">[17]</ref> .</s><s xml:id="_hYkBMWK">These five claims are related to the way humans use the environment as a dynamic resource to reduce 'online' cognitive demands.</s><s xml:id="_YMu2KPw">The sixth claim states that even our 'offline thinking' (thinking that is decoupled from the external environment, such as planning or remembering) is grounded in mental structures that originally evolved for interaction with the environment.</s><s xml:id="_vxnRJ7E">Furthermore, we depend upon these embodied resources to think, reflect, reason, and communicate diverse ideas using conceptual mapping.</s><s xml:id="_qBUXTfz">For example, there is evidence that we use conceptual metaphors to comprehend abstract concepts in term of concrete entities <ref type="bibr" target="#b17">[18]</ref>.</s><s xml:id="_sG6bvFZ">Abstract concepts refers to concepts that do not have physical constraints as they have no concrete representation in the physical world (e.g., emotions, metaphors, and thinking as an abstract action).</s><s xml:id="_psuAxRp"><ref type="bibr" target="#b18">[19]</ref>.</s><s xml:id="_tng6cfF">In contrast, concrete concepts refer to entities with a presentation in the physical world and special constraints, such as the Sun in the sky or walking as a concrete action.</s></p><p xml:id="_3DWZ3dB"><s xml:id="_PTVVbCZ">There is ongoing research on using embodied cognition to understand the way students learn and how they progress from concrete to abstract.</s><s xml:id="_pwYXuDf">Learners often express their ideas spontaneously through gesture <ref type="bibr" target="#b19">[20]</ref>.</s><s xml:id="_yXzXuDH">Many researchers study motion and gestures as a way to understand how people learn such as <ref type="bibr" target="#b19">[20]</ref> and <ref type="bibr" target="#b11">[12]</ref> and there is emerging research that addresses how young learners progress from concrete to abstract representations of computing concepts <ref type="bibr" target="#b20">[21]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GFU7egD">Embodiment and Learning Programming</head><p xml:id="_Pa5dern"><s xml:id="_jSfKAwV">Programming is a foundational concept in CS but learning to program is not easy <ref type="bibr" target="#b21">[22]</ref>.</s><s xml:id="_zz4WrNb">Even the most basic programming concepts, which are elementary to specialists, are commonly studied among novices and found difficult to understand <ref type="bibr" target="#b21">[22]</ref>.</s><s xml:id="_bbeXsGJ">Programming concepts are precisely defined and implemented, and students are required to understand what certain constructs and concepts do, such as variables, variable assignments, and flow of execution <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>.</s></p><p xml:id="_vhYmuX4"><s xml:id="_ry3QytD">Programming languages, on the other hand, are cultural instruments with complex syntaxes that were often conceived and constructed for professional usage, rather than to facilitate learning <ref type="bibr" target="#b23">[24]</ref>.</s><s xml:id="_QFjvMub">Learning programming is not easy because students find it conceptually difficult to understand; they do not grasp the program's critical features and do not know how to handle them by writing the program.</s><s xml:id="_ZeA9G8C"><ref type="bibr" target="#b22">[23]</ref>.</s><s xml:id="_PCMKceK">Students find it hard to create a mental model of how computing concepts work, a prominent example of which is the concept of pointers <ref type="bibr" target="#b24">[25]</ref>.</s><s xml:id="_kReVZ9x">Responses such as this make iteration difficult to learn for students at the primary level.</s><s xml:id="_8temNFq">Abstraction in computing is ultimately about hiding information.</s><s xml:id="_TxBnryC">Programmers write lines of code to instruct the compiler, and these lines of code do not demonstrate the complex computation and operations that are happening behind the scenes <ref type="bibr" target="#b25">[26]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_YYExkge">Conceptual metaphors</head><p xml:id="_UHcPcFa"><s xml:id="_NCqVkRP">Conceptual metaphors represent embodied experiences as they involve the generation of image schemas that map metaphors to abstract concepts.</s><s xml:id="_Bb5W2s7">For example, the concept of time is grounded in the experience of linear motion, and for many cultures, the past is behind while the future is in front <ref type="bibr" target="#b26">[27]</ref>.</s><s xml:id="_Ea2CwZc">A conceptual metaphor involves the mapping between a source domain such as movement and a target domain such as time.</s><s xml:id="_qKETcvT">The target domain is understood unconsciously in terms of the relations that are rooted in the source domain, which is entrenched in everyday sensorimotor experience.</s><s xml:id="_NqG3ppH">Thus, conceptual metaphors demonstrate the human ability to think and reason about abstract concepts <ref type="bibr" target="#b27">[28]</ref> .</s><s xml:id="_p5zSSzE">In 2021, Bettin and Ott explored the perception of metaphors in computing education.</s><s xml:id="_nCdBSPN">They discussed the possible potential of using metaphors in computing education which can lead to greater development in learning and enrich the field of computing education <ref type="bibr" target="#b4">[5]</ref> .</s></p><p xml:id="_jkaR79G"><s xml:id="_KH9bwmn">Most empirical work in this area investigates conceptual metaphors that are expressed through language.</s><s xml:id="_GhFJE7h">For example, in mathematics, words such as "count out" and "next" might indicate a conceptualisation of numbers as a collection of objects or as points along a path <ref type="bibr" target="#b17">[18]</ref>.</s><s xml:id="_PN7gDFE">Language is not the only way people use conceptual metaphors: they can also be expressed using gestures, which provide another way to express our understanding of abstract concepts.</s></p><p xml:id="_aZHMTZz"><s xml:id="_CSCrgKC">In 2009, Bakker et al. argued that abstract concepts are initially understood experientially before children can articulate them in speech, and that the limited number of metaphors that children use may be connected to conceptual difficulties for the age group <ref type="bibr" target="#b28">[29]</ref> .</s><s xml:id="_W96JkSP">This suggests that the use of conceptual metaphors reflects understanding and is powerful in communication and learning.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_CUJzc2C">Gestures</head><p xml:id="_JFsKpKD"><s xml:id="_ZF2NxDb">According to McNeill in 1992, gestures are spontaneous hand movements that accompany speech <ref type="bibr" target="#b29">[30]</ref>.</s><s xml:id="_XR7D8Vu">Speech is considered analytic, while a gesture is more global and image-based, providing a unique lens to examine meaning <ref type="bibr" target="#b30">[31]</ref>.</s><s xml:id="_ZQvvCWu">Gesture, unlike speech, involves iconic mapping as a vital mechanism of meaning creation.</s><s xml:id="_PeJfkUW">Mapping is a cognitive process of perceiving similarity and linking it between one thing and another.</s><s xml:id="_pPhEkW6">For example, the receiver is engaging in a mapping process when they see a hand in a certain configuration and conclude that the hand represents a physical entity being talked about in the accompanying discourse <ref type="bibr" target="#b31">[32]</ref>.</s></p><p xml:id="_ZxPfaeG"><s xml:id="_ChZZs5b">Approximately 20 years of research literature has documented the potential benefits and roles of gestures to support learning, whether observed or produced <ref type="bibr" target="#b32">[33]</ref>.</s><s xml:id="_GGVxYD5">Gestures may simply be indicative of understanding <ref type="bibr" target="#b28">[29]</ref> or deliberately used to convey understanding <ref type="bibr" target="#b33">[34]</ref>, but there is also evidence that they may actively help in processing and learning, including problem-solving <ref type="bibr" target="#b34">[35]</ref> and/or generating new ideas <ref type="bibr" target="#b19">[20]</ref>.</s><s xml:id="_AyKR9q9">However, in some contexts, it is challenging to distinguish between the different roles of gestures to support learning.</s></p><p xml:id="_Tg25nQt"><s xml:id="_2Juakws">One way in which gestures may support learning directly is by allowing cognitive offloading to the environment.</s><s xml:id="_rkZh3e3">Ping in 2008 found that children taught using gestures outperformed their counterparts on solving Piagetian conservation problems, regardless of the physical presence of objects during instruction <ref type="bibr" target="#b33">[34]</ref>.</s><s xml:id="_48SWZ6C"><ref type="bibr" target="#b34">Cook et al. in 2012</ref> found that performing gestures that coordinated with the speech while solving math problems enabled the participants to recall more information than when they did not gesture <ref type="bibr" target="#b34">[35]</ref>.</s><s xml:id="_dhm3ena">Previous research has suggested that gestures enhance learning and problem solving by encouraging learners to link abstract concepts or to act out the abstract concept to give learners a concrete representation with which they may engage.</s><s xml:id="_QPWZxtJ">In 1996, Schwartz et al. suggested that spontaneous gestures are physical illustrations of mental models.</s><s xml:id="_S3PPkzp">The authors found that their participants used hand gestures to represent the movement of gears when solving interlocking gear problems, which supported them in imagining the correct directions of movement of the gears.</s><s xml:id="_VWaQsup">In turn, they progressively learned to abstract rules over mental depictions to solve gear problems <ref type="bibr" target="#b35">[36]</ref>.</s></p><p xml:id="_gePE5Am"><s xml:id="_2nzuQxc">Gestures can also convey knowledge that is not expressed in speech, either incidentally or deliberately, to assist the observer's understanding <ref type="bibr" target="#b33">[34]</ref>.</s><s xml:id="_t333Kpp">Therefore, understanding gestures can provide teachers with insights into learners' thinking.</s><s xml:id="_9eAryhu">For example, Novak and Goldin-Meadow described how the child stated that a given volume of water changed when it was poured from a tall, thin container into a short, fat container <ref type="bibr" target="#b19">[20]</ref>.</s><s xml:id="_qAsH8WF">Additionally, Teachers can assess learning using gestures <ref type="bibr" target="#b36">[37]</ref> as they provide additional information about the speaker's conceptualisations by externalising dynamic visual imagery to support cognitive activity.</s><s xml:id="_asaHQCC">Students' gestures and teachers' gestures can support communication and improve learning <ref type="bibr" target="#b37">[38]</ref> and there are benefits identified in training teachers to use gestures <ref type="bibr" target="#b38">[39]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3" xml:id="_2g2zYdb">Related work</head><p xml:id="_fXdkrW4"><s xml:id="_27AQt6Y">Gestures have been studied in different learning fields, such as mathematics and reading comprehension <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>.</s><s xml:id="_NwhkYqK">However, there is little research describing the role of gestures in learning in computing education.</s><s xml:id="_CdzNmqz">In this section, we give an overview of the few studies that have explored the role of gestures in computing education.</s></p><p xml:id="_ZceKhYc"><s xml:id="_bwrdxqg">Solomon et al. conducted an exploratory study observing high school students with a total of eight participants and their gestures as part of an introductory computing course using Scratch <ref type="bibr" target="#b41">[42]</ref>.</s><s xml:id="_vSmXA5t">Students learned about variables, conditional statements, and loops for 12 weeks.</s><s xml:id="_Ty65WBf">At the end of the course, 15-minute interviews were conducted with the participants in which they explained the topics they had covered in the course.</s><s xml:id="_mM22ffX">The researchers aimed to understand the types of gesture that students and teachers produced in the course.</s><s xml:id="_VnBmcFX">They used McNeil's textonym, which is a gesture taxonomy for mathematics <ref type="bibr" target="#b30">[31]</ref>.</s><s xml:id="_MyrYBBx">They reported some of the challenges of fitting McNeill's taxonomy to the data, emphasising the need for a particular conceptual framework to support gesture analysis in computing education.</s><s xml:id="_uc5kh6X">They stated that gestures in computing courses are potentially used as problem-solving strategies and to communicate students' understanding of abstract concepts.</s></p><p xml:id="_AxmQa4K"><s xml:id="_2TqPp8h">A more recent study by Manches et al. investigated the conceptual metaphors generated by university-level computing students <ref type="bibr" target="#b11">[12]</ref>.</s><s xml:id="_2kRHeCT">They examined gestures by asking 16 participants to explain three computing concepts (algorithm, loop and conditional).</s><s xml:id="_WecFpMW">Although they were not asked to use gesture, the participants produced 368 representational and metaphorical gestures, suggesting that CS concepts are often embodied through gestures.</s><s xml:id="_B3VYwnV">Manches and colleagues found that participants mapped their gesturing onto two embodied metaphors.</s><s xml:id="_VqhfEka">The first metaphor was computing constructs as a physical objects.</s><s xml:id="_Wv7N7Cc">In this case, participants simulated manipulating physical objects when referring to a range of computing constructs.</s><s xml:id="_3yV2Jxw">The second metaphor represented computing processes as motion along a path, in which participants moved their hands along one of three body-based axes when referencing temporal sequences.</s></p><p xml:id="_S2Ppx5c"><s xml:id="_W5K96s5">Sanford, et al., interviewed 10 CS instructors regarding their use of metaphor in the classroom <ref type="bibr" target="#b42">[43]</ref>.</s><s xml:id="_6vnu5fE">The purpose of this study was to understand the role that metaphors have for CS instructors, to identify the many types of metaphors that are employed, and to evaluate how well they facilitate learning.</s><s xml:id="_ZJhAJJP">Their findings showed that instructors used metaphors widely.</s><s xml:id="_vm2RCuS">However, the instructors could not always explain the common questions and misunderstandings that students had when using those metaphors.</s><s xml:id="_gUhdUD6">Therefore, additional research is needed into student thinking about computing concepts when scaffolded by metaphors.</s></p><p xml:id="_EkNcHDp"><s xml:id="_53jwkWg">As a first study to explore teachers' uses of gesture in computer classrooms, Solomon et al., described teachers' use of embodied representations in the form of gestures, embodied language, and tools used in two case studies on teaching recursion <ref type="bibr" target="#b43">[44]</ref>.</s><s xml:id="_srYcKax">Using a grounded theory approach, they analysed video recordings of undergraduate computing instructors teaching recursion.</s><s xml:id="_amcAN3b">They produced a conceptual framework of the gestures that teachers used in computer classrooms, which was the first step to understanding how embodied representation supported learners.</s><s xml:id="_s99E964">However, the study could not distinguish between the intentional and non-intentional (spontaneous) use of embodied representations.</s><s xml:id="_mCypGzJ">Investigating whether the use of embodied representation is intentional might help in critical studies and reflect an understanding of what instructors are communicating.</s><s xml:id="_BFTrsxR">In mathematics, the use of scripted gestures has helped children to retain the knowledge they learned <ref type="bibr" target="#b44">[45]</ref>.</s><s xml:id="_Ksffcpe">This might apply in computing education, as well.</s><s xml:id="_tYQVrxc">However, computing education researchers first need to understand and explore what types of gesture teachers and students produce spontaneously in the classroom and what effects these gestures have on learning.</s><s xml:id="_uxpezUM">This is what the next study addressed.</s></p><p xml:id="_JPh6ujv"><s xml:id="_ntNPdgX">Almjally et al. investigated children's spontaneous gestures when learning fundamental programming concepts through either a tangible user interface (TUI) or a graphical user interface (GUI) <ref type="bibr" target="#b45">[46]</ref>.</s><s xml:id="_9884aNU">They explored the relationship between spontaneous gestures, interface type and learning outcomes in a programming lesson for primary school students aged 6-7.</s><s xml:id="_dGx6xU9">In their study, 34 participants engaged in a learning activity lasting approximately 37 minutes.</s><s xml:id="_n7cy45k">The sessions were video recorded and subsequently coded and analysed using the Alibali gesture analysis scheme <ref type="bibr" target="#b7">[8]</ref>, adapted from research in mathematics education.</s><s xml:id="_qj9SwxD">They found a statistically significant difference between the mean learning gains of high-frequency gesturers and low-frequency gesturers, with the top quartile showing significant learning gains.</s><s xml:id="_Xv2ck7v">Overall, 1020 gestures were generated, including 702 pointing, 306 literal representations and 12 metaphorical representations.</s></p><p xml:id="_6UAXRxx"><s xml:id="_3B7WV4m">Some additional studies have examined young children's verbal explanations of computing concepts such as <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>.</s><s xml:id="_A2yHfat">However, these studies did not investigate gesture use, and were not conducted with children who had previously taken part in programming activities, so the concepts described were very general.</s><s xml:id="_Hj8JX4R">This work provides a broader view of children's expression of computing concepts, with a focus on embodied expression.</s><s xml:id="_h9hH8fQ">It explores the types of gesture that young children use when explaining programming concepts on two separate occasions (directly after a programming activity and approximately two weeks later).</s><s xml:id="_Z5e8M93">Additionally, this work explores how young children map abstract concepts to concrete concepts.</s><s xml:id="_7PmDeY7">Through this work, we aim to encourage other computing education researchers to investigate the roles of gesture further in computing education and other STEM subjects.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" xml:id="_SKrcb86">Method</head><p xml:id="_yBeFzM4"><s xml:id="_MFXaAng">This study draws upon the learning sciences theoretical framework of embodied cognition and the methodological tools of cognitive linguistics and gesture research to investigate participants' use of gesture when responding to interview questions.</s><s xml:id="_ydkdp2V">The meaning of their gestures was interpreted from context, which was the verbal response to the structured interview <ref type="bibr" target="#b31">[32]</ref>.</s><s xml:id="_hJzVXXh">Interviews are often used with children to prompt explanations of their understanding of computing <ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_NqfE5mH">Participants</head><p xml:id="_3dZdnJC"><s xml:id="_QqaXZaE">The study was conducted at an international school in Saudi Arabia.</s><s xml:id="_SGmx55s">Participants were from 5 single-gender classes (two girls' classes, three boys' classes), and all had participated in a previous study with the researcher.</s><s xml:id="_p43wna5">The children learned fundamental computer concepts using a block-based programming language.</s><s xml:id="_qSWPnpW">Thus, participants were familiar with the basic programming concepts asked about in the interview.</s><s xml:id="_8c8CavF">Fifty students in total participated (25 girls, 25 boys, all aged between 6 and 7).</s><s xml:id="_rZnUUyq">The participants were interviewed at two different times after the previous study, with two weeks between the interviews.</s><s xml:id="_92nXTgQ">This was to check in changes in understanding might occurred of delay in two weeks.</s><s xml:id="_F634cyT">Parents gave informed consent for their children to participate in the study.</s><s xml:id="_Y52e3zZ">The focus on embodied responses in the study was not explicitly mentioned to participants, however, the parental consent form stated that this was the main focus of this study.</s><s xml:id="_VwcVSdR">Children gave verbal assent before each interview.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9zUCMEy">Data collection</head><p xml:id="_qpDYGPQ"><s xml:id="_9vM3Nx4">This study was conducted via interviews, in which participants were asked to explain their understanding of computing concepts.</s><s xml:id="_uhYyMme">The approach of using interviews to prompt gestures is in line with the work of Solomon et al. and Manches et al. <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b41">42]</ref>, who investigated the use of gesture in computing education with older learners.</s></p><p xml:id="_sey2mfW"><s xml:id="_cVtxztr">Although observing gestures produced spontaneously in the classroom as Almjally et al. <ref type="bibr" target="#b45">[46]</ref> did gives valuable naturalistic evidence about the use of gestures in learning, our goal here was to collect evidence on the types of gestures and conceptual metaphors children use when describing specific computing concepts, which meant that interviews were the most appropriate method.</s><s xml:id="_G27gfUW">The interview provides a context for the generation of rich data over a short period and consistently among participants.</s><s xml:id="_3ma9AcX">This metho was therefore a good match for our aim of investigating the embodied representations (gestures) which children spontaneously produce while explaining computing concepts.</s></p><p xml:id="_8eyrr8Z"><s xml:id="_fuV5gMU">The way questions (see Table <ref type="table" target="#tab_0">1</ref>) were asked influenced children's explanations, and thus the questions were intended to be as open and non-prescriptive as possible <ref type="bibr" target="#b48">[49]</ref>.</s><s xml:id="_Huha4yv">The questions were asked first in English and then translated immediately to Arabic, using the two languages alternately just as the children's teachers do in the classroom.</s><s xml:id="_rkc7ZE8">Interviews were video recorded using a GoPro video camera positioned in such a way as to observe children's hand movements.</s></p><p xml:id="_TfFVGuv"><s xml:id="_RQh7UNy">All participants were asked to explain the same concepts in the same order.</s><s xml:id="_ykRumeT">For some questions, participants were given a code snippet on a sheet of paper that they were then asked to explain; this provision may have influenced gestures, such as deictic gestures used directly toward the resources <ref type="bibr" target="#b16">[17]</ref>.</s><s xml:id="_Wyyue6U">Therefore, we recorded all the types of gestures, including the deictic gesture.</s></p><p xml:id="_WHmvvnD"><s xml:id="_zEuAGeQ">This study adhered to university ethical guidelines and the ministry of education rules in Saudi Arabia.</s><s xml:id="_UPqzb2H">It was conducted at an international school in Riyadh, Saudi Arabia.</s><s xml:id="_8tEQsAQ">Ethical approval was granted by both the universities and the ministry's ethics committee.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1" xml:id="_g38zKQQ">Immediate and Delayed Interviews</head><p xml:id="_QGhkcuu"><s xml:id="_Wwc72Xd">This study was conducted via two interviews, the first interview aimed to capture students' gestures immediately after the learning session.</s><s xml:id="_tFhUkHM">The second interview was two weeks after the introductory programming activity and first interview.</s><s xml:id="_pzenwNR">The role of the second, delayed, interview was to see how well they remembered the computing concepts and whether there were any changes in their gesturing as they recounted their understanding.</s></p><p xml:id="_dszVJ35"><s xml:id="_fdp9AfH">Gestures can support learning over time, such as in mathematics <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">50]</ref> and in learning a second language <ref type="bibr" target="#b50">[51]</ref> and potentially be related to the role of gestures in encoding and retrieving information to and from memory <ref type="bibr" target="#b51">[52]</ref>.</s></p><p xml:id="_xXWaUFK"><s xml:id="_7rEF36E">Many studies have investigated the use of gestures in terms of their immediate impact, but few studies have looked at their longer-term impact.</s><s xml:id="_9QtTYSS">Previous research on gestures has shown that the effect of engaging in gesturing was greater on the long-term assessment (over three weeks) compared to the short term (Cook, Mitchell, and Goldin-Meadow 2008a; Cook, Yip, and Goldin-Meadow 2010a) or even two days after learning <ref type="bibr" target="#b52">[53]</ref>.</s><s xml:id="_KQ5EtBC">This might be related to the learning effects on memory after sleep.</s><s xml:id="_3Gkqwd5">During sleep, learning-related neural networks are reactivated <ref type="bibr" target="#b53">[54]</ref>.</s></p><p xml:id="_f9x5G68"><s xml:id="_p3ubZ8U">The periods between the first and second assessment in the literature varied from two days to three weeks.</s><s xml:id="_AEwCmEq">Therefore, in the experiment described in this paper, the second interview was conducted two weeks later due to the school schedule.</s><s xml:id="_WqpK7Z2">Also, two weeks would have given children time to think further about the topic and have reduced (if any) the influence of researcher's gestures during the learning session.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hYz4Jyq">Interview Questions</head><p xml:id="_P4j99cK"><s xml:id="_B6XHEnr">The first question (Q1) was an ice breaker for the interview session to help make participants more comfortable.</s><s xml:id="_MwZncPz">Subsequent questions prompted children to explain the meaning of "program" (Q2), the code of a simple program (Q3), the meaning of "iteration" (Q4) and the code of a complex program including iteration (Q5).</s><s xml:id="_Nu3jazv">We selected the concepts program and iteration because they are age-appropriate foundational concepts that primary students need to understand and use <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56]</ref>.</s><s xml:id="_uHuksKU">Iteration <ref type="bibr" target="#b56">[57]</ref> is considered a complex concept for young children that may require them to offload their cognitive work and use an embodied representation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_c4A3a4h">Procedure and materials</head><p xml:id="_2Nq6eZE"><s xml:id="_xbv4Cph">Before the study, participants engaged in a single learning session lasting approximately 25 minutes.</s><s xml:id="_zjsjcYX">They learned fundamental programming concepts, including program and repeat.</s><s xml:id="_BtNuS7B">The researcher conducting the learning session took care not to use any metaphorical gestures whilst explaining concepts or elsewhere in the activity.</s><s xml:id="_ETmhCyb">The children participated in single-gender pairs and used a block-based programming environment to move a robot around a map to solve four programming tasks.</s><s xml:id="_tx7nyXc">Interview 1 aimed to capture the immediate representation of the programming concepts immediately after the programming session.</s><s xml:id="_NjQjbKH">The author interviewed the participants individually in a quiet room.</s><s xml:id="_Kueuta5">In turn, the second interview was held two weeks later, the setting for which was a quiet room.</s><s xml:id="_JmXqFUs">This approach sought to give children time to grasp the knowledge they had learned in the learning session; it also enabled investigation into whether the participants' understanding and use of conceptual metaphors changed over time; and it assessed the effect of time on the use of gestures when explaining programming concepts.</s><s xml:id="_22zZbrk">There was no formal computing classroom during the two weeks.</s><s xml:id="_VkN6BWR">The same questions were asked in both interviews, the only change being to Q1, which changed from "What did you learn today in our session with the robot?" to "What did you learn last time in our session with the robot?"</s></p><p xml:id="_7DAH3E3"><s xml:id="_yTcHUEg">Participants were asked to stand when they were interviewed as Manches et al. <ref type="bibr" target="#b11">[12]</ref> reported that sitting may obscure gesturing.</s><s xml:id="_VkS6kmq">The interviewer then asked the questions in Table <ref type="table" target="#tab_0">1</ref>.</s><s xml:id="_aeqrnWK">The 'relevant stimuli' e.g., code snippets were shown when the questions Q3 or Q5 were asked or the child did not answer Q4 and needed a reminder of the Repeat block.</s><s xml:id="_9wbFQ3q">Then the researcher took codes snippets away.</s></p><p xml:id="_6MpxVqH"><s xml:id="_se7PdPB">Each interview took around 2 to 3 minutes, and the participants were all given the questions in the same order.</s><s xml:id="_NnkDbjj">During the interviews, prompts were given to get the participants to clarify what they meant or to correct their code reading (see Table <ref type="table" target="#tab_1">2</ref>).</s></p><p xml:id="_DptqYwR"><s xml:id="_qY4dH2G">The interviewer thanked the participants every time they answered a question.</s><s xml:id="_PureVEs">The interviewer tried to avoid making representational gestures because this may have led to mirroring.</s><s xml:id="_94G2YhC">After the participants had finished, the interviewer thanked them again for their participation.</s><s xml:id="_AehS5xp">Figure 2 Repeat block Figure 3 (Q5) complex code aimed to describing how a complex program works</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ZnW5zUx">Measures and Data analysis</head><p xml:id="_S9haFdr"><s xml:id="_Rhtptb7">The first author recorded and processed the videos of participants answering the interview questions.</s><s xml:id="_D8UBgny">She then prepared them for analysis, which included reducing the data into themes through coding, data display and conclusion <ref type="bibr" target="#b55">[56]</ref>.</s><s xml:id="_KT9yMK2">Each recording was first reviewed, then translated from Arabic to English if needed, and transcribed.</s><s xml:id="_yrDjFZp">A structured Excel spreadsheet was created with the following categories for each question: researcher talk, gestures, participant's answer, participant's gesture type and gesture description.</s><s xml:id="_GnrH8QZ">We filled in the categories in which we believed the researcher or participant had responded verbally or used gestures while asking and answering the questions.</s><s xml:id="_bAzBTQU">Additionally, we removed irrelevant parts of the interaction that were not related to the questions.</s><s xml:id="_jXQaCTw">The first author coded all the video data.</s><s xml:id="_AfjxFjH">A random sample of 20% of the data was generated for second coding by the second author.</s><s xml:id="_Sh6X5Zm">Inter-rater reliability was determined using Cohen's Kappa scores, with substantial agreement based on Fleiss <ref type="bibr" target="#b57">[58]</ref>.</s><s xml:id="_m9tJp5V">Results were as follows: Kappa score for the gesture type is 0.681.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1" xml:id="_CRv4JMh">Verbal responses</head><p xml:id="_BTkFaNx"><s xml:id="_9RPHs85">'Verbal responses were not within the scope of this study; instead, they were transcribed and used to interpret the meaning of the children's use of gestures.</s><s xml:id="_Fen2nYf">The participants answered the questions using Arabic and English interchangeably, often changing between the languages in a single sentence.</s><s xml:id="_YeVPFBv">Therefore, the language that each participant used was hard to catch and code.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2" xml:id="_HdBVphA">Gesture responses</head><p xml:id="_h52jytn"><s xml:id="_3Aa9nXq">The first author coded all gestures, drawing upon the children's speech to guide their interpretation and recorded them in the transcript and the Excel spreadsheet.</s><s xml:id="_fs6tpjp">The gesture responses were then categorised based on Alibali and Nathan's scheme <ref type="bibr" target="#b7">[8]</ref> and divided into two types of gesture, as follows:</s></p><p xml:id="_fuTK3bW"><s xml:id="_sQJA8eg">• Deictic gesturing (e.g., pointing) reflected the grounding of cognitive gestures in the physical environment (e.g., pointing to the function block).</s><s xml:id="_yVj52qd">• Representational gesturing (RG): including gesturing that represented concrete or abstract concepts by hand (hand shape, or motion trajectory) or body (e.g., rotating the whole body to indicate a turn).</s><s xml:id="_X62YqUA">It could be either a: o Literal gesture (i.e., iconic gesture): depicted aspects of meaning.</s><s xml:id="_MAGz6jc">It is important to note that in our analysis when a participant pointed their index finger to the right while explaining the Right block concept, we considered this to be an iconic gesture not referring to an object in the environment.</s></p><p xml:id="_6EFC5dN"><s xml:id="_FyY329q">o Metaphorical gesture: e.g., identifying how children represented the abstract notion of iteration.</s></p><p xml:id="_JNyrfrB"><s xml:id="_GMcPqBv">For the Metaphorical gestures identified, the authors worked together to identify conceptual mapping patterns across participants.</s><s xml:id="_axdXSSM">Conceptual mapping is the process of mapping between the gesture and conceptual entities in children's speech.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" xml:id="_pPEZqS8">Results</head><p xml:id="_RCjWaU8"><s xml:id="_XUgsdBQ">The number of questions asked, the responses and prompts for each question as well as the prompt types are shown in Table <ref type="table" target="#tab_1">2</ref> (e.g., in Interview 1, Question 1 was asked 45 times to the 45 participants, received 38 responses without prompt and 10 gestures without prompt, no prompts were given, 0 the non-answer,38 total number of answer after promote, 10 is the total number of gestures after prompt).</s></p><p xml:id="_jcJmKCP"><s xml:id="_BpW5vvs">Q1, an icebreaker, was added to the script after the first group was interviewed because the researcher noticed that participants seemed shy about the interview setting.</s><s xml:id="_GyERKA8">During the data collection and due to technical issues with the camera, we lost 9 recordings (three in Interview 1 and five in Interview 2) and one participant withdrew from Interview 2. Additionally, due to interviewer error, not all participants were asked Q2.</s></p><p xml:id="_QcTvsSk"><s xml:id="_zEgU35W">Identifying the prompt type was vital to make sure that participants' gestures were not influenced by any researcher prompts.</s><s xml:id="_QYNf7ur">More prompts were given in the first interview than the second because participants were not familiar with the interview setting and the questions.</s><s xml:id="_uJYgXXb">The number of prompts was higher in questions in which participants were asked to explain written code (Q3, Q5).</s><s xml:id="_2mSPCxY">Participants sometimes just read the code, so the researcher prompted them to explain the code instead of just reading it.</s><s xml:id="_dukqfwV">What kinds of gesture were produced?</s></p><p xml:id="_FgEDsHv"><s xml:id="_7a5Y5Sr">In total, we coded 1066 gestures into three types: pointing, representation gesture (RG) either as a literal or as a metaphor: see Table <ref type="table">3</ref> below for examples for each type.</s><s xml:id="_t3CCutv">Table 3 examples of gesture type</s></p><p xml:id="_YuQF5Nz"><s xml:id="_qdchYVd">The 1068 gestures were coded across 566 explanations (see Table <ref type="table" target="#tab_1">2</ref>).</s><s xml:id="_GUeEWfR">Three participants generated no gestures.</s><s xml:id="_YqgnNvR">Figure <ref type="figure">7</ref> illustrate the numbers and types of gestures recorded for each question.</s><s xml:id="_2VaNKfd">The total number of participants' gestures in Interview 1 ranged from 0 to 26, with a median of 11, while that for Interview 2 ranged from 0 to 21 (median 13).</s><s xml:id="_T95CmDM">Additionally, an independent-samples t-test was run to determine differences in the number of overall gestures between the two interviews.</s><s xml:id="_pFJy69A">Participants in Interview 2 made more gestures (N=45, M= 12.98, SD = 5.4) than in Interview 1 (N=47, M=10.30,</s><s xml:id="_4rfc8YY">SD=5.7), the different was a statistically significant difference (95% CI, -5.007 to -.353), t (90) =. -2.288, p =.024).</s></p><p xml:id="_fm37wax"><s xml:id="_tyc78bu">Figure <ref type="figure">7</ref> Interviews, number and type of gestures generated for each question</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1" xml:id="_FQN6svp">Deictic gestures</head><p xml:id="_C6saFpC"><s xml:id="_GtXhefU">A deictic gesture (e.g., pointing) is used to indicate an object's location <ref type="bibr" target="#b29">[30]</ref>.</s><s xml:id="_HaVcaxf">Participants pointed frequently when physical material was provided, such as in Q3 and Q5, by indicating a code block while explaining its functionality.</s><s xml:id="_zuKscuD">These gestures guided both the participants and researcher to the related block.</s><s xml:id="_WTXH7hn">Tracing the code might have helped students while they tried to understand the control flow of the code.</s><s xml:id="_6K6DkEB">Deictic gestures might have reflected cognition and revealed students' understanding of the code execution, similar to Solomon et al. 2018 findings <ref type="bibr" target="#b41">[42]</ref> .</s><s xml:id="_hrRcknV">For example, when participants pointed to the left block in a simple program and said "right" whilst gesturing to the left, this let the researcher know that the participant had issues reading and or understanding the code or just muddled right and left.</s></p><p xml:id="_VrThC6E"><s xml:id="_zmGBFJm">0 50 100 150 200 250 Number of gesture for each question Gesture types Interview 1 Q1 Q2 Q3 Q4 Q5 0 50 100 150 200 250 Number of gesture for each question Gesture types Interview 2 Q1 Q2 Q3 Q4 Q5</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2" xml:id="_b77DTm2">Literal gestures</head><p xml:id="_Jp4dSvh"><s xml:id="_NnYMqfM">A literal representational gesture (RG-literal) represents a concrete idea and conveys information about the size, shape or orientation of a discourse object <ref type="bibr" target="#b58">[59]</ref>.</s><s xml:id="_KrK5JXV">Such gestures are used to facilitate communication and simulate an action.</s><s xml:id="_tjCFY43">Participants used literal gestures mostly to simulate the robot's action -forward, right and left.</s><s xml:id="_PNPrS5D">Others used literal gestures to represent a number that was important in the code.</s><s xml:id="_rPmXsj4">For example, one participant said "the robot would repeat the code twice" with a hand gesture for the number 2.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3" xml:id="_AQ9aHKY">Metaphorical gestures</head><p xml:id="_ZsHKMyu"><s xml:id="_Kzq279z">Metaphorical representational gestures (RG-metaphorical) are used to help communicate abstract concepts <ref type="bibr" target="#b59">[60]</ref>.</s><s xml:id="_2GPuvst">An abstract noun, as defined by Lexico, quoting from the Oxford Dictionary (2020), is "a noun which refers to ideas, qualities, and conditions -things that cannot be seen or touched and things which have no physical reality" <ref type="bibr" target="#b60">[61]</ref>.</s><s xml:id="_SJBkK4W">We considered the concepts of program and iteration as abstract concepts and therefore gestures used to communicate them as RG-metaphorical.</s></p><p xml:id="_n4xUzfH"><s xml:id="_EKXhqdn">The noise block was a unique case as it had two aspects that might be communicated: the lack of robot movement compared to other blocks and the generation of a noise, see Section 5.2.1.</s><s xml:id="_FRdD7vX">The lack of movement aspect of a noise block was readily communicated via range of literal gestures, in that gesturing lack of movement is as straightforward as gesturing movement.</s><s xml:id="_S4ZyPPz">Communicating the noise of the noise block through making a sound was not regarded as a gesture at all.</s><s xml:id="_jHV3pq2">However, it was not obvious how best to categorise the gestures that were used to communicate the sound aspect of the noise block and we chose to treat these gestures as RG-metaphorical in the sense that such gestures were in a different modality from sound and in that sense were metaphorical.</s></p><p xml:id="_jwUVxsG"><s xml:id="_tZMSpfa">Participants produced a total of 53 RG-metaphorical gestures (Interview 1 = 24; Interview 2 = 29).</s></p><p xml:id="_Bhrgezw"><s xml:id="_jCAuzKa">How are metaphorical gestures used to represent computing concepts?</s></p><p xml:id="_7qJ4Pms"><s xml:id="_4fCSYaZ">This section explores the metaphorical gestures and what they reveal about how children conceptualise computing concepts.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1" xml:id="_63QN7CZ">Noise block</head><p xml:id="_wFwh7Jp"><s xml:id="_XKRqqQf">The noise block, which makes a buzzing sound and does not involve any movement of the robot, was part of the simple program that participants explained.</s><s xml:id="_evpGw5X">A noise block is a commonly occurring programming element in robot programming block environments, in addition to movement-related blocks.</s><s xml:id="_bDFhbBa">The noise block is one of the few blocks that are not tied to the spatial elements of the programming task.</s><s xml:id="_YF2sNuX">When this block is reached during program execution the robot emits a buzz without moving from where it is at that moment.</s><s xml:id="_nCkc7EX">Therefore, the noise block cannot so easily be represented via movement gestures; so it is also potentially more likely to be communicated via metaphorical representations.</s></p><p xml:id="_eaS2zWK"><s xml:id="_8P9ThDF">In describing the effect of the noise block some participants focused on the lack of movement of the robot, others on the noise the robot made and others again on both aspects.</s><s xml:id="_eYcN8bU">For example, some participants demonstrated the noise with a gesture, and a few said "pop".</s><s xml:id="_zZbwv3n">Over both interviews 15 RG-metaphorical gestures and 30 pointing gestures were generated for the noise block, and there were 45 responses where no gesture was produced when the noise block was reached in Question 3.</s></p><p xml:id="_Hx9gB93"><s xml:id="_5tS3ZFn">Participants represented the noise metaphorically in many different ways, either by keeping the same position, representing the freezing by an action, or by demonstrating a movement.</s><s xml:id="_nEEmjWv">First, a few participants represented the noise as a moment of freezing, where the robot stopped moving and kept its previous position, which is exactly what the robot did, e.g., P40.</s><s xml:id="_f5n7ntH">Others represented the freezing by an action.</s><s xml:id="_7M8pdhe">For example, P26 and P27 clenched their hands, whereas P50 clasped her hands.</s><s xml:id="_Nm4cwQJ">P28 posed his hands as if they were holding something, whereas P18 held a handout flat and said "pop," and P10 hit the table with her fist as a gesture to represent the noise.</s><s xml:id="_6gp2GVJ">Other participants represented the noise block with different movements, even though the robot in the learning session did not move when it produced the noise.</s><s xml:id="_3yTsykw">For example, P23, P40, and P42 used their whole body to dance when they reached the noise block, whereas others just moved their hands.</s><s xml:id="_zBKy6uQ">P31 moved his hand left and right, whereas P35 moved his hands toward the front.</s><s xml:id="_PZqH2Sz">P09 moved both of her hands in a circular motion as if they were a hurricane.</s><s xml:id="_uTHfW5h">P45 moved his hands in an arc motion.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2" xml:id="_Dv63EU9">Program</head><p xml:id="_vqgCZzX"><s xml:id="_UjN6ASD">Only two participants used gestures when asked about the meaning of a program, and they both answered that the program means repeat.</s><s xml:id="_bRnhaZT">For example, participant (P37) said that the program was a "repeat" while gesturing the form of a container.</s><s xml:id="_UhYhsCX">Therefore, their gestures were coded as a metaphorical representation of the repeat.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3" xml:id="_A4xeq6V">Repeat</head><p xml:id="_rhtfGRz"><s xml:id="_dCwzVKg">In Interview 1, 18 gestures represented the repeat either as a circle (8), an arc (6), a forward line (2), or a flowing arrow mark on the repeat block (2).</s><s xml:id="_7x2NsyT">In Interview 2, 20 gestures represented the repeat either as a circle (8), a container (4), an arc (4), through repetitive movements such as a wave (1), or by drawing the arrow found on the repeat block (1) and performing the action (2).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4" xml:id="_HmT8Af8">Computing constructs as physical objects</head><p xml:id="_y4FWHUm"><s xml:id="_TVWNJUk">When explaining computing concepts, two participants simulated a pinching action described by Edwards in a 2009 study focusing on mathematical concepts <ref type="bibr" target="#b61">[62]</ref>.</s><s xml:id="_8UfAH2B">Similar to numbers that are represented physically, participants' experience with programming blocks might have influenced them to draw upon experiences of manipulating tangible representations of computing concepts.</s><s xml:id="_uXH2bRv">Pinch was used when describing programming blocks inside the repeat, e.g., Figure <ref type="figure">8</ref>.</s><s xml:id="_yskygNU">Additionally, participants represented repeat as a container, see Figure <ref type="figure">9</ref>, by creating the boundary of an object and using another hand to gesture into the hand.</s><s xml:id="_xksQ2JT">This was often associated with indicating that the code inside the repeat will be executed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5" xml:id="_5m6bXwz">Computing processes as a motion along a path</head><p xml:id="_HzfMBXE"><s xml:id="_BEWk4Pk">There are three main axes related to the body: longitudinal, frontal, and transverse:</s></p><p xml:id="_tMb3mW4"><s xml:id="_667GEaW">Longitudinal axis: the path up to down in front of the body, paralleling how the participants wrote the code from top to bottom.</s><s xml:id="_Cq8xqS3">For example, a gesture referring to time-based computing processes might go downward in a longitudinal direction.</s><s xml:id="_hf5jZ26">One participant (P41) produced this gesture and said "Repeat" while his arm moved downward.</s><s xml:id="_kv4Rqcp">He discussed algorithmic steps/instructions, while making a step going downward with his hand see Figure <ref type="figure">10</ref>.</s></p><p xml:id="_hB66fX7"><s xml:id="_qDqrEgV">Frontal axis: this is the pathway moving away from the body where a circular gesture was projected outward from the body.</s><s xml:id="_sx54rVf">Two participants (Interview 1: P44, Interview 2, P05) represented the repetition with two straight lines going forth and back (such as P44, see Figure <ref type="figure">10</ref>).</s><s xml:id="_p3NYQK8">This supports the idea that participants were drawing a general body-based spatial metaphor of time, that the future was in front of them, conceptualising the robot movement.</s></p><p xml:id="_KxNEkkk"><s xml:id="_dDXWmeV">Transversal axis: this is the pathway moving from left to right across the body, or vice versa.</s><s xml:id="_zh9vbwE">English is written from left to right, whereas Arabic, the participants' native language, is written from right to left.</s><s xml:id="_W7h3Umt">This suggests that gestures communicating computational processes might trace a similar transversal axis.</s><s xml:id="_TFhTPJb">Twelve participants drew the arc/circular shape from right to left, anticlockwise (6 participants in Interview 1, and 6 participants in Interview 2) see Table <ref type="table">5</ref>.</s></p><p xml:id="_un5z8WX"><s xml:id="_aEyFAqG">Gesture movement pathways were noticed when participants talked about repeating a program or what they had just said.</s><s xml:id="_W5JDzud">For example, P20 read the first line of the code for Q3, "left", then said, "It will do it again", with her right hand (RH) moving in an arching gesture.</s><s xml:id="_a9HbdQ6">Another gesture represented the repetition as a wave or climbing a hill from left to right (Figure <ref type="figure" target="#fig_8">18</ref>).</s><s xml:id="_jBPjua5">Moreover, some participants represented one circle of the repeat clockwise and the second circler anticlockwise, see Figure <ref type="figure">20</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.6" xml:id="_9VzVzvf">Gesture size and frequency</head><p xml:id="_QGT4BS5"><s xml:id="_J7x5BVV">The shape of the hand and whether one or two hands were used suggested differences in the perspective of the size of an imaginary object.</s><s xml:id="_hQKrkgf">Participants had a different perspective of the "size" because, for computing constructs, physical size has no meaning.</s><s xml:id="_M4scw5D">For example, P09 represented the repeat using one big circle in both interviews, whereas P19 represented the repeat with a small circle.</s><s xml:id="_RHuFBQn">P36 represented the repeat with two circles, where the first was bigger than the second, see Figure <ref type="figure">20</ref>.</s><s xml:id="_TjJtuYZ">Additionally, the circular movement frequency was not consistent across participants, ranging from one to three cycles.</s><s xml:id="_atDT9Md">This is interesting because the repeat executes the command and then repeats it once.</s><s xml:id="_SER5qkd">Therefore, the frequency of participants' movements might indicate their understanding of the repeat block.</s><s xml:id="_C6URc2m">Table <ref type="table">5</ref> shows the different representations and frequency of the circular motion.</s><s xml:id="_HxvDSan">Figure 9, P17: "Put repeat [hand gesture as container], then the left, forward, right [2 RG-literal], and the sound".</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jUMjqM5">Pinch Container</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mTuJDc4">Longitudinal movement Frontal</head><p xml:id="_eCUg73s"><s xml:id="_SNGHPaQ">Table 4 Pinch, Container, Longitudinal, frontal and other representations Figure 12, P09 gesture: "It repeats.</s><s xml:id="_MTpq2ec">If you did it wrong, it would repeat it again", with her palm open.</s><s xml:id="_RvyDy29">Figure 13 P37: "Do it again".</s><s xml:id="_WgCbA8e">He drew two circles on the table with his hand closed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_8pkHhYe">One big circle, Clockwise Drawing two circles Clockwise on the table</head><p xml:id="_bPCGJZE"><s xml:id="_nATWYsy">Figure <ref type="figure" target="#fig_1">14</ref>, P19: "If we do a thing, we will do it again", making a small circular motion with her hands clasped.</s><s xml:id="_SCfAEEx">X2 2X Figure 10 P41 moves his hand downward and saying "Repeat"</s></p><p xml:id="_2j8nrWV"><s xml:id="_3yMXpGk">Grasping with a small circle Clockwise Arc -Clockwise  Moving both hands at the same time in an anticlockwise motion, three times Two big circles, anticlockwise Waves, anticlockwise Right-to-left movement, anticlockwise Figure <ref type="figure">20</ref>, P36 "Do it again".</s><s xml:id="_78tusPE">He drew a big circle on the table with his hands gripped clockwise, followed by a smaller circle and hand-moving when talking about repeat anticlockwise.</s><s xml:id="_C5phRT2">Tow circles, Clockwise and anticlockwise</s></p><p xml:id="_EcTD75T"><s xml:id="_sDa4pNr">Table 5 Transversal axis examples</s></p><p xml:id="_DTSqfng"><s xml:id="_SRcu2fS">In two instances, when participants answered the question, "What is a program?", their use of a gesture revealed implicit knowledge which they did not express in words.</s><s xml:id="_SkGhAbG">For example, P45 said: "yes program the stuff, like the robot".</s><s xml:id="_KyFVrHe">It was not clear what participants meant when they said "stuff"; it was ambiguous.</s><s xml:id="_xvHmdQU">However, their gesture, hands moved in top of each other, represented the order of the programming blocks used in the learning activity (see Figure <ref type="figure" target="#fig_9">21</ref>).</s><s xml:id="_eZdM9nM">In another example, P07 answered the question, "What is a program?" by saying "do something now" while holding both hands together.</s><s xml:id="_gJJeDXZ">The participant then continued, "Then you do the same thing there" while turning A B their body to the side and turning their hands.</s><s xml:id="_7rGUYKK">The researcher did not know what the student meant by "something" and "the same thing".</s><s xml:id="_uP63ScP">from the participant's gestures the researcher understood "something" as meaning the robot's movements.</s><s xml:id="_kQNQA8S">The participant was simulating its movement by moving their body.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.7" xml:id="_j7TPUB7">Representational Gesture Changes Over Time</head><p xml:id="_Wwp8f79"><s xml:id="_JTgKT7Z">This section describes metaphorical gesture changes across the two interviews to answer RQ3.3: 'Are there any differences evident in the use of gestures and conceptual metaphors when children are interviewed again, two weeks after the introductory programming activity, compared with that in a first interview immediately after the activity?'.</s></p><p xml:id="_yMKcxkS"><s xml:id="_AUFrH2R">The process compared the use of conceptual metaphors in each interview.</s></p><p xml:id="_5kZjqHx"><s xml:id="_j2nakK2">• Agreement-level 1: The concept was represented twice in one interview and followed the same category (e.g., P10).</s></p><p xml:id="_v5ufErN"><s xml:id="_QbpuU9y">• Agreement-level 2: The concept was represented in the same category in Interviews 1 and 2 (e.g., P09).</s></p><p xml:id="_44Dw2Kz"><s xml:id="_khnn3hs">• Disagreement-level 1: The concept was represented twice in one interview and each time was in different category than the other (e.g., P19).</s></p><p xml:id="_Ru3BxPS"><s xml:id="_hbKUFr7">• Disagreement-level 2 The concept was represented differently in each interview (e.g., P18).</s></p><p xml:id="_Xu7N6Kt"><s xml:id="_PGgQD3v">• Solo: The concept was represented once in Interview 1 or 2 (e.g., P01).</s></p><p xml:id="_7MZwDJH"><s xml:id="_29MMGXk">For the noise block, one participant generated an RG-metaphorical gesture in both interviews with consistent representations.</s><s xml:id="_wDEvrcz">Interview 1 featured five representations while Interview 2 featured eight .</s><s xml:id="_tuY7Axz">For the repeat concept, three participants (P09, P10, P20) maintained Agreement-level 2 for the repeat representation, while 10 participants represented the repeat differently in each interview (Disagreement-Level 2).</s><s xml:id="_32Wytwf">The other six represented the repeat solo in Interview 1 or Interview 2. Additionally, a more detailed breakdown is shown for repeating concepts twice in the same interview (five disagreements and one agreement).</s><s xml:id="_JRvsNGT">An independent-samples t-test was run to determine differences in the number of overall gestures between the two interviews.</s><s xml:id="_KRqBSTW">Participants in Interview 2 made more gestures (N=45, M= 12.98, SD = 5.4) than in Interview 1 (N=47, M=10.30,</s><s xml:id="_KBHRX7W">SD=5.7) and the difference was statistically significant (95% CI, -5.007 to -.353), t (90) = -2.288,</s><s xml:id="_6Xv8Ktq">p =.024).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6" xml:id="_MfYCcSB">Discussion</head><p xml:id="_kWYkNHH"><s xml:id="_W2RZVuA">Our overall goal in this study was to collect and analyse gesture responses that children used to describe computing topics after experiencing a programming activity, including the concepts of a program and of iteration.</s><s xml:id="_nhM8rPH">We explored how children used spontaneous gestures to convey computing concepts and how they conceptualised these concepts.</s><s xml:id="_b7WNB8R">Additionally, we developed an analytic framework suitable for understanding gestures generated within this domain.</s><s xml:id="_kHKwvt2">This study's findings indicate even for abstract concepts in computing education, the embodied nature of participants' understanding of computing concepts was made evident through their gestures..</s><s xml:id="_qr6jjC8">The participants also produced a high number of literally representational gestures that mostly referred to concrete objects or processes.</s><s xml:id="_WTVCp2u">These often related to tangible materials utilised in the programming blocks or the robot's movement.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_T3MER8n">What kinds of gesture did children produce?</head><p xml:id="_PEBvXSB"><s xml:id="_7KJKG36">The study identified 281 pointing, 734 RG-literal, and 53 RG-metaphorical gestures.</s><s xml:id="_zQjchvm">Our findings support one of the central claims of embodied cognition, namely, that offline thinking involves mental simulations of perception and action.</s><s xml:id="_S8MXwZU">The representational gestures were produced in the absence of 'relevant stimuli', e.g., a physical object such as a screen or board to point to.</s></p><p xml:id="_BaP5MQG"><s xml:id="_jmbkd53">Importantly, the representational nature of these gestures provided additional information to their speech to help us to analyse their thinking in this domain.</s><s xml:id="_vrx9b2J">Our findings suggest that embodied cognition has many insights to offer to computing education in which they would benefit from a greater understanding of conceptual development <ref type="bibr" target="#b62">[63]</ref>.</s></p><p xml:id="_UWaZHxB"><s xml:id="_kTjHW2c">This study shows that the children aged 6-7 years old produced less gestural evidence of metaphorical understanding compared to that of conceptual understanding.</s><s xml:id="_V9QMt5R">Only 5% of the generated gestures were metaphorical, suggesting that spontaneous metaphorical thinking did not play a strong role in these children's reasoning about CS concepts.</s><s xml:id="_ueam4s5">This is not surprising as the use of such metaphors is sophisticated and shows up more frequently with older children.</s></p><p xml:id="_w2MnsnP"><s xml:id="_7P3B2Nv">Another possible explanation might be that the participants who represented the repeat concept metaphorically understood it, as the use of a conceptual metaphor is the first sign of the understanding of the concept.</s><s xml:id="_VPMqQyg">In 2009, Bakker et al. showed that abstract concepts, after first being understood, can be represented in body movements before they can be explained in words <ref type="bibr" target="#b28">[29]</ref> .</s><s xml:id="_9ADs5R7">Therefore, the limited use of metaphorical gestures may reflect a limited understanding of programming concepts (e.g., iteration and program).</s><s xml:id="_f9HUTUA">If children experience difficulties in explaining the concept in words and gestures, it is an indication that the concept is difficult for the age group.</s><s xml:id="_KyPYTd7">Further work should look at the use of metaphors in CS with older children.</s></p><p xml:id="_DWmpBh7"><s xml:id="_XSQzX7h">How were metaphorical gestures used to represent computing concepts?</s></p><p xml:id="_jfDSSym"><s xml:id="_AjBUg2a">Despite the participants' young age and their having no previous experience with a programming language (except for the 25 -minute learning session before the study), they generated 52 RG-metaphorical gestures.</s><s xml:id="_wyuCRCH">Several patterns of gesture were identified.</s><s xml:id="_bXpRC5T">Patterns included using a circular motion to communicate the repeat block with different frequencies and sizes, and different hand grasps to represent the robot's non-movement when making a noise.</s></p><p xml:id="_8hQpzWA"><s xml:id="_PGvz5rY">Most of the RG-metaphorical gestures that were identified described either a repeat or a noise.</s><s xml:id="_JjDsFbv">The way participants gestured suggested their degree of understanding.</s><s xml:id="_Y7YE6p2">It was not possible to test the accuracy of these postulated degrees of understanding independently, but with this caveat, we offer some plausible interpretations.</s><s xml:id="_7UyrDNV">For example, participants representing the noise block with a movement might have indicated a low understanding of the noise block's functionality because the robot did not move when making a noise in the learning session.</s><s xml:id="_2ae366x">Conversely, the no-movement representation was either a literal representation of the freeze or metaphorical; either way, any representation might indicate that participants understood that the noise block meant that the robot would be in the same position.</s><s xml:id="_fR3JuEG">A literal representation of the freeze means simulating the robot's movement when it runs the Noise block by keeping the previous gestures that participants made for the previous Action block and saying "noise" or "sound".</s></p><p xml:id="_UuwXjPg"><s xml:id="_wvgKsr4">In contrast, a metaphorical representation of the noise block as freeze involved the child using a gesture such as clenching, clasping or hitting the table to indicate his or her understanding that the noise block caused the robot to remain stationery.</s><s xml:id="_r79kJ7f">This could indicate how students had understood the idea and could be used by teachers to glean information about their students' learning stage.</s></p><p xml:id="_AVWqHcz"><s xml:id="_bvYjeMt">Also, the frequency of circular gestures -ranging from 1 to 3 may indicate the repeated execution of a program (once, twice, or thrice) based on the number of times the child performed the circular motion.</s><s xml:id="_G6PwB9v">This could be reflective of the children's understanding of the repeat concept.</s><s xml:id="_deUjsUG">Noteworthily, teachers can use the information that students convey with their hand movements to guide and assist their learning.</s><s xml:id="_Ahw7NH8">For example, Kelly et al. in 2002 found that teachers can assess understanding by considering students' gestures <ref type="bibr" target="#b36">[37]</ref>.</s><s xml:id="_KeJgQDw">This was attributed to the fact that the information students convey using gestures is at the cutting edge of their knowledge (e.g., the noise block was not a moving action block, and they were aware of its functionality).</s></p><p xml:id="_R497YGY"><s xml:id="_pDcuPdY">The approach used to categorise RG-metaphorical in this paper was similar to that of Manches et al. <ref type="bibr" target="#b11">[12]</ref>.</s><s xml:id="_GKAmEmn">In their approach, the authors categorised the gestures of undergraduate computer science students into the following image schemes: the computer as an object or container and the path-course goal schemes that serve as the foundation for mathematical concepts <ref type="bibr" target="#b17">[18]</ref>.</s><s xml:id="_u4HGMmD">It is worth noting that the metaphor outlined here does not seem to differ greatly between adults and children, but varying forms of metaphors arise.</s><s xml:id="_R8GCmtK">As a case in point, in contrast to the non-Arabic speakers in Manches et al.'s study <ref type="bibr" target="#b11">[12]</ref>, who all represented iteration using a clockwise gesture, half of the participants in this study represented the repeat in an anticlockwise circle.</s><s xml:id="_pjPTtdc">This may be due to the difference in meaning implied by the left-right/right-left text direction in English/Arabic.</s><s xml:id="_fKvaz9Q">It is notable that half of our participants used a clockwise gesture despite the blocks-based language used in the learning activity representing the control flow of the repeat block in a clockwise direction.</s><s xml:id="_TMp8BCn">Insofar as the features of languages impact human conceptualisations of their surroundings, language may influence thought in a clear semantic way <ref type="bibr" target="#b63">[64]</ref>.</s><s xml:id="_2DE7sCc">Our findings indicate that when explaining programming concepts, the gestures used by these learners are notably different in terms of the aspect of their direction compared to the gestures used by learners whose first language is a left-to-right language (e.g., English).</s></p><p xml:id="_p2WuCFe"><s xml:id="_3KEeTJF">The features of languages impact human conceptualisations of their surroundings and language may influence thought in a clear semantic way.</s><s xml:id="_2AeE9pp">Therefore, to increase the accessibility of CS education for a non-left-to-right language speaker, new or adapted versions of programming environments might potentially be needed to support learners' pre-existing culturally based understanding.</s></p><p xml:id="_Yp4tnEa"><s xml:id="_G68mY2h">To increase the accessibility of programming and computing education among learners who do not speak English <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b64">65]</ref> , it might be necessary for new or adapted versions of programming environments to be designed to support learners' existing culturally based understandings.</s></p><p xml:id="_esRCP7z"><s xml:id="_feKGXtm">The programming blocks used in the pre-programming session were placed from top to bottom, but there were some elements of the design that implied a left-to-right reading order.</s><s xml:id="_MpqQhxm">The blocks had labels written in English, were slightly aligned with the code's left to right orientation, and the arrow on the repeat blocks moved in a clockwise direction.</s><s xml:id="_F9gbSDf">This might have created a potential conceptual challenge for children if right-to-left reading was their main model.</s><s xml:id="_UkZYhT8">Although the children who participated in this research were studying at an international school that taught English as the main language, and the programming language implied a left-to-right direction, the overall cultural context in which the ideas were presented appeared to be strongly present.</s></p><p xml:id="_HvR7vpZ"><s xml:id="_xEvxww7">Additionally, we noticed that several of the repeat gestures related to a special mapping of the code.</s><s xml:id="_Kx6jmaB">A significant number of the participants explained the repeat by giving an example similar to that used in the learning session; some of the participants drew the arrow shown on the repeat block.</s><s xml:id="_As8nEx4">Others represented it as a container similar to the repeat programming block with the other action blocks inside it.</s><s xml:id="_m7S8G84">This was not surprising, as block-based programming language involves blocks with a visual representation written on them, affecting how the children simulated the repeat block.</s></p><p xml:id="_qfafnHs"><s xml:id="_wYjayJ4">There is likely to be an interaction between computing environments and computing metaphors, in which metaphors are used to design environments and then shape the metaphorical thinking of the users <ref type="bibr" target="#b65">[66]</ref>.</s><s xml:id="_VaUFthz">Our findings suggest that the design of educational materials in computing education could help learners by exploring conceptual metaphors and could be applied to inform further design guidelines, for example, the representation of iteration.</s><s xml:id="_zXPdZba">This lens might help identify possible conceptual challenges, such as visually representing iteration and noise dynamics.</s><s xml:id="_cfQksZJ">These challenges might impact the user's use of gestures when designing learning interfaces that involve gesture use to support learning.</s><s xml:id="_v4NdRRf">It is important to also note the culturally defined nature of some metaphors and consider the implications of children being asked to use computing environments whose metaphors clash with their existing conceptual metaphors.</s></p><p xml:id="_ukMvvYZ"><s xml:id="_PPwWnYB">Gestures in which the hand moves along a linear axis typically refer to computing processes rather than direct constructs.</s><s xml:id="_AUN58Yf">This reveals that gestures mark both the start and endpoints of a process and a sequence of steps along a path.</s><s xml:id="_6HmSDFK">The delineated path axis is also interesting.</s><s xml:id="_AJ58gM4">The longitudinal axis corresponds with vertical lines of code.</s><s xml:id="_5gJG4GX">The traversal axis corresponds with the cultural left/right direction of time, and the frontal axis appears to correspond with a culture of time in relation to the body.</s><s xml:id="_MMQ75GW">Although gestures along these axes seemed to simulate processes, it is interesting to note the points along the trajectory because they often corresponded with algorithmic steps.</s><s xml:id="_ZsFPupF">More work is needed to investigate the special metaphors that represent computing concepts, and more investigation is needed to understand the potential benefits of explicitly encouraging gesturing, such as the gestures in this paper, for making implicit knowledge explicit.</s><s xml:id="_7gwsHRy">In some countries, such as the UK, young children are expected to learn computing concepts from the age of 5 <ref type="bibr" target="#b64">[65]</ref>, so it would be worth investigating whether encouraging children to use particular gestures might support their understanding of computing.</s><s xml:id="_2WEjCR9">Additionally, in other domains, there is evidence showing the benefits of teachers using specific gestures in the classroom <ref type="bibr" target="#b37">[38]</ref> to improve students' learning <ref type="bibr" target="#b43">[44]</ref>.There is emerging work in computing education, such as Solomon et al. in 2020 <ref type="bibr" target="#b43">[44]</ref> who investigated the use of gestures by computer instructors.</s><s xml:id="_3CskDPT">Further investigation is needed to evaluate the anecdotal evidence.</s></p><p xml:id="_UjpnPYx"><s xml:id="_jBT466P">Although this study was not designed to investigate the potential benefits of gestures, we noticed that gestures revealed information that students did not express in words.</s><s xml:id="_Y3HzQDP">Gesture use was beneficial for our understanding of the participants' implicit knowledge.</s><s xml:id="_5PY58ZA">It can be used as a tool to facilitate understanding that is not expressed by words.</s><s xml:id="_ErNbWXJ">For example, in our study, we spotted two instances where gestures revealed student knowledge and changed our classification of their understanding.</s><s xml:id="_sGGanFY">This in line with Novack and Goldin-Meadow, who discovered that gesture reveals what learners know <ref type="bibr" target="#b19">[20]</ref>.</s></p><p xml:id="_YZj84eA"><s xml:id="_QByPTp9">Are there any differences in the use of gestures and conceptual metaphors when children are interviewed again, two weeks after the introductory programming activity and first interview?'</s></p><p xml:id="_tq6qCmp"><s xml:id="_txs3VTn">The study identified one level 2 agreement with the metaphorical representation of noise and 13 solo representations (five from Interview 1 and eight from Interview 2).</s><s xml:id="_DRVKFqu">There were three agreements, eight disagreements and six solo representations of the repeat concept across the pairs of interviews.</s><s xml:id="_RMH853b">Additionally, a single interview revealed five disagreements and one agreement with the repeat representation.</s><s xml:id="_m4QpzFT">Drawing a conclusion is tricky because of the small number of representation gestures that participants generated across the interviews.</s><s xml:id="_QnM7j2U">For instance, the participants might not have developed a full conceptual representation for the concept of repetition.</s><s xml:id="_ZyrZPNQ">Thus, further work with more participants and thus a greater number of RG-metaphorical gestures could help us better assess any changes in the conceptual metaphors over time.</s></p><p xml:id="_HmuXC8r"><s xml:id="_WAheVCW">The results showed that participants generated more gestures in Interview 2. This may suggest that the participants needed time to more fully comprehend the concepts that they learned in Study 2. This finding could also support the notion of the use of gestures as a tool to offload some cognitive load, as <ref type="bibr">Wilson (2002)</ref> described in the use of the embodied cognition theory <ref type="bibr" target="#b66">[67]</ref>.</s><s xml:id="_uwbxVCD">Participants in Interview 1 were asked to explain the concepts immediately after they learned them: this process did not require much cognitive work as the concepts were new and, in the participants', short-term memory.</s><s xml:id="_kb5bCkp">In Interview 2, the students needed to retain and recall the concepts from their long-term memories, which may have required more cognitive work.</s><s xml:id="_NxzNvKu">Another explanation might be the consolidation of the meaning of embodied representations in Interview 2. These gestural representations may have been easier to recall compared to symbolic linguistic representations after two weeks.</s><s xml:id="_vkaKxpK">Further work is needed to investigate possible explanation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7" xml:id="_tK2mM5a">Implications</head><p xml:id="_tGxCuuu"><s xml:id="_NJ7gFMg">The findings of this study have a number of implications, these are discussed below, along with suggested directions for future research:</s></p><p xml:id="_cBhVZNq"><s xml:id="_UajgS2j">The Role of Gestures in learning -Encourage actions (gesturing and body): Using metaphorical gestures in computing classes by encouraging learners to use gestures might help reveal misconceptions in learners' knowledge that otherwise might not be picked up on.</s><s xml:id="_9Kpy98p">One of the most significant challenges CS teachers face with novices is helping them to build strategies and mental models to understand abstract concepts <ref type="bibr" target="#b67">[68]</ref>, of which CS is full.</s><s xml:id="_mYBbger">Although this research was limited to investigating the role of gestures, whole-body movement can be used to represent ideas in a similar way as gestures.</s><s xml:id="_bUdBa6a">This research presented several examples of children using their whole body to represent iteration or to represent noise through dancing.</s><s xml:id="_BhWvvEN">Gestures can be linked to the work related to bodybased action and embodied learning, such as CS Unplugged <ref type="bibr" target="#b68">[69]</ref>, based on the congruence between these embodied activities and computing concepts <ref type="bibr" target="#b69">[70]</ref>.</s><s xml:id="_dSxG9ad">This research is an encouraging sign for future researchers, showing the value of reflecting on the mapping between specific body actions and computing concepts, as well as the potential to adopt these actions through gestures, especially given the way that gestures can connect action, experience, and scientific language <ref type="bibr" target="#b59">[60]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7ENmzmr">The Role of Metaphors in Communication, Learning and Explaining</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cc6PQzG">-</head><p xml:id="_3VHX6Ev"><s xml:id="_hEptK4m">The role of metaphoric gestures as a tool to facilitate communication for both the gesture producer and the gesture receiver: In this study, we observed that students used gestures.</s><s xml:id="_znU3ZTD">However, this research did not focus on the issue of exactly when children used metaphorical gestures or their reasons for using them.</s></p><p xml:id="_9QfgKeB"><s xml:id="_YXmZZv6">A similar set of questions arise as in the previous subsection.</s><s xml:id="_AM26x3P">For example, do children feel that they spontaneously need to use metaphors in the form of gestures rather than using just speech to represent their understanding of a complex idea such as iteration?</s><s xml:id="_zSnEaze">Or do children decide to use metaphorical gestures because they are talking to an adult whom these gestures may assist?</s><s xml:id="_9RTz2wh">Future research should explore the intention associated with using metaphorical gestures, enabling educators to use these gestures to identify any misconceptions that students might have and correct their understanding.</s></p><p xml:id="_vum2mgs"><s xml:id="_k4Y9znd">-Depth and transfer of learning: research in mathematics education <ref type="bibr" target="#b70">[71]</ref> indicates that the use of representational gestures can lead to differences in the depth and transfer of learning.</s><s xml:id="_UukXjeP">Although this study examined gestures through two different interviews, more work is needed to examine how gesturing evolves with learners' ability over longer time.</s><s xml:id="_PRx2nGM">For example, does gesturing decrease over time as concepts get more established or does it increase over time as it seems to aid understanding?</s><s xml:id="_yy4tfWv">Future work is needed to examine how certain gestures are related to students' learning and how gestures can support different learning needs.</s><s xml:id="_KFb4AYD">This could be important in evaluating the potential of teaching gestures to assess and support learning <ref type="bibr" target="#b11">[12]</ref>.</s></p><p xml:id="_QJ3V9D5"><s xml:id="_sn4sAsK">-Tool to convey knowledge: Scopelitis argues that gesture can be employed as a tool to build representations that the speaker and hearer can use to achieve a common understanding <ref type="bibr" target="#b67">[68]</ref>.</s><s xml:id="_ptA274Z">One participant (P37) said that the program was a "repeat" while gesturing the form of a container, he described the meaning of a program with the help of a metaphorical gesture.</s><s xml:id="_ntkcrYp">Additionally, the participant expressed the concept of "put stuff inside" by simulating putting one programming block inside another programming block; he then expressed "then it will repeat" by gesturing a circular motion.</s><s xml:id="_zVD4S4s">The participant was likely trying to embody and share their mental representation of a program, which gave the hearer a concrete representation.</s><s xml:id="_qTgJHJG">This was very similar to Solomon's finding in the case study of a CS instructor who used the gesture as a tool to convey the concept of a list <ref type="bibr" target="#b43">[44]</ref>.</s></p><p xml:id="_D2zuga9"><s xml:id="_zP2Y8SN">-</s></p><p xml:id="_myzqHPt"><s xml:id="_K2xuSgA">The relationship between the development of metaphor and understanding: Even though we observed the gestures before and after a two-week gap, we did not trace a developmental path in the children's gestures and their relationship with understanding.</s><s xml:id="_cJq27uK">Future work should explore how gestural metaphors change as children develop their computing knowledge.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gqcpQcn">Teachers and Gestures</head><p xml:id="_j2Md5E8"><s xml:id="_832RyHa">Teachers' observations of gestures: The research highlights that many children use hand gestures to explain and communicate programming concepts.</s><s xml:id="_SZXJrF9">This finding underlines the relevance of gestures in communicating an understanding of computing topics to an adult (in this case the researcher).</s><s xml:id="_Z7xTDg9">The children used hand gestures to explain and communicate programming concepts.</s><s xml:id="_qY6xkkk">When teachers observe students' gestures in the classroom, this can enable them to assess the understanding of learners <ref type="bibr" target="#b36">[37]</ref>.</s><s xml:id="_KJvxUJd">This work documents and describes students' use of gestures while explaining computing concepts.</s><s xml:id="_9bvWsdg">Future research might seek to evaluate how teachers can increase the attention they pay towards children's use of gestures in the classroom, and how to assess the use of gestures.</s><s xml:id="_G988zzP">Since gestures can serve as a way to visualize a learner's understanding, teachers may be able to identify and assess potential strengths and weaknesses by considering them.</s><s xml:id="_CnbpPgx">In general, an educator's awareness of their students' thinking can be improved by paying attention to the gestures and by cautiously considering the reasons for these gestures and the conceptual mappings that they produce <ref type="bibr">[72]</ref>.</s><s xml:id="_tUBEbVr">Virtually all of the participants in the current study produced gestures that suggested hands-on or bodily simulation of the robot's movement.</s><s xml:id="_bYhX85F">Many of these gestures were not very precise about how the robot moved (for example, if it turned, it moved its head only, or turned and moved one step simultaneously).</s><s xml:id="_Dfr5Der">Such details of the robot's movement being inaccurate might mean that students had limited understanding of how the code functioned; this could be addressed further.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8" xml:id="_xB96AzG">Limitations</head><p xml:id="_HtdEXDR"><s xml:id="_xx6jQUP">Although we were limited to simple computing concepts because of the age group, we found promising results.</s><s xml:id="_AzWANF7">Research with a wider population with more diverse age groups, cultures and first languages would be required to examine how understandings of the importance and use of gesture might be generalised.</s><s xml:id="_JAxDh5h">Different metaphors may serve to support understanding at different levels.</s><s xml:id="_V5XG5Ke">We found a pattern that might reflect similarities across cultures or external representations that are possibly similar across contexts.</s><s xml:id="_WRv2czB">A more in-depth view is needed to generalise the findings using the methodology used in this paper, as the meaning of a gesture can differ between occurrences <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b62">63]</ref>.</s><s xml:id="_V9XBNAQ">Our study's findings demonstrate the value of this investigation in future work, as we discovered patterns across participants at a very young age, suggesting the potential to investigate overlap and different meanings and concepts.</s></p><p xml:id="_RhkXvAK"><s xml:id="_TbaNkj3">Additionally, due to the participants' young age, this work only focused on two computing concepts-program, and iteration.</s><s xml:id="_j6gxrkh">Further research should examine more computing concepts and identify the factors influencing the embodied nature of different concepts.</s><s xml:id="_bW5keYX">Such an approach might reveal more variations in metaphorical representation than those we found in this study.</s></p><p xml:id="_HRKsK3F"><s xml:id="_rdFYab6">Moreover, although this study examined gestures via two interviews, relatively few participants generated RGmetaphorical gestures in both interviews.</s><s xml:id="_GtnN6zu">For this reason, we were not able to present an analysis of qualitative differences in gestures between the two interviews nor infer from gestures a change in their understanding of the concepts over time.</s><s xml:id="_vRzqNhd">Further work is needed to examine how gesture evolves with learners' abilities over time, how certain gestures are related to students' learning and how gestures can support different learning needs.</s><s xml:id="_eNFPQrK">This could be important in evaluating teaching gestures' potential to assess and support learning <ref type="bibr" target="#b11">[12]</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9" xml:id="_6QwdREh">Conclusion</head><p xml:id="_pwVqrkF"><s xml:id="_AQU3EJW">This study explored the embodied expression of two programming concepts, program and iteration.</s><s xml:id="_NNXB5Um">The role and implication of embodied cognition have been studied extensively in STEM subjects, especially mathematics and science education.</s><s xml:id="_stWwNFV">This study contributes to children's computing education research by providing empirical evidence for the embodied nature of their understanding of computing concepts and draws attention to the potential benefits of exploring the role of embodied representations such as gestures in this domain.</s><s xml:id="_MwfAhZP">The findings show that the children aged 6-7 years old produced less gestural evidence of metaphorical understanding compared to that of conceptual understanding.</s><s xml:id="_RnErqR9">Additionally, this study provides supporting evidence for the ideas that gestures might have been used as a tool to offload cognitive load and as a secondary channel of communication instead of just using speech.</s><s xml:id="_H6dsZCg">This research also suggests how gestures might have been an indication of the embodiment of the children's computing notions.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 (Figure 2</head><label>12</label><figDesc><div><p xml:id="_N7kS3hY"><s xml:id="_RmUg8Z5">Figure 1 (Q3) Simple code aimed to describing how a simple program works</s></p></div></figDesc><graphic coords="9,78.00,72.00,140.25,228.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4</head><label>4</label><figDesc><div><p xml:id="_tGnmwrk"><s xml:id="_ebXKHBW">Figure 4 participant pointing to the code Figure 5 participant using RG-literally to descript the left turn Figure 6 participant moving their hand in a circular motion to represent repeat Pointing RG-literal RG-metaphorical</s></p></div></figDesc><graphic coords="12,389.30,122.87,107.07,102.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 P10Figure 9 ,</head><label>89</label><figDesc><div><p xml:id="_zYcqs5f"><s xml:id="_q4bfM6h">Figure8P10"we used that [referring to the repeat] that if we put two things will go and will return again."</s></p></div></figDesc><graphic coords="15,154.40,73.62,72.97,90.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 11 ,</head><label>11</label><figDesc><div><p xml:id="_aKZrUbU"><s xml:id="_zdmWWa5">Figure 11, P44: Hand moves two times forward.</s></p></div></figDesc><graphic coords="15,315.45,198.60,129.61,104.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 15 ,Figure 10</head><label>1510</label><figDesc><div><p xml:id="_fkCAeEZ"><s xml:id="_Ukg4EBn">Figure 15, P32: "You can put things like left, then it will move left left, then it will go to the flag.</s><s xml:id="_Hp5cpDb">The repeat will make it go again" [hand gesture in an arc].</s></p></div></figDesc><graphic coords="15,303.15,575.94,111.29,85.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 16 ,</head><label>16</label><figDesc><div><p xml:id="_yDtd4bw"><s xml:id="_sAk9USA">Figure 16, P39 pointed to the code from the previous question and said "It does it double times", gesturing with both hands in a circular motion.</s></p></div></figDesc><graphic coords="16,77.65,108.30,121.19,109.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 17 ,</head><label>17</label><figDesc><div><p xml:id="_qsTw3A2"><s xml:id="_Qt4q3yg">Figure 17, P18 "here is Repeat" pointing to the repeat."</s><s xml:id="_dkNxhq6">Inside there is right right" [ pointing inside the repeat] "it will repeat again and again" [big circular motion with her hand open]."</s></p></div></figDesc><graphic coords="16,302.40,98.55,128.65,128.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 18 ,</head><label>18</label><figDesc><div><p xml:id="_vdCjwCG"><s xml:id="_8XNquq4">Figure 18, P19 "If there is something here [A], it will move twice [B]"Figure19, P01 "Doing it again and again [hand moving from right to left] and again".</s></p></div></figDesc><graphic coords="16,302.40,304.09,120.65,136.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 21 P45</head><label>21</label><figDesc><div><p xml:id="_zzszXN6"><s xml:id="_kXy5Q5P">Figure 21 P45 used of gesture to reveal implicit knowledge</s></p></div></figDesc><graphic coords="17,72.00,106.50,98.60,110.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="1,52.20,28.26,524.88,144.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc><div><p xml:id="_8RmmPfE"><s xml:id="_vHy9CeF">Interview questions</s></p></div></figDesc><table><row><cell>Question Number</cell><cell>Question</cell><cell>Themes</cell></row></table><note xml:id="_ctNNqap"><p>Q1</p><p><s xml:id="_grEWMWK">What did you learn today in our session with the robot?</s><s xml:id="_6wxXT3Y">Icebreaker Q2 What is a program?</s><s xml:id="_Rkks4An">Understand the general concept of a program Q3 Explain this program, please?</s><s xml:id="_eJrGvWd">[showing the sequence program; see Figure 1] Describing how a simple program works using simple sequence commands Q4 What does repeat do? [If the child did not answer, the researcher would show the child an image of the Repeat block; see Figure 2] Understand complex computing concepts such as iteration Q5 Explain this program, please?</s><s xml:id="_FRCmtKH">[showing the complex program; see Figure 3] Describing how a complex program works</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc><div><p xml:id="_6J5JryQ"><s xml:id="_AAf2NcF">Prompts and responses for each question</s></p></div></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Interview</cell><cell cols="2">Asked Answers</cell><cell cols="2">Gestures Prompted</cell><cell cols="2">Prompt types</cell><cell>Total of</cell><cell>Total no</cell><cell>Total no</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Before</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>no of</cell><cell>of</cell><cell>of</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>prompted</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>answer</cell><cell>answers</cell><cell>gestures</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>after</cell><cell>after</cell></row><row><cell cols="3">Questions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>prompt</cell><cell>prompt</cell></row><row><cell>Q1:</cell><cell>Icebreake</cell><cell>r</cell><cell></cell><cell>45 45</cell><cell>38 43</cell><cell>10 5</cell><cell>0 0</cell><cell></cell><cell></cell><cell>0 2</cell><cell>38 43</cell><cell>10 5</cell></row><row><cell>Q2:</cell><cell>Understanding</cell><cell>program</cell><cell></cell><cell>45 37</cell><cell>34 22</cell><cell>10 5</cell><cell>0 0</cell><cell></cell><cell></cell><cell>11 15</cell><cell>45 22</cell><cell>10 3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>47</cell><cell>47</cell><cell>186</cell><cell>105</cell><cell></cell><cell>Asking the student to</cell><cell>0</cell><cell>47</cell><cell>261</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>demonstrate</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>the action</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(e.g., "Show</cell><cell></cell></row><row><cell></cell><cell>Q3: Explaining simple code</cell><cell></cell><cell></cell><cell>45</cell><cell>45</cell><cell>260</cell><cell>60</cell><cell>  </cell><cell>me how", or "How?") Indicating the start point of the code ("We start from way [pointing to the left]".) Encouraging them to here".) "Left is this</cell><cell>0</cell><cell>45</cell><cell>304</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>explain the</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>whole code</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>sequence</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>using "then"</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>or "continue".</cell><cell></cell></row><row><cell>Q4:</cell><cell>Understanding</cell><cell>iteration</cell><cell></cell><cell>47 35</cell><cell>40 33</cell><cell>51 60</cell><cell>7 10</cell><cell cols="2">Showing the image of the repeat</cell><cell>3 5</cell><cell>44 41</cell><cell>52 68</cell></row><row><cell>Q5: Explain</cell><cell>complex</cell><cell>code</cell><cell></cell><cell>47 45</cell><cell>47 44</cell><cell>137 188</cell><cell>22 22</cell><cell></cell><cell>Same as Q3</cell><cell>1</cell><cell>47 45</cell><cell>151 202</cell></row><row><cell cols="3">Total</cell><cell></cell><cell>231 218</cell><cell>206 186</cell><cell>394 518</cell><cell>134 92</cell><cell></cell><cell></cell><cell>14 23</cell><cell>211 355</cell><cell>484 582</cell></row><row><cell cols="3">Overall total</cell><cell>1 and 2</cell><cell>449</cell><cell>392</cell><cell>899</cell><cell>226</cell><cell></cell><cell></cell><cell>37</cell><cell>566</cell><cell>1068</cell></row></table></figure>
		</body>
		<back>


			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10" xml:id="_G6Nr2EY">ACKNOWLEDGMENTS</head><p xml:id="_7tWKt2U"><s xml:id="_8wTrdMz">The authors thank the school headteacher, teachers, parents, and children who participated in this study.</s><s xml:id="_VGTXw6U">This work was funded by [Institution anonymised for review].</s></p><p xml:id="_FZ9CNG5"><s xml:id="_5CArMg5">11 Bibliography</s></p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_4rdNTKe">Restart: The resurgence of computer science in UK schools</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C C</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sentance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Crick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Humphreys</surname></persName>
		</author>
		<idno type="DOI">10.1145/2602484</idno>
		<ptr target="https://doi.org/10.1145/2602484" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_kh6zBCW">ACM Transactions on Computing Education</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">N.C.C. Brown, S. Sentance, T. Crick, S. Humphreys, Restart: The resurgence of computer science in UK schools, ACM Transactions on Computing Education. 14 (2014). https://doi.org/10.1145/2602484.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_8bWgK5w">Computational thinking</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wing</surname></persName>
		</author>
		<idno type="DOI">10.1145/1118178.1118215</idno>
		<ptr target="https://doi.org/10.1145/1118178.1118215" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_JsaBfC4">Commun ACM</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="33" to="35" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J.M. Wing, Computational thinking, Commun ACM. 49 (2006) 33-35. https://doi.org/10.1145/1118178.1118215.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_xp3PjfR">Math on a sphere: Using public displays to support children&apos;s creativity and computational thinking on 3D surfaces</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eisenberg</surname></persName>
		</author>
		<idno type="DOI">10.1145/2307096.2307137</idno>
		<ptr target="https://doi.org/10.1145/2307096.2307137" />
	</analytic>
	<monogr>
		<title level="s" xml:id="_72XnES5">ACM International Conference Proceeding Series</title>
		<imprint>
			<biblScope unit="page" from="248" to="251" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Hsi, M. Eisenberg, Math on a sphere: Using public displays to support children&apos;s creativity and computational thinking on 3D surfaces, in: ACM International Conference Proceeding Series, 2012: pp. 248-251. https://doi.org/10.1145/2307096.2307137.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName><surname>Johnson</surname></persName>
		</author>
		<title level="m" xml:id="_5mcSHZM">Metaphors We Live by</title>
		<meeting><address><addrLine>Chicago,IL,USA</addrLine></address></meeting>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
	<note type="raw_reference">George. Lakoff, M. Johnson, Metaphors We Live by, University of Chicago Press, Chicago,IL,USA, 1980.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_7mGFYG5">Frozen in the Past: When it Comes to Analogy Fears, It&apos;s Time for Us to &quot;let it Go</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bettin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ott</surname></persName>
		</author>
		<idno type="DOI">10.1145/3430665.3456381</idno>
		<ptr target="https://doi.org/10.1145/3430665.3456381" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_tqW6wRP">Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="359" to="365" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. Bettin, L. Ott, Frozen in the Past: When it Comes to Analogy Fears, It&apos;s Time for Us to &quot;let it Go,&quot; Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE. (2021) 359-365. https://doi.org/10.1145/3430665.3456381.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Leroi-Gourhan</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/14647.003.0028</idno>
		<title level="m" xml:id="_3C5Y6C5">Gesture and Speech</title>
		<meeting><address><addrLine>Cambridge, Massachusetts</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A. Leroi-Gourhan, Gesture and Speech, The MIT Press, Cambridge, Massachusetts, 1993.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_NHnwYVU">Gesture and the process of speech production: We think, therefore we gesture</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.1080/016909600750040571</idno>
		<ptr target="https://doi.org/10.1080/016909600750040571" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_WDY7VfJ">Lang Cogn Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="593" to="613" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M.W. Alibali, S. Kita, A.J. Young, Gesture and the process of speech production: We think, therefore we gesture, Lang Cogn Process. 15 (2000) 593-613. https://doi.org/10.1080/016909600750040571.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_sRSPgqB">Embodiment in Mathematics Teaching and Learning: Evidence From Learners&apos; and Teachers&apos; Gestures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Nathan</surname></persName>
		</author>
		<idno type="DOI">10.1080/10508406.2011.611446</idno>
		<ptr target="https://doi.org/10.1080/10508406.2011.611446" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_g7h7RZb">Journal of the Learning Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="247" to="286" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M.W. Alibali, M.J. Nathan, Embodiment in Mathematics Teaching and Learning: Evidence From Learners&apos; and Teachers&apos; Gestures, Journal of the Learning Sciences. 21 (2012) 247-286. https://doi.org/10.1080/10508406.2011.611446.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main" xml:id="_Ka85e85">Perspective-Taking and Object Construction: Two Keys to Learning, Constuctionism in Practice: Designing, Thinking, and Learning in a Digital World</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Ackermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="25" to="37" />
		</imprint>
	</monogr>
	<note type="raw_reference">E.K. Ackermann, Perspective-Taking and Object Construction: Two Keys to Learning, Constuctionism in Practice: Designing, Thinking, and Learning in a Digital World. 1 (1996) 25-37.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_u3kkUNH">Distributed Cognition: Toward a New Foundation for Human-Computer Interaction Research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hollan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kirsh</surname></persName>
		</author>
		<idno type="DOI">10.1145/353485.353487</idno>
		<ptr target="https://doi.org/10.1145/353485.353487" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_3mzgqTd">ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="174" to="196" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Hollan, E. Hutchins, D. Kirsh, Distributed Cognition: Toward a New Foundation for Human- Computer Interaction Research, ACM Transactions on Computer-Human Interaction. 7 (2000) 174- 196. https://doi.org/10.1145/353485.353487.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_maYEQEP">Which cognitive abilities underlie computational thinking? Criterion validity of the Computational Thinking Test</title>
		<author>
			<persName><forename type="first">M</forename><surname>Román-González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><forename type="middle">C</forename><surname>Pérez-González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jiménez-Fernández</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2016.08.047</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2016.08.047" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_mUnsgea">Comput Human Behav</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="678" to="691" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Román-González, J.-C.C. Pérez-González, C. Jiménez-Fernández, Which cognitive abilities underlie computational thinking? Criterion validity of the Computational Thinking Test, Comput Human Behav. 72 (2017) 678-691. https://doi.org/10.1016/j.chb.2016.08.047.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_aFUzNRc">Identifying embodied metaphors for computing education</title>
		<author>
			<persName><forename type="first">A</forename><surname>Manches</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Mckenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Robertson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2018.12.037</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2018.12.037" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_pFM29h9">Comput Human Behav</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page">105859</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A. Manches, P.E. McKenna, G. Rajendran, J. Robertson, Identifying embodied metaphors for computing education, Comput Human Behav. 105 (2020) 105859. https://doi.org/10.1016/j.chb.2018.12.037.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_UnkMHjz">Improving early reading comprehension using embodied CAI</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Glenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11251-009-9096-7</idno>
		<ptr target="https://doi.org/10.1007/s11251-009-9096-7" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_2VB84cQ">Instr Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="27" to="39" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A.M. Glenberg, A.B. Goldberg, X. Zhu, Improving early reading comprehension using embodied CAI, Instr Sci. 39 (2010) 27-39. https://doi.org/10.1007/s11251-009-9096-7.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_SYjPbkd">The Missing Bodies of Mathematical Thinking and Learning Have Been Found</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
		<idno type="DOI">10.1080/10508406.2011.614326</idno>
		<ptr target="https://doi.org/10.1080/10508406.2011.614326" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Btw54SC">Journal of the Learning Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="337" to="346" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R. Stevens, The Missing Bodies of Mathematical Thinking and Learning Have Been Found, Journal of the Learning Sciences . 21 (2011) 337-346. https://doi.org/10.1080/10508406.2011.614326.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName><surname>Johnson</surname></persName>
		</author>
		<title level="m" xml:id="_v4nfA3t">Philosophy In The Flesh: The Embodied Mind And Its Challenge To Western Thought</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Basic Books</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="raw_reference">George. Lakoff, M. Johnson, Philosophy In The Flesh: The Embodied Mind And Its Challenge To Western Thought, Basic Books, New York, 1999.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Varela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eleanor</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kabat-Zinn</surname></persName>
		</author>
		<idno type="DOI">10.29173/cmplct8718</idno>
		<ptr target="https://doi.org/10.29173/cmplct8718" />
		<title level="m" xml:id="_WKvBmNG">The embodied mind: Cognitive science and human experience</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">F.J. Varela, Evan. Thompson, Eleanor. Rosch, J. Kabat-Zinn, The embodied mind: Cognitive science and human experience, MIT Press, 2016. https://doi.org/10.29173/cmplct8718.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_EBfNV3W">Six views of embodied cognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03196322</idno>
		<ptr target="https://doi.org/10.3758/BF03196322" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_yJJxTWQ">Psychon Bull Rev</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="625" to="636" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Wilson, Six views of embodied cognition, Psychon Bull Rev. 9 (2002) 625-636. https://doi.org/10.3758/BF03196322.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main" xml:id="_UA5NZfH">Where mathematics comes from : how the embodied mind brings mathematics into being</title>
		<author>
			<persName><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Lakoff</surname></persName>
		</author>
		<author>
			<persName><surname>Núñez</surname></persName>
		</author>
		<ptr target="https://www.maa.org/comment/27" />
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Basic Books</publisher>
			<pubPlace>New York, New York, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">George. Lakoff, R.E. Núñez, Where mathematics comes from : how the embodied mind brings mathematics into being, Basic Books, New York, New York, USA, 2000. https://www.maa.org/comment/27.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_trpzsUv">Embodied cognition, abstract concepts, and the benefits of new technology for implicit body manipulation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dijkstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eerland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zijlmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Post</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00757</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2014.00757" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_CeynFkw">Front Psychol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">757</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">K. Dijkstra, A. Eerland, J. Zijlmans, L.S. Post, Embodied cognition, abstract concepts, and the benefits of new technology for implicit body manipulation, Front Psychol. 5 (2014) 757. https://doi.org/10.3389/fpsyg.2014.00757.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_7bHdJz3">Learning from Gesture: How Our Hands Change Our Minds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Novack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10648-015-9325-3</idno>
		<ptr target="https://doi.org/10.1007/s10648-015-9325-3" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_7tyDRFb">Educ Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="405" to="412" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Novack, S. Goldin-Meadow, Learning from Gesture: How Our Hands Change Our Minds, Educ Psychol Rev. 27 (2015) 405-412. https://doi.org/10.1007/s10648-015-9325-3.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_dSaTaSD">Designing for concreteness fading in primary computing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Trory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Howland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Good</surname></persName>
		</author>
		<idno type="DOI">10.1145/3202185.3202748</idno>
		<ptr target="https://doi.org/10.1145/3202185.3202748" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_gxrrGrD">IDC 2018 -Proceedings of the 2018 ACM Conference on Interaction Design and Children</title>
		<imprint>
			<publisher>Association for Computing Machinery, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="278" to="288" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Trory, K. Howland, J. Good, Designing for concreteness fading in primary computing, in: IDC 2018 -Proceedings of the 2018 ACM Conference on Interaction Design and Children, Association for Computing Machinery, Inc, 2018: pp. 278-288. https://doi.org/10.1145/3202185.3202748.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_pg9F53U">Notional machines and introductory programming education</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sorva</surname></persName>
		</author>
		<idno type="DOI">10.1145/2483710.2483713</idno>
		<ptr target="https://doi.org/10.1145/2483710.2483713" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_YGvsRA7">ACM Transactions on Computing Education (TOCE)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Sorva, Notional machines and introductory programming education, ACM Transactions on Computing Education (TOCE). 13 (2013). https://doi.org/10.1145/2483710.2483713.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main" xml:id="_EvtY7SP">Some Difficulties of Learning to Program</title>
		<author>
			<persName><forename type="first">B</forename><surname>Boulay</surname></persName>
		</author>
		<idno type="DOI">10.2190/3lfx-9rrf-67t8-uvk9</idno>
		<ptr target="https://doi.org/10.2190/3LFX-9RRF-67T8-UVK9" />
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="57" to="73" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. du Boulay, Some Difficulties of Learning to Program:, Http://Dx.Doi.Org/10.2190/3LFX-9RRF- 67T8-UVK9. 2 (1995) 57-73. https://doi.org/10.2190/3LFX-9RRF-67T8-UVK9.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_KughbWF">To Write Code: The Cultural Fabrication of Programming Notation and Practice</title>
		<author>
			<persName><forename type="first">I</forename><surname>Arawjo</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376731</idno>
		<ptr target="https://doi.org/10.1145/3313831.3376731" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_nM4HJbU">Conference on Human Factors in Computing Systems -Proceedings</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">I. Arawjo, To Write Code: The Cultural Fabrication of Programming Notation and Practice, Conference on Human Factors in Computing Systems -Proceedings. (2020). https://doi.org/10.1145/3313831.3376731.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main" xml:id="_gFXG8Tx">Thinking with the Body: Conceptual Integration Through Gesture in Multiviewpoint Model Construction, Language and the Creative Mind</title>
		<author>
			<persName><forename type="first">D</forename><surname>Deliema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Francis</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781316569856.010</idno>
		<ptr target="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2266574" />
		<imprint>
			<date type="published" when="2013-03-13">2013. March 13, 2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D. DeLiema, S. Francis, Thinking with the Body: Conceptual Integration Through Gesture in Multiviewpoint Model Construction, Language and the Creative Mind. (2013). https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2266574 (accessed March 13, 2022).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_8ztUVfx">Metaphor in computer science</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Colburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Shute</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jal.2008.09.005</idno>
		<ptr target="https://doi.org/10.1016/j.jal.2008.09.005" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_DmKx9mJ">Journal of Applied Logic</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="526" to="533" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">T.R. Colburn, G.M. Shute, Metaphor in computer science, Journal of Applied Logic. 6 (2008) 526- 533. https://doi.org/10.1016/j.jal.2008.09.005.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main" xml:id="_Dc9ERv2">With the future behind them: Convergent evidence from Aymara language and gesture in the crosslinguistic comparison of spatial construals of time</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Núñez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sweetser</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15516709cog0000_62</idno>
		<ptr target="https://doi.org/10.1207/s15516709cog0000_62" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_vvAEAmt">Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="401" to="450" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R.E. Núñez, E. Sweetser, With the future behind them: Convergent evidence from Aymara language and gesture in the crosslinguistic comparison of spatial construals of time, Cogn Sci. 30 (2006) 401- 450. https://doi.org/10.1207/s15516709cog0000_62.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_6CeWscG">Conceptual metaphor theory: Some criticisms and alternative proposals</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kövecses</surname></persName>
		</author>
		<idno type="DOI">10.1075/arcl.6.08kov</idno>
		<ptr target="https://doi.org/10.1075/arcl.6.08kov" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_SD36huN">Annual Review of Cognitive Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="168" to="184" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Z. Kövecses, Conceptual metaphor theory: Some criticisms and alternative proposals, Annual Review of Cognitive Linguistics. 6 (2008) 168-184. https://doi.org/10.1075/arcl.6.08kov.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main" xml:id="_DF6cmDZ">Identifying embodied metaphors in children&apos;s soundaction mappings</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Antle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Van Den Hoven</surname></persName>
		</author>
		<idno type="DOI">10.1145/1551788.1551812</idno>
		<ptr target="https://doi.org/10.1145/1551788.1551812" />
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>ACM Press</publisher>
			<pubPlace>New York, New York, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bakker, A.N. Antle, E. van den Hoven, Identifying embodied metaphors in children&apos;s sound- action mappings, ACM Press, New York, New York, USA, 2009. https://doi.org/10.1145/1551788.1551812.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_EAZxz4b">Hand and Mind: What Gestures Reveal about Thought</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcneill</surname></persName>
		</author>
		<idno type="DOI">10.2307/1576015</idno>
		<ptr target="https://doi.org/10.2307/1576015" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_D8kr4WN">Lang Speech</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">432</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D. McNeill, Hand and Mind: What Gestures Reveal about Thought, Lang Speech. 27 (1994) 432. https://doi.org/10.2307/1576015.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_6gU7Pvb">Gestures and growth points in language disorders</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcneill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duncan</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203848005.ch32</idno>
		<ptr target="https://doi.org/10.4324/9780203848005.ch32" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_x4wMwAm">The Handbook of Psycholinguistic and Cognitive Processes: Perspectives in Communication Disorders</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Taylor and Francis</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="663" to="685" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. McNeill, S. Duncan, Gestures and growth points in language disorders, in: The Handbook of Psycholinguistic and Cognitive Processes: Perspectives in Communication Disorders, Taylor and Francis, New York, 2011: pp. 663-685. https://doi.org/10.4324/9780203848005.ch32.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_dyYhgT4">What we mean by meaning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Parrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sweetser</surname></persName>
		</author>
		<idno type="DOI">10.1075/gest.4.2.05par</idno>
		<ptr target="https://doi.org/10.1075/gest.4.2.05par" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_2kGpTqU">Gesture</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="197" to="219" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="raw_reference">F. Parrill, E. Sweetser, What we mean by meaning, Gesture. 4 (2005) 197-219. https://doi.org/10.1075/gest.4.2.05par.</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_9xhR6cR">When our hands help us understand: A meta-analysis into the effects of gesture on comprehension</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dargue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sweller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000202</idno>
		<ptr target="https://doi.org/10.1037/bul0000202" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_9Zj3cEd">Psychol Bull</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="765" to="784" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">N. Dargue, N. Sweller, M.P. Jones, When our hands help us understand: A meta-analysis into the effects of gesture on comprehension, Psychol Bull. 145 (2019) 765-784. https://doi.org/10.1037/bul0000202.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_78gE7GB">Hands in the Air: Using Ungrounded Iconic Gestures to Teach Children Conservation of Quantity</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1037/0012-1649.44.5.1277</idno>
		<ptr target="https://doi.org/10.1037/0012-1649.44.5.1277" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_g6w2z8k">Dev Psychol</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1277" to="1287" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">R.M. Ping, S. Goldin-Meadow, Hands in the Air: Using Ungrounded Iconic Gestures to Teach Children Conservation of Quantity, Dev Psychol. 44 (2008) 1277-1287. https://doi.org/10.1037/0012-1649.44.5.1277.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_kXZJsF4">Gestures, but not meaningless movements, lighten working memory load when explaining math</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Yip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1080/01690965.2011.567074</idno>
		<ptr target="https://doi.org/10.1080/01690965.2011.567074" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_cnRA3Gq">Lang Cogn Process</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="594" to="610" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S.W. Cook, T.K. Yip, S. Goldin-Meadow, Gestures, but not meaningless movements, lighten working memory load when explaining math, Lang Cogn Process. 27 (2012) 594-610. https://doi.org/10.1080/01690965.2011.567074.</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_zkMvad5">Shuttling between depictive models and abstract rules: Induction and fallback</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Black</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0364-0213(99)80012-3</idno>
		<ptr target="https://doi.org/10.1016/S0364-0213(99)80012-3" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_hTJhrtf">Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="457" to="497" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note type="raw_reference">D.L. Schwartz, J.B. Black, Shuttling between depictive models and abstract rules: Induction and fallback, Cogn Sci. 20 (1996) 457-497. https://doi.org/10.1016/S0364-0213(99)80012-3.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_sjw3xFu">A helping hand in assessing children&apos;s knowledge: Instructing adults to attend to gesture</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1207/S1532690XCI2001_1</idno>
		<ptr target="https://doi.org/10.1207/S1532690XCI2001_1" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_22cHThR">Cogn Instr</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S.D. Kelly, M. Singer, J. Hicks, S. Goldin-Meadow, A helping hand in assessing children&apos;s knowledge: Instructing adults to attend to gesture, Cogn Instr. 20 (2002) 1-26. https://doi.org/10.1207/S1532690XCI2001_1.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_HAgXwZE">Teachers&apos; gestures facilitate students&apos; learning: A lesson in symmetry</title>
		<author>
			<persName><forename type="first">L</forename><surname>Valenzeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klatzky</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0361-476x(02)00007-3</idno>
		<ptr target="https://doi.org/10.1016/S0361-476X(02)00007-3" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_tQbVdVA">Contemp Educ Psychol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="187" to="204" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="raw_reference">L. Valenzeno, M.W. Alibali, R. Klatzky, Teachers&apos; gestures facilitate students&apos; learning: A lesson in symmetry, Contemp Educ Psychol. 28 (2003) 187-204. https://doi.org/10.1016/S0361- 476X(02)00007-3.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_gArRfyc">Don &apos; t Just Tell Them , Show Them ! Teachers Can Intentionally Alter their Instructional Gestures</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Hostetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Street</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_Ychzc5H">Proceedings of the 28th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 28th Annual Conference of the Cognitive Science Society<address><addrLine>Mahwah, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1523" to="1528" />
		</imprint>
	</monogr>
	<note type="raw_reference">A.B. Hostetter, W.J. Street, M.W. Alibali, Don &apos; t Just Tell Them , Show Them ! Teachers Can Intentionally Alter their Instructional Gestures, Proceedings of the 28th Annual Conference of the Cognitive Science Society. Mahwah, NJ: Erlbaum,. (2006) 1523-1528.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main" xml:id="_NJQgUX8">Embodiment in Mathematics Teaching and Learning: Evidence From Learners&apos; and Teachers&apos; Gestures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Nathan</surname></persName>
		</author>
		<idno type="DOI">10.1080/10508406.2011.611446</idno>
		<ptr target="https://doi.org/10.1080/10508406.2011.611446" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Q28vmtw">Journal of the Learning Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="247" to="286" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M.W. Alibali, M.J. Nathan, Embodiment in Mathematics Teaching and Learning: Evidence From Learners&apos; and Teachers&apos; Gestures, Journal of the Learning Sciences. 21 (2012) 247-286. https://doi.org/10.1080/10508406.2011.611446.</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_6yPN5Zf">The role of gesture in learning: Do children use their hands to change their minds?</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327647jcd0702_4</idno>
		<ptr target="https://doi.org/10.1207/s15327647jcd0702_4" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_cqEPvt3">Journal of Cognition and Development</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="211" to="232" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S.W. Cook, S. Goldin-Meadow, The role of gesture in learning: Do children use their hands to change their minds?, Journal of Cognition and Development. 7 (2006) 211-232. https://doi.org/10.1207/s15327647jcd0702_4.</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_EcDgbev">Applying a Gesture Taxonomy to Introductory Computing Concepts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guzdial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Disalvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Shapiro</surname></persName>
		</author>
		<idno type="DOI">10.1145/3230977.3231001</idno>
		<ptr target="https://doi.org/10.1145/3230977.3231001" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_5jTWZmh">Proceedings of the 2018 ACM Conference on International Computing Education Research -ICER &apos;18</title>
		<meeting>the 2018 ACM Conference on International Computing Education Research -ICER &apos;18<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="250" to="257" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Solomon, M. Guzdial, B. DiSalvo, B.R. Shapiro, Applying a Gesture Taxonomy to Introductory Computing Concepts, in: Proceedings of the 2018 ACM Conference on International Computing Education Research -ICER &apos;18, ACM Press, New York, New York, USA, 2018: pp. 250-257. https://doi.org/10.1145/3230977.3231001.</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_kQe3E4g">Embodied Representations in Computing Education: How Gesture, Embodied Language, and Tool Use Support Teaching Recursion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Disalvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.22318/icls2020.2133</idno>
		<ptr target="https://doi.org/10.22318/icls2020.2133" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_5ZNQCqd">The Interdisciplinarity of the Learning Sciences, 14th International Conference of the Learning Sciences (ICLS) 2020</title>
		<meeting><address><addrLine>Nashville, Tennessee</addrLine></address></meeting>
		<imprint>
			<publisher>International Society of the Learning Sciences</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2133" to="2140" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Solomon, M. Bae, B. DiSalvo, M. Guzdial, Embodied Representations in Computing Education: How Gesture, Embodied Language, and Tool Use Support Teaching Recursion, in: The Interdisciplinarity of the Learning Sciences, 14th International Conference of the Learning Sciences (ICLS) 2020, International Society of the Learning Sciences, Nashville, Tennessee, 2020: pp. 2133- 2140. https://doi.org/10.22318/icls2020.2133.</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_AE2ptez">Gesturing makes learning last</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1016/J.COGNITION.2007.04.010</idno>
		<ptr target="https://doi.org/10.1016/J.COGNITION.2007.04.010" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_UV9pBAw">Cognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="1047" to="1058" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S.W. Cook, Z. Mitchell, S. Goldin-Meadow, Gesturing makes learning last, Cognition. 106 (2008) 1047-1058. https://doi.org/10.1016/J.COGNITION.2007.04.010.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_SSAMEjm">Investigating children&apos;s spontaneous gestures when programming using TUIs and GUIs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Almjally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Howland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Good</surname></persName>
		</author>
		<idno type="DOI">10.1145/3392063.3394408</idno>
		<ptr target="https://doi.org/10.1145/3392063.3394408" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_njKuduq">Proceedings of the Interaction Design and Children Conference, IDC 2020</title>
		<meeting>the Interaction Design and Children Conference, IDC 2020</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="36" to="48" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Almjally, K. Howland, J. Good, Investigating children&apos;s spontaneous gestures when programming using TUIs and GUIs, in: Proceedings of the Interaction Design and Children Conference, IDC 2020, Association for Computing Machinery, 2020: pp. 36-48. https://doi.org/10.1145/3392063.3394408.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_BZkK4QE">Children&apos;s perception of computer programming as an aid to designing programming environments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sheehan</surname></persName>
		</author>
		<idno type="DOI">10.1145/953536.953548</idno>
		<ptr target="https://doi.org/10.1145/953536.953548" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_YUhrh4A">Proceedings of the 2003 Conference on Interaction Design and Children, IDC 2003</title>
		<meeting>the 2003 Conference on Interaction Design and Children, IDC 2003<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery, Inc</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="75" to="83" />
		</imprint>
	</monogr>
	<note type="raw_reference">R. Sheehan, Children&apos;s perception of computer programming as an aid to designing programming environments, in: Proceedings of the 2003 Conference on Interaction Design and Children, IDC 2003, Association for Computing Machinery, Inc, New York, New York, USA, 2003: pp. 75-83. https://doi.org/10.1145/953536.953548.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main" xml:id="_tGtAd6S">It&apos;s Like a Giant Brain With a Keyboard&quot;: Children&apos;s Understandings About How Computers Work</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Manches</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pain</surname></persName>
		</author>
		<idno type="DOI">10.1080/00094056.2017.1343589</idno>
		<ptr target="https://doi.org/10.1080/00094056.2017.1343589" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_Dhz4MUe">Child Educ</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="338" to="345" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Robertson, A. Manches, H. Pain, &quot;It&apos;s Like a Giant Brain With a Keyboard&quot;: Children&apos;s Understandings About How Computers Work, Child Educ. 93 (2017) 338-345. https://doi.org/10.1080/00094056.2017.1343589.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_TsWxJ7A">Young children&apos;s conceptions of computers, code, and the Internet</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mertala</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijcci.2018.11.003</idno>
		<ptr target="https://doi.org/10.1016/j.ijcci.2018.11.003" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_UKJ8jYk">Int J Child Comput Interact</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="56" to="66" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">P. Mertala, Young children&apos;s conceptions of computers, code, and the Internet, Int J Child Comput Interact. 19 (2019) 56-66. https://doi.org/10.1016/j.ijcci.2018.11.003.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_wD8Vt5Z">Gesture-speech mismatch and mechanisms of learning: what the hands reveal about a child&apos;s state of mind</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldinmeadow</surname></persName>
		</author>
		<idno type="DOI">10.1006/cogp.1993.1012</idno>
		<ptr target="https://doi.org/10.1006/COGP.1993.1012" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_a8S9MzY">Cogn Psychol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="468" to="523" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M.W. Alibali, S. Goldinmeadow, Gesture-speech mismatch and mechanisms of learning: what the hands reveal about a child&apos;s state of mind, Cogn Psychol. 25 (1993) 468-523. https://doi.org/10.1006/COGP.1993.1012.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_EMxH5cq">The Effects of Emblematic Gestures on the Development and Access of Mental Representations of French Expressions</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Q</forename><surname>Allen</surname></persName>
		</author>
		<idno type="DOI">10.2307/330004</idno>
		<ptr target="https://doi.org/10.2307/330004" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_9yzjznR">The Modern Language Journal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">521</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note type="raw_reference">L.Q. Allen, The Effects of Emblematic Gestures on the Development and Access of Mental Representations of French Expressions, The Modern Language Journal. 79 (1995) 521. https://doi.org/10.2307/330004.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main" xml:id="_ubvy2Zb">Gesturing makes memories that last</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K Y</forename><surname>Yip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2010.07.002</idno>
		<ptr target="https://doi.org/10.1016/J.JML.2010.07.002" />
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">63</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">S.W. Cook, T.K.Y. Yip, S. Goldin-Meadow, Gesturing makes memories that last, 63 (2010). https://doi.org/10.1016/J.JML.2010.07.002.</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_T2NGQPQ">Memory for actions: Enactment and source memory</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Hornstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Mulligan</surname></persName>
		</author>
		<idno type="DOI">10.3758/bf03196584</idno>
		<ptr target="https://doi.org/10.3758/BF03196584" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_vrHwpfW">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="367" to="372" />
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S.L. Hornstein, N.W. Mulligan, Memory for actions: Enactment and source memory, Psychonomic Bulletin &amp; Review 2004 11:2. 11 (2004) 367-372. https://doi.org/10.3758/BF03196584.</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_mJgGXCM">Reactivation of hippocampal ensemble memories during sleep</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Mcnaughton</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.8036517</idno>
		<ptr target="https://doi.org/10.1126/science.8036517" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_EgdGebr">Science</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="676" to="679" />
			<date type="published" when="1979">1979. 1994</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M.A. Wilson, B.L. McNaughton, Reactivation of hippocampal ensemble memories during sleep, Science (1979). 265 (1994) 676-679. https://doi.org/10.1126/science.8036517.</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Berry</surname></persName>
		</author>
		<title level="m" xml:id="_NaGWZUj">QuickStart Primary Handbook</title>
		<meeting><address><addrLine>Swindon</addrLine></address></meeting>
		<imprint>
			<publisher>BCS</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Berry, QuickStart Primary Handbook, Swindon: BCS, 2015.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_xpFVmwC">Drawing Valid Meaning from Qualitative Data: Toward a Shared Craft</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Miles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Huberman</surname></persName>
		</author>
		<idno type="DOI">10.3102/0013189X013005020</idno>
		<ptr target="https://doi.org/10.3102/0013189X013005020" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_fhnMHtb">Educational Researcher</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="20" to="30" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M.B. Miles, A.M. Huberman, Drawing Valid Meaning from Qualitative Data: Toward a Shared Craft, Educational Researcher. 13 (1984) 20-30. https://doi.org/10.3102/0013189X013005020.</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_sDrg7Kr">Learning Algorithmic Thinking with Tangible Objects Eases Transition to Computer Programming</title>
		<author>
			<persName><forename type="first">G</forename><surname>Futschek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moschitz</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-24722-4_14</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-24722-4_14" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_RFNSfFm">Proceedings of the 5th International Conference on Informatics in Schools: Situation, Evolution and Perspectives</title>
		<meeting>the 5th International Conference on Informatics in Schools: Situation, Evolution and Perspectives</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
	<note type="raw_reference">G. Futschek, J. Moschitz, Learning Algorithmic Thinking with Tangible Objects Eases Transition to Computer Programming, in: Proceedings of the 5th International Conference on Informatics in Schools: Situation, Evolution and Perspectives, Springer-Verlag, 2011: pp. 155-164. https://doi.org/10.1007/978-3-642-24722-4_14.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_fbnkNMU">The Measurement of Interrater Agreement</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Paik</surname></persName>
		</author>
		<idno type="DOI">10.1002/0471445428.ch18</idno>
		<ptr target="https://doi.org/10.1002/0471445428.ch18" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_RJNPXs7">Statistical Methods for Rates and Proportions</title>
		<imprint>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="598" to="626" />
		</imprint>
	</monogr>
	<note type="raw_reference">J.L. Fleiss, B. Levin, M.C. Paik, The Measurement of Interrater Agreement, in: Statistical Methods for Rates and Proportions, Third, John Wiley &amp; Sons, Inc, 2004: pp. 598-626. https://doi.org/10.1002/0471445428.ch18.</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main" xml:id="_zJxuVcH">Visible embodiment: Gestures as simulated action</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Hostetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
		<idno type="DOI">10.3758/pbr.15.3.495</idno>
		<ptr target="https://doi.org/10.3758/PBR.15.3.495" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_8fV5F42">Psychon Bull Rev</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="495" to="514" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A.B. Hostetter, M.W. Alibali, Visible embodiment: Gestures as simulated action, Psychon Bull Rev. 15 (2008) 495-514. https://doi.org/10.3758/PBR.15.3.495.</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_RcJwE9B">Gestures: Their Role in Teaching and Learning</title>
		<author>
			<persName><forename type="first">W.-M</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.3102/00346543071003365</idno>
		<ptr target="https://doi.org/10.3102/00346543071003365" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_rt9ryTu">Rev Educ Res</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="365" to="392" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">W.-M. Roth, Gestures: Their Role in Teaching and Learning, Rev Educ Res. 71 (2001) 365-392. https://doi.org/10.3102/00346543071003365.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">Lexicon</forename><surname>Lexicon</surname></persName>
		</author>
		<ptr target="https://www.lexico.com/grammar/types-of-noun" />
		<title level="m" xml:id="_EDBMfnt">Types of nouns</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-30">2018. November 30, 2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Lexicon, Lexicon, Oxford. (2018) Types of nouns. https://www.lexico.com/grammar/types-of-noun (accessed November 30, 2020).</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_KTWhgM3">Gestures and conceptual integration in mathematical talk</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Edwards</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10649-008-9124-6</idno>
		<ptr target="https://doi.org/10.1007/s10649-008-9124-6" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_3nqyBdq">Educational Studies in Mathematics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="127" to="141" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">L.D. Edwards, Gestures and conceptual integration in mathematical talk, Educational Studies in Mathematics. 70 (2009) 127-141. https://doi.org/10.1007/s10649-008-9124-6.</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_dRGNESr">Computational Thinking in K-12: A Review of the State of the Field</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pea</surname></persName>
		</author>
		<idno type="DOI">10.3102/0013189x12463051</idno>
		<ptr target="https://doi.org/10.3102/0013189X12463051" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZyqSrA9">Educational Researcher</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="38" to="43" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Grover, R. Pea, Computational Thinking in K-12: A Review of the State of the Field, Educational Researcher. 42 (2013) 38-43. https://doi.org/10.3102/0013189X12463051.</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main" xml:id="_Zhv4Vts">The word order of languages predicts native speakers&apos; working memory</title>
		<author>
			<persName><forename type="first">F</forename><surname>Amici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sánchez-Amaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sebastián-Enesco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cacchione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Allritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Salazar-Bonet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rossano</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-018-37654-9</idno>
		<ptr target="https://doi.org/10.1038/s41598-018-37654-9" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_MQMSb8w">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1124</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">F. Amici, A. Sánchez-Amaro, C. Sebastián-Enesco, T. Cacchione, M. Allritz, J. Salazar-Bonet, F. Rossano, The word order of languages predicts native speakers&apos; working memory, Sci Rep. 9 (2019) 1124. https://doi.org/10.1038/s41598-018-37654-9.</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><surname>Gov</surname></persName>
		</author>
		<author>
			<persName><surname>Uk</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203769263-6</idno>
		<ptr target="https://www.gov.uk/government/publications/national-curriculum-in-england-computing-programmes-of-study/national-curriculum-in-england-computing-programmes-of-study" />
		<title level="m" xml:id="_WqGGe92">National curriculum in England: computing programmes of study</title>
		<imprint>
			<publisher>Department for Education</publisher>
			<date type="published" when="2013-11-07">2013. November 7, 2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">GOV.UK, National curriculum in England: computing programmes of study, Department for Education. (2013). https://www.gov.uk/government/publications/national-curriculum-in-england- computing-programmes-of-study/national-curriculum-in-england-computing-programmes-of-study (accessed November 7, 2017).</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_Z4w7gmP">Making Children Gesture Brings Out Implicit Knowledge and Leads to Learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Broaders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.136.4.539</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.136.4.539" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_f5vj3WX">J Exp Psychol Gen</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="539" to="550" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S.C. Broaders, S.W. Cook, Z. Mitchell, S. Goldin-Meadow, Making Children Gesture Brings Out Implicit Knowledge and Leads to Learning, J Exp Psychol Gen. 136 (2007) 539-550. https://doi.org/10.1037/0096-3445.136.4.539.</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main" xml:id="_sf8ZUF9">Six views of embodied cognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03196322</idno>
		<ptr target="https://doi.org/10.3758/BF03196322" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_BTxW7Gk">Psychon Bull Rev</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="625" to="636" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Wilson, Six views of embodied cognition, Psychon Bull Rev. 9 (2002) 625-636. https://doi.org/10.3758/BF03196322.</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main" xml:id="_tmJpp6P">Made by Hand: Gestural Practices for the Building of Complex Concepts in Face-to-Face, One-on-One Learning Arrangements</title>
		<author>
			<persName><forename type="first">S</forename><surname>Scopelitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
		<idno type="DOI">10.22318/ICLS2010.1.1127</idno>
		<ptr target="https://doi.org/10.22318/ICLS2010.1.1127" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_QJbU38Q">International Society of the Learning Sciences (ISLS)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Scopelitis, S. Mehus, R. Stevens, Made by Hand: Gestural Practices for the Building of Complex Concepts in Face-to-Face, One-on-One Learning Arrangements, International Society of the Learning Sciences (ISLS), 2010. https://doi.org/10.22318/ICLS2010.1.1127.</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main" xml:id="_8g8pzVk">CS unplugged, outreach and CS kinesthetic activities</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marghitu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2157136.2157410</idno>
		<ptr target="https://doi.org/10.1145/2157136.2157410" />
	</analytic>
	<monogr>
		<title level="m" xml:id="_xEwDxag">Association for Computing Machinery</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM)</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">676</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">T. Bell, L. Lambert, D. Marghitu, CS unplugged, outreach and CS kinesthetic activities, in: Association for Computing Machinery (ACM), New York, NY, USA, 2012: p. 676. https://doi.org/10.1145/2157136.2157410.</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_RqQaWuw">Embodied learning: introducing a taxonomy based on bodily engagement and task integration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Skulmowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Rey</surname></persName>
		</author>
		<idno type="DOI">10.1186/S41235-018-0092-9/FIGURES/1</idno>
		<ptr target="https://doi.org/10.1186/S41235-018-0092-9/FIGURES/1" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_xdzZHWa">Cogn Res Princ Implic</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A. Skulmowski, G.D. Rey, Embodied learning: introducing a taxonomy based on bodily engagement and task integration, Cogn Res Princ Implic. 3 (2018) 1-10. https://doi.org/10.1186/S41235-018-0092-9/FIGURES/1.</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main" xml:id="_fRDx42N">From Action to Abstraction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Novack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Congdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hemani-Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goldin-Meadow</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797613518351</idno>
		<ptr target="https://doi.org/10.1177/0956797613518351" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_zVtyWeX">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="903" to="910" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">M. Novack, E.L. Congdon, N. Hemani-Lopez, S. Goldin-Meadow, From Action to Abstraction, Psychol Sci. 25 (2014) 903-910. https://doi.org/10.1177/0956797613518351.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Kendon</surname></persName>
		</author>
		<author>
			<persName><surname>Gesture</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.anthro.26.1.109</idno>
		<ptr target="https://doi.org/10.1146/annurev.anthro.26.1.109" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_HG9fgSp">Annu Rev Anthropol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="109" to="128" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note type="raw_reference">A. Kendon, GESTURE, Annu Rev Anthropol. 26 (1997) 109-128. https://doi.org/10.1146/annurev.anthro.26.1.109.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
