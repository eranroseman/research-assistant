<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_T9TFhjM">Responsible development of clinical speech AI: Bridging the gap between clinical research and technology Check for updates</title>
				<funder ref="#_GsnreMw">
					<orgName type="full">NIH NIA</orgName>
				</funder>
				<funder ref="#_TeGDuEu">
					<orgName type="full">NIDCD</orgName>
				</funder>
				<funder>
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
					<idno type="DOI" subtype="crossref">https://doi.org/10.13039/100000002</idno>
				</funder>
				<funder ref="#_CChh99d">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_JjXU4Yt">
					<orgName type="full">NIH NIDCR</orgName>
				</funder>
				<funder>
					<orgName type="full">John and Tami Marick Family Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Visar</forename><surname>Berisha</surname></persName>
							<idno type="ORCID">0000-0001-8804-8874</idno>
							<affiliation key="aff0">
								<note type="raw_affiliation"><label>1</label> School of Electrical Computer and Energy Engineering and College of Health Solutions , Arizona State University , Tempe , AZ , USA.</note>
								<orgName type="department" key="dep1">School of Electrical Computer and Energy Engineering</orgName>
								<orgName type="department" key="dep2">College of Health Solutions</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julie</forename><forename type="middle">M</forename><surname>Liss</surname></persName>
							<affiliation key="aff1">
								<note type="raw_affiliation"><label>2</label> College of Health Solutions , Arizona State University , Tempe , AZ , USA.</note>
								<orgName type="department">College of Health Solutions</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<settlement>Tempe</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_5j73kMb">Responsible development of clinical speech AI: Bridging the gap between clinical research and technology Check for updates</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B16B4A2487EC5E909A5BAB265ACB35A</idno>
					<idno type="DOI">10.1038/s41746-024-01199-1</idno>
					<note type="submission">Received: 23 November 2023; Accepted: 19 July 2024;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T06:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_cRuDNS3"><p xml:id="_8myPgtB"><s xml:id="_5qmSTnG">This perspective article explores the challenges and potential of using speech as a biomarker in clinical settings, particularly when constrained by the small clinical datasets typically available in such contexts.</s><s xml:id="_GMr62Jt">We contend that by integrating insights from speech science and clinical research, we can reduce sample complexity in clinical speech AI models with the potential to decrease timelines to translation.</s><s xml:id="_ktFmj4x">Most existing models are based on high-dimensional feature representations trained with limited sample sizes and often do not leverage insights from speech science and clinical research.</s><s xml:id="_qea7M8S">This approach can lead to overfitting, where the models perform exceptionally well on training data but fail to generalize to new, unseen data.</s><s xml:id="_9AvN6w3">Additionally, without incorporating theoretical knowledge, these models may lack interpretability and robustness, making them challenging to troubleshoot or improve post-deployment.</s><s xml:id="_T7RpAnk">We propose a framework for organizing health conditions based on their impact on speech and promote the use of speech analytics in diverse clinical contexts beyond cross-sectional classification.</s><s xml:id="_7sbrNh2">For high-stakes clinical use cases, we advocate for a focus on explainable and individually-validated measures and stress the importance of rigorous validation frameworks and ethical considerations for responsible deployment.</s><s xml:id="_wJnkqhB">Bridging the gap between AI research and clinical speech research presents new opportunities for more efficient translation of speech-based AI tools and advancement of scientific discoveries in this interdisciplinary space, particularly if limited to small or retrospective datasets.</s></p><p xml:id="_tA8n7VX"><s xml:id="_htgG2tN">Recently, there has been a surge in interest in leveraging the acoustic properties (how it sounds) and linguistic content (what is said) of human speech as biomarkers for various health conditions.</s><s xml:id="_WRuXWxd">The underlying premise is that disturbances in neurological, mental, or physical health, which affect the speech production mechanism, can be discerned through alterations in speech patterns.</s><s xml:id="_YfsfAfv">As a result, there is a growing emphasis on developing AI models that use speech for the diagnosis, prognosis, and monitoring of conditions such as mental health 1-5 , cognitive disorders 6-10 , and motor diseases <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> , among others.</s></p><p xml:id="_U4JEc3y"><s xml:id="_7M6Fb3x">The development of clinical speech AI has predominantly followed a supervised learning paradigm, building on the success of data-driven approaches for consumer speech applications <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17</ref> .</s><s xml:id="_se7P4NG">For instance, analysis of published speech-based models for dementia reveals that most models rely on high-dimensional speech and language representations 18 , either explicitly extracted or obtained from acoustic foundation models <ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20</ref> and language foundation models <ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> , to predict diagnostic labels <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref> ; a similar trend is observed for depression <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b25">26</ref> .</s><s xml:id="_X4dtCE2">The foundational models, initially pre-trained on data from general populations, are subsequently fine-tuned using clinical</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_Muqg6gW"><p xml:id="_j8eCEcF"><s xml:id="_nArMYXd">data to improve predictive accuracy for specific conditions.</s><s xml:id="_FRxM2jE">While datadriven classification models based on deep learning have worked well for data-rich applications like automatic speech recognition (ASR), the challenges in high-stakes clinical speech technology are distinctly different due to a lack of data availability at scale.</s><s xml:id="_KdAVDye">For example, in the ASR literature, speech corpora can amount to hundreds of thousands of hours of speech samples and corresponding transcripts upon which models can be robustly trained in supervised fashion <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17</ref> .</s><s xml:id="_UCZNPyM">In contrast, currently available clinical datasets are much smaller, with the largest samples in the meta-analysis <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25</ref> consisting of only tens to hundreds of minutes of speech or a few thousand words.</s><s xml:id="_ZGG6tgB">This is because clinical data collection is inherently more challenging than in other speech-based applications.</s><s xml:id="_GwrRZa6">Clinical populations are more diverse and present with variable symptoms that must be simultaneously collected with the speech samples, ensuring proper sampling from relevant strata.</s></p><p xml:id="_vaq8eF5"><s xml:id="_QyQvGCj">Compounding the data problem is the fact that the ground truth accuracy of diagnostic labels for different conditions where speech is impacted varies from 100% certainty to less than 50% certainty, particularly in the early stages of disease when mild symptoms are nonspecific and present similarly across many different diseases <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref> .</s><s xml:id="_Tnvrdc5">Retrospective data often used to train published models does not always report diagnostic label accuracy or the criteria used to arrive at a diagnosis.</s><s xml:id="_8YCezHB">Collecting representative, longitudinal speech corpora with paired consensus diagnoses is time-intensive and further impedes the development of large-scale corpora, which are required for developing diagnostic models based on supervised learning.</s><s xml:id="_bTTcakH">Unfortunately, supervised models built on smaller-scale corpora often exhibit overoptimistic performance in controlled environments <ref type="bibr" target="#b34">35</ref> and fail to generalize in out-of-sample deployments <ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37</ref> .</s><s xml:id="_vnSX2Yz">This begs the question of how we can successfully harness the power of AI to advance clinical practice and population health in the context of data availability constraints.</s></p><p xml:id="_YVbue5y"><s xml:id="_HfmkrVc">Here we propose that the clinical data constraints provide an opportunity for co-design of new analytics pipelines with lower sample complexity in collaboration with the clinical speech science community.</s><s xml:id="_EppukKn">The clinical speech science community has long studied the correlational and causal links between various health conditions and speech characteristics <ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref> .</s><s xml:id="_858wGw6">This research has focused on the physiological, neurological, and psychological aspects of speech production and perception, primarily through acoustic analysis of the speech signal, and linguistic analysis of spoken language.</s><s xml:id="_XWk8bkw">They involve interpretable and conceptually meaningful attributes of speech, often measured perceptually <ref type="bibr" target="#b42">43</ref> , via functional rating scales <ref type="bibr" target="#b14">15</ref> , or self-reported questionnaires <ref type="bibr" target="#b43">44</ref> .</s><s xml:id="_rPM2wXU">Contributions from speech scientists, neuroscientists, and clinical researchers have deepened our understanding of human speech production mechanisms and their neural underpinnings, and particularly how neurodegeneration manifests as characteristic patterns of speech decline across clinical conditions <ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b44">45</ref> .</s></p><p xml:id="_GgCgEVd"><s xml:id="_Ak6UQxP">A co-design of a new explainable analytics pipeline can intentionally integrate scientific insights from speech science and clinical research into existing supervised models.</s><s xml:id="_kpYZ3rT">We hypothesize that this will reduce timelines to translation, therefore providing an opportunity to grow clinical data scale through in-clinic use.</s><s xml:id="_KevcUDj">As data size grows, data-driven methods with greater analytic flexibility can be used to discover new relations between speech and different clinical conditions and to develop more nuanced analytical models that can be confidently deployed for high-stakes clinical applications.</s></p><p xml:id="_ESD9DMy"><s xml:id="_cqvaxpC">Bridging the gap between speech AI and clinical speech research leads to new opportunities in both fields.</s><s xml:id="_vG56ZRf">There is a clear benefit to the development of more sensitive tools for the assessment of speech for the clinical speech community.</s><s xml:id="_gHtb7qX">Existing instruments for assessment of speech exhibit variable within-rater and between-rater variability <ref type="bibr" target="#b45">46</ref> .</s><s xml:id="_WxtkZEU">Developing objective proxies for these clinically-relevant constructs has the potential for increased sensitivity and reduced variability.</s><s xml:id="_nbPK7EE">More sensitive objective measures can also catalyze scientific discovery, enabling the identification of yet-to-be-discovered speech patterns across different clinical conditions.</s><s xml:id="_XkAjFvm">Conversely, effectively connecting speech AI research with clinical research enables AI developers to prioritize challenges directly aligned with clinical needs and streamline model building by leveraging domain-specific knowledge to mitigate the need for large datasets.</s><s xml:id="_hb8ztmP">To date, model developers have often overlooked feasibility constraints imposed by the inherent complexity of the relationship between speech production and the condition of interest.</s><s xml:id="_9ykyWcT">For example, recent efforts in clinical speech AI have focused on the cross-sectional classification of depression from short speech samples <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b25">26</ref> .</s><s xml:id="_edaJ28F">Given the well-documented variability in speech production <ref type="bibr" target="#b46">47</ref> , the limitations of existing instruments for detecting depression <ref type="bibr" target="#b39">40</ref> , and the heterogeneity in the manifestation of depression symptoms <ref type="bibr" target="#b47">48</ref> , it is unlikely that stand-alone speech-based models will yield high-accuracy diagnostic models.</s><s xml:id="_rWS8Q5m">Other studies have proposed using speech to predict conditions like coronary artery disease <ref type="bibr" target="#b48">49</ref> or diabetes <ref type="bibr" target="#b49">50</ref> .</s><s xml:id="_GRfVY5G">However, to the best of our knowledge, there is no substantial literature supporting the hypothesis that speech changes are specific enough to these conditions to serve as stand-alone indicators.</s><s xml:id="_rbxvyGJ">In working with small data sets, understanding the approximate limits of prediction is critical for resource allocation and avoiding unwarranted conclusions that could lead to premature model deployment.</s></p><p xml:id="_aQ9XNEQ"><s xml:id="_FcsrpWz">This perspective article advocates for a stronger link between the speech AI community and clinical speech community for the development of scientifically-grounded explainable models in clinical speech analytics.</s><s xml:id="_R83xF7K">We begin by presenting a new framework for organizing clinical conditions based on their impact on the speech production mechanism (see Fig. <ref type="figure">1</ref>).</s><s xml:id="_3Ee5H5K">We believe such a framework is important to facilitate a shared understanding of the impact of clinical conditions on speech and stimulate interdisciplinary thought and discussion.</s><s xml:id="_QjAXXEW">It is useful in categorizing health conditions by the complexity and uncertainty they present for speech-based clinical AI models and provides a mental model for considering the inherent limitations of speech-based classification across different conditions.</s><s xml:id="_CjkB6Yx">It orients researchers to consider the challenges posed by limited clinical datasets during model development, and helps prevent frequent methodological errors.</s><s xml:id="_32vhS2X">This has the potential to expedite progress and further foster collaboration between the speech AI community and the clinical speech community.</s><s xml:id="_dQJactE">We then explore various contexts of use for speech analytics beyond cross-sectional classification, highlighting their clinical value and the value they provide to the clinical speech research community (see Fig. <ref type="figure" target="#fig_0">2</ref>).</s><s xml:id="_TX9bmWH">The discussion further examines how the selected context of use influences model development and validation, advocating for the use of lowerdimensional, individually-validated and explainable measures with potential to reduce sample size requirements (see Fig. <ref type="figure" target="#fig_1">3</ref>).</s><s xml:id="_ceu7M6u">The paper concludes with a discussion on ethical, privacy, and security considerations, emphasizing the importance of rigorous validation frameworks and responsible deployment (see Fig. <ref type="figure" target="#fig_2">4</ref>).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_h389wAf">The clinically-relevant information in speech</head><p xml:id="_fUhqqfK"><s xml:id="_jKqCNrA">The production of spoken language is a complex, multi-stage process that involves precise integration of language, memory, cognition, and sensorimotor functions.</s><s xml:id="_taRgZjz">Here we use the term 'speech production' to refer broadly to the culmination of these spoken language processes.</s><s xml:id="_GFCrJVg">There are several extant speech production models, each developed to accomplish different goals (see, for example <ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref> ).</s><s xml:id="_qgE9tKd">Common to these models is that speech begins with a person conceptualizing an idea to be communicated, formulating the language that will convey that idea, specifying the sensorimotor patterns that will actualize the language, and then speaking <ref type="bibr" target="#b55">56</ref> :</s></p><p xml:id="_bUCHNRw"><s xml:id="_8wa9XdX">• Conceptualization: the speaker forms an abstract idea that they want to verbalize (Abstract idea formulation) and the intention to share through speech (Intent to speak).</s><s xml:id="_gY7S2FF">• Formulation: the speaker selects the words that best convey their idea and sequences them in an order allowed by the language (Linguistic formulation).</s><s xml:id="_qmMpDXv">Then they plan the sequence of phonemes and the prosodic pattern of the speech to be produced (Morphological encoding).</s><s xml:id="_W7pF2b2">Next, they program a sequence of neuromuscular commands to move speech structures (Phonetic encoding).</s><s xml:id="_Mhj4W8q">• Articulation: the speaker produces words via synergistic movement of the speech production system.</s><s xml:id="_RVwCHdC">Respiratory muscles produce a column of air that drives the vocal folds (Phonation) to produce sound.</s><s xml:id="_mxFvAhs">This sound is shaped by the Articulator movements to produce speech.</s><s xml:id="_gBNW7eq">Two feedback loops (Acoustic feedback and Proprioceptive feedback) refine the neuromuscular commands produced during the Phonetic encoding stage over time.</s></p><p xml:id="_krMhdNH"><s xml:id="_RuqqF9w">Figure <ref type="figure">1</ref> introduces a hierarchy, or ordering, of health conditions based on how direct their impact is on the speech production mechanism.</s><s xml:id="_eJBhceB">This hierarchy, motivated by initial work on speech and stress <ref type="bibr" target="#b56">57</ref> , roughly aligns with the three stages of speech production and has direct consequences for building robust clinical speech models based on supervised learning.</s></p><p xml:id="_sSeFR2Y"><s xml:id="_Rf7MtdB">This hierarchy compels researchers to ask and answer three critical questions prior to engaging in AI model development for a particular health condition.</s><s xml:id="_vEKwPR9">First, how directly and specifically does the health condition impact speech and/or language?</s><s xml:id="_DBEpzSw">In general, the further upstream the impact of a health condition on speech, the more indeterminate and nuanced the manifestations become, making it challenging to build supervised classification models on diagnostic labels.</s><s xml:id="_zhKhU8t">As we move from lower to higher-order health conditions, there are more mediating variables between the health condition and the observed speech changes, making the relationship between the two more variable and complex.</s></p><p xml:id="_XxHCEX4"><s xml:id="_ncTBGQp">The second question the model compels researchers to ask and answer is what are the sensitivity and specificity of ground truth labels for the health condition?</s><s xml:id="_AJVJdPe">In general (but with notable exceptions), the objective accuracy of ground truth labels for the presence or absence of a health condition generally becomes less certain from lower to higherorder conditions, adding noise and uncertainty to any supervised classification models built upon the labels.</s><s xml:id="_8AxVDKq">High specificity of ground truth labels is critical for the development of models that distinguish between health conditions with overlapping speech and language symptoms.</s><s xml:id="_HJVBm87">The answers to these two questions provide a critical context for predicting the utility of an eventual model prior to model building.</s></p><p xml:id="_aHyHxaa"><s xml:id="_JdaMkWp">Finally, the hierarchy asks model developers to consider the relevant clinical speech symptoms to be considered in the model.</s><s xml:id="_ZvbwXCt">In Table <ref type="table" target="#tab_0">1</ref>, we provide a more complete definition of each level in the hierarchy, a list of example conditions associated with the hierarchy, and primary speech symptoms associated with the condition.</s><s xml:id="_WAPWU2s">The list is not exhaustive and does not consider second and third-order impacts on speech.</s><s xml:id="_n6TmMmc">For example, Huntington's disease (HD) has a first-order impact on speech causing hyperkinetic dysarthria (e.g.</s><s xml:id="_he3Qe9T">see Table <ref type="table" target="#tab_0">1</ref>).</s><s xml:id="_4NcfqrH">But it also has a second-and thirdorder impact to the extent one experiences cognitive issues and personality changes with the disease.</s><s xml:id="_mRc5msu">Nevertheless, the table serves as a starting point for developing theoretically-grounded models.</s><s xml:id="_z8xfC7a">Directly modeling the subset of primary speech symptoms known to be impacted by the condition of interest may help reduce sample size requirements and result in smaller models that are more likely to generalize.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_CFMzcm7">Ordering of health conditions based on speech impact</head><p xml:id="_jQGWZC5"><s xml:id="_wNSHXP5">Zeroth-order conditions have direct, tangible effects on the speech production mechanism (including the structures of respiration, phonation, articulation, and resonance) that manifest in the acoustic signal, impacting the Articulation stage in our model in Fig. <ref type="figure">1</ref>.</s><s xml:id="_VS4xauT">This impact of the physical condition on the acoustic signal can be understood using physical models of the vocal tract and vocal folds <ref type="bibr" target="#b57">58</ref> that allow for precise characterization of the relationship between the health condition and the acoustics.</s><s xml:id="_FmH6mG8">As an example, benign vocal fold masses increase the mass of the epithelial cover of the vocal folds, thereby altering the stiffness ratio between the epithelial cover and the muscular body.</s><s xml:id="_Urupq7E">The impact on vocal fold vibration and the resulting acoustic signal are amenable to modeling.</s><s xml:id="_hN2pub3">These types of conditions are physically verifiable upon laryngoscopy, providing consistent ground truth labeling of the condition; and the direct relationship between the condition, its impact on the physical apparatus, and the voice acoustics is direct and quantifiable (although, note that differential diagnosis of vocal fold mass subtype is more difficult, see refs.</s><s xml:id="_KZyVTfj">59,60).</s><s xml:id="_c9jCAdk">Thus, zeroth-order health conditions directly impact the speech apparatus anatomy and often have verifiable ground-truth labels.</s></p><p xml:id="_ShWmr2B"><s xml:id="_5Jh2aQf">First-order conditions interfere with the transduction of neuromuscular commands into movement of the articulators (e.g.</s><s xml:id="_dZKXHCA">dysarthria secondary to motor disorder).</s><s xml:id="_FnKEBMR">As with zeroth-order conditions, first-order conditions also disturb the physical speech apparatus and the Articulation stage in our model, however the cause is indirect.</s><s xml:id="_hpgyRXs">Injury or damage to the cortical and subcortical neural circuits and nerves impacts sensorimotor control of the speech structures by causing weakness, improper muscle tone and/or mis-scaling and incoordination of speech movements <ref type="bibr" target="#b60">61</ref> .</s><s xml:id="_vCw5zaP">The sensorimotor control of speech movements is mediated through five neural pathways and circuits, each associated with a set of cardinal and overlapping speech symptoms: Upper and lower motor neuron pathways; the direct and indirect basal ganglia circuits; and the cerebellar circuit.</s><s xml:id="_W3kxD8B">Damage to these areas causes distinct changes in speech:</s></p><p xml:id="_QNsn2rQ"><s xml:id="_RGmYuXB">• The lower motor neurons (cranial and spinal nerves, originating in brainstem and spinal cord, respectively) directly innervate speech musculature.</s><s xml:id="_fbrN2Jy">Damage to lower motor neurons results in flaccid paralysis and reduced or absent reflexes in the muscles innervated by the damaged nerves, and a flaccid dysarthria when cranial nerves are involved.</s><s xml:id="_8BFJcnc">• The upper motor neurons originate in the motor cortex and are responsible for initiating and inhibiting activation of the lower motor neurons.</s><s xml:id="_yGVCwx8">Damage to upper motor neurons supplying speech musculature results in spastic paralysis and hyperreflexia, and a spastic dysarthria.</s><s xml:id="_AgUSqsq">• The basal ganglia circuit is responsible for facilitating and scaling motor programs and for inhibiting involuntary movements.</s><s xml:id="_Svk9xh4">Damage to the direct basal ganglia circuit causes too little movement (hypokinesia, as in Parkinson's disease), resulting in a hypokinetic dysarthria; while damage to the indirect basal ganglia circuit causes too much movement (hyperkinesia, as in Huntington's disease), resulting in a hyperkinetic dysarthria.</s><s xml:id="_dsU42sz">• The cerebellar circuit is responsible for fine-tuning movements during execution.</s><s xml:id="_MBxww3a">Damage to the cerebellar circuits result in incoordination, resulting in an ataxic dysarthria.</s></p><p xml:id="_aTvCwcC"><s xml:id="_2v9yhwb">Speech symptoms are characteristic when damage occurs to any of these (or multiple) neural pathways, although there is symptom overlap and symptoms evolve in presence and severity as the disease progresses <ref type="bibr" target="#b60">61</ref> .</s><s xml:id="_geg5ut2">The diagnostic accuracy and test-retest reliability (within and between raters) of dysarthria speech labels from the speech signal alone (i.e., without knowledge of the underlying health condition) is known to be modest, except for expert speech-language pathologists with large and varied neurology caseloads <ref type="bibr" target="#b61">62</ref> .</s><s xml:id="_D8WyZww">Diagnosis of the corresponding health conditions relies on a physician's clinical assessment and consideration of other confirmatory information beyond speech.</s><s xml:id="_mKdHd3G">Diagnostic accuracy is impacted by the physician's experience and expertise, whether the symptoms presenting in the Fig. <ref type="figure">1</ref> | Ordering of health conditions based on their impact on speech.</s><s xml:id="_yuPDfQb">The production of spoken language is a complex, multi-stage process that involves precise integration of language, memory, cognition, and sensorimotor functions.</s></p><p xml:id="_UbBmas7"><s xml:id="_y9NvBCS">The three stages are Conceptualization, Formulation, and Articulation.</s><s xml:id="_77E57tw">This figure introduces a hierarchy, or ordering, of health conditions based on how direct their impact is on the speech production mechanism.</s></p><p xml:id="_XsQUphA"><s xml:id="_BJPXEFP"><ref type="url" target="https://doi.org/10.1038/s41746-024-01199-1">https://doi.org/10.1038/s41746-024-01199-1</ref></s><s xml:id="_t9RFWmW">condition are textbook or unusual, and whether genetic, imaging, or other laboratory tests provide supporting or confirmatory evidence is available.</s><s xml:id="_XqqhcUc">For example, unilateral vocal fold paralysis is a first-order health condition with direct impact on the speech apparatus (impaired vocal fold vibration) and high-ground truth accuracy and specificity (can be visualized by laryngoscopy).</s><s xml:id="_SbWx8Bu">In contrast, Parkinson's disease (PD) has a diffuse impact on the speech apparatus (affecting phonation, articulation, and prosody) which is hard to distinguish from healthy speech or other similar health conditions (e.g., progressive supranuclear palsy) in early disease.</s><s xml:id="_sRqV6RS">The reported groundtruth accuracy of the initial clinical diagnosis ranges from 58% to 80%, calling into question clinical labels in early stage PD <ref type="bibr" target="#b27">28</ref> .</s></p><p xml:id="_rMWwMYb"><s xml:id="_xsSjwmW">Second-order conditions move away from the speech production mechanism's structure and function and into the cognitive (i.e., memory and language) and perceptual processing domains.</s><s xml:id="_nCkcdZn">These conditions impact the Formulation stage of speaking and manifest as problems finding and sequencing the words to convey one's intended message and may include Friedrich Ataxia Ataxic dysarthria: Cerebellar degeneration, slow speech, equal and even stress, irregular breakdown <ref type="bibr" target="#b60">61</ref> .</s></p><p xml:id="_dqW5NZp"><s xml:id="_Axnk2m3">High certainty with genetic testing and symptom presentation <ref type="bibr" target="#b29">30</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mM5VQrk">Primary Progressive Apraxia of speech</head><p xml:id="_XuWdbHT"><s xml:id="_ugDUzN6">Consonant and vowel distortions and substitutions; Perseverative and anticipatory errors; Metathetic syllable errors <ref type="bibr" target="#b60">61</ref> .</s></p><p xml:id="_sjbbH88"><s xml:id="_dfdC95e">80% misdiagnosis on the initial visit, with PAOS diagnosis taking an average of 3.4 years <ref type="bibr" target="#b30">31</ref> .</s></p><p xml:id="_xgaYN7X"><s xml:id="_MsEQBx7">Order 2: Conditions affecting higher-level cognitive or perceptual processes related to speech but not necessarily directly altering the physical speech apparatus.</s><s xml:id="_nEmbNSf">Second-order health conditions impact the Formulation stage of speech production.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_V2HmD49">CVA of left middle cerebral artery</head><p xml:id="_N3waW4C"><s xml:id="_3Nx2p3a">Aphasia, either non-fluent (effortful, halting, consonant imprecision, agrammatical) or fluent (speech flows easily but lacks meaning, neologisms, jargon, auditor comprehension deficits) <ref type="bibr">112</ref> .</s></p><p xml:id="_euhVdv8"><s xml:id="_MArGtY2">Estimates of misdiagnosis of acute CVA range from 5% to 31%</s></p><p xml:id="_W8RK25T"><s xml:id="_aSQbmFn">27 .</s><s xml:id="_pYWCEv2">CVA of right hemisphere syndrome Reduced affect (monotonicity, abnormal prosody); Reduced inference (concrete language, reduced recognition of humor, nuance); Articulatory, prosodic, and rate abnormalities 113 .</s><s xml:id="_7eETpbX">Estimates of misdiagnosis of acute CVA range from 5% to 31% 27 .</s><s xml:id="_DJ6hJAx">Alzheimer's disease Anomia, empty speech, simple, general vocabulary and syntax, circumlocutions, repetitions; Articulatory, prosodic, and rate abnormalities 114 .</s><s xml:id="_nDKuJYh">Estimates of AD misdiagnoses 40%; estimates of misdiagnoses of mild cognitive impairment 30% false positive 32,33 .</s><s xml:id="_KqhCREM">Order 3: Conditions that have their effects at the highest cognitive or emotional levels.</s><s xml:id="_tpMTXSp">The relationship between the condition and speech is more indirect, mediated by emotional, psychological, or high-level cognitive processes.</s><s xml:id="_tDejkJz">Third-order health conditions impact the Conceptualization stage of speech production.</s><s xml:id="_dMg4G3c">Psychological Conditions (Depression, Anxiety) Articulatory, prosodic, and rate abnormalities; Abnormal amount of verbal output 4 .</s><s xml:id="_Mctsdpn">Certainty of condition labels is difficult to ascertain without biological ground truth evidence.</s><s xml:id="_RNXuTtm">Symptom overlap among conditions further reduces the certainty of condition labels 34 .</s><s xml:id="_23SM2R5">Psychiatric Conditions (Bipolar disorder, Schizophrenia, Psychosis) Articulatory, prosodic, and rate abnormalities; Abnormal amount of verbal output; Language reflecting impaired Theory of Mind; Decreased coherence 4 .</s></p><p xml:id="_CJMEnJ7"><s xml:id="_rVkhdc9">Certainty of condition labels is difficult to ascertain without biological ground truth evidence.</s><s xml:id="_K9Heb43">Symptom overlap among conditions further reduces the certainty of condition labels <ref type="bibr" target="#b33">34</ref> .</s></p><p xml:id="_R8dz7Z2"><s xml:id="_ArbZrRj"><ref type="url" target="https://doi.org/10.1038/s41746-024-01199-1">https://doi.org/10.1038/s41746-024-01199-1</ref></s><s xml:id="_cQwgBrQ">deficits in speech comprehension.</s><s xml:id="_dd5xfCj">Alzheimer's disease (AD) is a second-order condition that deserves particular attention because of the burgeoning efforts in the literature to develop robust supervised classification models <ref type="bibr" target="#b62">63</ref> .</s><s xml:id="_3hTCeBE">AD disrupts the Formulation stage of speaking with word-finding problems, and the tendency to use simpler and more general semantic and syntactic structures.</s><s xml:id="_xn8xssu">Natural language processing (NLP) techniques have been used to characterize these patterns and acoustic analysis has identified speech slowing with greater pausing while speaking, presumably because of decreased efficiency of cognitive processing and early sensorimotor changes <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25</ref> .</s></p><p xml:id="_TnrmKsF"><s xml:id="_whECqzy">While the clinical study of speech and language in AD has consistently found evidence of such pattern changes in individuals diagnosed with probable AD, progress toward developing generalizable speech-based supervised learning clinical models for mild cognitive impairment (MCI) and AD has been relatively slow despite optimistic performance results reported in the literature <ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b62">63</ref> .</s><s xml:id="_uNnqhPN">We posit that this can be explained by answers to the first two questions that model in Fig. <ref type="figure">1</ref> compels researchers to consider.</s><s xml:id="_te9ePvF">First, there is a lack of specificity of early speech and language symptoms to MCI and AD, given that the output is mediated by several intermediate stages and the variability associated with speech production.</s><s xml:id="_EDEP5Q5">Mild and nonspecific speech and language symptoms will always pose a challenge for the development of clinical early detection/diagnostic speech tools until sufficient training data can result in the identification of distinct signatures (if they exist).</s><s xml:id="_YyuE7Kd">Furthermore, given the current difficulty in accurately diagnosing MCI and AD, models based on supervised learning may be unwittingly using mislabeled training data and testing samples in their models.</s><s xml:id="_U5b6DT4">At present, AD is a clinical diagnosis, often preceded by a period of another clinical diagnosis of MCI.</s><s xml:id="_KUEz8qT">MCI is extremely difficult to diagnose with certainty, owing to variability in symptoms and their presentation over time, the overlap of speech and language symptoms with other etiologies, and the diagnostic reliance on self-report <ref type="bibr" target="#b32">33</ref> .</s><s xml:id="_XAuRj64">With the current absence of a definitive ground truth label for MCI or early Alzheimer's disease, and the lack of specificity in speech changes, supervised learning models trained on small, questionably labeled data likely will continue to struggle to generalize to new data.</s></p><p xml:id="_gnz9Jse"><s xml:id="_k3qCxSJ">Third-order conditions impact the Conceptualization stage of speech production and include mental health conditions affecting mood and thought.</s><s xml:id="_DWtrE2F">These conditions can manifest in significant deficits and differences in speech and language, and this has been well-characterized in the literature <ref type="bibr" target="#b3">4</ref> .</s><s xml:id="_Zmh8b9S">For example, acoustic analysis can reveal rapid, pressed speech associated with mania, as well as slowed speech without prosodic variation that might accompany depression.</s><s xml:id="_vPGUnTy">Natural language processing can reveal and quantify disjointed and incoherent thought in the context of psychiatric disorders <ref type="bibr" target="#b63">64</ref> .</s><s xml:id="_Th5Wckh">Despite this, the impact of these mood and thought conditions on the speech apparatus and language centers in the brain may be indirect and nonspecific relative to low-order conditions.</s><s xml:id="_f7BYbH2">Mental health conditions frequently cause a mixture or fluctuation of positive symptoms (e.g., hallucinations, mania) and negative symptoms (e.g., despondence, depression), which can present chronically, acutely, or intermittently.</s><s xml:id="_ch2UJcf">The associated speech and language patterns can be attributed to any number of other reasons (fatigue, anxiety, etc.)</s><s xml:id="_gHdCBbz">With regard to ground-truth accuracy and specificity, studies have shown that around half of schizophrenia diagnoses are inaccurate <ref type="bibr" target="#b64">65</ref> .</s><s xml:id="_2mcdGwY">This problem has resulted in a push to identify objective biomarkers to distinguish schizophrenia from anxiety and other mood disorders <ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b66">67</ref> .</s><s xml:id="_5mBCtcm">This complicates the development of models for health condition detection and diagnosis; however, machine-learning models may be developed to objectively measure speech and language symptoms associated with specific symptomatology.</s><s xml:id="_KRgUuhH">For example, distinguishing between negative versus positive disease symptoms may be achievable with careful construction of speech elicitation tasks and normative reference data, given the central role that language plays in the definition of these symptoms <ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b68">69</ref> .</s></p><p xml:id="_YDwA2Gf"><s xml:id="_8N7CzNd">Across all health conditions, extraneous and comorbid factors can exert meaningful influence on speech production.</s><s xml:id="_9vZuqzB">For example, anxiety, depression, and fatigue, perhaps even as a consequence of an underlying illness, are known to impact the speech signal.</s><s xml:id="_rWHQKsT">It would not be straightforward to distinguish their influence from those of primary interest, adding complexity and uncertainty for models based on supervised learning, regardless of the health condition's order.</s><s xml:id="_z57vvg5">However, the increased variability in both data and diagnostic accuracy for many higher-order conditions makes speech-based models trained using supervised learning on small datasets vulnerable to reduced sensitivity and specificity.</s><s xml:id="_ZQXCp4C">This is not merely a matter of augmenting the dimensionality of speech features or enlarging the dataset; it reflects the intrinsic variability in how humans generate speech.</s><s xml:id="_BNhV8xz">Finally, the accuracy and specificity of ground truth labels for health conditions are critical to consider in assessing the feasibility of interpretable model development.</s><s xml:id="_yTBPWn2">Unlike the static link between speech and the health condition, as diagnostic technologies advance and criteria evolve, the accuracy of these labels is expected to improve over time, thereby potentially enabling more robust model development.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ATvm9ex">Defining an appropriate context of use</head><p xml:id="_4GU2wXX"><s xml:id="_WcCAyyT">As mentioned before, most published clinical speech AI development studies are based on supervised learning where developers build AI models to distinguish between two classes or to predict disease severity.</s><s xml:id="_rScXrH6">This approach generally presumes the same context of use for clinical speech analytics across different applications: namely, the cross-sectional detection of a specific condition or a prediction of clinical severity based on a speech sample.</s><s xml:id="_8Wj6rCS">As we established in the foregoing discussion, this approach, when combined with limited training data, is less likely to generalize.</s></p><p xml:id="_2tM8TJv"><s xml:id="_Fp46gC8">Nevertheless, there are a number of use cases, in which speech analytics and AI can provide more immediate value and expedite model translation.</s><s xml:id="_Qw5bBmJ">These are outlined in Fig. <ref type="figure" target="#fig_0">2</ref>, where we explore these applications in greater depth.</s><s xml:id="_745wQSx">Focusing on these use cases will reduce timelines to translation, providing an opportunity to grow clinical data scale through in-clinic collection.</s><s xml:id="_UeqNBrn">With increased data size and diversity, researchers will better characterize currently-unknown fundamental limits of prediction for speechbased classification models for higher-order conditions (e.g.</s><s xml:id="_QGaTxwp">how well can we classify between depressed and non-depressed speech); and can bring to bear more advanced data-driven methods to problems that provide clinical value.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GMVgAdD">Diagnostic assistance</head><p xml:id="_9SMxYPy"><s xml:id="_sNDwpVb">Despite rapid advancements in biomedical diagnostics, the majority of neurodegenerative diseases are diagnosed by the presence of cardinal symptoms on clinical exams.</s><s xml:id="_JT27Wbg">As discussed previously and as shown in Table <ref type="table" target="#tab_0">1</ref>, many health conditions include changes in speech as a core symptom.</s><s xml:id="_GtwMUBB">For example, diagnosis of psychiatric conditions involves analysis of speech and language attributes, such as coherence, fluency, and tangentiality <ref type="bibr" target="#b69">70</ref> .</s><s xml:id="_U6jWHVe">Likewise, many neurodegenerative diseases lead to dysarthria, and a confirmatory speech deficit pattern can be used to support their diagnoses <ref type="bibr" target="#b60">61</ref> .</s><s xml:id="_ef7dtPs">Tools for the assessment of these speech deficit patterns in the clinical setting typically depend on the clinical judgment or on scales reported by patients themselves.</s><s xml:id="_gA9b6zf">There is a large body of evidence indicating that these methods exhibit variable reliability, both between different raters and within the same rater over time <ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b61">62</ref> .</s><s xml:id="_HMNNmdG">Clinical speech analytics has the potential to enhance diagnostic accuracy by providing objective measures of clinical speech characteristics that contribute to diagnosis, such as hypernasality, impaired vocal quality, and articulation issues in dysarthria; or measures of coherence and tangentiality in psychosis.</s><s xml:id="_9PdVwV9">These objective measures can provide utility for manual diagnosis in clinic or can be used as input into multi-modal diagnostic systems based on machine learning.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cMY8rzw">Non-specific risk assessment tools</head><p xml:id="_vT6TAFQ"><s xml:id="_HYarndd">While differential diagnosis based on speech alone is likely not possible for many conditions, progressive and unremitting changes in certain aspects of speech within an individual can be a sign of an underlying illness or disorder <ref type="bibr" target="#b60">61</ref> .</s><s xml:id="_Mpxahus">Clinical speech analytics can be used to develop tools that track changes in speech along specific dimensions known to be vulnerable to degradation in different conditions.</s><s xml:id="_4CxbnDT">This could provide value as an early-warning indicator, particularly as the US health system moves toward home-based care and remote <ref type="url" target="https://doi.org/10.1038/s41746-024-01199-1">https://doi.org/10.1038/s41746-024-01199-1</ref></s><s xml:id="_zEBRyAU">patient monitoring.</s><s xml:id="_gszATjC">Such a tool could be used as a non-specific risk assessment tool triggering additional tests when key speech changes reach some threshold or is supported by changes in other monitored modalities.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_s9RR6W8">Longitudinal tracking post-diagnosis</head><p xml:id="_QsUjY2j"><s xml:id="_MfCQyD6">In many conditions, important symptoms can be tracked via speech postdiagnosis.</s><s xml:id="_7w89r5a">For example, tracking bulbar symptom severity in ALS, as a proxy for general disease progression, can provide insights on when AAC devices should be considered or to inform end-of-life planning <ref type="bibr" target="#b70">71</ref> .</s><s xml:id="_N8WVjyk">In Parkinson's disease, longitudinal tracking of speech symptoms would be beneficial for drug titration <ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b72">73</ref> .</s><s xml:id="_JzhRu9B">In dementia, longitudinal tracking of symptoms measurable via speech (e.g.</s><s xml:id="_czvZWNz">memory, cognitive-linguistic function) can provide valuable information regarding appropriate care and when changes need to be made.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_6yKb2Ah">Speech as a clinically meaningful endpoint</head><p xml:id="_qq3GD9W"><s xml:id="_5PZdGz3">Speech is our principal means of communication and social interaction.</s><s xml:id="_8K4dPxV">Conditions that impair speech can severely hinder a patient's communicative abilities, thereby diminishing their overall quality of life.</s><s xml:id="_rXjzHM7">Current methods for assessing communication outcomes include perceptual evaluations, such as listening and rating, or self-reported questionnaires <ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b68">69</ref> .</s><s xml:id="_ZCugWHK">In contrast to the use case as a solitary diagnostic tool, employing clinical speech analytics to objectively assess communicative abilities is inherently viable across many conditions.</s><s xml:id="_5g798r6">This is due to the direct correlation between the construct (communicative ability) and the input (speech).</s><s xml:id="_SsWUHxp">For instance, in dysarthria, clinical speech analytics may be utilized to estimate intelligibility, the percentage of words understood by listeners, which significantly affects communicative participation <ref type="bibr" target="#b73">74</ref> .</s><s xml:id="_Y5K7TAA">In psychosis, speech analytics can facilitate the creation of objective tools for assessing social competencies; these competencies are closely tied to quality of life indicators <ref type="bibr" target="#b68">69</ref> .</s><s xml:id="_yuNUkF9">Similarly, in dementia, a decline in social interaction can lead to isolation and depression, perhaps hastening cognitive decline <ref type="bibr" target="#b74">75</ref> .</s><s xml:id="_nVNE9FF">A related emerging use case in Alzheimer's disease is providing context for blood-based diagnostics.</s><s xml:id="_a9VsT7U">As new biomarkers with confirmatory evidence of pathophysiology emerge, there will likely be an increase in Alzheimer's diagnoses without co-occurring clinicalbehavioral features.</s><s xml:id="_NU72mse">The group of patients with AD diagnoses, but without symptoms, will require context around this diagnosis.</s><s xml:id="_qWAsA4E">Speech analytics will be important as measures of behavioral change that are related to quality of life.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_PqCR2Ef">Improving clinical trial design</head><p xml:id="_Wpc7nuH"><s xml:id="_JNU8bHt">The Food and Drug Administration (FDA) prioritizes patient-relevant measures as endpoints in clinical trials.</s><s xml:id="_wYRWCku">They have also identified speech and communication metrics as particularly underdeveloped for orphan diseases <ref type="bibr" target="#b75">76</ref> .</s><s xml:id="_7CHXjJg">Objective and clinically-meaningful measures based on speech analytics that are collected more frequently can result in an improved sensitivity for detecting intervention effects.</s><s xml:id="_KPZqAws">Such measures have the potential to decrease the required sample sizes for drug trials, enable more efficient enrollment, or to ascertain efficacy with greater efficiency <ref type="bibr" target="#b76">77</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_ARSbtc9">Facilitating development of digital therapeutics</head><p xml:id="_RMPVdqF"><s xml:id="_Hkx7uSQ">There has been significant recent interest in development of digital therapeutics for various neurological and mental health conditions.</s><s xml:id="_GJWKvdk">Several of these devices target improving the patients' social skills or communication abilities <ref type="bibr" target="#b77">78</ref> .</s><s xml:id="_FDDXBT6">In this evolving space, introducing concrete digital markers of social competence allows for more efficient evaluation of efficacy and precision approaches for customizing therapeutics for the patient.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_b8gYXmw">Development and validation of robust models</head><p xml:id="_7T8Ry8x"><s xml:id="_pxNYVWW">The context of use profoundly influences the development of clinical speech AI models, shaping their design, validation, and implementation strategies.</s><s xml:id="_x4ZDfkr">For example, for contexts of use involving home monitoring, robustness to background noise, variability in recording conditions and usability are essential.</s><s xml:id="_jScDPJj">For longitudinal monitoring, developed tools must be sensitive to subtle changes in speech characteristics relevant to the progression of the condition being monitored.</s><s xml:id="_bK9MnPw">This necessitates longitudinal data collection for development and validation to ensure stability and sensitivity over time.</s><s xml:id="_qzvuRsJ">Screening tools in diverse populations require a training dataset that captures demographic variability to avoid bias.</s><s xml:id="_ydNqB3Q">Solutions based on noisy diagnostic labels may require uncertainty modeling through Bayesian machine learning or ensemble methods that quantify prediction confidence <ref type="bibr" target="#b78">79</ref> .</s><s xml:id="_aPDJZ2q">Concurrently, techniques like label smoothing <ref type="bibr" target="#b79">80</ref> and robust loss functions <ref type="bibr" target="#b80">81</ref> can enhance model resilience under label noise.</s></p><p xml:id="_s7rxf9A"><s xml:id="_4zdGAjs">Each context of use presents a custom development path to address the unique challenges and a parallel validation strategy that spans hardware, analytical validation, and clinical validation -see Fig. <ref type="figure" target="#fig_1">3</ref>.</s><s xml:id="_XXZXMNe">The current approach focused on data-driven supervised learning on diagnostic labels limits the development and understanding of new models and makes model validation challenging.</s><s xml:id="_SUHSPYZ">While there are many validation metrics for evaluating AI model performance, the prevalent metrics in published speechbased models primarily focus on estimating "model accuracy" (e.g.</s><s xml:id="_8hqJHG3">what percent of the time does the model correctly classify between Healthy and <ref type="url" target="https://doi.org/10.1038/s41746-024-01199-1">https://doi.org/10.1038/s41746-024-01199-1</ref></s></p><p xml:id="_f393dbQ"><s xml:id="_p3kTjmD">Dementia labels based on speech) using a number of methods (e.g.</s><s xml:id="_rGMJrsK">crossvalidation, held-out test accuracy).</s><s xml:id="_8rR2tf2">However, accurately estimating the model accuracy of high-dimensional supervised learning models is challenging, and current methods are prone to overoptimism <ref type="bibr" target="#b34">35</ref> .</s><s xml:id="_ptsqCxb">In addition, many supervised machine learning models are sensitive to input perturbations, which is a significant concern for speech features known for their day-to-day variability <ref type="bibr" target="#b81">82</ref> .</s><s xml:id="_wnhE7J8">Consequently, model performance diminishes with any temporal variation in the data.</s></p><p xml:id="_g986wdZ"><s xml:id="_xQfbssF">A starting point for clinical model validation is the Verification/Analytical Validation/Clinical Validation (V3) framework, a framework for validating digital biometric monitoring technologies.</s><s xml:id="_pdY56xv">The original version of the framework proposes a structured approach with three evaluation levels: Verification of hardware, Analytical Validation, and Clinical Validation <ref type="bibr" target="#b82">83</ref> .</s><s xml:id="_Fd7hTnt">This framework has roots in principles of Verification and Validation for software quality product management and deployment <ref type="bibr" target="#b83">84</ref> .</s><s xml:id="_sDqcRab">While these existing validation systems are designed to confirm that the end system accurately measures what it purports to measure, the V3 framework adds the additional step of confirming that the clinical tools are meaningful to a defined clinical population.</s><s xml:id="_dzjecRY">To that end, Verification ascertains the sensor data's fidelity within its intended environment.</s><s xml:id="_ucmuET4">Analytical validation examines the accuracy of algorithms processing sensor data to yield behavioral or physiological metrics, and clinical validation evaluates clinical model outputs with clinic ground truths or established measures known to be meaningful to patients.</s><s xml:id="_hbwZKBY">This includes existing clinical scales like the PHQ-9 (depression) or the UPDRS (Parkinson's disease).</s><s xml:id="_8cGqtEE">In Fig. <ref type="figure" target="#fig_1">3</ref> we provide a high-level overview of the end-to-end development and validation process for clinical speech AI.</s><s xml:id="_VFJYnHe">It is important to note that the V3 is a conceptual framework that must be specifically instantiated for the validation of different clinical speech applications.</s><s xml:id="_mRsS4UZ">While it can help guide the development of a validation plan, it does not provide one out of the box.</s><s xml:id="_V8RgH3P">Furthermore, this level of validation is only a starting point as the FDA suggests constant model monitoring postdeployment to ensure continued generalization <ref type="bibr" target="#b84">85</ref> .</s></p><p xml:id="_uD5b6u3"><s xml:id="_usAVNWf">Supervised learning approaches based on uninterpretable input features and clinical diagnostic labels make adoption of the complete V3 framework challenging.</s><s xml:id="_Tz985HY">Analytical validation is especially challenging as it's difficult to ensure that learned speech representations are measuring or detecting physiological behaviors of interest.</s><s xml:id="_dzbesNW">For example, in Parkinson's disease, both the speaking rate and the rate of opening and closing of vocal folds is impacted.</s><s xml:id="_Wtmsng2">Uninterpretable features have unknown relationships with these behavioral and physiological parameters.</s><s xml:id="_jZa5BB6">As an alternative, model developers can use representations that are analytically validated relative to these constructs.</s><s xml:id="_npNrMpU">This would lead to more interpretable clinical models.</s><s xml:id="_TW5a5cK">Validation should be approached end-to-end during the development process, with different stages (and purposes of analysis) employing different validation methods.</s><s xml:id="_EzXvbPX">Small-scale pilot tests may focus on parts of this framework.</s><s xml:id="_FkJ2BD3">However, for work with deployment as a goal, ensuring generalizability and clinical utility requires validating the hardware on which the speech was collected, ensuring that intermediate representations are valid indicators of behavioral and physiological measures (e.g speaking rate, articulatory precision, language coherence), and clinical models developed using these speech measures are associated with existing clinical ground truths or scales that are meaningful to patients <ref type="bibr" target="#b85">86</ref> .</s></p><p xml:id="_SUGQhPm"><s xml:id="_UUa5K8n">Interpretable, clinically-important measures based on speech are currently missing from the literature.</s><s xml:id="_mqbpfRz">Clinically-relevant feature discovery and model performance evaluation in speech analytics are challenged by the high-dimensionality of speech, complex patterns, and limited datasets.</s><s xml:id="_KcKz75P">Table <ref type="table" target="#tab_0">1</ref> highlights several speech constructs that have been studied relative to various conditions; however, most of these constructs do not have standardized operational definitions in the clinical speech analytics literature.</s><s xml:id="_fBdzqGu">Instead, model developers rely on high-dimensional representations that have been developed for other purposes.</s><s xml:id="_aZ7s46u">For example, adopted from the ASR literature, many clinical models use representations based on melfrequency cepstral coefficients or mel-spectra <ref type="bibr" target="#b17">18</ref> ; or representations learned by pre-trained foundation models <ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20</ref> .</s><s xml:id="_APAt5Wt">However, these features are not interpretable, making analytical and clinical validation challenging.</s></p><p xml:id="_eq2w92m"><s xml:id="_yrFHVRb">Development of a clinically-tailored speech representation could significantly refine the development process, favoring smaller, individually validated, and clinically-grounded features that allow scientists to make contact with the existing literature and mitigate model overfitting and variability.</s><s xml:id="_WPepHUD">This field would benefit from a concerted and synergistic effort in the speech AI community and the speech science community to operationalize and validate a measurement model for the intermediate constructs like those listed in Table 1 <ref type="bibr" target="#b86">87</ref> .</s><s xml:id="_xyRP5GZ">For example, in our previous work, we made progress in this direction by developing measurement models for the assessment of hypernasality and consontant-vowel transitions and used it to evaluate cleft lip and palate and dysarthria <ref type="bibr" target="#b87">88,</ref><ref type="bibr" target="#b88">89</ref> ; several measures of volition</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_2mnBB2A">Clinical Validation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_mqz59vD">Interpretable representation learning</head><p xml:id="_PY34U3t"><s xml:id="_TfMvf8C">Clinical model development</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_kzT5Ty4">Speech data acquisition Verification</head><p xml:id="_PXY6aAx"><s xml:id="_geFV38h">What is the fidelity of the recorded speech?</s><s xml:id="_wbYWDJH">Is this fidelity level sufficient for downstream processing?</s></p><p xml:id="_ub9JMns"><s xml:id="_GXNv9C9">What is the accuracy of clinical model outputs relative to clinic ground truths or established measures?</s><s xml:id="_h2AYAhH">Are these reference measures meaningful to patients?</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_W9u4YCx">Analytical Validation</head><p xml:id="_vjKWwXd"><s xml:id="_t5xKDcH">What is the accuracy of speech analytics algorithms that yield behavioral or physiological measures (e.g.</s><s xml:id="_kpUhTXU">speaking rate, opening and closing of vocal folds)?</s><s xml:id="_X7cftPn">Are these measures repeatable?</s></p><p xml:id="_A683Qyp"><s xml:id="_3gTJESV">How directly and specifically does the health condition impact speech?</s><s xml:id="_BGPwVE2">What is the sensitivity/specificity of the ground truth labels?</s><s xml:id="_DrrMGnq">Is the context of use feasible?</s><s xml:id="_4qUbCxc">If so, what training data is required to achieve it?</s><s xml:id="_3YhS68F">Is it feasible to sample from relevant strata?</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_db6TAXJ">Context of use and feasibility</head><p xml:id="_rG8ZSdz"><s xml:id="_dhGN5Ch"><ref type="url" target="https://doi.org/10.1038/s41746-024-01199-1">https://doi.org/10.1038/s41746-024-01199-1</ref></s></p><p xml:id="_9Ewq8UW"><s xml:id="_yuEA7B2">and coherence for schizophrenia <ref type="bibr" target="#b68">69</ref> ; and measures of semantic relevance for dementia <ref type="bibr" target="#b9">10</ref> .</s><s xml:id="_wnRQCT9">Individually-validated interpretable measures allow for easier alignment to different contexts of use, integration within larger multi-modal systems, and establish a more direct link to the existing clinical literature.</s><s xml:id="_szmccUN">Furthermore, they can be used as a way of explaining the operation of larger, more complex models via bottleneck constraints <ref type="bibr" target="#b89">90</ref> or they can be combined with new methods in causal machine learning for development of explainable models <ref type="bibr" target="#b90">91</ref> .</s><s xml:id="_b6nDJPU">Finally, clinically-interpretable representations can also play a pivotal role in integrating the patient's perspective into the design of algorithms.</s><s xml:id="_XeKpkGA">The idea is that by aligning closely with the lived experiences and symptoms important to patients, these representations ensure that algorithmic outcomes resonate with the quality of life impact of health conditions.</s><s xml:id="_kBecuzP">The hypothesis is that this patient-centric approach could have the added benefit of reinforcing patient trust and engagement in digital health.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_DP7wJf9">Ethical, privacy, and security considerations</head><p xml:id="_cRsHQW5"><s xml:id="_SrhrFgm">The deployment and regulation of clinical speech models in healthcare present multiple challenges and risks.</s><s xml:id="_Cx8qBmg">Prematurely launched models (without robust validation) risk delivering clinically inaccurate results and potentially causing patient harm, while biases in model training can lead to skewed performance across diverse populations.</s><s xml:id="_EVy7JcQ">Moreover, the use of speech data for health analytics raises significant privacy and security concerns.</s><s xml:id="_6P2826E">We outline these considerations in Fig. <ref type="figure" target="#fig_2">4</ref> and expand on them below.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_yPmbEwk">Premature deployment inaccurate models</head><p xml:id="_JTNnvBk"><s xml:id="_4a828dj">A primary risk of prematurely-deployed models is that they will provide clinically inaccurate output.</s><s xml:id="_qqMxBwp">As discussed in previous work <ref type="bibr" target="#b34">35</ref> , current strategies to validate AI models are insufficient and produce overoptimistic estimates of accuracy.</s><s xml:id="_t5UQKPv">Several studies have highlighted this as a more general problem in AI-based science <ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b92">93</ref> .</s><s xml:id="_AuCHvVa">However, reported accuracy metrics carry much weight when presented to the public and can lead to premature deployment.</s><s xml:id="_R4xM9fA">There is considerable risk that these models will fail if deployed and potentially harm patients <ref type="bibr" target="#b93">94</ref> .</s><s xml:id="_Zkr8pZ4">For example, consider the Cigna Stress-Waves Test model, deployed after only internal evaluation and no public efficacy data.</s><s xml:id="_PQVEQhM">This model analyzes a user's voices to predict their stress level and is publicly available on the Cigna Website.</s><s xml:id="_4JmMJCq">Independent testing of the model reveals that it has poor test-retest reliability (measured via intraclass correlation) and poor agreement with existing instruments for measuring stress <ref type="bibr" target="#b36">37</ref> .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_4fcKfm6">Biased models</head><p xml:id="_MJv5kUZ"><s xml:id="_bJNEKJ8">An additional risk of clinical speech-based models stems from the homogeneity of the data often used to train these models.</s><s xml:id="_RKuCTNX">Biological and socio-cultural differences contribute significantly to the variation in both the speech signal and the clinical conditions (impacting aspects from risk factors to treatment efficacy).</s><s xml:id="_xsvt8pc">Careful consideration of these differences in model building necessitates robust experiment design and representative stratification of data.</s><s xml:id="_JqrnsZq">However, a recent study demonstrates that published clinical AI models are heavily biased demographically, with 71% of the training data coming from only three states: California, Massachusetts, and New York, with 34 of the states not represented at all <ref type="bibr" target="#b94">95</ref> .</s><s xml:id="_WdsdmEd">Similarly, analysis of clinical speech datasets indicates a significant skew towards the English language, overlooking the linguistic diversity of global populations.</s><s xml:id="_7RCxTkH">To accurately capture health-related speech variations, it's essential to broaden data collection efforts to include a more representative range of the world's native languages as health-related changes in speech can be native language-specific <ref type="bibr" target="#b95">96</ref> .</s><s xml:id="_JGAE7YX">It becomes challenging to determine how models trained on unrepresentative data would perform when deployed for demographic groups for which they were not trained.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_sReBeKX">Privacy and security considerations</head><p xml:id="_bAdMDAY"><s xml:id="_XuDVxqK">Speech and language data is widely available and, as we continue to interact with our mobile devices, we generate an ever-growing personal footprint of our health status.</s><s xml:id="_qrDdU5k">Previous studies have shown that this data (speeches, social media posts, interviews) can be analyzed for health analytics <ref type="bibr" target="#b96">[97]</ref><ref type="bibr" target="#b97">[98]</ref><ref type="bibr" target="#b98">[99]</ref> .</s><s xml:id="_vf4UYPR">There is a risk that similar data on an even larger scale and over longer periods of time can be accessed by technology companies to make claims about the health or emotional state of their users without their permission or by national or international adversaries to advance a potentially false narrative on the health of key figures.</s><s xml:id="_CXRCjP4">The risks to the privacy of this type of analysis, if used outside of academic research, is considerable, with national and international political ramifications.</s><s xml:id="_dnefF2Z">Internally, political adversaries can <ref type="url" target="https://doi.org/10.1038/s41746-024-01199-1">https://doi.org/10.1038/s41746-024-01199-1</ref></s></p><p xml:id="_5m8QBp3"><s xml:id="_pgvf2Mn">advance a potentially false narrative on the health of candidates.</s><s xml:id="_qfzspms">Internationally, geopolitical adversaries could explore this as an additional dimension of influence in elections.</s></p><p xml:id="_FTA24Z4"><s xml:id="_ez9dm5T">There is no silver bullet to reduce these risks, however, there are several steps that can be taken as mitigation strategies.</s><s xml:id="_Zu2Qfxk">With the public availability of speech technology, building AI models has become commoditized; however, the bottleneck remains prospective validation.</s><s xml:id="_97Wd34Y">Thorough validation of the model based on well-accepted frames such as the V3 framework is crucial prior to deployment <ref type="bibr" target="#b82">83</ref> .</s><s xml:id="_cnJZwa4">This validation must extend beyond initial data sets and include diverse demographic groups to mitigate biases.</s><s xml:id="_Qw5d5Sd">Moreover, developers should engage in continuous post-deployment monitoring to identify and rectify any deviations in model performance or emergent biases.</s><s xml:id="_rJQsYry">Transparency in methodology and results, coupled with responsible communication to the public, can reduce the risks of misperceived model accuracy.</s></p><p xml:id="_bUxcdfA"><s xml:id="_Ryrr6tR">On the privacy front, there are emerging technical solutions to parts of this problem based on differential privacy and federated learning 100-102 ; however, a complete socio-technical solution will require stringent data protection regulations and ethical guidelines to safeguard personal health information.</s><s xml:id="_sYm7JEv">First, it is wise to reconsider IRB review protocols in light of new technologies and publicly available data; in industry, proactive collaboration with regulatory bodies (e.g.</s><s xml:id="_jFmbWW8">FDA) can help establish clear guidelines.</s><s xml:id="_wuEsPRX">This is clear for companies focused on clinical solutions, however, the regulation of AI-based devices for technology companies, particularly those focused on wellness, is less well-defined.</s><s xml:id="_KE5HvfD">Recent guidance from the Federal Trade Commission (FTC) advising companies to only make evidencebacked claims about AI-driven products is a step in the right direction 103 .</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 |</head><label>2</label><figDesc><div><p xml:id="_ErJxMaH"><s xml:id="_UBzxKj4">Fig. 2 | Contexts of use for clinical speech AI.</s><s xml:id="_Rv2hKDD">A listing of different contexts of use for the development and validation of clinical tools based on speech AI.</s></p></div></figDesc><graphic coords="6,213.28,47.79,347.98,213.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 |</head><label>3</label><figDesc><div><p xml:id="_2FrJZcr"><s xml:id="_eH6Nmzd">Fig. 3 | Development and validation of clinical speech AI.</s><s xml:id="_aTPWUg8">The development of clinical speech AI models begins with a context of use.</s><s xml:id="_uvsQjvV">The context of use informs downstream development and validation of resulting models.</s><s xml:id="_chvu6tN">The Verification, Analytical Validation, and Clinical Validation (V3) framework has been proposed as a conceptual framework for the initial validation of biometric monitoring technologies.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 |</head><label>4</label><figDesc><div><p xml:id="_qe4ERyp"><s xml:id="_6S6TN2K">Fig. 4 | Risks and mitigation strategies for clinical speech AI.</s><s xml:id="_Px3Fs5N">An overview of key risks and corresponding mitigation strategies for the development of clinical speech AI models.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="3,90.85,49.70,419.32,144.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 |</head><label>1</label><figDesc><div><p><s xml:id="_fwgMQ6a">Clinical conditions and their ordering based on the model from Fig.1</s></p></div></figDesc><table><row><cell>Description</cell><cell>Conditions</cell><cell>Impact on Speech</cell><cell>Diagnostic Certainty</cell></row><row><cell>Order 0: Direct physical (structural or functional)</cell><cell>Cleft palate +/-lip or other</cell><cell>Hypernasality; Articulatory distortions and</cell><cell>100% certainty; physically verifiable,</cell></row><row><cell>effects on the speech production process. The</cell><cell>craniofacial anomaly</cell><cell>substitutions 104 .</cell><cell>functionally verifiable (physical examination,</cell></row><row><cell>condition or its symptoms have an immediate</cell><cell></cell><cell></cell><cell>imaging, ultrasound); diagnostic accuracy of</cell></row><row><cell>and evident impact on speech production</cell><cell></cell><cell></cell><cell>fetal cleft lip +/-palate is upwards of 90%</cell></row><row><cell>mechanics.</cell><cell></cell><cell></cell><cell>accuracy 105 .</cell></row><row><cell>Zeroth-order health conditions directly impact the Articulation stage of speech production.</cell><cell>Oral/laryngeal cancers, injury, resection</cell><cell>Articulatory distortions and substitutions; Phonatory abnormalities 106,107 .</cell><cell>High certainty; physically verifiable (physical examination, imaging).</cell></row><row><cell></cell><cell>Vocal fold cover pathology</cell><cell>Phonatory abnormalities 108 .</cell><cell>High certainty; physically verifiable</cell></row><row><cell></cell><cell>(polyp, nodule, contact</cell><cell></cell><cell>(laryngoscopy).</cell></row><row><cell></cell><cell>ulcers, edema)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Aspiration</cell><cell>Phonatory abnormalities 109 .</cell><cell>High certainty when aspiration occurs during</cell></row><row><cell></cell><cell></cell><cell></cell><cell>modified barium swallow videofluoroscopy.</cell></row><row><cell></cell><cell>Structural/ functional lung</cell><cell>Respiratory insufficiency 110 .</cell><cell>High certainty; functionally verifiable</cell></row><row><cell></cell><cell>conditions (e.g. COPD)</cell><cell></cell><cell>(respiratory function tests).</cell></row><row><cell>Order 1: Physiological changes that alter the</cell><cell>Recurrent laryngeal nerve</cell><cell>Flaccid dysarthria: breathiness from unilateral</cell><cell>High certainty; physically and functionally</cell></row><row><cell>transduction of neuromuscular commands into</cell><cell>(lower motor neuron) damage</cell><cell>(CN X) vocal fold paralysis, diplophonia 61 .</cell><cell>verifiable (laryngoscopy).</cell></row><row><cell>speech movements. The condition causes</cell><cell>during cardiac surgery</cell><cell></cell><cell></cell></row><row><cell>changes in the speech apparatus or the neural pathways leading to it. conditions impact the Articulation stage of Like zeroth-order health conditions, first-order</cell><cell>Bilateral internal capsule intracranial atherosclerosis CVAs secondary to</cell><cell>Spastic dysarthria: strained-strangled vocal quality, slow speech, articulatory imprecision 61 .</cell><cell>Estimates of misdiagnosis of acute CVA range from 5% to 31% 27 .</cell></row><row><cell>speech production, but indirectly.</cell><cell>Parkinson's disease</cell><cell>Hypokinetic dysarthria: (PD, breathy voice,</cell><cell>Estimates of misdiagnosis of early PD range</cell></row><row><cell></cell><cell></cell><cell>imprecise articulation, monotone, reduced</cell><cell>from 25%-50%. Long-term presentation of</cell></row><row><cell></cell><cell></cell><cell>loudness, short rushes of speech 61 .</cell><cell>chronic, hallmark symptoms plus a positive</cell></row><row><cell></cell><cell></cell><cell></cell><cell>DAT reduces misdiagnosis to 10-25% 28 .</cell></row><row><cell></cell><cell>Amyotrophic lateral sclerosis</cell><cell>Mixed flaccid/spastic dysarthria: slow,</cell><cell>40% of ALS patients initially receive a false</cell></row><row><cell></cell><cell></cell><cell>imprecise speech, hypernasality, vocal flutter,</cell><cell>negative diagnosis; 10-15% initially receive a</cell></row><row><cell></cell><cell></cell><cell>strained-strangled vocal quality 61 .</cell><cell>false positive diagnosis. Diagnosis is based on</cell></row><row><cell></cell><cell></cell><cell></cell><cell>clinical examination (El Escorial Criteria)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>and EMG 29 .</cell></row><row><cell></cell><cell>Huntington's disease</cell><cell>Hyperkinetic dysarthria: Abnormal rate and</cell><cell>15% misdiagnosis rate 111 .</cell></row><row><cell></cell><cell></cell><cell>prosody, abnormal articulatory breakdown 61 .</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_r5RNBF9"><s xml:id="_DZuetyX">npj Digital Medicine | (2024) 7:208</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_fnCgwHd"><s xml:id="_x88sG9q">© The Author(s) 2024 https://doi.org/10.1038/s41746-024-01199-1</s></p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head xml:id="_UKzFRNS">Acknowledgements</head><p xml:id="_mh7vEWs"><s xml:id="_BdAEvuX">This work is funded in part by the <rs type="funder">John and Tami Marick Family Foundation</rs>, <rs type="funder">NIH NIA</rs> grant <rs type="grantNumber">1R01AG082052-01</rs>, <rs type="funder">NIH</rs> <rs type="funder">NIDCD</rs> grants <rs type="grantNumber">R01DC006859-11</rs> and <rs type="grantNumber">R21DC019475</rs>, and <rs type="funder">NIH NIDCR</rs> grant <rs type="grantNumber">R21DE026252-01A</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_GsnreMw">
					<idno type="grant-number">1R01AG082052-01</idno>
				</org>
				<org type="funding" xml:id="_TeGDuEu">
					<idno type="grant-number">R01DC006859-11</idno>
				</org>
				<org type="funding" xml:id="_JjXU4Yt">
					<idno type="grant-number">R21DC019475</idno>
				</org>
				<org type="funding" xml:id="_CChh99d">
					<idno type="grant-number">R21DE026252-01A</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_BgsAhTH">Data availability</head><p xml:id="_x4Ddc23"><s xml:id="_hqk9rNC">There is no data associated with this manuscript as it is a perspectives article centered around a theoretical framework.</s></p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hRk4yqE">Author contributions</head><p xml:id="_wHaCBsP"><s xml:id="_ubnMvhR">V.B. and J.M.L. both made substantial contributions to the conception or design of this work and they helped draft and revise the manuscript.</s><s xml:id="_WMzA2Xz">Berisha is the corresponding author: visar@asu.edu.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_QKHq8Hj">Competing interests</head><p xml:id="_R95WHPQ"><s xml:id="_GC6q9tb">The Authors declare no Competing Non-Financial Interests but the following Competing Financial Interests: Berisha and Liss are founders of and previously held equity in Aural Analytics, a clinical speech analytics company.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_dzawGG3">Additional information</head><p xml:id="_qzSv8Gm"><s xml:id="_UVyUWug">Correspondence and requests for materials should be addressed to Visar Berisha.</s></p><p xml:id="_SKVGjjm"><s xml:id="_6H3GPMy">Reprints and permissions information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/reprints</ref></s><s xml:id="_gub2n4r">Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</s></p><p xml:id="_dPsmWDB"><s xml:id="_FUMkMSU">Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made.</s><s xml:id="_4gpFduQ">The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material.</s><s xml:id="_9Hgzcnw">If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</s><s xml:id="_ayPxyq6">To view a copy of this licence, visit <ref type="url" target="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ref>.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_2BBHRKm">Capturing mismatch between textual and acoustic emotion expressions for mood identification in bipolar disorder</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcinnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mower Provost</surname></persName>
		</author>
		<idno type="DOI">10.21437/interspeech.2023-1990</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_vuKRBSb">Proc. INTERSPEECH 2023</title>
		<meeting>INTERSPEECH 2023</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1718" to="1722" />
		</imprint>
	</monogr>
	<note type="raw_reference">Niu, M., Romana, A., Jaiswal, M., McInnis, M. &amp; Mower Provost, E. Capturing mismatch between textual and acoustic emotion expressions for mood identification in bipolar disorder. In Proc. INTERSPEECH 2023, 1718-1722 (2023).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_MDw7SrA">Speech as a biomarker for depression</title>
		<author>
			<persName><forename type="first">S</forename><surname>Koops</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_vJeGKME">CNS Neurol. Disord. Drug Targets</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="152" to="160" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Koops, S. et al. Speech as a biomarker for depression. CNS Neurol. Disord. Drug Targets 22, 152-160 (2023).</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_MxHqQBK">Automatic depression recognition by intelligent speech signal processing: A systematic survey</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1049/cit2.12113</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xCYSe3p">CAAI Trans. Intell. Technol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="701" to="711" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wu, P. et al. Automatic depression recognition by intelligent speech signal processing: A systematic survey. CAAI Trans. Intell. Technol. 8, 701-711 (2023).</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_nYcg2YA">Automated assessment of psychiatric disorders using speech: A systematic review</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Bentley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ghosh</surname></persName>
		</author>
		<idno type="DOI">10.1002/lio2.354</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7U3tktV">Laryngoscope Investig. Otolaryngol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="96" to="116" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Low, D. M., Bentley, K. H. &amp; Ghosh, S. S. Automated assessment of psychiatric disorders using speech: A systematic review. Laryngoscope Investig. Otolaryngol. 5, 96-116 (2020).</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_yKkK78f">A review of depression and suicide risk assessment using speech analysis</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cummins</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.specom.2015.03.004</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rr57TCu">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="10" to="49" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cummins, N. et al. A review of depression and suicide risk assessment using speech analysis. Speech Commun. 71, 10-49 (2015).</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_fxSaDyf">Classifying dementia in the presence of depression: A cross-corpus study</title>
		<author>
			<persName><forename type="first">F</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_qhZKZu8">INTERSPEECH 2023 (ISCA</title>
		<imprint>
			<publisher>ISCA</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Braun, F. et al. Classifying dementia in the presence of depression: A cross-corpus study. In INTERSPEECH 2023 (ISCA, ISCA, 2023).</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_uYzhFwP">A speech processing-based screening system for automatic identification of patients with alzheimer&apos;s disease and related dementia</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zolnoori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zolnour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Topaz</surname></persName>
		</author>
		<author>
			<persName><surname>Adscreen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artmed.2023.102624</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TubJ8eT">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">102624</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zolnoori, M., Zolnour, A. &amp; Topaz, M. Adscreen: A speech processing-based screening system for automatic identification of patients with alzheimer&apos;s disease and related dementia. Artif. Intell. Med. 143, 102624 (2023).</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_GKJXc7b">Predicting dementia from spontaneous speech using large language models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Agbavor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000168</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_snfqtaQ">PLOS Digit. Health</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">168</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Agbavor, F. &amp; Liang, H. Predicting dementia from spontaneous speech using large language models. PLOS Digit. Health 1, e0000168 (2022).</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_XphdtG7">Ten years of research on automatic voice and speech analysis of people with Alzheimer&apos;s disease and mild cognitive impairment: a systematic review article</title>
		<author>
			<persName><forename type="first">I</forename><surname>Martínez-Nicolás</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Llorente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Martínez-Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J G</forename><surname>Meilán</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2021.620251</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_G3hgdwY">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">620251</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Martínez-Nicolás, I., Llorente, T. E., Martínez-Sánchez, F. &amp; Meilán, J. J. G. Ten years of research on automatic voice and speech analysis of people with Alzheimer&apos;s disease and mild cognitive impairment: a systematic review article. Front. Psychol. 12, 620251 (2021).</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_ytetBbA">Automated semantic relevance as an indicator of cognitive decline: Out-of-sample validation on a large-scale longitudinal dataset</title>
		<author>
			<persName><forename type="first">G</forename><surname>Stegmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_X6WqKse">Alzheimer&apos;s. Dement.: Diagn. Assess. Dis. Monit</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">12294</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stegmann, G. et al. Automated semantic relevance as an indicator of cognitive decline: Out-of-sample validation on a large-scale longitudinal dataset. Alzheimer&apos;s. Dement.: Diagn. Assess. Dis. Monit. 14, e12294 (2022).</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_KK3HaPG">Automatic classification of hypokinetic and hyperkinetic dysarthria based on GMM-Supervectors</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Ríos-Urrego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rusz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nöth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Orozco-Arroyave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dUkh9Mz">INTERSPEECH 2023 (ISCA</title>
		<imprint>
			<publisher>ISCA</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ríos-Urrego, C. D., Rusz, J., Nöth, E. &amp; Orozco-Arroyave, J. R. Automatic classification of hypokinetic and hyperkinetic dysarthria based on GMM-Supervectors. In INTERSPEECH 2023 (ISCA, ISCA, 2023).</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_e2mNFff">Exemplar-based sparse representations for detection of Parkinson&apos;s disease from speech</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alku</surname></persName>
		</author>
		<idno type="DOI">10.1109/taslp.2023.3260709</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_mSQt6Mk">IEEE/ACM Trans. Audio, Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1386" to="1396" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Reddy, M. K. &amp; Alku, P. Exemplar-based sparse representations for detection of Parkinson&apos;s disease from speech. IEEE/ACM Trans. Audio, Speech Lang. Process. 31, 1386-1396 (2023).</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_qfgMhgb">Improving Parkinson&apos;s disease recognition through voice analysis using deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Khaskhoussy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patrec.2023.03.011</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pWtBNrQ">Pattern Recognit. Lett</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="page" from="64" to="70" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Khaskhoussy, R. &amp; Ayed, Y. B. Improving Parkinson&apos;s disease recognition through voice analysis using deep learning. Pattern Recognit. Lett. 168, 64-70 (2023).</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_ekRxUa2">Advances in Parkinson&apos;s disease detection and assessment using voice and speech: A review of the articulatory and phonatory aspects</title>
		<author>
			<persName><forename type="first">L</forename><surname>Moro-Velazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gomez-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Arias-Londoño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Godino-Llorente</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bspc.2021.102418</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KrpeuPg">Biomed. Signal Process. Control</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page">102418</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moro-Velazquez, L., Gomez-Garcia, J. A., Arias-Londoño, J. D., Dehak, N. &amp; Godino-Llorente, J. I. Advances in Parkinson&apos;s disease detection and assessment using voice and speech: A review of the articulatory and phonatory aspects. Biomed. Signal Process. Control 66, 102418 (2021).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_2SQbgwC">Early detection and tracking of bulbar changes in ALS via frequent and remote speech analysis</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Stegmann</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-020-00335-x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UpBjYPr">NPJ Digital Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">132</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stegmann, G. M. et al. Early detection and tracking of bulbar changes in ALS via frequent and remote speech analysis. NPJ Digital Med. 3, 132 (2020).</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_uEhv4Sv">Robust speech recognition via large-scale weak supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_wjUubZd">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="28492" to="28518" />
		</imprint>
	</monogr>
	<note type="raw_reference">Radford, A. et al. Robust speech recognition via large-scale weak supervision. In International Conference on Machine Learning, 28492-28518 (PMLR, 2023).</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_EM5PprG">Exploring architectures, data and units for streaming end-to-end speech recognition with RNNtransducer</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prabhavalkar</surname></persName>
		</author>
		<idno type="DOI">10.1109/asru.2017.8268935</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_58xcJPp">2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="193" to="199" />
		</imprint>
	</monogr>
	<note type="raw_reference">Rao, K., Sak, H. &amp; Prabhavalkar, R. Exploring architectures, data and units for streaming end-to-end speech recognition with RNN- transducer. In 2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), 193-199 (IEEE, 2017).</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main" xml:id="_MvnCSqG">Repeatability of commonly used speech and language features for clinical applications</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Stegmann</surname></persName>
		</author>
		<idno type="DOI">10.1159/000511671</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HaQwfqS">Digit. Biomark</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="109" to="122" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stegmann, G. M. et al. Repeatability of commonly used speech and language features for clinical applications. Digit. Biomark. 4, 109-122 (2020).</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_cev3Aj6">wav2vec 2.0: A framework for self-supervised learning of speech representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XJNkN9c">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12449" to="12460" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Baevski, A., Zhou, Y., Mohamed, A. &amp; Auli, M. wav2vec 2.0: A framework for self-supervised learning of speech representations. Adv. Neural Inf. Process. Syst. 33, 12449-12460 (2020).</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_V4mA7QP">XLS-R Self-supervised cross-lingual speech representation learning at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_bmj3nyf">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2278" to="2282" />
		</imprint>
	</monogr>
	<note type="raw_reference">Babu, A. et al. XLS-R Self-supervised cross-lingual speech representation learning at scale. In Proc. Interspeech 2278-2282 (2022).</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Achiam, J. et al. GPT-4 technical report. arXiv preprint arXiv:2303.08774 (2023).</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_abaubp3">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><forename type="middle">C</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_5ennExD">Proceedings of naacL-HLT</title>
		<meeting>naacL-HLT</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Kenton, J. D. M.-W. C. &amp; Toutanova, L. K. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of naacL-HLT, vol. 1, 2 (2019).</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_zcPxXXH">Text dialogue analysis for primary screening of mild cognitive impairment: Development and validation study</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yfX5gvt">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">51501</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wang, C., Liu, S., Li, A. &amp; Liu, J. Text dialogue analysis for primary screening of mild cognitive impairment: Development and validation study. J. Med. Internet Res. 25, e51501 (2023).</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_u96t6KV">Artificial intelligence, speech, and language processing approaches to monitoring Alzheimer&apos;s disease: a systematic review</title>
		<author>
			<persName><surname>De La Fuente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3AmRDHu">J. Alzheimer&apos;s. Dis</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1547" to="1574" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">de la Fuente Garcia, S., Ritchie, C. W. &amp; Luz, S. Artificial intelligence, speech, and language processing approaches to monitoring Alzheimer&apos;s disease: a systematic review. J. Alzheimer&apos;s. Dis. 78, 1547-1574 (2020).</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_qfGRmzp">A systematic literature review of automatic Alzheimer&apos;s disease detection from speech and language</title>
		<author>
			<persName><forename type="first">U</forename><surname>Petti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocaa174</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_N3SHZHm">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1784" to="1797" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Petti, U., Baker, S. &amp; Korhonen, A. A systematic literature review of automatic Alzheimer&apos;s disease detection from speech and language. J. Am. Med. Inform. Assoc. 27, 1784-1797 (2020).</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_K444KCM">Using acoustic speech patterns from smartphones to investigate mood disorders: scoping review</title>
		<author>
			<persName><forename type="first">O</forename><surname>Flanagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sundram</surname></persName>
		</author>
		<idno type="DOI">10.2196/24352</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_g7tc2my">JMIR mHealth uHealth</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">24352</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Flanagan, O., Chan, A., Roop, P. &amp; Sundram, F. Using acoustic speech patterns from smartphones to investigate mood disorders: scoping review. JMIR mHealth uHealth 9, e24352 (2021).</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Boushra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcdowell</surname></persName>
		</author>
		<ptr target="http://europepmc.org/books/NBK541044" />
		<title level="m" xml:id="_YgxEWnH">Stroke-Like Conditions</title>
		<meeting><address><addrLine>Treasure Island (FL)</addrLine></address></meeting>
		<imprint>
			<publisher>StatPearls Publishing</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Boushra, M. &amp; McDowell, C. Stroke-Like Conditions (StatPearls Publishing, Treasure Island (FL), 2023). http://europepmc.org/ books/NBK541044.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_xjBd3bD">Importance of low diagnostic accuracy for early Parkinson&apos;s disease</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Beach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Adler</surname></persName>
		</author>
		<idno type="DOI">10.1002/mds.27485</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SG2ZdbU">Mov. Disord</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1551" to="1554" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Beach, T. G. &amp; Adler, C. H. Importance of low diagnostic accuracy for early Parkinson&apos;s disease. Mov. Disord. 33, 1551-1554 (2018).</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_ARrRXBw">Time to diagnosis and factors affecting diagnostic delay in amyotrophic lateral sclerosis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Morren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Pioro</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-024-01199-1</idno>
		<ptr target="https://doi.org/10.1038/s41746-024-01199-1" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_eJh3Kd6">J. Neurol. Sci</title>
		<imprint>
			<biblScope unit="volume">417</biblScope>
			<biblScope unit="page">117054</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Richards, D., Morren, J. A. &amp; Pioro, E. P. Time to diagnosis and factors affecting diagnostic delay in amyotrophic lateral sclerosis. J. Neurol. Sci. 417, 117054 (2020). https://doi.org/10.1038/s41746-024-01199-1</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_qkm4rzf">Diagnosis and treatment of Friedreich Ataxia: a european perspective</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrneurol.2009.26</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EbUzruC">Nat. Rev. Neurol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="222" to="234" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Schulz, J. B. et al. Diagnosis and treatment of Friedreich Ataxia: a european perspective. Nat. Rev. Neurol. 5, 222-234 (2009).</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_MudXpGk">Progressive apraxia of speech: Delays to diagnosis and rates of alternative diagnoses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00415-021-10585-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_3fbcqT5">J. Neurol</title>
		<imprint>
			<biblScope unit="volume">268</biblScope>
			<biblScope unit="page" from="4752" to="4758" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dang, J. et al. Progressive apraxia of speech: Delays to diagnosis and rates of alternative diagnoses. J. Neurol. 268, 4752-4758 (2021).</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_UpavSwA">Genetic analysis suggests high misassignment rates in clinical Alzheimer&apos;s cases and controls</title>
		<author>
			<persName><forename type="first">V</forename><surname>Escott-Price</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neurobiolaging.2018.12.002</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GHsZcDP">Neurobiol. aging</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="178" to="182" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Escott-Price, V. et al. Genetic analysis suggests high misassignment rates in clinical Alzheimer&apos;s cases and controls. Neurobiol. aging 77, 178-182 (2019).</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main" xml:id="_f2w5DqQ">Subjective cognitive complaints contribute to misdiagnosis of mild cognitive impairment</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Edmonds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Delano-Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Galasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Salmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Bondi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rvEW6YA">J. Int. Neuropsychol. Soc</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="836" to="847" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Edmonds, E. C., Delano-Wood, L., Galasko, D. R., Salmon, D. P. &amp; Bondi, M. W. Subjective cognitive complaints contribute to misdiagnosis of mild cognitive impairment. J. Int. Neuropsychol. Soc. 20, 836-847 (2014).</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_Bsmdsxu">Evaluation of boundaries between mood and psychosis disorder using dynamic functional network connectivity (dfnc) via deep learning classification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rokham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Falakshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pearlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Calhoun</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.26273</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Cr6p4dA">Hum. Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="3180" to="3195" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rokham, H., Falakshahi, H., Fu, Z., Pearlson, G. &amp; Calhoun, V. D. Evaluation of boundaries between mood and psychosis disorder using dynamic functional network connectivity (dfnc) via deep learning classification. Hum. Brain Mapp. 44, 3180-3195 (2023).</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_YS3WdBu">Are reported accuracies in the clinical speech machine learning literature overoptimistic</title>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Krantsevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stegmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_7BB3gSe">Proceedings of the Annual Conference of the International Speech Communication Association</title>
		<meeting>the Annual Conference of the International Speech Communication Association</meeting>
		<imprint>
			<publisher>INTERSPEECH</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="2453" to="2457" />
		</imprint>
	</monogr>
	<note type="raw_reference">Berisha, V., Krantsevich, C., Stegmann, G., Hahn, S. &amp; Liss, J. Are reported accuracies in the clinical speech machine learning literature overoptimistic? In Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, vol. 2022, 2453-2457 (2022).</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main" xml:id="_jPyeD5R">Illusory generalizability of clinical prediction models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Chekroud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MNuzkFs">Science</title>
		<imprint>
			<biblScope unit="volume">383</biblScope>
			<biblScope unit="page" from="164" to="167" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chekroud, A. M. et al. Illusory generalizability of clinical prediction models. Science 383, 164-167 (2024).</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_TQcMchs">Reliability and validity of a widelyavailable ai tool for assessment of stress based on speech</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yawer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_f7MKPSB">Nature Scientific Reports</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yawer, B., Liss, J. &amp; Berisha, V. Reliability and validity of a widely- available ai tool for assessment of stress based on speech. In Nature Scientific Reports (2023).</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Behrman</surname></persName>
		</author>
		<title level="m" xml:id="_XKvnNuy">Speech and voice science</title>
		<imprint>
			<publisher>Plural publishing</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Behrman, A. Speech and voice science (Plural publishing, 2021).</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Weismer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hoit</surname></persName>
		</author>
		<title level="m" xml:id="_FbdsCuJ">Preclinical speech science: Anatomy, physiology, acoustics, and perception</title>
		<imprint>
			<publisher>Plural Publishing</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hixon, T. J., Weismer, G. &amp; Hoit, J. D. Preclinical speech science: Anatomy, physiology, acoustics, and perception (Plural Publishing, 2018).</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Lapointe</surname></persName>
		</author>
		<author>
			<persName><surname>Paul</surname></persName>
		</author>
		<title level="m" xml:id="_PBXmHEX">Broca and the origins of language in the brain</title>
		<imprint>
			<publisher>Plural Publishing</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">LaPointe, L. L. Paul Broca and the origins of language in the brain (Plural Publishing, 2012).</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Borden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Harris</surname></persName>
		</author>
		<title level="m" xml:id="_4FjXUtP">Speech science primer: Physiology, acoustics, and perception of speech</title>
		<imprint>
			<publisher>Lippincott Williams &amp; Wilkins</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Raphael, L. J., Borden, G. J. &amp; Harris, K. S. Speech science primer: Physiology, acoustics, and perception of speech (Lippincott Williams &amp; Wilkins, 2007).</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_v4grZMs">Speech science: An integrated approach to theory and clinical practice</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Ferrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jv9HekY">Ear Hearing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">549</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ferrand, C. T. Speech science: An integrated approach to theory and clinical practice. Ear Hearing 22, 549 (2001).</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Duffy</surname></persName>
		</author>
		<title level="m" xml:id="_RdBFmsA">Motor Speech Disorders-E-Book: Substrates, differential diagnosis, and management</title>
		<imprint>
			<publisher>Elsevier Health Sciences</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Duffy, J. R. In Motor Speech Disorders-E-Book: Substrates, differential diagnosis, and management (Elsevier Health Sciences, 2012).</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main" xml:id="_rM3VWCd">The communicative participation item bank (CPIB): Item bank calibration and development of a disorder-generic short form</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_uB9nDEF">J. Speech Lang. Hear. Res</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1190" to="1208" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Baylor, C. et al. The communicative participation item bank (CPIB): Item bank calibration and development of a disorder-generic short form. J. Speech Lang. Hear. Res. 56, 1190-1208 (2013).</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main" xml:id="_65wg3wf">Connected speech in neurodegenerative language disorders: a review</title>
		<author>
			<persName><forename type="first">V</forename><surname>Boschi</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2017.00269</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cStvF9u">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">208495</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Boschi, V. et al. Connected speech in neurodegenerative language disorders: a review. Front. Psychol. 8, 208495 (2017).</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_69kfBkb">Listener agreement for auditory-perceptual ratings of dysarthria</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bunton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Rosenbek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kent</surname></persName>
		</author>
		<idno type="DOI">10.1044/1092-4388(2007/102</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SrqEGbz">J. Speech Lang. Hear. Res</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1481" to="1495" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bunton, K., Kent, R. D., Duffy, J. R., Rosenbek, J. C. &amp; Kent, J. F. Listener agreement for auditory-perceptual ratings of dysarthria. J. Speech Lang. Hear. Res. 50, 1481-1495 (2007).</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Perkell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Klatt</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315802350</idno>
		<title level="m" xml:id="_n8Jd3uw">Invariance and variability in speech processes</title>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Perkell, J. S. &amp; Klatt, D. H. Invariance and variability in speech processes (Psychology Press, 2014).</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main" xml:id="_BAGjdDK">Moving forward: how depression heterogeneity hinders progress in treatment and research</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fried</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_TwWXsF3">Expert Rev. Neurother</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="423" to="425" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Fried, E. Moving forward: how depression heterogeneity hinders progress in treatment and research. Expert Rev. Neurother. 17, 423-425 (2017).</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main" xml:id="_vTgFK3S">Noninvasive voice biomarker is associated with incident coronary artery disease events at follow-up</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D S</forename><surname>Sara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KKBZhSm">Mayo Clinic Proceedings</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="835" to="846" />
			<date type="published" when="2022">2022</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Sara, J. D. S. et al. Noninvasive voice biomarker is associated with incident coronary artery disease events at follow-up. In Mayo Clinic Proceedings, vol. 97, 835-846 (Elsevier, 2022).</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main" xml:id="_T9F4UBe">Acoustic analysis and prediction of type 2 diabetes mellitus using smartphonerecorded voice segments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thommandram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fossat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_hYE9zEq">Mayo Clin. Proc.: Digit. Health</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="534" to="544" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kaufman, J. M., Thommandram, A. &amp; Fossat, Y. Acoustic analysis and prediction of type 2 diabetes mellitus using smartphone- recorded voice segments. Mayo Clin. Proc.: Digit. Health 1, 534-544 (2023).</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main" xml:id="_uw3FndW">Neural representations and mechanisms for the performance of simple speech sequences</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Bohland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bullock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Guenther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EyNmJcY">J. Cogn. Neurosci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1504" to="1529" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bohland, J. W., Bullock, D. &amp; Guenther, F. H. Neural representations and mechanisms for the performance of simple speech sequences. J. Cogn. Neurosci. 22, 1504-1529 (2010).</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main" xml:id="_kAAxG6p">Advancement of phonetics in the 21st century: Exemplar models of speech production</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goldrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9vHDbU2">J. Phon</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page">101254</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Goldrick, M. &amp; Cole, J. Advancement of phonetics in the 21st century: Exemplar models of speech production. J. Phon. 99, 101254 (2023).</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main" xml:id="_UvfJrFW">Speech production as state feedback control</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Houde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Nagarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_KB3NkJx">Front. Hum. Neurosci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">82</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Houde, J. F. &amp; Nagarajan, S. S. Speech production as state feedback control. Front. Hum. Neurosci. 5, 82 (2011).</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main" xml:id="_uFyKTHq">A model of speech production based on the acoustic relativity of the vocal tract</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Story</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bunton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xft887x">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="2522" to="2528" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Story, B. H. &amp; Bunton, K. A model of speech production based on the acoustic relativity of the vocal tract. J. Acoust. Soc. Am. 146, 2522-2528 (2019).</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main" xml:id="_HMMhbVG">Evaluating quantitative and conceptual models of speech production: how does slam fare?</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hickok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7SNJMuF">Psychon. Bull. Rev</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="653" to="660" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Walker, G. M. &amp; Hickok, G. Evaluating quantitative and conceptual models of speech production: how does slam fare? Psychon. Bull. Rev. 23, 653-660 (2016).</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main" xml:id="_AuPDBKt">Models of word production</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Levelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_R2RHdAa">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="223" to="232" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Levelt, W. J. Models of word production. Trends Cogn. Sci. 3, 223-232 (1999).</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main" xml:id="_3x8WbzE">Speech under stress conditions: overview of the effect on speech production and on system performance</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Steeneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_JheMVRN">IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No. 99CH36258</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999">1999. 1999</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2079" to="2082" />
		</imprint>
	</monogr>
	<note type="raw_reference">Steeneken, H. J. &amp; Hansen, J. H. Speech under stress conditions: overview of the effect on speech production and on system performance. In 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No. 99CH36258), vol. 4, 2079-2082 (IEEE, 1999).</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main" xml:id="_Q7xGzRg">A finite-element model of vocalfold vibration</title>
		<author>
			<persName><forename type="first">F</forename><surname>Alipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Titze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_JbAWwb6">J. Acoust. Soc. Am</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="3003" to="3012" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Alipour, F., Berry, D. A. &amp; Titze, I. R. A finite-element model of vocal- fold vibration. J. Acoust. Soc. Am. 108, 3003-3012 (2000).</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main" xml:id="_MfmcRST">Misdiagnosis of vocal fold nodules</title>
		<author>
			<persName><forename type="first">C</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al Omari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alnouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Sataloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_yzGcSAP">J. Voice</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Marshall, C., Lyons, T., Al Omari, A., Alnouri, G. &amp; Sataloff, R. T. Misdiagnosis of vocal fold nodules. J. Voice (2023).</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main" xml:id="_M4u9WgJ">Developing an artificial intelligence tool to predict vocal cord pathology in primary care settings</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Compton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_YZJ27Y2">Laryngoscope</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="1952" to="1960" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Compton, E. C. et al. Developing an artificial intelligence tool to predict vocal cord pathology in primary care settings. Laryngoscope 133, 1952-1960 (2023).</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main" xml:id="_8whxnHZ">Motor speech disorders: Clues to neurologic diagnosis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_JC9SqQm">Parkinson&apos;s disease and movement disorders: Diagnosis and treatment guidelines for the practicing physician</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="35" to="53" />
		</imprint>
	</monogr>
	<note type="raw_reference">Duffy, J. R. Motor speech disorders: Clues to neurologic diagnosis. In Parkinson&apos;s disease and movement disorders: Diagnosis and treatment guidelines for the practicing physician, 35-53 (Springer, 2000).</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main" xml:id="_bmttneU">Perceptual classification of motor speech disorders: the role of severity, speech task, and listener&apos;s expertise</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pernon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Assal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kodrasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laganaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EfdGxz2">J. Speech, Lang., Hear. Res</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="2727" to="2747" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Pernon, M., Assal, F., Kodrasi, I. &amp; Laganaro, M. Perceptual classification of motor speech disorders: the role of severity, speech task, and listener&apos;s expertise. J. Speech, Lang., Hear. Res. 65, 2727-2747 (2022).</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main" xml:id="_nadfwzg">AI-based assessments of speech and language impairments in dementia</title>
		<author>
			<persName><forename type="first">M</forename><surname>Parsapoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_swum8Np">Alzheimer&apos;s. Dement</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="4675" to="4687" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Parsapoor, M. AI-based assessments of speech and language impairments in dementia. Alzheimer&apos;s. Dement. 19, 4675-4687 (2023).</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main" xml:id="_HzjywSZ">A review of automated speech and language features for assessment of cognitive and thought disorders</title>
		<author>
			<persName><forename type="first">R</forename><surname>Voleti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Liss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tmwJwg2">IEEE J. Sel. Top. signal Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="282" to="298" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Voleti, R., Liss, J. M. &amp; Berisha, V. A review of automated speech and language features for assessment of cognitive and thought disorders. IEEE J. Sel. Top. signal Process. 14, 282-298 (2019).</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main" xml:id="_Ps7GSsy">Does method matter? assessing the validity and clinical utility of structured diagnostic interviews among a clinical sample of first-admitted patients with psychosis: A replication study</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Kvig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nilssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_spwJUBC">Front. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1076299</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kvig, E. I. &amp; Nilssen, S. Does method matter? assessing the validity and clinical utility of structured diagnostic interviews among a clinical sample of first-admitted patients with psychosis: A replication study. Front. Psychiatry 14, 1076299 (2023).</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main" xml:id="_nbShzMB">SOD and CAT as potential preliminary biomarkers for the differential diagnosis of schizophrenia and bipolar disorder in the first episode of psychosis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cachán-Vega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZVPV4Hg">Eur. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="449" to="S450" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cachán-Vega, C. SOD and CAT as potential preliminary biomarkers for the differential diagnosis of schizophrenia and bipolar disorder in the first episode of psychosis. Eur. Psychiatry 66, S449-S450 (2023).</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main" xml:id="_XSsngQy">Decreased resting-state neural signal in the left angular gyrus as a potential neuroimaging biomarker of schizophrenia: an amplitude of low-frequency fluctuation and support vector machine analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2g3MFFg">Front. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">949512</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gao, Y. et al. Decreased resting-state neural signal in the left angular gyrus as a potential neuroimaging biomarker of schizophrenia: an amplitude of low-frequency fluctuation and support vector machine analysis. Front. Psychiatry 13, 949512 (2022).</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main" xml:id="_xDyuMee">Language in schizophrenia part 1: An introduction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kuperberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UK9xTHY">language and linguistics compass</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="576" to="589" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kuperberg, G. Language in schizophrenia part 1: An introduction. language and linguistics compass, 4, 576-589 (2010).</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main" xml:id="_PTHmj33">Language analytics for assessment of mental health status and functional competency</title>
		<author>
			<persName><forename type="first">R</forename><surname>Voleti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5z44AKQ">Schizophr. Bull</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="183" to="S195" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Voleti, R. et al. Language analytics for assessment of mental health status and functional competency. Schizophr. Bull. 49, S183-S195 (2023).</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main" xml:id="_z9my9rz">Speech deficits in serious mental illness: a cognitive resource issue?</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mcgovern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Dinzeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Covington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UuHWKuf">Schizophr. Res</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="173" to="179" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cohen, A. S., McGovern, J. E., Dinzeo, T. J. &amp; Covington, M. A. Speech deficits in serious mental illness: a cognitive resource issue? Schizophr. Res. 160, 173-179 (2014).</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main" xml:id="_A9FWM7c">A speech-based prognostic model for dysarthria progression in als</title>
		<author>
			<persName><forename type="first">G</forename><surname>Stegmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_bXdfpQb">Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Stegmann, G. et al. A speech-based prognostic model for dysarthria progression in als. Amyotrophic Lateral Sclerosis and Frontotemporal Degeneration 1-6 (2023).</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main" xml:id="_9Ekxprb">Sensor measurements can characterize fluctuations and wearing off in parkinson&apos;s disease and guide therapy to improve motor, non-motor and quality of life scores</title>
		<author>
			<persName><forename type="first">P</forename><surname>Farzanehfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Woodrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HbrJ8Sf">Front. Aging Neurosci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">852992</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Farzanehfar, P., Woodrow, H. &amp; Horne, M. Sensor measurements can characterize fluctuations and wearing off in parkinson&apos;s disease and guide therapy to improve motor, non-motor and quality of life scores. Front. Aging Neurosci. 14, 852992 (2022).</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main" xml:id="_WyXmXXY">The effects of speech therapy and pharmacological treatments on voice and speech in Parkinson&apos;s disease: A review of the literature</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-024-01199-1</idno>
		<ptr target="https://doi.org/10.1038/s41746-024-01199-1" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_WcNBsnF">Curr. Med. Chem</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1359" to="1366" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Schulz, G. M. The effects of speech therapy and pharmacological treatments on voice and speech in Parkinson&apos;s disease: A review of the literature. Curr. Med. Chem. 9, 1359-1366 (2002). https://doi.org/10.1038/s41746-024-01199-1</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main" xml:id="_AZzyWpj">From speech acoustics to communicative participation in dysarthria: Toward a causal framework</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Borrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Barrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_xDBYtd5">J. Speech, Lang., Hear. Res</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="405" to="418" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Borrie, S. A., Wynn, C. J., Berisha, V. &amp; Barrett, T. S. From speech acoustics to communicative participation in dysarthria: Toward a causal framework. J. Speech, Lang., Hear. Res. 65, 405-418 (2022).</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main" xml:id="_ezKcyzC">Social isolation, social interaction, and Alzheimer&apos;s disease: a mendelian randomization study</title>
		<author>
			<persName><forename type="first">L.-X</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_byxvSZd">J. Alzheimer&apos;s. Dis</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="665" to="672" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Shen, L.-X. et al. Social isolation, social interaction, and Alzheimer&apos;s disease: a mendelian randomization study. J. Alzheimer&apos;s. Dis 80, 665-672 (2021).</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<idno>RFA-FD-21-004</idno>
		<ptr target="https://grants.nih.gov/grants/guide/rfa-files/RFA-FD-21-004.html" />
		<title level="m" xml:id="_RB6ptmJ">Development of Standard Core Clinical Outcomes Assessments (COAs) and Endpoints (UG3/UH3 Clinical Trial Optional)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
		<respStmt>
			<orgName>Department of Health and Human Services</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Department of Health and Human Services. Development of Standard Core Clinical Outcomes Assessments (COAs) and Endpoints (UG3/UH3 Clinical Trial Optional). https://grants.nih.gov/ grants/guide/rfa-files/RFA-FD-21-004.html. Funding Opportunity Announcement (FOA) Number: RFA-FD-21-004 (2020).</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main" xml:id="_cXyD7Pa">Improved ALS clinical trials through frequent athome self-assessment: a proof of concept study</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Rutkove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CdaYpbM">Ann. Clin. Transl. Neurol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1148" to="1157" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rutkove, S. B. et al. Improved ALS clinical trials through frequent at- home self-assessment: a proof of concept study. Ann. Clin. Transl. Neurol. 7, 1148-1157 (2020).</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kowatsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Marsch</surname></persName>
		</author>
		<title level="m" xml:id="_4RtJNKg">Digital therapeutics for mental health and addiction: The state of the science and vision for the future</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jacobson, N. C., Kowatsch, T. &amp; Marsch, L. A. Digital therapeutics for mental health and addiction: The state of the science and vision for the future (Academic Press, 2022).</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main" xml:id="_JvfyktR">Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gholipour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_s92nmR4">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">101759</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Karimi, D., Dou, H., Warfield, S. K. &amp; Gholipour, A. Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis. Med. Image Anal. 65, 101759 (2020).</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main" xml:id="_6ZXK3Dn">Regularization via structural label smoothing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_dss3mMk">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1453" to="1463" />
		</imprint>
	</monogr>
	<note type="raw_reference">Li, W., Dasarathy, G. &amp; Berisha, V. Regularization via structural label smoothing. In International Conference on Artificial Intelligence and Statistics, 1453-1463 (PMLR, 2020).</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main" xml:id="_TsgMQQz">Normalized loss functions for deep learning with noisy labels</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_2tYcSa9">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6543" to="6553" />
		</imprint>
	</monogr>
	<note type="raw_reference">Ma, X. et al. Normalized loss functions for deep learning with noisy labels. In International Conference on Machine Learning, 6543-6553 (PMLR, 2020).</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main" xml:id="_xG5DbuP">Worst-case perturbations for semisupervised deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><surname>Wcp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_tmTRPBJ">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3912" to="3921" />
		</imprint>
	</monogr>
	<note type="raw_reference">Zhang, L. &amp; Qi, G.-J. Wcp: Worst-case perturbations for semi- supervised deep learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 3912-3921 (2020).</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main" xml:id="_9aPRJxM">Verification, analytical validation, and clinical validation (V3): the foundation of determining fit-for-purpose for biometric monitoring technologies (biomets)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Goldsack</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-020-0260-4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EgxyMWB">npj Digital Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Goldsack, J. C. et al. Verification, analytical validation, and clinical validation (V3): the foundation of determining fit-for-purpose for biometric monitoring technologies (biomets). npj Digital Med. 3, 55 (2020).</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<title level="m" xml:id="_KjXPcyH">Center for Devices and Radiological Health &amp; Center for Biologics Eva-luation and Research</title>
		<imprint>
			<publisher>Food and Drug Administration</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Food &amp; Administration</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Final Guidance for Industry and FDA Staff</note>
	<note>General Principles of Software Validation</note>
	<note type="raw_reference">Food &amp; Administration, D. Center for Devices and Radiological Health &amp; Center for Biologics Eva-luation and Research. General Principles of Software Validation; Final Guidance for Industry and FDA Staff (Food and Drug Administration, 2002).</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main" xml:id="_7rqXaKy">Digital medicine and the curse of dimensionality</title>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Xdf7vHB">NPJ Digital Med</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Berisha, V. et al. Digital medicine and the curse of dimensionality. NPJ Digital Med. 4, 153 (2021).</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main" xml:id="_kSNHS7n">Evaluation of speech-based digital biomarkers: review and recommendations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_rDtgCez">Digit. Biomark</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Robin, J. et al. Evaluation of speech-based digital biomarkers: review and recommendations. Digit. Biomark. 4, 99-108 (2020).</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main" xml:id="_xGkvMdm">Operationalizing clinical speech analytics: Moving from features to measures for real-world clinical impact</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_57k43YS">J. Speech Lang. Hear. Res</title>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Liss, J. &amp; Berisha, V. Operationalizing clinical speech analytics: Moving from features to measures for real-world clinical impact. J. Speech Lang. Hear. Res. 1-7 (2024).</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main" xml:id="_Mu8Khzv">A deep learning algorithm for objective assessment of hypernasality in children with cleft palate</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Mathad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Liss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_duteSFU">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="2986" to="2996" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mathad, V. C., Scherer, N., Chapman, K., Liss, J. M. &amp; Berisha, V. A deep learning algorithm for objective assessment of hypernasality in children with cleft palate. IEEE Trans. Biomed. Eng. 68, 2986-2996 (2021).</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main" xml:id="_Am96yqA">Consonant-vowel transition models based on deep learning for objective evaluation of articulation</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Mathad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Liss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_h8gXqA9">IEEE/ACM Trans. Audio, Speech, Lang. Process</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="86" to="95" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mathad, V. C., Liss, J. M., Chapman, K., Scherer, N. &amp; Berisha, V. Consonant-vowel transition models based on deep learning for objective evaluation of articulation. IEEE/ACM Trans. Audio, Speech, Lang. Process. 31, 86-95 (2022).</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main" xml:id="_9AxUf3v">Dysarthria detection based on a deep learning model with a clinically-interpretable layer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_D2UC6q6">JASA Express Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Xu, L., Liss, J. &amp; Berisha, V. Dysarthria detection based on a deep learning model with a clinically-interpretable layer. JASA Express Lett. 3 (2023).</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main" xml:id="_hT7YEEg">Causal interpretability for machine learning-problems, methods and evaluation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Moraffah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raglin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_dTYE2CX">ACM SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="18" to="33" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Moraffah, R., Karami, M., Guo, R., Raglin, A. &amp; Liu, H. Causal interpretability for machine learning-problems, methods and evaluation. ACM SIGKDD Explor. Newsl. 22, 18-33 (2020).</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main" xml:id="_NbpRSrp">Is AI fuelling a reproducibility crisis in science</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gibney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GvAPPwb">Nature</title>
		<imprint>
			<biblScope unit="volume">608</biblScope>
			<biblScope unit="page" from="250" to="251" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Gibney, E. Is AI fuelling a reproducibility crisis in science. Nature 608, 250-251 (2022).</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main" xml:id="_jRJHF7H">Leakage and the reproducibility crisis in machine-learning-based science</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Br9xWqV">Patterns</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">100804</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kapoor, S. &amp; Narayanan, A. Leakage and the reproducibility crisis in machine-learning-based science. Patterns 4, 100804 (2023).</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main" xml:id="_CHDeQZF">Stress measurement using speech: Recent advancements, validation issues, and ethical and privacy considerations</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Slavich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PermgrQ">Stress</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="408" to="413" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Slavich, G. M., Taylor, S. &amp; Picard, R. W. Stress measurement using speech: Recent advancements, validation issues, and ethical and privacy considerations. Stress 22, 408-413 (2019).</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main" xml:id="_3KGvhpT">Geographic distribution of us cohorts used to train deep learning algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kaushal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Langlotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_U5XBCx7">Jama</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="1212" to="1213" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kaushal, A., Altman, R. &amp; Langlotz, C. Geographic distribution of us cohorts used to train deep learning algorithms. Jama 324, 1212-1213 (2020).</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main" xml:id="_eSY7E9V">Speech and language markers of neurodegeneration: a call for global equity</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>De Leon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Tee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Blasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Gorno-Tempini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7FCV7ZK">Brain</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="4870" to="4879" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">García, A. M., de Leon, J., Tee, B. L., Blasi, D. E. &amp; Gorno-Tempini, M. L. Speech and language markers of neurodegeneration: a call for global equity. Brain 146, 4870-4879 (2023).</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main" xml:id="_p7wAmsc">Tracking discourse complexity preceding alzheimer&apos;s disease diagnosis: a case study comparing the press conferences of presidents ronald reagan and george herbert walker bush</title>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lacross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5quqJ7J">J. Alzheimer&apos;s. Dis</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="959" to="963" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Berisha, V., Wang, S., LaCross, A. &amp; Liss, J. Tracking discourse complexity preceding alzheimer&apos;s disease diagnosis: a case study comparing the press conferences of presidents ronald reagan and george herbert walker bush. J. Alzheimer&apos;s. Dis. 45, 959-963 (2015).</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main" xml:id="_zkaCGDr">Float like a butterfly sting like a bee: Changes in speech preceded parkinsonism diagnosis for muhammad ali</title>
		<author>
			<persName><forename type="first">V</forename><surname>Berisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_nYtWhUF">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1809" to="1813" />
		</imprint>
	</monogr>
	<note type="raw_reference">Berisha, V. et al. Float like a butterfly sting like a bee: Changes in speech preceded parkinsonism diagnosis for muhammad ali. In INTERSPEECH, 1809-1813 (2017).</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main" xml:id="_GWsFpWy">Predicting depression from language-based emotion dynamics: longitudinal analysis of facebook and twitter status updates</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Seabrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Fulcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Rickard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_AFRTVCw">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">100</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Seabrook, E. M., Kern, M. L., Fulcher, B. D. &amp; Rickard, N. S. Predicting depression from language-based emotion dynamics: longitudinal analysis of facebook and twitter status updates. J. Med. Internet Res. 20, e168 (2018). 100</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main" xml:id="_vuDbf5E">Differential Privacy enabled Dementia Classification: An exploration of the privacy-accuracy trade-off in speech signal data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajtmajer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abdullah</surname></persName>
		</author>
		<idno type="DOI">10.21437/interspeech.2023-575</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_4hRKjj7">Proc. INTERSPEECH 2023</title>
		<meeting>INTERSPEECH 2023</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">101</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">BN, S., Rajtmajer, S. &amp; Abdullah, S. Differential Privacy enabled Dementia Classification: An exploration of the privacy-accuracy trade-off in speech signal data. In Proc. INTERSPEECH 2023, 346-350 (2023). 101</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main" xml:id="_x7KBsux">A systematic literature review on wearable health data publishing under differential privacy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Saifuzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Ananna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J M</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ferdous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_QvdGSEf">Int. J. Inf. Secur</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">102</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Saifuzzaman, M., Ananna, T. N., Chowdhury, M. J. M., Ferdous, M. S. &amp; Chowdhury, F. A systematic literature review on wearable health data publishing under differential privacy. Int. J. Inf. Secur. 21, 847-872 (2022). 102</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main" xml:id="_5VMtfrs">The future of digital health with federated learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rieke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_shrguEk">NPJ Digit. Med</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">103</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Rieke, N. et al. The future of digital health with federated learning. NPJ Digit. Med. 3, 119 (2020). 103</note>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Atleson</surname></persName>
		</author>
		<ptr target="https://www.ftc.gov/business-guidance/blog/2023/02/keep-your-ai-claims-check" />
		<title level="m" xml:id="_8z4wyXW">Keep your AI claims in check</title>
		<imprint>
			<date type="published" when="2023-11-21">2023-11-21 (2023</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Atleson, M. Keep your AI claims in check. https://www.ftc.gov/ business-guidance/blog/2023/02/keep-your-ai-claims-check. Accessed: 2023-11-21 (2023). 104</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main" xml:id="_ubSTxG3">Using &quot;real-world data&quot; to study cleft lip/palate care: An exploration of speech outcomes from a multi-center us learning health network</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dunworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_gtxGXF5">Cleft Palate Craniofac. J</title>
		<imprint>
			<biblScope unit="volume">10556656231207469</biblScope>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Dunworth, K. et al. Using &quot;real-world data&quot; to study cleft lip/palate care: An exploration of speech outcomes from a multi-center us learning health network.Cleft Palate Craniofac. J. 10556656231207469 (2023). 105</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main" xml:id="_DrKkFjX">The application of three-dimensional ultrasound with reformatting technique in the diagnosis of fetal cleft lip/palate</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NqRAUb9">J. Clin. Ultrasound</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ji, C. et al. The application of three-dimensional ultrasound with reformatting technique in the diagnosis of fetal cleft lip/palate. J. Clin. Ultrasound 49, 307-314 (2021). 106</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main" xml:id="_aMz7qKa">Eating and speech problems in oral and pharyngeal cancer survivors-associations with treatmentrelated side-effects and time since diagnosis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hadler-Olsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wFwsFuk">Spec. Care Dent</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">107</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Andreassen, R. &amp; Hadler-Olsen, E. Eating and speech problems in oral and pharyngeal cancer survivors-associations with treatment- related side-effects and time since diagnosis. Spec. Care Dent. 43, 561-571 (2023). 107</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main" xml:id="_dVYNCGZ">Preoperative voice analysis and survival outcomes in papillary thyroid cancer with recurrent laryngeal nerve invasion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_FMZRAPW">Front. Endocrinol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">108</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chen, J. et al. Preoperative voice analysis and survival outcomes in papillary thyroid cancer with recurrent laryngeal nerve invasion. Front. Endocrinol. 13, 1041538 (2022). 108</note>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main" xml:id="_JaJMpkT">Effects of vocal intensity and fundamental frequency on cepstral peak prominence in patients with voice disorders and vocally healthy controls</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brockmann-Bauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_ZhYDnf4">J. Voice</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">109</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Brockmann-Bauser, M. et al. Effects of vocal intensity and fundamental frequency on cepstral peak prominence in patients with voice disorders and vocally healthy controls. J. Voice 35, 411-417 (2021). 109</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main" xml:id="_RqBGHde">Perceptual and acoustic evaluation of pitch elevation to predict aspiration status in adults with dysphagia of various aetiologies/beyond stroke</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mavrea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Regan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_spYU9Kp">Dysphagia</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">110</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mavrea, S. &amp; Regan, J. Perceptual and acoustic evaluation of pitch elevation to predict aspiration status in adults with dysphagia of various aetiologies/beyond stroke. Dysphagia 33, 532-533 (2022). 110</note>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main" xml:id="_mXNS2cF">Self-perceived handicap associated with dysphonia and health-related quality of life of asthma and chronic obstructive pulmonary disease patients: A case-control study</title>
		<author>
			<persName><forename type="first">R</forename><surname>Hurtado-Ruzza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9w9JGSq">J. Speech, Lang., Hear. Res</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">111</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hurtado-Ruzza, R. et al. Self-perceived handicap associated with dysphonia and health-related quality of life of asthma and chronic obstructive pulmonary disease patients: A case-control study. J. Speech, Lang., Hear. Res. 64, 433-443 (2021). 111</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main" xml:id="_63WtQn4">The diagnosis of Huntington&apos;s disease</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Folstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Parhad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Folstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_RKKWgnC">Neurol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">112</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Folstein, S. E., Leigh, R. J., Parhad, I. M. &amp; Folstein, M. F. The diagnosis of Huntington&apos;s disease. Neurol. 36, 1279 (1986). 112</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main" xml:id="_Va4cMMZ">Multivariate approaches to understanding aphasia and its neural substrates</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Hula</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-024-01199-1113</idno>
		<ptr target="https://doi.org/10.1038/s41746-024-01199-1113" />
	</analytic>
	<monogr>
		<title level="j" xml:id="_K4G7WeA">Curr. Neurol. Neurosci. Rep</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Wilson, S. M. &amp; Hula, W. D. Multivariate approaches to understanding aphasia and its neural substrates. Curr. Neurol. Neurosci. Rep. 19, 1-9 (2019). https://doi.org/10.1038/s41746-024-01199-1 113</note>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main" xml:id="_jz3jgze">Disorders of vocal emotional expression and comprehension: The aprosodias</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Ross</surname></persName>
		</author>
		<idno type="DOI">10.1016/b978-0-12-822290-4.00005-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7pMNtTk">Handb. Clin. Neurol</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ross, E. D. Disorders of vocal emotional expression and comprehension: The aprosodias. Handb. Clin. Neurol. 183, 63-98 (2021). 114</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main" xml:id="_frhT2Hw">Automated detection of progressive speech changes in early Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">J</forename><surname>Robin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" xml:id="_4Qd6PRa">Alzheimer&apos;s. Dement</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">12445</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Robin, J. et al. Automated detection of progressive speech changes in early Alzheimer&apos;s disease. Alzheimer&apos;s. Dement. 15, e12445 (2023).</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
