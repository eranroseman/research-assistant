<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_gBY8vaY"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2016-07-25">July 25, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Ely</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation">Professor of Economics , Northwestern University.</note>
								<orgName type="department">Professor of Economics</orgName>
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emma</forename><forename type="middle">H</forename><surname>Morrison</surname></persName>
							<affiliation key="aff0">
								<note type="raw_affiliation">Professor of Economics , Northwestern University.</note>
								<orgName type="department">Professor of Economics</orgName>
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-07-25">July 25, 2016</date>
						</imprint>
					</monogr>
					<idno type="MD5">67F2735190AF26838B10B5AD1F641934</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-08-31T08:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=2, consolidateHeader=2, consolidateFunders=1, includeRawAffiliations=true, includeRawCitations=true, includeRawCopyrights=true, generateTeiIds=true, generateTeiCoordinates=[all], sentenceSegmentation=true, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_daZ2h5m">Calculations From The Introduction</head><p xml:id="_xNsAYCF"><s xml:id="_mjGPZ46">Here are the calculations for the expected waiting time under the random beep with probability z.</s><s xml:id="_tB7AJjz">First, consider the probability that there has been an arrival conditional on no beep prior to date t.</s><s xml:id="_PnChFVR">This is the probability that of at least one silent arrival conditional on the event that there was no noisy arrival.</s><s xml:id="_JaR85FD">Notice that by the memoryless property of the Poisson process, conditional on any number of noisy arrivals, the distribution of silent arrivals is Poisson with parameter λ(1z). 1 That is, the proba- bility of a silent arrival is independent of the number of noisy arrivals.</s><s xml:id="_aUCBsME">In particular the probability of at least one silent arrival conditional on no noisy arrival is just the unconditional probability of a silent arrival, i.e.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_3hYs6r4"><p xml:id="_akQMQzy"><s xml:id="_QkYdnQq">Therefore the time it takes for the agent's beliefs to reach p * in the absence of a beep is</s></p><formula xml:id="formula_0">ω = - log(1 -p * ) λ(1 -z)</formula><p xml:id="_GjRG8Sv"><s xml:id="_yhjjgbN">and the probability that this time is reached without a beep is</s></p><formula xml:id="formula_1">e -λzω .</formula><p xml:id="_QSEXpMZ"><s xml:id="_YMDs6gS">Finally, the expected time before the first beep conditional on that beep occurring prior to the agent's beliefs reaching the threshold is</s></p><formula xml:id="formula_2">1 λz - ω e λzω -1</formula><p xml:id="_6j234zA"><s xml:id="_JEyAu4u">Since the agent stops working either because his beliefs reach the threshold or because a beep is heard earlier than ω, the total expected waiting time is the weighted average</s></p><formula xml:id="formula_3">ωe -λzω + ( 1 λz - ω e λzω -1 ) ( 1 -e -λzω</formula><p xml:id="_w3X5je5"><s xml:id="_2TmqTct">) and after some algebra this simplifies to</s></p><formula xml:id="formula_4">1 -(1 -p * ) -z z-1</formula><p xml:id="_98Q9NEP"><s xml:id="_sy4RuSd">λz .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" xml:id="_5hR4Kx3">Formal Derivation Of The HJB Equation</head><p xml:id="_Bwrmn6b"><s xml:id="_Kc8tcbd">Let us approximate the optimized continuous time discounted payoff for the principal by discretizing the time dimension into intervals of length h and the summation</s></p><formula xml:id="formula_5">J(t, µ t ) = E ∞ ∑ s=0 e -r(t+sh) u(µ t+sh ) • h + O(h 2 ). E q [ e -rt u(ν)h + e -r(t+h) V( f (ν)) ] + O(h 2 ).</formula><p xml:id="_KkctCrT"><s xml:id="_XuFuT9d">Dividing through by e -rt ,</s></p><formula xml:id="formula_6">V(µ) = max q∈∆(∆S) Eq=µ E q [ u(ν)h + e -rh V( f (ν)) ] + O(h 2 ).</formula><p xml:id="_zCdaK4Z"><s xml:id="_umCcP4D">Now a first-order approximation</s></p><formula xml:id="formula_7">e -rh V( f (ν)) = e -rh [ V(ν) + V ′ (ν) dν dt h ] + O(h 2 ), so V(µ) = max q∈∆(∆S) Eq=µ E q { u(ν)h + e -rh [ V(ν) + V ′ (ν) dν dt h ]} + O(h 2 ).</formula><p xml:id="_45vjG4e"><s xml:id="_aBAzwE7">I claim that at an optimum q * of the maximization above, E q * V(ν) = V(µ).</s><s xml:id="_UuDCQC6">To see why, for each ν ∈ ∆(S), let q * (ν) be a maximizer for the optimization that defines V(ν).</s><s xml:id="_mxPR3pX">Then we have</s></p><formula xml:id="formula_8">u(ν)h + e -rh V( f (ν)) ≤ E q * (ν) [ u(ν ′ )h + e -rh V( f (ν ′ )) ] = max q∈∆(∆S) Eq=ν E q [ u(ν ′ )h + e -rh V( f (ν ′ ))</formula><p xml:id="_DMtge7u"><s xml:id="_Zyd63Qe">] since the left-hand side is a feasible value for the right-hand side optimization, taking q to be the degenerate lottery.</s><s xml:id="_kq5xtby">Therefore</s></p><formula xml:id="formula_9">V(µ) = E q * [ u(ν)h + e -rh V( f (ν)) ] ≤ E q * E q * (ν) [ u(ν ′ )h + e -rh V( f (ν ′ )) ] = E q * V(ν)</formula><p xml:id="_DFndvRQ"><s xml:id="_b7hWNxY">but also</s></p><formula xml:id="formula_10">V(µ) ≥ E q * V(ν)</formula><p xml:id="_3PrBg6D"><s xml:id="_J5ZT9tt">since the compound lottery in the middle expression above is feasible for the optimization that defines V(µ).</s><s xml:id="_uDTzz6u">We can thus re-arrange as follows</s></p><formula xml:id="formula_11">( 1 -e -rh ) V(µ) = max q∈∆(∆S) Eq=µ E q [ u(ν)h + e -rh V ′ (ν) dν dt h ] + O(h 2 ).</formula><p xml:id="_XpJs36n"><s xml:id="_Fvqmq9W">Dividing through by h and then taking h → 0 we obtain by l'Hopital's rule ,</s></p><formula xml:id="formula_12">rV(µ t ) = max q∈∆(∆S) Eq=µ E q [ u(ν) + V ′ (ν) dν dt ] or rV = cav [ u + V ′ • dν dt</formula><p xml:id="_Y2H6JkF"><s xml:id="_jn28hNN">] .</s></p><p xml:id="_tqUuxzW"><s xml:id="_FwhANyx">3 Calculations For The Basic Model</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1" xml:id="_CHXynBh">Value Function For Delayed Beep</head><p xml:id="_bF7YCgu"><s xml:id="_t488Axp">First, lets calculate the continuation value when the agent's belief is at the threshold p * .</s></p><p xml:id="_9jTSzaD"><s xml:id="_kjyTd6r">The principal collects a flow payoff of 1 until a beep arrives.</s><s xml:id="_5Vs9T88">He discounts payoffs at rate r and beeps arrive at rate λ.</s><s xml:id="_zbqnYhc">This yields the following expected discounted value</s></p><formula xml:id="formula_13">V(p * ). ∫ ∞ 0 ∫ t 0 e -rs λe -λt dsdt = ∫ ∞ 0 [ r -1 e -rs | s=t s=0 ] λe -λt dt = ∫ ∞ 0 1 -e -rt r λe -λt dt = r -1 [ 1 - ∫ ∞ 0 e -rt λe -λt dt ] = r -1 [ 1 -λ ∫ ∞ 0 e -(r+λ)t dt ] = r -1 [ 1 + ( λ r + λ e -(r+λ)t | t=∞ t=0 )] = r -1 [ 1 - λ r + λ ] = 1 r + λ</formula><p xml:id="_Gm74aE8"><s xml:id="_PJmBb2t">Next consider any µ ≤ p * .</s><s xml:id="_57mTQVd">Let τ(µ) be the time remaining before the belief reaches p * .</s></p><p xml:id="_Upr5D4h"><s xml:id="_fwVWTKd">The principal collects a flow payoff of 1 until the belief for a duration τ(µ) then earns the continuation value V(p * ).</s><s xml:id="_gNHzZ6U">The overall payoff is thus</s></p><formula xml:id="formula_14">V(µ) = ∫ τ(µ) 0 e -rt dt + e -rτ(µ) 1 r + λ = 1 r [ 1 -e -rτ(µ) + e -rτ(µ) r r + λ ] (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2" xml:id="_HDhR7hW">Solving the HJB Equation</head><p xml:id="_8KB4SFF"><s xml:id="_tWA6axW">We begin with the function in brackets, i.e.,</s></p><formula xml:id="formula_15">u + V ′ • dν dt (2)</formula><p xml:id="_HwFS57c"><s xml:id="_f5tpUrd">For µ ≤ p * , the flow payoff is constant u ≡ 1, the value function is given by Equation <ref type="formula">1</ref>and we have</s></p><formula xml:id="formula_16">1 + 1 r [ re -rτ(µ) • dτ dµ -re -rτ(µ) r r + λ • dτ dµ ] dν dt = 1 + [ e -rτ(µ) -e -rτ(µ) r r + λ ] dτ dµ • dν dt</formula><p xml:id="_KNxRYsG"><s xml:id="_5zWKuhv">and noting that dτ dµ = -( dν dt ) -1 , this reduces to</s></p><p xml:id="_sKf569e"><s xml:id="_6D3czeH">1e -rτ(µ) + e -rτ(µ) r r + λ which is simply rV over the range µ ≤ p * .</s><s xml:id="_6z5rux8">For µ &gt; p * , the flow payoff is constant u ≡ 0, and the value function is linear with negative slope</s></p><formula xml:id="formula_17">-V(p * ) 1 -p * . Thus u + V ′ • dν dt = -V(p * ) 1 -p * λ (1 -µ)</formula><p xml:id="_B6Y2bU9"><s xml:id="_XeGEeCH">which is negative for µ &lt; 1 and zero at µ = 1.</s></p><p xml:id="_66Bb5Yu"><s xml:id="_u7tccd3">Finally we consider the concavification.</s><s xml:id="_NqQQmbe">We can analyze the two intervals [0,</s></p><p xml:id="_DvyJ3Ys"><s xml:id="_dcpCJFv">p * ] and [p * , 1] separately.</s><s xml:id="_2W97HqY">Since the bracketed function equals rV which is already concave on the interval [0, p * ], it is its own concavification on that interval.</s><s xml:id="_tybenjU">Turning to the interval [p * , 1], the linear function which connects the points (p * , V(p * )) and (1, 0) is concave and no smaller than the bracketed function over this interval.</s><s xml:id="_YxvDuHF">Therefore the concavifi-cation (which is the pointwise smallest such function) must have these two points in its graph.</s><s xml:id="_Rfhfhpz">And any function with smaller values elsewhere would not be concave.</s><s xml:id="_zysM26H">Thus the linear function is the concavification on this interval.</s><s xml:id="_RyydQgb">Finally, rV is just the union of these two functions, and it is concave over the full domain µ ∈ [0, 1].</s><s xml:id="_h8Aymqg">It is therefore the concavification of the function in brackets.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" xml:id="_rHU6Byt">Proofs For The General Single Agent Model</head><p xml:id="_ncUysWG"><s xml:id="_z2yuEME">Proof of Lemma 1.</s><s xml:id="_uyRQ53r">For any current state s and subsequent state s ′ let χ(s, s ′ ) equal the probability conditional on the process being in state s at time l that the process is in state s ′ at time l + h where h is the discrete period length.</s><s xml:id="_W45EzyJ">Let χ be the matrix of these transition probabilities.</s><s xml:id="_Vmqd5p8">Then if the agent begins period t with belief µ and obtains no information, he will begin period t + 1 with belief</s></p><formula xml:id="formula_18">f (µ) = µ • χ.</formula><p xml:id="_XsNCWdA"><s xml:id="_j9qrubw">Proof of Theorem 1.</s><s xml:id="_MPFvswG">It remains only to show that the operator</s></p><formula xml:id="formula_19">TV = cav [(1 -δ)u + δ (V • f )] .</formula><p xml:id="_n3sCfvu"><s xml:id="_6k2FYDt">is a contraction mapping on the complete metric space of bounded real-valued functions with the sup metric.</s><s xml:id="_UvcDaVN">The Blackwell sufficient conditions for T to be contraction mapping (with modulus δ) are as follows.</s></p><formula xml:id="formula_20">1. If V ≥ V ′ then TV ≥ TV ′ , 2. If c is a constant then T(V + c) ≤ TV + δc.</formula><p xml:id="_SqVPSe8"><s xml:id="_FqW4r32">The first follows from the observation that if g ≥ g ′ , then any concave function which is weakly larger than g is also weakly larger than g ′ and therefore cav g ≥ cav g ′ .</s><s xml:id="_cYrv2SJ">The second follows from the observation that for any function h and any constant k, a concave function y is weakly larger than h if and only if y + k is weakly larger than h + k.</s></p><p xml:id="_uKhrD7N"><s xml:id="_CvtHSXE">Therefore cav(h + k) = (cav h) + k.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" xml:id="_geU2eSm">Calculations For the Monopoly Example</head><p xml:id="_aWxBQ5K"><s xml:id="_XFYtHxh">It was asserted that a convex u implies that full-disclosure is optimal and that a concave u implies that no disclosure is optimal.</s><s xml:id="_VtZp7cE">These claims are immediate consequences of Theorem 1.</s><s xml:id="_nYBMqeE">In particular consider any convex u.</s></p><formula xml:id="formula_21">If V is convex then so is (1 -δ)u + δ • f .</formula><p xml:id="_UTpV8D9"><s xml:id="_DZ9Ggj8">The operator T applied to any V is hence the concavification of convex function, i.e. linear (and hence convex.)</s><s xml:id="_nvAG3hQ">Thus the set of all convex functions V is closed under the operator T when u is convex.</s><s xml:id="_xB4dvdq">Thus its fixed point is in the (sup-norm) closure of of the set of all convex functions.</s><s xml:id="_3uJdF6D">The set of all convex functions is closed in the supnorm topology.</s><s xml:id="_9Uk9ErM">The optimal value function is thus the concavification of some convex function and therefore it is linear.</s><s xml:id="_hMZ5bzq">A linear value function implies that full-disclosure is optimal.</s><s xml:id="_T8j6FYx">An analogous argument shows that the optimal value function is (strictly) concave when u is (resp.</s><s xml:id="_PnG59s8">strictly) concave.</s><s xml:id="_8dkZv3d">A (strictly) concave value function implies that no disclosure is (resp.</s><s xml:id="_uf6AEnd">strictly) optimal.</s></p><p xml:id="_454yEfA"><s xml:id="_5r3n56a">Turning to the mixed demand case, let W(ν) represent the value of the no-disclosure policy beginning with belief ν.</s><s xml:id="_FFCy9Yh">It satisfies the recursive equation (recall that we have set λ and r both to 1.)</s></p><formula xml:id="formula_22">W(µ) = u(µ) -W ′ (µ) • dµ dt (3)</formula><p xml:id="_5fwwH6A"><s xml:id="_uXdDNPY">and it inherits the shape of u: it is first strictly concave and then strictly convex as µ ranges from 0 to 1. 2 Refer to Figure <ref type="figure">1</ref> throughout.</s></p><p xml:id="_z3ue2wM"><s xml:id="_rQPdVYe">Figure <ref type="figure">1</ref>: The mixed-demand monopoly example.</s></p><p xml:id="_vKDSKY5"><s xml:id="_fHmpyGZ">We will show that the optimal policy is partially informative: at belief µ = 1 the monopoly continuously sends a partially informative message which sends the belief either to an interior target ν * or keeps it at 1. Once the belief is sent to ν * , no further information is disclosed and the principal earns continuation value W(ν * ).</s></p><p xml:id="_uSHuVEp"><s xml:id="_AGJuhv6">Define X(ν * ) by</s></p><formula xml:id="formula_23">X(ν * ) = u(1) - X(ν * ) -W(ν * ) (1 -ν * ) . (<label>4</label></formula><formula xml:id="formula_24">)</formula><p xml:id="_QMj9bkW"><s xml:id="_jN28DxU">Note that this formula, rearranged, gives the initial value from a policy which, at rate 1/(1 -ν * ) sends the belief to ν * (and otherwise keeps it fixed at 1.)</s></p><formula xml:id="formula_25">X(ν * ) = u(1) 1 + 1 (1-ν * ) + 1 (1-ν * ) W(ν * ) 1 + 1 (1-ν * ) = (1 -ν * )u(1) + W(ν * ) 2 -ν * 2</formula><p xml:id="_mK9p2eX"><s xml:id="_nUn6UN5">The function W can be computed in closed form:</s></p><formula xml:id="formula_26">W(µ) = 6µ 1/2 + 8µ 5/4 + 3µ 2 72 .</formula><p xml:id="_4PnJD2T"><s xml:id="_cucvAvc">I claim that there is a unique ν * ∈ (0, 1) satisfying</s></p><formula xml:id="formula_27">W ′ (ν * ) = X(ν * ) -W(ν * ) 1 -ν * .</formula><p xml:id="_Dvd6YBN"><s xml:id="_tU7Q3PP">To prove this, first note that for all ν * in the convex range of W, X(ν</s></p><formula xml:id="formula_28">* ) ≥ W(1) &gt; W(ν * ) + W ′ (ν * )(1 -ν * ).</formula><p xml:id="_vg2UHbE"><s xml:id="_RSwdDNS">Let us prove these inequalities in turn.</s></p><p xml:id="_B9GKJKS"><s xml:id="_dUthBPf">Consider a policy which discloses nothing until the belief reaches µ ∈ (ν * , 1) whereupon it sends a binary message which sends the belief to 1 or ν * with probabilities p and (1p) respectively.</s><s xml:id="_66ZQkpp">After that it reverts to non-disclosure forever.</s><s xml:id="_dQUnhhb">The value of this policy is</s></p><formula xml:id="formula_29">W(1) + e -τ(µ) [pW(1) + (1 -p)W(ν * ) -W(µ)]</formula><p xml:id="_wxsSfAC"><s xml:id="_vASEBcj">where τ(µ) is the time it takes to reach belief µ.</s><s xml:id="_qHnNbMw">If W is convex to the right of ν * and by the law of total probability, this is greater than W(1).</s><s xml:id="_YtXU4Ku">By induction therefore the value of a policy which sends the same binary signal every time the belief reaches ν * is greater than W(1).</s><s xml:id="_J9z58UV">Since this is true for all µ ∈ (ν * , 1), it is true by continuity for the policy that generates X(ν * ) (i.e.</s><s xml:id="_pqsxJBP">taking limits as µ approaches 1), hence X(ν * ) ≥ W(1).</s></p><p xml:id="_PwUsxqB"><s xml:id="_v9kjBmU">The second inequality follows immediately from strict convexity of W on [ν * , 1].</s></p><p xml:id="_Nc5GxPP"><s xml:id="_c2B4y5F">Thus, if there exists a solution to the displayed equation it must occur at a value of ν * at which W is (strictly) concave.</s><s xml:id="_Y5paXZ3">Moreover by continuity there must exist at least</s></p><formula xml:id="formula_30">one solution because W ′ (0) is infinite (because u ′ (0) is infinite) and X(0) is finite. Re- arrange the equation to obtain (2 -ν * )W ′ (ν * ) + W(ν * ) -u(1) = 0. X ′ (ν * ) = (2 -ν * )W ′ (ν * ) + W(ν * ) -u(1) (2 -ν * ) 2</formula><p xml:id="_9utRE4a"><s xml:id="_m3etbtp">and thus the derivative vanishes at a value ν * that satisfies the displayed equation.</s></p><p xml:id="_5g7AARg"><s xml:id="_CZsFK5t">When W is strictly concave, the function W ′ (µ)(1 -µ) is strictly decreasing and therefore can intersect at most once where X ′ (µ) is zero.</s></p><p xml:id="_EJgtzCS"><s xml:id="_MuaKmk4">Let L(µ) be the linear function connecting the points (ν * , W(ν * )) and (1, X(ν * )) and consider the candidate value function</s></p><formula xml:id="formula_31">V(µ) =        W(µ) if µ ≤ ν * L(µ) if µ &gt; ν * .</formula><p xml:id="_7ZygRFQ"><s xml:id="_hAsNQWe">The function V is concave because we have shown that W is concave on [0, ν * ].</s></p><p xml:id="_8rGQUYN"><s xml:id="_DFKaJQ8">We will show that it solves the HJB equation.</s><s xml:id="_CBuPBzg">Define the function U as the bracketed expression in the HJB equation:</s></p><formula xml:id="formula_32">U(µ) = u(µ) -V ′ (µ) • dµ dt .</formula><p xml:id="_gmxSg8Z"><s xml:id="_8KFfmt8">For µ &lt; ν * , since V(µ) = W(µ), i.e. the no information value, it satisfies the differential equation in Equation <ref type="formula">3</ref>. Therefore U(µ) = V(µ).</s><s xml:id="_HZ5yMdH">Also, for µ = 1, the definition of</s></p><formula xml:id="formula_33">X(ν * ) (Equation 4) ensures that U(1) = V(1) because X(ν * )-W(ν * ) (1-ν * )</formula><p xml:id="_G4pGDgE"><s xml:id="_ku2K4xF">is the slope of L and hence equals V ′ (1) and dµ dt (1) = -1.</s><s xml:id="_9E3BeTt">We will now show that for µ ∈ (ν * , 1) we have U(µ) ≤ V(µ).</s><s xml:id="_qAyrEW3">It will then follow that the concave function V is the smallest concave function no smaller than U, i.e. the concavification.</s></p><p xml:id="_BzNFb7W"><s xml:id="_vhQe8WB">Since</s></p><formula xml:id="formula_34">V(ν * ) = u(ν * ) + V ′ (ν * ) dµ dt (ν * ) and V(1) = u(1) + V ′ (1) dµ dt (1)</formula><p xml:id="_fnE4dE6"><s xml:id="_F82vm3u">and V is linear on [ν * , 1], as is V ′ dµ dt , it follows that over this range</s></p><formula xml:id="formula_35">V = l + V ′ • dµ dt</formula><p xml:id="_5VF5sV5"><s xml:id="_acSKAY3">where l is the linear function whose graph is the chord connecting the points (ν * , u(ν * ))</s></p><p xml:id="_gmXBsts"><s xml:id="_Up2fQhz">and (1, u( <ref type="formula">1</ref>)) on the graph of u.</s><s xml:id="_SFxuWf6">Moreover, by definition</s></p><formula xml:id="formula_36">U(µ) = u(µ) + V ′ (µ) dµ dt (µ). So if we can show that l ≥ u over the range [ν * , 1] then it follows that U ≤ V.</formula><p xml:id="_3hUXTCn"><s xml:id="_7BeGyJF">Consider the graph of u.</s><s xml:id="_RRXvb7V">Since u is concave then convex, there exists a point ν ∈ (0, 1) such that for all µ ≥ ν, the chord connecting points (µ, u(µ)) and (1, u(1)) is above the graph of u, and for all µ &lt; ν, the chord intersects the graph in three points.</s></p><p xml:id="_jxnpHUf"><s xml:id="_BGv22pZ">In fact, the point ν is the unique point satisfying<ref type="foot" target="#foot_0">foot_0</ref></s></p><formula xml:id="formula_37">u ′ ( ν) = u(1) -u( ν) 1 - ν .</formula><p xml:id="_CdAgC3D"><s xml:id="_TFrxfn4">Direct calculation<ref type="foot" target="#foot_1">foot_1</ref> reveals that ν * &gt; ν.</s><s xml:id="_TBnBbPS">Thus, l ≥ u over [ν * , 1].</s></p><p xml:id="_ef8ZAyU"><s xml:id="_KqfnUju">We have shown U ≤ V.</s><s xml:id="_tmQ5zzt">And since the two functions coincide over [0, ν * ] and at 1, there can be no smaller concave function that is pointwise larger than U. Thus V is the concavification of U and thus solves the HJB equation.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6" xml:id="_hZyRSNt">Additional Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1" xml:id="_Bu4vbx9">Beeps In Discrete Time</head><p xml:id="_WkdapDS"><s xml:id="_K5Pmen6">In discrete time the email beeps example can be described as follows.</s><s xml:id="_Kr325pd">The set of states is S = {0, 1} indicating whether or not an email has arrived to the inbox.</s><s xml:id="_Nf2SNu4">The discrete time transition probability from state 0 to 1 is the probability within a period of length h that at least one email arrives and is given by M = 1e -λh yielding the following law of motion for the agent's beliefs when uninformed:</s></p><formula xml:id="formula_38">f (ν t ) = ν t + (1 -ν t )M</formula><p xml:id="_D4CDQS4"><s xml:id="_zSmNR32">The principal's indirect utility function is</s></p><formula xml:id="formula_39">u(ν) =        1 if ν ≤ p * 0 otherwise</formula><p xml:id="_xBZTRzC"><s xml:id="_9bXuMDJ">and he maximizes his expected discounted utility where the discount factor is e -r∆</s></p><p xml:id="_zs3m6C6"><s xml:id="_e6sV5DY">given a continuous time discount rate r.</s></p><p xml:id="_RFWUAbp"><s xml:id="_fK6CYJB">In Section 3.1 I derive the value function and optimal policy analytically.</s><s xml:id="_CQ3VZSJ">Here we will follow a sequence of diagrams to visualize the derivation and gain intuition.</s><s xml:id="_F8QsVuu">Recall the Bellman equation:</s></p><formula xml:id="formula_40">V = cav [(1 -δ)u + δ (V • f )] .</formula><p xml:id="_jrCEdkG"><s xml:id="_YcM73Yf">Consider as an initial guess, a linear V. We can trace through the operations on the right-hand side.</s><s xml:id="_m2BjZQM">The first step is to compose V with the transition mapping f .</s><s xml:id="_4twjAX5">Since f is linear and f (ν) &gt; ν, this composition has the effect of flattening V by rotating its graph to the left as illustrated in the following figure.</s></p><p xml:id="_DTUzh8n"><s xml:id="_dWgmFmj">Next, we take the convex combination with the step function u yielding the discontinuous decreasing function below.</s></p><p xml:id="_sMh6jGK"><s xml:id="_4ghKM47">Lastly, we concavify the resulting function as illustrated in the next figure, and we have the first iteration of the right-hand side operator.</s><s xml:id="_NJPpnUF">Notice that the function obtained differs from the initial candidate value function which is therefore not a fixed point and not the optimal value.</s><s xml:id="_EQ2HvaV">In fact, since the beep-on mechanism discussed in the introduction yields a linear value function, we have shown that beep-on is not an optimal mechanism. 5</s></p><p xml:id="_RQvkjZ6"><s xml:id="_9V7ybcJ">Let us take stock of this first iteration and its implications for the optimal policy.</s></p><p xml:id="_SpHv4C5"><s xml:id="_myRCpYv">Recall that the concavification represents the optimal lottery over interim beliefs, i.e.</s></p><p xml:id="_48hsCh7"><s xml:id="_NPSTfmd">the optimal message distribution.</s><s xml:id="_fWzcBkE">At beliefs along a segment where the concavification differs from the underlying function, the optimal policy is to randomize between the beliefs at the endpoints of the segment.</s><s xml:id="_KJ7RfGn">Thus in the interval (p * , 1], the principal wants to send the agent to either µ = p * or µ = 1 with the appropriate probabilities.</s><s xml:id="_S6g3vwY">At beliefs along a segment where the concavifcation and the underlying function coincide it is optimal to send no message, as is here between µ = 0 and µ = p * .</s></p><p xml:id="_yzQEygc"><s xml:id="_DqYx9kx">The kink at p * is a remnant of the discontinuity in the flow payoff u.</s><s xml:id="_dEtBKxp">It is easy to see that this kink will re-appear at every step of the iteration, as well as the linear segment <ref type="bibr">5</ref> We did not discuss how to interpret beep-on when the agent begins with a prior greater than zero.</s><s xml:id="_5R3sqtJ">A fitting story is the following.</s><s xml:id="_ePwWx9T">The agent arrives to his office in the morning with a belief µ 0 that there is an email already there waiting for him.</s><s xml:id="_Z9U2RKE">If indeed there is an email it will beep when his computer boots up, i.e. with probability µ 0 .</s><s xml:id="_EyVHA9W">If it does not, then his belief jumps to 0 and beep-on continues from there.</s><s xml:id="_tGknj98">Thus, the value at µ 0 is just (1 -µ 0 )V(0).</s><s xml:id="_zfXxR5W">from p * to 1.</s><s xml:id="_awPNskU">What subsequent iterations add are additional kinks, first at the point f -1 (p * ) in the second iteration, then at f -2 (p * ), etc.</s><s xml:id="_WhYt2ey">This occurs when we compose the drift mapping f with the previous iteration, shifting the kinks successively leftward.</s></p><p xml:id="_hESZc9P"><s xml:id="_gNJxhvj">As we continue to iterate these are the qualitative features of the fixed point to which we converge. <ref type="bibr">6</ref></s><s xml:id="_Q7RzVC5">The optimal value function is represented in Figure <ref type="figure" target="#fig_0">2</ref>. Now consider what happens to the optimal value function when we shorten the period length.</s><s xml:id="_qWxYBre">In the shorter time interval the belief moves less between periods and f approaches the identity mapping.</s><s xml:id="_vVe5ZZV">This has two implications.</s><s xml:id="_qFyTm3V">First, the number of kinks multiplies and in the limit the value function is smooth to the left of p * .</s><s xml:id="_zBC4tGs">Second, the slope of the linear segment just to the left of p * approaches the slope of the linear segment from p * to 1.</s><s xml:id="_NX8gbR2">In the limit therefore, the value function is differentiable at p * and indeed at every belief, see Figure <ref type="figure" target="#fig_1">3</ref>.</s></p><p xml:id="_Mb8nmAu"><s xml:id="_vuNtwMu">It follows that to the left of p * , it is uniquely optimal to send no message.</s><s xml:id="_b74V7YS">In the discrete-time approximation, the linear segments between kinks allowed for a multiplicity of optimal policies ranging from randomization across the whole segment to no message at all.</s><s xml:id="_RkhM8Ja">In continuous time, the strict concavity implies that any non-degenerate lottery is suboptimal.</s><s xml:id="_nawJCBY">To the right of p * , it remains optimal to randomize between p * and 1.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2" xml:id="_Cc9Qcnq">Ergodic Process</head><p xml:id="_2jDdK8p"><s xml:id="_baKYCWx">In the beeps example the state s = 1 is absorbing.</s><s xml:id="_AmNf84F">When on the other hand the process is ergodic a new issue must be addressed.</s><s xml:id="_jSWe8xK">If the agent's belief reaches µ = 1, it will begin to drift back to the interior, enabling further information revelation by the principal.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Rw96bZ2">How does the principal optimally incorporate this possibility?</head><p xml:id="_N9bFKhj"><s xml:id="_35U4hBm">To address this, consider now full-support transition probabilities so that the process admits a unique invariant distribution µ * and let's assume µ * &gt; p * .<ref type="foot" target="#foot_3">foot_3</ref></s></p><p xml:id="_PAm9K7Q"><s xml:id="_k8QwVRu">With µ * as the invariant distribution, the law of motion for beliefs is no longer monotonic.</s><s xml:id="_P92ZV7y">Beliefs greater than µ * move downward and beliefs below µ * move upward.</s><s xml:id="_fvaM7Ry">The mapping f crosses the 45-degree line at µ * :</s></p><p xml:id="_d9Q2wRQ"><s xml:id="_STBBXjs">To aid the analysis, it helps to make a general observation about absorbing sets of beliefs.</s><s xml:id="_a7vRC4Y">Say that an interval I ⊂ [0, 1] is absorbing under f if f (µ) ∈ I for all µ ∈ I.</s></p><p xml:id="_mPy7x3c"><s xml:id="_7cRUusy">According to the following lemma, if u is linear over an interval that is absorbing under f , then the value function must also be linear over that interval.</s></p><p xml:id="_Whw5qeZ"><s xml:id="_vdjXvNn">Lemma 1. Suppose that I is absorbing under f , and that u is linear over I. Then V is also linear on I.</s></p><p xml:id="_ykNVr9D"><s xml:id="_f5XSpTS">Proof.</s><s xml:id="_EJ9kCW2">Consider any candidate value function W which is linear over I. Since f is linear and u is linear over I, the formula</s></p><formula xml:id="formula_41">(1 -δ)u + δ (W • f ) (5)</formula><p xml:id="_bhrDHjZ"><s xml:id="_6UyjbXS">must be linear over I because it is the convex combination of two functions which are linear over that interval.</s><s xml:id="_29uycrs">(That the composition is linear follows from the assumption that I is absorbing and W is linear on I.)</s></p><p xml:id="_WW5YrWR"><s xml:id="_gxqUJRQ">The concavification of Equation 5 must be linear over I. Thus, iteration starting with W must always stay within the set of functions which are linear over I, i.e. the set of such functions is invariant under the value.</s><s xml:id="_ZnCZS9f">Since the value mapping is a contraction, iteration converges globally to a fixed point, the fixed point must belong to any invariant set of functions.</s></p><p xml:id="_sZF35Re"><s xml:id="_J5fECR6">When µ * &gt; p * the interval(p * , 1) is absorbing under f .</s><s xml:id="_XxY7gF8">Therefore the value function is linear there.</s><s xml:id="_yfStJjW">It follows that the value function has the same shape as in the absorbing beeps problem.</s><s xml:id="_VQgkPvX">The optimal policy is therefore identical.</s><s xml:id="_jxfhJqT">In terms of implementation there is only one novelty: at µ = 1 beliefs are now trending downward, i.e. the agent knows that eventually there will be a transition from state 1 to state 0. According to the optimal policy, the instant beliefs move into the interior the principal is randomizing between the two endpoints p * and 1.</s><s xml:id="_kWYX4em">This is achieved by a random message that reveals state changes but with false positives.</s><s xml:id="_VaeaP3b">As soon as a transition occurs the message is sent, but also each instant a transition does not occur the message is still sent but with a probability less than 1 calibrated so that the message induces interim belief p * .</s><s xml:id="_z72M3aV">Since the message has false positives but not false negatives, the agent remains at µ = 1 as long as no message is heard.</s></p><p xml:id="_JBDxzzq"><s xml:id="_sqfn3c4">In particular, the value V( <ref type="formula">1</ref>) is positive now because the agent will periodically switch back to working when his beliefs jump down to p * .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3" xml:id="_gVeV4NB">Three States</head><p xml:id="_Cbmk79m"><s xml:id="_MMGJAkH">When there are three states, S = {0, 1, 2} and two actions, the threshold is no longer a point but a line segment through the simplex of beliefs ∆S.</s><s xml:id="_v3CGwk3">On one side of the line the agent takes action 0 and on the other side he takes action 1.</s><s xml:id="_c9Kfrpd">The belief dynamics operate in a 2-dimensional simplex and can therefore be significantly more complicated.</s><s xml:id="_Mstx3SC">In this section I analyze a simple extension of the beeps problem to 3 states to illustrate.</s><s xml:id="_vabWpwN">This example is special because the belief dynamics have a monotonicity property.</s><s xml:id="_mGaddjF">Once the to zero at the s = 2 vertex, iterations lead to a piecewise linear value function with kinks along these segments. <ref type="bibr">8</ref></s><s xml:id="_NC4NPPd">The continuous time limit value function will therefore be linear along these line segments but strictly concave along rays toward the s = 2 vertex in the region below the threshold.</s><s xml:id="_aH9Za9d">It will be linear above the threshold and equal to zero at the s = 2 vertex.</s><s xml:id="_V7U5A8C">Thus, the optimal mechanism is a delayed beep signaling a past arrival of the second email.</s></p><p xml:id="_pGmUQd8"><s xml:id="_AhERqG7">The novelty that arises with three states concerns the evolution of beliefs and continuation values along the threshold.</s><s xml:id="_EvWz2vY">At the threshold the principal's policy is designed to maximize the probability that the agent continues working.</s><s xml:id="_wUaSNqB">As usual this is accomplished by sending the agent either to the threshold or to the most distant point in the shirk region (with the appropriate probability), in this case the vertex (0, 0, 1) where the agent is certain that two emails are waiting.</s><s xml:id="_V2zwTMY">This signal allows the agent to increase his belief that a single email has arrived and thus as long as the agent remains at the threshold, this belief will continue to trend upward, converging toward the right face of the simplex.</s><s xml:id="_DxkSEXH">Note that the right face, where the agent is certain that at least 1 email is waiting, is isomorphic to the original 1-dimensional beeps problem because the agent is simply waiting to find out if one more email arrives.</s></p><p xml:id="_FGuQdT7"><s xml:id="_vxvCsZP">The following diagram shows the path of the agent's beliefs.</s><s xml:id="_5wGnBCa">The beliefs will follow this path until they reach the threshold, then remain on the path until a beep sounds.</s></p><p xml:id="_9UeURQW"><s xml:id="_j8NYCuV">As long as there is no beep the beliefs will converge asymptotically to the right face.</s></p><p xml:id="_XNRzePD"><s xml:id="_kewyS5Z">It follows that the length of the optimal delay must change as time passes.</s><s xml:id="_cSzxWPa">To see this, first consider the delay length at the point a where the beliefs first touch the threshold.</s><s xml:id="_bFvmcSU">Let's determine the delay length that keeps the agent on the threshold.</s><s xml:id="_xcpv3r6">Let t a denote the length of time it takes for beliefs to reach a from the vertex (1, 0, 0).</s><s xml:id="_uxdVZ7r">If the beep has delay t a then when the agent is at a and hears no beep his updated beliefs continue to attach probability p * to the presence of 2 emails.</s><s xml:id="_uepAku6">The absence of a beep tells the agent that a second email did not arrive t a moments ago.</s><s xml:id="_JWh5h4a">The key question is what does this information tell the agent about the conditional distribution over the remaining states s = 0, s = 1.</s><s xml:id="_P9hJYV2">At that point in the past he was at the point (1, 0, 0).</s><s xml:id="_tEKJFTu">In particular he is certain that not even the first email had arrived.</s><s xml:id="_svUTFsM">Learning that a second email did not arrive at that moment gives him no information about the other states since the simultaneous arrival of two emails has probability zero.</s></p><p xml:id="_6XHxVXh"><s xml:id="_VEjcvm2">Thus, the absence of a beep tells him that his beliefs at the time t a ago were correct, and thus that his current beliefs should be updated from those prior beliefs based only on the information that a time period of length t a has passed during which he learns nothing about arrivals.</s><s xml:id="_9eFkWR5">By construction that updated belief assigns exactly p * to s = 2.</s></p><p xml:id="_eHtNHGz"><s xml:id="_N5YyQfj">By contrast, consider a point like b, further to the right.</s><s xml:id="_KJCWgrx">At this point he attaches higher probability to the presence of a single email.</s><s xml:id="_vYSVns2">Suppose the principal continued to use a beep with delay t a .</s><s xml:id="_DC6b7Nb">What does the agent believe conditional on hearing no beep?</s></p><p xml:id="_svhUYYW"><s xml:id="_JeCdw5b">He learns that as of t a ago, the second email had not arrived.</s><s xml:id="_7qdwU62">At that point in the past he assigned positive probability to the arrival of the first email.</s><s xml:id="_pGQSuhn">Of course the absence of the second email is information: it makes it less likely that the first email arrived.</s></p><p xml:id="_BYCkw4w"><s xml:id="_3ZppQbr">But nevertheless he will continue to assign positive probability to the event that a first email had arrived t a ago.</s><s xml:id="_GERagme">To obtain his current beliefs he will update that posterior based on knowing that t a time has passed.</s><s xml:id="_4k94ed2">His updated belief that a second has arrived during that time will be larger when starting from a positive probability of a first email than when starting with probability zero.</s><s xml:id="_nfuwDxe">The latter starting point would lead him to p * , so using the delay length t a would put him above p * .</s></p><p xml:id="_AWJMnVr"><s xml:id="_c9vh8ET">Therefore, in order to keep the agent on the threshold, the delay length must be shorter the more time has passed.</s><s xml:id="_b4zrnTN">In particular if the second email arrives at time t ′ then the delay before beeping must be shorter than if the second email arrived at time t &lt; t ′ .</s><s xml:id="_cpYTsP6">What happens to this delay length asymptotically as time increases?</s><s xml:id="_BumJzWZ">Since the beliefs are approaching probability 1 that exactly 1 email is waiting, the length of time it takes for the probability of a second email to equal p * converges to the length of time it would take if the agent were certain at the outset that the first email had already arrived.</s><s xml:id="_yHVQTvE">This is just the length of time for the arrival of a single email and that is the length t * from the 1-dimensional problem.</s></p><p xml:id="_eEVAPKC"><s xml:id="_Fxb44Fd">We can understand in these terms why the continuation value must decline as we move toward the right face.</s><s xml:id="_F9tq8Kg">Because the delay is shortening but the arrival rate of email is constant, it follows that beeps are arriving more quickly and thus the agent is jumping sooner on average to the upper vertex.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4" xml:id="_RKA3xu3">Three Actions</head><p xml:id="_kaFv5AM"><s xml:id="_KvEZT3E">The solutions for each of the examples considered thus far are special in at least two senses.</s><s xml:id="_53KQcVJ">First, as was shown by Renault, Solan and Vieille (2014) the optimal mechanism is greedy; in particular it is nearly identical to the optimal mechanism in a static version of the problem.</s><s xml:id="_W5Muf6b">Second, the optimal policy is monotonic in that there is an initial phase of silence leading eventually to a phase of random messages.</s><s xml:id="_Za7yyWu">These features are typical of problems with two states and two actions.</s><s xml:id="_ZExczvG">In this subsection I present the simplest 3 action problem in which the optimal mechanism is very different than the static problem and in particular consists of an early phase of messages followed by a duration of silence and then ultimately a final message phase.<ref type="foot" target="#foot_5">foot_5</ref></s></p><p xml:id="_s7wvu96"><s xml:id="_RqhrwzS">Consider the following indirect utility function with 3 steps:</s></p><formula xml:id="formula_42">u(ν) =                5/4 if ν = 0 1 if ν ∈ (0, 1/2] 0 otherwise (6)</formula><p xml:id="_ARy52Tm"><s xml:id="_SD98vqY">Here is a story that goes with it.</s><s xml:id="_trY7XBM">When the agent is certain there is no email waiting he can work with full concentration.</s><s xml:id="_CJD52Cm">When there is a small chance of an email he is tempted to check but he resists the temptation.</s><s xml:id="_xZhcFEt">The effort spent on willpower makes him somewhat less productive.</s><s xml:id="_TutmbX6">Finally when his beliefs cross the threshold (here p * = 1/2) he succumbs to temptation and stops working.</s></p><p xml:id="_ZsY8Jm9"><s xml:id="_MeRjMcr">The interval (1/2, 1] is absorbing and u is linear there and so by Lemma 1 the value function has the familiar linear segment and the optimal mechanism randomizes between 1/2 and 1 when the beliefs are anywhere in between.</s><s xml:id="_E3Zsmrt">To analyze the interval [0, 1/2) note that one feasible mechanism for the principal is to use the optimal mechanism from the basic beep example.</s><s xml:id="_FDTnA2r">That would yield a value function which is differentiable at the threshold 1/2.</s><s xml:id="_VCXuWHZ">Even though this is not optimal for the present problem, it places a lower bound on the optimal value function.</s><s xml:id="_xkjMd9K">In particular, the optimal value function cannot have a kink at 1/2.</s><s xml:id="_qQJpSBb">The value function is in fact smooth and strictly concave over some interval (p * * , 1/2] so that no message is optimal there.</s><s xml:id="_XKhujSw">However, unlike the original beeps problem, p * * ̸ = 0 and on the interval [0, p * * ] the value function is again linear.</s><s xml:id="_JXpbtKR">Intuitively, randomizing between 0 and p * * allows the principal to stay at the point 0, earning the high flow payoff of 5/4 for some duration, whereas following the original beeps solution the beliefs would spend only an instant there.</s></p><p xml:id="_bBYXBmr"><s xml:id="_b6fz2yv">With these observations in hand we can now show formally how the optimal mechanism changes in the three action version.</s><s xml:id="_NwHZ5pg">Indeed, if we take the original beeps value function V as a candidate continuous-time value function for the three-action problem, the HJB equation tells us to compute its time-derivative and add it to the three-step u in Equation <ref type="formula">6</ref>.</s><s xml:id="_8EU9KPC">We obtain exactly the same graph except that the height at µ = 0 jumps up by 1/4.</s><s xml:id="_JjYJeNe">When we concavify:</s></p><p xml:id="_cyTAmKB"><s xml:id="_hTcbbxe">We see that we do not recover V but instead there is now a linear segment over an initial interval.</s><s xml:id="_GADgszH">This gives us a hint that the optimal value function will have a similar shape.</s><s xml:id="_pPhpmrn">We can solve the model by picking the p * * that equates these and thus produces a fixed point.</s></p><p xml:id="_B2UGFGC"><s xml:id="_zpgX5EE">V(p * * ) + p * * V ′ (p * * ) = 5/4 + V ′ (p * * )λ.</s></p><p xml:id="_7wNF63B"><s xml:id="_YU2Ysva">A distinguishing feature of this example is that the optimal policy uses both false negatives and false positives.</s><s xml:id="_xRgycDr">In the initial phase, the signals that move from 0 to p * * are false positives: conditional on the agent receiving this signal he changes his behavior but there is a probability 1p * * that this signal was received even if no email arrived.</s></p><p xml:id="_neYp2DB"><s xml:id="_9jYAksA">On the other hand, once the agent reaches µ = 1/2 the optimal policy reverts to the false negatives from the original email problem.</s></p><p xml:id="_gVNezEG"><s xml:id="_qUEeYTx">functions of the state change date, ϕ.</s><s xml:id="_VduypxJ">In particular,</s></p><formula xml:id="formula_43">r1 (ϕ) = ϕ + t * r2 (ϕ) =        ϕ if ϕ ≥ t * -1 λ log ( F(ϕ) p * ) + t * if ϕ &lt; t *</formula><p xml:id="_ahB4kJx"><s xml:id="_qbND6Ws">The graphs of these functions are depicted in Figure <ref type="figure" target="#fig_3">4</ref>. Highlighted in blue is the graph of max ri , the date at which a bank run occurs.</s><s xml:id="_UpqgmjN">First, notice that a bank run cannot occur prior to the date t * * .</s><s xml:id="_WeQtkfN">It is the unique intersection of the two curves above, t * * = r1 (ϕ * * ) = r2 (ϕ * * ).</s><s xml:id="_7YG3gxU">Since this occurs prior to t * it</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc><div><p xml:id="_Ry4JTUp"><s xml:id="_zEeD2dj">Figure 2: The optimal value function for the Beeps problem.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc><div><p xml:id="_B8EqGh4"><s xml:id="_tpxTa9y">Figure 3: The continuous time value function.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc><div><p xml:id="_aqV4vGy"><s xml:id="_AeGsAtQ">And indeed we can reduce the functional fixed-point problem in the HJB equation to a parametric equation with a single unknown p * * .</s><s xml:id="_Md7F48A">For suppose we pick a threshold p * * where the mechanism switches from randomizing to silence.</s><s xml:id="_t4kK6wc">Knowing that the value function will be smooth at that point tells us what the slope of the initial linear segment must be.</s><s xml:id="_QVacBEb">It must be the slope of the email value function at p * * , namely V ′ (p * * ).</s><s xml:id="_6dkwH2q">This therefore tells us a candidate value for V(0):V(p * * ) + p * * V ′ (p * * )Now when we take the resulting candidate value function and feed it into the righthand side of the HJB equation we obtain a new value for V(0):u(0) + V ′ (p * * )λ</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc><div><p xml:id="_ZVBJCTH"><s xml:id="_JzWX3qq">Figure 4: Beep times ri as a function of the state change time ϕ for the optimal multiagent mechanism.</s></p></div></figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p xml:id="_KC85xDV"><s xml:id="_cXxnBDW">In fact if we were to consider a static version of this problem, we would apply the methods of Kamenica and Gentzkow (2011) and consider the concavification of u.</s><s xml:id="_ac7zDDF">The concavification would coincide with u to the left of ν, and would be linear to the right.</s><s xml:id="_7SZK8Jf">Thus, ν would be the target belief of a partially informative policy in the static problem.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p xml:id="_uRNPwN7"><s xml:id="_bQFxHKS">Specifically, ν ≈ 0.031 while ν * ≈ 0.058.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p xml:id="_yDxd5BN"><s xml:id="_QzdECwK">The number of kinks will be the maximum index k such that f k (0) ≤ p * .</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p xml:id="_RrwvqBQ"><s xml:id="_fj7HkVw">If µ * ≤ p * the problem is simpler and less interesting.</s><s xml:id="_BqyT2z4">Eventually the beliefs will reach p * .</s><s xml:id="_wUyDNS7">Once there the principal can cease sending messages and the agent will remain at p * and work forever.</s><s xml:id="_j9FrEQK">The only problem to solve is how to get the agent to start working as quickly as possible when he begins away from p * .</s><s xml:id="_7yxTSDV">It can be shown that this is accomplished by following exactly the strategy from the original beeps example.</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4"><p xml:id="_YB2qzXy"><s xml:id="_yr2d2vQ">These are not the level sets.</s><s xml:id="_bEE79mq">As we will show below, the value declines as we move to the right along the p * line.</s><s xml:id="_hBQxq8V">This pattern will thus be preserved at all of its inverse images under f .</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5"><p xml:id="_nqhytWN"><s xml:id="_rK8Mm2B">Renault, Solan and Vieille (2014) also present an example in which the optimal mechanism is nongreedy involving two actions but three states.</s><s xml:id="_6E2tQY8">Two-state problems are generally easier to analyze so the example below is simpler.</s></p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_qTDgcc3"><p xml:id="_EnXjqas"><s xml:id="_hMPQdMk">beliefs leave the region where the agent takes a given action they never return (absent information from the principal).</s><s xml:id="_NBW9wCm">With two states the belief dynamics always have this property.</s><s xml:id="_rgDUEbM">With three states the beliefs may cycle and move up and down the steps of the principal's payoff function u on their path toward the invariant distribution.</s><s xml:id="_APvMsex">Such problems are considerably more complex to solve.</s><s xml:id="_jmUv7kU">In independent work Renault, Solan   and Vieille (2014) analyze the many-state problem in more detail.</s></p><p xml:id="_7KYejAy"><s xml:id="_puTywMb">Consider a variation of the email problem in which the agent wishes to check as soon as the probability is sufficiently large, at least p * , that there are at least two emails to read.</s><s xml:id="_3KcdVjX">Let s ∈ S = {0, 1, 2} denote the number of unread emails currently in the inbox, where s = 0 and s = 1 indicate the exact number and s = 2 indicates 2 or more.</s></p><p xml:id="_Ukcx8cf"><s xml:id="_xYxqkvr">Maintain the assumption that email arrives at rate λ.</s><s xml:id="_ZRNfReq">The following diagram illustrates the situation.</s><s xml:id="_zRr9czy">The simplex is the set of possible beliefs for the agent and the line depicts the threshold above which the agent checks.</s><s xml:id="_mMN5Xqs">The arrows show the flow of the agent's beliefs when the principal withholds information.</s><s xml:id="_Rtf4fRM">The constant arrival of email implies that the beliefs move up and to the right.</s><s xml:id="_HpnDqnz">This analysis of this problem follows similar lines as the two-state email beep problem.</s></p><p xml:id="_9AKzMet"><s xml:id="_E2USfK5">In the diagram below the lines represent points which lead by iterations of f to the threshold line.</s><s xml:id="_wey4zxW">If we begin with a candidate value function which is linear and equal 7 Appendix For The Multi-Agent Section</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1" xml:id="_57DtAtG">Construction Of The Mechanism</head><p xml:id="_WP8S3yY"><s xml:id="_M8MTfT9">The two-agent mechanism is constructed by the following logic.</s><s xml:id="_CnPMmcS">Let's consider mechanisms in which agent 1 has a beep with a delay t * , and agent 2 withdraws immediately if the state change happens after t * .</s><s xml:id="_Nm72wbg">Within mechanisms with these properties, if the state changes after date t * , i.e. ϕ &gt; t * then agent 1 will be the last to withdraw and the date of the bank run is ϕ + t * .</s><s xml:id="_9UWXcEH">It remains only to specify the date at which 2 withdraws if the state change happens before t * .</s><s xml:id="_JdjZ8NP">Let us define the function ψ(ϕ) to give the date at which agent 2 withdraws as a function of the state change date ϕ.</s><s xml:id="_Uh3XBED">The only requirement of the random variable ψ is that its distribution be exponential with parameter λ, to satisfy incentive compatibility for agent 2.</s></p><p xml:id="_VbRUvYY"><s xml:id="_b9B5MCF">Then, conditional on ϕ ≤ t * agent 2 switches to run at r2 = ψ(ϕ), agent 1 switches to run at r1 = ϕ + t * and a bank run occurs at the following time max {r 1 , r2 } = max {ϕ + t * , ψ(ϕ)} with conditional expected value (conditional on the state change occurring prior to t * )</s></p><p xml:id="_7x4UKZA"><s xml:id="_aKEX2Rh">where</s></p><p xml:id="_9y9anc7"><s xml:id="_PDBfPfS">is the conditional CDF of max {r 1 , r2 }.</s></p><p xml:id="_XHDF68c"><s xml:id="_5TC2YDZ">From the theory of copulae in probability theory, and in particular Sklar's Theorem and the Fréchet-Hoeffding Theorem (see Nelsen (1999)) we can minimize G pointwise, and therefore maximize the expected delay length in Equation 7 by adopting as the the joint distribution for ϕ and ψ (whose marginal distributions we are given) the Fréchet-Hoeffding lower bound.</s><s xml:id="_g7zyehH">In this case the lower bound is achieved by setting</s></p><p xml:id="_kmYEynw"><s xml:id="_6WWfYHD">for all ϕ ≤ t * where F is the (marginal) CDF of ϕ, (i.e. the CDF of the exponential distribution with parameter λ.)</s><s xml:id="_dd4pf37">To verify, conditional on ϕ ≤ t * the distribution of</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_ZJs34AS">Bayesian persuasion</title>
		<author>
			<persName><forename type="first">Emir</forename><surname>Kamenica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Gentzkow</surname></persName>
		</author>
		<idno type="DOI">10.1257/aer.101.6.2590</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_D2Dh34A">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Kamenica, Emir, and Matthew Gentzkow. 2011. &quot;Bayesian persuasion.&quot; American Eco- nomic Review, 101(6).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main" xml:id="_f7UCqsP">An introduction to copulas</title>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">B</forename><surname>Nelsen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4757-3076-0_4</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Nelsen, Roger B. 1999. An introduction to copulas. Springer.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Jér</forename><surname>Renault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eilon</forename><surname>Ôme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName><surname>Vieille</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.geb.2017.04.010</idno>
		<idno type="arXiv">arXiv:1407.5649</idno>
		<title level="m" xml:id="_GjWVnhy">Optimal Dynamic Information Provision</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Renault, Jér ôme, Eilon Solan, and Nicolas Vieille. 2014. &quot;Optimal Dynamic Informa- tion Provision.&quot; arXiv preprint arXiv:1407.5649.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
